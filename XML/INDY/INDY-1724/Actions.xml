<Action id="51703" issue="34163" author="toktar" type="comment" created="2018-10-03 15:15:40.0" updateauthor="toktar" updated="2018-10-03 15:15:40.0"> <body><! CDATA In this task was found a bug in Restarter class. {code:java} stab_node8: Oct 01 10:03:49   File "/usr/local/lib/python3.5/dist-packages/indy_node/server/restarter.py", line 55, in _update_action_log_for_started_action stab_node8: Oct 01 10:03:49     self._notifier.sendMessageUponNodeRestartComplete( stab_node8: Oct 01 10:03:49 AttributeError: 'PluginManager' object has no attribute 'sendMessageUponNodeRestartComplete' {code} Fixed in PRÂ https://github.com/hyperledger/indy-node/pull/960  ></body> </Action>
<Action id="52603" issue="34163" author="sergey.khoroshavin" type="comment" created="2018-10-24 17:08:26.0" updateauthor="sergey.khoroshavin" updated="2018-10-24 17:08:26.0"> <body><! CDATA *Scope limiting* This investigation is concerned with case of increasing memory usage during load that node can sustain (so queues are in more or less in steady state)  *Limiting buffer sizes* Node use default RocksDB configuration and according to documentation defaults already have very tight limits.  *RocksDB vs LevelDB* !Screenshot from 2018-10-09 13-13-32.png|thumbnail!  Test was conducted with half nodes running RocksDB and another half LevelDB. It can be seen that memory consuption is rougly the same. This indicates that they either: * have same memory consumption OR * are not major memory consumers  *RocksDB metrics* !Screenshot from 2018-10-24 18-30-26.png|thumbnail!  This was part of other test with much higher load (hence much bigger memory consumption), but nodes already had some RocksDB metrics enabled. Interesting thing here are RocksDB memtable usage metrics. It can be seen that one database steadily increases it's memtable size until 70 Mb at which point it gives memory back and then process is repeated. Some other databases have much slower growth which doesn't cut off, but on the other hand they don't reach 70 Mb, so if test was run for more time we might see same cut off at 70 Mb. It can also explain visible jaggies in memory consumption of RocksDB vs LevelDB run. Unfortunately most interesting metric (block cache usage) is not available yet (it requires patching  RocksDB python wrapper).  *RocksDB vs file storage* This is work in progress which will be finished in scope of INDY-1769  *Preliminary conclusions* During sustained load memory usage grows and it might be RocksDB, but this growth is most likely have an upper bound. To prove this relatively long (probably at least 2-3 days) sustainable load test is needed.  ></body> </Action>
<Action id="52616" issue="34163" author="ashcherbakov" type="comment" created="2018-10-25 06:51:50.0" updateauthor="ashcherbakov" updated="2018-10-25 06:51:50.0"> <body><! CDATA 1) INDY-1774 is created to run a long tests to check memory consumption (prove a theory from the comment above)  2) INDY-1769 is created to continue testing with just file storage enabled  ></body> </Action>
