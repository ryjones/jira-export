<Action id="51335" issue="34161" author="derashe" type="comment" body="Some metrics added to find stashing collection(s) https://github.com/hyperledger/indy-plenum/pull/929" created="2018-09-28 07:23:16.0" updateauthor="derashe" updated="2018-09-28 07:23:16.0"/>
<Action id="51967" issue="34161" author="derashe" type="comment" created="2018-10-10 09:01:48.0" updateauthor="derashe" updated="2018-10-10 09:01:48.0"> <body><! CDATA Metrics of length of collections did not give us the results. New metrics added, which measuring most 'heavy' collections   https://github.com/hyperledger/indy-plenum/pull/934  ></body> </Action>
<Action id="52153" issue="34161" author="derashe" type="comment" created="2018-10-12 11:13:28.0" updateauthor="derashe" updated="2018-10-12 11:14:16.0"> <body><! CDATA Another day, another metrics(   https://github.com/hyperledger/indy-plenum/pull/945   ></body> </Action>
<Action id="52162" issue="34161" author="derashe" type="comment" created="2018-10-12 14:07:57.0" updateauthor="derashe" updated="2018-10-12 14:11:57.0"> <body><! CDATA Test node with  1.6.632 next case:|https://github.com/hyperledger/indy-node/releases/tag/1.6.632-master   for i in range(6):      run 10 minutes load of 40 nym/s      stop load for 5 minutes  run 30 minutes load of 40 nym/s  stop load and wait for 10 minutes  dump logs, metrics and validator info  ></body> </Action>
<Action id="52309" issue="34161" author="derashe" type="comment" created="2018-10-16 08:05:15.0" updateauthor="derashe" updated="2018-10-16 08:05:15.0"> <body><! CDATA !image-2018-10-16-11-05-27-789.png|thumbnail!  Here's the results of upper load testing. As we can see internal structures weight does not affect memory much.  ></body> </Action>
<Action id="52322" issue="34161" author="derashe" type="comment" created="2018-10-16 13:55:45.0" updateauthor="derashe" updated="2018-10-17 07:23:09.0"> <body><! CDATA During researching leaks, we've tested some cases locally ( https://github.com/hyperledger/indy-node/pull/984)   We used such a scenario for testing on a node: * order n txns * send n txns and hold them unordered * order these txns * call_gc * send n txns and hold them unordered again * order these txns again * call_gc again     ></body> </Action>
<Action id="52369" issue="34161" author="derashe" type="comment" created="2018-10-17 14:49:55.0" updateauthor="derashe" updated="2018-10-17 18:39:39.0"> <body><! CDATA We've profiled local tests with a objgraph and when we tried to profile every dict in node's pool, we've got such a results:  !image-2018-10-17-17-49-34-832.png|thumbnail!  As you can see, we are not getting more than 150 MBs. But in the same time RSS of the python process was around 1 Gb.   ></body> </Action>
<Action id="52370" issue="34161" author="derashe" type="comment" created="2018-10-17 14:56:58.0" updateauthor="derashe" updated="2018-10-17 18:40:10.0"> <body><! CDATA We've profiled Nodes with a pympler and it also showed us that when we are stashing not more that 60 Mbs when we have over 6k txns stashed. So we can be pretty sure, that there is no leak in our node code  Also, we've probably could reproduce memory leak in test environment. So probable direction for researching is to debug local test for something out of scope node's collections (like zmq or kv storages)  ></body> </Action>
