<Action id="48122" issue="30876" author="ozheregelya" type="comment" created="2018-07-30 15:05:41.0" updateauthor="ozheregelya" updated="2018-07-30 15:05:41.0"> <body><! CDATA *Test run: 1* *Environment:* indy-node 1.5.527 (25 AWS nodes) libindy 1.6.1~655 *Ledger size:* 325K -> 450K *Goal:* Pool should catch up after stop the flooding. New clients should be able to connect and write. *Load:* {code:java} python3 perf_processes.py -g ~/stab_transactions_genesis -m t -c 450 -t 1 -n 1 -k nym{code} from 10 client instances  *Results:* Duration of load - 16 min Duration of processing all txns: 2.5 hours Transactions written: ~140K of 160K Load script throughput: 160txns/sec Pool throughput: 15.8 txns/sec  *Current behavior:* 160 writing txns/sec were send to the pool during 16 min. After that load test was stopped and there were no load on the pool. Pool was working on processing of txns during 3 hours. ~20K txns were missed. New clients were not able to connect to the pool because of timeout error.   ~esplinr ,  ~krw910 , FYI.  ></body> </Action>
<Action id="48502" issue="30876" author="ozheregelya" type="comment" created="2018-08-07 15:30:23.0" updateauthor="ozheregelya" updated="2018-08-07 15:30:23.0"> <body><! CDATA *Test run: 2* *Environment:* indy-node 1.5.543 (25 AWS nodes, standard pool) libindy 1.6.1~655 *Ledger size:* 30 -> 87K *Goal:* Pool should catch up after stop the flooding. New clients should be able to connect and write. *Load:*  Writing (from 2 client instances): {code:java} python3.5 perf_processes.py -m t -n 1 -t 0.0001 -c 563 -g ~/stab_transactions_genesis_new -k " {\"nym\": {\"count\": 4}}, {\"schema\":{\"count\": 1}}, {\"attrib\":{\"count\": 3}}, {\"cred_def\":{\"count\": 1}} "{code} Reading (from 8 client instances): {code:java} python3.5 perf_processes.py -m t -n 1 -t 0.0001 -c 1125 -g ~/stab_transactions_genesis_new -k " {\"get_nym\": {\"count\": 9}}, {\"get_attrib\":{\"count\": 2}}, {\"get_schema\":{\"count\": 2}}, {\"get_cred_def\":{\"count\": 2}} "{code} *Results:* Duration of read load - 2 h Duration of write load - 30 min Duration of processing all txns: 2 h 15 min Transactions written: 85836  Transactions read: 5555965 (~20K requests got timeout error after start of writing load). Load script throughput: 47 txns/sec - write, 770 txns/sec - read Pool throughput for writing: 10.6 txns/sec  *Current behavior:* There is no big differences with the previous results. New clients were not able to connect to the pool because of timeout error during all 2 hours of txns processing.  ></body> </Action>
<Action id="49006" issue="30876" author="ozheregelya" type="comment" created="2018-08-17 08:57:06.0" updateauthor="ozheregelya" updated="2018-08-17 08:57:06.0"> <body><! CDATA All test results are placed here (all cases with Clients="2x500 (w) 8x1125 (r)", Delay="0.0001"):  https://docs.google.com/spreadsheets/d/1DTjDsLSysFBiKU-9z4-IzunJk4wEy44hE_PGZYxnN_8/edit#gid=1813415708   Current behavior is that the pool tries to process all incoming requests (even if it was send several hours ago). But it can't write more than ~10.5 txns/sec (min throughput 9 txns/sec, max throughput 12 txns/sec). If clients write more than 10-11 txns/sec, pool will not get on time with processing of requests. So, pool still will be busy even after stopping the test. For load of 50 writing and 500 reading requests pool process all requests during ~2.5 hours. Note that during this time new clients will get timeout errors on attempts to connect.  This data is actual for all txns exclude payments and revocations because now we have some problems with them in load script. Test will be run with all types of txns after these problems will be fixed.  This test will run on weekly base. Results will be added to the 'Load and Performance Info' spreadsheet.  ></body> </Action>
