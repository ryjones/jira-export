<Action id="49799" issue="33435" author="ashcherbakov" type="comment" created="2018-09-04 11:17:14.0" updateauthor="ashcherbakov" updated="2018-09-04 11:17:14.0"> <body><! CDATA It looks like this is caused by huge transport batches, so the looper process them for ~10 secs, and hence everything is slowed down.  Number of messages in one transport batch:     11520 samples, 1539857.00 None, 1.00/133.67/360.00 min/avg/max, 113.10 stddev  Node message size, bytes:     Outgoing: 11503 samples, 614338081.00 None, 2.00/53406.77/131070.00 min/avg/max, 42032.58 stddev     Incoming: 9841 samples, 387978683.00 None, 2.00/39424.72/131072.00 min/avg/max, 40372.12 stddev  NODE_PROD_TIME : 41957 samples, 2995.69 seconds, 2.52/71.40/27386.67 ms min/avg/max, 811.04 stddev  SERVICE_NODE_MSGS_TIME : 41958 samples, 1987.87 seconds, 0.53/47.38/17537.82 ms min/avg/max, 515.21 stddev  SERVICE_NODE_STACK_TIME : 41958 samples, 1509.35 seconds, 0.34/35.97/14055.15 ms min/avg/max, 387.47 stddev  PROCESS_NODE_INBOX_TIME : 41958 samples, 475.67 seconds, 0.00/11.34/3542.65 ms min/avg/max, 130.58 stddev  FLUSH_OUTBOXES_TIME : 41957 samples, 525.71 seconds, 0.01/12.53/21056.10 ms min/avg/max, 307.95 stddev  UNPACK_BATCH_TIME : 9268 samples, 1412.31 seconds, 0.41/152.39/2482.74 ms min/avg/max, 183.60 stddev        Next Steps: * Test and apply fixes from INDY-1602 * Check whether we create transport batches efficiently (there was a recent change which changed the algorithm)        ></body> </Action>
<Action id="49806" issue="33435" author="ashcherbakov" type="comment" created="2018-09-04 12:55:16.0" updateauthor="ashcherbakov" updated="2018-09-04 12:55:16.0"> <body><! CDATA Results of comparing performance of the Batch creation from Propagate msgs (since Propagate is the most frequent one): * Batch Size = 10: ** Current way: 0.0002 ** Old way: 0.00005 * Batch Size = 300: ** Current way: 0.03 sec ** Old way: 0.0003 sec * Batch Size = 1000: ** Current way: 0.33 ** Old way: 0.0008  ></body> </Action>
<Action id="49813" issue="33435" author="nataliadracheva" type="comment" created="2018-09-04 13:37:22.0" updateauthor="nataliadracheva" updated="2018-09-04 13:44:30.0"> <body><! CDATA *Test run 1:* *Environment:* indy-node 1.6.73 (RC) indy-plenum 1.6.51  *Steps to Validate:* 1) prepare pool with 25 nodes 2) run load test from 3 instances:: {code:java} python3.5 perf_processes.py -g pool_transactions_genesis -m t -n 1 -c 200 -l 10.00000 -y one -k nym {code} *Actual results:* Pool handles about 20 txns/sec for 30 minutes without any issues. View change happens if needed (has happened once per test) !1672_RC_73.png|thumbnail!   *Test run 2:* *Environment:* indy-node 1.6.586 (Master) indy-plenum 1.6.529.dev714  *Steps to Validate:* 1) prepare pool with 25 nodes 2) run load test from 3 instances:: {code:java} python3.5 perf_processes.py -g pool_transactions_genesis -m t -n 1 -c 200 -l 10.00000 -y one -k nym {code} *Actual results:* Pool handles about 20 txns/sec for 120 minutes without any issues. View change happens if needed. !1672_Master_586.png|thumbnail!    *metrics: \\iserver\exchange\Evernym\INDY-1672*  ></body> </Action>
<Action id="49814" issue="33435" author="ashcherbakov" type="comment" created="2018-09-04 13:44:10.0" updateauthor="ashcherbakov" updated="2018-09-04 13:46:19.0"> <body><! CDATA I think the ticket can be closed. The issue will be addressed in the following tickets: * INDY-1602 (dynamic quotas to prevent huge batches) * INDY-1677 (to fix batch creation performance) * INDY-1649 (fix performance of propagate signature verification, which should also prevent huge batches)  ></body> </Action>
