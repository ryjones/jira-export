<Action id="48818" issue="32643" author="ckochenower" type="comment" created="2018-08-14 00:06:10.0" updateauthor="ckochenower" updated="2018-08-14 00:15:15.0"> <body><! CDATA Rather than taking the approach of demoting a sufficient number of nodes to decrease f_value by 1, I wrote the experiment to demote a sufficient number of nodes to get f_value down to a given value. The primary is removed from the list of nodes from which to choose the list of nodes to be demoted. The primary is then stopped to force a view change.  I ran the experiment with a target f_value of 1 an 2. Both experiments run with the experiment starting with 10 nodes and an f_value of 3.  *Target f_value of 2:* To get f_value to 2, at least 1 of 10 nodes must be demoted to drop f_value to 2. If one node is demoted, N = 9 (instead of 10) and ((9 - 1) / 3) = 2. Running the experiment with the target f_value = 2, the experiment runs just fine, because demoting 1 node still allows the pool to come to consensus.  *Target f_value of 1:* Running the experiment with an f_value = 1 demotes 4 nodes almost all at once. They are, in fact, demoted serially, but the demotion process is quite fast, which may not give the cluster time to elect a new primary before dropping out of consensus. The maximum number of validator nodes that participate in consensus when f_value is 1 is 6 ((6 - 1)/3) = 1. However, demoting 4 nodes causes a pool of 10 validator nodes to fall out of consensus and the experiment fails waiting for a view change.  *Conclusion:* When the experiment attempts to demote a sufficient number of nodes to decrease the f_value by more than 1, the experiment fails, because the pool is unable to come to consensus . Restarting each of the participating 6 nodes does NOT appear to get the pool back into consensus.  ></body> </Action>
<Action id="48856" issue="32643" author="ckochenower" type="comment" created="2018-08-14 15:31:55.0" updateauthor="ckochenower" updated="2018-08-14 15:31:55.0"> <body><! CDATA Split master result following demotion of 5 of 10 nodes to reduce f_value from 3 to 1. Master was excluded from the 5 demoted nodes. The master was stopped to force view change. The 5 demoted nodes were then promoted as part of the rollback segment of the experiment in an attempt to bring the pool back to as close to a pre-experiment execution state as possible. !Screen Shot 2018-08-14 at 9.04.03 AM.png|thumbnail!   ></body> </Action>
<Action id="48898" issue="32643" author="ckochenower" type="comment" created="2018-08-15 16:41:11.0" updateauthor="ckochenower" updated="2018-08-15 16:44:11.0"> <body><! CDATA It appears that we may have another race condition to consider.  The following is the state of the pool before demoting 4 nodes (Node10, Node9, Node8, and Node7 - none of which are master or replica) to drop f_value from 3 to 1.  !Screen Shot 2018-08-14 at 5.41.19 PM.png|thumbnail!   A view change was required (stop indy-node on Node1 - the master) to complete the process of dropping the f_value from 3 to 1. Is this a problem?  Node2 became the new master and Node3 became the one and only backup replica.  As part of the promotion process during the rollback segment of the Chaos experiment the demoted nodes were promoted and restarted in the following order: Node10 promoted, Node10 restarted, Node8 promoted, Node8 restarted, Node9 promoted, Node9 restarted, Node7 promoted, and Node7 restarted.  Finally, the original master Node1 was started, because it was stopped to force a view change.  The following was the result:  !Screen Shot 2018-08-14 at 6.03.33 PM.png|thumbnail!   A second restart (stop/start) of Node7 brings Node7 completely into sync with the other nodes. Note that Node7 was the last of the aforementioned 4 nodes to be promoted and when it was promoted, N became 10, which should cause f_value to change from 2 to 3 ((10 - 1)/3) = 3).  !Screen Shot 2018-08-14 at 6.08.11 PM.png|thumbnail!  ></body> </Action>
<Action id="48901" issue="32643" author="ckochenower" type="comment" created="2018-08-15 18:13:56.0" updateauthor="ckochenower" updated="2018-08-15 18:13:56.0"> <body><! CDATA I think we can add one or more of the following exclude rules/features if/when we see the need, but I will not include them now unless someone strongly feels they should be included.  # "exclude by role" ## Roles: ### master ### replica (master is technically a replica) ### backup replica/primary (all non-mater replicas) ### other (all non-master and non-replica nodes)) # "exclude nodes list" ## Enumerate node aliases to exclude  This experiment has the following switches that can be combined to vary things sufficiently for now:  {code} (chaostoolkit) ubuntu@KellyStableClientVirgina:~/chaosindy$ ./scripts/run-shrink-pool -h Usage: ./scripts/run-shrink-pool required arguments: None optional arguments: -c|--cleanup Remove temporary files/directories created by the experiment? Default: Yes Valid Inputs (case insensitive): yes, y, 1, no, n, 0 -d|--decrease-f-to Decrease tolerance for faulty nodes (f = (N - 1) / 3) to a given number. Default: 2 Valid Input: Any positive number >= 1 and less than ((N - 1) / 3) where N is the number of validator nodes in the pool when the experiment begins. -e|--execution-count How many times to run the experiment. Default: 1 Valid Input: Any positive number >= 1 -g|--genesis-file Path to the target pool genesis transaction file. Default: /home/ubuntu/chaosindy/pool_transactions_genesis -h|--help Print script help/usage -n|--validator-nodes A JSON list of node names to include in the experiment. Usually the complete list from the genesis file. TODO: derive default from genesis file. Default: ' "Node1", "Node2", "Node3", "Node4", "Node5", "Node6", "Node7", "Node8", "Node9", "Node10" ' -o|--selection-order Order in which replicas are selected for demotion. Valid Input: 1 (FORWARD), 2 (REVERSE), 3 (RANDOM) Default: '2' -p|--pause-after How long to let the system reach a steady state (in seconds) after decreasing f_value Default: 60 Valid Input: Any positive number >= 1 -s|--set-services-timeout How long to wait (seconds) before timing out while promoting and demoting a node. A node's 'services' are changed between 'VALIDATOR' and '' \(blank\) during demotion/promotion. Default: 60 Valid Input: Any positive number >= 1 -t|--write-nym-timeout How long to wait (seconds) before timing out while writing a NYM transaction. Default: 60 Valid Input: Any positive number >= 1 -s|--seed Seed to use to create DID/Verkey pair used to get validator info via indy-cli. Must be a Trustee or Steward seed. Default: 000000000000000000000000Trustee1 Valid Input: A 32 byte string. See default above for an example. {code}  ></body> </Action>
