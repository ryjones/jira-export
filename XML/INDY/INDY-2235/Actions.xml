<Action id="64259" issue="42589" author="anikitindsr" type="comment" created="2019-10-02 13:00:40.0" updateauthor="anikitindsr" updated="2019-10-02 13:00:40.0"> <body><! CDATA Test for indicating the problem is:    test_view_change_after_back_to_quorum_with_disconnected_primary  ></body> </Action>
<Action id="65008" issue="42589" author="donqui" type="comment" created="2019-10-25 23:36:31.0" updateauthor="donqui" updated="2019-10-29 14:13:21.0"> <body><! CDATA   Problem reason/description: - As nodes lost preprepares and prepares on restart when view change was triggered they did not have enough information for re-ordering phase and because of that view change did not execute properly on all nodes.  Changes: - Save preprepares digest in audit ledger as part of audit transaction - Restore preprepared/prepared after catchup from the audit ledger  PR: -  https://github.com/hyperledger/indy-plenum/pull/1383  -  https://github.com/hyperledger/indy-plenum/pull/1385   Version: - plenum:  1.11.0.dev941  - node: 1.11.0.dev944 - sovtoken: sovtoken_1.0.4~dev111 sovtokenfees_1.0.4~dev111   Risk factors: - possible that the problem will happen in cases where we have a checkpoint interval that contains old audit txns and new ones with the digest. In this case will not restore them and we might see the same issue - changing the txn format may present a breaking change with some unknown consequences  Risk: - Med  Covered with tests: -  https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/view_change_with_delays/test_view_change_with_delayed_commits_on_half_of_the_nodes_and_restart_of_the_other_half.py  -  https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/view_change_with_delays/test_view_change_with_delayed_commits_on_half_of_the_nodes_and_restart_of_that_half.py  -  https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/view_change_with_delays/test_view_change_with_delayed_commits_on_one_node_and_restart_of_other_nodes.py  -  https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/node_catchup_with_3pc/test_preprepares_and_prepares_recovery_after_catchup.py  -  https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/view_change/test_view_change_after_back_to_quorum_with_disconnected_primary.py  -  https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/view_change/test_view_change_after_back_to_quorum_with_disconnected_primary_and_slow_node.py   Recommendations for QA - I would try to perform the same scenario as in the test  https://github.com/hyperledger/indy-plenum/pull/1383/files#diff-aa4abf76aa908a6c1a45e30589edecc9  -- Delay commits on Node1 -- Send a request and make sure it's ordered on Nodes2-4 -- Restart Nodes2-4 -- Start view change -- Make sure that view change is finished, and all nodes have equal data  ></body> </Action>
<Action id="65093" issue="42589" author="vladimirwork" type="comment" created="2019-10-29 15:15:25.0" updateauthor="vladimirwork" updated="2019-10-29 15:15:25.0"> <body><! CDATA Build Info: indy-node 1.11.0~dev1119  Steps to Validate: 1. Delay commits on Node1. 2. Send a request and make sure it's ordered on Nodes2-4. 3. Restart Nodes2-4. 4. Start view change. 5. Make sure that view change is finished and all nodes have equal data.  Actual Results: All nodes are in sync at the end of the test.  ></body> </Action>
