<Action id="60697" issue="39715" author="sergey.khoroshavin" type="comment" created="2019-06-05 14:07:16.0" updateauthor="sergey.khoroshavin" updated="2019-06-05 14:15:14.0"> <body><! CDATA *Protocol proposal* * Phase A ** Request ledger statuses from all nodes  ** Wait for N-f responses, on (long) timeout log an error and request again ** Sort responses by maximum seq no ** Use seq no of response f+1 as a target seq no ** Enter phase B * Phase B ** Request consistency proofs for target seq no ** Wait until we have f+1 equal cons proofs with target seq no, on (short) timeout log a warning and request again ** Start actual catch up  *Rationale*  Healthy network requires at least N-f honest nodes up and running, therefore we can expect to receive this number of replies eventually, usually within short timeframe. Failure to receive this amount of replies is a sign of serious connectivity problems at least, and should be logged.  In a worst case scenario our N-f replies can contain f replies from malicious nodes. Following cases are possible # Malicious nodes report very high sequence numbers. Taking f+1's reply will hit honest node, which means that eventually all honest nodes will have this many transactions, and it is safe to start a catch up to this target. In the worst case we can fail to get enough replies in phase B on the first try, this is why it has much shorter timeout. # Malicious nodes report very low sequence numbers. Taking f+1's reply will still hit honest node, and f honest nodes have at least this number of transactions, which means it is safe to start a catch up and we should get enough replies in phase B on the first try. In the worst case we won't catch up till the latest available transaction in pool, however in a healthy pool gap between fastest and somewhat lagging node shouldn't be very large, so this shouldn't be a problem. # Malicious nodes report random sequence numbers. Taking f+1's reply can possibly hit malicious node, however in this case at least one honest node is guaranteed to have at least same number of transactions, which brings us back to case 1.  f+1 equal consistency proofs in phase B are required in order to make sure, that at least one honest node have this many transactions with this target root hash.  ></body> </Action>
<Action id="60739" issue="39715" author="sergey.khoroshavin" type="comment" created="2019-06-06 17:15:47.0" updateauthor="sergey.khoroshavin" updated="2019-06-06 17:16:06.0"> <body><! CDATA *Minimal PoA* * Changes: ** Upon having N-f-1 replies without having f+1 equal consistency proofs send consistency proof request immediately AND schedule second request after timeout * Cover by integration test: ** Make cons proof request timeout very large ** Prepare a pool with different number of transactions on different nodes + one lagging node ** Make sure lagging node can catch up  ></body> </Action>
<Action id="60758" issue="39715" author="sergey.khoroshavin" type="comment" created="2019-06-07 12:53:07.0" updateauthor="sergey.khoroshavin" updated="2019-06-10 13:40:07.0"> <body><! CDATA *Problem reason* As in description  *Changes made* * request for equal consistency proofs is sent as soon as we have N-f-1 replies (either cons proofs or ledger statuses) * consistency proof is asked for f+1's largest known ledger size  *Version* indy-node 1.9.0~dev997  *PR* https://github.com/hyperledger/indy-plenum/pull/1235  *Covered by tests* * test_catchup_from_unequal_nodes_without_waiting  *Risk* Low  *Recommendation for QA* Run load test on 25-nodes AWS pool: * start load test with 10 writes per second * stop nodes 15-20 for 0.5/1/5/10 minutes * simultaneously start them * make sure they manage to catch up  ></body> </Action>
<Action id="60840" issue="39715" author="sergey.khoroshavin" type="comment" created="2019-06-10 16:32:08.0" updateauthor="sergey.khoroshavin" updated="2019-06-10 16:33:47.0"> <body><! CDATA *Test performed* Load test was performed with following command: {code} perf_processes.py -g persistent_transactions_genesis -m t -n 1 -y one -k " {\"nym\":{\"count\": 4}}, {\"schema\":{\"count\": 1}}, {\"attrib\":{\"count\": 3}}, {\"cred_def\":{\"count\": 1}}, {\"revoc_reg_def\":{\"count\": 1}} " -c 10 -b 10 -l 10 {code} and nodes stopped for 0.5/1/5/10 minutes  *Expected result* Nodes should quickly catch up after restart and continue ordering  *Actual result* In all cases except last (stopping for 10 minutes) all nodes managed to catch up and continue ordering with pool, however they were somewhat slower to do so than expected. In last case (stopping for 10 minutes) 4 of 5 nodes managed to catch up and continued ordering, 1 node remained stuck.  Quick *logs analysis* showed following evidence: * nodes were quite slow to connect to each other (it took up to 2 minutes in some cases) * some nodes were unable to connect to each other at all despite numerous reconnection attempts * nodes that were not restarted reported that they were able to connect to all restarted nodes * which means that some connections appeared to be one-sided (sic!) * in all cases initial phase (PreSyncPool) took about 3 minutes, mostly waiting for ledger statuses from other nodes, which were received with quite large delay * Node17 received just 13 ledger status messages, which was insufficient to continue a catch up * other phases were significantly faster (not more than 1.5 minutes per phase), however gathering ledger statuses and consistency proofs took some time (~30 seconds) * it seems like slow reaction was partly due to large non catchup-related traffic (propagates, 3PC messages)  Even though results are not perfect they are still better than all previous attempts. Besides, it seems like failures were partly connected to either connectivity issues or unexpected behavior of zeromq. Further catch-up improvements can be done in scope of other issues, some ideas: * investigate zmq behavior * make initial catch up more resilient by adding resending mechanism * use BLS signatures to reduce number of communication steps in cons proof gathering phase * consider adding separate communication channel for high priority traffic between nodes  ></body> </Action>
<Action id="60857" issue="39715" author="ashcherbakov" type="comment" created="2019-06-11 08:23:47.0" updateauthor="ashcherbakov" updated="2019-06-11 08:23:47.0"> <body><! CDATA We already have a number of tasks for the action items above: * https://jira.hyperledger.org/browse/INDY-1472 * https://jira.hyperledger.org/browse/INDY-2112 * https://jira.hyperledger.org/browse/INDY-2029 * https://jira.hyperledger.org/browse/INDY-1242  ></body> </Action>
