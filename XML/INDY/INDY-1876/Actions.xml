<Action id="53892" issue="35626" author="ashcherbakov" type="comment" created="2018-11-28 09:40:01.0" updateauthor="ashcherbakov" updated="2018-12-18 09:01:46.0"> <body><! CDATA *PoA:* # Write tests simulating active ordering while a node does a catchup. We expect that all newly ordered requests need to be applied after the cacthup immediately. # Create a a separate 3PC Message Validator class and cover by unit tests. Each Replica should have its own 3PC Validator instance. The Validator returns one of the following values:  PROCESS, STASH, DISCARD  ** Validate method for 3PC messages: *** Check if viewNo is correct. **** If it's less than view_no - 1, then discard **** If it's more than view_no, then stash (see next sections) **** If it's equal to view_no - 1, and view change is in progress, then check if it's less than last_prepared_certificate **** If it's equal to viewNo, and view change is in progress - stash **** Otherwise - Process *** Check if isParticipating **** If not - stash *** Check if already ordered **** If yes - discard *** Сheck if within watermarks **** If not - stash ** Validator for Checkpoint messages *** If already stable - discard *** If not participating - stash # Create a stasher for 3PC messages attached to the Replica. ** All messages for which STASH is returned by the Validator go to the Stasher ** The stasher should have a limit to not stash too much ** All messages from the stasher are trying to be re-applied after *** Catch-up is finished *** View Change is finished *** watermarks are chamged # Write the following integration tests:  ** Continue ordering while catching-up *** Expected result: a node applies stashed messages which were ordered during catchup, and will be up-to-date with the pool ** Continue ordering and stabilize checkpoints during catch-up *** Expected result - the node doesn't start catch-up again due to stashed checkpoints, and will be up-to-date after catch-up. ** A node starts view change latter, while other nodes already finished it and started ordering *** Expected result - the node successfully finished view change, and applied stashed messages that were ordered during view chnage, and will be up-to-date with the pool  ></body> </Action>
<Action id="54904" issue="35626" author="ashcherbakov" type="comment" body="The current work is in https://github.com/ashcherbakov/indy-plenum/tree/catchup-fixes" created="2018-12-18 09:02:00.0" updateauthor="ashcherbakov" updated="2018-12-18 09:02:00.0"/>
<Action id="55557" issue="35626" author="toktar" type="comment" created="2019-01-11 18:54:37.0" updateauthor="toktar" updated="2019-01-11 18:54:37.0"> <body><! CDATA Problem reason: - Current stash mechanism has a lot of bugs: ** process 3pc messages and checkpoints in catchup ** process checkpoints in view change ** late processing of unstashed messages   Changes: - Refactoring stashing mechanism. Create 3 types of stashing: ** queue for 3pc messages and checkpoints received in catchup ** for messages from a next view ** for out of watermarks messages - Add tests  PR: *  https://github.com/hyperledger/indy-node/pull/1122  *  https://github.com/hyperledger/indy-plenum/pull/1046   Version: * indy-node 1.6.753 -master * indy-plenum 1.6.652 -master  Risk factors: - Problem with ordering in catchup, view change. Performance degradation.  Risk: - Medium  Covered with tests: *  test_stashing_3pc_while_catchup.py|https://github.com/hyperledger/indy-plenum/pull/1046/files#diff-294ec0b032203ef2cf0abd48be770ead  *  test_stashing_3pc_while_catchup_checkpoints.py|https://github.com/hyperledger/indy-plenum/pull/1046/files#diff-0a9bf2d99bd0ce64e892a15b2b4701e8  *  test_replica_stasher.py|https://github.com/hyperledger/indy-plenum/pull/1046/files#diff-460da6f43d0f54da3852d5ad80984255  *  test_replica_unstashing.py|https://github.com/hyperledger/indy-plenum/pull/1046/files#diff-14832af9d700da535ee6d89e7691f4e8  *  test_stash_future_view.py|https://github.com/hyperledger/indy-plenum/pull/1046/files#diff-0e50e46f125b200e799d3067fa4759f9  *  test_stash_out_of_watermarks.py|https://github.com/hyperledger/indy-plenum/pull/1046/files#diff-e2d82babc11799caee9fe49e5c4be0a8  *  test_unstash_after_catchup_in_view_change.py|https://github.com/hyperledger/indy-plenum/pull/1046/files#diff-b83b05d0f6744d42770207355e481ed7  *  test_3pc_messages_validation.py|https://github.com/hyperledger/indy-plenum/pull/1046/files#diff-95600fdf1137ea91d61ab28d161944b2  *  test_replica_3pc_validation.py|https://github.com/hyperledger/indy-plenum/pull/1046/files#diff-e82220bb9f03171e61bf26ab539b2d6a  *  test_replica_checkpoint_validation.py|https://github.com/hyperledger/indy-plenum/pull/1046/files#diff-92507caf8a7c21885a02ab11416aab86  * and others  Recommendations for QA:  Production load. Check that performance are not degraded.  ></body> </Action>
<Action id="55603" issue="35626" author="ozheregelya" type="comment" created="2019-01-14 12:01:48.0" updateauthor="ozheregelya" updated="2019-01-14 12:01:48.0"> <body><! CDATA Environment: indy-node 1.6.753  Steps to Validate: 1. Setup the pool. 2. Run load test with production load (10 writes, 100 reads per sec).  Actual Results: Part of requests were failed with CommonIOError from libindy. Results of load script: {code:java} Time 57774.64 Clients 10/10 Sent: 375618 Succ: 231415 Failed: 144150 Nacked: 0 Rejected: 0{code} Errors in load script output:  {code:java} 2019-01-13 20:03:39,058|ERROR|libindy.py|indy.libindy.native.indy.errors.indy| src/errors/indy.rs:73 | Casting error to ErrorCode: Plugged method error. Consider the error code.{code} As for pool, it haven't stopped writing, but part of the nodes were lagged. Ledger sizes (domain | sovtoken): persistent_node13 31576 | 31872    <<< the only node which have more sovtoken txns than domain ones persistent_node14 42565 | 41774 persistent_node18 58636 | 56223 persistent_node20 58642 | 56242 persistent_node25 58727 | 56312 persistent_node19 58727 | 56312 persistent_node1 59599 | 57094 the rest ones 125755 | 116642  Logs and output of writing load script: s3://qanodelogs/indy-1876/load_script_out_14_01_2019 Logs and metrics from the nodes: s3://qanodelogs/indy-1876/prod_load_14_01_2019 To get logs, run following command on log processor machine:  aws s3 cp --recursive s3://qanodelogs/indy-1876/prod_load_14_01_2019/ /home/ev/logs/indy-1876/prod_load_14_01_2019/  ></body> </Action>
<Action id="55708" issue="35626" author="toktar" type="comment" created="2019-01-16 09:23:41.0" updateauthor="toktar" updated="2019-01-16 09:23:41.0"> <body><! CDATA The main problem was in the incorrect client. A new version * indy-node 1.6.759 -master * indy-plenum 1.6.654 -master  ></body> </Action>
<Action id="55765" issue="35626" author="ozheregelya" type="comment" created="2019-01-17 15:47:00.0" updateauthor="ozheregelya" updated="2019-01-17 15:47:00.0"> <body><! CDATA *Environment:* indy-node 1.6.759 (with disabled freshness)  *Steps to Validate:* 1. Setup the pool. 2. Run production load.  *Actual Results:* Pool was able to write during 23 hours. Tickets for the issues which were found during load test: INDY-1949, INDY-1955.  ></body> </Action>
