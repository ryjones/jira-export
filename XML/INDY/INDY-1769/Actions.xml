<Action id="52653" issue="34844" author="sergey.khoroshavin" type="comment" created="2018-10-25 16:19:26.0" updateauthor="sergey.khoroshavin" updated="2018-10-26 15:34:36.0"> <body><! CDATA Test should be done with following options in _indy_config.py_ on some of nodes: {code:python} hashStore = { "type": "file" } stateTsStorage = 5 domainStateStorage = 5 poolStateStorage = 5 configStateStorage = 5 reqIdToTxnStorage = 5 stateSignatureStorage = 5 transactionLogDefaultStorage = 5 configStateStorage = 5 idrCacheStorage = 5 attrStorage = 5 METRICS_KV_STORAGE = 5 {code}  Required load is 1 NYM per second with duration of at least 2 hours.  ></body> </Action>
<Action id="52685" issue="34844" author="sergey.khoroshavin" type="comment" created="2018-10-26 14:18:18.0" updateauthor="sergey.khoroshavin" updated="2018-10-26 14:18:18.0"> <body><! CDATA *Minimum verions:* indy-node: 1.6.647 indy-plenum: 1.6.573  ></body> </Action>
<Action id="53079" issue="34844" author="sergey.khoroshavin" type="comment" created="2018-11-06 14:09:49.0" updateauthor="sergey.khoroshavin" updated="2018-11-06 14:09:49.0"> <body><! CDATA  !Screenshot from 2018-10-31 14-02-41.png|thumbnail!  Test was done in docker with load of 3 NYMs per second. It can be seen that with file storage: * memory consumption is really low (around 100 Mb) compared to similar runs with RocksDB storage  * memory consumption increases mostly in sync with finalized request queue * memory usage didn't decrease when request queue was cleared, however it stayed constant until request queue size caught up to previous maximum value  Given all these things it seems safe to assume that: * there were no unexpected memory consumers in this test * internal request queue doesn't release memory when cleared, however this memory is reused, so this is not a leak * *increasing memory consumption during sustainable loads is due to RocksDB internal structures*  ></body> </Action>
