<Action id="37651" issue="26144" author="krw910" type="comment" body="This may be the same issue as INDY-1034" created="2017-12-19 22:04:26.0" updateauthor="krw910" updated="2017-12-19 22:04:26.0"/>
<Action id="37820" issue="26144" author="dsurnin" type="comment" created="2017-12-28 12:32:35.0" updateauthor="dsurnin" updated="2017-12-28 12:32:35.0"> <body><! CDATA  ~krw910   Could you please describe the machine each node run on? RAM, cpu cores, etc.  I would like to have journalctl logs from each machine.  Also could you please reproduce it once again and monitor memory usage on nodes with ps or top?  ></body> </Action>
<Action id="37856" issue="26144" author="spivachuk" type="comment" body=" ~krw910 , as to different IDs of {{propose_view_change}} actions on different nodes - specifically this is not an issue. Such an ID is not a view number. It is an identifier of an action added to the action queue of a node. So these IDs are not to be the same on different nodes." created="2017-12-29 15:22:33.0" updateauthor="spivachuk" updated="2017-12-29 15:22:33.0"/>
<Action id="38428" issue="26144" author="dsurnin" type="comment" created="2018-01-11 12:58:43.0" updateauthor="dsurnin" updated="2018-01-11 12:58:43.0"> <body><! CDATA according to logs the issue could be connected with INDY-1018 - adding new node to the pool with big ppseqno could lead to situation when node can catch up but cannot take part in consensus  the fix is ready for test, so could you please retest it with latest master  ></body> </Action>
<Action id="38458" issue="26144" author="spivachuk" type="comment" body="3PC-batches stopped to be ordered by the master protocol instance since the batch (1, 301) because this batch and the following batches in the view 1 were considered as laying outside the watermarks by master replicas of more than a third of the nodes. On these replicas the watermarks were staying at (0, 300  despite the previous batches including (1, 300) were ordered." created="2018-01-11 18:29:35.0" updateauthor="spivachuk" updated="2018-01-11 18:29:35.0"/>
<Action id="38668" issue="26144" author="ashcherbakov" type="comment" body="The issue reproduced again during adding of more nodes" created="2018-01-16 09:00:03.0" updateauthor="ashcherbakov" updated="2018-01-16 09:00:03.0"/>
<Action id="38669" issue="26144" author="vladimirwork" type="comment" body="AWS QA Live pool logs from 1st, 2nd and 19th nodes.  ^AWS_logs_1_2_272_master.7z  " created="2018-01-16 09:07:37.0" updateauthor="vladimirwork" updated="2018-01-16 09:07:37.0"/>
<Action id="38754" issue="26144" author="ashcherbakov" type="comment" created="2018-01-17 16:37:14.0" updateauthor="ashcherbakov" updated="2018-01-17 16:37:51.0"> <body><! CDATA *Problem reason* * Once a Node started, it starts a timer (60 sec by default) to check it it's connected to a Primary. This is needed to be able to select a Primary when all nodes except the first one are started (since we use round robin for Primary selection, 1st node is the first primary, and it may be not started). * If a primary for a new node still don't have a Primary after 60 sec, it sends INSTANCE_CHANGE. It used to send it unconditionally, not checking if the node is actually participating and ready, that is connected to all nodes in the Pool. But it doesn't make sense to send it, if it hasn't yet connected (the Primary is there, this is the new node which is not connected yet). * In the test scenario above, all new Nodes are started one by one, but NODE txn is not sent for a while. So, each node sent INSTANCE_CHANGE because of primary 'disconnection' (it wasn't able to connect to the Primary since other nodes don't accept such a connection without NODE txn sent). Each node sent INSTANCE_CHANGE once is started participating. After a number of new nodes, there was a quorum of INSTANCE_CHANGE messages (actually old and incorrect messages), so ViewChange happened. But the quorum was only for the first 7 nodes in the pool (not added manually). For new nodes it was not a real ViewChange, but propagate primary logic (since they didn't receive enough INSTANCE_CHANGE msgs, but received f+1 ViewChangeDone messages from the first 7 Nodes with a view greater than their current one). So, ViewChange finished for the new nodes (they got a quorum of ViewChangeDone), and, since it's Propagate Primary ViewChange, they didn't send ViewChangeDone to others. First 7 nodes had only 7 ViewChangeDone, which is not enough for their ViewChange quorum (n-f) since they experience a real View Change based on INSTANCE_CHANGE messages, not primary propagation as new nodes. As a result, pool becomes stalled.  *Changes* * do not send INSTANCE_CHANGE because of Primary disconnection if node is not ready yet (that is doesn't have enough connections).  *PR* *  https://github.com/hyperledger/indy-plenum/pull/502   *New Tests* * ` test_no_instance_change_before_node_is_ready.py|https://github.com/hyperledger/indy-plenum/pull/502/files#diff-22101ab3b6b3508dd4f6c9d3f87aa3cd `  *Risk* * low  *Recommendations for QA* * add nodes one by one to the pool (add sufficient number of nodes, ~15) * do not send NODE txn immediately for each node  *Build*  - master indy-node 1.2.275        ></body> </Action>
<Action id="38866" issue="26144" author="krw910" type="comment" body="Blocked by INDY-1095" created="2018-01-18 17:31:07.0" updateauthor="krw910" updated="2018-01-18 17:31:07.0"/>
<Action id="39119" issue="26144" author="ozheregelya" type="comment" created="2018-01-25 17:24:47.0" updateauthor="ozheregelya" updated="2018-01-25 17:24:47.0"> <body><! CDATA *Environment:* indy-node 1.2.279 AWS QA live pool (25 nodes)  *Case 1:* *Steps to Validate:* 1. Setup each node using generate_indy_pool_transactions script. 2. Start all nodes at once. 3. Run load test several times.  *Actual Results:* Pool successfully wrote 25000 transactions.   *Case 2:* *Steps to Validate:* 1. Setup 7 nodes using generate_indy_pool_transactions script. 2. Add 18 nodes to the pool one by one. 3. Initiate view change. 4. Check that pool works.  *Actual Results:* Pool works after adding 18 nodes and view change.   *Additional Information:* Steps to validate differ from initial procedure in description. Initial case will be verified in scope of INDY-1095.  ></body> </Action>
