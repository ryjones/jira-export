<Action id="45757" issue="30942" author="spivachuk" type="comment" created="2018-06-09 17:10:56.0" updateauthor="spivachuk" updated="2018-06-14 18:21:50.0"> <body><! CDATA There were troubles with node connections: {{Node4}} and {{Node5}} succeeded to connect to {{Node6}} only after 1 minute 42 seconds since the latter had started. Due to this {{Node4:0}} and {{Node5:0}} failed to send PREPARE(0, 7) and COMMIT(0, 7) to {{Node6:0}} and so {{Node6:0}} did not gather the quorum of COMMITs to order the batch (0, 7). Later when {{Node4}} and {{Node5}} had already been connected to {{Node6}}, {{Node6:0}} was not able to order the batch (0, 8) on the quorum of COMMITs because the previous batch (0, 7) had not been ordered yet. The missed messages were not requested because requesting of missed messages is performed only when PREPREPAREs are missed.  Note: {{Node6}}, however, successfully connected to {{Node4}} and {{Node5}} right after had started.  ></body> </Action>
<Action id="46192" issue="30942" author="sergey-shilov" type="comment" created="2018-06-19 12:41:30.0" updateauthor="sergey-shilov" updated="2018-06-19 12:41:30.0"> <body><! CDATA That issue is similar to  INDY-1390|https://jira.hyperledger.org/browse/INDY-1390 .  There were troubles with connections: * Node5 to Node3 * Node4 to Node6 * Node5 to Node6  They had been failed to connect until they recreated their sockets to connect. Moreover, they recreated sockets twice to be able to connect, Seems like it is a bug of ZeroMQ.  As soon as recreating of ZeroMQ sockets solves connection issue we've made a fix to reduce connections retrying using the same socket:  _MAX_RECONNECT_RETRY_ON_SAME_SOCKET = 1_  ></body> </Action>
<Action id="46365" issue="30942" author="sergey-shilov" type="comment" created="2018-06-21 11:46:20.0" updateauthor="sergey-shilov" updated="2018-06-21 11:46:20.0"> <body><! CDATA *Problem state / reason:*  Sometimes we face troubles with node-to-node connecting process. Each node-to-node logical connection consists of two TCP connections. A node connects to other node and sends packets using only this connection. A node receives packets using incoming connection. If one of these connections is not established then nodes can not communicate. In this ticket nodes had been failed to connect until they recreated their sockets to connect. Seems like it is a bug of ZeroMQ.  *Changes:*  As soon as recreating of ZeroMQ sockets solves connection issue we've made a fix to reduce connections retrying using the same socket:  _MAX_RECONNECT_RETRY_ON_SAME_SOCKET = 1_  *Committed into:*   https://github.com/hyperledger/indy-plenum/pull/749    https://github.com/hyperledger/indy-node/pull/767   indy-node 1.4.470-master  *Risk factors:*      Nothing is expected.  *Risk:*      Low  *Recommendations for QA:*  Repeate tests with adding of nodes and check that all nodes are connected.     ></body> </Action>
<Action id="46410" issue="30942" author="ozheregelya" type="comment" created="2018-06-21 19:18:31.0" updateauthor="ozheregelya" updated="2018-06-21 19:18:31.0"> <body><! CDATA *Environment:* indy-node 1.4.470 libindy 1.4.0~596  *Steps to Validate:* 1. Setup the pool of 4 nodes. 2. Init 2 more nodes (init_indy_node). 3. Send Node txn for one of these nodes. 4. Start both of additional nodes. 5. Check txns count on all nodes. => Added node processed all missed txns. Not added node has only genesis txns. 6. Send txn. => Txn successfully written on added node. 7. Add the second node, check txns count. => Added node processed all missed txns. All nodes have the same count of txns. 8. Send txn.  *Actual Results:* Nodes were successfully added, all nodes have the same amount of txns.  ></body> </Action>
