<Action id="46357" issue="30973" author="ashcherbakov" type="comment" created="2018-06-21 09:15:23.0" updateauthor="ashcherbakov" updated="2018-06-21 09:15:23.0"> <body><! CDATA `bug.png` - workflow of initial problem found in INDY-1400  `bug_fixed.png` - workflow of the fix done in the scope of INDY-1404 and INDY-1405  `node_init.png` - workflow of a similar problem with node initiation  `node_init_fixed.png` - workflow of the fix done in the scope of INDY-1404 and INDY-1405  ></body> </Action>
<Action id="46672" issue="30973" author="ashcherbakov" type="comment" created="2018-06-28 13:13:39.0" updateauthor="ashcherbakov" updated="2018-07-02 13:39:21.0"> <body><! CDATA Problem reason:  - Catchup can be interrupted in the middle because of a new view change. It means that the ledger will be in incorrect state (part of a 3PC batch will be applied) - see attached diagrams   Changes:  - do not process any View Change related messages (including ViewChangeDone from Current State for primary propagation) until the current catchup is finished; - this fixes initialization of a node where we mixed together initial catchup and primary propagation (initial view change); - also fixed recovering when primary is disconnected and (n-f)th node joins the pool   PR: - https://github.com/hyperledger/indy-plenum/pull/757  Version: - master Indy Node 1.4.487  Risk factors: - Catchup - View Change - Node initialization - Node restart - New node adding - Recovering from f+1 nodes  Risk: - Med  Covered with tests: - test_no_view_change_while_catchup.py - test_no_future_view_change_while_catchup.py  Recommendations for QA - Run acceptance for adding of a new node - Run acceptance against cases with restart of nodes  - Run acceptance against cases with recovering from f+1 nodes - Run load test with view changes  ></body> </Action>
<Action id="46857" issue="30973" author="vladimirwork" type="comment" created="2018-07-03 12:22:50.0" updateauthor="vladimirwork" updated="2018-07-03 12:25:11.0"> <body><! CDATA Build Info: indy-node 1.4.487  Steps to Reproduce: 1. Install pool of 4 nodes. 2. Run load test for ~5k NYMs. 3. Add 5th node. 4. Run load test for ~5k NYMs. 5. Restart 1st node to change the primary (since there were no view changes at this moment). 6. Stop 1st node. 7. Run load test for ~25k NYMs. *8. Add 6th node and start 1st node simultaneously to check their catchup under load.*  Actual Results: 1st node doesn't catch up (11.1k txns in ledger) even after an hour from starting (but 6th node does). Validator Info shows that all nodes are reachable. !INDY-1404.PNG|thumbnail!  Logs from 1st (bad) node and 2nd (good) are in attachment.  Expected Results: 1st node should catch up normally.  ></body> </Action>
<Action id="46905" issue="30973" author="ashcherbakov" type="comment" created="2018-07-04 09:03:10.0" updateauthor="ashcherbakov" updated="2018-07-04 09:03:10.0"> <body><! CDATA We can see the following in the logs:  2018-07-03 11:13:56,265 | INFO     | node.py              (3014) | send | Node3 sending message MESSAGE_RESPONSE\{'msg': LEDGER_STATUS\{'viewNo': None, 'txnSeqNo': 0, 'protocolVersion': 2, 'ppSeqNo': None, 'merkleRoot': 'GKot5hBsd81kMupNCXHaqbhv3huEbxAFMLnpcX2hniwn', 'ledgerId': 2}, 'msg_type': 'LEDGER_STATUS', 'params': \{'ledgerId': 2}} to 1 recipients:  'Node1'   2018-07-03 11:13:55,800 | INFO     | node.py              (3014) | send | Node2 sending message MESSAGE_RESPONSE\{'msg_type': 'LEDGER_STATUS', 'params': \{'ledgerId': 2}, 'msg': LEDGER_STATUS\{'ppSeqNo': None, 'txnSeqNo': 0, 'viewNo': None, 'ledgerId': 2, 'protocolVersion': 2, 'merkleRoot': 'GKot5hBsd81kMupNCXHaqbhv3huEbxAFMLnpcX2hniwn'}} to 1 recipients:  'Node1'    Node1 received ledger status: LEDGER_STATUS\{'viewNo': None, 'ledgerId': 2, 'ppSeqNo': None, 'txnSeqNo': 0, 'protocolVersion': 2, 'merkleRoot': 'GKot5hBsd81kMupNCXHaqbhv3huEbxAFMLnpcX2hniwn'} from Node2     So, Node 1 is doing catchup of Config ledger (ledgerId=2), but it received requested LEDGER_STATUS from Node2 only, although Node3 also sent it.      It looks like this is a problem we always had: if a lot of catchup-related messages (LEDGER_STATUS, CONSISTENCY_PROOFS) are lost, the node doesn't try to start catchup again. The messages can be lost due to high load (as in the test), and limited size of node-to-node's message queue.  The recent fixes regarding catchup and fixes done in the scope of INDY-1404 made the problem more visible, since we require that the previous round of catchup is finished before starting the next round.        ></body> </Action>
<Action id="46906" issue="30973" author="ashcherbakov" type="comment" body="Created INDY-1450 for this issue" created="2018-07-04 09:06:25.0" updateauthor="ashcherbakov" updated="2018-07-04 09:06:25.0"/>
<Action id="46922" issue="30973" author="vladimirwork" type="comment" created="2018-07-04 14:57:22.0" updateauthor="vladimirwork" updated="2018-07-04 14:57:22.0"> <body><! CDATA Build Info: indy-node 1.4.487  Steps to Validate: 1. Check adding of new nodes (and their catchup). 2. Check consensus count and f+1 recovery. 3. Check view change forced by primary shutdown and primary degradation (under load).  Actial Results: New nodes are added and caught up correctly. Write/read consensus and f+1 recovery are correct. View change caused by primary shutdown and primary degradation (up to ~570 view) also works. The issue found will be investigated and fixed in scope of INDY-1450.  ></body> </Action>
