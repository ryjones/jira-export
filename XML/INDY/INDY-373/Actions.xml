<Action id="28927" issue="18898" author="danielhardman" type="comment" body="Now that this has been deferred beyond the Go-Live milestone, we need to implement Rocks DB at the same time, so that we don&apos;t have to rewrite old ledger entries more than once." created="2017-07-24 20:17:19.0" updateauthor="danielhardman" updated="2017-07-24 20:17:19.0"/>
<Action id="28958" issue="18898" author="ashcherbakov" type="comment" created="2017-07-25 08:06:55.0" updateauthor="ashcherbakov" updated="2017-07-25 08:08:33.0"> <body><! CDATA  ~danielhardman   ~stevetolman  The ticket is still in M1, is it correct?  Options: * Finish it with leveldb in M1 * Get the ticket out of M1 until we support Rocksdb * Include Rocksdb support ticket into M1 (BTW Rocksdb task was almost done by Dmitry some time ago).  ></body> </Action>
<Action id="29720" issue="18898" author="ashcherbakov" type="comment" created="2017-08-11 14:00:40.0" updateauthor="ashcherbakov" updated="2017-08-16 16:03:30.0"> <body><! CDATA Changes: - use msgpack as a serializer for ledger (all ledgers: domain, pool, config) - use leveldb as a storage for all ledgers - use leveldb as a storage for all ledgers's tree hash stores - use '_genesis' suffix for genesis txn files - use 'domain_' prefix for domain ledger files - migration script (for upgrade) - script for reading the ledger - use real json instead of string for CLAIM_DEF and SCHEMA - code cleanup: - use json serialization for genesis txns -- re-factor all serializations to have one place for settings -- re-factor ledger and key-value storage hierarchy a bit (still not perfect)  PRs: - https://github.com/hyperledger/indy-plenum/pull/331 - https://github.com/hyperledger/indy-node/pull/300 - https://github.com/sovrin-foundation/sovrin/pull/16  Build: - indy-node 1.0.99 - sovrin 1.0.23  Recommendations for QA: 1. Check that a fresh pool with a new code is working (all genesis txn files are applied) 2. Check that Upgrade works and migration works (all previous data is present and accessible and the pool is still working after update) 3. Check that CLAIM_DEF/SCHEMA works (old one are still present and new one can be added) 4. Check that a new command `read_ledger` works. It can be used to read the ledger txns. Use `read_ledger -h` for help.  Examples: -  `read_ledger --type=pool`: first 100 pool txns as jsons -  `read_ledger --type=domain`: first 100 domain txns as jsons -  `read_ledger --type=domain frm=10 to=20`: domain txns from 10 till 20  -  `read_ledger --type=domain --seq_no=5`: 5th domain txn  -  `read_ledger --type=pool --count` -  `read_ledger --type=domain --count` -  `read_ledger --type=config --count`   ></body> </Action>
<Action id="29736" issue="18898" author="vladimirwork" type="comment" body="  ^node1.txt    ^node2.txt    ^node3.txt    ^node4.txt    ^dotsovrin (1).tar.gz  " created="2017-08-11 16:10:11.0" updateauthor="vladimirwork" updated="2017-08-11 16:10:11.0"/>
<Action id="29742" issue="18898" author="ashcherbakov" type="comment" created="2017-08-11 18:00:14.0" updateauthor="ashcherbakov" updated="2017-08-11 18:00:14.0"> <body><! CDATA Some fixes added: indy-node 1.0.102  ></body> </Action>
<Action id="29793" issue="18898" author="vladimirwork" type="comment" created="2017-08-14 09:16:48.0" updateauthor="vladimirwork" updated="2017-08-14 09:16:48.0"> <body><! CDATA Build Info: indy-node 1.0.102  Steps to Reproduce - Case 1: 1. Try "read_ledger" from root user. 2. Try "read_ledger" from sovrin user.  Actual Results: Step 1: No initiated nodes/client found: /root/.sovrin/data/nodes. Step 2: Traceback (most recent call last): File "/usr/local/bin/read_ledger", line 144, in <module> ledger = get_ledger(args) File "/usr/local/bin/read_ledger", line 101, in get_ledger fileNamePrefix=hash_store_name) File "/usr/local/lib/python3.5/dist-packages/plenum/persistence/leveldb_hash_store.py", line 15, in __init__ self.open() File "/usr/local/lib/python3.5/dist-packages/plenum/persistence/leveldb_hash_store.py", line 78, in open self.nodesDb = KeyValueStorageLeveldb(self.dataDir, self.nodes_db_name) File "/usr/local/lib/python3.5/dist-packages/storage/kv_store_leveldb.py", line 21, in __init__ self.open() File "/usr/local/lib/python3.5/dist-packages/storage/kv_store_leveldb.py", line 73, in open self._db = leveldb.LevelDB(self.db_path) leveldb.LevelDBError: IO error: lock /home/sovrin/.sovrin/data/nodes/Node1/pool_merkleNodes/LOCK: Resource temporarily unavailable.  Expected Results: Command should work from any user well.  Steps to Reproduce - Case 2: 1. Send pool upgrade command to reinstall the current version (e.g. from 1.0.102 to 1.0.102).  Actual Results: Upgrade is successful, but applied migrations seems to be wrong (Applying migration 1_0_96_to_1_0_97), see upgrade_journalctl log for more info.  Expected Results: Need to discuss.  ></body> </Action>
<Action id="29858" issue="18898" author="vladimirwork" type="comment" created="2017-08-15 14:46:09.0" updateauthor="vladimirwork" updated="2017-08-16 06:00:21.0"> <body><! CDATA Build Info: indy-node 1.0.84  Steps to Reproduce: 1. Send pool upgrade command from 84 to 105 version.  Actual Results: There are 2 files in .sovrin: pool_transactions_sandbox with correct info about nodes. pool_transactions_sandbox_genesis with incorrect info about nodes.  After the upgrade it looks like all nodes take incorrect info from pool_transactions_sandbox_genesis and this breaks the pool.  ^_node1.log    ^_node2.log    ^_node3.log    ^_node4.log  !Screenshot.PNG|thumbnail!   FYI  ~ashcherbakov   ></body> </Action>
<Action id="29893" issue="18898" author="ashcherbakov" type="comment" body="The latest build with fixes for migration: 1.0.108" created="2017-08-16 12:07:01.0" updateauthor="ashcherbakov" updated="2017-08-16 12:07:01.0"/>
<Action id="29894" issue="18898" author="ashcherbakov" type="comment" created="2017-08-16 12:11:04.0" updateauthor="ashcherbakov" updated="2017-08-16 12:11:04.0"> <body><! CDATA There is a possible problem with the migration: - since we changed the serialization for merkle tree, the roots are changed, and hence the newly updated nodes can not participate in consensus together with old nodes. - re-start of all nodes after migration helps - another workaround is to use force=True with the same time for update.  ></body> </Action>
<Action id="29915" issue="18898" author="ashcherbakov" type="comment" created="2017-08-16 16:02:45.0" updateauthor="ashcherbakov" updated="2017-08-16 16:02:45.0"> <body><! CDATA Another feature is added to read_ledger: show the number of txns in the ledger: `read_ledger --type=pool --count` `read_ledger --type=domain --count` `read_ledger --type=config --count`  ></body> </Action>
<Action id="29946" issue="18898" author="vladimirwork" type="comment" created="2017-08-17 10:24:01.0" updateauthor="vladimirwork" updated="2017-08-17 10:24:01.0"> <body><! CDATA Build Info: sovrin (client) 1.0.67 indy-node 1.0.110  Steps to Reproduce: 1. Send SCHEMA command with valid parameters. 2. Send CLAIM_DEF command with valid parameters.  Actual Results: sovrin@test> send SCHEMA name=Degree version=1.0 keys=undergrad,last_name,first_name,birth_date,postgrad,expiry_date sovrin74c17e is already started, so start has no effect _ensureReqCompleted failed; not trying any more because 20 seconds have passed; args were (('V4SGRU86Z58d6TV7PBUe6f', 1502965385233086), 7qmFGzvDFx5fW65qbQZS2G9SSrX8BXQf4avkdjSWmSpv, <function _submitData at 0x7f0245be1158>) Task exception was never retrieved future: <Task finished coro=<SovrinCli._sendSchemaActionAsync() done, defined at /usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py:863> exception=OperationError('error occurred during operation: client request invalid: InvalidClientRequest("validation error  SchemaField : invalid type <class \'str\'>, dict expected",)',)>  sovrin@test> send CLAIM_DEF ref=16 signature_type=CL Task exception was never retrieved future: <Task finished coro=<SovrinCli._sendClaimDefActionAsync() done, defined at /usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py:888> exception=KeyError('data',)>  Expected Results: Commands should work the same as in 1.0.110 version client.  ></body> </Action>
<Action id="29947" issue="18898" author="vladimirwork" type="comment" created="2017-08-17 10:26:47.0" updateauthor="vladimirwork" updated="2017-08-17 10:26:47.0"> <body><! CDATA Build Info: indy-node 1.0.110  Steps to Reproduce: 1. Perform some commands to add transactions to ledger (send NYM, send SCHEMA, etc). 2. Perform upgrade from 1.0.67 (old serialization) to 1.0.110 (new serialization) version. 3. Check the domain ledger consistency.  Actual Results: There are default entries (15 units) or there is nothing at all in the ledger in all nodes (so in both cases we lose data from the ledger).  Expected Results: Ledger should be the same as it was before the pool upgrade in all nodes.  ></body> </Action>
<Action id="29951" issue="18898" author="ozheregelya" type="comment" created="2017-08-17 12:04:53.0" updateauthor="ozheregelya" updated="2017-08-17 12:04:53.0"> <body><! CDATA *Build Info:* indy-node (used as client) 1.0.67 indy-node 1.0.110  Need to add migration script for client.  *Steps to Reproduce:* 1. Set up pool of 4 nodes, 1 clear node for adding and 1 client (using indy-node 1.0.67) 2. Add 1 clear node to pool. 3. Send POOL_UPGRADE command (for all nodes including newly added one). 4. Restart client, try to connect to test.  *Actual Results:* Following message appear. Client does not work. {code:java} 8BkoWKWvUvxs6g4rpugxzCHWwvHN4C3G2y265zGZ7N1u could not verify catchup reply CATCHUP_REP{'txns': {'5': {'type': '0', 'dest': '4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc', 'signature': '2MARwfygpjAEAfQhA9uG8dwPJcUA7R4WisqNk1bnTQU5eYKtwBCHeRcdBPFVJFQHphcpbdQiqKrqEYQsw6m1FvH2', 'txnTime': 1502961800, 'data': {'node_port': 9701, 'alias': 'Node5', 'services':  'VALIDATOR' , 'client_ip': '10.0.0.6', 'client_port': 9702, 'node_ip': '10.0.0.6'}, 'reqId': 1502961800712640, 'identifier': 'XhYtvJqezMUKfF6KVNaGmT'}}, 'consProof':   , 'ledgerId': 0} since Inconsistency: different root hashes for the same tree size{code} *Expected Results:* Need to add migration for client to have ability to work with the pool.  Â   ></body> </Action>
<Action id="29998" issue="18898" author="ashcherbakov" type="comment" created="2017-08-18 16:43:54.0" updateauthor="ashcherbakov" updated="2017-08-18 16:43:54.0"> <body><! CDATA There was a problem with migration tool that addresses the first issue. https://github.com/hyperledger/indy-node/pull/316  As for the second issue, for now let's assume that we test the latest client only (>1.0.110).   ></body> </Action>
<Action id="30033" issue="18898" author="ashcherbakov" type="comment" created="2017-08-21 09:36:35.0" updateauthor="ashcherbakov" updated="2017-08-21 09:36:35.0"> <body><! CDATA New build (master): 1.0.113  For now we assume that the latest client (1.0.113) can work with the latest pool only.  ></body> </Action>
<Action id="30070" issue="18898" author="vladimirwork" type="comment" created="2017-08-22 13:10:35.0" updateauthor="vladimirwork" updated="2017-08-22 13:10:35.0"> <body><! CDATA Build Info: indy-node 1.0.113  Steps to Reproduce: 1. Perform "send POOL_UPGRADE name=upgrade_reinstall version=1.0.113 sha256=ed0a366b4ef36d40c055672a8b83679e99246fec71a706b4ae4cb7958feace3f action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-18T15:20:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-08-18T15:25:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-08-18T15:30:00.258870+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-08-18T15:35:00.258870+00:00'} timeout=10 force=True reinstall=True"  Actual Results: Upgrade is not performed. Nodes are disconnected and are not connected themselves. !Screenshot.PNG|thumbnail!  See attached journalctl for more info.  ^!reinstall113.txt    ></body> </Action>
<Action id="30095" issue="18898" author="vladimirwork" type="comment" body="The last case is not connected to new serialization so INDY-755 is reported." created="2017-08-23 08:33:15.0" updateauthor="vladimirwork" updated="2017-08-23 08:33:15.0"/>
<Action id="30103" issue="18898" author="vladimirwork" type="comment" created="2017-08-23 12:40:21.0" updateauthor="vladimirwork" updated="2017-08-23 12:40:21.0"> <body><! CDATA Build Info: indy-node 1.0.113  Steps to Validate: 1. Check that a fresh pool with a new code is working (all genesis txn files are applied). 2. Check that pool upgrade works and migration works (all previous data is present and accessible and the pool is still working after update). 3. Check that CLAIM_DEF/SCHEMA works (old one are still present and new one can be added). 4. Check that a new command `read_ledger` works.  Actual Results: New serialization pool works normally.  Additional Info: All node-side issues found due to confirmation/regression testing of this ticket are fixed (client-side issues will be fixed in INDY-733).  ></body> </Action>
