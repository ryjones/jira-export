<Action id="60481" issue="40208" author="esplinr" type="comment" body="Is &apos;from b&apos;m$A&gt;b-io?3s#ui@iPqPU+pD)1DJD)JNg#$oZ%^ -&apos; a corrupt node name?" created="2019-05-29 20:15:55.0" updateauthor="esplinr" updated="2019-05-29 20:16:10.0"/>
<Action id="60518" issue="40208" author="lbendixsen" type="comment" created="2019-05-30 15:11:43.0" updateauthor="lbendixsen" updated="2019-05-30 15:19:11.0"> <body><! CDATA It looks like this might not be fixed for a while, so In the meantime I am interested to know a workaround for this issue.  Any suggestions?  (restart of the node didn't seem to help)     Thanks!  ></body> </Action>
<Action id="60648" issue="40208" author="esplinr" type="comment" created="2019-06-04 13:54:48.0" updateauthor="esplinr" updated="2019-06-04 13:54:48.0"> <body><! CDATA The "corrupt node name" is probably the public key of the node. When the node handshake does not succeed, the node will not have a valid name to put into the logs and so will display the public key.  This could be caused by a node that isn't initialized correctly. But it is more likely to be triggered by a poorly behaving client that is accessing the node. (This could be related to the catch up experiments  ~burdettadam  told me he was doing.)  To validate the error is not being triggered by another node in the pool, in addition to the logs we would need: * the pool ledger, * the audit ledger, * the public key for each node in the pool.  We can then look to see if the public key matches the error message and when it shows up in the ledgers and logs.  ></body> </Action>
<Action id="60655" issue="40208" author="ashcherbakov" type="comment" created="2019-06-04 15:22:03.0" updateauthor="ashcherbakov" updated="2019-06-04 15:22:03.0"> <body><! CDATA There is a very high probability that this is client requests since this is CATCHUP_REQ for the whole Pool ledger (ledgerId=0), that is from seqNo=12 (end of genesis txns) till 27 (the current pool ledger size at that time). Only clients sends CATCHUP_REQs this way. Nodes send CATCHUP_REQ differently: they split all txns to the number of nodes (but not less than 5 per node).  So, the CATCHUP_REQ format and data points to a client, not to the other node.   ~esplinr  ~lbendixsen  FYI  ></body> </Action>
<Action id="60657" issue="40208" author="burdettadam" type="comment" body=" ~esplinr , this one wasn&apos;t me, I have not done any CATCHUP experiments yet. I am still learning about merkle trie roots used in ledger status requests, I am not to the catchup yet." created="2019-06-04 16:08:38.0" updateauthor="burdettadam" updated="2019-06-04 16:08:38.0"/>
<Action id="60667" issue="40208" author="lbendixsen" type="comment" created="2019-06-04 20:19:36.0" updateauthor="lbendixsen" updated="2019-06-04 20:19:36.0"> <body><! CDATA As requested, I have attached the pool and audit ledgers of the FoundationBuilder node.   Here are the Validator DIDs for all of the nodes: |Node Alias|Target (dest)| |FoundationBuilder|GVvdyd7Y6hsBEy5yDDHjqkXgH8zW34K74RsxUiUCZDCE| | vnode1|9Aj2LjQ2fwszJRSdZqg53q5e6ayScmtpeZyPGgKDswT8| | xsvalidatorec2irl|DXn8PUYKZZkq8gC7CZ2PqwECzUs2bpxYiA5TWgoYARa7| | danube|52muwfE7EjTGDKxiQCYWr58D8BcrgyKVjhHgRQdaLiMw| | -uvs_val_node-|-4XgXATccdfzbaoHTN4rUz9sYvfknQ5CQfTF6Qp5T3vyM-| | makolab01|GnuKuvbdcY9ZU3GwvUYzEo3z5nmh1BhJ8BrrsASQM1Fi| | ovvalidator|FCLZXHPFAbARuu1vSp26bhFaNQz9sveL1QWvo2KDZjwb| | datum-sovrin|8t4gWhnbWCnPPkYoHki8zv17WyA8LBM3WhVVsv3ezzh8| | uvs_val2|BrhY8YyJJnuWGYAybMTW7bse9FcBMRpJXb7hfHoKzJjJ| | validatedid|5YwvqQySsNSPPM2RRQWGJeuiGgcCG5uD9NvQRR7ASJac| | OgNode|5aNBs6DToRDNuXamiswdvPhvoGxoLbdEL5XTLdZrv6Xf| | fetch-ai |2wLQxCe25iBQY2d2oEYwYA7StD3AzdiABjyZcMiRWo5n| | Certisign|9v2Wx46nMTqFSzCUbdEvMgP8Y2SaaV7EbVcVu4mvnfZL| | SYGNET1|462gFCdp8eS6SN3MmomACh1Q8XYVAKwYL89dRPYpKY1E|  ></body> </Action>
<Action id="60668" issue="40208" author="lbendixsen" type="comment" body=" ~ashcherbakov  thanks for your helpful comment.  Is there a way to determine which client was spamming the ledger?  I am thinking it was probably one of the several indy-CLIs that I have open on my workstation, as I am one of the few using the BuilderNet so far.  When the buildernet comes back online, I will watch for the spamming to begin again, then try shutting down my CLI&apos;s one by one to see if I can track down the culprit." created="2019-06-04 20:31:56.0" updateauthor="lbendixsen" updated="2019-06-04 20:31:56.0"/>
<Action id="61897" issue="40208" author="ashcherbakov" type="comment" created="2019-07-17 10:01:40.0" updateauthor="ashcherbakov" updated="2019-07-17 10:01:40.0"> <body><! CDATA  ~lbendixsen  Is the issue still valid? Can we close it?  ></body> </Action>
<Action id="61928" issue="40208" author="esplinr" type="comment" body=" ~lbendixsen  has not seen this behavior since this was originally reported. It seemed to disappear with the upgrade to 1.8.0. He is not convinced it isn&apos;t a bug. We will close as &quot;Cannot Reproduce&quot;, and will reopen it if we see it again and have more information." created="2019-07-17 22:46:30.0" updateauthor="esplinr" updated="2019-07-17 22:46:30.0"/>
