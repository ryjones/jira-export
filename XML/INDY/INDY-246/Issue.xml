<Issue id="18241" key="INDY-246" number="246" project="10303" reporter="alexander.shekhovcov" assignee="danielhardman" creator="alexander.shekhovcov" type="10004" summary="Missing pre-prepare hangs 3pc processing" priority="2" resolution="10000" status="10001" created="2017-06-16 16:42:31.0" updated="2019-03-29 20:32:40.0" resolutiondate="2019-03-29 20:32:40.0" votes="0" watches="6" timeoriginalestimate="97200" timeestimate="97200" workflowId="18246"> <description><! CDATA Working on INDY-245 I found that if node misses a pre-prepare from the primary replica the node becomes unable to participate in 3pc later requests.  I wrote the following test (just temporary changed _testNumOfPrePrepareWithOneFault_): {code:java} @pytest.fixture(scope="module") def setup(startedNodes): A = startedNodes.Alpha makeNodeFaulty(A, partial(delaysPrePrepareProcessing, delay=60)) A.delaySelfNomination(10) return adict(faulties=A)   @pytest.fixture(scope="module") def afterElection(setup, up): for r in setup.faulties.replicas: assert not r.isPrimary return setup   def testNumOfPrePrepareWithOneFault(looper, startedNodes, afterElection, preprepared1, wallet1, client1): A = startedNodes.Alpha B = startedNodes.Beta A.resetDelays() requests = sendRandomRequests(wallet1, client1, 5) waitForSufficientRepliesForRequests(looper, client1, requests=requests) assert A.replicas 0 .lastOrderedPPSeqNo == B.replicas 0 .lastOrderedPPSeqNo{code} I see that the Alpha: * gets pre-prepares after the delays were reset and stash them  {code:java} 2017-06-16 19:24:11,157 | DEBUG | replica.py (812) | __is_next_pre_prepare | Alpha:0 missing PRE-PREPAREs between 2 and 0 2017-06-16 19:24:11,157 | DEBUG | replica.py (1484) | enqueue_pre_prepare | Queueing pre-prepares due to unavailability of previous pre-prepares. PrePrepare PREPREPARE{'viewNo': 0, 'ppSeqNo': 2, 'digest': 'ca929a100002614c57ad9b34df75c09187562f2e71d136c86b8ef420b7425c6f', 'ledgerId': 1, 'discarded': 5, 'stateRootHash': 'baa69121f4fa752e60e1fd9285de388ff884dea5ff50a6c4f175e6a5e808e57e', 'reqIdr':  ('MRE3tAh3Wseda9K3ZYMDhL', 1497630250115240), ('MRE3tAh3Wseda9K3ZYMDhL', 1497630250116196), ('MRE3tAh3Wseda9K3ZYMDhL', 1497630250117102), ('MRE3tAh3Wseda9K3ZYMDhL', 1497630250117993), ('MRE3tAh3Wseda9K3ZYMDhL', 1497630250118847) , 'txnRootHash': '8aabbc81eace7f6ce505b4c49b9bdfbff9276bbc4b2d42008d1f2651512ee41e', 'ppTime': 1497630251085.8435, 'instId': 0} from Delta:0 {code} * stashes prepares  {code:java} 2017-06-16 19:24:11,237 | DEBUG | replica.py (708) | processPrepare | Alpha:1 received PREPARE(0, 2) from Delta:1 2017-06-16 19:24:11,237 | DEBUG | replica.py (1525) | enqueuePrepare | Queueing prepare due to unavailability of PRE-PREPARE. Prepare PREPARE{'viewNo': 0, 'ppSeqNo': 2, 'digest': 'ca929a100002614c57ad9b34df75c09187562f2e71d136c86b8ef420b7425c6f', 'stateRootHash': None, 'txnRootHash': None, 'instId': 1} from Delta:1 2017-06-16 19:24:11,237 | DEBUG | replica.py (724) | processPrepare | Alpha:1 cannot process incoming PREPARE {code} * stashes commits  {code:java} 2017-06-16 19:24:11,303 | DEBUG    | replica.py           (1549) | enqueueCommit | Queueing commit due to unavailability of PREPARE. Request COMMIT{'viewNo': 0, 'ppSeqNo': 2, 'instId': 0} from Gamma:0 {code} * and eventually does not reply      Looks like only restarting the node fixes this problem.  h4. POA: A node simply requests PRE-PREPAREs in when lacks PRE-PREPARE, PRE-PREPARE is needed since it has the requests which needs to be ordered. Missing PRE-PREPARE is not very common and to solve this uncommon problem, increasing size of each PREPARE is not acceptable. The request for PRE-PREPARE does not necessarily need to be made to the primary, it can be made to any non-primary or multiple nodes in parallel since quorum of PREPAREs will tell if the PRE-PREPARE is correct or not. So our protocol works even if a minority (<f) of replicas is partitioned from primary. *When to request PRE-PREPARE*: If after receiving a PREPARE, a replica finds that it does not have a PRE-PREPARE for it, the replica checks if it has 2f-1 PREPAREs, if yes then it simply requests PRE-PREPARE from one or more of the nodes that sent PREPARE. A variation can be to wait for a timeout and then request PRE-PREPARE since the replica might miss more than 1 PRE-PREPARE and thus can request in bulk but we are being aggressive so not doing that. Also the replica waits for 2f-1 PREPAREs and not f+1 PREPAREs since even if it got a PRE-PREPARE, it cannot order it until it has >=2f PREPAREs. A general message requesting component needs to be built. A node can send a *MessageReq(type: str, params: dict)* to any node, the other node responds with corresponding message in *MessageRep(type: str, params: dict, msg: Any)*. The *msg* will be null if the other node did not have what was requested, but it should send the *MessageRep* anyway. This mechanism should be used to request `PrePrepare`, `LedgerStatus` and `ConsistencyProof`. {code} Eg. MessageReq(type: LedgerStatus, params: {ledger_id: 1}) MessageReq(type: PrePrepare, params: {instId: 0, viewNo: 0, ppSeqNo:5}) MessageReq(type: ConsistencyProof, params: {ledger_id: 1, seqNoStart: 20, seqNoEnd: 30}) {code}   ></description> </Issue>
