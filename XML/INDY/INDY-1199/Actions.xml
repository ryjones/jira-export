<Action id="43046" issue="28060" author="ashcherbakov" type="comment" created="2018-04-17 08:18:49.0" updateauthor="ashcherbakov" updated="2018-04-17 08:18:49.0"> <body><! CDATA  ~sergey-shilov  Please write a PoA for the issue.  We can consider two more or less simple fixes: just notification of Stewards that the node has lower view change and hence restart is needed, or auto-restart.  ></body> </Action>
<Action id="43475" issue="28060" author="sergey-shilov" type="comment" created="2018-04-26 13:49:04.0" updateauthor="sergey-shilov" updated="2018-04-26 13:49:04.0"> <body><! CDATA *PoA:*  Current implementation of "view change" logic does not accept moving to lower than current view number. Moreover, for now we process in a different ways INSTANCE_CHANGE messages which contain _viewno = currrent_viewno - 1_ and _viewno < currrent_viewno - 1_ as the first described messages treated as 'rudiments' of the previous view change process (as I understand). Finally, for now all these messages are discarded. Various tests shows that we can achieve quorum of nodes that have lower viewno relative to particular participating nodes (group restarts, demote/promote etc.).  The main complexity here is the fact that for now whole our system is designed in a manner when we expect *monotonically growing of everything* since the service is started. It relates to view numbers, ppseqno's, timestamps etc. So that switching to lower viewno on fly, a.g. making step back without service restart, does not correspond to current architecture, has so many explicit and implicit side effects and seems like really hard to implement and debug.  So that I propose the following solution: * collect INSTANCE_CHANGE messages for lower viewno's as well as for higher viewno's * if a quorum for some lower viewno is reached than call auto-restart (instead of starting of whole view change process)  I think that now it is the most optimal solution that does not require very much time.  *NOTE:* current code base contain at least two places with conditions that check for lower viewno, be careful modifying or removing them.  ></body> </Action>
<Action id="47515" issue="28060" author="sergey.khoroshavin" type="comment" created="2018-07-19 08:36:15.0" updateauthor="sergey.khoroshavin" updated="2018-07-19 08:37:38.0"> <body><! CDATA *Problem reason:* When n-f or more nodes restart they have clear 3PC state viewNo 0 ppSeqNo 0, while f or less remaining nodes retain their current state and cannot communicate it back to restarted nodes. This leads to inability to order requests by minority nodes until either view change happens with viewNo greater than their current state, or these nodes are restarted as well.  *Changes:* Added option ENABLE_INCONSISTENCY_WATCHER_NETWORK (disabled by default). When enabled it will restart nodes if they suspect they are in minority with inconsistent 3PC state. Detection is done using network events (connections/disconnections).  *PR:* https://github.com/hyperledger/indy-plenum/pull/811 https://github.com/hyperledger/indy-node/pull/821  *Version:* indy-plenum: 1.4.461-master indy-node: 1.4.509-master  *Risk:* Low/Medium  *Risk factors:* None when ENABLE_INCONSISTENCY_WATCHER_NETWORK is disabled. When this option is enabled there is risk that some sequence of connection/disconnection events can lead to false positive restart, although probability of this is low.  *Covered with tests:* Unit tests: https://github.com/hyperledger/indy-plenum/pull/811/files#diff-8a7a254ad0901148c601c3b13e6cc79e Plenum integration tests: https://github.com/hyperledger/indy-plenum/pull/811/files#diff-8c3427188e75361797749306d6ed0f4f Node integration tests: https://github.com/hyperledger/indy-node/pull/821/files#diff-f381ea2de93ed34e6167e29aa3c25824  *Recommendations for QA:* In order to validate this issue you can: - put ENABLE_INCONSISTENCY_WATCHER_NETWORK=True in /etc/indy/indy_config.py on all nodes - start pool along with mild load test - restart n-f or more nodes - check that after that remaining nodes automatically restart as well - check that all nodes have increasing number of transactions in their ledger  Also it's recommended to enable this option during other tests and watch out for sporadic restarts. If they happen this might be a bug.  ></body> </Action>
<Action id="47591" issue="28060" author="ozheregelya" type="comment" created="2018-07-20 13:11:10.0" updateauthor="ozheregelya" updated="2018-07-20 21:36:53.0"> <body><! CDATA *Environment:* AWS pool of 25 nodes indy-node 1.5.515  *Steps to Reproduce:* 1. Setup the pool with ENABLE_INCONSISTENCY_WATCHER_NETWORK=True in /etc/indy/indy_config.py 2. Run the load test, grep logs for the message "Suspecting inconsistent 3PC state, going to restart". => No "Suspecting inconsistent 3PC state, going to restart" in logs. 3. Restart 1 node manually, check the logs. => No "Suspecting inconsistent 3PC state, going to restart" in logs. 4. Restart F nodes manually. => No "Suspecting inconsistent 3PC state, going to restart" in logs. 5. Restart N - (F+1) nodes manually. => No "Suspecting inconsistent 3PC state, going to restart" in logs. 6. Restart N - F nodes manually. => "Suspecting inconsistent 3PC state, going to restart" appears in logs of not restarted manually nodes. Not restarted nodes also were restarted. 7. Restart N nodes manually. => Part of nodes were restarted second time because of "Suspecting inconsistent 3PC state". 8. Restart N nodes by _ledger pool-restart_. => Part of nodes were restarted second time because of "Suspecting inconsistent 3PC state".  *Actual Results:* After simultaneous restart of all nodes part of the nodes were restarted twice.  *Expected Results:* Nodes should restart once.  ></body> </Action>
<Action id="47629" issue="28060" author="sergey.khoroshavin" type="comment" created="2018-07-23 09:17:53.0" updateauthor="sergey.khoroshavin" updated="2018-07-23 16:56:39.0"> <body><! CDATA *PR:* https://github.com/hyperledger/indy-node/pull/838  *Version:* indy-node 1.5.519-master  *Changes:* Instead of performing restart immediately on suspecting inconsistent 3PC state it is scheduled some time later to avoid double restarts when all pool is manually restarted.  Added INCONSISTENCY_WATCHER_NETWORK_TIMEOUT (defaulting to 90 seconds).  *Risk:* Medium  *Risk factors:* Possible interference with POOL_RESTART transactions which schedule restarts.  *Recommendations for QA:* - validate  original case|https://jira.hyperledger.org/browse/INDY-1199?focusedCommentId=47515&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-47515  - check that during full pool restart inconsistency 3PC restarts are still scheduled, but not actually triggered - check that inconsistency restarts don't interfere with scheduled POOL_RESTART in some unexpected ways  ></body> </Action>
<Action id="48236" issue="28060" author="ozheregelya" type="comment" created="2018-08-01 10:57:28.0" updateauthor="ozheregelya" updated="2018-08-01 10:57:28.0"> <body><! CDATA Environment: indy-node 1.5.529 libindy 1.6.1~659  Steps to Validate: 1. Restart all nodes exclude one of them. => Not restarted node restarted in $(INCONSISTENCY_WATCHER_NETWORK_TIMEOUT) seconds because of 'suspecting inconsistent 3PC state'. 2. Send pool restart without specified date. => All nodes were restarted once. On part of nodes 'suspecting inconsistent 3PC state' appears, but it is cancelled by pool-restart. 3. Restart all nodes exclude one of them. 4. Before the end of INCONSISTENCY_WATCHER_NETWORK_TIMEOUT, send pool-restart. => Restart because of 'suspecting inconsistent 3PC state' was cancelled by pool-restart. 5. Schedule pool-restart. 6. Restart all nodes exclude one of them. => Pool restart was not happened on restarted nodes. It was not happened on not restarted node as well because it cancelled pool restart when scheduled restart because of 'suspecting inconsistent 3PC state'. 7. Restart whole the pool. => Part of nodes scheduled restart because of 'suspecting inconsistent 3PC state', but it was not happened after actual restart.  Actual Results: Pool restarts only once independently on type of restart.  ></body> </Action>
