<Action id="44620" issue="29685" author="spivachuk" type="comment" created="2018-05-17 23:27:47.0" updateauthor="spivachuk" updated="2018-05-17 23:27:47.0"> <body><! CDATA *Problem reason:* - Catch-up initiated by {{LedgerStatus}}-based trigger had a wrong workflow. Moreover, {{LedgerStatus}}-based trigger of catch-up was redundant because catch-up has also {{Checkpoint}}-based trigger. - Commits were not requested for missed ranges of 3PC-batches. - A number of issues were found in the catch-up logic (see the list of them in INDY-1298). - {{Replica.processStashedMsgsForNewWaterMarks}} had a wrong logic which might lead to {{IndexError}} in case of a recursive call of this method.  *Changes:* - Removed the faulty logic of a catch-up start from an arbitrary ledger on reception of a newer {{LedgerStatus}}. - Added requesting of missed {{Commits}} on reception of an out-of-order {{PrePrepare}} to make it possible for the node's replicas to fill the gap in the sequence of 3PC-messages and order them after the node disconnection and further re-connection (because catch-up is not done anymore on reception of a newer {{LedgerStatus}}). - Updated the tests that verify the message requesting mechanism and requesting and processing of missed 3PC-messages. - Removed handling of {{PrePrepares}} being received during catch-up. - Added clearing of the queues related to 3PC-process to {{Node.no_more_catchups_needed}} method in order to eliminate attempts to execute 3PC-batches reverted before catch-up and not re-applied later. - Removed postponing of processing {{LedgerStatuses}} in case a catch-up is in progress. Now older {{LedgerStatuses}} are responded with {{ConsistencyProofs}} immediately in any case. - Fixed issues with use of a wrong quorum for none-proofs. - Fixed a bug with a lack of setting discovering node mode. - Fixed a bug with a possible {{IndexError}} in {{Replica.processStashedMsgsForNewWaterMarks}} method. - Reworked {{test_non_primary_recvs_3phase_message_outside_watermarks}}. - Corrected tests according to the changes made in the catch-up logic. - Disabled the tests which became irrelevant after {{LedgerStatus}}-based catch-up trigger had been removed. - Fixed a bug in test fixtures of indy-node with modifying the genesis domain transactions after the pool nodes have already been initiated using the initial genesis domain transactions.  *PRs:* - https://github.com/hyperledger/indy-plenum/pull/638 - https://github.com/hyperledger/indy-node/pull/694  *Version:* - indy-node 1.3.413-master - indy-plenum 1.2.358-master  *Risk factors:* - {{Checkpoint}}-based catch-up trigger. (Previously we did not deal with it in system tests and real cases because when a node was lagging, {{LedgerStatus}}-based catch-up trigger was raised first.) - Interaction between catch-up and processing of 3PC-messages.  *Risk:* - Medium  *Covered with tests:* - The tests in {{plenum.test.node_catchup}} package. - The tests in {{plenum.test.node_request.message_request}} package. - {{test_non_primary_recvs_3phase_message_outside_watermarks}}  *Recommendations for QA:* - Catch-up is not performed anymore on network reconnection. This also means that catch-up is not performed on node promotion. However, in such situations either the node replicas will request missed 3PC-messages on reception of new PrePrepares and eventually order the missed 3PC-batches (in case a lag in scope of one checkpoint of the master protocol instance) or the node will start catch-up on reception of 2 generation of future {{Checkpoints}} from other nodes (in case of a significant lag). Please note that catch-up is still performed on node start / restart. - Please test that a node requests 3PC-messages and eventually orders the 3PC-batches missed while it was being disconnected (but turned on) in case the lag is in scope of one checkpoint of the master protocol instance. - Please test catch-up under load to check operability of the interaction between catch-up and processing of 3PC-messages.  ></body> </Action>
<Action id="44987" issue="29685" author="zhigunenko.dsr" type="comment" created="2018-05-23 14:17:57.0" updateauthor="zhigunenko.dsr" updated="2018-05-23 14:17:57.0"> <body><! CDATA *Test scenario:* 1) create pool with 20 nodes 2) demote 2 of nodes 3) make load test session 4) check logs for catch-up by checkpoint 5) promote one node and observe its behavior (without load) 6) promote another one during next load test session, observe its behavior 7) during load test session down and up network interface 8) during load test session stop and start indy-node service 9) add new node to pool (when pool is idle) 10) add new node to pool (when pool is under load)  ></body> </Action>
<Action id="45071" issue="29685" author="ozheregelya" type="comment" created="2018-05-24 15:37:05.0" updateauthor="ozheregelya" updated="2018-05-24 15:37:05.0"> <body><! CDATA Testing of this ticket will be performed in scope of INDY-1367 because of current problems with load testing (INDY-1365).  |https://jira.hyperledger.org/secure/AddComment!default.jspa?id=28802   ></body> </Action>
