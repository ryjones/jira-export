<Action id="53994" issue="35685" author="derashe" type="comment" created="2018-11-29 08:52:43.0" updateauthor="derashe" updated="2018-11-29 10:54:03.0"> <body><! CDATA *PoA:*  We need to define ways how can we clear collections related to requests in node and replicas. Also we need to write tests to demonstrate that we are able to clear both finalized and non-finalized requests correctly.  To correctly clear all collections we must take into account all processes that happens after ordering (including hooks). * We can start with already implemented mechanism of clearing replica's queues. ** On master replica we already collecting all "written" pre-prepares and clear every included related requests. We could delete these requests from node.requests right away. ** We can add clearing of requestsQueues on backup replicas, because we clearing monitor statistic right after that.  * For master, the above relates to finalized requests, that were included in 3pc. But we must also consider finalized requests that were not included in 3pc (which must be stored in replica.requestQueues and replica.inBox, node.requests, node.requestSender) and non-finalized requests (which store in node.requests, node.requestSender). One of the ways we can do this by iterating throught node.requests and looking in seqNoDb. If request was placed in DB, than it was catched up, so we can delete it, following the above algorithm. * We must also consider correctly syncronizing token and domain ledger.  ></body> </Action>
<Action id="54002" issue="35685" author="derashe" type="comment" created="2018-11-29 13:01:32.0" updateauthor="derashe" updated="2018-12-03 11:57:41.0"> <body><! CDATA As a result of a discussion we are going to make such a changes: * for requests which were included in prePrepares and sentPrePrepares on master replica with 3PC keys <= last_caught_up_3PC: delete them from requestQueues of master replica _(already implemented)_ and call node.requests.free() for them * for requests in requestQueues of master replica which presented in seqNoDb: delete them from requestQueues of master replica and call node.requests.free() for them * delete those non-finalized requests from node.requests which presented in seqNoDb  We are also going to test at least 6 cases to test postive and negative sides of the above changes: * freeing of finalized sent requests which were caughtup * freeing of finalized non-sent requests which were caughtup * deletion of non-finalized requests which were caughtup * no freeing of finalized sent requests which >= last_caught_up_3PC * no freeing of finalized non-sent requests which >= last_caught_up_3PC * no deletion of non-finalized requests which is not in ledger  ></body> </Action>
<Action id="54438" issue="35685" author="derashe" type="comment" created="2018-12-06 13:23:28.0" updateauthor="derashe" updated="2018-12-06 15:21:04.0"> <body><! CDATA Build info: * indy-node  1.6.720|https://github.com/hyperledger/indy-node/releases/tag/1.6.720-master  * indy-plenum 1.6.624  Committed into: *  https://github.com/hyperledger/indy-plenum/pull/1004   Covered with tests: *  test_clearing_requests_after_catchup.py|https://github.com/hyperledger/indy-plenum/pull/1004/files#diff-eec3d66b372d1ed53aecbff6040d454c   Recommendations for QA:  * Check that catchup procedure works without an anomalies  P.S: Unfortunatelly, it seems it's too hard to reproduce tricky integration test situations described above. But me must ensure that catchup is still fucntioning as follows  ></body> </Action>
<Action id="54616" issue="35685" author="ozheregelya" type="comment" created="2018-12-10 18:58:11.0" updateauthor="ozheregelya" updated="2018-12-10 19:07:11.0"> <body><! CDATA *Environment:* indy-node 1.6.725  *Steps to Validate:* 1. Setup the pool. 2. Demote one of nodes. 3. Run load test. 4. Promote demoted node back. 5. Make sure that node completed catch up successfully and can write after catch up.  *Actual Results:* Catch up basically works. Catch up of large ledger will be tested during of load testing.  ></body> </Action>
