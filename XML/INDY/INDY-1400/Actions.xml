<Action id="45675" issue="30941" author="sergey.khoroshavin" type="comment" created="2018-06-07 23:38:40.0" updateauthor="sergey.khoroshavin" updated="2018-06-07 23:38:40.0"> <body><! CDATA Attached filtered logs around problematic case (along with rules to filter). It can be seen that all nodes can be split into 4 groups: 1) nodes that were able to receive (155,11) through COMMITs during view change, and they were not catching up anything 2) nodes that received (155,11) through catch up, they didn't receive COMMITs because they were pended due to last prepared being (155, 10) 3) nodes that were late and received (155,11) through catch up (along with many other things) 4) bad node (16) which started catchup, received some transactions, then received enough COMMITs to order (155,11), then received more transactions through catchup, then view change timeout fired and during next view change ordered batch was commited on top of some transactions that were added due to catchup   ></body> </Action>
<Action id="45737" issue="30941" author="spivachuk" type="comment" created="2018-06-08 20:09:38.0" updateauthor="spivachuk" updated="2018-06-09 09:32:36.0"> <body><! CDATA h2. The issue with an incorrect state trie root on Node16  A catch-up on Node16 being performed in scope of view change to the view 156 was interrupted by starting the propagate primary view change to the view 157. In result, {{LedgerManager.last_caught_up_3PC}} had not been updated and this made it possible for Node16 to order 3PC-batch (155, 11) including already caught up transactions during the new view change. Thus duplicates were added to the ledger and so it was corrupted. Under such conditions Node16 fell out from consensus and the next {{PrePrepare}} was discarded as having an incorrect state trie root.  Node4 that remained in consensus executed the batch (155, 10) with the {{txn_seq_no}} range (60330, 60429): {code:java} 2018-05-31 09:30:19.729 | DEBUG | node.py              (2593) | executeBatch | Node4 storing 3PC key (155, 10) for ledger 1 range (60330, 60429) {code} Then it started view change to the view 156 on a quorum of {{InstanceChanges}}: {code:java} 2018-05-31 09:30:23.064000 | Node4:- | INFO | view_changer.py      ( 468) | do_view_change_if_possible | VIEW CHANGE: Node4 initiating a view change to 156 from 155 {code} During the view change it executed the batch (155, 11) with the {{txn_seq_no}} range (60430, 60529): {code:java} 2018-05-31 09:30:41.946 | DEBUG | node.py              (2593) | executeBatch | Node4 storing 3PC key (155, 11) for ledger 1 range (60430, 60529) {code} Node16 executed the batch (155, 10) with the same {{txn_seq_no}} range as Node4: {code:java} 2018-05-31 09:30:14.875 | DEBUG | node.py              (2593) | executeBatch | Node16 storing 3PC key (155, 10) for ledger 1 range (60330, 60429) {code} Then it started a view change to the view 156 on a quorum of {{InstanceChanges}}: {code:java} 2018-05-31 09:30:20.189 | INFO | view_changer.py      ( 468) | do_view_change_if_possible | VIEW CHANGE: Node16 initiating a view change to 156 from 155 {code} During the view change Node16 started to perform the domain ledger synchronization in scope of some catch-up round: {code:java} 2018-05-31 09:30:43.117 | DEBUG | ledger_manager.py    ( 802) | startCatchUpProcess | Node16 started catching up with consistency proof CONSISTENCY_PROOF{'oldMerkleRoot': ..., 'ppSeqNo': 11, 'seqNoStart': 60429, 'seqNoEnd': 60529, 'hashes': (...), 'viewNo': 155, 'newMerkleRoot': ..., 'ledgerId': 1} {code} It actually caught up only 7 of 100 transactions: {code:java} 2018-05-31 09:30:43.333 | DEBUG | ledger_manager.py    ( 499) | processCatchupRep | Node16 processed 5 catchup replies with sequence numbers  60430, 60431, 60432, 60433, 60434  2018-05-31 09:32:43.248 | DEBUG | ledger_manager.py    ( 499) | processCatchupRep | Node16 processed 2 catchup replies with sequence numbers  60435, 60436  {code} Then it started a propagate primary view change to the view 157 on a quorum of {{ViewChangeDones}} to a future view from other nodes, so that the catch-up was interrupted: {code:java} 2018-05-31 09:33:49.359 | INFO | view_changer.py      ( 481) | _start_view_change_if_possible | VIEW CHANGE: Node16 starting view change for 157 after 8 view change indications from other nodes {code} During this new view change it executed the batch (155, 11) with the {{txn_seq_no}} range {color:#d04437}(60437, 60536){color} shifted 7 txns upper because some transactions from this batch had already been added to the ledger in scope of the uncompleted catch-up: {code:java} 2018-05-31 09:33:49.872 | DEBUG | node.py              (2593) | executeBatch | Node16 storing 3PC key (155, 11) for ledger 1 range (60437, 60536) {code} This was revealed as a mismatch between the resulting state and the state from {{Ordered}} message (where it was taken from {{PrePrepare}} message initially applied and later rolled back at catch-up start): {code:java} 2018-05-31 09:33:49.858 | WARNING | idr_cache.py         ( 106) | onBatchCommitted | 3PC: Node16: The first created batch has not been committed or reverted and yet another batch is trying to be committed, b'\xf1\x9e"rJ\x86\x82\xe6\xaa&\n\xf5\x80\xea\n/\x90\xfa\xf2\xf5=\x917#\xe1\xbamT\xf0\xbe\xd1\xbe' b'\xc1\xcfi\xab\xc8z \xd0\xb2I_~|\xa7\x04(\xeciR\x91\xcfQ8\xe0z2\x80\xdbT\x17\xe7%' {code} Eventually this resulted in that Node16 fell out from consensus when trying to apply the next batch (157, 1) after the view change completion: {code:java} 2018-05-31 09:37:06.734 | WARNING | node.py              (2821) | Node16 raised suspicion on node Node4 for Pre-Prepare message has incorrect state trie root; suspicion code is 21 {code}  ></body> </Action>
<Action id="46358" issue="30941" author="ashcherbakov" type="comment" created="2018-06-21 09:16:15.0" updateauthor="ashcherbakov" updated="2018-06-21 09:16:15.0"> <body><! CDATA `bug.png` - workflow of initial problem found in INDY-1400  `bug_fixed.png` - workflow of the fix done in the scope of INDY-1404 and INDY-1405  `node_init.png` - workflow of a similar problem with node initiation  `node_init_fixed.png` - workflow of the fix done in the scope of INDY-1404 and INDY-1405  ></body> </Action>
