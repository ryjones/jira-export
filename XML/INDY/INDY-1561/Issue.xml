<Issue id="32663" key="INDY-1561" number="1561" project="10303" reporter="ozheregelya" creator="ozheregelya" type="10004" summary="Nodes with 32Gb RAM were failed with OOM after 9 hours with 22thns/sec load" priority="3" resolution="10000" status="10001" created="2018-08-08 09:49:11.0" updated="2019-03-29 20:33:33.0" resolutiondate="2019-03-29 20:33:33.0" votes="0" watches="2" workflowId="43889"> <description><! CDATA indy-node 1.5.543 libindy 1.6.1~655  Steps to Reproduce: 1. Setup the pool of 25 nodes with m4.2xlarge instances (32Gb RAM). 2. Run the load test from 6 client instances (load from INDY-1343 x2): {code:java} python3 perf_processes.py -g pool_transactions_genesis -m t -c 334 -t 33 -n 1 -k nym python3 perf_processes.py -g pool_transactions_genesis -m t -c 334 -t 33 -n 1 -k "{\"schema\": 1, \"attrib\": 3}" python3 perf_processes.py -g pool_transactions_genesis -m t -c 334 -t 132 -n 1 -k cred_def --- python3 perf_processes.py -g pool_transactions_genesis -m t -c 334 -t 1.35 -n 1 -k get_nym python3 perf_processes.py -g pool_transactions_genesis -m t -c 334 -t 3 -n 1 -k "{\"get_schema\": 1, \"get_attrib\": 1}"  python3 perf_processes.py -g pool_transactions_genesis -m t -c 334 -t 6 -n 1 -k get_cred_def{code} Actual Results: Part of nodes were lagged during load. Part of lagged nodes were failed with OOM after end of load.  Additional Information: Reading load was less than writing one. There were only 16 read requests per second, but expectation was that reading load will be greater that the writing one.    Logs and metrics: s3://qanodelogs/load32RAM06aug18/NodeXX/ To get logs, run following command on log processor machine:  aws s3 cp --recursive s3://qanodelogs/load32RAM06aug18/ /home/ev/logs/1561/  ></description> </Issue>
