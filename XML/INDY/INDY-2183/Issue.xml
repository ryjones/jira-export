<Issue id="41379" key="INDY-2183" number="2183" project="10303" reporter="ashcherbakov" assignee="vladimirwork" creator="ashcherbakov" type="10004" summary="A node may not be able to connect to another node if another node was able to connect " priority="3" resolution="10000" status="10001" created="2019-07-24 09:43:35.0" updated="2019-09-24 09:59:44.0" resolutiondate="2019-09-09 12:41:36.0" votes="0" watches="2" workflowId="54386"> <description><! CDATA *How the issues is reproduced* * See logs from INDY-2180: Node1 wasn't able to connect to two nodes (node 4 and node 7), but these two nodes connected to Node1.  Â   *Details* * Node1 was trying to connect to Nodes 4 and 7 all the time. It re-created sockets and sent pings, but didn't receive pongs.  {code:java} ..... 2019-07-23 13:19:42,029|TRACE|remote.py|disconnecting socket 147 2019-07-23 13:19:42,029|TRACE|remote.py|connecting socket 158 to remote Node7:HA(host='10.0.0.8', port=9713), addr: tcp://0.0.0.0:0;10.0.0.8:9713 2019-07-23 13:19:42,029|DEBUG|zstack.py|Node1 pinged Node7 -- 2019-07-23 13:19:42,030|TRACE|remote.py|disconnecting socket 154 2019-07-23 13:19:42,030|TRACE|remote.py|connecting socket 147 to remote Node4:HA(host='10.0.0.5', port=9707), addr: tcp://0.0.0.0:0;10.0.0.5:9707 2019-07-23 13:19:42,031|DEBUG|zstack.py|Node1 pinged Node4 -- 2019-07-23 13:20:12,046|TRACE|remote.py|disconnecting socket 158 2019-07-23 13:20:12,046|TRACE|remote.py|connecting socket 155 to remote Node7:HA(host='10.0.0.8', port=9713), addr: tcp://0.0.0.0:0;10.0.0.8:9713 2019-07-23 13:20:12,047|DEBUG|zstack.py|Node1 pinged Node7 -- 2019-07-23 13:20:12,047|TRACE|remote.py|disconnecting socket 147 2019-07-23 13:20:12,048|TRACE|remote.py|connecting socket 174 to remote Node4:HA(host='10.0.0.5', port=9707), addr: tcp://0.0.0.0:0;10.0.0.5:9707 2019-07-23 13:20:12,048|DEBUG|zstack.py|Node1 pinged Node4 -- 2019-07-23 13:20:42,053|TRACE|remote.py|disconnecting socket 155 2019-07-23 13:20:42,056|TRACE|remote.py|connecting socket 147 to remote Node7:HA(host='10.0.0.8', port=9713), addr: tcp://0.0.0.0:0;10.0.0.8:9713 2019-07-23 13:20:42,056|DEBUG|zstack.py|Node1 pinged Node7 ..... {code} * However, Nodes 4 and 7 were able to connect to Node1:  {code:java} 2019-07-23 13:17:12,365|NOTIFICATION|keep_in_touch.py|Node4's connections changed from {'Node3', 'Node7', 'Node5', 'Node6'} to {'Node1', 'Node3', 'Node7', 'Node5', 'Node6'} ------------ 2019-07-23 13:17:12,378|NOTIFICATION|keep_in_touch.py|Node7's connections changed from {'Node6', 'Node4', 'Node3', 'Node5'} to {'Node6', 'Node4', 'Node3', 'Node5', 'Node1'} {code} * A possible issue here is that Nodes4 and 7 were able to connect and didn't re-created (close and create) the socket anymore. However, Node1 wasn't able and started to close and re-create sockets. For some reasons, Node4 and 7 were not able to detect that Node1's socket is closed. It may indicate a problem with closing a socket, or a problem in a monitor socket responsible for getting Disconnect events. * The hypothesis above is proved by the fact that Node 1 also experience problems with connection to Node2, but was eventually able to connect to it. Node 2 at the same time also wasn't able to connect to Node1 and was re-creating sockets the same way as Node 1 did.  *Suggested fix* * Write a test that tries to reproduce the issue:  ** Make Node1 connected to Node2, but Node2 not connected so that Node2 re-creates sockets to Node1, but Node1 doesn't. * Fix the issue: ** Check that closing of sockets work properly ** Check that monitor events work ** Re-connect a socket to a connected node if we continue getting PINGs from this node which mean that Node1 can not connect to us.  ></description> </Issue>
