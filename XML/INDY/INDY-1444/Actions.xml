<Action id="46835" issue="31564" author="ckochenower" type="comment" created="2018-07-02 20:35:03.0" updateauthor="ckochenower" updated="2018-07-02 20:51:28.0"> <body><! CDATA  ~ashcherbakov  says: "...restart is just one of the ways to start catchup. Another strategy to start Cathup is when node understands that it is behind by receiving a number of stable checkpoints. So, a load is need (about 200 requests) before a node starts catchup."  I attempted to generate several thousand transactions (4000+) and wait a sufficient amount of time (10+ minutes) after unblocking the node port and was unable to observe the node "catch up" in the logs or in validator-info output. As expected, restarting indy-node brought the node back in sync.  {noformat} Node8.log:2018-07-02 20:18:30,383 | INFO     | ledger_manager.py    ( 860) | mark_ledger_synced | CATCH-UP: Node8 completed catching up ledger 1, caught up 4600 in total {noformat}  I still think we have a bug.   ~sergey.khoroshavin  asked that I attach journalctl and node logs. See attached:  dump-of-journalctl.txt  jira.hyperledger.org has a 10MB file size limit for uploads. You may retrieve the indy-node logs at:  https://drive.google.com/file/d/1QkxxTHGOSND35ms7arVitsXjXA6BjaLx/view?usp=sharing  ></body> </Action>
<Action id="46855" issue="31564" author="ashcherbakov" type="comment" created="2018-07-03 12:12:53.0" updateauthor="ashcherbakov" updated="2018-07-03 12:14:01.0"> <body><! CDATA Catchup is started if a node realizes that it's behind by *200 3PC batches,* not 200 requests. Each 3PC bath is created each second, and may contain up to 10000 requests.  So, you need to make sure that 200 batches are created, that is that your load script send at least 200 txns with a delay of >= 1 sec.  The load script that you run doens't specify delay between requests, so they all may be sent at once, and be placed into just a couple of 3PC batches.  Please use `-t` option to specify a delay between requests. See,  https://github.com/hyperledger/indy-node/blob/master/docs/process-based-load-script.md#examples  and, for example, `{{python3 perf_processes.py -c 100 -n 10 -t 1 -k TXN_TYPE}}`  ></body> </Action>
<Action id="46878" issue="31564" author="ckochenower" type="comment" created="2018-07-03 14:53:15.0" updateauthor="ckochenower" updated="2018-07-03 14:53:15.0"> <body><! CDATA  ~ashcherbakov  - Thank you for the detailed explanation. I see now that "So, a load is need (about 200 requests) before a node starts catchup." is more accurately written "So, a load is need *(about 200 3PC batches)* before a node starts catchup."  I will add the '-t 1' when generating load and try again. I will also attempt to discover how many 3PC batches are generated using validator info to ensure the load script generates at least 200 3PC batches.  I will close this ticket if catchup is triggered. Otherwise, I will modify the description to account for changes in my experiment.  ></body> </Action>
<Action id="46885" issue="31564" author="ckochenower" type="comment" created="2018-07-03 16:41:29.0" updateauthor="ckochenower" updated="2018-07-03 16:41:29.0"> <body><! CDATA  ~VladimirWork  successfully demonstrated that catchup is triggered after unblocking the node port AND generating a sufficient number of transactions / 3PC batches.  He followed the same steps I outlined in the description. However, his performance script invocation differed from mine. The difference being I used '-c 20 -n 20' and he used '-c 1 -n 400'.  I retried my experiment using '-c 1 -n 400' while the node port was blocked by the firewall followed by two invocations of '-c 1 -n 400' (800 txns in total - not sure how many 3PC batches this equated to) after unblocking the node port and observed the node "catch up".  I won't attempt to understand or explain how '-c 20 -n 20' and '-c 1 -n 400' differs at the transaction and 3PC batch level. However, I will create a chaosindy experiment that ensures catchup is triggered.  Closing this issue as 'Won't Fix'. Please change the status if 'Won't Fix' is not accurate.  ></body> </Action>
