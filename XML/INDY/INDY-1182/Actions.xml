<Action id="40973" issue="27864" author="seanbohan_sovrin" type="comment" body=" ~smithbk  - right now no one else is working with NFS within the Sovrin network. Is this something where you have the bandwidth to submit a pull-request or support a developer for reproducing and testing a fix?" created="2018-02-27 22:31:48.0" updateauthor="seanbohan_sovrin" updated="2018-02-27 22:31:48.0"/>
<Action id="41129" issue="27864" author="ashcherbakov" type="comment" created="2018-03-02 07:52:45.0" updateauthor="ashcherbakov" updated="2018-03-02 07:52:45.0"> <body><! CDATA I believe a proper way to fix it is to migrate to RocksDB from Leveldb. We've already started this work, just need to finish and make sure that everything works.  We've started making a refactoring with breaking changes, which will require migration of ledgers (changes in txns format). So, it would be convenient to migrate to RocksDB as well.  ></body> </Action>
<Action id="44062" issue="27864" author="smithbk" type="comment" created="2018-05-08 14:37:11.0" updateauthor="smithbk" updated="2018-05-08 14:40:35.0"> <body><! CDATA There are still issues on RocksDB.  It looks to me that read_ledger is not passing read_only=true when opening the DB.   See the following stack entry below. File "/usr/local/lib/python3.5/dist-packages/ledger/ledger.py", line 26, in _defaultStore dataDir, logName, open)  Here is the full stack trace.  $ read_ledger --type pool Traceback (most recent call last): File "/usr/local/bin/read_ledger", line 177, in <module> ledger = get_ledger(args.type, ledger_data_dir) File "/usr/local/bin/read_ledger", line 99, in get_ledger return Ledger(CompactMerkleTree(hashStore=hash_store), dataDir=ledger_data_dir, fileName=ledger_name) File "/usr/local/lib/python3.5/dist-packages/plenum/common/ledger.py", line 13, in __init__ super().__init__(*args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/ledger/ledger.py", line 60, in __init__ self.start() File "/usr/local/lib/python3.5/dist-packages/ledger/ledger.py", line 214, in start config=self.config) File "/usr/local/lib/python3.5/dist-packages/ledger/ledger.py", line 26, in _defaultStore dataDir, logName, open) File "/usr/local/lib/python3.5/dist-packages/storage/helper.py", line 36, in initKeyValueStorageIntKeys return KeyValueStorageRocksdbIntKeys(dataLocation, keyValueStorageName, open, read_only) File "/usr/local/lib/python3.5/dist-packages/storage/kv_store_rocksdb_int_keys.py", line 21, in __init__ super().__init__(db_dir, db_name, open, read_only) File "/usr/local/lib/python3.5/dist-packages/storage/kv_store_rocksdb.py", line 23, in __init__ self.open() File "/usr/local/lib/python3.5/dist-packages/storage/kv_store_rocksdb_int_keys.py", line 27, in open self._db = rocksdb.DB(self._db_path, opts) File "rocksdb/_rocksdb.pyx", line 1437, in rocksdb._rocksdb.DB.__cinit__ File "rocksdb/_rocksdb.pyx", line 84, in rocksdb._rocksdb.check_status rocksdb.errors.RocksIOError: b'IO error: While lock file: /var/lib/indy/sandbox/data/ibmTest/pool_transactions/LOCK: Resource temporarily unavailable'  When indy-node is running, it creates the following NFS locks:  $ find /var/lib/indy/sandbox/data/ibmTest -name LOCK /var/lib/indy/sandbox/data/ibmTest/domain_merkleNodes/LOCK /var/lib/indy/sandbox/data/ibmTest/domain_merkleLeaves/LOCK /var/lib/indy/sandbox/data/ibmTest/domain_transactions/LOCK /var/lib/indy/sandbox/data/ibmTest/domain_state/LOCK /var/lib/indy/sandbox/data/ibmTest/pool_state/LOCK /var/lib/indy/sandbox/data/ibmTest/pool_merkleNodes/LOCK /var/lib/indy/sandbox/data/ibmTest/pool_merkleLeaves/LOCK /var/lib/indy/sandbox/data/ibmTest/pool_transactions/LOCK /var/lib/indy/sandbox/data/ibmTest/idr_cache_db/LOCK /var/lib/indy/sandbox/data/ibmTest/state_signature/LOCK /var/lib/indy/sandbox/data/ibmTest/attr_db/LOCK /var/lib/indy/sandbox/data/ibmTest/state_ts_db/LOCK /var/lib/indy/sandbox/data/ibmTest/seq_no_db/LOCK /var/lib/indy/sandbox/data/ibmTest/config_merkleNodes/LOCK /var/lib/indy/sandbox/data/ibmTest/config_merkleLeaves/LOCK /var/lib/indy/sandbox/data/ibmTest/config_transactions/LOCK /var/lib/indy/sandbox/data/ibmTest/config_state/LOCK    ></body> </Action>
<Action id="44064" issue="27864" author="smithbk" type="comment" body="Ah ... this is now a dup of https://jira.hyperledger.org/browse/INDY-1289, but note that https://jira.hyperledger.org/browse/INDY-1289 is different from https://jira.hyperledger.org/browse/INDY-1317" created="2018-05-08 14:44:51.0" updateauthor="smithbk" updated="2018-05-08 14:45:11.0"/>
<Action id="44324" issue="27864" author="ashcherbakov" type="comment" body=" ~ozheregelya  Please check it as https://jira.hyperledger.org/browse/INDY-1289 is resolved." created="2018-05-14 11:51:17.0" updateauthor="ashcherbakov" updated="2018-05-14 11:51:17.0"/>
<Action id="44545" issue="27864" author="ozheregelya" type="comment" created="2018-05-17 11:13:04.0" updateauthor="ozheregelya" updated="2018-05-17 11:13:04.0"> <body><! CDATA Environment: indy-node 1.3.412 AWS acceptance pool  Steps to Validate: 1. Setup NFS server. 2. Mount NFS to /var/lib/indy on one of nodes. 3. Run the node, write several txns, run read_ledger. => Read ledger works. 4. Stop the node with NFS. 5. Unmount NFS and mount it to another folder. 6. In /etc/indy/indy_config.py change /var/lib/indy to new mount point. 7. Run the node, write several txns, run read_ledger. => Node works, read_ledger works.  Actual Results: Read_ledger works fine with NFS.  ></body> </Action>
