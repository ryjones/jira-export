<Action id="40468" issue="27873" author="mgbailey" type="comment" created="2018-02-20 22:40:58.0" updateauthor="mgbailey" updated="2018-02-20 22:40:58.0"> <body><! CDATA Last Thursday (2/15), we reset the ledger back to the genesis data.  As a part of this, we sent instructions to the stewards on how to backup and delete the ledger data on their nodes.  It appears that these instructions were not followed properly by the stewards of pcValidator01, since there is pre-reset ledger data on the copy of the ledger on their node.  It is not complete (i.e., not all of the old ledger data is there), which is confusing.  Interestingly enough, this mismatch did not prevent consensus until the upgrade occurred.   My current theory is that when the nodes restarted their services following the upgrade, the ledger mismatch was discovered, and the nodes are unable to recover from it.  Logs and ledger data from pcValidator01 are attached.  ^pcvalidator01_logs_2018_02_20.zip   ></body> </Action>
<Action id="40470" issue="27873" author="mgbailey" type="comment" created="2018-02-20 23:41:30.0" updateauthor="mgbailey" updated="2018-02-20 23:41:30.0"> <body><! CDATA *New update.*  I was able to work with the steward of pcValidator01 to get his problem corrected.  He restarted the service on his node.  I then restarted the service on my 7 nodes as well (at 23:24).  At 23:26 I sent a new transaction to the ledger, as shown.  Still no transaction was written. {code:java} indy@sandbox> send NYM dest=2iha2ZoMLJuxvaAU4DPgE5 verkey=~DqZ4ej4PTC6ZPMf6zBY7Es Adding nym 2iha2ZoMLJuxvaAU4DPgE5 indy@sandbox> {code} I am uploading refreshed logs to include this last attempt.         ></body> </Action>
<Action id="40496" issue="27873" author="ashcherbakov" type="comment" created="2018-02-21 14:00:01.0" updateauthor="ashcherbakov" updated="2018-02-21 14:47:50.0"> <body><! CDATA *Problem reason* * One node didn't perform upgrade, and hence didn't restart. So, the last ordered 3PC key for this node was (2,1) (viewNo=2, ppSeqNo=1). * The other nodes restarted and started first catch-up after Upgrade. * All nodes except the not-restarted one send LedgerStatus with viewNo=None and ppSeqNo=None since a view change is not happened yet (no primary is selected yet). * The not-restarted node sent LedgerStatus with viewNo= 2and ppSeqNo=1 * Since all ledgers are the same, the viewNo and ppSeqNo from LedgerStatus are used for setting of last_ordered_3PC for master replica. * There was a bug, that used the first non-None 3PC key from LedgerStatus without checking for quorum. * So, all restarted nodes set (2,1) as last_ordered_3PC for master * But the viewNo was set as 0. * So, when a request came, the primary sent a PREPREPARE with viewNo=0, ppSeqNo=1: (0,1) * All Nodes rejected it with `already ordered`, since (0,1) < (2,1).  => One malicious Node broke the whole Pool.  *Changes*  Require a f+1 quorum for 3PC keys in LedgerStatus when using it for master replica's last_ordered_3PC.  *PR*  Hotfix to Stable branch:  https://github.com/hyperledger/indy-plenum/pull/542   *Version:* - RC 1.3.53  *Risk factors:* - CatchUp - Recovering from f+1 Nodes - Upgrade  *Risk* Low/Med  *Covered with tests:* * test_same_ledger_initial_catchup * test_get_last_txn_3PC_key  *Recommendations for QA* * Do multiple View Changes and perform a forced simultaneous Upgrade for all Nodes except the one (the one should be at viewNo>0). * Check that catch-up works * Check that recovering from f+1 works.  ></body> </Action>
<Action id="40566" issue="27873" author="ashcherbakov" type="comment" created="2018-02-22 14:30:58.0" updateauthor="ashcherbakov" updated="2018-02-22 14:30:58.0"> <body><! CDATA *Problem Description***  After simultaneous forced Upgrade, the first Node doesn't write any new txns.  *Problem reason* * One node (the first one) started Upgrade a bit earlier than the others, finished initial cathc-up and set `last_ordered_3PC= (1,111)` (viewNo=1, ppSeqNo=111). This is fine, since it was the real state of the pool at that time, and there was consensus for this value.  * Then the rest of the pool started restart at the same time. The rest of the pool set `last_ordered_3PC= (0,0)` (as a new fresh state). * => Node1's master replica last_ordered_3PC= (1,111), and all other nodes' master replica last_ordered_3PC= (0,0) * Initial viewNo=0 is set, and the first Node is selected as a primary. * First Node sends PREPREPARE for a new request, and it's correctly ordered on all nodes except the first one * It's not ordered on the first Node, since all 3PC msgs (PREPARE, COMMIT) from other nodes are discarded as `already ordered` (since (0,5) < (1,111)).  *Changes*  Reset `last_ordered_3PC` when starting a view change if the current last_ordered_3PC's viewNo is equal or greater than the new proposed view (because it means this is a last_ordered_3PC from an old state of the pool).  *PR*  Hotfix to Stable branch: https://github.com/hyperledger/indy-plenum/pull/546  *Version:* - RC 1.3.54  *Risk factors:* - CatchUp - Recovering from f+1 Nodes - Upgrade - ViewChange  *Risk* Med  *Covered with tests:* * http://test_last_ordered_reset_for_new_view  *Recommendations for QA* * Do multiple View Changes and perform a forced simultaneous Upgrade for all Nodes except the one (the one should be at viewNo>0). Do simultaneous Upgrade of all Nodes * Check that catch-up works * Check that recovering from f+1 works.  ></body> </Action>
<Action id="40657" issue="27873" author="ozheregelya" type="comment" created="2018-02-23 15:57:33.0" updateauthor="ozheregelya" updated="2018-02-23 16:00:20.0"> <body><! CDATA *Environment:* indy-node=1.3.54 (RC)  *Steps to Validate:* 1. Setup the pool of 11 nodes with indy-node=1.2.50. 2. On one of the nodes change repos in /etc/apt/sources.list from RC to master (it is necessary to get upgrade on this node failed because there is no 1.3.52 version in master repos). 3. Schedule upgrade to version 1.3.52 for all nodes. => Node with changed sources.list was not upgraded. Pool is broken. 4. Upgrade not upgraded node to version 1.3.52 manually and restart it. 5. Schedule upgrade of all nodes to version 1.2.54.  *Actual Results:* Pool works after upgrade to 1.2.54 version.  *Additional Information:* Note that all upgrades were performed with force=True and with the same dates in upgrade schedule for all nodes.  *Following cases were verified in scope of regression testing:* Upgrade 1.2.50 -> 1.3.54: \- Simple upgrade on analog of Live pool; \- Upgrade without one node; \- Manual upgrade; Upgrade 1.3.52 -> 1.3.54: \- Simple upgrade on analog of STN pool; \- Upgrade without one node; \- Manual upgrade; Adding new node to the pool; View change; Catch up; Restore after losing consensus; Upgrade on large pool.  ></body> </Action>
