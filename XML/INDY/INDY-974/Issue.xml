<Issue id="24537" key="INDY-974" number="974" project="10303" reporter="krw910" assignee="sergey-shilov" creator="krw910" type="10004" summary="The larger the pool size the slower the transactions per second" priority="2" resolution="10000" status="10001" created="2017-11-28 21:06:18.0" updated="2019-03-29 20:32:50.0" resolutiondate="2019-03-29 20:32:50.0" votes="0" watches="3" workflowId="24537"> <description><! CDATA The larger the size of a pool the slower the writes per second become.   *Testing Setup* Global pool setup through AWS across as many as 13 regions. 5 Globally dispersed client machines each running Libindy and load testing scripts.  Each client machine using Libindy ran 40 threads each thread sending 10 transactions. So with 5 Libindy machines it was simulating 200 clients each sending 10 transactions for a total of 2,000 transactions.  I would run this test 4 times and take the average transaction per second.  The measurement of transactions per second is done be getting the epoch time stamp from the first transaction that was sent and subtracting it from the epoch time stamp of the last transaction that was sent. The difference in the time stamps gives you the total number of seconds.  Dividing the total transactions by the total seconds of what was committed to the ledger gives the number of transactions per second.  I started with a 7 node pool. After 4 successful runs I would wipe out the ledger and add 3 more nodes. So each run using a different pool size started with basically the same fresh ledger with the exception of the few node transactions to add the new ones to the pool.  *Results of Test* || Ledger Size || Pool Size || Avg Txns / Sec || | 8012 | 7 | 41 | | 8023 | 10 | 35 | | 8021 | 13 | 27 | | 8024 | 16 | 23 | | 6357 | 19 | 21 | | 6705 | 22 | 18 | | 6836 | 25 | 16 |    ></description> </Issue>
