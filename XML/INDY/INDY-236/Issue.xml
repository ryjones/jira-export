<Issue id="18069" key="INDY-236" number="236" project="10303" reporter="aleksey-roldugin" assignee="danielhardman" creator="aleksey-roldugin" type="10004" summary=" RC acceptance testing  Node crashed after promotion" priority="3" resolution="10000" status="10001" created="2017-06-15 16:03:38.0" updated="2019-03-29 20:35:11.0" resolutiondate="2019-03-29 20:35:11.0" votes="0" watches="2" workflowId="18074"> <description><! CDATA h6. BUILD  sovrin-node 0.3.22 sovrin-client 0.3.21  h6. PRECONDITIONS # Pool from 10 machines: 6 nodes and 4 clients # 4 nodes appear as original pool, 2 other were successfully added  h6. STEPS TO REPRODUCE  # Demote Node1: {code:java} sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services':   } Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL (request id: 1497537593487900) G5ZfRFgnnpA4RP7E8gPusd3UEpKpavS1q6PjeWk561Us disconnected from Node1C Fq5bVpEJAg56A4rnhGaCtiunHjZxYfY1Jt4p2dNRuG57 disconnected from Node1C 1thRpQudNCc9MMyGbdpEPzEPmXRWynMXr9MVz1aMkwD disconnected from Node1C Node request completed Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv {code} # Demote Node6: {code:java} sovrin@test> send NODE dest=6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G data={'alias': 'Node6', 'services':   } Sending node request for node identifier 6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G by GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL (request id: 1497538086040430) G5ZfRFgnnpA4RP7E8gPusd3UEpKpavS1q6PjeWk561Us disconnected from Node6C Fq5bVpEJAg56A4rnhGaCtiunHjZxYfY1Jt4p2dNRuG57 disconnected from Node6C 1thRpQudNCc9MMyGbdpEPzEPmXRWynMXr9MVz1aMkwD disconnected from Node6C Node request completed 6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G {code} # Update Node5 (it wasn't demoted so this should not make any effectcs): {code:java} sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'alias': 'Node5', 'services':  'VALIDATOR' } Sending node request for node identifier 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1497538210863065) Node request completed 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc {code} # Promote Node6 (successful): {code:java} sovrin@test> send NODE dest=6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G data={'alias': 'Node6', 'services':  'VALIDATOR' } Sending node request for node identifier 6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G by GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL (request id: 1497538289548552) G5ZfRFgnnpA4RP7E8gPusd3UEpKpavS1q6PjeWk561Us looking for Node6C at 10.0.0.106:9712 Fq5bVpEJAg56A4rnhGaCtiunHjZxYfY1Jt4p2dNRuG57 looking for Node6C at 10.0.0.106:9712 1thRpQudNCc9MMyGbdpEPzEPmXRWynMXr9MVz1aMkwD looking for Node6C at 10.0.0.106:9712 Node request completed 6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G G5ZfRFgnnpA4RP7E8gPusd3UEpKpavS1q6PjeWk561Us now connected to Node6C Fq5bVpEJAg56A4rnhGaCtiunHjZxYfY1Jt4p2dNRuG57 now connected to Node6C 1thRpQudNCc9MMyGbdpEPzEPmXRWynMXr9MVz1aMkwD now connected to Node6C {code} # Promote Node1 (unsuccessful): {code:java} sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services':  'VALIDATOR' } Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL (request id: 1497538346027633) G5ZfRFgnnpA4RP7E8gPusd3UEpKpavS1q6PjeWk561Us looking for Node1C at 10.0.0.101:9702 Fq5bVpEJAg56A4rnhGaCtiunHjZxYfY1Jt4p2dNRuG57 looking for Node1C at 10.0.0.101:9702 1thRpQudNCc9MMyGbdpEPzEPmXRWynMXr9MVz1aMkwD looking for Node1C at 10.0.0.101:9702 Node request completed Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv {code}   h6. ACTUAL RESULT - Node1 probably was not promoted (it didn't make catch up) - There are some errors in response to satus command: {code:java} sovrin@Node1:~/.sovrin$ sudo systemctl status sovrin-node  sudo  password for sovrin: ● sovrin-node.service - Sovrin Node Loaded: loaded (/etc/systemd/system/sovrin-node.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2017-06-15 13:39:26 UTC; 1h 21min ago Main PID: 10937 (start_sovrin_no) Tasks: 3 Memory: 62.7M CPU: 16min 9.592s CGroup: /system.slice/sovrin-node.service └─10937 /usr/bin/python3 /usr/local/bin/start_sovrin_node Node1 9701 9702  Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node 10937 :     ledger.tree.consistency_proof(end, req.catchupTill)  Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node 10937 :   File "/usr/local/lib/python3.5/dist-packages/ledger/compact_merkle_tree.py", line 211, in consistency_proof Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node 10937 :     self._subproof(first, 0, second, True)  Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node 10937 :   File "/usr/local/lib/python3.5/dist-packages/ledger/compact_merkle_tree.py", line 210, in <listcomp> Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node 10937 :     return  self.merkle_tree_hash(a, b) for a, b in Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node 10937 :   File "/usr/local/lib/python3.5/dist-packages/ledger/compact_merkle_tree.py", line 198, in merkle_tree_hash Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node 10937 :     return self.hashStore.readLeaf(end) Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node 10937 :   File "/usr/local/lib/python3.5/dist-packages/ledger/stores/file_hash_store.py", line 81, in readLeaf Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node 10937 :     raise IndexError("No leaf at given position") Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node 10937 : IndexError: No leaf at given position {code}  h6. ADDITIONAL INFORMATION - After restarting sovrin-node.service it made catch up and client connected to it. - Please see attachments  ></description> </Issue>
