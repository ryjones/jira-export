<Action id="47431" issue="31795" author="anikitindsr" type="comment" created="2018-07-17 16:32:50.0" updateauthor="anikitindsr" updated="2018-07-17 16:32:50.0"> <body><! CDATA During log investigation was found that: # Node3 was stopped # Node2 was stopped (view change forcing by primary restart) Current viewNo = 2 # Other nodes try to send start view_change procedure by sending INSTANCE_CHANGE messages. # Needed quorum is n -f . Therefore need at least 5 instance change messages (1 from self and 4 from other) but reachable node count is 4. # Node2 was started and receive 2 INSTANCE_CHANGE message from b'public key' nodes (not connected yet) # After this, Node2 complete propagate primary by current state and Node2's current viewNo is 2 now. # Node2 received 3 INSTANCE_CHANGE messages after connecting to other nodes. Then, this node has 3 INSTANCE_CHANGE messages from identificated nodes (Node6, Node4, Node1) and 2 message from unknown (b'BEhc!q7/\{^9)vgy&p$f!kx.sTfa9gxeT9(BqKVil'  and  b'-2aEQy3=<9:V.^B.sB#>dXd^DGfVU69 2yMSLsc9') # Node2 initiated view change procedure from 2 to 3, completed catchup and try to initiate new view change, because proposed Node3 is not connected (there is no received VIEW_CHANGE_DONE message from proposed primary node) # In other words, nodes: Node1, Node4, Node5 and Node6 never finish view_change to 3 number, Node2 never finish view change to number 4 and will not order transaction.  Fixes: # Don't send INSTANCE_CHANGE to disconnected nodes # Check, that 'from' section in INSTANCE_CHANGE message is identified node (connected node) for incoming INSTANCE_CHANGE messages  ></body> </Action>
<Action id="47522" issue="31795" author="anikitindsr" type="comment" created="2018-07-19 11:16:38.0" updateauthor="anikitindsr" updated="2018-07-19 11:16:38.0"> <body><! CDATA Reasons: * we can receive instance change messages from anyone (also not identified node)  Changes: * added check, that received instance change message was got from known/identified node  Versions: * indy-node: 1.5.514 * indy-plenum: 1.5.465  Steps to validate: * setup pool from 6 nodes * restart primary (node 1) * ensure, that now primary node is number 2 * stop node3 * ensure view change by stopping node2 * wait about 1 minute and check, that new primary is not elected yet * start node2 and check that node2 propagate primary and current viewno is 1 (as for other) * check, that node2 will not start view_change to view 2  ></body> </Action>
<Action id="47616" issue="31795" author="ckochenower" type="comment" created="2018-07-20 20:46:37.0" updateauthor="ckochenower" updated="2018-07-20 20:49:45.0"> <body><! CDATA  ~anikitinDSR  - In response to the stacktrace you posted in the Berdyaev 6 slack channel: {code} My steps is: 1. git checkout <corresponding version of indy-node and indy-plenum> 2. in my develop environment i run `nsreplay Node1.sandbox.20180711163531.tar.gz` and got the next traceback: `Aprox run time: 2 days, 0:41:05 Replaying 530682 messages in total node msg count: 47 of 530682 node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle Traceback (most recent call last): File "./nsreplay", line 447, in <module> sys.exit(main(arguments)) File "./nsreplay", line 440, in main replayer.replay_node(args.recording) File "./nsreplay", line 365, in replay_node start_times) File "/home/anikitin/projects/evernym/sample_project/indy-plenum/plenum/recorder/replayer.py", line 110, in prepare_node_for_replay_and_replay return replay_patched_node(looper, replaying_node, node_recorder, cr) File "/home/anikitin/projects/evernym/sample_project/indy-plenum/plenum/recorder/replayer.py", line 186, in replay_patched_node looper.run(replaying_node.prod()) File "/home/anikitin/projects/evernym/sample_project/indy-plenum/stp_core/loop/looper.py", line 264, in run return self.loop.run_until_complete(what) File "/usr/lib/python3.5/asyncio/base_events.py", line 387, in run_until_complete return future.result() File "/usr/lib/python3.5/asyncio/futures.py", line 274, in result raise self._exception File "/usr/lib/python3.5/asyncio/tasks.py", line 239, in _step result = coro.send(None) File "/home/anikitin/projects/evernym/sample_project/indy-plenum/stp_core/loop/looper.py", line 255, in wrapper raise ex File "/home/anikitin/projects/evernym/sample_project/indy-plenum/stp_core/loop/looper.py", line 242, in wrapper results.append(await coro) File "/home/anikitin/projects/evernym/sample_project/indy-node/indy_node/server/node.py", line 297, in prod c = await super().prod(limit) File "/home/anikitin/projects/evernym/sample_project/indy-plenum/plenum/server/node.py", line 1047, in prod c += await self.serviceReplicas(limit) File "/home/anikitin/projects/evernym/sample_project/indy-plenum/plenum/server/node.py", line 1070, in serviceReplicas inbox_processed = self.replicas.service_inboxes(limit) File "/home/anikitin/projects/evernym/sample_project/indy-plenum/plenum/server/replicas.py", line 74, in service_inboxes sum(replica.serviceQueues(limit) for replica in self._replicas) File "/home/anikitin/projects/evernym/sample_project/indy-plenum/plenum/server/replicas.py", line 74, in <genexpr> sum(replica.serviceQueues(limit) for replica in self._replicas) File "/home/anikitin/projects/evernym/sample_project/indy-plenum/plenum/server/replica.py", line 853, in serviceQueues self.node.isParticipating) else 0 File "/home/anikitin/projects/evernym/sample_project/indy-plenum/plenum/server/replica.py", line 715, in send3PCBatch ppReq = self.create3PCBatch(lid) File "/home/anikitin/projects/evernym/sample_project/indy-plenum/plenum/server/replica.py", line 766, in create3PCBatch pp_seq_no) TypeError: 'NoneType' object is not iterable {code}  It appears to be bug in the replayer: !Screen Shot 2018-07-20 at 2.19.13 PM.png|thumbnail! !Screen Shot 2018-07-20 at 2.17.30 PM.png|thumbnail!   I changed...  {code} ... for key in req_ids: if key not in self.requestQueues ledger_id : # Request not available yet return ... {code}  ...to...  {code} ... for key in req_ids: if key not in self.requestQueues ledger_id : # Request not available yet return None, None, None, tm ... {code}  ...and the replayer is no longer stacktracing.   {code} (indy-1470) vagrant@ubuntu-xenial:~$ ./indy-node/tools/diagnostics/nsreplay -c n ./Node1.sandbox.20180711163531.tar.gz  2018-07-20 20:31:16,451 | INFO     | notifier_plugin_manager.py ( 121) | importPlugins | Found notifier plugins:    2018-07-20 20:31:16,654 | INFO     | notifier_plugin_manager.py ( 121) | importPlugins | Found notifier plugins:    Aprox run time: 2 days, 0:41:05 Replaying 530682 messages in total node msg count: 47 of 530682 node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node msg count: 69 of 530682 node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle node is idle {code}  ></body> </Action>
<Action id="47618" issue="31795" author="ckochenower" type="comment" created="2018-07-20 21:23:42.0" updateauthor="ckochenower" updated="2018-07-20 21:25:01.0"> <body><! CDATA  ~lovesh  - says that the code in replica.py calling consume_req_queue_for_pre_prepare has been changed. The change is causing the stacktrace.  In simplest terms, when binding the left side (l-value) of an expression in python that expects a tuple, the right side of the expression (r-value) must be a tuple with the same arity. When this is not the case, python produces the following stacktrace:  An example of incorrect followed by correct arity. {code} >>> foo = None >>> bar, baz = foo Traceback (most recent call last): File "<stdin>", line 1, in <module> TypeError: 'NoneType' object is not iterable >>> foo = None, None >>> bar, baz = foo >>>  {code}  I will try to find the commit that overwrote  ~lovesh 's original commit. If it can be reverted, I will do so. Otherwise, I will reimplement his original changes to replica.py and submit a PR.  ></body> </Action>
<Action id="47619" issue="31795" author="ckochenower" type="comment" created="2018-07-20 21:32:23.0" updateauthor="ckochenower" updated="2018-07-20 21:34:24.0"> <body><! CDATA  ~lovesh 's PR is  here|https://github.com/hyperledger/indy-plenum/pull/692  (a month ago)  This is the commit that broke the replay: https://github.com/hyperledger/indy-plenum/commit/0ee85972fce5eece7cac95fa943bf8e66f44a878 (18 days ago)  The commit that broke the replay added a test. Therefore, I will submit a PR sufficient to revert the changes in the commit made to replay.py.  ></body> </Action>
<Action id="48142" issue="31795" author="ozheregelya" type="comment" created="2018-07-30 19:50:20.0" updateauthor="ozheregelya" updated="2018-07-31 10:23:21.0"> <body><! CDATA Environment: indy-node 1.5.529 libindy 1.6.1~659  Steps to Validate: 1. Setup the pool of 6 nodes 2. Initiate View Change by primary (Node 1) restart. => Primary is Node 2, ViewNo 1. 3. Stop the Node3. 4. Stop the primary (Node 2). => View Change was not happened. 5. Start the Node2.  Actual Results: After starting of Node2 View Change was not happened. View No is still 1, Primary is Node 2. Pool still works, new txns were written on all nodes.  Additional Information: Node 2 have not started View Change, as described in  ~anikitinDSR 's comment, but the following messages were noticed in logs of Node2: {code:java} 2018-07-30 19:29:47,605|DEBUG|node.py|Node2 received node message from Node5: INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} 2018-07-30 19:29:47,606|TRACE|node.py|Node2 msg validated ({'reason': 26, 'viewNo': 2, 'op': 'INSTANCE_CHANGE'}, 'Node5') 2018-07-30 19:29:47,606|TRACE|node.py|Node2 appending to nodeInbox INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} 2018-07-30 19:29:47,606|DEBUG|node.py|Node2 sending message to view changer: (INSTANCE_CHANGE{'reason': 26, 'viewNo': 2}, 'Node5') 2018-07-30 19:29:47,606|INFO|view_changer.py|Node2 received instance change request: INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} from Node5 2018-07-30 19:29:47,607|DEBUG|monitor.py|Node2 master throughput is not measurable. 2018-07-30 19:29:47,607|TRACE|monitor.py|Node2 found difference between master and backups avg latencies to be acceptable 2018-07-30 19:29:47,607|INFO|view_changer.py|Node2 received instance change message INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} but did not find the master to be slow 2018-07-30 19:29:47,652|TRACE|zstack.py|Node2 got 1 messages through listener 2018-07-30 19:29:47,652|DEBUG|node.py|Node2 received node message from Node1: INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} 2018-07-30 19:29:47,652|TRACE|node.py|Node2 msg validated ({'reason': 26, 'viewNo': 2, 'op': 'INSTANCE_CHANGE'}, 'Node1') 2018-07-30 19:29:47,652|TRACE|node.py|Node2 appending to nodeInbox INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} 2018-07-30 19:29:47,652|DEBUG|node.py|Node2 sending message to view changer: (INSTANCE_CHANGE{'reason': 26, 'viewNo': 2}, 'Node1') 2018-07-30 19:29:47,653|INFO|view_changer.py|Node2 received instance change request: INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} from Node1 2018-07-30 19:29:47,653|DEBUG|monitor.py|Node2 master throughput is not measurable. 2018-07-30 19:29:47,653|TRACE|monitor.py|Node2 found difference between master and backups avg latencies to be acceptable 2018-07-30 19:29:47,653|INFO|view_changer.py|Node2 received instance change message INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} but did not find the master to be slow 2018-07-30 19:29:47,667|TRACE|zstack.py|Node2 got 1 messages through listener 2018-07-30 19:29:47,667|DEBUG|node.py|Node2 received node message from Node4: INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} 2018-07-30 19:29:47,667|TRACE|node.py|Node2 msg validated ({'op': 'INSTANCE_CHANGE', 'reason': 26, 'viewNo': 2}, 'Node4') 2018-07-30 19:29:47,667|TRACE|node.py|Node2 appending to nodeInbox INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} 2018-07-30 19:29:47,667|DEBUG|node.py|Node2 sending message to view changer: (INSTANCE_CHANGE{'reason': 26, 'viewNo': 2}, 'Node4') 2018-07-30 19:29:47,668|INFO|view_changer.py|Node2 received instance change request: INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} from Node4 2018-07-30 19:29:47,668|DEBUG|monitor.py|Node2 master throughput is not measurable. 2018-07-30 19:29:47,668|TRACE|monitor.py|Node2 found difference between master and backups avg latencies to be acceptable 2018-07-30 19:29:47,668|INFO|view_changer.py|Node2 received instance change message INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} but did not find the master to be slow 2018-07-30 19:29:47,745|TRACE|zstack.py|Node2 got 1 messages through listener 2018-07-30 19:29:47,746|DEBUG|node.py|Node2 received node message from Node6: INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} 2018-07-30 19:29:47,746|TRACE|node.py|Node2 msg validated ({'reason': 26, 'op': 'INSTANCE_CHANGE', 'viewNo': 2}, 'Node6') 2018-07-30 19:29:47,746|TRACE|node.py|Node2 appending to nodeInbox INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} 2018-07-30 19:29:47,746|DEBUG|node.py|Node2 sending message to view changer: (INSTANCE_CHANGE{'reason': 26, 'viewNo': 2}, 'Node6') 2018-07-30 19:29:47,747|INFO|view_changer.py|Node2 received instance change request: INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} from Node6 2018-07-30 19:29:47,747|DEBUG|monitor.py|Node2 master throughput is not measurable. 2018-07-30 19:29:47,747|TRACE|monitor.py|Node2 found difference between master and backups avg latencies to be acceptable 2018-07-30 19:29:47,747|INFO|view_changer.py|Node2 received instance change message INSTANCE_CHANGE{'reason': 26, 'viewNo': 2} but did not find the master to be slow {code}  ~anikitinDSR , Is it expected behavior that the rest nodes sent 'INSTANCE_CHANGE' to Node2?     ></body> </Action>
<Action id="48154" issue="31795" author="ozheregelya" type="comment" created="2018-07-30 21:27:20.0" updateauthor="ozheregelya" updated="2018-07-30 21:27:20.0"> <body><! CDATA One more thing. {quote}Fixes: # Don't send INSTANCE_CHANGE to disconnected nodes{quote} Following messages were noticed in logs of active node while Node3 and Node 2 were stopped (after step 4 from previous comment): {code:java} 2018-07-30 21:17:49,655|DEBUG|view_changer.py|Node6's view_changer sending INSTANCE_CHANGE{'viewNo': 2, 'reason': 26} 2018-07-30 21:17:49,655|TRACE|has_action_queue.py|Node6 scheduling action partial(send_instance_change_if_needed) with id 3 to run in 60 seconds 2018-07-30 21:17:49,655|INFO|view_changer.py|Count of rounds without quorum of instance change messages: 0 2018-07-30 21:17:49,656|DEBUG|node.py|Node6 sending message INSTANCE_CHANGE{'viewNo': 2, 'reason': 26} to all recipients:  'Node2', 'Node5', 'Node4', 'Node1', 'Node3'  2018-07-30 21:17:49,656|TRACE|batched.py|Node6 sending msg b'{"op":"INSTANCE_CHANGE","viewNo":2,"reason":26}' to Node2 2018-07-30 21:17:49,656|TRACE|zstack.py|Node6 transmitting message b'{"op":"INSTANCE_CHANGE","viewNo":2,"reason":26}' to Node2 2018-07-30 21:17:49,656|INFO|zstack.py|Remote Node2 is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings 2018-07-30 21:17:49,656|TRACE|batched.py|Node6 sending msg b'{"op":"INSTANCE_CHANGE","viewNo":2,"reason":26}' to Node1 2018-07-30 21:17:49,656|TRACE|zstack.py|Node6 transmitting message b'{"op":"INSTANCE_CHANGE","viewNo":2,"reason":26}' to Node1 2018-07-30 21:17:49,661|TRACE|batched.py|Node6 sending msg b'{"op":"INSTANCE_CHANGE","viewNo":2,"reason":26}' to Node5 2018-07-30 21:17:49,661|TRACE|zstack.py|Node6 transmitting message b'{"op":"INSTANCE_CHANGE","viewNo":2,"reason":26}' to Node5 2018-07-30 21:17:49,661|TRACE|batched.py|Node6 sending msg b'{"op":"INSTANCE_CHANGE","viewNo":2,"reason":26}' to Node4 2018-07-30 21:17:49,661|TRACE|zstack.py|Node6 transmitting message b'{"op":"INSTANCE_CHANGE","viewNo":2,"reason":26}' to Node4 2018-07-30 21:17:49,661|TRACE|batched.py|Node6 sending msg b'{"op":"INSTANCE_CHANGE","viewNo":2,"reason":26}' to Node3 2018-07-30 21:17:49,661|TRACE|zstack.py|Node6 transmitting message b'{"op":"INSTANCE_CHANGE","viewNo":2,"reason":26}' to Node3 2018-07-30 21:17:49,661|INFO|zstack.py|Remote Node3 is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings {code} Is it ok?  ></body> </Action>
<Action id="48168" issue="31795" author="anikitindsr" type="comment" body="Yes, INSTANCE_CHANGE messages to disconnected node would be sent. &quot;Don&apos;t send INSTANCE_CHANGE to disconnected nodes&quot; it&apos;s just a suggestion and fix with ignoring INSTANCE_CHANGE message from unknown will enough" created="2018-07-31 09:43:11.0" updateauthor="anikitindsr" updated="2018-07-31 09:43:11.0"/>
