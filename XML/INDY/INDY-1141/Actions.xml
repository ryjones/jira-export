<Action id="39592" issue="27374" author="vladimirwork" type="comment" body="There is the same issue when I run load test from client machine (logs from 1st (primary), 2nd and 5th (lagged) node are in attachment)." created="2018-02-02 14:43:23.0" updateauthor="vladimirwork" updated="2018-02-02 14:43:23.0"/>
<Action id="39723" issue="27374" author="dsurnin" type="comment" body="it looks like lagged node is able to restore valid state after load script is finished" created="2018-02-06 15:20:22.0" updateauthor="dsurnin" updated="2018-02-06 15:20:22.0"/>
<Action id="39767" issue="27374" author="vladimirwork" type="comment" body="The issue is still reproducing in AWS pool with 4 nodes during adding NYMs via 80 threads. Logs are too big to add them to Jira, will be sent in Slack." created="2018-02-07 10:48:36.0" updateauthor="vladimirwork" updated="2018-02-07 11:36:41.0"/>
<Action id="40379" issue="27374" author="dsurnin" type="comment" created="2018-02-19 13:25:54.0" updateauthor="dsurnin" updated="2018-02-19 13:25:54.0"> <body><! CDATA lagged node cannot catchup because batching logic cannot generate batch from messages almost reached the size limit fixed in node v 310 plenum v 250  ></body> </Action>
<Action id="40406" issue="27374" author="vladimirwork" type="comment" created="2018-02-20 11:29:29.0" updateauthor="vladimirwork" updated="2018-02-20 11:29:29.0"> <body><! CDATA Build Info: indy-node 1.3.310 indy-plenum 1.2.250  Steps to Reproduce: 1. Install pool of 4 nodes. 2. Run 80 threads x 100 write requests load test (from 1st node) and check domain ledger count. 3. Run 100 threads x 100 write requests load test (from 1st node) and check domain ledger count. 4. Run 120 threads x 100 write requests load test (from 1st node) and check domain ledger count. 5. *Run 200 threads x 50 write requests load test (from 1st node) and check domain ledger count.* 6. *Run 1 thread x 100 write requests load test (from 1st node) and check domain ledger count.* 7. *Run 1 thread x 1 write request load test (from 1st node) and check domain ledger count.*  Actual Results: There are 29531 txns written to 1st node vs 29533 txns written to all other nodes at Step 5 (2 lost txns). There are 29627 txns written to 1st node vs 29633 txns written to all other nodes at Step 6 (6 lost txns). There are 29627 txns written to 1st node vs 29634 txns written to all other nodes at Step 7 (7 lost txns).   ></body> </Action>
<Action id="40568" issue="27374" author="dsurnin" type="comment" created="2018-02-22 14:55:16.0" updateauthor="dsurnin" updated="2018-02-22 14:55:16.0"> <body><! CDATA looks like issue is not reproduced with small load.  for QA: could you please test basic case: 25 nodes, 20 threads, >= 100000 reqs, run load test from the client machine  ></body> </Action>
<Action id="40916" issue="27374" author="vladimirwork" type="comment" created="2018-02-27 12:26:54.0" updateauthor="vladimirwork" updated="2018-02-27 12:26:54.0"> <body><! CDATA The issue is not reproducing with small load (less than 200 threads) and pools up to 11 nodes. Case with 25 nodes pool will be tested in scope of INDY-1180.  ></body> </Action>
