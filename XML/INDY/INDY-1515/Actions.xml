<Action id="48041" issue="32143" author="ckochenower" type="comment" created="2018-07-27 14:55:58.0" updateauthor="ckochenower" updated="2018-07-27 14:55:58.0"> <body><! CDATA  ~ozheregelya  made the following clarifying remarks:  In these cases behavior for 'more than or equal F+1 nodes alive' differs from behavior for 'less than F+1 nodes alive':  1. More than F, but less than N - F nodes stopped / out of sync. => Pool can't write txns while nodes are stopped / out of sync. After starting of stopped nodes pool works and all nodes have ViewNo is the same as before. 2. More than or equal N - F nodes stopped / out of sync. => Pool can't write txns while nodes are stopped / out of sync. After simultaneous starting of stopped nodes pool works and all nodes have ViewNo 0. For case 3 we had an issue INDY-1199. It's already fixed, but for now need to put option ENABLE_INCONSISTENCY_WATCHER_NETWORK=True to the /etc/indy/indy_config.py to enable restoring the pool after stopping of more than N - F nodes. This parameter will be set to the config by default soon.  ></body> </Action>
<Action id="48044" issue="32143" author="ozheregelya" type="comment" created="2018-07-27 15:20:36.0" updateauthor="ozheregelya" updated="2018-07-27 15:20:36.0"> <body><! CDATA Sorry for my mistake in Case 1. View No may be changed if primary was stopped when more than N-F nodes were alive. So here should be  1. More than F, but less than N - F nodes stopped / out of sync. => Pool can't write txns while nodes are stopped / out of sync. After starting of stopped nodes pool works and all nodes have ViewNo is -the same as before- not less than before.  ></body> </Action>
