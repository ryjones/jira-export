<Action id="39084" issue="27052" author="seanbohan_sovrin" type="comment" created="2018-01-24 22:11:06.0" updateauthor="seanbohan_sovrin" updated="2018-01-24 22:11:06.0"> <body><! CDATA  ~ashcherbakov  - this one is a high priority per my last discussion with MikeB, Kelly and Nathan     ></body> </Action>
<Action id="39100" issue="27052" author="spivachuk" type="comment" body=" ~mgbailey , could you please provide config ledgers from all the nodes and also pool and domain ledgers from {{ev1}}?" created="2018-01-25 12:56:24.0" updateauthor="spivachuk" updated="2018-01-25 12:57:06.0"/>
<Action id="39105" issue="27052" author="mgbailey" type="comment" body=" ~spivachuk  I have requested ledgers from stewards.  It would probably take days to get them from all nodes.  Attached are the ledgers from ev1. ^ev1_ledgers.tgz " created="2018-01-25 14:17:06.0" updateauthor="mgbailey" updated="2018-01-25 14:17:06.0"/>
<Action id="39170" issue="27052" author="spivachuk" type="comment" body="Thank you,  ~mgbailey . Could you please provide logs from {{BIGAWSUSEAST1-001}}?" created="2018-01-26 14:16:49.0" updateauthor="spivachuk" updated="2018-01-26 14:16:49.0"/>
<Action id="39191" issue="27052" author="mgbailey" type="comment" body=" ~spivachuk , Attached logs from BIG:  ^BIG_Node.tar " created="2018-01-26 16:51:35.0" updateauthor="mgbailey" updated="2018-01-26 16:51:35.0"/>
<Action id="39358" issue="27052" author="spivachuk" type="comment" created="2018-01-30 11:38:32.0" updateauthor="spivachuk" updated="2018-01-30 14:50:52.0"> <body><! CDATA *Problem reason:* - The master replica of {{ev1}} stopped to order 3PC-batches on January, 24 at 13:21:06 when it received a PREPREPARE message with a wrong state trie root hash from the master's primary ({{BIGAWSUSEAST1-001:0}}). As we can see in the attached ledgers, the whole master protocol instance stopped to order 3PC-batches from this PREPREPARE. This PREPREPARE contained repeated and belated requests. _(We saw the behavior with sending PREPREPAREs with repeated requests earlier in INDY-959, INDY-1045 and INDY-1079 and we made a related fix in scope of INDY-959 with adding a check of the request presence in {{seqNoDB}} on processing PROPAGATE.)_ Also this PREPREPARE was the first one for the domain ledger during the pool upgrade process. The format of a nym representation in the domain state was changed in the version {{1.2.50-stable}} in comparison with the version {{1.1.43-stable}}: {{txnTime}} field was added to the set of fields being stored. This results in difference between the states trie root hashes for the same domain transaction logs in these versions. At the moment when this PREPREPARE was sent, 5 nodes (including {{ev1}}) of 14 were already upgraded to the version {{1.2.50-stable}}, 1 node was in the process of upgrading and 8 nodes (including the master's primary {{BIGAWSUSEAST1-001}}) were still on the version {{1.1.43-stable}}. Each upgraded node re-created all the states because they had been removed by the migration script {{1_2_44_to_1_2_45.py}}. So each upgraded node got the domain state in the new format. Also when applying NYM requests from the PREPREPARE, each upgraded node updated the domain state using the new format. So only 7 not upgraded non-primary nodes could agree with the state trie root hash of this PREPREPARE from the not upgraded primary and send PREPARE. But that was insufficient for the quorum of PREPAREs which was 9. Thus the master instance did not order this 3PC-batch.  *Problem state:* - The change of the domain state format (the addition of {{txnTime}} field to the nym representation) was appeared in the version {{1.2.50-stable}}. Each upgraded node rebuilt all the states because they had been removed by the migration script {{1_2_44_to_1_2_45.py}}. Thus each upgraded node has the domain state in the new format. So this change in the domain state format will not harm upgrades from {{1.2.50-stable}} or higher version, i.e. further upgrades of the live pool.  *Recommendations for QA:* - When testing upgrade to a new version, it makes sense to test pool upgrade under load of domain requests.  ></body> </Action>
<Action id="39359" issue="27052" author="spivachuk" type="comment" body="The cause of the issue observed in INDY-1079 with incorrect state trie root hash of PREPREPARE message was the same as in this ticket." created="2018-01-30 11:46:07.0" updateauthor="spivachuk" updated="2018-01-30 11:46:07.0"/>
<Action id="39435" issue="27052" author="ashcherbakov" type="comment" created="2018-01-31 15:37:34.0" updateauthor="ashcherbakov" updated="2018-01-31 15:37:34.0"> <body><! CDATA So, nothing to fix now, the issues as it is will not be reproduced on master.  Nevertheless it's worth creating some exploratory tasks to investigate about duplicates (they will not have any harm because of INDY-959, but it makes sense to check whether they still may occur and why).  ></body> </Action>
<Action id="39502" issue="27052" author="ozheregelya" type="comment" body="Ticket for QA exploration: INDY-1120." created="2018-02-01 14:09:38.0" updateauthor="ozheregelya" updated="2018-02-01 14:09:38.0"/>
