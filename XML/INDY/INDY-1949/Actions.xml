<Action id="55723" issue="36825" author="ozheregelya" type="comment" created="2019-01-16 16:12:11.0" updateauthor="ozheregelya" updated="2019-01-16 16:12:11.0"> <body><! CDATA Process is still alive: !111.png|thumbnail!  ></body> </Action>
<Action id="55755" issue="36825" author="sergey.khoroshavin" type="comment" created="2019-01-17 10:14:56.0" updateauthor="sergey.khoroshavin" updated="2019-01-17 10:14:56.0"> <body><! CDATA Looked at Node3 and found very similar logs in the end: {code} 2019-01-16 13:16:52,297|INFO|replica.py|Node3:7 set last ordered as (1, 1200) 2019-01-16 13:16:52,297|INFO|replica.py|Node3:7 ordered batch request, view no 1, ppSeqNo 1200, ledger 1, state root None, txn root None, requests ordered 5, discarded 0 2019-01-16 13:16:52,297|INFO|replica.py|Node3:7 sending Checkpoint (1101, 1200) view 1 checkpointState digest 687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301. Ledger 1 txn root hash None. Committed state root hash None Uncommitted state root hash None 2019-01-16 13:16:52,297|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node14 2019-01-16 13:16:52,298|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node13 2019-01-16 13:16:52,298|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node21 2019-01-16 13:16:52,298|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node23 2019-01-16 13:16:52,298|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node20 2019-01-16 13:16:52,298|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node19 2019-01-16 13:16:52,298|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node1 2019-01-16 13:16:52,298|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node15 2019-01-16 13:16:52,299|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node12 2019-01-16 13:16:52,299|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node25 2019-01-16 13:16:52,299|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node4 2019-01-16 13:16:52,299|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node10 2019-01-16 13:16:52,299|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node7 2019-01-16 13:16:52,299|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node17 2019-01-16 13:16:52,299|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node2 2019-01-16 13:16:52,299|INFO|replica.py|Node3:7 processing checkpoint CHECKPOINT{'digest': '687892c94e23725c077ee96072824a2a3d18eb28edd740fe1147db26fc6d2301', 'seqNoEnd': 1200, 'seqNoStart': 1101, 'instId': 7, 'viewNo': 1} from Node6 2019-01-16 13:16:52,300|INFO|replica.py|Node3:7 set watermarks as 1200 1500 2019-01-16 13:16:52,300|INFO|replica.py|Node3:7 removing stashed checkpoints: viewNo=1, seqNoStart=1101, seqNoEnd=1200 2019-01-16 13:16:52,300|INFO|replica.py|Node3:7 cleaning up till (1, 1200) 2019-01-16 13:16:52,311|INFO|replica.py|Node3:7 marked stable checkpoint (1101, 1200) 2019-01-16 13:16:52,312|INFO|replica.py|Node3:7 processed 16 stashed checkpoints for (1101, 1200), 16 of them were stashed again {code}  Attaching to hung process with gdb showed that there is an activity in main thread, and when stopping at random times stack trace were very similar. One stack trace example: {code} File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 68, in handleSync if isinstance(msg, tuple) and len( File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 94, in handleSync super().handleSync(msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 2343, in dequeue_commits self.threePhaseRouter.handleSync((commit, sender)) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1572, in addToPrepares self.dequeue_commits(prepare.viewNo, prepare.ppSeqNo) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1173, in processPrepare self.addToPrepares(prepare, sender) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 210, in wrapper return f(self, *args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 70, in handleSync return self.getFunc(msg 0 )(*msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 94, in handleSync super().handleSync(msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 2316, in dequeue_prepares self.threePhaseRouter.handleSync((prepare, sender)) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1469, in addToPrePrepares self.dequeue_prepares(*key) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1036, in _process_valid_preprepare self.addToPrePrepares(pre_prepare) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1078, in processPrePrepare self._process_valid_preprepare(pre_prepare, sender) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 210, in wrapper return f(self, *args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 70, in handleSync return self.getFunc(msg 0 )(*msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 94, in handleSync super().handleSync(msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1021, in process_three_phase_msg self.threePhaseRouter.handleSync((msg, sender)) File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 70, in handleSync return self.getFunc(msg 0 )(*msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 114, in handleAllSync self.handleSync(msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 995, in serviceQueues r += self.inBoxRouter.handleAllSync(self.inBox, limit) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 210, in wrapper return f(self, *args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replicas.py", line 97, in <genexpr> sum(replica.serviceQueues(limit) for replica in self._replicas.values()) <built-in method sum of module object at remote 0x7ffbb83145e8> File "/usr/local/lib/python3.5/dist-packages/plenum/server/replicas.py", line 97, in service_inboxes sum(replica.serviceQueues(limit) for replica in self._replicas.values()) File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1389, in _process_replica_messages inbox_processed = self.replicas.service_inboxes(limit) File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1386, in serviceReplicas return self._process_replica_messages(limit) File "/usr/local/lib/python3.5/dist-packages/plenum/common/metrics_collector.py", line 367, in wrapper return await f(self, *args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1356, in prod c += await self.serviceReplicas(limit) File "/usr/local/lib/python3.5/dist-packages/plenum/common/metrics_collector.py", line 367, in wrapper return await f(self, *args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/indy_node/server/node.py", line 313, in prod c = await super().prod(limit) File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 152, in prodAllOnce s += await n.prod(limit) File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 210, in runOnceNicely msgsProcessed = await self.prodAllOnce() File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 227, in runForever await self.runOnceNicely() File "/usr/lib/python3.5/asyncio/tasks.py", line 239, in _step result = coro.send(None) File "/usr/lib/python3.5/asyncio/tasks.py", line 307, in _wakeup self._step() File "/usr/lib/python3.5/asyncio/events.py", line 125, in _run self._callback(*self._args) File "/usr/lib/python3.5/asyncio/base_events.py", line 1312, in _run_once handle._run() File "/usr/lib/python3.5/asyncio/base_events.py", line 345, in run_forever self._run_once() File "/usr/lib/python3.5/asyncio/base_events.py", line 375, in run_until_complete self.run_forever() File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 263, in run return self.loop.run_until_complete(what) File "/usr/local/lib/python3.5/dist-packages/indy_node/utils/node_runner.py", line 54, in run_node looper.run() File "/usr/local/bin/start_indy_node", line 19, in <module> client_ip=sys.argv 4 , client_port=int(sys.argv 5 )) {code}  Another (a bit trimmed) example: {code} File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 2324, in enqueue_commit "Request {} from {}".format(request, sender)) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1650, in validateCommit self.enqueue_commit(commit, sender) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1197, in processCommit if self.validateCommit(commit, sender): File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 210, in wrapper return f(self, *args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 70, in handleSync return self.getFunc(msg 0 )(*msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 94, in handleSync super().handleSync(msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 2343, in dequeue_commits self.threePhaseRouter.handleSync((commit, sender)) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1572, in addToPrepares self.dequeue_commits(prepare.viewNo, prepare.ppSeqNo) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1173, in processPrepare self.addToPrepares(prepare, sender) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 210, in wrapper return f(self, *args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 70, in handleSync return self.getFunc(msg 0 )(*msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 94, in handleSync super().handleSync(msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 2316, in dequeue_prepares self.threePhaseRouter.handleSync((prepare, sender)) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1469, in addToPrePrepares self.dequeue_prepares(*key) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1036, in _process_valid_preprepare self.addToPrePrepares(pre_prepare) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1078, in processPrePrepare self._process_valid_preprepare(pre_prepare, sender) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 210, in wrapper return f(self, *args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 70, in handleSync return self.getFunc(msg 0 )(*msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 94, in handleSync super().handleSync(msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 1021, in process_three_phase_msg self.threePhaseRouter.handleSync((msg, sender)) File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 70, in handleSync return self.getFunc(msg 0 )(*msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 114, in handleAllSync self.handleSync(msg) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 995, in serviceQueues r += self.inBoxRouter.handleAllSync(self.inBox, limit) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 210, in wrapper return f(self, *args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/plenum/server/replicas.py", line 97, in <genexpr> sum(replica.serviceQueues(limit) for replica in self._replicas.values()) <built-in method sum of module object at remote 0x7ffbb83145e8> File "/usr/local/lib/python3.5/dist-packages/plenum/server/replicas.py", line 97, in service_inboxes sum(replica.serviceQueues(limit) for replica in self._replicas.values()) File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1389, in _process_replica_messages inbox_processed = self.replicas.service_inboxes(limit) File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1386, in serviceReplicas return self._process_replica_messages(limit) File "/usr/local/lib/python3.5/dist-packages/plenum/common/metrics_collector.py", line 367, in wrapper return await f(self, *args, **kwargs) File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1356, in prod {code}  ></body> </Action>
<Action id="55756" issue="36825" author="sergey.khoroshavin" type="comment" body="*Preliminary hypothesis:* during processing of PREPREPARE some PREPAREs and COMMITs are getting processed, but then stashed again in an infinite loop." created="2019-01-17 10:17:18.0" updateauthor="sergey.khoroshavin" updated="2019-01-17 10:17:18.0"/>
<Action id="55852" issue="36825" author="ozheregelya" type="comment" created="2019-01-19 12:53:36.0" updateauthor="ozheregelya" updated="2019-01-21 11:56:38.0"> <body><! CDATA *Environment:* indy-node 1.6.761  *Steps to Reproduce:* 1. Set up the pool. 2. Run production load.  *Actual Results:* *Case 1:* Pool stopped writing after ~85K txns in domain and ~80K in sovtoken ledgers.  Hanged nodes were not noticed, but Node23 was stopped earlier than the others with following errors in journalctl: {code:java} Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 : --- Logging error --- Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 : Traceback (most recent call last): Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/logging/handlers.py", line 72, in emit Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     self.doRollover() Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/common/logging/CompressingFileHandler.py", line 40, in doRollover Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     self.compressor.start() Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/multiprocessing/process.py", line 105, in start Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     self._popen = self._Popen(self) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/multiprocessing/context.py", line 212, in _Popen Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     return _default_context.get_context().Process._Popen(process_obj) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/multiprocessing/context.py", line 267, in _Popen Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     return Popen(process_obj) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/multiprocessing/popen_fork.py", line 20, in __init__ Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     self._launch(process_obj) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/multiprocessing/popen_fork.py", line 67, in _launch Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     self.pid = os.fork() Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 : OSError:  Errno 12  Cannot allocate memory Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 : Call stack: Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/bin/start_indy_node", line 19, in <module> Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     client_ip=sys.argv 4 , client_port=int(sys.argv 5 )) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/indy_node/utils/node_runner.py", line 54, in run_node Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     looper.run() Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 263, in run Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     return self.loop.run_until_complete(what) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/asyncio/base_events.py", line 375, in run_until_complete Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     self.run_forever() Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/asyncio/base_events.py", line 345, in run_forever Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     self._run_once() Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/asyncio/base_events.py", line 1312, in _run_once Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     handle._run() Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/asyncio/events.py", line 125, in _run Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     self._callback(*self._args) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/asyncio/tasks.py", line 307, in _wakeup Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     self._step() Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/asyncio/tasks.py", line 239, in _step Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     result = coro.send(None) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 227, in runForever Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     await self.runOnceNicely() Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 210, in runOnceNicely Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     msgsProcessed = await self.prodAllOnce() Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 152, in prodAllOnce Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     s += await n.prod(limit) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/indy_node/server/node.py", line 313, in prod Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     c = await super().prod(limit) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/common/metrics_collector.py", line 367, in wrapper Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     return await f(self, *args, **kwargs) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1356, in prod Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     c += await self.serviceReplicas(limit) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/common/metrics_collector.py", line 367, in wrapper Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     return await f(self, *args, **kwargs) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1386, in serviceReplicas Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     return self._process_replica_messages(limit) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1389, in _process_replica_messages Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     inbox_processed = self.replicas.service_inboxes(limit) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/replicas.py", line 97, in service_inboxes Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     sum(replica.serviceQueues(limit) for replica in self._replicas.values()) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/replicas.py", line 97, in <genexpr> Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     sum(replica.serviceQueues(limit) for replica in self._replicas.values()) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 210, in wrapper Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     return f(self, *args, **kwargs) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 995, in serviceQueues Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     r += self.inBoxRouter.handleAllSync(self.inBox, limit) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 114, in handleAllSync Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     self.handleSync(msg) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 72, in handleSync Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     return self.getFunc(msg)(msg) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py", line 982, in readyFor3PC Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 :     'until a primary is chosen'.format(self)) Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 : Message: 'Node23:1 is getting requests but still does not have a primary so the replica will not process the request until a primary is chosen' Jan 19 09:36:37 virginaQALive23.qatest.evernym.com env 15739 : Arguments: () Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 : Traceback (most recent call last): Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/bin/start_indy_node", line 19, in <module> Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     client_ip=sys.argv 4 , client_port=int(sys.argv 5 )) Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/indy_node/utils/node_runner.py", line 54, in run_node Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     looper.run() Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 263, in run Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     return self.loop.run_until_complete(what) Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/asyncio/base_events.py", line 387, in run_until_complete Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     return future.result() Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/asyncio/futures.py", line 274, in result Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     raise self._exception Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/lib/python3.5/asyncio/tasks.py", line 239, in _step Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     result = coro.send(None) Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 227, in runForever Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     await self.runOnceNicely() Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 210, in runOnceNicely Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     msgsProcessed = await self.prodAllOnce() Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 152, in prodAllOnce Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     s += await n.prod(limit) Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/indy_node/server/node.py", line 313, in prod Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     c = await super().prod(limit) Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/common/metrics_collector.py", line 367, in wrapper Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     return await f(self, *args, **kwargs) Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1360, in prod Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     c += self._serviceActions() Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/has_action_queue.py", line 100, in _serviceActions Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     action() Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/has_action_queue.py", line 110, in wrapper Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     action() Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 2851, in flush_metrics Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 :     self.metrics.add_event(MetricsName.GC_TRACKED_OBJECTS, len(gc.get_objects())) Jan 19 09:36:38 virginaQALive23.qatest.evernym.com env 15739 : MemoryError {code} *Logs and metrics for Case 1:* s3://qanodelogs/indy-1949/not_completed_VC_19_01_2019 To get logs, run following command on log processor machine:  aws s3 cp --recursive s3://qanodelogs/indy-1949/not_completed_VC_19_01_2019/ /home/ev/logs/qanodelogs/indy-1949/not_completed_VC_19_01_2019/     *Case 2:* When the test was stopped, pool was in View Change. 8 of 25 nodes were lagged: persistent_node17 80154 persistent_node23 70777 persistent_node21 95689 persistent_node11 119120 persistent_node14 328697 (no space left) persistent_node10 557561 (no space left) persistent_node2 582729 (no space left) persistent_node13 618651 (no space left)  One node have 2 txns more in comparison with the main part of nodes: persistent_node4 778778  The rest nodes have 778776 txns.  *Logs and metrics for Case 2:* s3://qanodelogs/indy-1949/successful_20_01_2019 To get logs, run following command on log processor machine:  aws s3 cp --recursive s3://qanodelogs/indy-1949/successful_20_01_2019/ /home/ev/logs/qanodelogs/indy-1949/successful_20_01_2019/  ></body> </Action>
<Action id="56018" issue="36825" author="ozheregelya" type="comment" created="2019-01-22 16:16:31.0" updateauthor="ozheregelya" updated="2019-01-22 16:16:31.0"> <body><! CDATA *Case 3* (with default config):  No View Changes, but 8 nodes were lagged at the moment when the test was stopped: {code:java} persistent_node1 421566 persistent_node2 421566 persistent_node3 269964 persistent_node4 412970 persistent_node5 421566 persistent_node6 421566 persistent_node7 421566 persistent_node8 421566 persistent_node9 75345 persistent_node10 421566 persistent_node11 421566 persistent_node12 421566 persistent_node13 328253 persistent_node14 280839 persistent_node15 309501  persistent_node16 421566 persistent_node17 164241 persistent_node18 421566 persistent_node19 421566 persistent_node20 421566 persistent_node21 421566 persistent_node22 193836 persistent_node23 421566 persistent_node24 421566 persistent_node25 421566{code} Several hours later part of the nodes completed catch up: {code:java} persistent_node1 421566 persistent_node2 421566 persistent_node3 269964 persistent_node4 421566 persistent_node5 421566 persistent_node6 421566 persistent_node7 421566 persistent_node8 421566 persistent_node9 75345 persistent_node10 421566 persistent_node11 421566 persistent_node12 421566 persistent_node13 421566 persistent_node14 280839 persistent_node15 421566 persistent_node16 421566 persistent_node17 164241 persistent_node18 421566 persistent_node19 421566 persistent_node20 421566 persistent_node21 421566 persistent_node22 193836 persistent_node23 421566 persistent_node24 421566 persistent_node25 421566{code} *Logs and metrics:* s3://qanodelogs/indy-1949/default_config_22_01_2019 To get logs, run following command on log processor machine:  aws s3 cp --recursive s3://qanodelogs/indy-1949/default_config_22_01_2019/ /home/ev/logs/qanodelogs/indy-1949/default_config_22_01_2019/  ></body> </Action>
<Action id="56097" issue="36825" author="ashcherbakov" type="comment" created="2019-01-23 13:25:55.0" updateauthor="ashcherbakov" updated="2019-01-23 13:25:55.0"> <body><! CDATA h2. Initial problem (case 1)  *Problem reason:* * There can be prepares and commits without pre-prepares * Once corresponding pre-prepares are received, prepares and commits are processed * Processing of commits can lead to checkpoint stabilization * During checkpoint stabilization we call GC and remove this PrePrepare * The code was written in a way, that after removing this PrePrepare the Commit is stashed again since its doesn't have a PrePrepare.  *Fix:* * The code processing stashed prepare/commits because of missing PrePrepares was calling process methods directly, that is our in-one-place validation (ReplicaValidator) wasn't called. * This is fixed so that we always call validation first, so that Commits are not stashed again, but discarded as already ordered.  *PR:* *  https://github.com/hyperledger/indy-plenum/pull/1057 ** * **  *Version:* * indy-node 1.6.761  ></body> </Action>
<Action id="56111" issue="36825" author="derashe" type="comment" created="2019-01-23 16:30:44.0" updateauthor="derashe" updated="2019-01-23 16:30:44.0"> <body><! CDATA h2. Case 2: h3. Research result: * Node2 had a connection problem form a very beginning !2_node.PNG|thumbnail! . Noticeable things there:  ** node's request queue more that finalized request queue. That means, that this node did not get enought propagates. ** avg_node_stack_messages_processed is on it's maximum - 100 requests.  ** looper run time values higher that on other nodes * These problems led Node2 to slowed ordering. * Node2 was primary for 1 instance, since view_no was 0, and so, ordering on 1 instance for all nodes was slowed.  * That caused requests to delay on every node. And this called OOM exception on some nodes. !image-2019-01-23-19-31-40-410.png|thumbnail! * At some time few view_changes happened, so lagged node were not primary anymore. * The nodes, that did not yet go down, continued ordering successfully !image-2019-01-23-19-34-22-909.png|thumbnail!  ></body> </Action>
<Action id="56245" issue="36825" author="ashcherbakov" type="comment" created="2019-01-28 07:58:18.0" updateauthor="ashcherbakov" updated="2019-01-28 07:58:18.0"> <body><! CDATA Since the initial issue if fixed, this ticket can be closed.  The issues found in cases 2 and 3 look like the new ones. They will be addressed in the scope of INDY-1965.  ></body> </Action>
