<Action id="54063" issue="35241" author="sergey-shilov" type="comment" created="2018-11-30 09:46:05.0" updateauthor="sergey-shilov" updated="2018-11-30 09:46:05.0"> <body><! CDATA The list of proposed tests:  * Drop request on propagate phase (primary and non-primary): ** Propagate is sent ** Propagates from other nodes are delayed more than drop time out ** Request is dropped before finalization ** Then Propagates are received ** Request should be ordered  * Drop finalized request before Pre-Prepare (non-primary only): ** Request is finalized ** Pre-Prepare from primary is delayed more than drop time out ** Request is dropped ** Then Pre-Prepare, Prepares and Commits are received ** Request should be ordered  * Drop finalized request before Prepares and Commits received (primary and non-primary): ** Request is finalized, Pre-Prepare: *** is sent (primary) *** is received (non-primary) ** Prepares and Commits from other nodes are delayed more than drop time out ** Request is dropped ** Then Prepares and Commits are received ** Request should be ordered  * Drop finalized request before Commits received (primary and non-primary): ** Request is finalized, Pre-Prepare: *** is sent (primary) *** is received (non-primary) ** Prepares are received ** Commits from other nodes are delayed more than drop time out ** Request is dropped ** Then Commits are received ** Request should be ordered   ></body> </Action>
<Action id="54357" issue="35241" author="sergey-shilov" type="comment" created="2018-12-05 08:25:45.0" updateauthor="sergey-shilov" updated="2018-12-05 08:26:12.0"> <body><! CDATA The list of currently implemented tests: * Drop request on propagate phase (primary and non-primary) * Drop finalized request before Prepares and Commits received (primary and non-primary) * Drop finalized request before Commits received (primary and non-primary)  PR: https://github.com/hyperledger/indy-plenum/pull/984  ></body> </Action>
<Action id="54375" issue="35241" author="sergey-shilov" type="comment" created="2018-12-05 13:36:50.0" updateauthor="sergey-shilov" updated="2018-12-05 13:36:50.0"> <body><! CDATA *Problem state / reason:*  For now there is a memory leak in propagator's requests queue in case of requests that are not committed for a very long time. We need a mechanism to drop such requests.  *Changes:*  Two new time outs were added: 1) A time out for propagate phase (i.e. before request is finalised) 2) A time out for ordering phase (i.e. after request is finalised)  The first time out starts when the request is added to the propagator's requests queue. When request is finalised (i.e. quorum of propagates is reached) the second time out starts and the first time out is not used further. Request is dropped from the requests queue if one of these time outs exceeded.  This is a kind of a sanity check, not a regular action. Proposed time outs are very high (10 hours for propagates phase and 20 hours for ordering phase) so we do not expect dropping of requests from the propagate's requests queue on a regular basis.  *Committed into:*  https://github.com/hyperledger/indy-plenum/pull/984 https://github.com/hyperledger/indy-node/pull/1078 indy-node 1.6.717-master  *Risk factors:*  Unstable behaviour of the node if requests are dropped.  *Risk:*  Medium  *Recommendations for QA:*  Firstly, enable this strategy by setting in the indy config file: _OUTDATED_REQS_CHECK_ENABLED = True_ _OUTDATED_REQS_CHECK_INTERVAL = 10_  The run acceptance mix twice: * the first run with parameters: ** PROPAGATES_PHASE_REQ_TIMEOUT = 60  # seconds ** ORDERING_PHASE_REQ_TIMEOUT = 72000  # seconds * the second run with parameters: ** PROPAGATES_PHASE_REQ_TIMEOUT = 36000  # seconds ** ORDERING_PHASE_REQ_TIMEOUT = 120  # seconds   ></body> </Action>
<Action id="54432" issue="35241" author="vladimirwork" type="comment" created="2018-12-06 11:43:16.0" updateauthor="vladimirwork" updated="2018-12-06 13:20:30.0"> <body><! CDATA Build Info: indy-node 1.6.718  Steps to Reproduce: 1. Run production load without fees with this parameters: {noformat} OUTDATED_REQS_CHECK_ENABLED = True OUTDATED_REQS_CHECK_INTERVAL = 10 PROPAGATES_PHASE_REQ_TIMEOUT = 60 # seconds ORDERING_PHASE_REQ_TIMEOUT = 72000 # seconds {noformat} 2. Check client output/logs/metrics.  Actual Results: Writing client has the next stats: {code:java}Time 55390.65 Clients 0/10 Sent: 547931 Succ: 416561 Failed: 128300 Nacked: 3070 Rejected: 0{code} Pool has stopped ordering txns and some less than f nodes have View 1 (i.e. 1st node). Metrics from 1st, 15th and 25th nodes: !1836_1node_1case.png|thumbnail!  !1836_15node_1case.png|thumbnail!  !1836_25node_1case.png|thumbnail!   All nodes' logs\validator-info\detailed client output are in ev@evernymr33:logs/1836_1case.tar.gz and ev@evernymr33:logs/1836_1case_writing_client_data.tar.gz   ></body> </Action>
<Action id="54491" issue="35241" author="sergey-shilov" type="comment" created="2018-12-07 12:18:29.0" updateauthor="sergey-shilov" updated="2018-12-07 12:18:29.0"> <body><! CDATA New indy-node master build: *1.6.725-master*  Please run tests described in https://jira.hyperledger.org/browse/INDY-1836?focusedCommentId=54375&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-54375  ></body> </Action>
<Action id="54555" issue="35241" author="vladimirwork" type="comment" created="2018-12-10 10:15:50.0" updateauthor="vladimirwork" updated="2018-12-10 10:15:50.0"> <body><! CDATA Build Info: indy-node 1.6.725  Steps to Reproduce: 1. Run production load without fees with this parameters: {noformat} OUTDATED_REQS_CHECK_ENABLED = True OUTDATED_REQS_CHECK_INTERVAL = 10 PROPAGATES_PHASE_REQ_TIMEOUT = 60 # seconds ORDERING_PHASE_REQ_TIMEOUT = 72000 # seconds {noformat} 2. Check client output/logs/metrics.  Actual Results: Pool has stopped ordering txns at ~219k domain txns written.  !INDY-1836_1.PNG|thumbnail!  !INDY-1836_25.PNG|thumbnail!   All logs and metrics are in ev@evernymr33:logs/1836_08_12_2018.tar.gz and ev@evernymr33:logs/1836_08_12_2018_metrics.tar.gz  ></body> </Action>
<Action id="54651" issue="35241" author="vladimirwork" type="comment" created="2018-12-11 10:17:11.0" updateauthor="vladimirwork" updated="2018-12-11 10:17:11.0"> <body><! CDATA Build Info: indy-node 1.6.725  Steps to Reproduce: 1. Run production load without fees with this parameters: {noformat} OUTDATED_REQS_CHECK_ENABLED = True OUTDATED_REQS_CHECK_INTERVAL = 10 PROPAGATES_PHASE_REQ_TIMEOUT = 36000 # seconds ORDERING_PHASE_REQ_TIMEOUT = 120 # seconds {noformat} 2. Check client output/logs/metrics.  Actual Results: Pool has written ~200k domain txns sucessfully and has continued ordering until load test stopping. !INDY-1836_1_2nd.PNG|thumbnail!  !INDY-1836_25_2nd.PNG|thumbnail!   All logs and metrics are in ev@evernymr33:logs/1836_11_12_2018.tar.gz and ev@evernymr33:logs/1836_11_12_2018_metrics.tar.gz  ></body> </Action>
<Action id="54722" issue="35241" author="sergey-shilov" type="comment" created="2018-12-12 15:08:01.0" updateauthor="sergey-shilov" updated="2018-12-12 15:51:12.0"> <body><! CDATA Seems like we need to re-test the first run. Our persistent pool works faster than we thought and no one time out on propagate phase occurred during normal work. After several working hours all nodes went out of disk space and then time outs started triggering while the pool was inoperable. So we need to reduce propagates phase time out and solve disk space problem before test run. !INDY-1836_1.png|thumbnail!  !INDY-1836_25.png|thumbnail!   Proposed parameters:  OUTDATED_REQS_CHECK_ENABLED = True OUTDATED_REQS_CHECK_INTERVAL = 10 PROPAGATES_PHASE_REQ_TIMEOUT = 5 # seconds ORDERING_PHASE_REQ_TIMEOUT = 72000 # seconds  ></body> </Action>
<Action id="54776" issue="35241" author="sergey-shilov" type="comment" created="2018-12-13 14:56:57.0" updateauthor="sergey-shilov" updated="2018-12-13 14:58:59.0"> <body><! CDATA Seems like we need to re-test the second run too, no one ordering time out occurred during normal work, the pool works pretty fast! We see time outs at the end of the test run, but they happen due to started view change by "Primary disconnected" reason. Primary was disconnected as it could not bind its' listener as address was already in use when it tried to restart the client stack. Client stack restart was triggered on all nodes due to unexpected spike in clients connections, but four nodes (including primary) could not bind their listeners in 1 second. !INDY-1836_1.png|thumbnail! !INDY-1836_25.png|thumbnail!  So there are two action items here: # Increase interval between bind re-tries to 1 second to have 5 seconds overall for trying to bind # Increase primary disconnected time out (2 seconds is very short time out for production network)  Proposed parameters:  OUTDATED_REQS_CHECK_ENABLED = True OUTDATED_REQS_CHECK_INTERVAL = 10 PROPAGATES_PHASE_REQ_TIMEOUT = 36000 # seconds ORDERING_PHASE_REQ_TIMEOUT = 7 # seconds  ></body> </Action>
<Action id="54798" issue="35241" author="vladimirwork" type="comment" created="2018-12-14 09:05:34.0" updateauthor="vladimirwork" updated="2018-12-14 09:05:34.0"> <body><! CDATA Steps to Reproduce: 1. Run production load without fees with this parameters: {noformat} OUTDATED_REQS_CHECK_ENABLED = True OUTDATED_REQS_CHECK_INTERVAL = 10 PROPAGATES_PHASE_REQ_TIMEOUT = 5 # seconds ORDERING_PHASE_REQ_TIMEOUT = 72000 # seconds {noformat} 2. Check client output/logs/metrics.  Actual Results: Pool has written 100k+ domain txns sucessfully and has continued ordering until load test stopping.  !INDY-1836_1_3rd.PNG|thumbnail!  !INDY-1836_25_3rd.PNG|thumbnail!   All logs and metrics are in ev@evernymr33:logs/1836_13_12_2018.tar.gz and ev@evernymr33:logs/1836_13_12_2018_metrics.tar.gz  ></body> </Action>
<Action id="54799" issue="35241" author="sergey-shilov" type="comment" created="2018-12-14 09:42:16.0" updateauthor="sergey-shilov" updated="2018-12-14 09:52:58.0"> <body><! CDATA We need to do the following test: emulation of stopped ordering replica.  Test parameters:  OUTDATED_REQS_CHECK_ENABLED = True OUTDATED_REQS_CHECK_INTERVAL = 2 PROPAGATES_PHASE_REQ_TIMEOUT = 3 ORDERING_PHASE_REQ_TIMEOUT = 120 REPLICAS_REMOVING_WITH_DEGRADATION = None REPLICAS_REMOVING_WITH_PRIMARY_DISCONNECTED = None  Before load is started it is needed to stop some non-master primary (for example, Node3) and leave it stopped during whole test.   ></body> </Action>
<Action id="54817" issue="35241" author="vladimirwork" type="comment" body="Logs and metrics from the last run described above are in ev@evernymr33:logs/1836_14_12_2018.tar.gz and ev@evernymr33:logs/1836_14_12_2018_metrics.tar.gz" created="2018-12-14 15:52:44.0" updateauthor="vladimirwork" updated="2018-12-14 15:52:44.0"/>
<Action id="54920" issue="35241" author="sergey-shilov" type="comment" created="2018-12-18 13:11:27.0" updateauthor="sergey-shilov" updated="2018-12-18 13:11:27.0"> <body><! CDATA Please re-test the case described in  https://jira.hyperledger.org/browse/INDY-1836?focusedCommentId=54799&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-54799  with a new indy-node 1.6.738-master.  ></body> </Action>
<Action id="54960" issue="35241" author="ozheregelya" type="comment" created="2018-12-19 12:14:21.0" updateauthor="ozheregelya" updated="2018-12-19 12:25:13.0"> <body><! CDATA Retested with indy-node 1.6.738. Pool stopped writing after ~12 hours of load. !prod1836node13_18_12_2018.png|thumbnail!  Logs and metrics: s3://qanodelogs/indy-1836/prod_load_18_12_2018 To get logs, run following command on log processor machine:  aws s3 cp --recursive s3://qanodelogs/indy-1836/prod_load_18_12_2018/ /home/ev/logs/indy-1836/prod_load_18_12_2018/  UPD: Node3 was not stopped before load by mistake.  ></body> </Action>
<Action id="55008" issue="35241" author="ozheregelya" type="comment" created="2018-12-19 23:14:10.0" updateauthor="ozheregelya" updated="2018-12-20 18:46:55.0"> <body><! CDATA Logs for correct test (without metrics and validator-info history): s3://qanodelogs/indy-1836/logs-only-19-12-2018  Logs for second run (with metrics and validator-info): s3://qanodelogs/indy-1836/logs-and-metrics-20-12-2018  ></body> </Action>
<Action id="55131" issue="35241" author="sergey-shilov" type="comment" created="2018-12-25 12:00:06.0" updateauthor="sergey-shilov" updated="2018-12-25 12:00:06.0"> <body><! CDATA Please re-test the case described in  https://jira.hyperledger.org/browse/INDY-1836?focusedCommentId=54799&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-54799  with a new indy-node 1.6.745-master.   ></body> </Action>
<Action id="55136" issue="35241" author="zhigunenko.dsr" type="comment" created="2018-12-26 06:58:39.0" updateauthor="zhigunenko.dsr" updated="2018-12-26 06:58:39.0"> <body><! CDATA Logs and metrics for 1.6.745 are available here: /home/ev/logs/INDY-1836/1836_25_12_2018    Node3 was stopped during test  ></body> </Action>
<Action id="55152" issue="35241" author="sergey-shilov" type="comment" created="2018-12-27 12:04:21.0" updateauthor="sergey-shilov" updated="2018-12-27 12:04:21.0"> <body><! CDATA Please re-test the case described in  https://jira.hyperledger.org/browse/INDY-1836?focusedCommentId=54799&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-54799  with a new indy-node 1.6.747-master.   ></body> </Action>
<Action id="55161" issue="35241" author="ozheregelya" type="comment" created="2018-12-28 10:57:48.0" updateauthor="ozheregelya" updated="2018-12-28 13:31:23.0"> <body><! CDATA Logs and metrics sources for 1.6.747: s3://qanodelogs/indy-1836/prod_load_28_12_2018  Metrics .csv files: s3://qanodelogs/indy-1836/prod_load_28_12_2018/metrics_csv  Note that in this test writing load was started not from the beginning test (it's caused by load script issue), so, first it was reading load only during several hours.  At the end of the test pool stopped writing. Following nodes were lagged during test: persistent_node16 6697 persistent_node10 11140 persistent_node23 26379 persistent_node1 16119 persistent_node19 31722 persistent_node7 15672 the rest nodes have 33520 domain txns.  ></body> </Action>
<Action id="55547" issue="35241" author="vladimirwork" type="comment" created="2019-01-11 16:31:14.0" updateauthor="vladimirwork" updated="2019-01-11 16:31:14.0"> <body><! CDATA Build Info: indy-node 1.6.752  Steps to Reproduce: 0. Set the next parameters in config file: {noformat} OUTDATED_REQS_CHECK_INTERVAL = 120  # seconds PROPAGATES_PHASE_REQ_TIMEOUT = 300  # seconds ORDERING_PHASE_REQ_TIMEOUT = 600 # seconds REPLICAS_REMOVING_WITH_DEGRADATION = None REPLICAS_REMOVING_WITH_PRIMARY_DISCONNECTED = None GC_STATS_REPORT_INTERVAL=300 {noformat} 1.  17:30  Run production load without fees (10 writes and ~30 reads per seconds since I fell into an issue with `too many files opened` error). 2.  17:45  Stop 3rd node (primary of the 2nd instance). 3.  19:00  Stop the load.  Actual Results: All nodes except stopped one have the same amount of txns in domain and sovtoken ledgers. All journals\logs\metrics are sent to  ~anikitinDSR .  ></body> </Action>
<Action id="55569" issue="35241" author="anikitindsr" type="comment" created="2019-01-12 11:00:59.0" updateauthor="anikitindsr" updated="2019-01-12 11:01:36.0"> <body><! CDATA After logs and metrics analyzing from the last load_test launching we got the next results:  !node1.png|thumbnail!    !node15.png|thumbnail!  As we can see on "Request queues" we have increased count of unordered request because of stopped 3rd node (primary of the 2nd instance). But this queue does not raise extremely and "Clear Request Queue strategy" periodically delete requests from queue.  ></body> </Action>
