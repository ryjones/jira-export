<Action id="61987" issue="41321" author="esplinr" type="comment" body=" ~lbendixsen  Can you please include the log file?" created="2019-07-19 14:55:02.0" updateauthor="esplinr" updated="2019-07-19 14:55:02.0"/>
<Action id="63648" issue="41321" author="donqui" type="comment" created="2019-09-10 09:38:52.0" updateauthor="donqui" updated="2019-09-10 09:38:52.0"> <body><! CDATA  ~lbendixsen  Could you please provide me with a scenario or a series of steps that led to this behavior I am having trouble reproducing it?     ></body> </Action>
<Action id="63683" issue="41321" author="lbendixsen" type="comment" created="2019-09-11 17:43:51.0" updateauthor="lbendixsen" updated="2019-09-11 17:43:51.0"> <body><! CDATA I am sorry, but I do not know what causes the issue to occur besides my guesses in the original description (1. removing nodes from the pool, perhaps nodes that are in the genesis file, 2. Changing the ips/ports of nodes, 3. Changing the Steward nym after addition of a node and then re-adding the node with a new Steward DID).  I might be able to provide more hints/guesses if I knew what these specific rid's were referencing.  How do I figure that out?  It is happening on at least the BuilderNet and the StagingNet at this point.  Here is an excerpt that I got just now from tailing the log file on a StagingNet server (Sovrin)  2019-09-11 17:26:15,991|WARNING|batched.py|CONNECTION: SovrinNode has removed rid BHXePWAv2F3fhXtwgjmkzAJtCM1XVB7ZDfypEkpN7uNd  2019-09-11 17:26:25,055|WARNING|batched.py|CONNECTION: SovrinNode has removed rid 6Rw6fxUtoVdCgVs4VSawFYF4Kix8nCHFXWk8EALTDkc5  2019-09-11 17:26:31,201|WARNING|batched.py|CONNECTION: SovrinNode has removed rid BHXePWAv2F3fhXtwgjmkzAJtCM1XVB7ZDfypEkpN7uNd  2019-09-11 17:26:40,286|WARNING|batched.py|CONNECTION: SovrinNode has removed rid 6Rw6fxUtoVdCgVs4VSawFYF4Kix8nCHFXWk8EALTDkc5  2019-09-11 17:26:46,012|WARNING|batched.py|CONNECTION: SovrinNode has removed rid BHXePWAv2F3fhXtwgjmkzAJtCM1XVB7ZDfypEkpN7uNd  2019-09-11 17:26:46,643|INFO|seeder_service.py|SovrinNode received ledger status: LEDGER_STATUS\{'protocolVersion': 2, 'merkleRoot': '7z1u3Rh6hydSbzi9P2C1e4LJ4bCermGr1HQ1b5s81xW8', 'ledgerId': 0, 'viewNo': None, 'ppSeqNo': None, 'txnSeqNo': 127} from b'iBcy&1eE@/biSqz1j54m>{4t?p**aR@zhp{)7vTK'  2019-09-11 17:26:46,644|INFO|seeder_service.py|SovrinNode sending consistency proof: CONSISTENCY_PROOF\{'seqNoStart': 127, 'hashes':  '7z3ZWXDTYXJd7hkHfMxw9MHjFBfMkWTWrNCphv4n1k3X', 'tQJyoXbJnjg4FyKqZXdCqdUUhqGFK7jwSimQ426FXLy', 'EBFt7oCpPzmGgbqathUZJRfYC7zn8ZDNXSSFpcCnTdfS', '6idJSG7xjjFqTeFCn6yaRhq4gSuvrV1ZZaNYY7F7H8J', '7fr4JQXUCVTtcrD2jSDXKjvyMYTzaiw52xTH4Cgdpc95', '2oycntybkivHAVXDMZPNazgsJnhaGMU2hvBbbMCEf8tz', 'Fbq95zj8GWZMqdTWab7BQd9qpkKkFaCzdv1kdzHuDJrt', '6v5B5z6RTtvJrMh1J5q6UxrLfQYd6XuDFZBQExXwPVsu', 'BkxxHCQXgw8F5XkXvhjkwVDZ9FguzMwSt57vRmjrTB7L' , 'ledgerId': 0, 'viewNo': 0, 'ppSeqNo': 0, 'newMerkleRoot': 'EVf6FCk1W6gNNqW9jtg8X37LnGxuUWoDgsyrzt3Luf8C', 'oldMerkleRoot': '7z1u3Rh6hydSbzi9P2C1e4LJ4bCermGr1HQ1b5s81xW8', 'seqNoEnd': 138} to b'iBcy&1eE@/biSqz1j54m>{4t?p**aR@zhp{)7vTK'  2019-09-11 17:26:55,078|WARNING|batched.py|CONNECTION: SovrinNode has removed rid 6Rw6fxUtoVdCgVs4VSawFYF4Kix8nCHFXWk8EALTDkc5  2019-09-11 17:27:01,217|WARNING|batched.py|CONNECTION: SovrinNode has removed rid BHXePWAv2F3fhXtwgjmkzAJtCM1XVB7ZDfypEkpN7uNd  ></body> </Action>
<Action id="63902" issue="41321" author="donqui" type="comment" created="2019-09-20 11:55:38.0" updateauthor="donqui" updated="2019-09-20 12:05:04.0"> <body><! CDATA Problem reason/description: - too many logs about removed RIDs that do not get cleared once the cause is resolved  Changes: - log level changed from WARNING to INFO as the logs are useful for debugging and the issues described in the ticket could not be reproduced  PR: -  https://github.com/hyperledger/indy-plenum/pull/1340   Version: - plenum: 1.10.0.dev902 - node: 1.10.0.dev1087 - sov: sovtoken_1.0.3~dev97 sovtokenfees_1.0.3~dev97  Risk: - Low  Recommendations for QA - Start a pool with 4 nodes - demote node4 - restart indy-node service on Node4 - logs should start appearing with INFO level - promote Node4 - logs should stop  ></body> </Action>
<Action id="63920" issue="41321" author="lbendixsen" type="comment" created="2019-09-20 15:58:15.0" updateauthor="lbendixsen" updated="2019-09-20 15:58:15.0"> <body><! CDATA Changing the log level is an unacceptable solution to this issue.  I did not enter the ticket because I wanted fewer lines in my log file.  I entered the ticket because I thought that there is an underlying issue where RID are repeated being removed (or at least attempted according to the message) and that seems like at least a waste of cycles and at most an indication that something isn't working as expected.  I am not sure why this is difficult to reproduce, so please help me understand what else you need.  I did a reset of the buildernet over the last few weeks (meaning we completely removed the data directory with all of the ledgers and started over with the genesis files) and the issue started up within a few seconds of me adding my node in to the pool.  danube was the first node connected to the pool, and mine (FoundationBuilder) was the second, and we had to wait a few days for the other 2 genesis nodes(vnode1 and xsvalidatorec2irl) to add themselves in to the initial pool.  Here is an excerpt showing the few seconds difference between starting up and seeing the rid message and I will also attach the whole log.    {{2019-09-03 17:12:58,224|NOTIFICATION|looper.py|Looper shut down in 0.010 seconds.}}{{2019-09-11 22:54:45,499|INFO|looper.py|Starting up indy-node}}{{2019-09-11 22:54:45,603|INFO|ledger.py|Starting ledger...}}{{2019-09-11 22:54:45,616|INFO|ledger.py|Recovering tree from transaction log}}{{2019-09-11 22:54:45,644|INFO|ledger.py|Recovered tree in 0.027606574818491936 seconds}}{{2019-09-11 22:54:45,684|INFO|ledger.py|Starting ledger...}}{{2019-09-11 22:54:45,697|INFO|ledger.py|Recovering tree from transaction log}}{{2019-09-11 22:54:45,725|INFO|ledger.py|Recovered tree in 0.02819257229566574 seconds}}{{2019-09-11 22:54:45,770|INFO|ledger.py|Starting ledger...}}{{2019-09-11 22:54:45,783|INFO|ledger.py|Recovering tree from transaction log}}{{2019-09-11 22:54:45,810|INFO|ledger.py|Recovered tree in 0.027425142005085945 seconds}}{{2019-09-11 22:54:45,856|INFO|ledger.py|Starting ledger...}}{{2019-09-11 22:54:45,869|INFO|ledger.py|Recovering tree from transaction log}}{{2019-09-11 22:54:45,897|INFO|ledger.py|Recovered tree in 0.028343386948108673 seconds}}{{2019-09-11 22:54:45,995|NOTIFICATION|node_bootstrap.py|BLS: BLS Signatures will be used for Node FoundationBuilder}}{{2019-09-11 22:54:45,995|INFO|pool_manager.py|FoundationBuilder sets node FoundationBuilder (GVvdyd7Y6hsBEy5yDDHjqkXgH8zW34K74RsxUiUCZDCE) order to 17}}{{2019-09-11 22:54:45,995|INFO|pool_manager.py|FoundationBuilder sets node vnode1 (9Aj2LjQ2fwszJRSdZqg53q5e6ayScmtpeZyPGgKDswT8) order to 6}}{{2019-09-11 22:54:45,995|INFO|pool_manager.py|FoundationBuilder sets node xsvalidatorec2irl (DXn8PUYKZZkq8gC7CZ2PqwECzUs2bpxYiA5TWgoYARa7) order to 17}}{{2019-09-11 22:54:45,995|INFO|pool_manager.py|FoundationBuilder sets node danube (52muwfE7EjTGDKxiQCYWr58D8BcrgyKVjhHgRQdaLiMw) order to 6}}{{2019-09-11 22:54:46,024|INFO|notifier_plugin_manager.py|Found notifier plugins:   }}{{2019-09-11 22:54:46,049|INFO|notifier_plugin_manager.py|Found notifier plugins:   }}{{2019-09-11 22:54:46,049|INFO|node_bootstrap.py|<indy_node.server.node_bootstrap.NodeBootstrap object at 0x7fa572b5e710> found state to be empty, recreating from ledger}}{{2019-09-11 22:54:46,052|INFO|node_bootstrap.py|<indy_node.server.node_bootstrap.NodeBootstrap object at 0x7fa572b5e710> initialized pool state: state root 2VNAcq8b6Bg7ePF4FBRUe6duUBytP35eYduGzSyMwFuz}}{{2019-09-11 22:54:46,052|INFO|node_bootstrap.py|<indy_node.server.node_bootstrap.NodeBootstrap object at 0x7fa572b5e710> found state to be empty, recreating from ledger}}{{2019-09-11 22:54:46,052|INFO|node_bootstrap.py|<indy_node.server.node_bootstrap.NodeBootstrap object at 0x7fa572b5e710> initialized config state: state root DfNLmH4DAHTKv63YPFJzuRdeEtVwF5RtVnvKYHd8iLEA}}{{2019-09-11 22:54:46,052|INFO|node_bootstrap.py|<indy_node.server.node_bootstrap.NodeBootstrap object at 0x7fa572b5e710> found state to be empty, recreating from ledger}}{{2019-09-11 22:54:46,059|INFO|node_bootstrap.py|<indy_node.server.node_bootstrap.NodeBootstrap object at 0x7fa572b5e710> initialized domain state: state root 4RbC2qVepj1kn2jdmvemxtwpYKfrsA9XowGGAUs7m79Y}}{{2019-09-11 22:54:46,061|INFO|stacks.py|FoundationBuilderC: clients connections tracking is enabled.}}{{2019-09-11 22:54:46,061|INFO|stacks.py|FoundationBuilderC: client stack restart is enabled.}}{{2019-09-11 22:54:46,062|INFO|node.py|FoundationBuilder updated its pool parameters: f 1, totalNodes 4, allNodeNames \{'FoundationBuilder', 'danube', 'xsvalidatorec2irl', 'vnode1'}, requiredNumberOfInstances 2, minimumNodes 3, quorums \{'view_change_ack': Quorum(2), 'prepare': Quorum(2), 'checkpoint': Quorum(2), 'commit': Quorum(3), 'backup_instance_faulty': Quorum(2), 'n': 4, 'strong': Quorum(3), 'view_change': Quorum(3), 'reply': Quorum(2), 'weak': Quorum(2), 'ledger_status': Quorum(2), 'f': 1, 'election': Quorum(3), 'ledger_status_last_3PC': Quorum(2), 'observer_data': Quorum(2), 'timestamp': Quorum(2), 'same_consistency_proof': Quorum(2), 'consistency_proof': Quorum(2), 'view_change_done': Quorum(3), 'bls_signatures': Quorum(3), 'propagate': Quorum(2)}}}{{2019-09-11 22:54:46,098|NOTIFICATION|plugin_loader.py|skipping plugin plugin_firebase_stats_consumer class: typing.Dict<~KT, ~VT>  because it does not have a 'pluginType' attribute}}{{2019-09-11 22:54:46,098|NOTIFICATION|plugin_loader.py|skipping plugin plugin_firebase_stats_consumer class: <class 'plenum.server.stats_consumer.StatsConsumer'>  because it does not have a 'pluginType' attribute}}{{2019-09-11 22:54:46,098|NOTIFICATION|plugin_loader.py|skipping plugin plugin_firebase_stats_consumer class: <enum 'Topic'>  because it does not have a 'pluginType' attribute}}{{2019-09-11 22:54:46,098|NOTIFICATION|plugin_loader.py|skipping plugin plugin_firebase_stats_consumer class: <class 'plenum.server.plugin.stats_consumer.stats_publisher.StatsPublisher'>  because it does not have a 'pluginType' attribute}}{{2019-09-11 22:54:46,098|INFO|plugin_loader.py|plugin FirebaseStatsConsumer successfully loaded from module plugin_firebase_stats_consumer}}{{2019-09-11 22:54:46,098|NOTIFICATION|plugin_loader.py|skipping plugin plugin_firebase_stats_consumer class: <class 'plenum.server.plugin_loader.HasDynamicallyImportedModules'>  because it does not have a 'pluginType' attribute}}{{2019-09-11 22:54:46,099|INFO|replica.py|FoundationBuilder:0 set watermarks as 0 300}}{{2019-09-11 22:54:46,099|INFO|replica_stasher.py|FoundationBuilder:0 unstash 0 out of watermarks messages}}{{2019-09-11 22:54:46,100|NOTIFICATION|replicas.py|FoundationBuilder added replica FoundationBuilder:0 to instance 0 (master)}}{{2019-09-11 22:54:46,100|INFO|replicas.py|reset monitor due to replica addition}}{{2019-09-11 22:54:46,100|INFO|replica.py|FoundationBuilder:1 set watermarks as 0 300}}{{2019-09-11 22:54:46,100|INFO|replica_stasher.py|FoundationBuilder:1 unstash 0 out of watermarks messages}}{{2019-09-11 22:54:46,101|NOTIFICATION|replicas.py|FoundationBuilder added replica FoundationBuilder:1 to instance 1 (backup)}}{{2019-09-11 22:54:46,101|INFO|replicas.py|reset monitor due to replica addition}}{{2019-09-11 22:54:46,102|INFO|node.py|total plugins loaded in node: 0}}{{2019-09-11 22:54:46,146|INFO|node_runner.py|Going to integrate plugin: sovtoken}}{{2019-09-11 22:54:46,191|INFO|ledger.py|Starting ledger...}}{{2019-09-11 22:54:46,205|INFO|ledger.py|Recovering tree from transaction log}}{{2019-09-11 22:54:46,232|INFO|ledger.py|Recovered tree in 0.027781154960393906 seconds}}{{2019-09-11 22:54:46,246|INFO|node_runner.py|Integrated plugin: sovtoken}}{{2019-09-11 22:54:46,303|INFO|node_runner.py|Going to integrate plugin: sovtokenfees}}{{2019-09-11 22:54:46,303|INFO|node_runner.py|Integrated plugin: sovtokenfees}}{{2019-09-11 22:54:46,303|INFO|motor.py|FoundationBuilder changing status from stopped to starting}}{{2019-09-11 22:54:46,305|INFO|stacks.py|CONNECTION: FoundationBuilder listening for other nodes at 172.31.35.134:9701}}{{2019-09-11 22:54:46,340|INFO|node.py|FoundationBuilder first time running...}}{{2019-09-11 22:54:46,340|INFO|node.py|FoundationBuilder processed 0 Ordered batches for instance 0 before starting catch up}}{{2019-09-11 22:54:46,340|INFO|node.py|FoundationBuilder processed 0 Ordered batches for instance 1 before starting catch up}}{{2019-09-11 22:54:46,340|INFO|node.py|FoundationBuilder reverted 0 batches before starting catch up}}{{2019-09-11 22:54:46,340|INFO|node_leecher_service.py|FoundationBuilder:NodeLeecherService starting catchup (is_initial=True)}}{{2019-09-11 22:54:46,340|INFO|node_leecher_service.py|FoundationBuilder:NodeLeecherService transitioning from Idle to PreSyncingPool}}{{2019-09-11 22:54:46,340|INFO|cons_proof_service.py|FoundationBuilder:ConsProofService:0 starts}}{{2019-09-11 22:54:46,342|INFO|kit_zstack.py|CONNECTION: FoundationBuilder found the following missing connections: danube, xsvalidatorec2irl, vnode1}}{{2019-09-11 22:54:46,342|INFO|zstack.py|CONNECTION: FoundationBuilder looking for danube at 173.249.14.196:9701}}{{2019-09-11 22:54:46,344|INFO|zstack.py|CONNECTION: FoundationBuilder looking for xsvalidatorec2irl at 52.209.6.196:9701}}{{2019-09-11 22:54:46,345|INFO|zstack.py|CONNECTION: FoundationBuilder looking for vnode1 at 206.189.143.34:9797}}{{2019-09-11 22:54:46,729|WARNING|batched.py|CONNECTION: FoundationBuilder has removed rid HsD7niKXgMFxckXNeSE1Np8cfgMDs8aHpYxSWWBA4BDp}}{{2019-09-11 22:54:46,762|WARNING|batched.py|CONNECTION: FoundationBuilder has removed rid 4gauyZ56Y4WsbFEtzDEU2uAwrBRs95iKrMLoQjFNkst1}}{{2019-09-11 22:54:47,401|WARNING|batched.py|CONNECTION: FoundationBuilder has removed rid DacmhXMW9xYRCy6R3fAj54iCKCD8BdJnwyMGgt329cdy}}  ></body> </Action>
<Action id="63937" issue="41321" author="esplinr" type="comment" body="It&apos;s useful to know that you are seeing this on the reset Builder Net. We&apos;ll discuss it again as a team." created="2019-09-20 22:32:38.0" updateauthor="esplinr" updated="2019-09-20 22:32:38.0"/>
<Action id="64369" issue="41321" author="donqui" type="comment" created="2019-10-08 13:27:51.0" updateauthor="donqui" updated="2019-10-08 13:56:59.0"> <body><! CDATA    *Findings:*  The error in the logs is a sign that we are receiving messages from a node that was once a part of the network but for some reason it was removed from it. As it was removed we do not communicate to it, don't send announcements or other transactions, but we still allow for it to connect to get the ledger state (catch-up) and check if it has been promoted back.  When a node is demoted it still has a established zmq connection to all other nodes. If a connection to one or more nodes is lost demoted node tries to reconnect but never manages to confirm that the connection is really established. This is because it does not receive pongs for his pings as other nodes do not respond to messages from the demoted nodes. As the demoted node does not receive the pong for it's ping it assumes that it was a network issue and tries to reconnect indefinitely.  Snippets of logs showing this behavior are bellow:     *Node3 (demoted node):* {code:java} $ tail -f /var/log/indy/sandbox/Node3.log 2019-10-08 13:12:44,048|DEBUG|node.py|Node3 sending message MESSAGE_REQUEST{'params': {'ledgerId': 0}, 'msg_type': 'LEDGER_STATUS'} to 2 recipients:  'Node2', 'Node1'  2019-10-08 13:12:44,049|TRACE|batched.py|Node3 sending msg b'{"op":"MESSAGE_REQUEST","params":{"ledgerId":0},"msg_type":"LEDGER_STATUS"}' to Node2 2019-10-08 13:12:44,049|TRACE|zstack.py|Node3 transmitting message b'{"op":"MESSAGE_REQUEST","params":{"ledgerId":0},"msg_type":"LEDGER_STATUS"}' to Node2 by socket 178 46152880 2019-10-08 13:12:44,050|WARNING|zstack.py|Remote Node2 is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings 2019-10-08 13:12:44,050|TRACE|batched.py|Node3 sending msg b'{"op":"MESSAGE_REQUEST","params":{"ledgerId":0},"msg_type":"LEDGER_STATUS"}' to Node1 2019-10-08 13:12:44,050|TRACE|zstack.py|Node3 transmitting message b'{"op":"MESSAGE_REQUEST","params":{"ledgerId":0},"msg_type":"LEDGER_STATUS"}' to Node1 by socket 184 46220592 2019-10-08 13:12:44,050|WARNING|zstack.py|Remote Node1 is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings 2019-10-08 13:12:45,772|DEBUG|kit_zstack.py|Node3 matched remote Node4 HA(host='10.0.0.5', port=9707) 2019-10-08 13:12:45,772|DEBUG|kit_zstack.py|Node3 matched remote Node2 HA(host='10.0.0.3', port=9703) 2019-10-08 13:12:45,772|DEBUG|kit_zstack.py|Node3 matched remote Node1 HA(host='10.0.0.2', port=9701) 2019-10-08 13:12:45,773|DEBUG|zstack.py|Node3 pinged Node2 2019-10-08 13:12:45,773|DEBUG|zstack.py|Node3 pinged Node1 2019-10-08 13:12:45,774|TRACE|kit_zstack.py|Node3 next check for retries in 2.00 seconds 2019-10-08 13:12:45,789|TRACE|batched.py|Node3 sending msg b'pi' to Node2 2019-10-08 13:12:45,789|TRACE|zstack.py|Node3 transmitting message b'pi' to Node2 by socket 178 46152880 2019-10-08 13:12:45,791|TRACE|batched.py|Node3 sending msg b'pi' to Node1 2019-10-08 13:12:45,792|TRACE|zstack.py|Node3 transmitting message b'pi' to Node1 by socket 184 46220592  {code}    *Node1 (participating node):* {code:java} $ tail -f /var/log/indy/sandbox/Node1.log | grep 'removed rid' 2019-10-08 13:10:55,422|WARNING|batched.py|CONNECTION: Node1 has removed rid 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN 2019-10-08 13:10:57,424|WARNING|batched.py|CONNECTION: Node1 has removed rid 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN 2019-10-08 13:10:59,483|WARNING|batched.py|CONNECTION: Node1 has removed rid 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN 2019-10-08 13:11:01,455|WARNING|batched.py|CONNECTION: Node1 has removed rid 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN 2019-10-08 13:11:03,457|WARNING|batched.py|CONNECTION: Node1 has removed rid 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN {code}    *Node2 (participating node):* {code:java} $ tail -f /var/log/indy/sandbox/Node2.log 2019-10-08 13:13:29,949|TRACE|zstack.py|Node2 got ping from 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN 2019-10-08 13:13:29,949|DEBUG|zstack.py|Node2 ponged 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN 2019-10-08 13:13:29,950|WARNING|batched.py|CONNECTION: Node2 has removed rid 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN 2019-10-08 13:13:29,951|DEBUG|message_processor.py|Node2 discarding message deque( b'po' ) because CONNECTION: rid 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN no longer available 2019-10-08 13:13:30,842|TRACE|has_action_queue.py|Node2 running action flush_metrics with id 879 2019-10-08 13:13:30,843|TRACE|has_action_queue.py|Node2 scheduling action flush_metrics with id 882 to run in 10.0 seconds 2019-10-08 13:13:30,843|TRACE|has_action_queue.py|Node2 running action checkPerformance with id 878 2019-10-08 13:13:30,843|TRACE|node.py|Node2 checking its performance 2019-10-08 13:13:30,843|TRACE|node.py|Node2 ordered no new requests 2019-10-08 13:13:30,844|TRACE|has_action_queue.py|Node2 scheduling action checkPerformance with id 883 to run in 10 seconds 2019-10-08 13:13:31,242|DEBUG|kit_zstack.py|Node2 matched remote Node1 HA(host='10.0.0.2', port=9701) 2019-10-08 13:13:31,243|DEBUG|kit_zstack.py|Node2 matched remote Node4 HA(host='10.0.0.5', port=9707) 2019-10-08 13:13:31,243|TRACE|kit_zstack.py|Node2 next check for retries in 2.00 seconds 2019-10-08 13:13:32,007|TRACE|zstack.py|Node2 got 1 messages through listener 2019-10-08 13:13:32,008|TRACE|zstack.py|Node2 got ping from 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN 2019-10-08 13:13:32,008|DEBUG|zstack.py|Node2 ponged 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN 2019-10-08 13:13:32,009|WARNING|batched.py|CONNECTION: Node2 has removed rid 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN 2019-10-08 13:13:32,009|DEBUG|message_processor.py|Node2 discarding message deque( b'po' ) because CONNECTION: rid 6KTs7Q9Lng5uX6oWCkVifiJ6hSpkdHiRijAsXtAunnGN no longer available{code}    *Implications:* # Unnecessary traffic because of constant pings sent by the demoted node in a desperate attempt to reconnect to the lost remote #  CPU cycles spent on handling these messages by the participating nodes # Logs constantly getting filled by lines saying that we got a message from a node that for some reason is no longer participating in the pool     *Potential Solutions:* # Add a config option telling the node that it should not try to connect as it is demoted – would require a manual action on the side of the demoted node. # Allow catch-up but close the connections and stop the communication after that if the status of the node hasn't changed. # Decrease the frequency at which we try to talk to the pool if we are demoted – increase the timeout between requests and shutdown if you don't get a pong. # Change the logic so that the participating nodes connect to the demoted node - demoted node would only listen to incoming messages (push vs pull or a combo of both). # Add a poison pill message that would tell the node to shut down as it is still demoted limiting the number of attempts to 1. Would require moving ping/pong logic up so that we can see if a node is demoted or not, log a meaningful message, and send an appropriate response.  ></body> </Action>
<Action id="64422" issue="41321" author="donqui" type="comment" created="2019-10-09 08:21:05.0" updateauthor="donqui" updated="2019-10-09 08:40:42.0"> <body><! CDATA Closing this ticket and creating a new one for handling the identified issues.  We changed the log level for the error messages so that whoever is running a node can change it and not see the errors in the logs, and another way of solving this would be an update of the firewall rules that would drop any traffic coming from nodes that should not be participating in the network any-more.  ></body> </Action>
