<Action id="63139" issue="41898" author="sergey.khoroshavin" type="comment" created="2019-08-21 14:52:30.0" updateauthor="sergey.khoroshavin" updated="2019-08-21 15:59:28.0"> <body><! CDATA  ~lbendixsen  Changed priority of this issue to Highest since initial analysis of logs showed that "bad" nodes ended up with corrupted state. Unfortunatelly it is not apparent from logs why this happened, so the following is needed: * output of validator info from good and bad nodes (most interesting info is packages versions) * output of journalctl from good and bad nodes from same period as logs * archives with full contents of /var/lib/indy/<network name>/data from one good and one bad node  Also it makes sense to do the following experiment on ONE of bad nodes: * stop indy-node service * delete following directories located in /var/lib/indy/<network name>/data: ** config_state ** domain_state ** pool_state ** sovtoken_state * start indy-node service, this should take some time because node will be restoring deleted state databases * see whether node managed to enter into consensus or not   ></body> </Action>
<Action id="63150" issue="41898" author="sergey.khoroshavin" type="comment" created="2019-08-21 17:00:20.0" updateauthor="sergey.khoroshavin" updated="2019-08-21 17:06:33.0"> <body><! CDATA It seems like issue happened due to accidental change in state application of AUTH_RULE transaction between 1.9.0 and 1.9.1 versions. This means that if AUTH_RULEs were written to network running indy-node 1.9.0 then after upgrade to 1.9.1 newly added nodes will fall out of consensus as soon as they get requests that require writes to config ledger. Most probably proper solution is to write *migration that recreates state databases and patches audit ledger contents*. Mechanism of failure is following: * suppose we have pool running 1.9.0 * writing AUTH_RULE appends it to config ledger and applies some changeset X to config state * also config state root hash H is added to audit ledger * after upgrading pool to 1.9.1 neither config state nor audit ledger is changed * if we add new node it will start catching up ledgers * so it catches up that AUTH_RULE transaction, appends it to config ledger and applies changeset X' to config state * however audit ledger is caught up as is, so it is same as on all other pool * X' is different from X because application of AUTH_RULE to state is different in 1.9.0 and 1.9.1 * no errors show up because after catch up only ledger root hashes are checked, not state root hashes * as soon as write request to config ledger is issued it will try to apply new changeset Y to config state and communicate it between nodes, however new state root hashes will be different on old and new nodes since result of application (X, Y) is different from (X', Y), and new node falls out of consensus  It is possible to resort to simple solution and just recreate state databases on all old nodes, however this will leave audit ledger unchanged and external audit will show that new state doesn't contain some of state root hashes present in audit ledger.  Also I need to note that only newly added nodes are affected by this problem, old nodes will remain in consensus.  ></body> </Action>
<Action id="63159" issue="41898" author="esplinr" type="comment" body="Thank you  ~sergey.khoroshavin  for looking into this. We need to preserve the ability to audit ledger history, so it sounds like a migration of the audit ledger back to a consistent state is necessary. The August release can be delayed to fix this if necessary." created="2019-08-21 20:43:56.0" updateauthor="esplinr" updated="2019-08-21 20:43:56.0"/>
<Action id="63169" issue="41898" author="ashcherbakov" type="comment" created="2019-08-22 07:06:51.0" updateauthor="ashcherbakov" updated="2019-08-22 08:57:42.0"> <body><! CDATA  ~lbendixsen   ~sergey.khoroshavin   ~esplinr  The next steps and fixes depend on the content on config ledgers on Builder, Staging and Main Nets, and, in particular, the time when AUTH_RULE transactions have been written. So, we still need the ledgers and states from at least one node.  I suggest to do the following now: # Do not write any AUTH_RULE transactions to any nets until the fix is applied # Do not add any Nodes to any nets until the fox is applied # For the Nets with no AUTH_RULE txns written after 1.9.1: ** Do a fix to not write OFF_LEDGER_SIGNATURE  if it's not explicitly set ** Issue a hotfix release ** Clean up all ledgers and state on Builder Nodes added after 1.9.1 release and stop the nodes (or demote to have enough nodes for consensus). ** Apply the hotfix to all Nets ASAP ** This will prevent the issue from possible happening on Staging and Main Nets, as well as fix the nodes on Builder Nets (they will catchup properly after update) # For the Nets with AUTH_RULE txns written after 1.9.1 but where the audit history is not so critical (Builder Net?) ** Do the same as in Step 3 ** Cleanup config state on all Nodes in the Net # For the Nets with AUTH_RULE txns written after 1.9.1 but where the audit history is  critical (Staging and Main Net?) ** Do the same as in Step 3 ** Create a migration script: *** Cleanup the config state *** Cleanup config ledger merklee tree (it will be automatically recreated from txn log after restart) *** Go through the audit ledger; on every config ledger batch apply the corresponding number of config ledger transactions to the config state; modify config state in audit transaction is it's not equal to the existing one. *** Modify audit ledger to point to correct config ledger state ** The upgrade needs to be forced for these nets to apply the migration script  Please note that if we clear config state, then already added state proofs will not work for config transactions (for example TAA).  ></body> </Action>
<Action id="63173" issue="41898" author="ashcherbakov" type="comment" body="The issue may also affect our next release. See the options in https://jira.hyperledger.org/browse/INDY-2204" created="2019-08-22 08:39:53.0" updateauthor="ashcherbakov" updated="2019-08-22 08:39:53.0"/>
<Action id="63174" issue="41898" author="sergey.khoroshavin" type="comment" created="2019-08-22 08:54:42.0" updateauthor="sergey.khoroshavin" updated="2019-08-22 08:54:42.0"> <body><! CDATA  ~lbendixsen  I'd like to second Alex request to send contents of ledgers from one of correct nodes from each of Builder, Staging and Main Net. This data is located in */var/lib/indy/<network name>/data*  ></body> </Action>
<Action id="63191" issue="41898" author="mgbailey" type="comment" body=" ~sergey.khoroshavin  Do you need MainNet ledger data, if no new nodes have been added to it?" created="2019-08-22 14:52:59.0" updateauthor="mgbailey" updated="2019-08-22 14:52:59.0"/>
<Action id="63197" issue="41898" author="lbendixsen" type="comment" created="2019-08-22 15:59:56.0" updateauthor="lbendixsen" updated="2019-08-22 15:59:56.0"> <body><! CDATA  ~sergey.khoroshavin   ~ashcherbakov   I have added states and transactions for the FoundationBuilder Node from the BuilderNet.  The StagingNet's files are huge for this so it will take me a bit longer to get those tarred and uploaded with the current 10M limit.  It would help to know which individual files are needed, or if the whole _state and _transactions directories are required for this request.  ></body> </Action>
<Action id="63220" issue="41898" author="toktar" type="comment" created="2019-08-23 08:00:47.0" updateauthor="toktar" updated="2019-08-23 08:00:47.0"> <body><! CDATA *Problem reason:* - OFF_LEDGER_SIGNATURE always writes to a state  *Changes:* - Add a fix to not write OFF_LEDGER_SIGNATURE  if it's not explicitly set - Add tests  *PR:* *  https://github.com/hyperledger/indy-node/pull/1418   *Version:* * indy-node 1.9.2.dev1061 -master  *Risk factors:* - Problems with an inconsistency of states  *Risk:* - Medium  *Tests:* * test_auth_constraint_without_off_ledger_sig_from_dct_succesfull * test_auth_rule_state_format  ></body> </Action>
<Action id="63223" issue="41898" author="ashcherbakov" type="comment" created="2019-08-23 12:13:57.0" updateauthor="ashcherbakov" updated="2019-08-23 12:52:10.0"> <body><! CDATA  ~esplinr   ~lbendixsen   ~mgbailey  Let me summarize our decisions: * Fix: ** See above ** Will be included into next Release * Release: ** Do a common release with this fix included according to regular schedule * Migration script: ** Do not do a migration script * How to recover consensus: ## The best way to recover and avoid such issue for newly added nodes: *** wait for the update *** resetting (clean up) config state on ALL Nodes (including the ones in consensus) *** Please note that the audit legder still be inconsistent in terms of history, so an audit script (for a config ledger and state) will fail on Builder Net. The only correct way to avoid this would be real migration touching audit ledger. ## If there are no config transactions will be written, then a simple restart of the nodes experiencing the issue will help. It still means that Item 1 needs to be done later (upgrade + state cleanup) ## If config txns are planned to be written before the upgrade, then consensus can be recovered by manual copy of config state from a valid (in consensus) node. It still means that Item 1 needs to be done later (upgrade + state cleanup)  ></body> </Action>
<Action id="63227" issue="41898" author="vladimirwork" type="comment" body="Verified against indy-node setup." created="2019-08-23 14:36:09.0" updateauthor="vladimirwork" updated="2019-08-23 14:36:09.0"/>
<Action id="63238" issue="41898" author="anikitindsr" type="comment" created="2019-08-23 18:34:57.0" updateauthor="anikitindsr" updated="2019-08-23 18:34:57.0"> <body><! CDATA  ^remove_config_state.py  was created for fixing problem.  ~VladimirWork , please check that, this script working correctly for test pool.  ></body> </Action>
<Action id="63275" issue="41898" author="vladimirwork" type="comment" body="Verified against sovrin setup (but upgraded using `apt install` because of INDY-2216)." created="2019-08-26 10:04:22.0" updateauthor="vladimirwork" updated="2019-08-26 10:04:22.0"/>
<Action id="63330" issue="41898" author="vladimirwork" type="comment" created="2019-08-27 15:40:38.0" updateauthor="vladimirwork" updated="2019-08-27 15:48:09.0"> <body><! CDATA Verified against indy-node and sovrin setups with config migration script.  https://github.com/VladimirWork/indy-test-automation/blob/acb03d2da0e16ae81e30e964736232cec41c129c/system/draft/test_misc.py#L1529  ></body> </Action>
