<Action id="48887" issue="32764" author="derashe" type="comment" created="2018-08-15 13:24:27.0" updateauthor="derashe" updated="2018-08-15 13:24:27.0"> <body><! CDATA Problem reason: * Node5 stopped writing txns in it's ledger after removal of network issues.  Research: * While researching logs, we found that master replica of Node5 wasn't able to write txns, while backup replicas wrote txn as usual. That explains why did we send INSTANCE_CHANGE\{'viewNo': 1, 'reason': 25} * This situation can appear, when NodeX get new pre-prepare (0,3 for example), then because of connection troubles we've lost all prepare and commit messages for (0,3). But pool had quorum to order (0,3) and so to overtook NodeX. In that case NodeX will stay behid the pool till the nearest stable checkpoint, when it will catchup ledger and continue ordering with pool     ></body> </Action>
<Action id="49402" issue="32764" author="ozheregelya" type="comment" body="INDY-1163 will be fixed in scope of this ticket, so it should be re-tested as well." created="2018-08-27 10:52:20.0" updateauthor="ozheregelya" updated="2018-08-27 10:52:20.0"/>
<Action id="49503" issue="32764" author="derashe" type="comment" created="2018-08-28 17:34:36.0" updateauthor="derashe" updated="2018-09-06 15:09:32.0"> <body><! CDATA Some tests were made to make sure that this behind node will catchup on closest stable checkpoint and pool will continue ordering. Also we checked, that in case of loosing quorum, pool will not breake and stop writing txns.  We could provide solution to resolve this issue, such as request missing messages again, but we didn't because of two reasons: * This may serioulsy affect node behaviuor and slow it down in some cases * Case that was reproduces in test environment with iptables is a bit syntetic. In real case, there is low probablility to reproduce this  Covered with tests: *  plenum/test/node_request/test_node_got_no_preprepare.py|https://github.com/hyperledger/indy-plenum/pull/894/files#diff-ecb7ed89c12ee93adde659056521eb71  *  plenum/test/node_request/test_node_got_only_preprepare.py|https://github.com/hyperledger/indy-plenum/pull/894/files#diff-d5e169d031dabc49cf0dc530532f16ce   Commited info: *  https://github.com/hyperledger/indy-plenum/pull/894   Conclusion:  That problem will be resolved and pool will continue stable work after achieving closest stable checkpoint  Recomendation for QA: * Reproduce case of this ticket and after unblocking primary, make pool order 300 batches (enought for stable checkpoint) * After these batches nodes should work correctly  ></body> </Action>
<Action id="50114" issue="32764" author="ozheregelya" type="comment" created="2018-09-07 20:04:20.0" updateauthor="ozheregelya" updated="2018-09-07 20:04:20.0"> <body><! CDATA *Environment:* indy-node 1.6.599  *Steps to Validate:* 1. Setup the docker pool of 7 nodes. 2. On one of the nodes (node 5) block the Primary (node 1) IP: iptables -A INPUT -s 10.0.0.2 -j DROP 3. Check nodes logs. => Only 1 INSTANCE_CHANGE\{'viewNo': 1, 'reason': 25} was send by Node5, but one more INSTANCE_CHANGE\{'viewNo': 1, 'reason': 26} was send by Node7. 4. Unblock the Primary IP: iptables -D INPUT -s 10.0.0.2 -j DROP 5. Run load test.  *Actual Results:* Node 5 wrote all txns.  INDY-1163 was not reproduced.  ></body> </Action>
