<Action id="53829" issue="35514" author="sergey.khoroshavin" type="comment" created="2018-11-27 09:21:57.0" updateauthor="sergey.khoroshavin" updated="2018-11-27 09:21:57.0"> <body><! CDATA  !Screenshot from 2018-11-27 12-10-59.png|thumbnail!  Seems like there is indeed memory leak in nodes when one of them restarts while under load. Furthermore, when node was stopped and started after some time it's memory grew much more. It seemed like memory growth during restart is proportional to number of transactions missed by node, which makes catchup code prime suspect. Top live objects showed that growth was in number of _dict_ and _set_ objects. Further investigation will be performed.  ></body> </Action>
<Action id="54076" issue="35514" author="sergey.khoroshavin" type="comment" created="2018-11-30 14:00:33.0" updateauthor="sergey.khoroshavin" updated="2018-11-30 14:00:33.0"> <body><! CDATA Following experiments were performed in docker pool with one node constantly restarting: * load test with one node ignoring catchup requests, but there was no difference in memory consumption compared to normal nodes * load test with one node ignoring both ledger status and catchup requests, but there was no difference in memory consumption compared to normal nodes * no load showed no memory growth  ></body> </Action>
<Action id="54427" issue="35514" author="sergey.khoroshavin" type="comment" created="2018-12-06 11:16:11.0" updateauthor="sergey.khoroshavin" updated="2018-12-06 12:12:12.0"> <body><! CDATA *Problem reason* Rebooting node was propagating requests that were already ordered by other nodes. While these propagates were discarded requests were still accumulating in ReqAuthenticator during message authentication, which takes place before actual processing.  *Solution* Make sure request is deleted from ReqAuthenticator when discarding PROPAGATE during actual processing.  *Version* indy-plenum 1.6.625  *PR* https://github.com/hyperledger/indy-plenum/pull/1012  *Covered by tests* https://github.com/hyperledger/indy-plenum/pull/1012/files#diff-bd3503579ad656b2b2f2726298ed1602R85  *Risk* Low  *Recommendations for QA* Continuously restart one of non-primary nodes while under load test for at least 4 hours. Look for number of objects tracked by GC in metrics - it shouldn't increase in long term.  ></body> </Action>
<Action id="54428" issue="35514" author="sergey.khoroshavin" type="comment" created="2018-12-06 11:18:17.0" updateauthor="sergey.khoroshavin" updated="2018-12-06 11:18:27.0"> <body><! CDATA Actually some validation was already done using docker pool with Node2 having this fix and other nodes not: !Screenshot from 2018-12-06 12-37-27.png|thumbnail!   ></body> </Action>
