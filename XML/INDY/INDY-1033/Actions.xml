<Action id="38495" issue="25729" author="dsurnin" type="comment" created="2018-01-12 11:50:54.0" updateauthor="dsurnin" updated="2018-01-12 11:50:54.0"> <body><! CDATA the issue might be fixed with 1018 so needs to be retested with latest master with plenum v215  ></body> </Action>
<Action id="38648" issue="25729" author="ozheregelya" type="comment" created="2018-01-15 18:02:51.0" updateauthor="ozheregelya" updated="2018-01-15 19:36:20.0"> <body><! CDATA  ~dsurnin , Case 1 is still reproducing on version 1.2.270.   Case 2 can't be rechecked now because of unclear problem with load scripts: {code:java} indy@de69716a8962:~/perf$ python3 Perf_Add_nyms.py -n 1000 Traceback (most recent call last): File "Perf_Add_nyms.py", line 9, in <module> from indy import ledger, signus, wallet, pool ImportError: No module named 'indy'{code}  ></body> </Action>
<Action id="38886" issue="25729" author="dsurnin" type="comment" created="2018-01-19 09:01:55.0" updateauthor="dsurnin" updated="2018-01-19 09:07:28.0"> <body><! CDATA Problem reason: quorum for checkpoint txn was 2f  Changes: change quorum to n-f-1  Versions: master plenum 224 master node 277  Risk factors: watermarks, checkpoints, catch up  Risk: Med/  Covered with tests: plenum/test/primary_selection plenum/test/checkpoints  ></body> </Action>
<Action id="38899" issue="25729" author="vladimirwork" type="comment" created="2018-01-19 15:57:58.0" updateauthor="vladimirwork" updated="2018-01-19 15:57:58.0"> <body><! CDATA Build Info: indy-node 1.2.279  Steps to Reproduce: 1. Setup the pool of 7 nodes. 2. Write several transactions. 3. Disconnect one of nodes (not primary) using following command in CLI: send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services':   } 4. Send 1000 tnx using load test (based on indy-sdk). 5. Connect disconnected node back: send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services':  'VALIDATOR' } 6. Send 1000 tnx using load test.  Actual Results: Node which was disconnected stopped processed transactions (it wrote 1631 when the rest ones wrote 2021). Logs from 1st (demoted/promoted back) and 2nd, 3rd nodes are in attachment.  ^logs.tar.gz    ></body> </Action>
<Action id="39130" issue="25729" author="ozheregelya" type="comment" created="2018-01-25 18:26:39.0" updateauthor="ozheregelya" updated="2018-01-31 19:59:47.0"> <body><! CDATA One more problem with lagging node. (Case 3) On pool of 25 nodes Node1 was lagged without any demotions/promotions. Note that Node11 was not connected to the pool. Logs for this problem:  https://drive.google.com/file/d/1Lv6VrHJl4j64b44xnj__HdyEOBCxyOfZ/view?usp=sharing   (Case 4) On pool of 7 nodes Node7 was lagged without any demotions/promotions. Logs for this case:  https://drive.google.com/open?id=1sFt8n-69h-8vdvT2kuXpXQsAev1zJ4W4   In both of cases *steps for reproduce* are: 1. Setup nodes using generate_indy_pool_transactions. 2. Start nodes at once. 3. Run load test.  ></body> </Action>
<Action id="39350" issue="25729" author="vladimirwork" type="comment" body="Issue is not reproducing on 1.2.287 master." created="2018-01-30 09:12:01.0" updateauthor="vladimirwork" updated="2018-01-30 09:12:01.0"/>
<Action id="39362" issue="25729" author="dsurnin" type="comment" body="According to logs with 7 nodes it looks like that lagged nodes works correctly and most probably they just need some time to get all the missed txns" created="2018-01-30 13:21:25.0" updateauthor="dsurnin" updated="2018-01-30 13:21:25.0"/>
<Action id="39405" issue="25729" author="dsurnin" type="comment" body="About logs for pool of 25 nodes - all the logs shows that all the nodes committed the same seqNo, so there are now any lagging according to logs" created="2018-01-31 06:45:27.0" updateauthor="dsurnin" updated="2018-01-31 06:45:27.0"/>
<Action id="39406" issue="25729" author="dsurnin" type="comment" created="2018-01-31 07:01:45.0" updateauthor="dsurnin" updated="2018-01-31 07:01:45.0"> <body><! CDATA Probably it should be mentioned that read_ledger is not really a precise way to detect that ledgers are the same. Due to leveldb limitations to read from levelbd we first copy all files to different folder and then traverse all the records one by one. It is not the fastest way and actual ledger contents could be changed significantly to the end of read_ledger script. So probably to check the ledgers equality read_ledger script should be called only in case of pool without any load and several times with some time span.  ></body> </Action>
<Action id="39408" issue="25729" author="dsurnin" type="comment" created="2018-01-31 10:18:35.0" updateauthor="dsurnin" updated="2018-01-31 10:18:35.0"> <body><! CDATA According to discussion with Alexandr and Andrey K it looks like better way to monitor ledgers equality is validator-info but it also should be run without a load and several times  ></body> </Action>
<Action id="39459" issue="25729" author="ozheregelya" type="comment" created="2018-01-31 20:13:50.0" updateauthor="ozheregelya" updated="2018-01-31 20:13:50.0"> <body><! CDATA Ticket for read_ledger problems: INDY-1117  Case 1: was retested by  ~VladimirWork  on version 1.2.287 - ok. Case 2: INDY-1095 - ok. Case 3: this was not a problem on node side, it was a problem with read_ledger script (INDY-1117). Validator-info showed that all nodes successfully wrote 350356 transactions. - ok.  *Case 4 - not ok:* It doesn't looks like problem from INDY-1117 - there are no old read_ledger data: {code:java} root@e2878f6f0526:/home/indy# sudo find / -type d -name "*-read-copy" root@e2878f6f0526:/home/indy# {code} But results of read_ledger and validator-info are different: {code:java} root@e2878f6f0526:/home/indy# read_ledger --type domain --count 703 root@e2878f6f0526:/home/indy# validator-info  Validator Node7 is running Validator DID: BM8dTooz5uykCbYSAAFwKNkYfT4koomBHsSWHTDtkjhW Verification Key: 4u9hRgKH6daKcEWb6x9zhsM1G6X93VoXSJHppaeJhdivrHWpKvVtUj9 Node Port: 9713 Client Port: 9714 Metrics: Uptime: 26 minutes, 22 seconds Total Ledger Transactions: 569 Total Pool Transactions: 7 Read Transactions/Seconds: 0.00 Write Transactions/Seconds: 0.35 Reachable Hosts: 7/7 Unreachable Hosts: 0/7{code} Anyway, count of transactions on 7th node is less than count of transactions on another ones.     There is no load on this pool. Node is working since  {{Wed Jan 31 14:47:10 UTC 2018}} but it still have not wrote remaining transactions.  So, I can't close this ticket for now. It needs in additional discussion and exploration.  ></body> </Action>
<Action id="39586" issue="25729" author="vladimirwork" type="comment" body="The most of cases are done and it looks like in Case 4 we face another issue with watermarks so INDY-1141 is reported according to the last discussion." created="2018-02-02 13:24:41.0" updateauthor="vladimirwork" updated="2018-02-02 13:25:03.0"/>
