<Action id="35332" issue="24429" author="mgbailey" type="comment" body="The reqId of the transaction that was posted during the view change is identical to the one that was posted when the validator was originally added to the ledger weeks ago." created="2017-11-21 22:33:10.0" updateauthor="mgbailey" updated="2017-11-21 22:33:10.0"/>
<Action id="35350" issue="24429" author="mgbailey" type="comment" body="adding logs from the esatus node" created="2017-11-22 16:02:08.0" updateauthor="mgbailey" updated="2017-11-22 16:02:08.0"/>
<Action id="37723" issue="24429" author="spivachuk" type="comment" body=" ~mgbailey , could you please provide the logs from the nodes &quot;canada&quot; and &quot;england&quot; for 11/20/2017 if they are available?" created="2017-12-21 15:54:26.0" updateauthor="spivachuk" updated="2017-12-21 15:54:26.0"/>
<Action id="37726" issue="24429" author="mgbailey" type="comment" created="2017-12-21 16:35:55.0" updateauthor="mgbailey" updated="2017-12-21 16:36:24.0"> <body><! CDATA  ~spivachuk  The logs of these nodes go back only 2 days because they are quickly filling with repeated messages and are rolling.  The messages are:  {code:java} 2017-12-21 15:01:05,485 | WARNING | replica.py ( 983) | __is_next_pre_prepare | england:0 missing PRE-PREPAREs between 4 and 0 2017-12-21 15:01:05,511 | WARNING | replica.py ( 983) | __is_next_pre_prepare | england:0 missing PRE-PREPAREs between 4 and 0 2017-12-21 15:01:05,523 | WARNING | replica.py ( 983) | __is_next_pre_prepare | england:0 missing PRE-PREPAREs between 4 and 0 2017-12-21 15:01:05,536 | WARNING | replica.py ( 983) | __is_next_pre_prepare | england:0 missing PRE-PREPAREs between 4 and 0 ...{code}  ></body> </Action>
<Action id="37728" issue="24429" author="spivachuk" type="comment" body="Thank you,  ~mgbailey . Could you please check also if &quot;singapore&quot; log for 11/20/2017 is available and attach it if so?" created="2017-12-21 18:04:04.0" updateauthor="spivachuk" updated="2017-12-21 18:04:04.0"/>
<Action id="37729" issue="24429" author="mgbailey" type="comment" created="2017-12-21 18:59:00.0" updateauthor="mgbailey" updated="2017-12-21 18:59:00.0"> <body><! CDATA  ~spivachuk , although we have about 12 days of logs on Singapore, it also is rolling logs more quickly than might be expected due to repeated log messages.  I am concerned about the health of this network, which is our most active long-lived network.  Here are the log messages I am seeing repeated: {code:java} 2017-12-21 10:45:08,833 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'0@75wWXu$y-:}@dG*&HtG!H4kuYXW/&MPgUBV8%7' has been removed 2017-12-21 10:45:16,110 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'BEhc!q7/{^9)vgy&p$f!kx.sTfa9gxeT9(BqKVil' has been removed 2017-12-21 10:45:23,544 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'0@75wWXu$y-:}@dG*&HtG!H4kuYXW/&MPgUBV8%7' has been removed 2017-12-21 10:45:30,841 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'BEhc!q7/{^9)vgy&p$f!kx.sTfa9gxeT9(BqKVil' has been removed 2017-12-21 10:45:38,861 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'0@75wWXu$y-:}@dG*&HtG!H4kuYXW/&MPgUBV8%7' has been removed 2017-12-21 10:45:46,139 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'BEhc!q7/{^9)vgy&p$f!kx.sTfa9gxeT9(BqKVil' has been removed ...{code}  ></body> </Action>
<Action id="37803" issue="24429" author="spivachuk" type="comment" created="2017-12-26 18:04:31.0" updateauthor="spivachuk" updated="2017-12-26 18:17:41.0"> <body><! CDATA *Problem reason:* As we can see in the attached logs, the scenario was as follows: # In the backup instance 3 its primary replica {{singapore:3}} sent PREPREPARE with one client request that was already ordered earlier to all the other replicas in the instance _(this request was {{send NODE services= VALIDATOR }} for {{esatus}})_. # The nodes containing these other replicas sent MESSAGE_REQUEST for PROPAGATE of this client request to all the others. # {{singapore}} responded to each received MESSAGE_REQUEST by MESSAGE_RESPONSE with the requested PROPAGATE. # Having seen the client request as if for the first time, the rest of the nodes sent the PROPAGATE to all the others (but actually the nodes just didn't detect that this old already processed request was received earlier). # All the nodes reached quorum for PROPAGATE. 3PC-process for the request proceeded in the instance 3 and also started in in all the other instances (0, 1, 2). # Eventually the client request was ordered for the second time.  We were not able to detect the initial cause of why {{singapore:3}} initiated 3PC-process for the old already processed request because logs were available for some nodes only (for {{singapore}} - not available) and a DEBUG/TRACE log was available for one node only ({{korea}}). Most likely, the node {{singapore}} took the request from some queue of postponed messages where it was stashed previously and was not removed later after the request had been ordered in scope of some 3PC-batch. Possibly the issue was fixed in master branch in scope of one of recently resolved bug tickets.  However, another issue was also revealed - the nodes didn't detect that the received PROPAGATE contained a request received earlier. This issue was caused by a lack in {{Node.processPropagate}} method of a check of the request presence in {{seqNoDB}}. This resulted in the following behavior: if some repeated or belated request or PROPAGATE was received when the request had already been processed and later removed from {{Propagator.requests}} dictionary (for example, on a view change) then the request was processed again. In our case this issue made it possible for the nodes in the pool to order once again the already ordered request {{send NODE services= VALIDATOR }} for {{esatus}}. So the node {{esatus}} was promoted.  *Changes:* - Fixed a bug with a lack of a check of the request presence in {{seqNoDB}} on processing of the belated PROPAGATE message. - Added tests for processing of repeated requests, belated requests and belated PROPAGATE messages received at different moments (during 3PC-process, after the request has been ordered, after the request has been ordered and a view change has occurred). - Corrected {{sdk_send_and_check}} and {{sdk_send_random_and_check}} functions. Now they ensure that each passed request gets a confirmed reply.  *PRs:* -  https://github.com/hyperledger/indy-plenum/pull/492  -  https://github.com/hyperledger/indy-plenum/pull/493  -  https://github.com/hyperledger/indy-node/pull/507   *Version:* - indy-node 1.2.252 master - indy-plenum 1.2.212 master  *Risk factors:* - Nothing is expected.  *Risk:* - Low  *Covered with tests:* - {{test_belated_propagate_not_processed_after_view_change}}  ></body> </Action>
<Action id="37830" issue="24429" author="vladimirwork" type="comment" created="2017-12-28 15:47:13.0" updateauthor="vladimirwork" updated="2017-12-28 15:47:13.0"> <body><! CDATA Build Info: indy-node 1.2.253  Steps to Validate: 1. Demote new added to the pool nodes. 2. Force view changes by primary nodes restarting. 3. Demote nodes that were demoted and promoted back earlier. 4. Force view changes by primary nodes restarting. 5. Check logs of all nodes for `propagate` messages.  Actual Results: Issue with spontaneously promoted back node is not reproducing.  ></body> </Action>
