<Action id="33672" issue="22405" author="andkononykhin" type="comment" created="2017-11-01 10:37:03.0" updateauthor="andkononykhin" updated="2017-11-01 10:37:03.0"> <body><! CDATA PoA: # implement test: 5th node added to pool of 4 nodes, 4 view changes already happened, expect node5 will accept current primaries # implement logic of collecting pool information using optional argument of ledger size # add conditional logic during primary selection routine to use only ledger info which was actual for the moment when view change happenedÂ  (possible for nodes that are connected to a running pool)  ></body> </Action>
<Action id="34499" issue="22405" author="andkononykhin" type="comment" created="2017-11-09 13:36:52.0" updateauthor="andkononykhin" updated="2017-11-09 13:36:52.0"> <body><! CDATA Problem reason: - when node is joined after several view changes happened it will likely choose different primary than other nodes because it operates with different node registry than other nodes - as far as I explored the logs there it's not an issue of upgrade  Changes: - added logic for newly joined node to accept current primary without sending any view change done messages to other nodes - besides that such a node during primary selection chooses pool ledger of the state actual for the moment when view change happened (according to information from CURRENT_STATE messages) - did some refactoring - fixed some low level util api - added api to cancel scheduled events - added tests  Committed into: - https://github.com/hyperledger/indy-plenum/pull/443  Risk factors: - Nothing is expected.  Risk: - Low  Covered with tests: - https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/primary_selection/test_new_node_accepts_chosen_primary.py  Recommendations for QA: do the following sequence of steps * start pool of 4 nodes * force 4 view changes * add new node * ensure that pool works properly and all 5 nodes chose Alpha:0 as a master primary and Beta:1 as a primary for backup instance  ></body> </Action>
<Action id="34584" issue="22405" author="vladimirwork" type="comment" created="2017-11-13 09:50:32.0" updateauthor="vladimirwork" updated="2017-11-13 09:50:32.0"> <body><! CDATA Build Info: indy-node 1.2.208  Steps to Validate: 1. Start pool of 4 nodes. 2. Force 4 view changes. 3. Add new node.  Actual Results: Pool works properly and all 5 nodes chose Node1:0 as a master primary and Node2:1 as a primary for backup instance. Normal cases with nodes adding (without view changes) also works.  Additional info: Special case with two nodes adding and more view changes reported as INDY-948.   ></body> </Action>
