<Action id="52675" issue="34855" author="spivachuk" type="comment" body="In the logs {{indy-1711/success}} the instances 3, 4 and 6 stopped ordering 3PC-batches because their *primaries were restarted and so lost {{lastPrePrepareSeqNo}} counter value and started numbering of pp_seq_nos from 1 again* while other replicas expected continuous numbering of pp_seq_nos. The primaries in the instances 3 (Node4), 4 (Node5) and 6 (Node7) were restarted on 10/19 at 18:10, 18:07 and 18:23 correspondingly. Node4 and Node5 fell due to out-of-memory and so were restarted. As to Node7, there is no systemd journal for that period but most probably the reason of its restart is the same." created="2018-10-26 09:36:01.0" updateauthor="spivachuk" updated="2018-10-26 09:38:17.0"/>
<Action id="52763" issue="34855" author="spivachuk" type="comment" created="2018-10-30 13:02:37.0" updateauthor="spivachuk" updated="2018-10-30 13:05:25.0"> <body><! CDATA In the logs {{indy-1574-new}} *the instance 6 stopped ordering 3PC-batches because its primary - Node8 - was restarted and so lost {{lastPrePrepareSeqNo}} counter value and started numbering of pp_seq_nos from 1 again while other replicas expected continuous numbering of pp_seq_nos.*  *Node8 was restarted because it fell due to out-of-memory on 10/02 at 01:55. This out-of-memory was most likely caused by that the replica Node8:7 stopped ordering 3PC-batches. The last batch which it ordered was (1, 9136). It was on 10/01 at 16:52:10.* However, the primary of the instance 7 - Node9 - did not fall and was not restarted at that period, it did not stopped ordering, it did not report about disconnection from Node8 and Node8 did not report about disconnection from it. There was a pause in receiving Checkpoints by Node8 from Node9 from 16:52:08 till 16:55:41 but after it Node8 continued receiving Checkpoints from Node9 in all the instances. Moreover, there was no gap in incoming Checkpoints from Node9 in any instance. *Most likely Node8:7 did not receive Commits for the batch (1, 9137) from some replicas and so did not gather the quorum of Commits for this batch. Since missing of Commits is not a trigger for requesting missed 3PC-messages, Node8:7 stopped ordering.* However, due to Node8:7 continued to receive Checkpoints, it moved the watermarks on gathering the quorum of messages for each next Checkpoint generation (starting from 2 quorumed generations of stashed checkpoints). *But backup replicas {color:#de350b}do nothing other than moving the watermarks{color} when detecting a lag in Checkpoints. So they cannot resume ordering.* This leads to growth of the queues of request keys and pending 3PC-messages on the replica and growth of request map on the node. This can eventually result in a node fall due to out-of-memory. We see such a fall on Node8 at 01:55.  So ordering in the instance 6, where Node8 was the primary at that moment, was stopped all over the pool. In turn, stop of ordering in an instance lead to growth of memory consumption on all the nodes in the pool and can eventually result in their falls due to out-of-memory (as it is specified in the ticket description).  ></body> </Action>
<Action id="52766" issue="34855" author="spivachuk" type="comment" body="Created INDY-1795 for adding adjustment of {{last_ordered_3pc}} and performing GC to the logic of handling a lag in checkpoints on a backup replica." created="2018-10-30 13:59:14.0" updateauthor="spivachuk" updated="2018-10-30 13:59:14.0"/>
