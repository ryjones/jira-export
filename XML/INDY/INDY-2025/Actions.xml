<Action id="58839" issue="38513" author="sergey.khoroshavin" type="comment" created="2019-04-02 11:40:19.0" updateauthor="sergey.khoroshavin" updated="2019-04-02 11:40:19.0"> <body><! CDATA First load test on AWS pool showed that nodes sometimes were crashing after view change: {code} Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 : Traceback (most recent call last): Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/bin/start_indy_node", line 19, in <module> Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     client_ip=sys.argv 4 , client_port=int(sys.argv 5 )) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/indy_node/utils/node_runner.py", line 54, in run_node Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     looper.run() Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 263, in run Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     return self.loop.run_until_complete(what) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/lib/python3.5/asyncio/base_events.py", line 387, in run_until_complete Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     return future.result() Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/lib/python3.5/asyncio/futures.py", line 274, in result Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     raise self._exception Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/lib/python3.5/asyncio/tasks.py", line 239, in _step Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     result = coro.send(None) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 227, in runForever Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     await self.runOnceNicely() Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 210, in runOnceNicely Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     msgsProcessed = await self.prodAllOnce() Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py", line 152, in prodAllOnce Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     s += await n.prod(limit) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/indy_node/server/node.py", line 336, in prod Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     c = await super().prod(limit) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/common/metrics_collector.py", line 375, in wrapper Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     return await f(self, *args, **kwargs) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1326, in prod Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     c += await self.serviceViewChanger(limit) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/common/metrics_collector.py", line 375, in wrapper Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     return await f(self, *args, **kwargs) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1396, in serviceViewChanger Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     i = await self.serviceViewChangerInbox(limit) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 1727, in serviceViewChangerInbox Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     await self.view_changer.serviceQueues(limit) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/view_change/view_changer.py", line 472, in serviceQueues Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     return await self.inBoxRouter.handleAll(self.inBox, limit) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 104, in handleAll Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     await self.handle(item) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 86, in handle Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     res = self.handleSync(msg) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/router.py", line 75, in handleSync Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     return self.getFunc(msg 0 )(*msg) Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/view_change/view_changer.py", line 451, in process_vchd_msg Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     self._start_selection() Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/view_change/view_changer.py", line 642, in _start_selection Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     self.provider.select_primaries() Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/view_change/node_view_changer.py", line 87, in select_primaries Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     self._node.select_primaries() Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/node.py", line 3125, in select_primaries Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     replica = self.replicas i  Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :   File "/usr/local/lib/python3.5/dist-packages/plenum/server/replicas.py", line 248, in __getitem__ Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 :     return self._replicas item  Apr 02 10:29:16 ohioQALive11.qatest.evernym.com env 16927 : KeyError: 2 {code}  ></body> </Action>
<Action id="58845" issue="38513" author="vladimirwork" type="comment" created="2019-04-02 13:57:51.0" updateauthor="vladimirwork" updated="2019-04-02 13:59:20.0"> <body><! CDATA Build Info: indy-node 1.7.0~dev883 plugins 0.9.6~7  Steps to Reproduce: 1. Run 10 nyms/sec load test with forced VCs every 1800 seconds.  Actual Results: We have 16th and 17th node that *stop ordering* and have view different from other nodes. This nodes *don't catch up* under load and after it so only way to catch up them is service restart. Also there is an exception that described above.  Expected Results: There should be no stalled nodes at this load rate.  Logs and metrics: ev@evernymr33:logs/02_04_2019_view_changes_nyms_only_logs.tar.gz ev@evernymr33:logs/02_04_2019_view_changes_nyms_only_metrics.tar.gz  ></body> </Action>
<Action id="58877" issue="38513" author="derashe" type="comment" body="Fix:Â  https://github.com/hyperledger/indy-plenum/pull/1147 " created="2019-04-03 07:35:42.0" updateauthor="derashe" updated="2019-04-03 07:35:42.0"/>
<Action id="58890" issue="38513" author="vladimirwork" type="comment" created="2019-04-03 11:37:11.0" updateauthor="vladimirwork" updated="2019-04-03 11:37:11.0"> <body><! CDATA Build Info: indy-node 1.7.0~dev884 plugins 0.9.6~7  Steps to Reproduce: 1. Run all ledgers load test (load rate 10) with forced VCs every 1800 seconds.  Actual Results: We have 1st and 3rd node that *stop ordering* and have view different from other nodes. This nodes *don't catch up* under load and after it so only way to catch up them is service restart.   Expected Results: There should be no stalled nodes at this load rate.  Logs and metrics: ev@evernymr33:logs/03_04_2019_view_changes_all_ledgers_logs.tar.gz ev@evernymr33:logs/03_04_2019_view_changes_all_ledgers_metrics.tar.gz  ></body> </Action>
<Action id="58945" issue="38513" author="vladimirwork" type="comment" created="2019-04-04 11:36:17.0" updateauthor="vladimirwork" updated="2019-04-04 11:36:17.0"> <body><! CDATA Build Info: indy-node 1.7.0~dev885 plugins 0.9.6~7  Steps to Reproduce: 1. Run all ledgers load test (load rate 10) with forced VCs every 1800 seconds.  Actual Results: We have 6th node that stop ordering and have view different from other nodes. This node doesn't catch up under load and after it. Also there were catch up problems with 12th, 18th, 22nd nodes *under load* but after load they catch up successfully.  Expected Results: There should be no stalled nodes at this load rate.  Logs and metrics: ev@evernymr33:logs/04_04_2019_view_changes_all_ledgers_logs.tar.gz ev@evernymr33:logs/04_04_2019_view_changes_all_ledgers_metrics.tar.gz ev@evernymr33:logs/04_04_2019_interesting_txns.tar.gz  ></body> </Action>
<Action id="58974" issue="38513" author="vladimirwork" type="comment" created="2019-04-05 12:37:49.0" updateauthor="vladimirwork" updated="2019-04-05 12:37:49.0"> <body><! CDATA Build Info: indy-node 1.7.0~dev887  Steps to Reproduce: 1. Run all ledgers (*without payments*) load test (load rate 10) with forced VCs every 1800 seconds.  Actual Results: We have 5, 6, 7, 8, 20 nodes that stop ordering and catching up and have view different from other nodes. *After some time the whole pool has lost consensus.*  Expected Results: There should be no stalled nodes at this load rate. Pool should sustain this load rate more time than just ~10 hours.  Logs and metrics: ev@evernymr33:logs/05_04_2019_view_changes_all_ledgers_logs.tar.gz ev@evernymr33:logs/05_04_2019_view_changes_all_ledgers_metrics.tar.gz ev@evernymr33:logs/05_04_2019_interesting_txns.tar.gz  ></body> </Action>
<Action id="58979" issue="38513" author="vladimirwork" type="comment" created="2019-04-05 13:58:00.0" updateauthor="vladimirwork" updated="2019-04-05 13:58:00.0"> <body><! CDATA *1 by 1 case*  Build Info: indy-node 1.7.0~dev886  Steps to Reproduce: 1. Start acceptance load with all ledgers except payment ledger. 2. Wait for some time. 3. Provoke view change (stop 1st Node; make sure view has changed; start it back) 4. Restart nodes 1 by 1 (Node1 - Node25). 5. Make sure that every node participates in consensus 6. Stop the load.  Actual Results: First 11 and last 14 nodes have different amount of txns in the ledgers. Pool has lost consensus and the lesser group of nodes doesn't catch up with the bigger one.  Expected Results: There should be no stalled nodes and consensus loss.  Logs: ev@evernymr33:logs/2025_04_04_2019_1_by_1_stop_case.tar.gz  ></body> </Action>
<Action id="59050" issue="38513" author="toktar" type="comment" created="2019-04-09 08:57:59.0" updateauthor="toktar" updated="2019-04-09 08:57:59.0"> <body><! CDATA  ~VladimirWork  Please, re-test last load. But wait ~1 hour after restarting Node25 and check that a view change not in progress before stopping load test. Thank you!  ></body> </Action>
<Action id="59062" issue="38513" author="vladimirwork" type="comment" created="2019-04-09 15:02:42.0" updateauthor="vladimirwork" updated="2019-04-09 15:02:42.0"> <body><! CDATA Build Info: indy-node 1.7.0~dev888  Steps to Reproduce: 1. Run all ledgers (without payments) load test (load rate 10) with forced VCs every 1800 seconds.  Actual Results: We have 3, 6, 7, 22, 23 nodes that stop ordering and catching up and have view different from other nodes.  Expected Results: There should be no stalled nodes at this load rate. Pool should sustain this load rate more time than just ~10 hours.  Logs and metrics: ev@evernymr33:logs/09_04_2019_view_changes_all_ledgers_logs.tar.gz ev@evernymr33:logs/09_04_2019_view_changes_all_ledgers_metrics.tar.gz  ></body> </Action>
<Action id="59127" issue="38513" author="vladimirwork" type="comment" created="2019-04-11 11:52:56.0" updateauthor="vladimirwork" updated="2019-04-11 11:52:56.0"> <body><! CDATA  ~Toktar  > Please, re-test last load. But wait ~1 hour after restarting Node25 and check that a view change not in progress before stopping load test. Thank you! The issue doesn't reproduce against 1.7.0~dev888.  ></body> </Action>
<Action id="59187" issue="38513" author="vladimirwork" type="comment" body="All ledgers during production load with payments and forced VCs against the latest master node and plugins are in sync but there is some issue with sovtoken ledger - it has too few txns (7.6k) and there is no writes there but domain ledger looks good (713k txns and still growing). ViewNo is the same for all nodes. &lt;&lt; This case investigation and work on all cases untested in scope of this ticket will be continued in INDY-2051. All system tests implemented in scope of this ticket are in https://github.com/hyperledger/indy-test-automation/pull/21 (TestAuditSuite)." created="2019-04-12 09:35:33.0" updateauthor="vladimirwork" updated="2019-04-12 09:35:33.0"/>
