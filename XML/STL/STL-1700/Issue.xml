<Issue id="44394" key="STL-1700" number="1700" project="10001" reporter="JIRAUSER19826" creator="JIRAUSER19826" type="10004" summary="Memory runs out on block catchup if backlog is too high" priority="1" status="10100" created="2020-02-24 03:49:04.0" updated="2020-02-24 14:04:52.0" votes="0" watches="1" workflowId="58302" archived="N"> <description><! CDATA This issue has caused several developers to post on the #sawtooth-core-dev list.  When a new or previously disabled validator is added back into the blockchain, it must catch up on blocks previously validated, but not on its chain.  If the number of blocks or size of these blocks that must be added to the new validator are greater than the available RAM on the validator node, the node will crash.  If auto re-start is enabled, it will continuously restart and crash. We figured out this shows up in a NON Docker environment.  Docker will enable memory-swap and take the excess blocks and spool them to disk, if so enabled.  Thus this issue does not show up in a Docker environment.  Unless your environment has memory-swap enabled, the spooling of blocks to the new validator node will continue until such time available RAM is exhausted and the node is re-started.   How we recreated this issue: # Configured a cluster of five nodes with PBFT in Docker Compose, Added a 1 GB memory limit to the validator. # Brought up the first four nodes, which is enough for consensus. # Ran intkey load for an hour, roughly 50 tps. # Activated the final (fifth) node, and observed the memory usage. Maxed out at 1 GB, and swapped over 2 GB to disk before I interrupted it (was progressing, but slow because of swapping the was handled automatically by Docker) # Disabled swap for Validator dockers and restarted. Validator now immediately crashes when it reaches 1 GB memory limit. # Restarted validator with much larger memory limit (4-8GB) and catchup completes successfully.  This issue is related to STL-972 which is asking for a limiter to be added to reduce the number of blocks released at a time to catchup blocks on a new validator node or one re-entering after being taken offline.          ></description> </Issue>
