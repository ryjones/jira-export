<Action id="57660" issue="38025" author="mgbailey" type="comment" created="2019-02-27 18:17:08.0" updateauthor="mgbailey" updated="2019-02-27 18:17:08.0"> <body><! CDATA We have need to remove nodes from TestNet, but fear to do so until this issue is understood. Please determine the cause, and report it as quickly as possible.     ></body> </Action>
<Action id="57706" issue="38025" author="artemkaaas" type="comment" created="2019-02-28 09:43:44.0" updateauthor="artemkaaas" updated="2019-02-28 09:43:44.0"> <body><! CDATA Changes: delete cache and restart catchup in case of an outdated cache Done in PR: https://github.com/hyperledger/indy-sdk/pull/1505  ></body> </Action>
<Action id="57737" issue="38025" author="mgbailey" type="comment" body=" ~Artemkaaas , please let us know under what circumstances this issue occurs? We need to know so that we know how to avoid the issue before the PR is released to TestNet." created="2019-02-28 15:18:35.0" updateauthor="mgbailey" updated="2019-02-28 15:18:35.0"/>
<Action id="57740" issue="38025" author="artemkaaas" type="comment" body=" ~mgbailey , for real pool it can occur If somebody hasn&apos;t connected to the pool (for which significantly changed the list of nodes) for a long time and has a very outdated cache." created="2019-02-28 15:31:57.0" updateauthor="artemkaaas" updated="2019-02-28 15:31:57.0"/>
<Action id="57754" issue="38025" author="sergey.minaev" type="comment" created="2019-02-28 18:51:13.0" updateauthor="sergey.minaev" updated="2019-02-28 18:57:21.0"> <body><! CDATA  ~mgbailey  let me share some context: client trying to establish connection to pool based on 2 entities  1) genesis transactions 2) local client cache - updated every time when client connecting to pool and see some new transactions  Let's assume 3 different states of the ledger 1 == genesis transactions 2 == intermediate with max count of nodes 3 == latest, some nodes disabled against 2nd state or just replaced by others  If current libindy has cache == 2nd state it will results in inability to connect to pool. It happens because priority/trust of cache is greater then just genesis file. From one side available nodes are not enough to make catchup from 2 to 3 states. And from another side libindy will not drop cache to catchup from 1st state to the latest one even it's theoretically possible.   ~Artemkaaas  suggest to change the priority/trust between cache and genesis and drop cache if something is going wrong with connection. This new approach will resolve current ticket but may have some negative (from security point of view) side effect  ></body> </Action>
<Action id="57760" issue="38025" author="esplinr" type="comment" created="2019-02-28 22:08:46.0" updateauthor="esplinr" updated="2019-02-28 22:08:46.0"> <body><! CDATA Using the cache for security against a malicious genesis file seems like a misuse of the cache.  But a solution for INDY-2015 could also be used to allow clients to update the pool information after a cache clear.  Workaround: individual clients can always delete the cache file on the filesystem to force a pool update.  ></body> </Action>
<Action id="57768" issue="38025" author="ashcherbakov" type="comment" created="2019-03-01 06:30:40.0" updateauthor="ashcherbakov" updated="2019-03-01 06:30:40.0"> <body><! CDATA  ~sergey.minaev  But the quorum (minimum number of nodes) for catchup is f+1, so if the client is in state 2, that is N=9, f=2, then even if the pool goes to state 3, the client must be able to catch-up, since at least f+1 nodes are still available (f+1=3, and there are 4 nodes in the pool). Maybe the issue is that the client gets timeout when asking transactions from the 5 demoted nodes, and doesn't try to re-ask other nodes?  ></body> </Action>
<Action id="57769" issue="38025" author="ashcherbakov" type="comment" created="2019-03-01 06:42:09.0" updateauthor="ashcherbakov" updated="2019-03-01 06:42:09.0"> <body><! CDATA After discussion with  ~Artemkaaas  it turned out that the quorum for ConsistencyProof on client is `n-f`, not `f+1` as on Node side. I think we need to change this to `f+1` on the client side, and the issue will gone.  ></body> </Action>
<Action id="57781" issue="38025" author="mgbailey" type="comment" body="Why is any quorum at all needed for client catch-up? I would think that with BLS signatures, a single node would be sufficient." created="2019-03-01 14:30:49.0" updateauthor="mgbailey" updated="2019-03-01 14:30:49.0"/>
<Action id="57783" issue="38025" author="ashcherbakov" type="comment" created="2019-03-01 14:35:20.0" updateauthor="ashcherbakov" updated="2019-03-01 14:35:20.0"> <body><! CDATA  ~mgbailey  You are right, but usage of BLS signature for catch-up is not supported yet.  ></body> </Action>
<Action id="58137" issue="38025" author="vladimirwork" type="comment" created="2019-03-14 10:02:41.0" updateauthor="vladimirwork" updated="2019-03-14 10:02:41.0"> <body><! CDATA Build Info: indy-cli 1.8.1~1015 indy-node 1.6.855  Steps to Reproduce: 1. Setup pool of 9 (7) nodes. 2. Create client pool connection using genesis file with only 4 (1,2,3,4) nodes of 9 (7). 3. Connect pool and demote the last 5 (3) (5,6,7,8,9 (5,6,7)) of 9 (7) nodes. 4. Exit CLI. 5. Start CLI and try to connect using existing pool created in Step2 (it was created from 4 pool txn genesis file and actual pool now has the same 4 nodes that were in genesis file).  Actual Results: Client connects pool successfully.  ></body> </Action>
