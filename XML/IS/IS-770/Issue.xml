<Issue id="31033" key="IS-770" number="770" project="10401" reporter="danielhardman" creator="danielhardman" type="10002" summary="need to prove correctness of how-to code with each checkin" priority="3" status="10405" created="2018-06-13 15:36:35.0" updated="2019-03-29 21:04:23.0" votes="1" watches="2" workflowId="50645"> <description><! CDATA Today, the content under   doc/how-tos|https://github.com/hyperledger/indy-sdk/tree/master/doc/how-tos  is stale and inaccurate. We can fix it once, but it will always be in danger of growing stale without us noticing, unless we force it to be updated regularly.  I suggest that we write a test that runs as part of the build, that works like this: # Each how-to folder should follow a convention for how its sample code is named. I suggest that the convention be: have a file named "template.<py|java|js|cs|etc>" that has comments like "//code for step 1 goes here"; also have files named "step1.<ext>", "step2.<ext>", and so forth. You can see something that roughly matches this convention in https://github.com/hyperledger/indy-sdk/tree/master/doc/how-tos/issue-credential/java # Have the test find each folder like this, and build a composite file by opening the template file and adding in the snippets from each step. Call the new file "combined.<ext>" and save it somewhere. # Compare "combined.<ext>" with the other file in this folder, which is the hand-combined version of the sample code (in  https://github.com/hyperledger/indy-sdk/tree/master/doc/how-tos/issue-credential/java,  this would be the file named IssueCredential.java). These two files should be identical except for whitespace. If they are not, the test should fail with a message saying that the hand-written file is not the same as the algorithmically built combined.<ext>. # Assuming we pass step 3, if the folder of code is for a compiled language, check to see if combined.<ext> compiles. If yes, consider the how-to code valid. # For interpreted languages like python, check to see if combined.<ext> runs in a limited way. (Since some of these scripts would require a full pool to be running when the code executes, it's not clear to me whether we can afford to run the script to completion. I think the minimum goal would be to prove the same things that a compiled language would tell us–that all the methods exist and that we have the correct number of parameters to each. Possibly we could do this by simply finding method names and making sure they exist in the .py file we imported, or by doing a help() call on each method name to see if we're calling it correctly.) If combined.<ext> seems reasonable, consider the how-to code valid. # The test should pass if it encounters no cases where the how-to sample code is considered invalid.  ></description> </Issue>
