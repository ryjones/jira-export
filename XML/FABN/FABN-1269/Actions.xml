<Action id="61459" issue="40489" author="nasht00" type="comment" created="2019-07-03 18:59:11.0" updateauthor="nasht00" updated="2019-07-03 18:59:11.0"> <body><! CDATA Here is another bit of information that strengthen the need for a solution.  As I said, the event hub bombards me with events and does not wait for me to process one before sending me the next.  Which means, I need to keep each event (block) in memory to process them gradually (a queue for example).  That's fine if you have a handful of blocks in the history. However imagine (my case), you have thousands of blocks to sync. Imagine the blockchain has been running for days/months/years with a block every 2 seconds.  Now EventHub will try to dump on me the ENTIRE blockchain history in one shot.  In my simple in-memory queue solution, I'm getting javascript "JavaScript heap out of memory".  Ideally I would like EventHub to not retrieve the next block until I tell it too, when I'm ready to process...  ></body> </Action>
<Action id="68211" issue="40489" author="JIRAUSER19902" type="comment" created="2020-03-03 18:19:02.0" updateauthor="JIRAUSER19902" updated="2020-03-03 18:19:02.0"> <body><! CDATA I know this is an old issue but it was something I was looking into as well.  Digging through the source code for tag v1.4.2 I can see that checkpointing will wait for the eventCallback to finish before running:  Â  {noformat} async _onEvent(block) { 		let blockNumber; 		if (!this._filtered) { 			blockNumber = Number(block.header.number); 		} else { 			blockNumber = Number(block.number); 		}  		try { 			await this.eventCallback(null, block); 			if (this.useEventReplay() && this.checkpointer instanceof BaseCheckpointer) { 				const checkpoint = await this.checkpointer.load(); 				if (!checkpoint.blockNumber || Number(checkpoint.blockNumber) <= Number(blockNumber)) { 					await this.checkpointer.save(null, blockNumber); 				} 			} 		} catch (err) { 			logger.error(util.format('Error executing callback: %s', err)); 		} 		if (this._registration.unregister) { 			this.unregister(); 		} 	} {noformat}  But that means the eventCallback must return a Promise and resolve that promise once the async processing is done. If the eventCallback doesn't return a resolvable promise (i.e. a synchronous function) then I've noticed that the checkpointing doesn't always work as expected (doesn't always update the blockNumber to the last block processed).    ></body> </Action>
<Action id="68492" issue="40489" author="JIRAUSER19902" type="comment" created="2020-03-21 22:32:48.0" updateauthor="JIRAUSER19902" updated="2020-03-21 22:32:48.0"> <body><! CDATA tl;dr Checkpointing doesn't work as expected. In fact the current implementation is flawed (in 1.4.8 and v2).  ...And after further digging because I started seeing the same issues as Nathan is looks like the issue is with how the listeners are handled within fabric-client.  Testing with a simple blocklistener using the default FileSystemCheckpointer:  {code:javascript} const listener = await network.addBlockListener( "my-block-listener", (error, block) => { if (error) { console.error(error); return; } console.log("Successfully received the block ", block.header.number); }, { filtered: false, replay: true} ); {code}  And adding some console.logs to  fabric-network/lib/impl/event/blockeventlistener.js :  {code:javascript}  async _onEvent(block) { 		let blockNumber; 		if (!this._filtered) { 			blockNumber = Number(block.header.number); 		} else { 			blockNumber = Number(block.number); 		}  		try { 			await this.eventCallback(null, block); 			if (this.useEventReplay() && this.checkpointer instanceof BaseCheckpointer) { 				console.log("Current") 				const checkpoint = await this.checkpointer.load(); 				console.log(`Current checkpoint: ${checkpoint.blockNumber}`) 				if (!checkpoint.blockNumber || Number(checkpoint.blockNumber) <= Number(blockNumber)) { 					await this.checkpointer.save(null, blockNumber); 					console.log(`Finished saving checkpointers for: ${blockNumber}`) 				} 			} 		} catch (err) { 			logger.error(util.format('Error executing callback: %s', err)); 		} 		if (this._registration.unregister) { 			this.unregister(); 		} 	} {code}  Running this on a network which already has 7 blocks: {code:bash} $ node blockEventsProcessor.js  Successfully received the block  1 Successfully received the block  2 Successfully received the block  3 Successfully received the block  4 Successfully received the block  5 Successfully received the block  6 Successfully received the block  7 Current Current checkpoint: 0 Current checkpoint: 0 Current checkpoint: 0 Current checkpoint: 0 Current checkpoint: 0 Finished saving checkpointers for: 2 Finished saving checkpointers for: 1 Finished saving checkpointers for: 3 Finished saving checkpointers for: 5 Finished saving checkpointers for: 4 Finished saving checkpointers for: 6 Finished saving checkpointers for: 7 {code} We can see that checkpointing is occurring "out of sync" to from the even processing itself. Checkpointing should happen after even each was successfully processed but it's actually running asynchronously without being waited on (file IO are async operations in Node.js).  I identified the following issues in fabric-client/lib/ChannelEventHub.js (where these listeners are called): 1) The callback on the GRPC stream handler should be an async function 2) On the GRPC stream 'data' handler, we should pause the stream so we can do async stuff with the block 3) The internal process event functions (_processBlockEvents) should be async 4) EventRegistration onEvent method should be async and await on this._onEvent(...args) call You can view the changes I made here to get it working as expected: https://github.com/georgejdli/fabric-sdk-node/compare/v1.4.8...georgejdli:sequential-block-processing?expand=1  Running again with the above changes we get the sequential processing behavior: {code:bash} $ node blockEventsProcessor.js  Successfully received the block  1 Current checkpoint: 0 Finished saving checkpointers for: 1 Successfully received the block  2 Current checkpoint: 1 Finished saving checkpointers for: 2 Successfully received the block  3 Current checkpoint: 2 Finished saving checkpointers for: 3 Successfully received the block  4 Current checkpoint: 3 Finished saving checkpointers for: 4 Successfully received the block  5 Current checkpoint: 4 Finished saving checkpointers for: 5 Successfully received the block  6 Current checkpoint: 5 Finished saving checkpointers for: 6 Successfully received the block  7 Current checkpoint: 6 Finished saving checkpointers for: 7 {code}  By no means am I suggesting that my code changes be merged into the project but perhaps they could be used as a guide for any future rearchitecting efforts. Looking at the source code for v2 I see the same problems remain.  I have a tight deadline so I'll be using my monkey patch in production :P.   ></body> </Action>
<Action id="69308" issue="40489" author="bestbeforetoday" type="comment" created="2020-05-21 11:16:11.0" updateauthor="bestbeforetoday" updated="2020-05-21 11:16:11.0"> <body><! CDATA  ~georgejdli  I would appreciate it if you could try the v2.1.x version of fabric-network to see if the problem of event and checkpoint ordering still exist as I believe they are fixed following a complete rewrite of the event handling in the fabric-network layer. This layer now decouples the synchronous event receipt from asynchronous event delivery to block, commit and contract listeners attached to Network and Contract objects. So events should be delivered strictly in order and checkpointing should be done exactly at the end of each successful event notification.  I don't think using an async function as the event emitter callback is safe. The emitter is expecting to drive a synchronous callback and may deliver another message immediately after the callback function invocation is complete, which in the case of an async function doesn't necessarily mean that any of the code within the function has run.  With some ad-hoc testing I have driven tens of thousands of replayed events through the v2 API without observing any issues. The implementation does buffer events to achieve both deduplication and the decoupling of synchronous and async code, so it is possible that the buffer could grow to the point that the heap is exhausted depending on how quickly client listeners handle events. Pausing the stream at appropriate points as you suggest seems like a good approach to dealing with this. I don't know if this really addresses any overflow issues or just pushes the problem further down into the GRPC and/or network layer. It just isn't something I got to investigating or implementing in the time available.  ></body> </Action>
<Action id="69311" issue="40489" author="bestbeforetoday" type="comment" body="This issue should be resolved in the v2.1.0 release" created="2020-05-21 14:32:51.0" updateauthor="bestbeforetoday" updated="2020-05-21 14:32:51.0"/>
