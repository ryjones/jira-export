<Action id="69504" issue="45200" author="bestbeforetoday" type="comment" body="Do we really need this to be a configurable option? Is there a good default we could just use and everyone&apos;s happy? I&apos;ve never heard anyone ask for this." created="2020-06-19 10:08:45.0" updateauthor="bestbeforetoday" updated="2020-06-19 10:08:45.0"/>
<Action id="70088" issue="45200" author="denyeart" type="comment" created="2020-08-27 16:21:54.0" updateauthor="denyeart" updated="2020-08-27 16:31:12.0"> <body><! CDATA Applications do need to consider height when picking endorsing peers. Consider a scenario when a new peer comes online (or gets restarted after being down for maintenance for a while). It starts processing channel block commits from block 0 and it may take a number of hours to catch up to latest channel height. You don't want applications using this peer for endorsements until it has caught up in height. Fabric hosting platforms have asked for this, so that they can bring up new peers without negatively impacting the application (getting old data back on queries, or submitting transactions with old readsets that will ultimately get invalidated). This is why the height information was added to the service discovery responses.  That being said, the definition for being 'caught up' needs to be configurable. The gossip layer shares information across peers about current peer channel heights. When this information is returned to the client app via service discovery call, some of the peer data may be a few seconds old. For example peer1 reports it is at block 1000 while peer2 reports it is at block 1001, when really both peers are caught up and the difference is simply due to a timing difference of when the peers last reported their heights via gossip. Because the SDKs cache the service discovery results, this can lead to ALL endorsements getting sent to peer2, which is not desirable. So we need a threshold that defines that if multiple peers are within N blocks of each other, then we should load balance across them rather than prefer the (slightly) higher peer.  In terms of the best default of N, maybe  ~yacovm  could suggest based on typical peer reported height deviations when using default block cutting and gossip configurations.  ></body> </Action>
<Action id="70090" issue="45200" author="yacovm" type="comment" created="2020-08-27 16:36:17.0" updateauthor="yacovm" updated="2020-08-27 16:36:17.0"> <body><! CDATA I guess what I'd do if I was the application, is that once I know I am caught up to the orderers (my latest block event matches the orderer's height or close to it), measure the mean frequency of block production in the latest couple of seconds, and derive from it how much block are produced within a time unit. Then, we know if blocks are produced seldomly or frequently (and how frequently) and given this information we can do quantization of block sequences to buckets of time units and then consider that 2 peers are of the same height if they are within a distance of some blocks.  Another approach would be to simply throw out the "catching up" peers - first we "cluster" the peers into segments of blocks according to their block heights. For example, for heights 100, 110, 130, 140 we can segment them into 2 segments of 105 and 135. Then we throw out the bottom segment of peers, etc.   ></body> </Action>
<Action id="70168" issue="45200" author="denyeart" type="comment" created="2020-09-09 13:46:19.0" updateauthor="denyeart" updated="2020-09-09 13:46:19.0"> <body><! CDATA https://github.com/hyperledger/fabric-sdk-node/pull/260 https://github.com/hyperledger/fabric-sdk-node/pull/315  When building a group list of peers for the discovery handler, randomize peers with the highest ledger height. Peers with a ledger height within one of the highest will be included. This will avoid the same peer from being called to endorse, yet not use peers that are not up to date.  ></body> </Action>
