<Action id="22558" issue="15359" author="jimthematrix" type="comment" body=" ~harrisob@us.ibm.com  this bug has information on reproducing the grpc errors caused by network devices terminating the session" created="2017-04-17 04:57:02.0" updateauthor="jimthematrix" updated="2017-04-17 04:57:02.0"/>
<Action id="24244" issue="15359" author="jimthematrix" type="comment" body="Assigning this one to  ~harrisob@us.ibm.com  to investigate the impact of this network device behavior on the event stream b/w the app and peers" created="2017-05-24 14:55:43.0" updateauthor="jimthematrix" updated="2017-05-24 14:55:43.0"/>
<Action id="24709" issue="15359" author="rickr" type="comment" created="2017-05-30 22:07:08.0" updateauthor="rickr" updated="2017-05-30 22:08:52.0"> <body><! CDATA Java spec says  grpc will never go to idle mode once it has left that state  http://www.grpc.io/grpc-java/javadoc/io/grpc/ManagedChannelBuilder.html#idleTimeout-long-java.util.concurrent.TimeUnit-      ></body> </Action>
<Action id="25357" issue="15359" author="jimthematrix" type="comment" created="2017-06-05 15:02:18.0" updateauthor="jimthematrix" updated="2017-06-05 15:04:41.0"> <body><! CDATA https://gerrit.hyperledger.org/r/#/c/10095/  using keepalive settings from grpc 1.2.4 and 1.3.7 to keep the channel chatty enough so as to avoid the network devices cutting the wire in the middle.   ~ibmamnt  we are trying to set up an environment in softlayer to validate the fix. in the meanwhile if you can help verify the fix that'd be great.  ></body> </Action>
<Action id="27473" issue="15359" author="ibmamnt" type="comment" created="2017-06-28 07:12:49.0" updateauthor="ibmamnt" updated="2017-06-28 07:12:49.0"> <body><! CDATA  ~jimthematrix  Sorry about the long delay, I was able to test the case. Unfortunately, the result was negative. I still get timeout. First of all, should I set CORE_CHAINCODE_KEEPALIVE ?  I just read this issue, and it seems there is still a problem.   gRPC timeout b/w committer and orderer and SDK event listeners  https://jira.hyperledger.org/browse/FAB-3310  Here is my test environment.     Fabric : v1.0.0 beta (sorry this is team requested configuration for now)  SDK: v1.0.0-rc1 ( note about the version in-consistency )    I used "balance-transfer" sample. I modified app/network_config.json , config.json and testAPIs.sh to point to VM which runs on Softlayer.  The application run locally (i.e. on my machine inside IBM intranet).  I also modified testAPIs.sh to sleep 320 ( 5minutes + 20 seconds) such that it invokes transaction (invoke/query) after the sleep.   Here is a output from testAPIs.sh  ----  POST invoke chaincode on peers of Org1 and Org2 Transacton ID is 8580bfd63109b938f1713bd3da3688a7d0bf664bfd76fa8105d6350a088e827e   GET query chaincode on peer1 of Org1  a now has 80 after the move     Sleep 320 seconds 5minutes + 20 seconds POST invoke chaincode on peers of Org1 and Org2     Transacton ID is Failed to order the transaction. Error code: undefined GET query chaincode on peer1 of Org1   a now has Error: REQUEST_TIMEOUT after the move  --   Snippet of log output is attached as "nodejs-app-log.txt".   ></body> </Action>
<Action id="27474" issue="15359" author="ibmamnt" type="comment" body="I confirmed that setting &quot;CORE_CHAINCODE_KEEPALIVE=10&quot; did not resolve the problem. " created="2017-06-28 07:33:36.0" updateauthor="ibmamnt" updated="2017-06-28 07:33:36.0"/>
<Action id="30471" issue="15359" author="masaruhayakawa" type="comment" created="2017-09-02 18:47:03.0" updateauthor="masaruhayakawa" updated="2017-09-02 18:47:03.0"> <body><! CDATA if GRPC option was used, I also confirmed the behaviors of "keepalive" using the following environment.  <Environment> * HFC: 1.0.0 * Hyperledger facric: 1.0 * Node.js for HFC: 6.10.0  <How to specify the "keepalive" setting>      I specified GRPC options to "opts" parameter for the following methods in the HFC codes. * client.newOrderer(url, opts) * client.newPeer(url, opts) * eventhub.setPeerAddr(url, opts)  <Test result> |GRPC option|Behaviors if the connection is dropped on a network component| |No options|HFC could not detect the closed connection and could not receive any responses.| |grpc.http2.keepalive_time:  an int value grpc.http2.keepalive_timeout:  an int value|HFC could not detect the closed connection and could not receive any responses.| |grpc.http2.keepalive_time: an int value grpc.http2.keepalive_timeout: an int value grpc.http2.keepalive_permit_without_calls: 0|HFC could not detect the closed connection and could not receive any responses.| |grpc.http2.keepalive_time: an int value grpc.http2.keepalive_timeout: an int value grpc.http2.keepalive_permit_without_calls: 1|HFC executed "ping" 3 times and detected the closed connection. However, if HFC executed a transaction after 3 times "ping",  grpc error (Endopoint read failed) occurred. | |grpc.http2.keepalive_time: an int value grpc.http2.keepalive_timeout: an int value grpc.http2.keepalive_permit_without_calls: 1 grpc.http2.max_pings_without_data: an int value|HFC executed "ping" 3 times and detected the closed connection. However, even though the connection is normal (not dropped) ,  HFC closed the connection after 4 times "ping" regardless of the value of grpc.http2.max_pings_without_data.|     I could not understand why the behaviors became these results. II would like to know what causes these behaviors.        ></body> </Action>
<Action id="31167" issue="15359" author="jimthematrix@gmail.com" type="comment" body=" ~harrisob@us.ibm.com  can you take a look at the test results above from  ~MasaruHayakawa ?" created="2017-09-26 12:27:51.0" updateauthor="jimthematrix@gmail.com" updated="2017-09-26 12:27:51.0"/>
<Action id="31228" issue="15359" author="masaruhayakawa" type="comment" created="2017-09-28 12:17:09.0" updateauthor="masaruhayakawa" updated="2017-09-28 12:20:53.0"> <body><! CDATA I confirmed the behavior using the other versions.  <Environment #1 (previous test)> * HFC: 1.0.0 * Hyperledger facric: 1.0 * Node.js for HFC: 6.10.0 * GRPC: 1.24  <Environment #2)> * HFC: 1.0.2 * Hyperledger facric: 1.01 * Node.js for HFC: 6.10.0 * GRPC: 1.6  <Test result> |GRPC option|Behaviors if the connection is dropped on a network component|　| |　|Environment #1 (previous test)|Environment #2| |No options|HFC could not detect the closed connection and could not receive any responses.|HFC could not detect the closed connection and could not receive any responses.| |grpc.http2.keepalive_time:  an int value grpc.http2.keepalive_timeout:  an int value|HFC could not detect the closed connection and could not receive any responses.|HFC could not detect the closed connection and could not receive any responses.| |grpc.http2.keepalive_time: an int value grpc.http2.keepalive_timeout: an int value grpc.http2.keepalive_permit_without_calls: 0|HFC could not detect the closed connection and could not receive any responses.|HFC could not detect the closed connection and could not receive any responses.| |grpc.http2.keepalive_time: an int value grpc.http2.keepalive_timeout: an int value grpc.http2.keepalive_permit_without_calls: 1|HFC executed "ping" 3 times and detected the closed connection. However, if HFC executed a transaction after 3 times "ping",  grpc error (Endopoint read failed) occurred. |HFC executed "ping" 3 times and detected the closed connection. However, even though the connection is normal (not dropped) ,  HFC closed the connection after 4 times "ping".| |grpc.http2.keepalive_time: an int value grpc.http2.keepalive_timeout: an int value grpc.http2.keepalive_permit_without_calls: 1 grpc.http2.max_pings_without_data: an int value|HFC executed "ping" 3 times and detected the closed connection. However, even though the connection is normal (not dropped) ,  HFC closed the connection after 4 times "ping" regardless of the value of grpc.http2.max_pings_without_data.|HFC executed "ping" 3 times and detected the closed connection. However, even though the connection is normal (not dropped) ,  HFC closed the connection after 4 times "ping" regardless of the value of grpc.http2.max_pings_without_data.| |grpc.max_connection_idle_ms: int value grpc.max_connection_age_ms: int value grpc.max_connection_age_grace_ms: int value|These option can not be used at the version 1.24 of GRPC|The behavior was not changed.|   These options did not work as our expected behaviors as well.     ></body> </Action>
<Action id="31527" issue="15359" author="harrisob@us.ibm.com" type="comment" created="2017-10-02 16:50:26.0" updateauthor="harrisob@us.ibm.com" updated="2017-10-02 16:50:26.0"> <body><! CDATA In using:  ```  Node: 8.4.0  grpc: 1.6.0  fabric-client: 1.1.0-snapshot  ```     When the `grpc.keepalive_time_ms` is anything less than 6 minutes, there will be an error after 4 pings,  GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to "too_many_pings".  Other settings do not seem to change the results during my testing.  If there is an error callback registered, then the application will see this and other errors. An interval time of 6 minutes or above will continue to ping.  ></body> </Action>
<Action id="32949" issue="15359" author="denyeart" type="comment" body=" ~harrisob@us.ibm.com  Can you clarify your last comment?  Are you saying the the problem is not reproducible? Is there a change to investigate or are you saying you think it is ok as-is?" created="2017-10-20 19:22:15.0" updateauthor="denyeart" updated="2017-10-20 19:22:15.0"/>
<Action id="33135" issue="15359" author="harrisob@us.ibm.com" type="comment" created="2017-10-24 21:53:46.0" updateauthor="harrisob@us.ibm.com" updated="2017-10-24 21:53:46.0"> <body><! CDATA  ~denyeart  In a single box test environment (my laptop running both the client and docker compose) I was not able to maintain polling between the client and the peer unless the keep alive value was around 6 minutes. I do not have an environment with a network box that will quietly break the connection.   ~ibmamnt  are you still having an issue ?  ></body> </Action>
<Action id="33140" issue="15359" author="ibmamnt" type="comment" body=" ~harrisob@us.ibm.com   I no longer have the reproducible environment.  Our project has removed hardware firewall for now. We can not attach again since the project actually finished.  If someone inside IBM can order VM in Softlayer, and add me to the account space, I&apos;ll be able to re-create the reproducible environment (or test to see if latest code surely fixed the problem).  " created="2017-10-25 00:51:13.0" updateauthor="ibmamnt" updated="2017-10-25 00:51:13.0"/>
<Action id="33164" issue="15359" author="harrisob@us.ibm.com" type="comment" body="We may wish to have this as part of some broader test bucket." created="2017-10-25 15:00:06.0" updateauthor="harrisob@us.ibm.com" updated="2017-10-25 15:00:06.0"/>
<Action id="34352" issue="15359" author="mastersingh24" type="comment" created="2017-11-05 20:32:26.0" updateauthor="mastersingh24" updated="2017-11-05 20:39:21.0"> <body><! CDATA  ~harrisob@us.ibm.com   - regarding https://jira.hyperledger.org/browse/FAB-2787?focusedCommentId=31527&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-31527 , I just ran this with grpc@1.7.1 with *grpc.keepalive_time_ms=60000 (1 min)* and did not have any issues (as I post this it's been running for over 10 min)  Now if I set *grpc.keepalive_time_ms=10000* , then I get the GOAWAY after 4 pings.  This makes sense since the client policy for the gRPC server in the peer is 1 min.  In my test, I never really sent any data over the event hub connection so I also have to set *grpc.http2.min_time_between_pings_ms : 0*  ></body> </Action>
<Action id="34360" issue="15359" author="mastersingh24" type="comment" created="2017-11-06 10:39:53.0" updateauthor="mastersingh24" updated="2017-11-06 10:39:53.0"> <body><! CDATA  ~harrisob@us.ibm.com   ~jimthematrix@gmail.com   I'd suggest we do the following:  1) update to grpc@1.7.1  2) add setting *grpc.http2.min_time_between_pings_ms* in the code and docs  ></body> </Action>
<Action id="35415" issue="15359" author="denyeart" type="comment" body=" ~harrisob@us.ibm.com   ~bmos299  Barry, what is the plan for this one? Do you agree with Gari&apos;s recommendation? If so should we go ahead and re-assign back to fabric-sdk node so that the update can be made?" created="2017-11-27 01:21:20.0" updateauthor="denyeart" updated="2017-11-27 01:21:20.0"/>
<Action id="38301" issue="15359" author="jonathanlevi" type="comment" body="What&apos;s the latest here, please?" created="2018-01-08 16:48:10.0" updateauthor="jonathanlevi" updated="2018-01-08 16:48:10.0"/>
<Action id="38916" issue="15359" author="clayton sims" type="comment" body=" ~harrisob@us.ibm.com   ~bmos299   whats the latest ?" created="2018-01-19 22:22:18.0" updateauthor="clayton sims" updated="2018-01-19 22:22:18.0"/>
<Action id="40347" issue="15359" author="denyeart" type="comment" body=" ~harrisob@us.ibm.com  Do you agree to proceed with Gari&apos;s suggestion for 1.1?" created="2018-02-18 14:36:11.0" updateauthor="denyeart" updated="2018-02-18 14:36:11.0"/>
<Action id="40439" issue="15359" author="harrisob@us.ibm.com" type="comment" created="2018-02-20 19:04:43.0" updateauthor="harrisob@us.ibm.com" updated="2018-02-20 19:06:04.0"> <body><! CDATA grpc will load 1.9.1 (latest)   https://gerrit.hyperledger.org/r/#/c/18095/   |https://gerrit.hyperledger.org/r/#/c/18095/   adds the min ping time  ></body> </Action>
<Action id="40592" issue="15359" author="harrisob@us.ibm.com" type="comment" created="2018-02-22 19:40:33.0" updateauthor="harrisob@us.ibm.com" updated="2018-02-22 19:40:33.0"> <body><! CDATA fixed the options issue  https://gerrit.hyperledger.org/r/#/c/18219/  ></body> </Action>
