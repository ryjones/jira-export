<Issue id="15359" key="FABN-481" number="481" project="10604" reporter="ibmamnt" assignee="harrisob@us.ibm.com" creator="ibmamnt" type="10004" summary="Client app timeout when the gRPC session is closed by network equipment (LB and/or Firewall)" priority="1" resolution="10000" status="6" created="2017-03-15 04:09:10.0" updated="2018-07-19 00:54:14.0" resolutiondate="2018-02-23 18:20:44.0" votes="3" watches="15" workflowId="34212"> <description><! CDATA Summary: Client app using node SDK hangs when gRPC session is closed, hence it won't return expected result.  Details: Here is a setup:  App on Cloud (e.g. Bluemix) ->    Firewall   ->   Hyperledger VM    gRPC session becomes IDLE when 300 seconds has passed according to gRPC spec. https://github.com/grpc/grpc/blob/master/doc/connectivity-semantics-and-api.md  And it is very common to close IDLE session by network equipment so that tcp connection can be reused by another process. For example, AWS LB killed idle connection within 60 sec. LB does not  kill connection when "keep alive" is set. gRPC does not have that option. As a result, gRPC call  wait for reply from the closed connection. Typical sympton is as follows (when GRPC_VERBOSITY=DEBUG; GRPC_TRACE=all; DEBUG=hfc is set).  ---- D0314 15:55:52.345432506   14837 tcp_posix.c:405             WRITE 0x7f9470000cb0 (peer=ipv4:X.X.X.X:17054): 00 00 09 01 04 00 00 00 03 c6 c5 c4 c3 c2 c1 '...............' D0314 15:55:52.345438187   14837 tcp_posix.c:405             WRITE 0x7f9470000cb0 (peer=ipv4:X.X.X.X:17054): c0 bf be 00 00 04 08 00 00 00 00 03 00 00 ff '...............' D0314 15:55:52.345443035   14837 tcp_posix.c:405             WRITE 0x7f9470000cb0 (peer=ipv4:X.X.X.X:17054): ff 00 00 bf 00 01 00 00 00 03 00 00 00 00 ba '...............' D0314 15:55:52.345455006   14837 tcp_posix.c:405             WRITE 0x7f9470000cb0 (peer=ipv4:X.X.X.X:17054): 0a 06 08 f8 a7 9e c6 05 12 0d 0a 0b 57 65 62 41 70 70 41 64 6d 69 6e 18 01 2a 9e 01 12 4d 39 32 36 36 34 39 39 34 34 30 34 36 31 35 30 38 36 32 39 39 39 39 31 34 34 37 37 35 30 35 37 31 31 30 31 33 34 36 34 39 30 39 38 32 35 31 31 37 33 36 37 38 38 32 34 33 34 34 30 38 36 33 37 37 32 34 32 39 30 32 30 38 34 34 33 37 32 1a 4d 36 33 33 35 31 33 31 30 31 30 38 39 34 30 33 35 30 35 36 39 33 39 35 39 35 32 31 32 34 36 37 38 33 38 37 32 34 32 33 35 31 31 35 31 33 32 31 38 31 38 37 38 33 35 30 37 37 31 31 30 32 35 33 33 30 35 38 38 33 35 38 32 30 38 30 31 32 '............WebAppAdmin..*...M92664994404615086299991447750571101346490982511736788243440863772429020844372.M63351310108940350569395952124678387242351151321818783507711025330588358208012' D0314 15:55:52.345492342   14837 chttp2_transport.c:675      W:0x7f9470000e50 WRITING -> INACTIVE because terminate_writing ----  The app wait for reply from the channel.   The attaches file "session alive.txt" is when the application runs on the same machine (VM). In this case, session is not closed. Hence peer process replies even after IDLE session. "session down case.txt" is when the session is closed by network equipment.  The return value of gRPC is code: 14 (Unavailable). gRPC specification states that it should re-try by fallback.  How-to-reproduce the problem ------------ - setup Hyperledger in Cloud (e.g. Softlayer). - setup app in another Cloud (e.g. Bluemix CF runtime).  The app should look like this. Invoke chaincode, and then wait for 6 minutes, and then run query.  invoke(webappadmin); admin = webappadmin;  setInterval(loopQuery, 6*60*1000);  });  function loopQuery() { console.log("looping query"); query(admin); }   Suggested fix. SDK should check if the session is alive, if it is not unavailable it should re-try (or re-open) the connection.   Potentially, this problem happen even in Hyperledger fabric v1.0.   ></description> </Issue>
