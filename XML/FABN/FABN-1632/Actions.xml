<Action id="70164" issue="45990" author="yacovm" type="comment" created="2020-09-08 23:28:36.0" updateauthor="yacovm" updated="2020-09-08 23:28:36.0"> <body><! CDATA {quote}Have the SDK at least remember the last orderer (or peer) that worked and continue to use that one until it fails. At which point the SDK can go through the list and select a new endpoint like it does today. The benefit of this is the SDK only needs to remember one bit of information and there's no complex cases around removing possible nodes from the list, how often to recheck, when to add them back, etc. The downside is this does not load balance at all, but neither does the current approach. {quote} You can perhaps do a variation of this- if the list doesn't exist, fetch it. When you fetch the list, to re-arrange it randomly and then pick the next orderer in the list, try it, and if it fails go to the next, etc. When finding one that is "good", move it to the beginning of the list. It should provide some degree of load balancing across different clients.  ></body> </Action>
<Action id="70176" issue="45990" author="harrisob@us.ibm.com" type="comment" created="2020-09-09 16:58:15.0" updateauthor="harrisob@us.ibm.com" updated="2020-09-09 16:58:15.0"> <body><! CDATA So what if we fetch the list and cache it for the user's acceptable time (default 5 minutes) and then on each NodeSDK submit, randomize the list. Check the connection of the first one on the randomized list and if successful send the commit request. If either actions fail, try the next on the list. When the connection check fails, remove the orderer from the list. If and when it becomes active again, discovery will put it on the fetched list.  This will provide fail over and load balancing.  ></body> </Action>
<Action id="70179" issue="45990" author="denyeart" type="comment" created="2020-09-09 19:06:48.0" updateauthor="denyeart" updated="2020-09-09 19:06:48.0"> <body><! CDATA {quote}If and when it becomes active again, discovery will put it on the fetched list.{quote}  Service Discovery doesn't check liveness of ordering service nodes, since orderers don't participate in gossip. So the onus would be on the client to get the configured list of orderers from Service Discovery and manage the live/dead statuses, list reset, and handle special cases such as when all orderers get restarted (assumption is you wouldn't want to wait for the full 5 minute cycle to reset the list). This could all be done, but starts to get into the challenges and complexity that Paul mentioned in #3. Yacov's proposal is simpler, although doesn't load balance across orderers within the context of a single application client, only across multiple application clients.  Any of these options would be a big improvement, but to Paul's point complexity and speed of a fix should be considered.  ></body> </Action>
<Action id="70180" issue="45990" author="ptippett" type="comment" created="2020-09-09 19:47:02.0" updateauthor="ptippett" updated="2020-09-09 19:55:06.0"> <body><! CDATA I was waiting to see how a node would get put back after being removed.  Too bad that doesn't work.  Having to manage removing nodes from the list then figuring out how quickly to add them back without something else handling that seems troublesome.     I like Yacov's proposal but would modify it to have the SDK keep reusing the last orderer that worked vs rearranging the list.  I guess they aren't much different other than if the one it's using fails, which one does it try next and whether the SDK has to remember anything other than the list itself.  I like the sticky approach because even if several orderers were dead, the SDK would quickly find a good one and as long as that one stayed working, nothing would need to change.  I was thinking about what happens each time the orderer the SDK is using fails.  It seems it could either move to the next one without touching the current list, or randomize the list again as if pulling it for the first time and start all over.  I suppose randomizing the list again would be unnecessary since each client would have a random list and if over time they all ended up on one or two orderers, a restart of that node would cause them all to scatter again.  Agree that it would only load balance if there were multiple clients, but it seems like without some sort of automatic health check that manages the list, load balancing between a single client is more complex and doesn't add that much more.  When would the list normally get refreshed?  For example, today, if I add a new orderer node to a cluster, when would the SDK pick that up in the list of possible orderer endpoints it could use?  ></body> </Action>
<Action id="70181" issue="45990" author="denyeart" type="comment" created="2020-09-09 20:42:23.0" updateauthor="denyeart" updated="2020-09-09 20:45:17.0"> <body><! CDATA {quote}I like Yacov's proposal but would modify it to have the SDK keep reusing the last orderer that worked vs rearranging the list. {quote}  Yacov's proposal DOES have the SDK keep using the last orderer that worked. So I think we all agree it is a good and simple approach.  SDK requests fresh Service Discovery results every 5 minutes by default. So perhaps tweak Yacov's proposal to also refresh the list after each interval, and also if none of the list members are responding after trying them all. If the orderer "currently in use" is still in the refreshed list then continue using it. This would provide continuity of service, even if orderers all restart or if orderers are replaced.  ></body> </Action>
<Action id="70182" issue="45990" author="ptippett" type="comment" body="That sounds good to me." created="2020-09-09 21:07:17.0" updateauthor="ptippett" updated="2020-09-09 21:07:17.0"/>
<Action id="70188" issue="45990" author="harrisob@us.ibm.com" type="comment" created="2020-09-10 15:21:45.0" updateauthor="harrisob@us.ibm.com" updated="2020-09-10 15:21:45.0"> <body><! CDATA How about when we submit to be committed when using discovery: * fetch the list and cache it (default 5 minutes), connect to new orderers or reconnect to existing orderers that are disconnected * randomize the list * first pass through list, check connection status of the orderer, if connected, send the commit, if success we are done, else check next * if not done, second pass through list, try reconnect, if connected, send the commit, if success we are done, else check next  Notice how this will first try to use orderers first that are known connected, load balancing by randomizing  Notice how this will fail over to use another orderer and only try to reconnect after all known good orderers fail  Notice how this will reconnect an off line orderer during the refresh interval. An orderer that has been reconnected will now be marked as connected and will be available during the first pass for load balancing along with other connected orderers.     ></body> </Action>
<Action id="70189" issue="45990" author="denyeart" type="comment" body="Ok, that does sound better Bret. It meets all the requirements, only slightly more complicated than Yacov&apos;s proposal, and provides randomized load balancing." created="2020-09-10 16:00:55.0" updateauthor="denyeart" updated="2020-09-10 16:00:55.0"/>
<Action id="70190" issue="45990" author="lesleyannj" type="comment" body="Solution requested in 2.x and 1.4" created="2020-09-10 16:21:23.0" updateauthor="lesleyannj" updated="2020-09-10 16:21:23.0"/>
<Action id="70191" issue="45990" author="ptippett" type="comment" body="Agreed.  This sounds good.  Is the list randomized every 5 minutes or on every transaction?" created="2020-09-10 16:36:50.0" updateauthor="ptippett" updated="2020-09-10 16:36:50.0"/>
<Action id="70192" issue="45990" author="harrisob@us.ibm.com" type="comment" body="Every call, to load balance" created="2020-09-10 16:56:21.0" updateauthor="harrisob@us.ibm.com" updated="2020-09-10 16:56:21.0"/>
<Action id="70200" issue="45990" author="yacovm" type="comment" created="2020-09-10 17:28:02.0" updateauthor="yacovm" updated="2020-09-10 17:28:02.0"> <body><! CDATA {quote}Every call, to load balance {quote} I am not sure it's such a good idea to do a discovery query prior to every transaction :)     Let's keep it once in a while.  ></body> </Action>
