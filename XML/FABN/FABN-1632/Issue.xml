<Issue id="45990" key="FABN-1632" number="1632" project="10604" reporter="ptippett" assignee="JIRAUSER20949" creator="ptippett" type="10001" summary="Improve SDK load balancing and fail-over for ordering service nodes" priority="2" resolution="10000" status="6" created="2020-09-08 22:50:45.0" updated="2020-10-16 18:17:28.0" resolutiondate="2020-09-15 12:56:44.0" votes="0" watches="5" workflowId="59901" archived="N"> <description><! CDATA Currently, at least for the Node SDK, when using service discovery and selecting which orderer to use when submitting a transaction, the SDK will iterate through the list of available orderers in the same sequence on each transaction.     This is far from ideal since if the orderer(s) at the front of the list are offline, the application will need to wait for those to time out and for the SDK to find a good orderer on each and every transaction.  Users are reporting that this causes delays in their application.     There are several complex ways to solve this, but some possible simpler ones are:  1 - Have the SDK at least remember the last orderer (or peer) that worked and continue to use that one until it fails.  At which point the SDK can go through the list and select a new endpoint like it does today.  The benefit of this is the SDK only needs to remember one bit of information and there's no complex cases around removing possible nodes from the list, how often to recheck, when to add them back, etc.  The downside is this does not load balance at all, but neither does the current approach.     2 - Have the SDK continue to go through the list on every call, but randomize the list each time so that the orderer it picks will be different.  The benefit of this approach is the SDK doesn't have to remember anything since it's only changing the order of the list each time.  Downsides I see are the time it takes to randomize the list if done on every transaction (this could be negligible however) and the fact that if a high percentage of the orderers or peers are bad (2 bad out of 3 for example), you'd still hit the bad one around 67% of the time.     3 - Some variation of option 2 where the bad endpoint(s) are removed from the list and put back later.  The complexity here is you'd have to keep track of who you removed and periodically put them back after some amount of time.  One issue I see here is during a rolling restart you may end up in a case where ALL of them have been removed and none added back yet, so the edge cases here concern me.     These are what I came up with quickly.  I'm sure there are better ones.     A couple of other things:  1 - It'd be nice to get something simpler that improves the current behavior without much effort vs waiting for a more complex solution that may scale or load balance better, etc. 2 - I also believe that while it'd be nice for all SDKs to behave the same, I think the priority should be node, then java, then go or others.  In short, don't wait to fix it in all of them before releasing one of them.     Listing as high since we have users with this issue and since there's a big push to set up multiple distributed nodes for high availability but at med to high transaction rates, the sdk behavior still causes unacceptable delays if a component is taken offline.  ></description> </Issue>
