<Action id="63952" issue="42364" author="denyeart" type="comment" body=" ~silentspark Any idea which CouchDB release will include the fix?" created="2019-09-23 03:11:48.0" updateauthor="denyeart" updated="2019-09-23 03:11:48.0"/>
<Action id="64203" issue="42364" author="silentspark" type="comment" created="2019-09-30 11:21:07.0" updateauthor="silentspark" updated="2019-09-30 11:21:07.0"> <body><! CDATA I've no idea about CouchDB release plan. However, even I retrofitted couchdb v2.2.0 with timeout fix #2153 above and built a new image,  couchdb somehow still gets error during block commit which results in peer crash. Peer code should handle couchdb error properly. {code:java} {"log":" error  2019-09-26T06:42:05.043417Z nonode@nohost \u003c0.19232.14\u003e e1b783c110 req_err(1436168396) unknown_error : function_clause\n","stream":"stderr","time":"2019-09-26T06:42:05.937923806Z"} {"log":"     \u003c\u003c\"couch_mrview_http:view_cb/2 L338\"\u003e\u003e,\u003c\u003c\"chttpd_db:all_docs_view/4 L690\"\u003e\u003e,\u003c\u003c\"chttpd:handle_req_after_auth/2 L317\"\u003e\u003e,\u003c\u003c\"chttpd:process_request/1 L300\"\u003e\u003e,\u003c\u003c\"chttpd:handle_request_int/1 L240\"\u003e\u003e,\u003c\u003c\"mochiweb_http:headers/6 L124\"\u003e\u003e,\u003c\u003c\"proc_lib:init_p_do_apply/3 L240\"\u003e\u003e \n","stream":"stderr","time":"2019-09-26T06:42:05.937972642Z"}{code}    !image-2019-09-30-19-17-38-993.png!  ></body> </Action>
<Action id="65690" issue="42364" author="denyeart" type="comment" body=" ~silentspark  Do you expect a retry to couchdb would be successful? Do you know what HTTP response CouchDB returns in this scenario? Peer does retries for most CouchDB interactions, that can be investigated for this integration as well." created="2019-11-21 14:32:06.0" updateauthor="denyeart" updated="2020-01-30 19:06:57.0"/>
<Action id="65776" issue="42364" author="silentspark" type="comment" body="Hi  David, after debug, it turn to the disk I/O problem causes abnormal response from couchdb，which makes the peer crash. I&apos;ll close this issue" created="2019-11-26 04:48:43.0" updateauthor="silentspark" updated="2019-11-26 04:48:43.0"/>
<Action id="65777" issue="42364" author="silentspark" type="comment" body="Caused by disk I/O problem" created="2019-11-26 04:50:45.0" updateauthor="silentspark" updated="2019-11-26 04:50:45.0"/>
<Action id="65791" issue="42364" author="kolayuk" type="comment" body=" ~silentspark  Hello! What&apos;s exactly problem with I/O? Slow disk, lack of file handlers, etc? And could you point how to debug it, how did you understood that reason of couchdb&apos;s error is I/O?" created="2019-11-27 07:56:49.0" updateauthor="kolayuk" updated="2019-11-27 07:56:49.0"/>
<Action id="66273" issue="42364" author="rajatsharma" type="comment" created="2019-12-16 12:57:09.0" updateauthor="rajatsharma" updated="2019-12-16 12:57:09.0"> <body><! CDATA  ~denyeart   ~silentspark , Even I'm encountering this issue. This got resolved by restarting the peers.  I didn't get why was this ticket closed?  This issue should be handled, from the peer.      ></body> </Action>
<Action id="67750" issue="42364" author="denyeart" type="comment" body="While the underlying issue is in CouchDB, I agree this ticket can be re-opened to investigate more graceful handling of the error from peer." created="2020-01-30 19:10:01.0" updateauthor="denyeart" updated="2020-01-30 19:10:01.0"/>
<Action id="67751" issue="42364" author="denyeart" type="comment" body="Another occurrence reported at https://lists.hyperledger.org/g/fabric/message/7645" created="2020-01-30 19:11:24.0" updateauthor="denyeart" updated="2020-01-30 19:11:24.0"/>
<Action id="69126" issue="42364" author="mastersingh24" type="comment" created="2020-05-01 10:08:52.0" updateauthor="mastersingh24" updated="2020-05-01 10:08:52.0"> <body><! CDATA Was the peer panicking here?  Not clear from the error if that's the case. As I recall, if the peer cannot write the state from a valid commit to the state db, it will panic. A better way to handle this would be to stop processing for the channel where this happens rather than bringing down the whole peer.  ></body> </Action>
<Action id="69966" issue="42364" author="rajatsharma" type="comment" created="2020-08-17 09:10:19.0" updateauthor="rajatsharma" updated="2020-08-17 09:10:19.0"> <body><! CDATA  ~mastersingh24   ~denyeart ,  We're repeatedly getting this issue, while we did not find anything unusual in server usage. Is there any solution for this?  Is this issue resolved in any further versions?      ></body> </Action>
<Action id="69967" issue="42364" author="denyeart" type="comment" created="2020-08-17 12:24:46.0" updateauthor="denyeart" updated="2020-08-17 12:24:46.0"> <body><! CDATA  ~Rajatsharma  The root cause is a CouchDB error. Can you determine why your CouchDB returns an error in this environment?  Can you provide CouchDB log and peer log, ideally with peer logging set to {code:java} FABRIC_LOGGING_SPEC=info:statecouchdb,couchdb=debug{code} When CouchDB returns this error, is the peer doing retries? Would you expect subsequent retries to be successful when CouchDB returns this error?  Can you be more specific on the fix you are looking for... what would you expect peer to do when CouchDB cannot commit.  ></body> </Action>
<Action id="70102" issue="42364" author="rajatsharma" type="comment" created="2020-08-31 06:23:14.0" updateauthor="rajatsharma" updated="2020-08-31 06:23:14.0"> <body><! CDATA  ~denyeart , This issue is very aberrant. Still, we've changed the logging level and I'll send you logs as soon as we encounter this issue again.  We were running the peer with info logging and by seeing peer and CouchDB logs, we could only see a single request and on receiving that the peer goes down.   Ideally, if it retries then it should work normally. We are just aiming to find a way that peers either retries for a while and the whole peer process are not killed just after a single try.   ></body> </Action>
<Action id="70156" issue="42364" author="rajatsharma" type="comment" created="2020-09-08 09:29:42.0" updateauthor="rajatsharma" updated="2020-09-08 09:29:42.0"> <body><! CDATA  ~denyeart   ~mastersingh24 ,  Here I'm attaching the logs of the peers and couchDB. We experienced this issue on 2020-09-03 09:40:37.314. The sar memory output for that instance was high. Please look into the logs and let us know if there's any viable solution for this.    ^couch-logs.txt   ^peer-logs.txt   ^peer-memory-sar.txt   ></body> </Action>
<Action id="70175" issue="42364" author="rajatsharma" type="comment" created="2020-09-09 16:40:17.0" updateauthor="rajatsharma" updated="2020-09-09 16:40:17.0"> <body><! CDATA  ~denyeart   ~mastersingh24  ,  As Fabric still does not have support for couchDB 3.0.1. We're stuck with this issue and we're getting this repeatedly, earlier restarting the peer was solving this but we encountered this now even in the peer initialize and the peer is not starting.  This is the log message:  ^peer-start.log   ></body> </Action>
<Action id="70681" issue="42364" author="manish-sethi" type="comment" body=" ~wenjian  - can you take a look at this" created="2020-11-16 18:08:54.0" updateauthor="manish-sethi" updated="2020-11-16 18:08:54.0"/>
<Action id="70761" issue="42364" author="denyeart" type="comment" created="2020-11-19 21:04:15.0" updateauthor="denyeart" updated="2020-11-19 21:04:15.0"> <body><! CDATA The root cause is an error returned from CouchDB during a chunked (streaming) response of all_docs query. For these types of responses, CouchDB initially returns back a 200 OK status and then streams the response back to the caller. In the logs provided, CouchDB hit a badmatch/timeout error after streaming the response for 10 seconds, and therefore peer was not able to process the commit. When peer cannot process a commit it crashes. Many operators prefer to automatically restart the peer and CouchDB containers in these situations. Retries against CouchDB may continue to fail when CouchDB is not responding.  Fabric v2.2 added support for CouchDB 3.1.x. The original poster thought the issue was resolved in this CouchDB version. Regardless, CouchDB 3.1.1 offers a new config option  chttpd  buffer_response=true which disables streaming, so that CouchDB can return the final error code and payload together. In these cases, CouchDB would return a 500. Peer performs retries on CouchDB responses of 500.  Suggestion is to move to Fabric v2.2.x (LTS release) with CouchDB 3.1.1, and if problem still occurs on CouchDB 3.1.1, enable  chttpd  buffer_response=true. As we expect this will resolve the problem, issue will be closed, but please re-open if you continue to see issue on Fabric v2.2.x with CouchDB 3.1.1.  ></body> </Action>
