<Action id="64900" issue="42552" author="wlahti" type="comment" body="Hit again today:  https://jenkins.hyperledger.org/job/fabric-verify-integration-tests-x86_64/12339/console " created="2019-10-23 16:09:41.0" updateauthor="wlahti" updated="2019-10-23 16:09:41.0"/>
<Action id="65049" issue="42552" author="sykesm" type="comment" body="Again: https://jenkins.hyperledger.org/job/fabric-verify-integration-tests-x86_64/12394/console" created="2019-10-28 20:20:44.0" updateauthor="sykesm" updated="2019-10-28 20:20:44.0"/>
<Action id="65050" issue="42552" author="sykesm" type="comment" body=" ~yacovm  it looks like this is related to gossip. Any chance you can take a peek?" created="2019-10-28 20:21:09.0" updateauthor="sykesm" updated="2019-10-28 20:21:09.0"/>
<Action id="65051" issue="42552" author="yacovm" type="comment" created="2019-10-28 20:26:58.0" updateauthor="yacovm" updated="2019-10-28 20:26:58.0"> <body><! CDATA yeah i noticed them appearing.  This is private data related and you guys have been messing with it lately ;)  basically " error: private data matching public hash version is not available." means that the peer hasn't received the private data.  If you can tell me the sub-test to focus on (ginkgo --focus) I can try and have a look...   ></body> </Action>
<Action id="65052" issue="42552" author="wlahti" type="comment" created="2019-10-28 20:33:41.0" updateauthor="wlahti" updated="2019-10-28 20:33:41.0"> <body><! CDATA Re-running locally with some of the gossip loggers set to debug. Once I hit the flake again, I'll share those.  When the flake occurs, the two peers in Org1 are no longer connected via gossip (i.e. they have both called "expireDeadMembers" for the other peer in the org). This causes the peer that wasn't involved in the approval step to be unable to retrieve the private data from the other peer in its org.   ></body> </Action>
<Action id="65053" issue="42552" author="sykesm" type="comment" created="2019-10-28 20:35:10.0" updateauthor="sykesm" updated="2019-10-28 20:35:10.0"> <body><! CDATA And again.  https://jenkins.hyperledger.org/job/fabric-verify-integration-tests-x86_64/12395/  ></body> </Action>
<Action id="65054" issue="42552" author="wlahti" type="comment" body="I&apos;m able to replicate this locally by focusing &quot;deploys and executes chaincode using _lifecycle and upgrades it&quot; in  lifecycle_test.go and running &quot;ginkgo -untilItFails&quot;. It can happen anywhere between 3 and 40+ runs of the test, so I have everything commented out below where the failure occurs (aka starting with &quot;// By(&quot;setting the correct package ID to restore the chaincode&quot;)&quot;) to save a little time." created="2019-10-28 20:36:46.0" updateauthor="wlahti" updated="2019-10-28 20:39:05.0"/>
<Action id="65056" issue="42552" author="wlahti" type="comment" created="2019-10-28 20:52:47.0" updateauthor="wlahti" updated="2019-10-28 20:54:57.0"> <body><! CDATA Added the logs with the following spec: "gossip.privdata,gossip.comm,gossip.discovery=DEBUG:INFO".  The error occurs while Org1.peer1 is validating block 4.  {code:java}  e  Org1.peer1  2019-10-28 16:47:23.316 EDT  gossip.privdata  listMissingPrivateData -> DEBU 144 Retrieving private write sets for 1 transactions from transient store  e  Org1.peer1  2019-10-28 16:47:23.316 EDT  gossip.privdata  StoreBlock -> DEBU 145  testchannel  Could not find all collection private write sets in local peer transient store for block  4 .  e  Org1.peer1  2019-10-28 16:47:23.316 EDT  gossip.privdata  StoreBlock -> DEBU 146  testchannel  Fetching 1 collection private write sets from remote peers for a maximum duration of 15s  e  Org1.peer1  2019-10-28 16:47:23.316 EDT  gossip.privdata  func1 -> DEBU 147 Fetching {2587fd87cdfae2ba7068d1f8783a366ee509a1cad9ad27aca8ff4eb549cf2075 0 _lifecycle _implicit_org_Org1MSP 76bb731cba4046413906bdaee4f98f4a210c21a13dedb1207c0158b2f02a281b} from peers  e  Org1.peer1  2019-10-28 16:47:23.316 EDT  gossip.privdata  fetchPrivateData -> DEBU 148 Total members in channel:  Endpoint: 127.0.0.1:22019, InternalEndpoint: , PKI-ID: 5f4cd15f35c33a735f4c82e00d5d146eec2eba93674ea0ad13cd0079efc928cc, Metadata:  Endpoint: 127.0.0.1:22014, InternalEndpoint: , PKI-ID: b969f93560cc9c72f91ee3b441ea4b2368c4d6a399d4f5c64d2f431589987b95, Metadata:    e  Org1.peer1  2019-10-28 16:47:23.316 EDT  gossip.privdata  fetchPrivateData -> DEBU 149 Total members that fit some digest:     e  Org1.peer1  2019-10-28 16:47:23.316 EDT  gossip.privdata  fetchPrivateData -> WARN 14a Do not know any peer in the channel( testchannel ) that matches the policies , aborting  e  Org1.peer1  2019-10-28 16:47:23.316 EDT  gossip.privdata  fetchFromPeers -> WARN 14b Failed fetching private data for block 4 from peers: Empty membership {code}  ></body> </Action>
<Action id="65062" issue="42552" author="yacovm" type="comment" created="2019-10-28 22:56:38.0" updateauthor="yacovm" updated="2019-10-28 22:56:38.0"> <body><! CDATA I think that: {quote} e  Org1.peer0  2019-10-28 16:47:22.587 EDT  gossip.comm  createConnection -> DEBU 1d4 Entering 9.27.111.31:22009 7b3a51ac125fcf06ace7d6af1795e686911fa9fd63c6152d6c7d5c952618b422{quote}  might be the problem... I'll take another glance tomorrow   ></body> </Action>
<Action id="65168" issue="42552" author="wlahti" type="comment" body="After looking at entirely too many logs, I noticed that it was taking just over 15 seconds for most of the successful test runs to retrieve the private data from the other peer in the org. Increasing the gossip.pvtData.pullRetryThreshold from 15 to 30 seconds seems to have helped locally so far, so I&apos;ve pushed a CR to see if the same appears to be true in CI:  https://gerrit.hyperledger.org/r/c/fabric/+/34152 ." created="2019-10-29 20:50:27.0" updateauthor="wlahti" updated="2019-10-29 20:50:27.0"/>
