<Issue id="30122" key="FAB-10008" number="10008" project="10002" reporter="yacovm" assignee="yacovm" creator="yacovm" type="10001" summary="Fine tune pull parameters" priority="3" resolution="10000" status="6" created="2018-05-10 21:35:05.0" updated="2018-07-20 18:50:47.0" resolutiondate="2018-05-11 01:11:32.0" votes="0" watches="1" workflowId="42141"> <description><! CDATA Gossip pull is configured by the following parameters with the given default values:  Â  {code:java} # Determines frequency of pull phases(unit: second) pullInterval: 4s # Time to wait before pull engine processes incoming digests (unit: second) digestWaitTime: 1s # Time to wait before pull engine removes incoming nonce (unit: second) requestWaitTime: 1s # Time to wait before pull engine ends pull (unit: second) responseWaitTime: 2s{code}  The pull protocol works as follows: # The initiator, once every *pull interval* sends a hello message to some peers # Each responding peer, upon receiving a hello - replies with a digest, and promises to send a response if received a request for the digest(s) before *requestWaitTime* expires. # The initiator gathers waits *digestWaitTime* to collect all digests from the responding peers, and allocates the requests according to digests and sends back requests accordingly.  # Each responding peer sends back a response with data # The initiator waits *responseWaitTime* to all responses.  The default values of *digestWaitTime* and *requestWaitTime* are 1 second which aren't optimal... we should increase the *requestWaitTime* slightly.     ~C0rWin   I tested with the following test: {code} func TestPull(t *testing.T) { 	portPrefix := 5610 	algo.SetDigestWaitTime(time.Duration(300) * time.Millisecond) 	algo.SetRequestWaitTime(time.Duration(310) * time.Millisecond)  	//algo.SetRequestWaitTime(time.Duration(300) * time.Millisecond)  	algo.SetResponseWaitTime(time.Duration(200) * time.Millisecond)  	stopped := int32(0) 	go waitForTestCompletion(&stopped, t)  	n := 10 	msgsCount2Send := 10  	peers := make(  Gossip, n) 	wg := sync.WaitGroup{} 	wg.Add(n) 	for i := 1; i <= n; i++ { 		go func(i int) { 			defer wg.Done() 			pI := newGossipInstanceWithOnlyPull(portPrefix, i, 100, 0) 			pI.JoinChan(&joinChanMsg{}, common.ChainID("A")) 			pI.UpdateLedgerHeight(1, common.ChainID("A")) 			peers i-1  = pI 		}(i) 	} 	wg.Wait()  	time.Sleep(time.Second)  	boot := newGossipInstanceWithOnlyPull(portPrefix, 0, 100) 	boot.JoinChan(&joinChanMsg{}, common.ChainID("A")) 	boot.UpdateLedgerHeight(1, common.ChainID("A"))  	knowAll := func() bool { 		for i := 1; i <= n; i++ { 			neighborCount := len(peers i-1 .Peers()) 			if n != neighborCount { 				return false 			} 		} 		return true 	}  	receivedMessages := make(  int, n) 	wg = sync.WaitGroup{} 	wg.Add(n) 	for i := 1; i <= n; i++ { 		go func(i int) { 			acceptChan, _ := peers i-1 .Accept(acceptData, false) 			go func(index int, ch <-chan *proto.GossipMessage) { 				defer wg.Done() 				for j := 0; j < msgsCount2Send; j++ { 					<-ch 					receivedMessages index ++ 				} 			}(i-1, acceptChan) 		}(i) 	}  	waitUntilOrFail(t, knowAll)  	t1 := time.Now() 	for i := 1; i <= msgsCount2Send; i++ { 		boot.Gossip(createDataMsg(uint64(i),   byte{}, common.ChainID("A"))) 	}  	receivedAll := func() bool { 		for i := 0; i < n; i++ { 			if msgsCount2Send != receivedMessages i  { 				return false 			} 		} 		return true 	} 	waitUntilOrFailBlocking(t, wg.Wait) 	waitUntilOrFail(t, receivedAll) 	fmt.Println("Elapsed:", time.Since(t1)) } {code}  When the total pull interval is 1 second. When the request wait time and digest wait time are *both 300ms* the sync time is pretty lousy:  {code} Elapsed: 12.332810378s Elapsed: 22.328394203s Elapsed: 10.33719305s Elapsed: 19.365986459s Elapsed: 9.323892933s Elapsed: 5.341059941s Elapsed: 14.320656216s Elapsed: 9.330490205s Elapsed: 8.334320911s Elapsed: 14.365369576s Elapsed: 10.345410596s Elapsed: 14.312947752s Elapsed: 12.314239796s Elapsed: 10.33379929s Elapsed: 19.349245746s Elapsed: 9.334648385s {code}  Once I gave 10 more milliseconds to the request wait time (310ms total instead of 300ms) the times improved significantly: {code} Elapsed: 1.324676655s Elapsed: 2.305325138s Elapsed: 2.319018949s Elapsed: 1.313411938s Elapsed: 2.319686774s Elapsed: 2.333012902s Elapsed: 1.354115248s Elapsed: 2.325411354s Elapsed: 2.318554851s Elapsed: 2.314270934s Elapsed: 2.324762851s Elapsed: 2.341140647s Elapsed: 2.328180085s Elapsed: 1.322969532s Elapsed: 1.32131714s  {code}   ></description> </Issue>
