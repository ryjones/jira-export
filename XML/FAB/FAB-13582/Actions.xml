<Action id="55559" issue="36588" author="mastersingh24" type="comment" created="2019-01-11 19:32:19.0" updateauthor="mastersingh24" updated="2019-01-11 19:45:49.0"> <body><! CDATA I'm not quite sure I understand the first phase (or why it's needed).  If we are going to do this (which we should), should just do phase 2 and remove any build/deploy of images/containers from the peer (clearly we'd need to keep some level of support for backwards compatibility, but the new model should not involve the peer building / launching anything).  Very much looking forward to this!  ></body> </Action>
<Action id="56711" issue="36588" author="yoheiueda" type="comment" created="2019-02-06 08:41:48.0" updateauthor="yoheiueda" updated="2019-02-06 08:50:11.0"> <body><! CDATA I read the design document, and noticed that this change will possibly lead to further performance improvements.  I think the phase 2 design will also enable an optimization that alleviates lock contention in peer as described in FAB-7744.  Current implementation uses a mutex lock to guard concurrent accesses to a GRPC stream between peer and chain code. I observed severe lock contention here.   https://github.com/hyperledger/fabric/blob/v1.4.0/core/chaincode/handler.go#L324   If we can use one GRPC stream per transaction proposal, we don’t need the mutex lock at all. Moreover, it will simplify the code of managing transactions. For example, currently we need to manage mapping of transaction contexts in order to correctly handle shim requests from chaincode, but if we use this solution, each transaction proposal simulation uses a dedicated stream for chaincode communication, so we don’t need to manage such relationship.  My microbenchmark in FAB-7744 shows that use of multiple GRPC streams is cheaper than mutex locking.  Creation of new GRPC streams must be initiated from client side. In the current implementation, peer starts a GRPC server, and a chaincode container establishes a TLS connection to the server at its startup. So peer is a server, and can’t initiate new GRPC streams. This limitation makes it difficult to create new GRPC stream for each transaction proposal.  Phase 2 design uses an opposite way. A chaincode container starts a GRPC server, and peer establishes a TLS connection to the server. In this design, peer can create new GRPC stream for each transaction proposal.  My point is that the phase 2 design will introduce optimization and refactoring opportunities for better performance in addition to security and operations.  ></body> </Action>
<Action id="56722" issue="36588" author="muralisr" type="comment" created="2019-02-06 15:25:00.0" updateauthor="muralisr" updated="2019-02-06 15:25:00.0"> <body><! CDATA  ~yoheiueda  yes, with this model we can make "Invoke" a service directly on the chaincode instead of Invokes "tunneling" on one overarching GRPC stream. Among other simplification, we wouldn't need the locks that protect the invokes any longer.  Bulk of the extra work would be in refactoring so the old and new models can coexist and use shared code. Certainly on the radar though.   {code:java} My point is that the phase 2 design will introduce optimization and refactoring opportunities for better performance in addition to security and operations. {code}  Agreed!  ></body> </Action>
<Action id="57093" issue="36588" author="mastersingh24" type="comment" created="2019-02-16 16:16:15.0" updateauthor="mastersingh24" updated="2019-02-16 16:16:15.0"> <body><! CDATA {quote}Bulk of the extra work would be in refactoring so the old and new models can coexist and use shared code. Certainly on the radar though. {quote}  I'm not sure it makes sense to share much code here ... we of course will need to support the old model for at least one release, but I really think we get into trouble every time we try to share code and/or use code paths with switch statements.  Perhaps that's not what is meant here, but we do need to watch out for that.  ></body> </Action>
<Action id="57096" issue="36588" author="yacovm" type="comment" created="2019-02-16 19:48:37.0" updateauthor="yacovm" updated="2019-02-16 19:48:37.0"> <body><! CDATA {quote}My point is that the phase 2 design will introduce optimization and refactoring opportunities for better performance in addition to security and operations. {quote}    It doesn't add any security in my opinion. What I think is missing in the google doc, is a section that deals with how the chaincode shim authenticates the peer.  We need the peer to prove he is who he is to the chaincode shim.  ></body> </Action>
<Action id="57298" issue="36588" author="muralisr" type="comment" created="2019-02-19 14:40:12.0" updateauthor="muralisr" updated="2019-02-19 14:40:12.0"> <body><! CDATA  ~mastersingh24  The work to separate the go-shim is independent (FAB-12246) from the new cc model and requires more design/discussion, slated for 2.01 currently. The work for the peer-chaincode separation and having chaincode run as server is minimal and isolated for most part on the shim side (the peer side is not too bad either but we have to have common code there anyway till we are ready to remove the support for old model). The plan is to do this first as this will get the new model out so everyone can use it (docs, test, users etc).  This is a low change, low risk effort with the significant benefits of the new model and sooner we get it out the better IMO. Also when we do take the shim to a new repo the common code would be separated easily.    ~binhn    ></body> </Action>
<Action id="57299" issue="36588" author="muralisr" type="comment" created="2019-02-19 14:45:40.0" updateauthor="muralisr" updated="2019-02-19 14:45:40.0"> <body><! CDATA  ~yacovm   {code:java} It doesn't add any security in my opinion.{code}  From a pure transport point of view it doesn't, true. But the users now have more control on the security model for the chaincode (on prem, cloud, secure enclaves (if/when) etc).   {code:java} What I think is missing in the google doc, is a section that deals with how the chaincode shim authenticates the peer.  We need the peer to prove he is who he is to the chaincode shim. {code}  See your comment/question the doc as well. Lets' address there.   ></body> </Action>
<Action id="58007" issue="36588" author="jeffgarratt" type="comment" created="2019-03-08 17:23:23.0" updateauthor="jeffgarratt" updated="2019-03-08 17:23:23.0"> <body><! CDATA I am concerned that the issues raised with turning chaincode from a self initiated outbound only actor to a server will introduce far more complexities than imagined.  The simplicity in the original design was in the more innocuous mechanisms chaincode employs (i.e. preemptive outbound stream only communication to designated endpoint).  This tremendously decreases the vulnerability of the chaincode process itself.   Adding inbound port connectivity to the chaincode basically turns it from an interface requiring no concept of internal functional identity wrt to port access to one that must now make access control decisions.  Secondly, you are simply moving the "privileged" aspect from the peer to your administrative service (e.g. kubernetes, etc.).   I could envision a simple way to achieve the same effect to be to augment the chaincode install request/response process without breaking backwards compatibility.  Add another arg to the install invocation to indicate lifecycle responsibility (Default to TRUE if arg omitted, and operate as today).    If FALSE, then the Peer simply does NOT perform any of the chaincode management processes (i.e. compile, launch, etc.), and returns TLS materials that would normally be used to preconfigure the chaincode in the Response to the install request (This makes sense as today install requires Peer Admin role).  The peer can then refer to the flag for future invocations and act accordingly.   The caller can then take responsibility for deployment and management of the chaincode however they wish utilizing the credentials from the Install response, as long as the chaincode can reach the peer.  Then you are free to have the chaincode run anyway you wish, as long as it can connect back to the peer.  This path would require minimal effort in my estimation with no compatibility issues that I can see offhand, while maintaining credential control within the peer.  ></body> </Action>
<Action id="65344" issue="36588" author="jgdomine" type="comment" created="2019-11-07 14:17:22.0" updateauthor="jgdomine" updated="2019-11-07 14:17:34.0"> <body><! CDATA Do we have an update on this topic?  We're still using Docker in Docker as a workaround and this is not production acceptable...  Thank you  ></body> </Action>
<Action id="65354" issue="36588" author="muralisr" type="comment" body=" ~jgdomine  Slated for 2.0 and CR review in progress - https://gerrit.hyperledger.org/r/#/c/fabric/+/34100/" created="2019-11-07 17:34:03.0" updateauthor="muralisr" updated="2019-11-07 17:34:03.0"/>
<Action id="65371" issue="36588" author="jgdomine" type="comment" created="2019-11-08 08:00:05.0" updateauthor="jgdomine" updated="2019-11-08 08:00:05.0"> <body><! CDATA Thank you for your quick reply  ~muralisr   I followed the links to try to understand how this issue would be solved and read about the notion of external chaincode launcher and  saw that as a consequence the core.yaml would have an additional section.  But I'm not sure I understood everything because I'm no expert in HLF Fabric :)  By external launcher, do we talk about things such as K8S?  By the way, is the 2.0 release date planned yet?  Thank you for your insights  ></body> </Action>
<Action id="65392" issue="36588" author="muralisr" type="comment" created="2019-11-08 16:24:12.0" updateauthor="muralisr" updated="2019-11-08 16:24:12.0"> <body><! CDATA Of course,  ~jgdomine .  The CR set would be hard to follow and connect the dots. I just provided it to give an update on where we are.  As a background, currently the peer is entirely responsible for building and launching the chaincode. In 2.0 hooks are provided via the "external chaincode launcher" mechanism for users to optionally control overbuilding and launching of the chaincode using scripts. This is what you refer to with "the core.yaml would have an additional section." I won't describe this process but leave it to upcoming documentation... (and also defer to  ~sykesm   ~jyellick ). One thing important to understand is this is a general mechanism - the "external" in "external chaincode launcher" refers to have the build/launch steps not being internal to peer.  What _is_ relevant to this JIRA is this:  We leverage the "external chaincode launcher" to let user provide connection information of the externally running chaincode to the peer (in the "build" step of the process) via the core.yaml section. This tells the peer where to connect to (along with other TLS information). Note that the "build" could also start the chaincode-as-server first in your k8s env but its not necessary - e..g., the chaincode could running a priori in your k8s env where you fully control the running of the chaincode.  There will be samples and documentation to help clarify of course. Meanwhile, hope this helps.   ~jyellick   ~sykesm  please do add/correct.  ></body> </Action>
<Action id="65564" issue="36588" author="jgdomine" type="comment" created="2019-11-15 08:25:01.0" updateauthor="jgdomine" updated="2019-11-15 08:25:01.0"> <body><! CDATA Thank you very much for the clarification  ~muralisr .  I'm really looking forward these changes as from what I understand, this mechanism will enable the full management of the chaincode container lifecycle via Kubernetes  Hope 2.0 is coming soon  Regards  ></body> </Action>
<Action id="65568" issue="36588" author="muralisr" type="comment" created="2019-11-15 13:38:12.0" updateauthor="muralisr" updated="2019-11-15 13:38:12.0"> <body><! CDATA _...from what I understand, this mechanism will enable the full management of the chaincode container lifecycle via Kubernetes_  That's correct  ~jgdomine .  ></body> </Action>
