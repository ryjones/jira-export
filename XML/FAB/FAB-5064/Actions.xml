<Action id="27600" issue="18770" author="clayton sims" type="comment" body="Scott are you saying this is a Kafka specific issue?" created="2017-06-29 13:22:22.0" updateauthor="clayton sims" updated="2017-06-29 13:22:22.0"/>
<Action id="27607" issue="18770" author="bmos299" type="comment" body=" ~Clayton Sims  yes this is specific to Kafka. " created="2017-06-29 14:17:05.0" updateauthor="bmos299" updated="2017-06-29 14:17:05.0"/>
<Action id="27620" issue="18770" author="jyellick" type="comment" created="2017-06-29 15:11:02.0" updateauthor="jyellick" updated="2017-06-29 15:11:12.0"> <body><! CDATA This is not a fabric bug.  I also do not believe this is a Kafka bug, it is Kafka working as designed.  Imagine KB2 receives a message while KB3 is going down.  KB2 might receive and acknowledge that message, then go down itself.  If KB3 comes back up with KB1 and turns the partition active, then this message acknowledged by KB2 could be lost, violating the guarantees of the Kafka system.  The last ISR must be a member of the new ISR set.  Closing as this is expected behavior.  ></body> </Action>
<Action id="27621" issue="18770" author="jyellick" type="comment" created="2017-06-29 15:34:45.0" updateauthor="jyellick" updated="2017-06-29 15:38:37.0"> <body><! CDATA Note, from the compose file:  {noformat} # # unclean.leader.election.enable # Data consistency is key in a blockchain environment. We cannot have a # leader chosen outside of the in-sync replica set, or we run the risk of # overwriting the offsets that the previous leader produced, and --as a # result-- rewriting the blockchain that the orderers produce. - KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE=false {noformat}  This is exactly why you see the behavior observed.  Please see a more detailed discussion here:  http://kafka.apache.org/documentation/#design_ha  Also note that this is documented in the Fabric Kafka documentation in section 4.a https://github.com/hyperledger/fabric/blob/master/docs/source/kafka.rst  ></body> </Action>
<Action id="27635" issue="18770" author="bmos299" type="comment" body=" ~scottz  let&apos;s change this to an improvement in document the symptom in stack overflow and have a pointer to the link provided above.  Also,  ~mlishok  should be well aware of this one. " created="2017-06-29 17:29:44.0" updateauthor="bmos299" updated="2017-06-29 17:29:44.0"/>
<Action id="27651" issue="18770" author="scottz" type="comment" created="2017-06-29 19:21:55.0" updateauthor="scottz" updated="2017-06-29 19:21:55.0"> <body><! CDATA Yes I have read those sections. Kafka talks about the difficulties, which is why it has several config variables to use. I disagree that there is no bug anywhere.  The section "http://kafka.apache.org/documentation/#design_ha" makes the following statements: * When writing to Kafka, producers can choose whether they wait for the message to be acknowledged by 0,1 or all (-1) replicas. * Specify a minimum ISR size - the partition will only accept writes if the size of the ISR is above a certain minimum, in order to prevent the loss of messages that were written to just a single replica, which subsequently becomes unavailable. * This  min ISR  setting only takes effect if the producer uses acks=all and guarantees that the message will be acknowledged by at least this many in-sync replicas.  We chose to set MIN_INSYNC_REPLICAS=2 and to set unclean.leader.election.enable=false. +*Can you confirm if the orderer does in fact use acks=all ?*+ *If not, then this could be a fabric bug.* According to those statements, fabric should do this for the MIN_INSYNC_REPLICAS setting to be effective. It is not discussed in  https://github.com/hyperledger/fabric/blob/master/docs/source/kafka.rst,  and I don't see anything in fabric/bddtests/*.yml or in fabric/sampletests/*yaml.  The problem is that the ISR set is reduced to one node, when MIN_INSYNC_REPLICAS is 2 (or more). Somehow, this does not cause problems until the scenario where only one node is running and one node is in the ISR set and then that node goes down too - at which point, kafka's promise (when using the suggested settings as directed) is broken.  This is serious for a practical installation. For data duplication and HA, Kafka says if we use suggested settings then we are assured that a blockchain would be able to resume if at least one in the ISR set is running - i.e. ANY one out of MIN_INSYNC_REPLICAS nodes. (The clear implication of setting MIN_INSYNC_REPLICAS=2 is that the ISR set should never drop below 2 nodes - but it does in this scenario, which shows that the blockchain can be permanently LOST if only ONE particular node is unrecoverable. What is the point of backing up data to multiple servers if that doesn't matter?  ></body> </Action>
<Action id="27658" issue="18770" author="binhn" type="comment" body=" ~scottz   This trade off makes sense to me as we wouldn&apos;t want the risks of inconsistency in data. Setting KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE=false which means  {{if all replicas become unavailable, then the partition will remain unavailable until the most recent leader becomes available again.}}  And of course the ISR set helps with redundancy that if the leader failed, one of the replicas in the ISR would take over, so this rare case, total crash, would require careful restart." created="2017-06-29 20:28:38.0" updateauthor="binhn" updated="2017-06-29 20:28:38.0"/>
<Action id="27703" issue="18770" author="scottz" type="comment" created="2017-06-30 14:11:20.0" updateauthor="scottz" updated="2017-06-30 14:11:42.0"> <body><! CDATA In section  http://kafka.apache.org/documentation/#design_uncleanleader  (What if they all die?), it indicates 2 options. I agree we want option 1 "Wait for a replica in the ISR to come back to life and choose this replica as the leader". I agree we don't want a replica that is not in the ISR set, which does not have the latest data. The problem in this scenario is that there is only 1 node in the ISR set. My implications of using of min_isr=2 means that there should always be 2 in this ISR set. It IS a fact that at least 2 will have the latest view of the data. The only reason the 2nd-last KB is not in the ISR set is because it went down prior to the last one failing, and Kafka removed it from ISR set (because it is not currently AVAILABLE) although it still has the latest data. It seems Kafka could manage this better.  That said...  Assuming  ~jyellick  answers my last question about the acks setting and confirms we are configured correctly, then there is nothing we can do; and unless Kafka fixed this hole in a more recent Kafka version, then... at least for now we need to accept that behavior and (as Barry suggested) to point it out to our blockchain network customers using Kafka for their ordering service. Hopefully they can design their network layout to reduce the chance that this unlikely scenario would happen.  ></body> </Action>
<Action id="27704" issue="18770" author="jyellick" type="comment" created="2017-06-30 14:25:00.0" updateauthor="jyellick" updated="2017-06-30 14:25:00.0"> <body><! CDATA I had a conversation with  ~kchristidis  about this to confirm that there is in fact, no bug here.  I would point out first, that the crash fault tolerance has been exceeded in this test.  With a RF=3 and MIN_ISR=2, all three nodes have crashed.  There is no guarantee for data integrity.  ----  Here is an explanation of this behavior in more detail:  Kafka producers may select one of three behaviors for how messages are acknowledged.  To quote from the link above:  > When writing to Kafka, producers can choose whether they wait for the message to be acknowledged by 0,1 or all (-1) replicas.  The fabric Kafka producer is appropriately setting itself to 'all' for this behavior.  However, this is a client setting, and not a cluster setting.  There is no way for the cluster to enforce client behavior.  So, when KB1/KB2 have failed, there is no way to guarantee that a Kafka producer does not connect with an acknowledgement setting of 1, and successfully send messages to KB3.  For this reason, after KB3 goes down, KB2 has no idea if another producer connected and sent messages with the ack behavior of 1 (or 0), so it appropriately does not included itself in the ISR set, because without communicating with KB3, there is no way to know.  ----  So, in summary.  This behavior is expected and this behavior is not a bug because the CFT parameters of Kafka have been violated by this test.   ></body> </Action>
<Action id="27706" issue="18770" author="jyellick" type="comment" created="2017-06-30 14:39:16.0" updateauthor="jyellick" updated="2017-06-30 14:39:16.0"> <body><! CDATA Just to call it out a little more explicitly,  ~scottz   > Assuming Jason Yellick answers my last question about the acks setting and confirms we are configured correctly, then there is nothing we can do;  Yes, the fabric kafka producer sets the acks setting to all.  -----  And just a little further information courtesy of  ~kchristidis   > A replica needs to have an active session with ZK for it to eligible for inclusion in the ISR set. > It also needs to do a "fetch" to the leader for latest messages in the last 10 seconds.  So, in the test described in the issue, KB2 has been out of contact with ZK, and not talked with the leader in the last 10 seconds, so it necessarily cannot be part of the ISR set.  Whether Kafka could handle this better (which I am certain, is much easier said than done) or not, as you point out, there is nothing we can do to change this behavior.  ></body> </Action>
<Action id="27726" issue="18770" author="scottz" type="comment" body="Thanks!" created="2017-06-30 20:16:58.0" updateauthor="scottz" updated="2017-06-30 20:16:58.0"/>
<Action id="28056" issue="18770" author="kchristidis" type="comment" body="Don&apos;t see any reason for this to still be open, closing." created="2017-07-09 20:54:16.0" updateauthor="kchristidis" updated="2017-07-09 20:54:16.0"/>
