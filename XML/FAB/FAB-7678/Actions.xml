<Action id="38401" issue="26698" author="dongming" type="comment" created="2018-01-10 19:39:47.0" updateauthor="dongming" updated="2018-01-10 19:39:47.0"> <body><! CDATA Comment from Marko Vukolic on 1/10/2018:  Hi Barry,  what we observed was that the MVCC processing in validation got longer - but we do not have more detailed profiling. We know it is not ledger of VSCC part of the validation it is really inside MVCC check which is in between the two.  Hope this helps a bit Marko  ></body> </Action>
<Action id="38803" issue="26698" author="clayton sims" type="comment" created="2018-01-17 21:51:38.0" updateauthor="clayton sims" updated="2018-01-17 21:51:38.0"> <body><! CDATA  ~marko.vukolic   is this something you can help the team with to further profile and narrow the root cause?     ></body> </Action>
<Action id="38804" issue="26698" author="denyeart" type="comment" created="2018-01-17 21:57:38.0" updateauthor="denyeart" updated="2018-01-17 21:59:17.0"> <body><! CDATA  ~dongming  If I am reading the stats correctly in the description, it looks like TPS *improved* from 82.66 TPS to 116.27 TPS (single channel, 1.0.3 to 1.0.5). And from 98.32 to 104.18 TPS (8 channels, 1.0.3 to 1.0.5).  I'm not understanding what the regression is?   Yes it looks like 1.0.4 was a little slower, but 1.0.5 is a little faster.  Maybe that is just within the margin of error of the test?  ></body> </Action>
<Action id="38810" issue="26698" author="dongming" type="comment" body=" ~denyeart   Yes, v1.0.5 has  better TPS then v1.0.3.  I have done some test and observed that v1.0.4 is consistently slower than v1.0.3.  If we consider this is within the margin of error, then we can close this bug." created="2018-01-17 22:18:11.0" updateauthor="dongming" updated="2018-01-17 22:18:11.0"/>
<Action id="38845" issue="26698" author="vukolic" type="comment" created="2018-01-18 14:10:18.0" updateauthor="vukolic" updated="2018-01-18 14:10:18.0"> <body><! CDATA We observed at some point a regression in MVCC latency but since we were evaluating on master it is difficult to pinpoint which release was affected. What we seem to be needing is a bit more profiling in those tps numbers quoted above. Even simple latency staging split in validation phases would help (we use VSCC/MVCC/ledger staging internally)     sorry this does not help more.  ></body> </Action>
<Action id="38847" issue="26698" author="denyeart" type="comment" created="2018-01-18 14:38:56.0" updateauthor="denyeart" updated="2018-01-18 14:38:56.0"> <body><! CDATA  ~dongming   ~vukolic  Has anybody looked into performance profiling utilities at the golang level?  Seems that would give us the most detailed answers.  Thoughts?  If we are evaluating performance on master (1.1), then a 1.0.x (release) vs 1.1 (master) analysis should be done.  Has anybody done that yet?  ></body> </Action>
<Action id="38894" issue="26698" author="dongming" type="comment" created="2018-01-19 14:54:08.0" updateauthor="dongming" updated="2018-01-19 14:54:08.0"> <body><! CDATA Another data point on v1.1.0-preview  1 channel: 138.39, 2 channels: 134.13, 8 channels: 129.43  overall, v1.1.0-preview has the best TPS.  ></body> </Action>
<Action id="38964" issue="26698" author="dongming" type="comment" created="2018-01-22 14:47:27.0" updateauthor="dongming" updated="2018-01-22 14:47:27.0"> <body><! CDATA The TPS for v1.1 commit a85b2fa are:  1 channel: 147.80, 2 channels: 140.01, 8 channels: 134.64  ></body> </Action>
<Action id="39343" issue="26698" author="denyeart" type="comment" body="Since the performance is generally improved on the latest 1.0.x and 1.1, I&apos;m not seeing an perf bug here.  It seems the 1.0.4 perf numbers are within the margin of error.  I will close this item." created="2018-01-30 03:23:29.0" updateauthor="denyeart" updated="2018-01-30 03:23:29.0"/>
