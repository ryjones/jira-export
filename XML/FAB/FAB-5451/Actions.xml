<Action id="29230" issue="19464" author="kletkeman" type="comment" created="2017-07-31 13:38:20.0" updateauthor="kletkeman" updated="2017-07-31 13:38:20.0"> <body><! CDATA Some thoughts:  1) Please define all terms (e.g. QSCC).  2) Please explain situations in which this new service is used. The generic "cannot reach known endorsers or orderer" makes sense as a start, but if an application is not fed a connection profile, then what is it fed?  3) If the discovery service is offline, is the fabric equally unreachable? Or does must the client SDK be given a full connection profile as is true today, AND be given a discovery service to fish around for other peers to which is can talk?  4) The three flows don't really make sense, since they are merely descriptions of a query with little context. How about adding sections for scenarios? E.g.: * Scenario: How discovery service is configured with index for organizations, channels, chaincodes * Scenario: How an application in ORGx can find out what it is able to access and present a list of channels or chaincodes or both to the end user, of course with monikers that are relevant in the context of the application's stated purpose * Scenario: How application knows about the discovery service * Scenario: How application asks discovery service for a list of endorsers and orderers * Scenario: When many small channels (two peers, one orderer) are in use for privacy purposes, is there actually a fall back? Or is the discovery service going to simply report "that channel is off line"? I.e. in such a scenario, does the service provide useful info?  I like the thought of a discovery service in lieu of having to give the applications too much information up front. But I think it needs to be defined very clearly.  ></body> </Action>
<Action id="29266" issue="19464" author="yacovm" type="comment" created="2017-08-01 07:38:45.0" updateauthor="yacovm" updated="2017-08-01 07:38:45.0"> <body><! CDATA Hi, thanks for the feedback.  {quote}1) Please define all terms (e.g. QSCC).{quote} QSCC is Query system chaincode. I expanded the acronym and gave a few links.  {quote}2) Please explain situations in which this new service is used. The generic "cannot reach known endorsers or orderer" makes sense as a start, but if an application is not fed a connection profile, then what is it fed?{quote} I added a section: bq. Intended consumers of the feature: The service discovery would be a used by client SDKs in the same way it is used now (via QSCC - Query system chaincode) in order to learn about nodes (peers and orderers) in the fabric network, and the services they provide (channels, chaincodes, etc.)  {quote}3) If the discovery service is offline, is the fabric equally unreachable? Or does must the client SDK be given a full connection profile as is true today, AND be given a discovery service to fish around for other peers to which is can talk?{quote}  There isn't a discovery service in the proposal, but a service discovery capability that would be embedded into Hyperledger Fabric peers. However, the flow would be similar to having a discovery service (as described briefly in the document): # A client SDK is preconfigured with a bootstrap set of peer endpoints # It can query it to obtain more peer endpoints # It can query those peer endpoints, and so on and so forth. It is a good question what happens when the bootstrap peers of the application aren't available - in that case I think the reasonable step would be that if the organization of the peers would want high availability, it can: * Have more than 1 peer have the same DNS alias and then DNS queries to the peer endpoint would return a random ip from the set of peers * Have the TLS certificates of the peers have also a subject alternative name that fits the DNS alias Do you think it's worthwhile to put this consideration into the document?   {quote}4) The three flows don't really make sense, since they are merely descriptions of a query with little context. How about adding sections for scenarios? E.g.:{quote} Note that we already have the base capability of querying a peer for its local knowledge, all I am proposing here is to have a peer keep the information about other peers in its memory, and have this information propagated via gossip (that already has the capability).   ></body> </Action>
<Action id="29661" issue="19464" author="christopherferris" type="comment" body="This has the requisite 5 maintainers on board. Good luck!" created="2017-08-10 17:25:07.0" updateauthor="christopherferris" updated="2017-08-10 17:25:07.0"/>
<Action id="30346" issue="19464" author="rickr" type="comment" body=" ~jimthematrix   ~Clayton Sims  Is something inconsistent here with fix version v1.1 but a label Relase-planning-1.2 ?" created="2017-08-29 22:30:38.0" updateauthor="rickr" updated="2017-08-29 22:30:38.0"/>
<Action id="30347" issue="19464" author="yacovm" type="comment" body="It was planned to v1.1 but re-prioritized to 1.2 at least for now" created="2017-08-29 22:35:06.0" updateauthor="yacovm" updated="2017-08-29 22:35:06.0"/>
<Action id="30447" issue="19464" author="ianj_mitchell@uk.ibm.com" type="comment" body="Is the intent to provide enough information to be discovered that would enable an SDK in one org to include peers from other orgs in its endorsement gathering? That&apos;s the configuration challenge we&apos;ve been struggling with for the generic REST server and Composer REST server deployment." created="2017-09-01 13:28:28.0" updateauthor="ianj_mitchell@uk.ibm.com" updated="2017-09-01 13:28:28.0"/>
<Action id="30449" issue="19464" author="yacovm" type="comment" created="2017-09-01 13:33:59.0" updateauthor="yacovm" updated="2017-09-01 13:33:59.0"> <body><! CDATA {quote}Is the intent to provide enough information to be discovered that would enable an SDK in one org to include peers from other orgs in its endorsement gathering? {quote} This is a major bonus for having this. The idea is that a client can only "bootstrap" with his own organization's certificates and would be able to use other peer's certificates as well.   ></body> </Action>
<Action id="30451" issue="19464" author="ianj_mitchell@uk.ibm.com" type="comment" body="Are you thinking that the format of information returned will be consistent with the connection profile in FAB-5363? ie it might just be a form/subset of the general structure established for connection profiles." created="2017-09-01 13:42:06.0" updateauthor="ianj_mitchell@uk.ibm.com" updated="2017-09-01 13:42:06.0"/>
<Action id="30452" issue="19464" author="yacovm" type="comment" body="I think that thing is more useful for files and less for information that is dynamically calculated, and changes over time." created="2017-09-01 13:52:50.0" updateauthor="yacovm" updated="2017-09-01 13:52:50.0"/>
<Action id="30454" issue="19464" author="ianj_mitchell@uk.ibm.com" type="comment" body="As peers come and go, or orgs come and go even, how would you expect SDK instances to stay up-to-date?" created="2017-09-01 13:57:27.0" updateauthor="ianj_mitchell@uk.ibm.com" updated="2017-09-01 13:57:27.0"/>
<Action id="30455" issue="19464" author="yacovm" type="comment" created="2017-09-01 14:03:39.0" updateauthor="yacovm" updated="2017-09-01 14:03:39.0"> <body><! CDATA The SDK only needs a peer for endorsement. When it tries invoking endorsements and the peer isn't available, it can send a service discovery query to any peer that it knows (from configuration or from service discovery) and get the list of peers that are alive currently, and usable by the client.    ></body> </Action>
<Action id="44542" issue="19464" author="yashganthe" type="comment" body="I have read the proposal document. When a client queries a peer that it trusts, how does the peer get the information about peers of other organizations? Do all organizations need to set up an Anchor peer and get those added in the configtx.yaml? " created="2018-05-17 10:36:36.0" updateauthor="yashganthe" updated="2018-05-17 10:36:36.0"/>
<Action id="44543" issue="19464" author="yacovm" type="comment" body="yes" created="2018-05-17 10:42:50.0" updateauthor="yacovm" updated="2018-05-17 10:42:50.0"/>
<Action id="44707" issue="19464" author="jufeng.yao" type="comment" created="2018-05-21 03:28:01.0" updateauthor="jufeng.yao" updated="2018-05-21 03:28:01.0"> <body><! CDATA This is really a wonderful new feature !  but still I wonder that if we now support dynamically select endorser. the use case is this :  1, suppose org1 has 4 endorsers for channel-A, and org2 has 4 endorsers for channel-A too 2, the endorsement policy is AND('org1.peer', 'org2.peer') now, for under *huge* requests case, can client dynamically select org1 endorsers & org2 endorsers in turn to balance the requests? that is : #1 request : endorsed by org1.endorser1 && org2.endorser1 #2 request : endorsed by org1.endorser2 && org2.endorser2 #3 request : endorsed by org1.endorser3 && org2.endorser3 #4 request : endorsed by org1.endorser4 && org2.endorser4 #5 request:  endorsed by org1.endorser2 && org2.endorser3 ........   ></body> </Action>
<Action id="44711" issue="19464" author="c0rwin" type="comment" created="2018-05-21 07:46:41.0" updateauthor="c0rwin" updated="2018-05-21 07:46:41.0"> <body><! CDATA  ~jufeng.yao   {quote} the endorsement policy is AND('org1.peer', 'org2.peer') {quote}  with endorsement policy as you stated and having that each org has 4 peers following response will be send back to client, i.e.:   {code} Layouts:   QuantitiesByGroup: { “Org1”: 1, “Org2”: 1, }  , EndorsersByGroups: { “Org1”:  peer0.org1, peer1.org1, peer2.org1, pee3.org1 , “Org2”:  peer0.org2, peer1.org2, peer2.org2, peer3.org2  } {code}  which basically means that there is one group to satisfy endorsement policy, where for Org1 you need to select one among the list mapped under same id   {code} {   EndorsersByGroups: { “Org1”:  peer0.org1, peer1.org1, peer2.org1, pee3.org1 , } {code}  and one for Org2  {code} EndorsersByGroups: { “Org2”:  peer0.org2, peer1.org2, peer2.org2, peer3.org2  } {code}  so having this you can obviously balance endorsements requests, for example selecting next peer for each org at round robin or randomly.  ></body> </Action>
<Action id="44713" issue="19464" author="yacovm" type="comment" created="2018-05-21 08:18:18.0" updateauthor="yacovm" updated="2018-05-21 08:18:18.0"> <body><! CDATA It's exactly as Artem said ^ , the peer gives you a descriptor which allows you to choose the peers for the endorsements according to any policy you want: * Based on peer properties like organization affiliation, ledger height * Based on prior selections, i.e for round-robin * Based on randomness  I expect the SDKs to provide a default policy which "makes sense" and is largely optimal, but also to expose to the application developer the ability to pass its own peer selection logic should he/she want.  ></body> </Action>
<Action id="44735" issue="19464" author="jufeng.yao" type="comment" created="2018-05-21 14:23:56.0" updateauthor="jufeng.yao" updated="2018-05-21 14:23:56.0"> <body><! CDATA thanks  ~C0rWin , it's helpful.   and I agree with  ~yacovm  that SDK will balance by default, and also expose to the application developer these configuration.  the SDKs don't have such ability yet, right?  and one more question is :   since the client which instantiate chaincode will get the response (I guess, right?), but how do other clients from same channel groups get the layouts? do we have query function for endorsement policy? I seems can't find such API in SDK.   by the way, it confused me that why only *one local* container per chaincode per peer, why can't we deploy multi-containers on multi-machines?  thanks  ></body> </Action>
<Action id="44737" issue="19464" author="yacovm" type="comment" created="2018-05-21 14:53:33.0" updateauthor="yacovm" updated="2018-05-21 14:53:33.0"> <body><! CDATA {quote}the SDKs don't have such ability yet, right? {quote} They're supposed to implement discovery client side support for v1.2 {quote}   since the client which instantiate chaincode will get the response (I guess, right?), but how do other clients from same channel groups get the layouts? do we have query function for endorsement policy? I seems can't find such API in SDK. {quote} The client doesn't need to know the endorsement policy. It asks the peer "which peers should I endorse for a specific chaincode" and the peer tells him that descriptor Artem showed you, in response    {quote}by the way, it confused me that why only *one local* container per chaincode per peer, why can't we deploy multi-containers on multi-machines? {quote} You can deploy the chaincode on kubernetes in theory. In practice I never tried     ></body> </Action>
<Action id="44809" issue="19464" author="jufeng.yao" type="comment" created="2018-05-22 03:13:02.0" updateauthor="jufeng.yao" updated="2018-05-22 03:13:02.0"> <body><! CDATA  ~yacovm  thanks very much !  what I really want is that : we can deploy multi-containers for a chaincode in distributed container env, such as kubernetes or docker swarm, and load balance. after investigated source code, I noticed that the cc container proactively & directly connect to peer, which will cause a problem : load balance should be done by peer endpoint, not by kubernetes or docker swarm.   but peer doesn't have such ability yet, right?  ></body> </Action>
<Action id="44875" issue="19464" author="yacovm" type="comment" created="2018-05-22 17:45:30.0" updateauthor="yacovm" updated="2018-05-22 17:45:30.0"> <body><! CDATA No, you can't load balance chaincode containers for the same chaincode. I also don't think it's a good idea - instead, what we need is the ability to have the chaincode shim (container) to have parallel processing and not sequential as now.     What is your use case for load balancing?  ></body> </Action>
<Action id="44939" issue="19464" author="jufeng.yao" type="comment" created="2018-05-23 05:35:03.0" updateauthor="jufeng.yao" updated="2018-05-23 05:35:03.0"> <body><! CDATA for performance case actually. one container per chaincode won't be enough under huge requests case. currently, cc container uses go-routine to parallel process all requests, but the question is : if request number is very big, one container won't be enough at all (of course, it won't be problem under low TPS).   one cc container need to process all requests of channels relative to this cc.  if the resource required to process huge requests (suppose 1m TPS, just an example of huge requests) exceeds ability of one container or even one machine, what should we do? 2 or more containers/machines will be needed.   what I said is not sequential, but multi-containers, each container will parallel processing requests, while multi-containers will greatly enlarge parallel processing ability.  if we need 2 or more containers/machines, load balance is needed at some place. it can be resided in peer, or maybe shim (not very clear about this).  I think about some bottle-nicks of hyperledger fabric under high TPS: 1, SDK load balance, which is discussed above, and almost done 2, BCCSP : currently can be SW or HW, while HW costs too much, so I consider if we can have another way : docker cluster for signing and verification, this can be done by a new implementation of BCCSP 3, one container per cc: we can extend to multi-containers to enlarge the parallel ability 4, block validation :  one peer need to endorse 1/n huge requests, if this stage already make peer very busy, then possibly need other resource to validate blocks (although currently validator already uses go-routine to speed up block validation, but if peer is busy enough for endorsement stage?)   ></body> </Action>
<Action id="44957" issue="19464" author="yacovm" type="comment" created="2018-05-23 09:35:52.0" updateauthor="yacovm" updated="2018-05-23 09:35:52.0"> <body><! CDATA {quote}currently, cc container uses go-routine to parallel process all requests {quote} It has a single goroutine... it doesn't have a goroutine pool from what I remember. That's the problem. It needs to have multiple streams and multiple goroutines (with a handler each). {quote}but the question is : if request number is very big, one container won't be enough at all (of course, it won't be problem under low TPS). {quote} It only seems that way but in practice since you do at least 1 read in most chaincodes or at least 1 write, the CPU won't be the bottleneck. In a typical application, most time is spent during network IO between the container and the peer.        ></body> </Action>
<Action id="44972" issue="19464" author="jufeng.yao" type="comment" body="thanks very much. go-routine pool is a good idea. and even most time is spent in network IO, in current design, this can&apos;t be avoided. under huge requests case, when reach to limitation of capability of container, multi-containers still can be considered, except that cc container *NEVER* be bottleneck." created="2018-05-23 12:31:19.0" updateauthor="jufeng.yao" updated="2018-05-23 12:31:19.0"/>
