<Action id="52704" issue="33932" author="denyeart" type="comment" created="2018-10-26 19:54:09.0" updateauthor="denyeart" updated="2018-10-26 19:54:52.0"> <body><! CDATA Still being seen intermittently:   https://jenkins.hyperledger.org/job/fabric-verify-unit-tests-x86_64/5635/consoleFull  {code:java} 18:56:00 unit-tests_1 | â€” FAIL: TestLeaderYield (117.02s) 18:56:00 unit-tests_1 | integration_test.go:156: p0 started its delivery service 18:56:00 unit-tests_1 | integration_test.go:161: p0 stopped its delivery service 18:56:00 unit-tests_1 | integration_test.go:171: p1 hasn't taken over leadership within 1m0s: -1 18:56:00 unit-tests_1 | 2018-10-26 18:55:12.561 UTC  gossip.service  updateAnchors -> ERRO 084 Tried joining channel A but our org( OrgMSP0 ), isn't among the orgs of the channel:  Org0  , aborting.{code}  ></body> </Action>
<Action id="52767" issue="33932" author="denyeart" type="comment" body=" ~C0rWin   ~inbarbadian   ~yacovm  This failure is seen often... what&apos;s the plan to address?" created="2018-10-30 14:41:32.0" updateauthor="denyeart" updated="2018-10-30 14:41:32.0"/>
<Action id="55000" issue="33932" author="sykesm" type="comment" created="2018-12-19 19:53:10.0" updateauthor="sykesm" updated="2018-12-19 19:53:10.0"> <body><! CDATA Observed in ci: https://gerrit.hyperledger.org/r/c/28300/   ^console.log    ></body> </Action>
<Action id="55359" issue="33932" author="wael" type="comment" body="could not recapture the bug again." created="2019-01-07 08:52:48.0" updateauthor="wael" updated="2019-01-07 08:52:48.0"/>
<Action id="55515" issue="33932" author="c0rwin" type="comment" body="https://gerrit.hyperledger.org/r/#/c/28647/" created="2019-01-11 00:22:02.0" updateauthor="c0rwin" updated="2019-01-11 00:22:02.0"/>
<Action id="58840" issue="33932" author="c0rwin" type="comment" created="2019-04-02 11:44:13.0" updateauthor="c0rwin" updated="2019-04-02 11:44:13.0"> <body><! CDATA Reopening since discovered it failing again   {code} 09:41:21 --- FAIL: TestLeaderYield (93.90s) 09:41:21     integration_test.go:169: p0 started its delivery service 09:41:21     integration_test.go:174: p0 stopped its delivery service 09:41:21     integration_test.go:184: p1 hasn't taken over leadership within 1m0s: -1 {code}  https://jenkins.hyperledger.org/job/fabric-verify-unit-tests-x86_64/11228/console CR: https://gerrit.hyperledger.org/r/#/c/30627/   ></body> </Action>
<Action id="59081" issue="33932" author="rameshthoomu" type="comment" created="2019-04-09 21:22:22.0" updateauthor="rameshthoomu" updated="2019-04-09 21:22:22.0"> <body><! CDATA 6:35:22 goroutine 987  select, 1 minutes : 16:35:22 github.com/hyperledger/fabric/gossip/gossip.(*gossipServiceImpl).Accept.func2(0xc0001cadc0, 0xc0001eae40, 0xc0001eaea0) 16:35:22 	/w/workspace/fabric-merge-x86_64/gopath/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:811 +0xde 16:35:22 created by github.com/hyperledger/fabric/gossip/gossip.(*gossipServiceImpl).Accept 16:35:22 	/w/workspace/fabric-merge-x86_64/gopath/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:809 +0xdf 16:35:22 --- FAIL: TestLeaderYield (93.90s) 16:35:22     integration_test.go:169: p0 started its delivery service 16:35:22     integration_test.go:174: p0 stopped its delivery service 16:35:22     integration_test.go:184: p1 hasn't taken over leadership within 1m0s: -1 16:35:22 2019-04-09 20:34:51.087 UTC  gossip.service  updateAnchors -> ERRO 057 Tried joining channel A but our org( OrgMSP0 ), isn't among the orgs of the channel:  Org0  , aborting.  ></body> </Action>
<Action id="59251" issue="33932" author="wlahti" type="comment" body="Hit again here: https://jenkins.hyperledger.org/job/fabric-verify-unit-tests-x86_64/11529/console" created="2019-04-15 18:49:15.0" updateauthor="wlahti" updated="2019-04-15 18:49:15.0"/>
<Action id="59252" issue="33932" author="wlahti" type="comment" body="Matt also logged two hits of this flake in FAB-15039 (which I just closed as a duplicate of this item)." created="2019-04-15 18:58:14.0" updateauthor="wlahti" updated="2019-04-15 18:58:14.0"/>
<Action id="59477" issue="33932" author="sykesm" type="comment" created="2019-04-24 16:50:48.0" updateauthor="sykesm" updated="2019-04-24 16:50:48.0"> <body><! CDATA And again...  16:34:46 --- FAIL: TestLeaderYield (93.93s) 16:34:46     integration_test.go:169: p0 started its delivery service 16:34:46     integration_test.go:174: p0 stopped its delivery service 16:34:46     integration_test.go:184: p1 hasn't taken over leadership within 1m0s: -1  https://jenkins.hyperledger.org/job/fabric-verify-unit-tests-x86_64/11697/console  ></body> </Action>
<Action id="59659" issue="33932" author="sykesm" type="comment" created="2019-05-01 18:08:43.0" updateauthor="sykesm" updated="2019-05-01 18:08:43.0"> <body><! CDATA And again...  13:52:25 --- FAIL: TestLeaderYield (93.90s) 13:52:25     integration_test.go:169: p0 started its delivery service 13:52:25     integration_test.go:174: p0 stopped its delivery service 13:52:25     integration_test.go:184: p1 hasn't taken over leadership within 1m0s: -1  https://jenkins.hyperledger.org/job/fabric-verify-unit-tests-x86_64/11845/console  ></body> </Action>
<Action id="59887" issue="33932" author="wlahti" type="comment" created="2019-05-09 17:24:49.0" updateauthor="wlahti" updated="2019-05-09 17:24:49.0"> <body><! CDATA Different failure in TestLeaderYield: {code:java} 13:16:15 --- FAIL: TestLeaderYield (32.06s) 13:16:15     gossip_service_test.go:555: Failed to establish full membership. Only 1 out of 2 peers have full membership {code}  https://jenkins.hyperledger.org/job/fabric-verify-unit-tests-x86_64/12040/console   ></body> </Action>
<Action id="59980" issue="33932" author="mhbauer" type="comment" created="2019-05-14 05:56:28.0" updateauthor="mhbauer" updated="2019-05-14 05:56:28.0"> <body><! CDATA This test is exceptionally flakey for me locally. Even races some times.  Consistently co-incident with failures is a log line like: 2019-05-13 21:32:13.979 PDT  gossip.comm  func1 -> WARN 003 127.0.0.1:35195, PKIid:3132372e302e302e313a3335313935 isn't responsive: rpc error: code = Unavailable desc = transport is closing coming from comm_impl.go L#234 Which is a closure that's most likely actually invoked at conn.go L#339  I see it sometimes, but during most failures, it's the ONLY thing I see.  Successes take a widely varying amount of time, from 5-20 seconds.  Most irritating is that adding prints or enabling logging seems to have in inverse relationship, throwing off the timing enough that it seems to fail less.   ></body> </Action>
<Action id="59988" issue="33932" author="ronenschafferibm" type="comment" created="2019-05-14 07:21:43.0" updateauthor="ronenschafferibm" updated="2019-05-14 07:21:43.0"> <body><! CDATA Running the test locally with -race flag occasionally fails and a data race is detected. The race seems to happen due to both peers trying to connect each other concurrently.  Â    ^race-detection.log   ></body> </Action>
<Action id="59996" issue="33932" author="ronenschafferibm" type="comment" created="2019-05-14 13:42:15.0" updateauthor="ronenschafferibm" updated="2019-05-14 13:42:15.0"> <body><! CDATA Setting the bootstrap peers list to be only one of the peers solves the race problem and the peers are getting full membership in less than a second. But, there are still sometimes that the test runs for a long time (about 30 seconds). After timing each part of the test I found out it is due to the waiting for p1 to take leadership.  https://github.com/hyperledger/fabric/blob/a239ae0ab290618597c0b4f33ae9c2e8ee5ff102/gossip/service/integration_test.go#L177-L181  ></body> </Action>
<Action id="60636" issue="33932" author="ronenschafferibm" type="comment" created="2019-06-04 08:11:40.0" updateauthor="ronenschafferibm" updated="2019-06-04 08:11:40.0"> <body><! CDATA Closing this issue since the inherent problems of TestLeaderYield() are handled. Normally, this test takes about 14 sec to pass. It still may fail due to communication issues in gossip/comm (there is a race when both peers create a connection to each other simultaneously).  ></body> </Action>
<Action id="69386" issue="33932" author="JIRAUSER20206" type="comment" created="2020-06-03 06:30:27.0" updateauthor="JIRAUSER20206" updated="2020-06-03 06:30:27.0"> <body><! CDATA goroutine 1499  semacquire : sync.runtime_SemacquireMutex(0xc0005b27f4, 0x1105e00, 0x1) /usr/local/go/src/runtime/sema.go:71 +0x47 sync.(*Mutex).lockSlow(0xc0005b27f0) /usr/local/go/src/sync/mutex.go:138 +0xfc sync.(*Mutex).Lock(...) /usr/local/go/src/sync/mutex.go:81 github.com/hyperledger/fabric/gossip/comm.(*connectionStore).getConnection(0xc0001b2b40, 0xc0003288d0, 0x0, 0x0, 0x0) /opt/cloud/workspace/CloudBU-OpenSourceCenter-Fabric-X86-MR-FUNCTEST/src/github.com/hyperledger/fabric/gossip/comm/conn.go:78 +0x8ee github.com/hyperledger/fabric/gossip/comm.(*commImpl).sendToEndpoint(0xc0005bb680, 0xc0003288d0, 0xc000593c20, 0x0) /opt/cloud/workspace/CloudBU-OpenSourceCenter-Fabric-X86-MR-FUNCTEST/src/github.com/hyperledger/fabric/gossip/comm/comm_impl.go:235 +0x1c4 github.com/hyperledger/fabric/gossip/comm.(*commImpl).Send.func1(0xc0005bb680, 0xc0003288d0, 0xc000593c20) /opt/cloud/workspace/CloudBU-OpenSourceCenter-Fabric-X86-MR-FUNCTEST/src/github.com/hyperledger/fabric/gossip/comm/comm_impl.go:222 +0x44 created by github.com/hyperledger/fabric/gossip/comm.(*commImpl).Send /opt/cloud/workspace/CloudBU-OpenSourceCenter-Fabric-X86-MR-FUNCTEST/src/github.com/hyperledger/fabric/gossip/comm/comm_impl.go:221 +0x151  33m2020-06-03 11:44:03.938 CST  gossip.comm  sendToEndpoint -> WARN 05e 0m Failed obtaining connection for 1.2.3.4:37157, PKIid:3132372e302e302e313a3337313537 reason: ConnStore is closing  33m2020-06-03 11:44:03.938 CST  gossip.comm  sendToEndpoint -> WARN 05f 0m Failed obtaining connection for 127.0.0.1:37157, PKIid:3132372e302e302e313a3337313537 reason: ConnStore is closing  33m2020-06-03 11:44:03.938 CST  gossip.comm  sendToEndpoint -> WARN 060 0m Failed obtaining connection for 127.0.0.1:37157, PKIid:3132372e302e302e313a3337313537 reason: ConnStore is closing  33m2020-06-03 11:44:03.938 CST  gossip.comm  sendToEndpoint -> WARN 061 0m Failed obtaining connection for 127.0.0.1:37157, PKIid:3132372e302e302e313a3337313537 reason: ConnStore is closing  33m2020-06-03 11:44:03.938 CST  gossip.comm  sendToEndpoint -> WARN 062 0m Failed obtaining connection for 127.0.0.1:37157, PKIid:3132372e302e302e313a3337313537 reason: ConnStore is closing --- FAIL: TestLeaderYield (93.92s)  ></body> </Action>
