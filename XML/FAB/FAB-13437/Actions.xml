<Action id="58351" issue="36389" author="vukolic" type="comment" created="2019-03-20 18:56:53.0" updateauthor="vukolic" updated="2019-03-20 18:56:53.0"> <body><! CDATA The idea for using time instead of blockheight for Block Time Locks (BTL) in the proposal is simplistic and not viable.   In bad case (asynchrony, faults), ordering service (based on a protocol designed to tolerate asynchrony such as Raft, Kafka or some BFT) cannot guarantee to emit a block every X seconds.              ></body> </Action>
<Action id="58354" issue="36389" author="baohua" type="comment" created="2019-03-21 02:15:13.0" updateauthor="baohua" updated="2019-03-21 02:15:13.0"> <body><! CDATA  ~vukolic , i guess the reason is that:  in bitcoin, ledger height actually guaranteed time clock, while Fabric's block emit time varies.  Hence we need to find some way to represent the time. I know this is always difficult in distributed system.  On the other hand, directly using ledger height in fabric should be OK for most cases.  ></body> </Action>
<Action id="58355" issue="36389" author="baohua" type="comment" created="2019-03-21 02:18:26.0" updateauthor="baohua" updated="2019-03-21 02:18:26.0"> <body><! CDATA Besides, the idea of HTLC itself is not a big problem, but definitely requires some changes to existing implementation.  Several major ones (potentially because of the EOV model): * waiting list; * send secret; * permissioned.  ></body> </Action>
<Action id="58362" issue="36389" author="praveen.j" type="comment" created="2019-03-21 05:43:30.0" updateauthor="praveen.j" updated="2019-03-21 05:43:30.0"> <body><! CDATA  ~marko.vukolic  Yes, we have intentionally kept the time aspect very simple and approximate. Note that we need the notion of time only as a timeout, i.e., a client should have sufficient time to provide the secret to commit a transaction in HTLC. So, some clock drift can be easily tolerated. In the event that a particular use case requires synchronized clocks, we can incorporate time synchronization, but we dont think its necessary.  Further, if the logical clock based on block creation is slower than absolute time, there is no impact to safety of the protocol. It is highly unlikely that blocks will be created faster than absolute time.   Finally, as  ~baohua  mentioned, directly using ledger height for timeout can be made the default option, which should work for most scenarios.  ></body> </Action>
<Action id="58381" issue="36389" author="hagarm" type="comment" created="2019-03-21 12:54:58.0" updateauthor="hagarm" updated="2019-03-21 12:54:58.0"> <body><! CDATA I don't think that using ledger height for timeout should work for most scenarios. In order to guaranty the atomicity of transactions the timeouts used by the HTLC most be chosen such that one is less than the other. However, when using ledger height to determine the time, there is no relation between the "time" of one channel and another channel, no assurance that one timeout is less than the other.  So I don't see how using the ledger height can work for any scenario.  Moreover, the other proposal of making the ordering service emit a block on a timeout (instead of block size), might solve the HTLC timeout issue, but has its own risks and effects on Fabric and needs to be carefully examined.  ></body> </Action>
<Action id="58383" issue="36389" author="praveen.j" type="comment" created="2019-03-21 13:12:42.0" updateauthor="praveen.j" updated="2019-03-21 13:12:42.0"> <body><! CDATA  ~hagarm  You are right in that the rate of forming blocks in 2 channels may have no correlation whatsoever. What I intended was to say that the onus would be on the client applications to set large enough timeouts on both channels (we can provide some defaults). They would have to approximate the timeout in terms of block height in both channels independently, to cater to the needs of HTLC (one timeout being larger than the other). Clients not setting proper timeouts is a pitfall of the HTLC protocol itself (the issue is worse in blockchains that do not guarantee finality of transactions).     There is a risk in the ordering service emiting a block based on timeout instead of block size. The risk is that if this timeout is not properly selected, it could result in a queue build up (when load is high).           ></body> </Action>
<Action id="58384" issue="36389" author="c0rwin" type="comment" created="2019-03-21 13:45:05.0" updateauthor="c0rwin" updated="2019-03-21 13:45:05.0"> <body><! CDATA  ~praveen.j  {quote} They would have to approximate the timeout in terms of block height in both channels independently, to cater to the needs of HTLC (one timeout being larger than the other). {quote} Even if client could approximate the timeout, the adversary could easily construct the runaway attack by speeding up block formation.  {quote} There is a risk in the ordering service emiting a block based on timeout instead of block size. The risk is that if this timeout is not properly selected, it could result in a queue build up (when load is high). {quote}  Can you elaborate about the queue part? What do you suggest to do if no incoming transactions for given ordering service? Are you suggesting to emit empty blocks? IMO this is might be a bit expensive storage wise in a long term.  I think the corner stone here is the absence of time, therefore prior to going into HTLC or any timeout based models for atomic exchanges we probably need to provide convincing/reasonable solution which could provide good time approximation.  ></body> </Action>
<Action id="58410" issue="36389" author="senthil1" type="comment" created="2019-03-21 19:04:38.0" updateauthor="senthil1" updated="2019-03-21 19:04:38.0"> <body><! CDATA  ~C0rWin   I agree that there are both pros and cons with any proposed approach. I think the issue related to storage consumption can be handled. As you know, we will be working on the checkpointing and pruning (the tentative proposal is here:  https://blockchain-fabric.blogspot.com/2018/09/checkpointing-for-efficient-blockchain.html)|https://blockchain-fabric.blogspot.com/2018/09/checkpointing-for-efficient-blockchain.html  which can take care of the storage consumption issue. Without checkpointing feature also, we could save the storage space by avoid storing a lot of duplicate certificates (assume that the same set of endorsers are endorsing all transaction, we will have the same certificate in all transactions). I am just saying that there could be a lot of mechanisms to solve the storage consumption issues and hence, an empty block should not be adding much of a burden. Having said that, i agree that having an empty block looks little odd.  Other than HTLC,  ~manish-sethi  and I also looked at 2-phase commit protocol which became too complex in our design. Our initial thought on this can be found here  https://blockchain-fabric.blogspot.com/2019/02/fabric-interoperability-atomic-commit.html  Though the designed protocol may not be accurate or correct, we understood the complexity and moved to the design of HTLC approach. Further, to perform an atomic commit with other platforms such as Ethereum, we need HTLC rather than 2 phase commit protocol.  As you know, there is a Jira FAB-3678 and proposal from  ~elli-androulaki   ~adc  on mapping the blockchain time to real-world time to detect x509 certificate expiry. We can see whether the same proposal can be employed here or can be extended to support HTLC. Note, currently, we support block to live for the private data expiry which is defined based on the block height. If we use the elapsed time calculated approximately out of the block timeout, it could help both the private data expiry and HTLC.   There is two major work in achieving the HTLC. One set of changes needed at the ledger and another at the orderer or some other new mechanism to express the time. Once the ledger related module for HTLC is implemented, I think the block height based, approximate elapsed time, real-time, etc... can be pluggable in to decide the duration of the lock and the trust model. IMO, both work can happen in parallel.     ></body> </Action>
<Action id="58505" issue="36389" author="yacovm" type="comment" created="2019-03-25 11:16:05.0" updateauthor="yacovm" updated="2019-03-25 11:16:05.0"> <body><! CDATA I agree with  ~hagarm   that relying on block number isn't a good approach, since there is no correlation between the amount of blocks and the time that passed, and like  ~C0rWin  pointed out - this exposes any protocol that relies on time to malicious attacks that artificially speed up time.   However, I am not sure that cutting a block upon a timeout is such a bad idea, as our use case essentially can work if we have a discretization of the continuous time to periods of a certain coarse granularity.    I'd say that aborts in cross chain transactions are rare, since the parties usually agree out of band on the details of the swap, and therefore a timeout of ~ 30 minutes would suffice, and there is no need to go any lower than that (but it should be configurable by the channel admins).  So, if we tie each data block to its corresponding half an hour time period - we can perhaps use this as a building block for a timeout. What if we had a special field in the block that associates it to its corresponding "time bucket", and if we have no traffic in the channel - we emit a block once per 30 minutes.  First, let's compute the overhead of such a feature: if we have transactions then we can piggyback this to the existing blocks, so we the overhead is zero. If we have no transactions, then we need to emit a block once per 30 minutes. A block signature signed by a CFT orderer (let's overlook BFT for now) is around 700 bytes, and there is no data in that block - just the header, so it means 700 bytes per half an hour, which sounds pretty cheap to me (an upper bound would be 12MB per year).  The hard part in this, is that leaders now need to keep track of time, which isn't possible because leaders can come and go. What we can do, is to persist in each block the time the leader created it, and then have the leader keep track of the blocks created an hour minutes ago and when 30 minutes pass - either a new "time block" is created, or the 30 minutes indicator is piggybacked to the next created block. This works also if the leader crashes, as the leader taking over would simply look back at the earlier blocks and then emit a time block or piggyback it upon demand.   However, this gets complex in the Byzantine setting, as a byzantine leader might not create a block within a timely manner, and the other consenters would need to be aware of it and overthrow that leader, but at the same time - if a Byzantine leader cuts a block prematurely - it hurts the correctness of the protocol, because the Byzantine leader of the counterparty blockchain may cut blocks too late, and then the x2 timeout guarantee won't hold.    ></body> </Action>
<Action id="58506" issue="36389" author="vukolic" type="comment" created="2019-03-25 11:20:29.0" updateauthor="vukolic" updated="2019-03-25 11:20:29.0"> <body><! CDATA If ordering service is to output a timestamp that resembles what humans call "real-time" - we should have another Jira only for that.  Doing this in BFT is not at all trivial - but it is doable with adequate assumptions.  ></body> </Action>
<Action id="58641" issue="36389" author="praveen.j" type="comment" body=" ~yacovm  What you suggest is workable, but as both you and  ~vukolic  call out, ensuring it works in a Byzantine setting could be non-trivial. Which is why we had suggested an intermediate solution of cutting blocks only on timeout and not based on size (no one can speed up block formation). We do not need a strict notion of time to enforce timeouts and a discussion on how to enforce &apos;real&apos; time is an orthogonal topic that requires a separate discussion. As  ~Senthil1  pointed out, how the timeout is specified and enforced can be pluggable and modified later as well." created="2019-03-27 18:45:59.0" updateauthor="praveen.j" updated="2019-03-27 18:45:59.0"/>
