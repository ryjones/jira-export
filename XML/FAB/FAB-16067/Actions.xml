<Action id="62958" issue="41399" author="rameshthoomu" type="comment" body=" ~scottz  I am using 1000tx per thread per channel, so this comes around 4000tx (2 threads and 2 channels)." created="2019-08-15 18:08:59.0" updateauthor="rameshthoomu" updated="2019-08-15 18:08:59.0"/>
<Action id="63741" issue="41399" author="rameshthoomu" type="comment" created="2019-09-12 19:27:41.0" updateauthor="rameshthoomu" updated="2019-09-12 19:27:41.0"> <body><! CDATA Testing is in-progress. Below are observations made so far.  TestEnvironment: 1Cpu 4GB memory on peer 1 channel 1 org and 1 process sample cc chaincode orderer: #! Consensus type orderertype: etcdraft batchsize: maxmessagecount: 100 absolutemaxbytes: 99 MB preferredmaxbytes: 10 MB batchtimeout: 2s #! Etcd raft options and this will be used when orderertype is #! selected as etcdraft etcdraft_options: TickInterval: 500ms ElectionTick: 10 HeartbeatTick: 1 MaxInflightBlocks: 5 SnapshotIntervalSize: 100 MB  TC#1 Used 4M payload for about 40 transactions and all worked as expected.  TC#2 Used 49MB payload size and sent 1 tx using PTE client. Observed leader is dropping and the block is not delivering. Attached are the logs from orderer.  ^Untitled     ></body> </Action>
<Action id="63805" issue="41399" author="rameshthoomu" type="comment" body="https://gerrit.hyperledger.org/r/#/c/fabric-test/+/33498/" created="2019-09-17 19:17:07.0" updateauthor="rameshthoomu" updated="2019-09-17 19:17:07.0"/>
<Action id="63808" issue="41399" author="rameshthoomu" type="comment" body="10K transaction test case has been removed from the pool of system test cases but covered the same in samplecc with Random  payload sizes. Also, for now 49MB payload test case has been added to the list but to make it work we have to increase the TickInterval to 1 sec from 500ms. Also the current test configured to run 4MB payload for 10 tx on 4 threads." created="2019-09-17 19:48:42.0" updateauthor="rameshthoomu" updated="2019-09-17 19:48:42.0"/>
<Action id="63828" issue="41399" author="scottz" type="comment" created="2019-09-18 14:21:00.0" updateauthor="scottz" updated="2019-09-18 14:21:00.0"> <body><! CDATA As discussed, doubling the tick interval will double the time it takes for the orderers to trigger a reelection of new leader in a new term when they no longer receive heartbeat ticks. With our current host configuration and disk speeds, in a network using raft, this would allow the test to pass, since the leader seems to be taking about 7 seconds to write a single 98 MB transaction block to the WAL. During that time, the leader cannot send out any heartbeat ticks to other orderers. With the HeartbeatTick=1 and TickInterval=500ms, the leader election timeout is 5 secs which is when the other orderers trigger a new term and leader election. Doubling the time to 10s will allow the orderer leader to complete the write to the WAL and then to resume sending heartbeats within the 10s interval.  However, that means it takes the other orderers 10s to realize the leader is in trouble. When the trouble is real and permanent, that means the network is effectively halted for 10s instead of 5s (which is the default setting). It is recommended to avoid lengthening the recovery time for outages, and instead increase the disk speed to handle disk writes. We can explore that, but of course, that comes at a monetary cost, and note that we are sending these huge msgs only for a single test in a network k8s cluster which is used for many other things including restarts and chaos testing (where lengthened recovery times would be undesirable).  Therefore, it seems best to avoid increasing the HeartbeatTicks or the TickInterval. Instead, I propose to run the max TX size testcase (98MB) in the kafka network only, and just use a max of 50MB in the raft network with our current configuration. Alternatively, we could revisit this at any time, and could increase the disk write speeds of the hosts in our k8s cluster if the additional cost is deemed acceptable.  ></body> </Action>
<Action id="63887" issue="41399" author="rameshthoomu" type="comment" body="Created new task to test the same size of payloads in kafka based networks https://jira.hyperledger.org/browse/FAB-16659" created="2019-09-19 16:07:35.0" updateauthor="rameshthoomu" updated="2019-09-19 16:07:35.0"/>
