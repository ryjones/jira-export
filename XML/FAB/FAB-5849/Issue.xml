<Issue id="20300" key="FAB-5849" number="5849" project="10002" reporter="scottz" assignee="yacovm" creator="scottz" type="10004" summary="coming late to the party, lagging peer crashes due to exhaustion" priority="2" resolution="10000" status="6" created="2017-08-19 15:00:55.0" updated="2018-07-20 14:14:09.0" resolutiondate="2017-09-24 14:01:31.0" votes="0" watches="5" workflowId="39792"> <description><! CDATA +Summary+:  A lagging nonleader peer has memory exhaustion and crashes while trying to catch up. A new gossip-non-leader peer resets 6-10 mins after joining a network channel when existing peers ledger exceeds 20000 blocks. It recovers close to 2000 blocks and then crashes. Also, but rarely, a peer that joins and becomes a gossip-orgleader crashes (say 1 out of 10 times). This happens on v1.0.1, with and without the solution FAB-5793.  +Scenario+ # Establish a network using docker swarm with multihost configuration. Refer to attached configuration files. Create one channel which has processed and written more than 10000 transactions to the ledger. For all peers, set CORE_PEER_GOSSIP_USELEADERELECTION=false. With two peers in one org, set one peer as leader (CORE_PEER_GOSSIP_ORGLEADER=true) and set the other one as nonleader (CORE_PEER_GOSSIP_ORGLEADER=false). # Join a third peer, set as nonleader (CORE_PEER_GOSSIP_ORGLEADER=false). # We turned on gossip debug logs and could see the peer requesting 10 blocks at a time from neighboring peers and gradually trying to "catch up" its ledger closer to the size of the existing peers. (As expected, we do not see any logs saying "cannot enqueue block with sequence of", because the inflow of blocks to the new peer is only in groups of 10 at a time, as requested by the peer itself. A different test, when a peer joins and becomes an orgleader and connects to an orderer, produces different behavior which makes use of the "blocking" solution of FAB-5793.) # The new peer spontaneously resets, without any error logs in the peer container logs, after about 10 mins after joining new peer.  +Observations+ * It appears to be a memory exhaustion problem. * It happened quickly. * It can be reproduced every attempt. * We tried configuring the "newly joining peer" on different host, and observed same problem. * And, when joining peer as an orgleader, we saw it happen once or twice in about 11 attempts. * We executed "top" in the host which contained docker containers for this new peer as well as a few others, and we noticed +CPU usage > 100%+ and noticed +memory usage climbing quickly past 50% and above 90% after 3 minutes.+ We captured some other linux system logs too.  {code:java} top - 14:46:20 up 51 days, 4:27, 1 user, load average: 4.88, 3.69, 2.76 Tasks: 196 total, 4 running, 192 sleeping, 0 stopped, 0 zombie %Cpu(s): 32.9 us, 30.2 sy, 0.0 ni, 31.8 id, 3.8 wa, 0.0 hi, 1.3 si, 0.0 st KiB Mem : 8175024 total, 156032 free, 7795564 used, 223428 buff/cache KiB Swap: 4194300 total, 1944476 free, 2249824 used. 98044 avail Mem  PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND  18027 root 20 0 9584564 7.084g 5704 S 120.5 90.9 5:23.09 peer  1650 root 20 0 111756 436 352 R 99.7 0.0 27199:48 x11vnc  19591 root 20 0 2861080 53368 10508 S 16.9 0.7 433:22.16 dockerd  18008 root 20 0 421516 1992 0 S 6.0 0.0 0:18.76 docker-containe  44 root 20 0 0 0 0 S 4.3 0.0 1:27.28 kswapd0  {code} Looking in file /var/log/kern.log , we saw: {code:java} Aug 17 16:55:39 multihost15 kernel:  4430259.788325  Out of memory: Kill process 23925 (peer) score 931 or sacrifice child Aug 17 16:55:39 multihost15 kernel:  4430259.788338  Killed process 23925 (peer) total-vm:11930304kB, anon-rss:7676004kB, file-rss:0kB  {code} Looking in file /var/log/syslog , we saw: {code:java} Aug 17 16:55:43 multihost15 dockerd 19591 : time="2017-08-17T16:55:43.129099623-04:00" level=error msg="fatal task error" error="task: non-zero exit (137)" module="node/agent/taskmanager" node.id=ziblrz0z5ntplqueaq7o3zqhp service.id=nmjcpxd55wj0k83u7qjn3i3n8 task.id=sbjyia9kduyrwrst7su2aeouh  {code}  Here are the environment variables used for the lagging peer: {code:java} CORE_PEER_ADDRESSAUTODETECT=false \ CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock \ CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=basic \ CORE_LOGGING_LEVEL=ERROR \ CORE_PEER_TLS_ENABLED=true \ CORE_PEER_COMMITTER_ENABLED=true \ CORE_PEER_GOSSIP_ORGLEADER=false \ CORE_PEER_GOSSIP_USELEADERELECTION=false \ CORE_PEER_PROFILE_ENABLED=true \ CORE_PEER_ADDRESS=peer2.org1.example.com:7051 \ CORE_PEER_ID=peer2.org1.example.com \ CORE_PEER_MSPCONFIGPATH=/etc/hyperledger/fabric/msp \ CORE_PEER_LOCALMSPID=Org1MSP \ CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051 \ CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt \ CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key \ CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt \ {code}    ></description> </Issue>
