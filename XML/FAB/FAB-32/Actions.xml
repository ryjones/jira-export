<Action id="18525" issue="12331" author="kchristidis" type="comment" created="2016-08-15 14:43:33.0" updateauthor="kchristidis" updated="2016-08-15 14:43:33.0"> <body><! CDATA I have built a Docker image for Kafka/Zookeeper: https://github.com/kchristidis/docker-kafka  This acts as our ordering node, what we call a "solo" orderer.  ></body> </Action>
<Action id="18526" issue="12331" author="kchristidis" type="comment" created="2016-08-15 14:59:21.0" updateauthor="kchristidis" updated="2016-08-15 14:59:21.0"> <body><! CDATA I am building the orderer in this repo: https://github.com/kchristidis/kafka-orderer  This is where I also maintain a rough TODO list of sorts.  ></body> </Action>
<Action id="18527" issue="12331" author="kchristidis" type="comment" body="Support for the Broadcast RPC has been added." created="2016-08-15 15:01:28.0" updateauthor="kchristidis" updated="2016-08-15 15:01:28.0"/>
<Action id="18528" issue="12331" author="kchristidis" type="comment" created="2016-08-15 15:06:33.0" updateauthor="kchristidis" updated="2016-08-15 15:06:33.0"> <body><! CDATA Currently working on the Deliver RPC.  The Golang Kafka libraries do not support the Seek() method, so implementing this in a straightforward manner is not possible.  To make matters a bit more complicated, the use of Seek() mid-consumption is considered unsafe even in the Java library. I will add this the proper way, by stopping the consumption of the partition first, and then resuming it at the right offset. The downside to this is that it will introduce delays because we'll kick into rebalancing mode. I will see if there is any way to mitigate this side-effect.  ></body> </Action>
<Action id="18539" issue="12331" author="mastersingh24" type="comment" body=" ~kchristidis  what are / were you trying to do with the Seek() method?  In this in the case where you realize you are missing something?  If you don&apos;t want to trigger a rebalance but simply wish to momentarily stop consumption, you can use the pause() method (at least in Java)" created="2016-08-16 11:40:26.0" updateauthor="mastersingh24" updated="2016-08-16 11:40:26.0"/>
<Action id="18540" issue="12331" author="kchristidis" type="comment" created="2016-08-16 12:04:26.0" updateauthor="kchristidis" updated="2016-08-16 12:04:26.0"> <body><! CDATA  ~mastersingh24  Have a look at the proto with the RPC definitions: https://github.com/kchristidis/kafka-orderer/blob/devel/ab/ab.proto  Via the properties message type, the Deliver() client is effectively able to say "I'd like to start from message with offset X". My Deliver() server can deliver a stream of messages starting from X by setting up a PartitionConsumer whose config is set to that offset, no problem.  Now assume that mid-consumption, the Deliver() client sends a new properties message with a certain specified_number (offset), because the back-office process they are connected to messed up. Ideally, I wanted to be able to seek to that number within the existing PartitionConsumer.  As I stated in yesterday's comment, this is however not possible in the Go libraries, and even in the Java world where it is, it is considered unsafe.  Therefore in my current not-yet-pushed code, I close this PartitionConsumer and start a new one configured with the desired starting offset. This is the only proper way to do it.  Let me know if that answers your question.  ></body> </Action>
<Action id="18542" issue="12331" author="mastersingh24" type="comment" body=" ~kchristidis   Got it.  Makes sense.  By the way, rebalancing only happens if you are using consumer groups which I don&apos;t think we&apos;d want to use in this scenario anyway since we want all clients to get all messages." created="2016-08-16 14:26:26.0" updateauthor="mastersingh24" updated="2016-08-16 14:26:26.0"/>
<Action id="18554" issue="12331" author="kchristidis" type="comment" body=" ~mastersingh24  You&apos;re right on the rebalancing note. (And FWIW we do have consumer groups, it&apos;s just that they&apos;re groups of one.)" created="2016-08-16 19:49:15.0" updateauthor="kchristidis" updated="2016-08-16 19:49:15.0"/>
<Action id="18658" issue="12331" author="kchristidis" type="comment" body="An implementation of this is now up and running: https://github.com/kchristidis/kafka-orderer/tree/devel. I need to add a bunch of tests however, so not marking it as done yet." created="2016-08-24 08:06:33.0" updateauthor="kchristidis" updated="2016-08-24 08:06:33.0"/>
<Action id="18659" issue="12331" author="kchristidis" type="comment" created="2016-08-24 08:19:57.0" updateauthor="kchristidis" updated="2016-08-24 08:19:57.0"> <body><! CDATA Of note, with regards to creating blocks of X messages:  - It is not possible to have the orderer (i.e. the Kafka broker) output a batch/block for, say, every 10 messages sent its way. (Unless we work with Kafka Streams, I guess.) - Additionally, the consumer can only specify a min/max fetch size. Therefore, unless every message has a fixed size, we cannot guarantee that the consumer will be reading a batch of, say, 10 messages as a time. (Note: I am not talking about the window here.)  The only way to get "batches" is if you have the producer batch the messages up into a block, but that's not the batching we're looking for. (You'll have a block with messages coming from A, and a separate block with messages coming from B, etc.) I may always be missing something.  ></body> </Action>
<Action id="18678" issue="12331" author="kchristidis" type="comment" created="2016-08-25 07:53:36.0" updateauthor="kchristidis" updated="2016-08-25 07:55:48.0"> <body><! CDATA Also worth noting that the folks behind Kafka are working on a Go library. Right now it's mostly a wrapper around librdkafka, the C library. You can find it here but it's clearly alpha: https://github.com/confluentinc/confluent-kafka-go  A review of it can be found here: http://www.agardner.me/golang/kafka/library/sarama/confluent/2016/08/24/kafka-go-library.html (I'malso using sarama, same as the author.)  ></body> </Action>
<Action id="18797" issue="12331" author="kchristidis" type="comment" created="2016-09-06 21:01:45.0" updateauthor="kchristidis" updated="2016-09-06 21:04:56.0"> <body><! CDATA - Updated the design - Added block cutting logic - Enabled Glide for package management - Updated the documentation  All basic functionality needed expected from the SOLO orderer is there: https://github.com/kchristidis/kafka-orderer/tree/devel  Working on tests now -- using this opportunity to try out the GoConvey framework: http://goconvey.co  ></body> </Action>
<Action id="18874" issue="12331" author="kchristidis" type="comment" body="Updated to an epic according to Binh&apos;s instructions." created="2016-09-13 06:02:17.0" updateauthor="kchristidis" updated="2016-09-13 06:02:17.0"/>
<Action id="18989" issue="12331" author="kchristidis" type="comment" body="Added unit tests." created="2016-09-25 17:16:14.0" updateauthor="kchristidis" updated="2016-09-25 17:16:14.0"/>
<Action id="19005" issue="12331" author="kchristidis" type="comment" body="Added support for the orderer/config package introduced in the feature/convergence branch: https://github.com/kchristidis/kafka-orderer/commit/a9bb5e7c67f3f4f3c10784176801efd4299de3a7" created="2016-09-27 04:55:56.0" updateauthor="kchristidis" updated="2016-09-27 04:55:56.0"/>
<Action id="19012" issue="12331" author="kchristidis" type="comment" body="Added support for MaxWindowSize: https://github.com/kchristidis/kafka-orderer/commit/a109782be0c6dd821ef76c65f52b707e5bd82594" created="2016-09-27 14:51:56.0" updateauthor="kchristidis" updated="2016-09-27 14:51:56.0"/>
<Action id="19084" issue="12331" author="kchristidis" type="comment" created="2016-10-01 21:03:15.0" updateauthor="kchristidis" updated="2016-10-01 21:03:15.0"> <body><! CDATA Fixed Docker Compose issue related to the Kafka broker's ADVERTISEMENT_HOST.  I've also updated the docker-kafka image accordingly and cleaned up the supervisord execution path as well: https://github.com/kchristidis/docker-kafka  As soo as we upgrading the Vagrant image to Go 1.7, the Kafka orderer is good to.  Tested here: https://github.com/kchristidis/fabric/tree/kafka-orderer-complete/orderer  ></body> </Action>
<Action id="19085" issue="12331" author="kchristidis" type="comment" created="2016-10-01 21:12:31.0" updateauthor="kchristidis" updated="2016-10-01 21:12:47.0"> <body><! CDATA And just in case anyone's curious, I created a Docker Compose file and a super-lightweight image for the orderer to make experimentation easier:  https://github.com/kchristidis/kafka-orderer/blob/devel/docker-compose.yml  {{docker-compose up}}  Then use the sample client to broadcast blocks or have them delivered to you. (Target the Docker host's IP and the default port 5151.)  ></body> </Action>
<Action id="19175" issue="12331" author="kchristidis" type="comment" body="Up for review here: https://gerrit.hyperledger.org/r/#/c/1627/" created="2016-10-08 23:06:49.0" updateauthor="kchristidis" updated="2016-10-09 05:41:26.0"/>
<Action id="20021" issue="12331" author="kchristidis" type="comment" created="2016-12-07 23:21:14.0" updateauthor="kchristidis" updated="2016-12-07 23:23:33.0"> <body><! CDATA The first prototype of the Kafka orderer was completed a long time ago.  Closing this epic as we track its revisions through newer stories.  ></body> </Action>
