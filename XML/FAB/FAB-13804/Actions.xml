<Action id="55940" issue="37013" author="kchristidis" type="comment" created="2019-01-21 17:00:20.0" updateauthor="kchristidis" updated="2019-01-21 17:00:20.0"> <body><! CDATA Agreed with turning the Step RPC into a stream, this is a good proposal.  RE: Tuning timeouts - I agree we should make them a bit more lenient. (Obligatory link to  https://github.com/etcd-io/etcd/issues/4887  for figuring out the values for the parameters.)  ></body> </Action>
<Action id="55962" issue="37013" author="guoger" type="comment" created="2019-01-22 03:22:33.0" updateauthor="guoger" updated="2019-01-22 03:25:54.0"> <body><! CDATA 1. as we discussed in #fabric-orderer-dev, i like the idea!  2. i partially agree with this, but for different reason. - i'm not sure why tick-per-100ms is too harsh for a cluster located in single DC, where RTT is ~10ms. (granted that 1. is implemented) - as  ~kchristidis  commented, we should make {{ElectionTick}} 10x than {{HeartbeatTick}}, to avoid high probability of split vote. Otherwise we would significantly prolong failover time (especially with large {{TickInterval}} - {{TickInterval}} could be enlarged to reduce Heartbeat overhead, in a cluster with many channels. But a better way to do this, is to gather the information of active nodes from communication layer, i.e. a message has been sent/received between A and B recently, and simply drop outgoing {{MsgHeartbeat}} if it's sufficiently active. This way, in an idle channel, we have regular heartbeats to maintain liveness, and in a busy channel, we effectively kill the overhead of {{MsgHeartbeat}}  wdyt  ~kchristidis  ~yacovm   ></body> </Action>
<Action id="55977" issue="37013" author="yacovm" type="comment" created="2019-01-22 09:10:33.0" updateauthor="yacovm" updated="2019-01-22 09:10:33.0"> <body><! CDATA {quote}But a better way to do this, is to gather the information of active nodes from communication layer, i.e. a message has been sent/received between A and B recently, and simply drop outgoing {{MsgHeartbeat}} if it's sufficiently active. {quote}    This is a bad way of doing it, in my opinion: * Raft should be a black box. We don't want to make any assumptions on its algorithm. * The communication layer shouldn't contain logic that is related to the consensus implementation. * You have no idea if a message is really sent once you send it.... it's a gRPC stream. The node on the other side can be stuck in a deadlock and the gRPC buffer will still have room for lots of heart-beats.  ></body> </Action>
<Action id="55980" issue="37013" author="guoger" type="comment" created="2019-01-22 10:25:04.0" updateauthor="guoger" updated="2019-01-22 10:25:04.0"> <body><! CDATA {quote}Raft should be a black box. We don't want to make any assumptions on its algorithm. {quote} why not? we have the knowledge and the lib is implemented to give user the flexibility, i don't see why we should restrain ourselves from leveraging it. (even etcd itself intercepts outgoing messages) {quote}The communication layer shouldn't contain logic that is related to the consensus implementation {quote} if we maintain this liveness in chain, we don't need info from communication layer, no? {quote}You have no idea if a message is really sent once you send it.... it's a gRPC stream. The node on the other side can be stuck in a deadlock and the gRPC buffer will still have room for lots of heart-beats. {quote} that's why we should base on the messages received, instead of sent, i.e. I, raft leader, has recently received a {{MsgAppResp}} from a follower, so i have enough confidence to say that this follower has reset its {{ElectionTimeout}} recently enough, so I can defer sending out this heartbeat.  ></body> </Action>
<Action id="55982" issue="37013" author="tock" type="comment" created="2019-01-22 11:18:31.0" updateauthor="tock" updated="2019-01-24 07:21:56.0"> <body><! CDATA From my experience in these kind of clusters (and I have a lot), what needs to be done is the following:  For a fast, tightly coupled system, for example: nodes on bare-metal servers, connected by a fast LAN:  heartbeat-interval = 1s  heartbeat-timeout= 10s  for a cloud based system, on a less then perfect network:  heartbeat-interval = 3s  heartbeat-timeout= 30s  As a rule of thumb: heartbeat-timeout=10x heartbeat-interval. You can keep the ticks at 100ms.  When you reduce the heartbeat-timeout, you generally discover failures faster, but increase that chance of a false alarm. False alarms our bad in our context, and we do not  need need extra-fast failure detection. We need to keep the system stable. (FYI - in WebSphere clusters, the heartbeat timeout may be as large as 3 minutes).  These settings are comparable to what you find in systems like: zookeeper, kafka, and mongodb. No need to invent the wheel here.  As to the optimizations suggested above, I completely agree with Yacov - avoid doing this,  First - it is not needed; the bandwidth consumed by heartbeats is negligible compared to all the other traffic (as well as the bandwidth of modern networks.)  Second - treat Raft as a black box and adhere to the contract specified in the documentation, for the sanity of all involved.  In the words of Donald Knuth:  "premature optimization is the root of all evil." ;)     ></body> </Action>
<Action id="55983" issue="37013" author="yacovm" type="comment" body="I think the default should be tuned for a non-LAN environment, otherwise users will deploy this thing in a non LAN environment and at first their cluster might behave, but when it starts misbehaving - it will be too late for them (you need consensus to change the parameters)" created="2019-01-22 11:27:18.0" updateauthor="yacovm" updated="2019-01-22 11:27:18.0"/>
<Action id="55984" issue="37013" author="guoger" type="comment" created="2019-01-22 11:28:06.0" updateauthor="guoger" updated="2019-01-22 11:28:06.0"> <body><! CDATA As I mentioned in previous comment, election timeout should be 10x of heartbeat tick, and I think none of us objects that?  As for optimization, I was merely pointing out what should be done, but I firmly agree that it should be tackled later, when we actually see it becoming a problem.  As for blackboxing raft library, I’d keep my opinion but we certainly could defer this discussion, for the same reason aforementioned.  As for actually tick interval, I don’t understand why we go against etcd best practice?  ></body> </Action>
<Action id="55985" issue="37013" author="tock" type="comment" created="2019-01-22 12:19:13.0" updateauthor="tock" updated="2019-01-22 12:19:55.0"> <body><! CDATA  ~yacovm  I agree - better start with long timeouts and reduce if needed.     ></body> </Action>
<Action id="56073" issue="37013" author="guoger" type="comment" created="2019-01-23 06:17:46.0" updateauthor="guoger" updated="2019-01-23 06:17:46.0"> <body><! CDATA {quote} it will be too late for them (you need consensus to change the parameters) {quote} this is actually convincing...  how about interval of 500ms? so the worst failover time is 10s  cc  ~yacovm   ~tock   ></body> </Action>
<Action id="56079" issue="37013" author="yacovm" type="comment" body="(y)" created="2019-01-23 07:52:06.0" updateauthor="yacovm" updated="2019-01-23 07:52:06.0"/>
<Action id="56128" issue="37013" author="kchristidis" type="comment" created="2019-01-23 23:57:20.0" updateauthor="kchristidis" updated="2019-01-24 00:03:11.0"> <body><! CDATA {quote}As for actually tick interval, I don’t understand why we go against etcd best practice? {quote}  ~guoger : What is this in reference to? Can you expand?  +1 on deferring on the optimization where we infer liveness from {{MsgAppResp}}. This seems like a clever hack, but we're better off being done with this in a generic way and shifting our focus to BFT.   ~tock : Thanks for chiming in! That's good feedback.  ></body> </Action>
<Action id="56133" issue="37013" author="guoger" type="comment" created="2019-01-24 02:43:20.0" updateauthor="guoger" updated="2019-01-24 02:43:20.0"> <body><! CDATA I'm referring to  this|https://coreos.com/etcd/docs/latest/tuning.html  {quote} The value of heartbeat interval is recommended to be around the maximum of average round-trip time (RTT) between members, normally around 0.5-1.5x the round-trip time. {quote}  i'm not saying that we should be optimizing it *now*, but merely providing an easy workaround, *iff* this becomes an actual problem later on. This is not necessarily a hack, {{etcd}} intercepts messages, and this mechanism is also suggested by raft paper.  cc  ~kchristidis   ></body> </Action>
<Action id="56137" issue="37013" author="kchristidis" type="comment" created="2019-01-24 03:15:49.0" updateauthor="kchristidis" updated="2019-01-24 03:15:49.0"> <body><! CDATA Understood. I didn't know that about the Raft paper - thanks! (FWIW, I wasn't using the term _hack_ pejoratively.) Either way, sounds like we're all onboard for deferring.  RE: heartbeat value - what is the suggestion that goes against the best practice, as documented by the CoreOS folks?  ></body> </Action>
<Action id="56139" issue="37013" author="guoger" type="comment" created="2019-01-24 03:32:06.0" updateauthor="guoger" updated="2019-01-24 03:32:06.0"> <body><! CDATA setting it to 1s, where RTT is not that long (iks, local or CI)  but i'm good changing it to 500ms, as stated in https://jira.hyperledger.org/browse/FAB-13845. Although that's due to slow disk IO on CI, so we need to increase the interval to avoid flakes (long pause on leader due to wal sync, which prevents heartbeats from being sent timely, and results in unexpected leader failover)  ></body> </Action>
<Action id="56144" issue="37013" author="guoger" type="comment" created="2019-01-24 08:22:43.0" updateauthor="guoger" updated="2019-01-24 08:23:03.0"> <body><! CDATA a few more words on this:  {quote} the bandwidth consumed by heartbeats is negligible compared to all the other traffic (as well as the bandwidth of modern networks.) {quote}  it's not the bandwidth we are concerned here, it's more of cpu and extra cycles on machines to process these heartbeats.  ></body> </Action>
<Action id="56242" issue="37013" author="kchristidis" type="comment" body="LOL at the reworded title but OCD is OCD and I needed to come up with a story-like title, and we&apos;re doing these changes to benefit the end-user so that&apos;s our target persona. Feel free to revise." created="2019-01-28 05:19:47.0" updateauthor="kchristidis" updated="2019-01-28 05:19:47.0"/>
