<Action id="52594" issue="34813" author="jyellick" type="comment" created="2018-10-24 15:15:59.0" updateauthor="jyellick" updated="2018-10-24 15:25:58.0"> <body><! CDATA Edit: I had originally outlined a 'different' approach, which very much missed the point.  For anyone else reading who might similarly miss the point, the problem this is addressing, is that we may not be able to simply 'play the chains', because the set of orderers may have changed, along with TLS CAs etc.  With that context, I agree, this proposal looks good.  ></body> </Action>
<Action id="52597" issue="34813" author="yacovm" type="comment" body="Thanks  ~jyellick   ! " created="2018-10-24 15:40:22.0" updateauthor="yacovm" updated="2018-10-24 15:40:22.0"/>
<Action id="52655" issue="34813" author="kchristidis" type="comment" created="2018-10-25 16:43:15.0" updateauthor="kchristidis" updated="2018-10-25 16:43:15.0"> <body><! CDATA Recording this for posterity's sake, based on what we discussed during the scrum call today — a key assumption here is that the administrator of the about-to-be-onboarded OSN trusts the system channel config block that they are given (read: they've done their vetting offline). That is a reasonable assumption.  Assume that we have two OSNs in the cluster already. (Forget about Raft where that number might not make sense.) We now wish to onboard OSN C. C learns of the existence of channel {{foo}} via your proposal and gets different responses from A and B regarding {{foo}} ledger's height. How does C proceed?  I'm not aiming for a gotcha here - we're operating in the CFT domain for the time being. I want to know: # How we're proceeding for the time being # Whether what we build now can be easily modified to work in the BFT case  ></body> </Action>
<Action id="52659" issue="34813" author="kchristidis" type="comment" created="2018-10-25 18:33:18.0" updateauthor="kchristidis" updated="2018-10-25 19:13:37.0"> <body><! CDATA On a tangentially related matter —  Part of the functionality covered by Yacov's proposal above is: find out all the channels created so far, along with their OSN endpoints at the time of creation.  Is there a way to expose this functionality (and just this one) to someone with read rights on the system channel?  The hacky way would be to add this info to the metadata of the system chain config blocks, every time a channel is created. But this means that you have a metadata field that can balloon in size, and we're now treating metadata as a kitchen sink. Perhaps make it so that any channel creation creates a new node in the configuration tree? (In both cases a read of the latest configuration block would get us the answer we need.)   ~jyellick : IIRC Varad had brought up a similar request a while back. Is there a Jira issue that tracks any thoughts on this?  ></body> </Action>
<Action id="52660" issue="34813" author="yacovm" type="comment" created="2018-10-25 19:37:44.0" updateauthor="yacovm" updated="2018-10-25 20:14:33.0"> <body><! CDATA {quote}I'm not aiming for a gotcha here - we're operating in the CFT domain for the time being. I want to know: # How we're proceeding for the time being # Whether what we build now can be easily modified to work in the BFT case{quote}  ~kchristidis  It's a valid question.  I'd say, we need to pick some nodes, but be aware of the following corner cases: * A node might publish to you (the fresh new node) a block height that no other node has, and then either not respond (byzantine) or crash (failure). In such a case, you'll be stuck forever trying to pull blocks. So, a naive *maximum* won't work here. * A node might publish to you a block height that is lower than the last config block for the application channel, either because it's byzantine, or just because it was disconnected for a long time and is now catching up with the rest of the cluster, but hasn't caught up yet. I argue that if a node was disconnected for a long time and the configuration has changed so much that it can't connect back to the cluster, it needs to return service_unavailable to prevent nodes from taking it into consideration. This way, we make it that if an honest node returns an answer, it means it has connected to the cluster for that application channel, and - that means that if your node is going to pull blocks up to that block height, it will also be able to connect to the cluster, unless the channel admins decide to reconfigure the channel config, which is unlikely because.... you're adding a new node, and it's their responsibility to not interfere with this. Therefore we 're only left with the case where a node maliciously sends you a block height that is too low.  Since BFT can only tolerate *f* failures, I'd say that we can do something similar to this: Denote the last block sequences of *n=3f+1* nodes as: *h1, h2, ... h_n* and assume they are sorted in ascending order. We take the block heights with "slacks" of *f* nodes from each side, that is - we take the heights of *h_\{f+1}, h_\{f+2}, ... h_\{2f+1}* and pick the "median" one, that is - one that has more than *f* heights to its left, and more than *f* heights to its right.  If we have nodes that are unreachable to us, as long as we still have more than *f+1* honest nodes we can reach, it leaves us with *f+1* heights of honest nodes, and *f* heights of malicious nodes, so we'll always have that *1* extra height in the middle that would belong to an honest node.  So, in the extreme case if we are left with *f+1* honest nodes and *f* malicious nodes that we can connect to (let's assume that the existing nodes can connect to each other, but the new node can only connect to *2f+1* nodes, out of which *f* are malicious) - we'll pick the median height and be saved and after we pull the blocks - if we can eventually connect to the rest of the cluster, we can then officially join the cluster as a new node and we won't be forked.  For CFT, I guess we can just take the median one among all nodes.     Edit - when I mean block heights, I mean last config block heights. The actual blocks after the config blocks are not interesting as the chains can just pull them when they are initialized.  ></body> </Action>
<Action id="52661" issue="34813" author="yacovm" type="comment" created="2018-10-25 19:46:24.0" updateauthor="yacovm" updated="2018-10-25 20:56:54.0"> <body><! CDATA After you get the height, you can just check *2f+1* nodes and get the majority hash, and this is what you trust until that point in time. The missing piece here, is that you have no knowledge of *n* or *f* for the channel...  Denote *F* and *N* as the number of malicious, total nodes for the system channel. I claim that all *f* malicious nodes in some application channel are contained in the *F* malicious nodes in the system channel. Otherwise, there is a node that is malicious in an application channel and not in the system channel, and that's not realistic.  Our goal is to derive *n* and *f* from *N* and *F* .  Even if we query all *N* nodes, let's say *2F+1* of them respond honest answers, and we ask them of the last config block of the application channel.  At least *2f+1* of them are going to respond honestly, and they are all contained in the *2F+1* nodes.  However, a total of *F-f+n* can respond - the nodes in the application channel but also the malicious nodes outside of the application channel, but inside of the system channel.  We can't even do a majority vote, since *n* can be really small in comparison to *N* , i.e - if the application channel has 10 nodes with *F=3* but the cluster has 4 nodes... a majority vote on the application channel would have only 3 correct blocks, and 3 incorrect blocks from the *F* malicious nodes, and 4 (10-3-3) would be "N/A" votes that don't count, so it's a tie.     I think, that if we can just take the genesis block of the application channel from the system channel, it's secure enough to validate all the signatures from that point onwards, until the last height that is repoted by any node.  So, in BFT - maybe what we need to do, is - just query all the nodes in the system channel for the last config block of the application channel, and then try to pull until the minimum of the block heights, and then pull blocks and verify them with the previous committed config blocks, until we reach a height for which we can't fetch that block from any node, or that every node that returns a block for that height - returns one that cannot be verified.  ></body> </Action>
<Action id="52682" issue="34813" author="jyellick" type="comment" created="2018-10-26 13:27:44.0" updateauthor="jyellick" updated="2018-10-26 13:27:44.0"> <body><! CDATA Sorry for being late to the discussion, and hopefully I'm not missing something like in my original comment in this thread, but:  1. Given the latest config block for the orderer system channel, the new orderer may safely pull the entire orderer system channel.  2. As part of pulling the orderer system channel, each orderer may construct the genesis block for each channel.  This is a deterministic operation and uses only data embedded in the orderer system channel.  3. If each application channel is bootstrapped using this 'definitely correct' genesis block, then the orderer may pull blocks from any valid orderer, and use the constructed channel config for that channel to validate the block signatures on the blockchain according to the block validation policy.  As the orderer set for that channel mutates, so does the block validation policy, and therefore there's no need to pull from more than one node (unless the blocks returned do not satisfy this policy).  So where is the problem?  We need the latest orderer system channel config in order to get TLS certs and valid orderer addresses.  But assuming we have those, we should be able to pull the chains and play them forward normally? The key here being that the set of signatures embedded in the block must be correct at a point in time, not according to the latest channel config.  ></body> </Action>
<Action id="52684" issue="34813" author="yacovm" type="comment" created="2018-10-26 14:08:58.0" updateauthor="yacovm" updated="2018-10-26 14:08:58.0"> <body><! CDATA {quote}  so does the block validation policy, and therefore there's no need to pull from more than one node (unless the blocks returned do not satisfy this policy). So where is the problem? {quote}  The problem is termination. You don't know what is the last config block in the application channel. Let's say that at some point, there was a config change that changed the TLS certificates of the OSNs, and that was the last config change that did it. When you onboard a new OSN you have to make it pull that config block, else it can't replicate using the chain mechanisms, because the chain mechanisms rely on the communication layer to send you metadata about yourself being late, and what blocks you should pull to catch up, but if the TLS certificates were changed in a config block which you are not aware of, you will reject all TLS handshakes because of TLS pinning is used.   Therefore you need to know the last config block before you initialize the chain when you onboard.  But, a malicious BFT node might send you config blocks up to an earlier height, and actually not send you the last config block that you need, and you'll be stuck.   ></body> </Action>
<Action id="52688" issue="34813" author="kchristidis" type="comment" created="2018-10-26 14:54:46.0" updateauthor="kchristidis" updated="2018-10-26 14:54:46.0"> <body><! CDATA I still don't quite follow, and I think Jason is touching on what I reached out to you for in RC yesterday. (Mainly that if you're OK with the new OSN getting config block X which is not actually the very latest config block, then you _should_ in theory be OK with the new OSN making ends meet with the genesis block for that channel.)  Are we saying that the issue is: we need a config block that is recent enough, in the sense that it records the TLS certificates that correspond to a currently active quorum?  ></body> </Action>
<Action id="52689" issue="34813" author="yacovm" type="comment" body="Yes, I&apos;m saying that the issue here is TLS certificates in the config block which you never obtain, thus the TLS pinning authentication fails and you can never synchronize with the cluster in the consensus driven way." created="2018-10-26 15:03:28.0" updateauthor="yacovm" updated="2018-10-26 15:03:28.0"/>
<Action id="52692" issue="34813" author="kchristidis" type="comment" created="2018-10-26 16:08:34.0" updateauthor="kchristidis" updated="2018-10-26 16:08:34.0"> <body><! CDATA Perhaps then the requirement should be that I, as a new OSN administrator, should be given both a recent system channel config block, _and_ a recent config block from all the channels I'm allowed to join?  The usability hit is tremendous, but we avoid the murkiness of how to get a recent-ish config block on the channels we have access to, and the logic on finding which channels we have access to becomes simpler as well.  ></body> </Action>
<Action id="52693" issue="34813" author="yacovm" type="comment" created="2018-10-26 16:19:58.0" updateauthor="yacovm" updated="2018-10-26 16:19:58.0"> <body><! CDATA The usability hit isn't tremendous, as we don't do this very often.  I think for CFT we can go on without, and not require this for now, and when we reach the BFT bridge we'll see how to cross it.  In any case I certainly see this as a valid solution (receiving all config blocks of application channels).  ></body> </Action>
<Action id="52694" issue="34813" author="yacovm" type="comment" created="2018-10-26 16:24:30.0" updateauthor="yacovm" updated="2018-10-26 16:24:30.0"> <body><! CDATA So, for CFT I think we should only have the latest config block of the system channel and the orderer itself will just find some OSN that has the block via querying everyone possible, and obtaining the median of all answers. This is under the assumption that a Raft orderer that can't connect to the cluster, will return service unavailable.   I am hesitant to require all application channel blocks and I think that if I can go an extra mile to avoid it, it's worth it usability wise.  ></body> </Action>
<Action id="52696" issue="34813" author="jyellick" type="comment" created="2018-10-26 17:46:52.0" updateauthor="jyellick" updated="2018-10-26 17:46:52.0"> <body><! CDATA Ah, so this is a problem of "when do we conclude we're up to date on the channel?".  The naive/obvious way to me, is to identify the subset of orderers in the orderer system channel which service the channel, then pull from the first until it runs out of blocks, then ask the next to start from the last block the first orderer claimed was the last, and keep going until you've exhausted all orderers.  Probably a little overkill (you'll be hitting N, not f+1), but the cost should be pretty negligible, and nothing out of band.  I think this works because we agreed, all valid orderers must service the orderer system channel?  ></body> </Action>
<Action id="52698" issue="34813" author="yacovm" type="comment" body=" ~jyellick  did you mean this idea to be used for BFT or CFT or both?" created="2018-10-26 18:27:14.0" updateauthor="yacovm" updated="2018-10-26 18:27:23.0"/>
<Action id="52699" issue="34813" author="jyellick" type="comment" body="Both.  In CFT it should be unnecessary, but, the penalty is so small, I see no reason not to." created="2018-10-26 18:38:44.0" updateauthor="jyellick" updated="2018-10-26 18:38:44.0"/>
<Action id="52701" issue="34813" author="yacovm" type="comment" created="2018-10-26 18:58:56.0" updateauthor="yacovm" updated="2018-10-26 18:58:56.0"> <body><! CDATA What I'm worried about, is that "pull from the first until it runs out of blocks" is not trivial because blocks may form once per batch timeout and then you'll never run out of blocks. How about just polling all orderer nodes and fetching the last block and seeing what is the last config block index that corresponds to that last block, for CFT?   ></body> </Action>
<Action id="52702" issue="34813" author="jyellick" type="comment" created="2018-10-26 19:52:23.0" updateauthor="jyellick" updated="2018-10-26 19:52:23.0"> <body><! CDATA > What I'm worried about, is that "pull from the first until it runs out of blocks" is not trivial because blocks may form once per batch timeout and then you'll never run out of blocks.  The {{Deliver}} service has explicit support for not encountering this problem.  You may specify `NEWEST` as the end block when you connect to deliver.  The deliver service stores the block height at the time of the request, and returns blocks through this number.  So, no new blocks would cause the request to take longer.  Once the target block is reached, it returns a SUCCESS indicating that the deliver request was completed.  ></body> </Action>
<Action id="52703" issue="34813" author="kchristidis" type="comment" created="2018-10-26 19:53:10.0" updateauthor="kchristidis" updated="2018-10-26 19:53:10.0"> <body><! CDATA bq. How about just polling all orderer nodes and fetching the last block and seeing what is the last config block index that corresponds to that last block, for CFT?  I think that can work. (That block is committed so it's persisted by a quorum. If that entire quorum goes down and the new OSN cannot fetch it, we've got bigger problems.)  ></body> </Action>
