<Issue id="16540" key="FAB-3770" number="3770" project="10002" reporter="bmos299" creator="bmos299" type="10000" summary="The FAB Stories and Tasks for all Tests in the Daily Test Folder" priority="1" resolution="10000" status="6" created="2017-05-10 13:32:53.0" updated="2019-08-01 01:09:55.0" resolutiondate="2019-08-01 01:09:55.0" votes="0" watches="3" workflowId="43168"> <description><! CDATA This epic will list all the tests that are run in CI for //fabric/test/regression/daily.  Please put the following information in your test description in jira:  +Fabric Test Template+: * ++Test Name+:  <JIRA>_<Title>+ * +Component+:  <use the Component column from the testplan> * +Description+:  <test overview and objective> * +Artifact Locations+:  <location of test script and input files> * +Network Topology+:  <number of nodes of each type; use "standard" for our standard docker-compose file that is being used for most tests> * +Client Driver+:  <test tool> * +Input+:  <command to run the test> * +Output+:  <key portions of stdout of running the test, showing it passes>  In order to provide a good user experience when reading the CI automation test suite output reports: * create a test filename that includes the Component (Orderer, Ledger, Endorser, etc, or use "systest" for system tests covering the entire network when the focus is not specifically on a particular component); in addition, the filename should also include the Client Driver test tool (e.g. Behave, CLI, PTE, OTE, LTE, ...); and use underscores between each word * Inside the file, use a group / classname that includes the feature or category of test coverage * In each classname, create specific testcase titles that differentiate it from other tests, showing the test objective unique to that test. The testnames must start with the string "test_" so that the tools such as Behave and pytest can execute them correctly.  Here are some examples, using this format:  filename (component_driver) , classname (feature_focusArea) , test name * systest_pte , perf_stress , test_FAB3814_Payload_1Meg * systest_pte , perf_reliability , test_FAB3820_TimedRun_12Hr * orderer_behave , bootstrap , test_FAB0000_SetupStandardNetwork * ledger_lte , perf_couchdb , test_FAB_3870_VaryNumParallelTxPerChain * systest_cli , integration , test_FAB0001 , test_e2e_cli * systest_cli , integration , test_FAB0002 , test_e2e_nodesdk * systest_cli , chaincodetest , test_FAB0003 , test_example02_API_4peers  Note: Many of our system tests will use the same docker-compose file (or docker swarm file) that creates our "Standard Network" configuration:  "Standard Network": * 3 Ord, 4 KafkaBrokers, 3 ZooKeepers, 2 Orgs, 2 Peers/Org, 1 Chan, sample_cc, 2 thrds     Note: Recommended Configuration for a kafka-based orderer service:  3 Orderers, 4 kafkabrokers, 3 zookeepers  Refer to all the Kafka-related settings here:  https://github.com/hyperledger/fabric/blob/master/bddtests/dc-orderer-base.yml  (`ORDERER_KAFKA_*`)  https://github.com/hyperledger/fabric/blob/master/bddtests/dc-orderer-kafka-base.yml   https://github.com/hyperledger/fabric/blob/master/bddtests/dc-orderer-kafka.yml  Anything not set explicitly in those places, above, is assumed to have the default value taken from here:   https://kafka.apache.org/documentation/#brokerconfigs  The two additional things that someone would set are TLS and `{{log.retention.hours}}` (`KAFKA_LOG_RETENTION_HOURS`)  which will need to be set to a large value in a production environment. For every orderer: - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_KAFKA_RETRY_SHORTINTERVAL=1s - ORDERER_KAFKA_RETRY_SHORTTOTAL=30s - ORDERER_KAFKA_VERBOSE=true  For every kafka: - KAFKA_MESSAGE_MAX_BYTES=103809024 # 99 **1024* *1024 B - KAFKA_REPLICA_FETCH_MAX_BYTES=103809024 # 99 **1024* *1024 B - KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE=false - KAFKA_MIN_INSYNC_REPLICAS=2 - KAFKA_DEFAULT_REPLICATION_FACTOR=3 - KAFKA_ZOOKEEPER_CONNECT=zookeeper0:2181,zookeeper1:2181,zookeeper2:2181  ></description> </Issue>
