<Action id="32530" issue="22428" author="yacovm" type="comment" created="2017-10-16 18:43:27.0" updateauthor="yacovm" updated="2017-10-16 18:43:27.0"> <body><! CDATA {quote}Microservices architecture is a better software development style that enables flexibility in deployment and management of the applications. Basically this style decomposes the software into a suite of independently deployable (micro) services.{quote} {quote}We want to improve the chaincode model such that we would have an option to load chaincode into an existing container, especially with VM-based chaincodes like Java or Nodejs{quote} I'm not sure micro-services is the best name to call that. to me it resembles more an application server, servlet container, etc.  than micro-services.  In example- a front page of a website that behind the scenes uses a cache service like memcached and also a search service and a database service, and the search service also uses the database service, and i.e they all find each others instances via a service discovery service - this is a better example for microservice architecture.  {quote}It would encourage decomposing chaincode into microservices{quote} I don't really understand what it should be decomposed to? Can you elaborate?  A chaincode is essentially a process that on startup connects to the peer and starts listening for transactions, and then it executes the transactions via API calls to the peer. What would you decompose it to? Can you give an example please? {quote} We want to improve the chaincode model such that we would have an option to load chaincode into an existing container, especially with VM-based chaincodes like Java or Nodejs.{quote} I think that it can indeed save resources especially in chaincodes like java, because co-locating 2 simple chaincodes that have the same dependencies in the same JVM consumes much less memory than having 2 instances of JVMs each running a single chaincode.  However we must not forget that security is probably the biggest reason that people use blockchains and therefore we *must not* trade security for anything else like resource consumption.  Therefore if we are to do this, we need first to agree on the security requirements from a chaincode process. In my opinion (and please others - chime in) a chaincode process needs to be able to: # Prove (authenticate) to the peer that it runs the code that the administrator installed on the peer, or if we extend this model - that it runs code that an administrator of the peer trusts. # Prove (authenticate) to the peer that the id (name + version) of the chaincode that interacts with it at a given point in time on a given gRPC stream is indeed the right chaincode that the peer sent a transaction to.   In my opinion we need to start from this ^ and build on top of these requirements.   Now, thinking aloud - if we think of chaincode as an application container (i.e Tomcat) then perhaps if the administrator trusts the code that he/she installed on the peer (and knows it) - they can all run in the same JVM and we will only have 1 container, loaded with all the chaincodes running inside the same JVM and each chaincode would use some secret to authenticate itself to the peer, and the secret would be injected inside the container at startup. (We can just use mutual TLS instead of the secret, of course)  ></body> </Action>
<Action id="32531" issue="22428" author="christopherferris" type="comment" created="2017-10-16 18:59:49.0" updateauthor="christopherferris" updated="2017-10-16 18:59:49.0"> <body><! CDATA This doesn't sound to me like microservices so much as a mode where the chaincode container becomes an app server (such as OpenLiberty) hosting multiple, possibly related (or unrelated) chaincode functions. It seems more like FaaS than microservices, TBH.  A true microservices would have independently operated services running in independent containers, connected in a service mesh fronted by a load balancer and augmented with NetflixOSS type services - in short, something the likes of Istio envisages running on K8s. That would actually have more containers than we have now, not fewer as described above.     ></body> </Action>
<Action id="32535" issue="22428" author="c0rwin" type="comment" created="2017-10-16 21:41:23.0" updateauthor="c0rwin" updated="2017-10-16 21:41:23.0"> <body><! CDATA > The current chaincode runtime model loads a chaincode per container to ensure complete isolation of chaincode address space. This certainly provides security protection between chaincodes such that one chaincode can't negatively interfere with or bring down the others. However, this model comes with a cost of system resource to accommodate containers, which encourages monolithic chaincodes.   Splitting chaincode into several chaincode while collocating them back into single container doesn't sound like microservice approach, moreover it's hard to underestimate security threat which will bring this approach as failure of one chaincode might cause failure to another.  Currently due to the fact we have separation of execution, ordering and validation - you can install different chaincodes on different peers to load balance resource consumption, this also will allow to mitigate the cost of resource consumption.  ></body> </Action>
<Action id="32536" issue="22428" author="binhn" type="comment" created="2017-10-16 21:54:08.0" updateauthor="binhn" updated="2017-10-16 22:22:10.0"> <body><! CDATA I probably didn't describe it clearly my use of Microservices. Microservices is an architectural style; it doesn't prescribe a specific technology or platform, so I am talking about applying the microservices architecture style to chaincode to encourage  decomposition into a set of independent services (which themselves could be chaincodes, but much lightweight). We may call these micro-chaincodes.  Imagine implementing a supply-chain use-case, given the current runtime model, developers would tend to implement few monolithic chaincodes with many functions hanging off a switch. We want to decompose this use-case into many microchaincodes so that each can be managed independently without facing the current heavy chaincode lifecycle.  That said, let's not get hung up on Microservices, and let's focus on the objective of enable developers to write many small chaincodes (or services) rather than monolithic ones.  ></body> </Action>
<Action id="32545" issue="22428" author="baohua" type="comment" created="2017-10-17 03:06:09.0" updateauthor="baohua" updated="2017-10-17 03:07:13.0"> <body><! CDATA I prefer the name of micro-chaincode, as the term "microservice" does arise too much confusions these years (arch, container, platform...).  There are two aspects as I can see: * Chaincode design pattern: i.e., micro vs monolithic. Whether we need to limit the developer to only pick one? Definitely NO, but we can try to support both development options efficiently. I guess  ~binhn 's major questions is this one? *  Chaincode lifecycle management|https://docs.google.com/document/d/1aSWNOuvOBzi1OzZ-b8h0IP-Qs6JL8iREXM7Jtc0VkE0/edit : The existing lifecycle seems not that effective. E.g., a chaincode container can occupy unnecessary resource usage even it is not called. Here we may introduce the concept of FaaS, which can provide more efficient choices for users.  And I wanna highlight that, since fabric is targeting a general-purpose platform, we need to encourage to keep its functionality flexible to support various requirements.  ></body> </Action>
<Action id="32548" issue="22428" author="gatakka" type="comment" created="2017-10-17 06:44:22.0" updateauthor="gatakka" updated="2017-10-17 06:44:22.0"> <body><! CDATA I am not sure what exact problem must be solved.  With current architecture is possible to separate monolithic chaincode with big switch to smaller chaincodes and install them in same channel. They can be developed,updated and managed separately. A huge benefit with this approach, at least in one of our projects, is that they can have different policies.  Resource consumption probably will be a issue in some huge installations, but still,this is noting compared to additional complexity, security and synchronization implication that will follow.  I am doing some experiments and I found a simple solution for resource utilization that is working for us, and it is very simple. Monolithic chaincode is separated to smaller chaincodes and if some chaincode is not used for X amount of time (let's say 1 minute) its container is shut down, not destroyed, just docker stop. When this chaincode is invoked the container is started. So every peer is managing it own chaincode containers.  In case of docker containers with Go chaincode the start of the container is really fast, I have no idea how fast it will be for Java or NodeJs chaincodes.       ></body> </Action>
<Action id="32572" issue="22428" author="christopherferris" type="comment" created="2017-10-17 16:30:57.0" updateauthor="christopherferris" updated="2017-10-17 16:30:57.0"> <body><! CDATA Clearly, we need a better definition of the problem(s) to be solved.  Operational overhead for chaincode running in separate containers needs to be reduced?  Chaincode operational model encourages monolithic code to conserve system resources?  My buzzword bingo card is needs the 'microservices' ball to be drawn to complete a row?     ></body> </Action>
<Action id="32598" issue="22428" author="binhn" type="comment" created="2017-10-17 22:24:33.0" updateauthor="binhn" updated="2017-10-17 22:24:33.0"> <body><! CDATA  ~yacovm  and  ~C0rWin  Thanks for bringing up your concerns on security, but I think less of a problem for the following reasons: # The local peer admin is the one installing the chaincodes, which always come from a known source (either private or consortium controlled) # JVM already solves colocation and for Go, we can use plugin or a different process  Do you see other security aspects that we should cover?   ~gatakka  I am glad the current model works for you. As you mentioned, we can break down a big chaincode into multiple smaller ones; however, we would face 2 problems: # Heavy lifecycle management which you mentioned # Chaincodes can't share data  Not impossible to overcome but not efficient: Chaincode calling chaincode is a long path.  Some use cases may require situational chaincodes operate on existing data; i.e., chaincodes are created on demand and short live.  So we need an efficient model to manage microchaincode and allow sharing data. I believe Composer might do something like this conceptually, but I have to look.  ></body> </Action>
<Action id="32599" issue="22428" author="yacovm" type="comment" created="2017-10-17 22:51:14.0" updateauthor="yacovm" updated="2017-10-17 22:51:14.0"> <body><! CDATA Can you give a bit more information on how you envision the micro service chaincodes being deployed, running, etc?  In case you don't use chaincode-to-chaincode invocations I take it that you want the client to do multiple transactions for each chaincode? a single one? More information is needed so we can discuss this topic. {quote}The local peer admin is the one installing the chaincodes, which always come from a known source (either private or consortium controlled) {quote}    Right, but there are CVEs of execution of arbitrary code out there, and I'm really not an expert on this but I think saying that the peer blindly trusts the chaincode is too much assumptions. In addition, we still need to ensure that in your idea *only* the chaincode can identify as itself and not some other network entity such as a client.     ></body> </Action>
<Action id="32601" issue="22428" author="c0rwin" type="comment" created="2017-10-17 23:06:36.0" updateauthor="c0rwin" updated="2017-10-17 23:10:10.0"> <body><! CDATA {quote}  The local peer admin is the one installing the chaincodes, which always come from a known source (either private or consortium controlled) {quote}  While this is true, it doesn't make chaincode bug free, e.g. my probably main concern is that with this approach we loosing pros of running chaincodes isolated such that they cannot cause any damage to each other.  {quote} So we need an efficient model to manage microchaincode and allow sharing data. {quote}  Could you elaborate on use case, why would you like to share data between chaincodes? Also it sounds like you are talking to group chaincodes into bundles, is that correct?  ></body> </Action>
<Action id="32606" issue="22428" author="gatakka" type="comment" created="2017-10-18 07:39:42.0" updateauthor="gatakka" updated="2017-10-18 07:41:57.0"> <body><! CDATA  ~binhn     {quote} # Heavy lifecycle management which you mentioned{quote} You are talking about heavy life cycle from dev-ops point of view (developing, deploying, updating the chaincodes) or from internal implementations view (system chaincodes).   If is deploying and management of the chaincodes  I do not see any problem to adapt existing, mature, well established dev-ops tools and process. Also, in this context, it makes no difference what is the architecture, if you have 2 or 200 chaincodes you must manage 2 or 200 of them.   If is the internal implementation, then, please, describe the problem(s), because many of us are not so intimately familiar with the implementation details.    {quote}Chaincodes can't share data {quote}    Please, elaborate more. Chaincodes must be "pure functions". They must depend only on provided parameters and data taken from shim. This is how operations can be deterministic. They share data through the ledger in the channel.  Adding another way for communication between chaincodes will increase the complexity a lot. For example how sequential operations will be executed, who will track the status of execution and decide what to do next. What if some of the operations fails? I am sure that technical solutions to all this problems can be found, but the main question, at least for me, is what real problem is solved.  One functionality that can be helpful for a lot of use-cases and is related to current discussion is the ability of the chaincode to invoke another chaincode for read/write operations. Current implementation allows only reading data. This will require changes in read/write sets and also in policy validation. Also it will be better write operations to be allowed only for chaincodes in same channel.   Probably will be a good idea to start using real examples and use-cases instead of abstract ideas.           ></body> </Action>
<Action id="32977" issue="22428" author="muralisr" type="comment" created="2017-10-23 12:48:16.0" updateauthor="muralisr" updated="2017-10-23 13:41:20.0"> <body><! CDATA To focus on the basic intent here - separation of concerns between state and the code that manipulates state. Currently chaincode implements both monolithically. This constrains chaincode model in a couple of ways * hard to extend chaincode functionality - need to modify and redeploy * every participant owns all "functions" of the chaincode. Wouldn't it be nice for the "insurance" company to provide insurance related transforms to the "Car" asset and not have to worry about the "loan" transforms (more interesting to the bank)  The tight coupling of state and its transforming code also gives raise to more surface area that would need change causing more churn in chaincode lifecycle.   If we generalize chaincode framework to accept transform as post instantiate extensions (in  ~binhn  terms "microchaincode") it will open an entirely new way to program chaincodes - the base chaincode a pure "state" keeper leaving the transformation to the add-on extensions.  This separation between state and transforms/queries will give raise to more natural ways to structure state (everyone owns state with each providing their particular transforms/queries).  Implementation ? ...  Composer extends functionality by running node "scripts" in GO chaincode. While intent there is not about separation in the above sense, it shows that such loose coupling is possible to implement.   More interestingly, a simple experiment shows the Java chaincode environment in latest master execute Clojure code on the fly (thanks,  ~sanchezl  :-) )  with a simple modification. Perhaps  ~greg.haskins  can expand ?  This would have deep positive implications for  the chaincode programming model.  ></body> </Action>
<Action id="32982" issue="22428" author="gatakka" type="comment" created="2017-10-23 14:20:00.0" updateauthor="gatakka" updated="2017-10-23 14:28:56.0"> <body><! CDATA  ~muralisr  I am not against this idea in general but the devil is in details.  Currently Fabric is delivering a very new approach for solving one of the biggest problems out there - how parties that don't trust each other can trust each other. And this is done (as all we know) by allowing every party to have same data, that is crypto-validated, on there servers, and before any update all parties must deliver same change set derived from business logic implemented by chancode.  There are channels and every channel can have many chaincodes. In example above why insurance and the loan data must be in same channel? This is bad business design at first place, they must be in separate channels.   Parties must share only functionality that is common for there operations, not all chaincodes.   I do not understand completely what you mean by "separation between state and transforms". Chaincode is not responsible for state transform, it just execute a method that eventually will change the state. In chaincode you even cannot read the data from read/write set before is committed.  So it seems that chaincode has only one responsibility - using provided parameters and shim data to apply rules and make a request for state update.  With current implementation is not necessary all parties to have same chaincode. Correct me if I am wrong but they need to provide same read/write set. So every party can make there own implementation about the process. It is not even necessary chaincode in different parties to be in same language.  Lets say that this separation is done using any implementation. Where in the stack will be business logic implementation and who will create read/write set? How this "layer" will guarantee consistency? What data and from where will be send to chaincode? This data must be encrypted, so the caller and the chaincode must share keys and CPU time will be required for encrypt/decrypt/verify.   And all this for what? To allow separation of monolith code in small peaces that must find a way to work together and exchange data in synchronization, for what? Probably in 100% of the real cases the process that is controlled by chaincode is sequential and monolithic.   Better result will be to make chancode install/instantiate and upgrade more streamline and to allow one chaincode to execute another chaincode (for write operations) in same channel. If this is done then separation can be done using many chaincodes in same channel that have fast way to communicate between each other (using shim interface), will have deterministic behavior and will not require extra network connections or cypto operations.              ></body> </Action>
<Action id="32996" issue="22428" author="muralisr" type="comment" created="2017-10-23 17:03:21.0" updateauthor="muralisr" updated="2017-10-23 17:03:21.0"> <body><! CDATA  ~gatakka  Clarifying a few points (in different order than they appear in your comment). {quote}Better result will be to make chancode install/instantiate and upgrade more streamline and to allow one chaincode to execute another chaincode (for write operations) in same channel. If this is done then separation can be done using many chaincodes in same channel that have fast way to communicate between each other (using shim interface), will have deterministic behavior and will not require extra network connections or cypto operations. {quote} The last part _"will not require extra network connections"_  makes me wonder if you are thinking of an additional communication layer on top of chaincode. Thats not the model ... this could completely change the way you view the JIRA. {quote}And all this for what? To allow separation of monolith code in small peaces that must find a way to work together and exchange data in synchronization, for what? Probably in 100% of the real cases the process that is controlled by chaincode is sequential and monolithic. {quote} There's no additional "synchronization". The same considerations as for concurrent invokes today apply. {quote}Chaincode is not responsible for state transform, it just execute a method that eventually will change the state. {quote} In both models chaincode will execute functions that (eventually) causes transform ..did not mean to imply that chaincode will commit the state. {quote}With current implementation is not necessary all parties to have same chaincode. Correct me if I am wrong but they need to provide same read/write set. So every party can make there own implementation about the process. It is not even necessary chaincode in different parties to be in same language. {quote} Parties using the same chaincode namespace for manipulating same assets should have the same chaincode.  Maybe it'll help to have some experimental code. I'll try and push something out by tomorrow.  ></body> </Action>
<Action id="32997" issue="22428" author="gatakka" type="comment" created="2017-10-23 17:15:28.0" updateauthor="gatakka" updated="2017-10-23 17:16:23.0"> <body><! CDATA  ~muralisr   This is the main issue here, I (and probably others) do not have common understanding about the problem that has to be solved, therefore the possible solutions.  I proposed,in comments above, to start using real examples and use-cases, so to have common context, but your proposal about code is much better.  It is off-topic question -  if two chaincodes with same namespace but with different implementation return same read/write set  will they be considered as same code in context of endorsement verification?     ></body> </Action>
<Action id="33006" issue="22428" author="muralisr" type="comment" created="2017-10-23 18:48:22.0" updateauthor="muralisr" updated="2017-10-23 18:48:41.0"> <body><! CDATA  ~gatakka   {quote}It is off-topic question -  if two chaincodes with same namespace but with different implementation return same read/write set  will they be considered as same code in context of endorsement verification? {quote}  Lets take this on one of the Rocker Chat channels (you can ping me directly of course) so readers don't get side-tracked please ?  ></body> </Action>
<Action id="33141" issue="22428" author="muralisr" type="comment" body="https://gerrit.hyperledger.org/r/#/c/14827/ contains the code and a README.txt to take it for a spin." created="2017-10-25 01:01:58.0" updateauthor="muralisr" updated="2017-10-25 01:01:58.0"/>
<Action id="33658" issue="22428" author="binhn" type="comment" created="2017-10-31 22:29:13.0" updateauthor="binhn" updated="2017-10-31 22:29:13.0"> <body><! CDATA  ~muralisr  Thanks for illustrating the idea with code. It's actually a pleasant surprise to me how you did it with code stored on ledger as the old model (nostalgic:-). You showed 2 key capabilities here: # Decomposition of chaincode into micro chaincodes acting within the same programming scope # Light deployment model allowing functional enhancement or addition without upgrading (I called this situational chaincode in my previous comment)  Baking these 2 capabilities into the chaincode model would provide much more flexibility and usability. I could envision ability to compose micro-chaincodes in execution; that is, either via another micro-chaincode to call other micro-chaincodes or declaratively pipeline micro-chaincodes in a transaction, allowing output from one to feed into another, which is only possible due to #1 above.  ></body> </Action>
<Action id="40463" issue="22428" author="mastersingh24" type="comment" body="I do not believe this fits in with the high level goals for v1.2 so pushing to v1.3 for now" created="2018-02-20 21:27:58.0" updateauthor="mastersingh24" updated="2018-02-20 21:27:58.0"/>
<Action id="67161" issue="22428" author="sykesm" type="comment" body="Stale" created="2020-01-22 22:13:40.0" updateauthor="sykesm" updated="2020-01-22 22:13:40.0"/>
