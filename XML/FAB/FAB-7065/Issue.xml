<Issue id="24301" key="FAB-7065" number="7065" project="10002" reporter="yihuang518" assignee="muralisr" creator="yihuang518" type="10004" summary="different timestamp of the chaincode will make chaincode fingerprint different" priority="3" resolution="10000" status="6" created="2017-11-21 09:24:01.0" updated="2018-07-20 14:15:00.0" resolutiondate="2018-05-21 17:46:52.0" votes="0" watches="8" workflowId="40556"> <environment><! CDATA Linux server :Linux ubuntu 4.10.0-38-generic #42~16.04.1 Java sdk: 1.0.1 fabric: 1.0.1~1.0.4 I am doing the command line testing by using e2e-cli  ></environment> <description><! CDATA I have two machines, one machine is for org0(let's say server A) and one is for org1(server B), I have a chaincode and copy it to these two machines.  Then I installed the chaincode on org0's peers  from server A and do the same thing to org1s from server B, and then I initialized the chaincode on one of peers on org0,  I did the query on one of the peer on org1, I got the error as following ,  Error: Error endorsing query: rpc error: code = Unknown desc = Error executing chaincode: Could not get deployment transaction from LSCC for mycc:1.0 - Get ChaincodeDeploymentSpec for mycc/mychannel from LSCC error: chaincode fingerprint mismatch data mismatch - <nil>  I login each peer server and find out the md5sum of the chaincode binary in directory /var/hyperledger/production/chaincodes/  are different between org0 and org1.   And I did many testing by using command line and java sdk, and I find out if you want to make all the  chaincode binary the same with each other, you should make sure you load the same chain code, that means in the same directory with the same time stamp. Even you move the chain code away and copy back, you will get fail because of the time stamp issue. It does not make sense, different orgs should install the chaincode on their own machine. I think it is a bug.   If I was wrong ,please correct me, if you can tell me what else will impact the fingerprint, it will be very helpful, thanks so much.     ></description> </Issue>
