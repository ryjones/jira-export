<Action id="55859" issue="36961" author="guoger" type="comment" body="cc  ~sykesm   ~yacovm " created="2019-01-20 07:13:33.0" updateauthor="guoger" updated="2019-01-20 07:13:33.0"/>
<Action id="55861" issue="36961" author="yacovm" type="comment" created="2019-01-20 10:33:08.0" updateauthor="yacovm" updated="2019-01-20 10:33:26.0"> <body><! CDATA But doesn't the peer channel create loop until it succeeds?  {code}func getGenesisBlock(cf *ChannelCmdFactory) (*cb.Block, error) { 	timer := time.NewTimer(timeout) 	defer timer.Stop()  	for { 		select { 		case <-timer.C: 			cf.DeliverClient.Close() 			return nil, errors.New("timeout waiting for channel creation") 		default: 			if block, err := cf.DeliverClient.GetSpecifiedBlock(0); err != nil { 				cf.DeliverClient.Close() 				cf, err = InitCmdFactory(EndorserNotRequired, PeerDeliverNotRequired, OrdererRequired) 				if err != nil { 					return nil, errors.WithMessage(err, "failed connecting") 				} 				time.Sleep(200 * time.Millisecond) 			} else { 				cf.DeliverClient.Close() 				return block, nil 			} 		} 	} } {code}  maybe we just need to pass a timeout to the command in nwo?  ></body> </Action>
<Action id="55873" issue="36961" author="guoger" type="comment" created="2019-01-20 15:09:28.0" updateauthor="guoger" updated="2019-01-20 15:10:20.0"> <body><! CDATA  ~yacovm  you were right, timeout was 5 seconds by default, and this has exceeded {code} 20:15:53  e  peer-channel-create  Error: timeout waiting for channel creation {code} because there happens to be a leader re-election at that time. And the cause is slow wal sync {code} 20:15:53  e  OrdererOrg.orderer1  2019-01-18 12:14:54.283574 W | wal: sync duration of 1.041177978s, expected less than 1s {code}   I've seen slow sync of wal in our CI several times. My suggestion here, is that if this is only observed in CI (maybe slow disk?), we could just increase default election timeout in integration tests.  Otherwise, we should investigate the cause of slow wal sync. I've requested system testers to keep an eye on this.  ></body> </Action>
<Action id="56439" issue="36961" author="guoger" type="comment" created="2019-01-31 13:22:00.0" updateauthor="guoger" updated="2019-01-31 13:22:20.0"> <body><! CDATA Failure seen here:  {code}  Fail  EndToEnd Crash Fault Tolerance when an orderer is behind the latest snapshot on leader  It  catches up using the block stored in snapshot {code}  https://jenkins.hyperledger.org/job/fabric-verify-integration-tests-x86_64/5164/  ></body> </Action>
<Action id="57539" issue="36961" author="guoger" type="comment" body="With raft lib version being bumped, the probability of this happening is fairly low, and we can backlog this for now." created="2019-02-25 13:30:40.0" updateauthor="guoger" updated="2019-02-25 13:30:40.0"/>
