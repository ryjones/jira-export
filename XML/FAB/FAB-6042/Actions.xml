<Action id="31023" issue="20623" author="jyellick" type="comment" created="2017-09-19 20:30:09.0" updateauthor="jyellick" updated="2017-09-19 20:30:09.0"> <body><! CDATA I've taken a quick stab at the larger sub-tasks for this item.  Documentation on these could all be improved.  I've also omitted any items which are SDK related, as I think we need to get a concrete implementation, particularly of the new lifecycle API in mind before we can sanely guess what SDK work is required.  ></body> </Action>
<Action id="31030" issue="20623" author="denyeart" type="comment" body="I&apos;ve created FAB-6236 subtask as a placeholder item for the various SDKs to support the new style chaincode deployment approach.  Once the design and implementation stabilize to the point where the SDKs can begin work, it can be promoted to a top level task with its own subtasks, one per SDK." created="2017-09-19 21:43:16.0" updateauthor="denyeart" updated="2017-09-19 21:43:16.0"/>
<Action id="31233" issue="20623" author="jonathanlevi" type="comment" body="Hi, I have just up-voted this, bringing the number of up-votes to 5 (five)." created="2017-09-28 13:39:19.0" updateauthor="jonathanlevi" updated="2017-09-28 13:39:19.0"/>
<Action id="31540" issue="20623" author="binhn" type="comment" created="2017-10-02 19:58:50.0" updateauthor="binhn" updated="2017-10-02 20:00:16.0"> <body><! CDATA -1  As I thought about this more, and given what we discussed last week that  ~kchristidis  captured in FAB-6398, and from which I have expressed my opinion: chaincode is an asset and it should follow asset materialization process. It is not a configuration. If we think our current endorsement process is inadequate in consensus, then we should fix that. I do see the need for "asynchronous" endorsement where it would necessitate multiple steps (workflow) to complete, and which could be expressed in terms of multiple transactions.  The problem is understandable, but the solution proposed here is not desirable IMHO, and we should consider FAB-6398 as a short-term solution.  ></body> </Action>
<Action id="31559" issue="20623" author="muralisr" type="comment" created="2017-10-03 13:42:53.0" updateauthor="muralisr" updated="2017-10-03 13:42:53.0"> <body><! CDATA -1 from me too...just want to make sure as this is a big change from user point of view and would be hard to turn back .  My main issue is that user has to do two actions to instantiate a chaincode (1) send a config TX followed by (2) an instantiate TX. The fabric for its part has to maintain a flag to check if instantiate has been called before allowing an Invoke. Currently chaincode instantiate is a TX just like an Invoke.  It could be that I just got used to the 1 TX model and really the proposal with the 2 action model is the correct approach. If everyone agrees with that assessment I'm willing to be convinced.   ></body> </Action>
<Action id="31563" issue="20623" author="jyellick" type="comment" created="2017-10-03 15:05:17.0" updateauthor="jyellick" updated="2017-10-03 15:05:17.0"> <body><! CDATA I would just like to point out, that nothing in the design of the above precludes the possibility of using peers in an endorsement process in the future to collect the necessary signatures as 'endorsements' as suggested in FAB-6398.  Although there are some other deficiencies in the proposal in FAB-6398 which I will reply to directly there, the ultimate problem with FAB-6398 is that as a 'short-term' solution, there is no way to implement it with any security.  To implement FAB-6398 without leaving a security hole requires:  1. A custom ESCC hook to call out to an organization's workflow for deciding whether to endorse 2. Support for asynchronous transactions  neither of which are trivial tasks and I would assume imply completion in 1.3 or beyond.  IMO we need to address the deficiencies in the lifecycle much sooner than this.  ></body> </Action>
<Action id="34326" issue="20623" author="jeffgarratt" type="comment" created="2017-11-04 02:31:23.0" updateauthor="jeffgarratt" updated="2017-11-04 02:31:23.0"> <body><! CDATA I wanted to demonstrate possible support for such a function through the existing mechanisms for comparative purposes.  The CR is here https://gerrit.hyperledger.org/r/#/c/15191/  My reasoning is that moving to a GRPC based approach for functional extension would be a move from the current protocol based implementation now in place at the fabric level to an API based approach (which is currently fulfilled by our SDKs).  The associated addition to an SDK based upon the above approach is shown below...  +    def get_resources_config(self, timeout=2): +        cc_spec= self._get_cc_spec(args= 'GetResourcesConfig', self.channel_name ) +        return self._send(cc_spec=cc_spec, type_of_response=common_dot_configtx_pb2.Config, timeout=timeout)  The ramifications of moving to such an API based approach at the fabric level vs the current protocol based approach are many in my opinion and should be considered carefully before deciding to venture down this path.  ></body> </Action>
<Action id="34334" issue="20623" author="muralisr" type="comment" created="2017-11-04 16:04:37.0" updateauthor="muralisr" updated="2017-11-04 16:04:37.0"> <body><! CDATA  ~jeffgarratt  I think I understand the extension in the CR (I'd have used the RSCC system chaincode but I can see it doing it with the CSCC and peer code too as a keeper of channels and configs).  Its all GRPC based right (Endorser is a grpc service). Any extensions can be provided by single mechanism of SCC calls. What specifically do you mean by `My reasoning is that moving to a GRPC based approach` please ?  ></body> </Action>
<Action id="34336" issue="20623" author="yacovm" type="comment" created="2017-11-04 17:36:58.0" updateauthor="yacovm" updated="2017-11-04 20:03:05.0"> <body><! CDATA {quote}(I'd have used the RSCC system chaincode but I can see it doing it with the CSCC and peer code too as a keeper of channels and configs {quote} I would like to point out that *there is no really such a thing as CSCC*. It's only a chaincode running inside the peer's process, *initialized using singletons*, uses channels for communication with the endorser code, and then invokes non-instance functions like *peer.GetCurrConfigBlock* to do its work.     In fact, in my opinion- LSCC-install, CSCC, VSCC and ESCC and QSCC are actually all simply chaincodes that are doing argument processing and then passing them to the peer.  The only real system chaincodes are the upgrade/instantiate part of LSCC and RSCC, since they read/write to the ledger.  I do not know why the former functions *\{L-install,Q,V,E,C*}SCC were implemented as system chaincodes, as I wasn't present when it was decided or discussed, but had I been asked I'd probably implement ESCC and VSCC as just interfaces that can by dynamically loaded via go plugins, and LSCC, QSCC and CSCC would not be implemented as chaincodes.     So, in my opinion - if we need something that involves doing a bunch of "PutState"s and "GetState"s or range queries - we can implement that using a chaincode that will run inside the peer (AKA "system" chaincode)  However - if we just need something that invokes a function in the peer, such as: * Writing to the file system * Updating a data structure * Doing communication  What do we gain by having it confined in a system chaincode? From my perspective, it is hard to write unit tests for SCCs since they rely so much on singleton access, and also the un-typed arguments (byte arrays) are error-prone by nature.  ></body> </Action>
<Action id="34337" issue="20623" author="muralisr" type="comment" created="2017-11-04 21:39:02.0" updateauthor="muralisr" updated="2017-11-05 16:54:59.0"> <body><! CDATA  ~yacovm   The biggest benefit of chaincodes in general is the uniform treatment they afford. Once we say "chaincode" one knows what can be done with it, what security aspects are bound to it, how it can be replaced / extended ... etc. Instead of inventing new external entry points for adding services, you simply extend a SCC (or in worst case when a new service is needed, create a new scc) and reap the benefits of the surrounding infrastructure that supports it. We can not predict how users may want to adapt / modify something. But  if they want to do that we can say that the message driven chaincode programming model  affords a uniform, simple mechanism to extend/replace/adapt functionality fairly easily.  As a case in point - I trivially extended the RSCC to have user chaincodes do ACL checks via chaincode-chaincode call... just an example, lets not get diverted or read too much into that.  But more to the point, I think  ~jeffgarratt  is making a similar point with his illustration.  ></body> </Action>
<Action id="34348" issue="20623" author="denyeart" type="comment" created="2017-11-05 15:28:36.0" updateauthor="denyeart" updated="2017-11-05 16:23:23.0"> <body><! CDATA  ~jyellick  As the points above demonstrate, there are naturally pros and cons with the proposal/scc choice vs gRPC choice.  I don't want to block forward progress with -2 on  https://gerrit.hyperledger.org/r/#/c/15107/  , but I do think we need to first (and quickly) get to a decision on the peer config interaction approach. As the owner of this work item, could you net out the pros and cons of each approach in your opinion, and your reasoning for suggesting gRPC approach (in the second-to-last paragraph of Description)?  Perhaps it is possible to meet the main objectives of both sides with a 3rd option.  For example utilize the existing Proposal/ProposalResponse protocol (message driven approach) to keep SDK/peer loosely coupled and leverage existing ProcessProposal handling for signing, authentication, and access control, but have a new HeaderType other then ENDORSER_TRANSACTION (e.g. PEER_API_REQUEST) that would dispatch the request to a non-singleton plugin-capable peer API handler, rather than to a system chaincode. What do you think?  ></body> </Action>
<Action id="34353" issue="20623" author="muralisr" type="comment" created="2017-11-06 02:49:30.0" updateauthor="muralisr" updated="2017-11-06 02:49:30.0"> <body><! CDATA  ~denyeart  {quote}Perhaps it is possible to meet the main objectives of both sides with a 3rd option. For example utilize the existing Proposal/ProposalResponse protocol (message driven approach) to keep SDK/peer loosely coupled and leverage existing ProcessProposal handling for signing, authentication, and access control, but have a new HeaderType other then ENDORSER_TRANSACTION (e.g. PEER_API_REQUEST) that would dispatch the request to a non-singleton plugin-capable peer API handler, rather than to a system chaincode. {quote} Once we admit the Proposal/ProposalResponse mechanism, it crosses the API boundary and the mechanism that serves the request becomes an implementation detail. In fact having a new PEER_API_REQUEST bleeds that internal implementation detail.  With the chaincode we have one proposal mechanism  - call invoke on the chaincode with parameters to get some response. Just like HTTP, this simple declarative mechanism can be flexibly used in many ways. If we can express new function with that, why would we not simply do that ?  ></body> </Action>
<Action id="34356" issue="20623" author="jyellick" type="comment" created="2017-11-06 07:02:20.0" updateauthor="jyellick" updated="2017-11-06 07:02:20.0"> <body><! CDATA > As the owner of this work item, could you net out the pros and cons of each approach in your opinion, and your reasoning for suggesting gRPC approach (in the second-to-last paragraph of Description)?  I will do my best to net out the pros/cons.  I think  ~yacovm  actually did a nice job responding in favor of the gRPC interface, as did  ~jeffgarratt  and  ~muralisr  in favor of chaincode, so I would encourage everyone to read their posts directly (from which I will steal heavily).  As pointed out by others, system chaincode is still fundamentally implemented over gRPC, so we refer to 'gRPC' here, we mean a new gRPC service.   ---- *System Chaincode*  Pros for chaincode: * It's already there. * The semantics for success/failure of a chaincode invocation already exist, which can make writing a client easier (take Jeff's bdds). * Chaincode invocation has a security workflow around it.  Cons for chaincode: * Chaincode is designed to operate on state in a chaincode's DB namespace, and this API would be operating on in memory structures, not the state DB. * The current state of system chaincode is a bit of a mess.  It's practically impossible to write unit tests against (we achieve code coverage only through unholy non-unit-test-like backflips) and just generally, it is very difficult to write good, modular, testable system chaincode. * There are already other interfaces, like the event service, the ordering service, and gossip which are not implemented as chaincode. * The notion of chaincode invocation which has side effects, but which never appears as a transaction (like install) has always been hacky.  In general, system chaincode operations which reach to disk, or in memory structures, seems like a hack. * The idea that clients can acquire new function without being rebuilt seems to work better in theory than reality.  ---- *New gRPC Service*  Pros to gRPC: * Interface is more explicit for clients and server. * Peer code is cleaner because there is no manual argument handling / switch statements. * Trivial to write in a testable modular way. * Can re-use security structures from ordering and events, for security.  Cons to gRPC: * Requires clients to learn a new interface. * No automatic security.  ---- *An alternative?*  It seems to me that the biggest complaint about using a gRPC service seems to be that clients must write new logic to invoke it, and the service must re-invent security.  It also seems obvious to me, that not all services are a good fit for chaincode.  Take the ordering APIs, or the event APIs.  Both take a message as input, then produce a (not necessarily bounded) stream as output.  The chaincode API is not designed to accommodate such services, which I don't personally see as a deficiency, but rather a point of design.  These services must implement their own security, and clients must learn how to encode messages which meet this security.  For the orderer, the {{Broadcast}} and {{Deliver}} APIs originally took different inputs.  However, we soon realized that this meant implementing the security twice, so opted to standardize both of these to accept a stream of {{common.Envelope}} messages, so that the security properties could be shared.  I've been discussing with  ~wlahti  about security in the new channel event service, and he has been working to use the same {{common.Envelope}} message as input so that he can leverage the same security features like replay prevention etc. that come baked into this message type.  In my discussions with  ~yacovm  on the new service, I encouraged him to use the {{common.Envelope}} as the parameter so that it too, could use this same client validation logic.   If we can standardize the input to these gRPC services to be a {{common.Envelope}}, this seems to solve many of the complaints.  Security is not re-invented, and the clients may use the same message encoding logic for each service (up to the data in the payload).  There is still the question of handling the responses, as I see no obvious way to standardize on the reply type of the services (though maybe it is possible).  If we move towards convention in our non-chaincode gRPC services, does this address the heart of the problem?  ></body> </Action>
<Action id="34357" issue="20623" author="yacovm" type="comment" created="2017-11-06 08:50:53.0" updateauthor="yacovm" updated="2017-11-06 08:55:59.0"> <body><! CDATA I must say that I completely don't understand the "we can re-use security if we use SCC, and if we implement a gRPC service we need to re-implement security".  Security in fabric has 3 parts  1  and all of them are not handled by SCC or anything related, and thus is implicitly reused: * Verification of signatures - this is done by BCCSP * Identification of identities, mapping them to principles and validating their existence - this is done by MSP * Evaluation of the access rights, this is done by the policies, via passing them a common.SignedData  How can we reuse security if we implement it in SCC? SCCs are just a bunch of functions with a big switch-case statement, and in each case- we have a different key that maps to a policy via the aclmgmt package. If we add a new function to CSCC or QSCC we need to add another case, and then put there a policy selection for the function name. The only "re-using" we will get is the little line after the case that actually calls to check the policy.  Is that enough re-using to justify ignoring the benefits of the gRPC approach  ~jyellick  listed? I don't think so.           1  One can argue that after  https://gerrit.hyperledger.org/r/#/c/15137/  was merged it has another, but it can easily be integrated with the gRPC approach as I have demonstrated in the change set  ></body> </Action>
<Action id="34359" issue="20623" author="mastersingh24" type="comment" created="2017-11-06 10:11:50.0" updateauthor="mastersingh24" updated="2017-11-06 10:11:50.0"> <body><! CDATA So I 100% agree with the comments made by  ~jyellick  and  ~yacovm   I will also state that reuse for the sake of reuse is an absolute mistake and I'm not going to list here, but this has and continues to cause us issues in the codebase.  I'd like to break things into several parts:  *1) Chaincode and system chaincode - what are they for?*  In simplest terms, chaincode is Fabric's mechanism for adding smart logic processing.  Without chaincode, Fabric does not really do anything.  It was designed to allow users of Fabric to implement their logic which would be validated and processed by Fabric with Fabric being the core blockchain infrastructure.  Some will also say that chaincode is Fabric's version of smart contracts and while the analogy is fine, chaincode is a bit more powerful than that.  Chaincodeis not a generic plugin mechanism for arbitrary functionality.  While of course you can do whatever you want since you have the full power of programming languages at your disposal, it was intended for processing user-defined transactions.  What is sytem chancode.  Typical chaincode runs out of process from the peer (using Docker today).  The point of system chaincode was to allow people who had well-tested, well-defined chaincode to run it within the peer process itself.  Again, I will assert that it is / was not a generic plugin capability.  The intention was to take standard chaincode and run it in process.  That's it.  *2) Reuse of the chaincode infrastructure as an extension mechanism*  Let's start with how one actually calls chaincode externally.  This is quite simple - call the gRPC ProcessProposal rpc of the  Endorser |https://github.com/hyperledger/fabric/blob/master/protos/peer/peer.proto#L35  service which makes sense because the Fabric transaction model is based on obtaining endorsements for chaincode execution and then submitting them for validation and commit (via the ordering service).  This is not a "generic" message passing API as indicated by  ~jeffgarratt  and  ~muralisr . It is a very specific service intended to handle the endorser flow. Yes - it uses a "message passing" API style, but that is not the same thing as being a generic message passing API entry point to the peer.  I disagreed with implementing the current cscc and qscc functionality this way for exactly these reasons.  Now from code within the peer, one can actually call chaincode a little more directly, but again in the end you are still dealing an endorsement model. I'll continue to argue that SCC is not the proper architecture for system plugins.  *3) Style of APIs*    ~jeffgarratt  brings up a good point about using message style APIs - although frankly I'm not sure what's so hard about calling a different RPC. To  ~jyellick  's point, we can use the common.Envelope as the message wrapper for the request payloads (for consistency) and we also get the benefit of having a well-defined set of external APIs for specific functions. (FWIW, in v0.6 qscc-like functions were implemented as gRPC RPCs).  *4) Moving forward*  From  ~denyeart  {quote}Also, is the intent to shift the other cscc functions over to gRPC approach, or leave peer config interactions in an inconsistent state going forward? {quote}  I believe that we should move a majority of the qscc and cscc interactions to this model.  It's actually trivial to do in any case, but we can decide to defer it until 1.2 or later           ></body> </Action>
<Action id="34367" issue="20623" author="binhn" type="comment" created="2017-11-06 14:25:28.0" updateauthor="binhn" updated="2017-11-06 16:36:25.0"> <body><! CDATA I am not following why all the discussion on this JIRA item. This is *about chaincode life-cycle*. Please open up another item to discuss new API vs existing API or implementation.  Whichever way we end up, I want to emphasize again (because I am afraid that some of us might not grasp the concept of chaincode correctly):  chaincode is an asset and it should follow asset materialization process; i.e. things about chaincode must be stored in the blockchain and followed the consensus process. In the current implementation, we optimize and store the cc source code off-chain but its evidence on-chain.     ></body> </Action>
<Action id="34369" issue="20623" author="denyeart" type="comment" body=" ~binhn  It is being discussed here since gRPC APIs to support chaincode lifecycle were proposed in second-to-last paragraph of Description here.  The actual work is covered in subtask FAB-6224.  Given the existing discussion thread here, I think it makes sense to keep the discussion here." created="2017-11-06 14:41:59.0" updateauthor="denyeart" updated="2017-11-06 14:41:59.0"/>
<Action id="34378" issue="20623" author="muralisr" type="comment" created="2017-11-06 16:39:50.0" updateauthor="muralisr" updated="2017-11-06 16:39:50.0"> <body><! CDATA  ~mastersingh24    {quote}I will also state that reuse for the sake of reuse is an absolute mistake and I'm not going to list here, but this has and continues to cause us issues in the codebase. {quote} I'm not advocating building upon the existing chaincode for reuse sake. On the contrary, I'm saying once implemented in that style, its open to being used in many ways. Just do invoke with args, use cc-2-cc calls, etc.   Now, one can argue some SCCs will/do not need to be usable in the above sense (but we know sometime use comes later). If we are going to replace such chaincodes as regular gRPC services, then it would make sense to implement these new APIs on top of them. But seems to me we can do that when we do move but for now build the new service on existing chaincode (like  ~jeffgarratt  example does) and save on all the costs associated with another new service.  ></body> </Action>
<Action id="34379" issue="20623" author="binhn" type="comment" created="2017-11-06 16:42:06.0" updateauthor="binhn" updated="2017-11-06 16:42:06.0"> <body><! CDATA  ~denyeart  I think it's convoluted to group them together. The ramifications of changing this API is big for our user community that must be properly vetted, and I rather not burry it here while the title of this item is about cc life-cycle.      ></body> </Action>
<Action id="34380" issue="20623" author="yacovm" type="comment" created="2017-11-06 16:49:18.0" updateauthor="yacovm" updated="2017-11-06 16:49:18.0"> <body><! CDATA {quote}The ramifications of changing this API is big for our user community {quote} What ramification? The user just uses an SDK API, he/she has no idea if the peer has a gRPC service or a system chaincode. Isn't this part of the reason we made fabric have an SDK? So the peer's API can mutate and the user will not have to re-program its application.  ></body> </Action>
<Action id="34388" issue="20623" author="binhn" type="comment" body=" ~yacovm  who would you think our users are at this level? " created="2017-11-06 20:29:50.0" updateauthor="binhn" updated="2017-11-06 20:29:50.0"/>
<Action id="34391" issue="20623" author="yacovm" type="comment" body="Why, it&apos;s people who deploy fabric, write smart contracts using chaincodes, and interact with the orderer and the peer using the officially supported SDKs of course" created="2017-11-06 20:33:58.0" updateauthor="yacovm" updated="2017-11-06 20:33:58.0"/>
<Action id="34393" issue="20623" author="binhn" type="comment" body=" ~yacovm  just as I thought – no, our users at this level are those who using the current method – they are the SDK developers and those who might have called it directly in their code. We have a number of SDK&apos;s now implemented by community at large, and who knows how many using gRPC level directly." created="2017-11-06 20:43:58.0" updateauthor="binhn" updated="2017-11-06 20:43:58.0"/>
<Action id="34395" issue="20623" author="denyeart" type="comment" body=" ~binhn  I do agree with the last comment to me - a change in overall API direction should be evaluated and vetted in a separate JIRA item, especially given the varying opinions." created="2017-11-06 22:12:27.0" updateauthor="denyeart" updated="2017-11-06 22:12:27.0"/>
<Action id="34398" issue="20623" author="kchristidis" type="comment" body="+1 to David&apos;s comment above and Binh&apos;s original comment: the gRPC vs chaincode API change deserves its own JIRA. I suggest we move one step at a time and not couple the main contribution here (i.e. making chaincode lifecycle management config based) with the simultaneous introduction of a gRPC API, especially since we _can_ deliver config-based lifecycle management without it." created="2017-11-06 22:51:32.0" updateauthor="kchristidis" updated="2017-11-06 22:51:32.0"/>
<Action id="34400" issue="20623" author="jimthematrix" type="comment" created="2017-11-07 05:21:31.0" updateauthor="jimthematrix" updated="2017-11-07 05:21:31.0"> <body><! CDATA +1 to  ~binhn 's point on the impact of the proposed gRPC API (vs. continuing to use scc), suggest moving FAB-6224 out of this story and making it an enhancement to give the community at large a chance to weigh in. At the minimum we should invite the SDK development teams to comment.  +1 to  ~kchristidis  suggestion (and it's  ~jeffgarratt 's point of view as well) to sever the tie b/w the lifecycle changes work by  ~jyellick  and what's implemented for FAB-6224. It seems a good engineering practice anyway to tackle one problem at a time. Suggest merging https://gerrit.hyperledger.org/r/#/c/15191/ for now so that Jason's work can be tested end-to-end. And it'll allow us the time and space to debate over the gRPC vs. SCC approach.  ></body> </Action>
<Action id="34406" issue="20623" author="denyeart" type="comment" body=" ~jimthematrix  Note that  https://gerrit.hyperledger.org/r/#/c/15191/  (SCC approach) sits on top of  https://gerrit.hyperledger.org/r/#/c/15107/  (gRPC approach), so if we merge  https://gerrit.hyperledger.org/r/#/c/15191/   we would get BOTH options implemented.  I think what you intended to say is that a new CR which implements SCC approach only should be merged.  I would agree - that would allow the function to work with existing mechanisms while the gRPC approach is debated." created="2017-11-07 07:18:06.0" updateauthor="denyeart" updated="2017-11-07 07:18:06.0"/>
<Action id="34410" issue="20623" author="yacovm" type="comment" body=" ~denyeart  ,  ~jimthematrix  note that if we implement the SCC approach and later on switch to the gRPC then the SDK teams would need to implement things twice." created="2017-11-07 10:41:20.0" updateauthor="yacovm" updated="2017-11-07 10:41:20.0"/>
<Action id="34411" issue="20623" author="denyeart" type="comment" body=" ~yacovm  That is understood.  The main objective for now is to get chaincode lifecycle enhancements working quickly and with minimal code changes and risk on both peer and SDK sides, and for that the answer is to extend the SCC pattern.  I suspect there will not be a majority of maintainers ready to vote for a gRPC approach which diverges from existing patterns during 1.1 shutdown.  However if the architectural benefits of gRPC approach are clearly articulated in a separate JIRA Epic, potentially there would be a majority that would vote in favor of switching over all the SCCs in a next release (difficult to know until the ideas and debate brew for some time).  For me personally, going out with an inconsistent story for peer config interactions in 1.1 timeframe is not an appealing answer." created="2017-11-07 12:58:12.0" updateauthor="denyeart" updated="2017-11-07 12:58:12.0"/>
<Action id="34414" issue="20623" author="jimthematrix" type="comment" created="2017-11-07 13:38:30.0" updateauthor="jimthematrix" updated="2017-11-07 13:38:30.0"> <body><! CDATA  ~denyeart  +1.   ~yacovm  thanks for pointing that out, to add support in the SDK for the SCC based API the work is pretty straightforward (as we already has APIs built against the CSCC), so if it has to be thrown away it's not a big waste of time.  ></body> </Action>
<Action id="34434" issue="20623" author="jeffgarratt" type="comment" created="2017-11-07 20:43:35.0" updateauthor="jeffgarratt" updated="2017-11-07 20:43:35.0"> <body><! CDATA  ~yacovm   ~muralisr   With respect to your first statement Yacov:  _"I would like to point out that there is no really such a thing as CSCC. It's only a chaincode running inside the peer's process, initialized using singletons, uses channels for communication with the endorser code, and then invokes non-instance functions like peer.GetCurrConfigBlock to do its work."_  Your description seems to align precisely with the following specification document ->  https://github.com/hyperledger-archives/fabric/wiki/System-Chaincode-Specification .  Your declaration that system chaincode designation requires read/write to the ledger does not align with the pre-existing specification.  Your second statement of you weren't present but if you were you would use interfaces vs the message based protocol is analogous to the issue of GRPC vs the protocol discussions I have already raised.  This change in architectural principle from a protocol base interface to API is precisely the one that I believe should not be embarked upon without significant contemplation.  You would have used plugins as well. Plugins were not available in the time frame of these design decisions. In addition, nothing precludes the use of plugins now wrt to implementation. The concept of a message based protocol between reception and dispatch is standardized within the original architecture and the specification clearly denotes this desire to maintain pattern homogeneity internally.  ></body> </Action>
<Action id="34500" issue="20623" author="kchristidis" type="comment" created="2017-11-09 13:54:53.0" updateauthor="kchristidis" updated="2017-11-09 13:54:53.0"> <body><! CDATA Let's provide some clarity on how we intend to proceed here.  Folks have voiced their opinions on how we should go about implementing the needed APIs, but nowhere do we really say: "OK, we'll do this."  To that end I propose the following: # We remove the non-chaincode API reference in the second-to-last paragraph of this JIRA description. # We create a new sub-task titled "Implement client-interacting APIs" (or similar), move over some of the existing discussion there, and agree on the implementation (review-needed, comments, votes). Then the description of the sub-task is updated to reflect consensus. FAB-6224 could be re-purposed/rewritten for this as well.  If you think this is the wrong way to go, propose your own set of steps. I'm not really married to my proposal above – all I care about is that we address the fact that we do not _explicitly_ state that "we will do X" w/r/t implementation.  We'll need to start doing a better job separating problem description from proposed implementation, so that we won't get caught up in a similar process again in the future. Work on a better decision/release process is underway.  And it should be noted that my current proposal leaves loopholes. (For instance, should you be allowed to modify a JIRA description that has already been voted on?) But for now, let's figure out a way to clarify the implementation related to this JIRA.  ></body> </Action>
<Action id="34525" issue="20623" author="denyeart" type="comment" created="2017-11-09 21:08:39.0" updateauthor="denyeart" updated="2017-11-09 21:08:39.0"> <body><! CDATA  ~kchristidis  I agree.  I propose that  ~jyellick  update the Description and create the subtask for "Implement client-interacting peer config APIs" (or similar), so that nothing gets lost in translation.  And sure, for lack of a better voting mechanism, all in favor can upvote it in the subtask.   ~aambati  has freed up and is starting to look at what an extension of Jeff's sample impl would look like (Jason and Yacov and Jeff are aware).  ></body> </Action>
<Action id="34528" issue="20623" author="jyellick" type="comment" body=" ~denyeart   ~kchristidis  I&apos;ve done as suggested, editing the main text of this issue to be more agnostic about the API implementation, and created a new sub-task https://jira.hyperledger.org/browse/FAB-6951 for further discussion." created="2017-11-09 21:35:20.0" updateauthor="jyellick" updated="2017-11-09 21:35:20.0"/>
<Action id="36022" issue="20623" author="rickr" type="comment" body="If an SDK creates the update for the chaincode resource there are many parts of the group/tree  where mod policies must be specified.  How flexible would the API need to be to allow the application to specify these ?  Would for example specifying a single mod policy applied to all levels be too limiting ?   Allowing every specific mod policy to be specified too cumbersome for typical use case?" created="2017-12-08 16:25:03.0" updateauthor="rickr" updated="2017-12-08 16:25:03.0"/>
<Action id="36023" issue="20623" author="rickr" type="comment" body="It seems also at any point the SDK would need to allow overwrite or not option on mod policies. In case of not being there use the mod policy specified or if the already present overwrite / use existing." created="2017-12-08 16:39:35.0" updateauthor="rickr" updated="2017-12-08 16:39:35.0"/>
<Action id="36025" issue="20623" author="rickr" type="comment" created="2017-12-08 16:53:53.0" updateauthor="rickr" updated="2017-12-08 16:53:53.0"> <body><! CDATA The mod policies are referenced to places in a _tree_ (/Channel/Application/Writers) can the SDKs just assume the application will know where and what these are ?     ></body> </Action>
<Action id="36039" issue="20623" author="jyellick" type="comment" created="2017-12-08 20:06:16.0" updateauthor="jyellick" updated="2017-12-08 20:06:16.0"> <body><! CDATA  ~rickr   With respect to the {{mod_policy}} fields in the resources config, I would suggest that the SDKs begin simply. There is a {{mod_policy}} that will be present for the {{Chaincodes}} group (already existing in the config). If you are creating a new item which requires a {{mod_policy}} be set, simply set it to the value from the {{Chaincodes}} group. If the item is not new, simply leave the {{mod_policy}} alone.  If you wanted to expose the {{mod_policy}} as an option,then I would think a single string would be the logical place to start. Let's keep it simple until we learn more about how users will typically want to configure their system?  ></body> </Action>
<Action id="37932" issue="20623" author="jyellick" type="comment" body="This approach has been abandoned.  Marked Done / WON&apos;T FIX." created="2018-01-03 18:00:43.0" updateauthor="jyellick" updated="2018-01-03 18:00:43.0"/>
