<Action id="28622" issue="19206" author="kchristidis" type="comment" created="2017-07-18 21:20:59.0" updateauthor="kchristidis" updated="2017-07-18 21:20:59.0"> <body><! CDATA  ~jyellick  suggests that we extend the `KafkaMessage` proto definition with a `class` field that annotates the message type, so as to get v1.0 OSNs to coexist with v1.1 OSNs. I like this idea.  v1.0 OSNs do not recognize this field and automatically set it to 0. We could then have a mapping along the lines of: * 0 - unknown type * 1 - normal message * 2 - config message  So in the revised flow, the v1.1 OSNs will proceed as follows right after calling the `Sequence()` method on the orderer messages: * If type is 0, run ClassifyMsg to determine type, then: * If type is 1, proceed as in normal_msg_flow * If type is 2, proceed as in config_msg_flow  ></body> </Action>
<Action id="29524" issue="19206" author="guoger" type="comment" created="2017-08-08 10:28:02.0" updateauthor="guoger" updated="2017-08-08 10:28:02.0"> <body><! CDATA To adapt to new message flow, {{ConfigSeq}} should be embedded into {{KafkaMessage}}, so that consenter could decide whether to re-validate message. {code:java} // KafkaMessageRegular wraps a marshalled envelope. message KafkaMessageRegular { bytes payload = 1; uint64 config_seq = 2; } {code}  the purpose of allowing a _mixed cluster_, a.k.a _get v1.0 OSNs to coexist with v1.1 OSNs_, is for upgrading, correct?  I'm not entirely sure why we need to inject message type (NORMAL/CONFIG). (I know we do that for solo already, but also not clear to me). I feel it's OK to use {{ClassifyMsg}} to dispatch messages in consenter?  Suppose we want to do that, we will end up with following proto: {code:java} // KafkaMessage is a wrapper type for the messages // that the Kafka-based orderer deals with. message KafkaMessage { oneof Type { KafkaMessageRegular regular = 1; KafkaMessageTimeToCut time_to_cut = 2; KafkaMessageConnect connect = 3; } enum Class { UNKNOWN = 0; NORMAL = 1; CONFIG = 2; } Class class = 4; }  // KafkaMessageRegular wraps a marshalled envelope. message KafkaMessageRegular { bytes payload = 1; uint64 config_seq = 2; } {code}  Ideally, we could have: {code:java} // KafkaMessage is a wrapper type for the messages // that the Kafka-based orderer deals with. message KafkaMessage { oneof Type { KafkaMessageNormal normal = 1; KafkaMessageConfig connect = 3; KafkaMessageTimeToCut time_to_cut = 2; KafkaMessageConnect connect = 3; } } {code} Even though there's no way we could make it compatible with v1.0, I guess this is not off the table for v2.0?  Let me know what you think  ~kchristidis  ~jyellick  ~sanchezl   ></body> </Action>
<Action id="29543" issue="19206" author="jyellick" type="comment" created="2017-08-08 14:25:57.0" updateauthor="jyellick" updated="2017-08-08 14:25:57.0"> <body><! CDATA  ~guoger  I think there may be a typo in your comment above, in particular for the second {{KafkaMessage}} definition, you define the {{connect}} field twice.  It would of course be possible to re-run 'classify' on the messages, but this would be one of the redundant checks we hope to eliminate.  Additionally, recall that for the config update path, as seen in the diagram in the parent story, revalidating a config update involves generating a new config transaction to re-order, so we actually need to pass two messages, not just one in the config case.  The idea with the classification enum is that we can identity messages which were processed by a v1.0 OSN and were not tagged with classification messages.  For these messages, we must re-run the classify msg code.  ></body> </Action>
<Action id="29573" issue="19206" author="kchristidis" type="comment" created="2017-08-09 02:44:03.0" updateauthor="kchristidis" updated="2017-08-10 01:39:12.0"> <body><! CDATA So a quick overview which may or may not be useful. (And as always, I suspect that it takes longer to write this prose, than actually write the code.) h2. How v1.0. of the Kafka-based orderer works # Broadcast component receives message # If it is a CONFIG_UPDATE message or not turn it into either an existing channel configuration message, or a new channel creation one # Apply filters # Wrap message into a KafkaRegular message # Post KafkaRegular message to the channel's Kafka partition for ordering # Consume the partition above, read the message from the ordered stream # Invoke the block cutter to order the message # If this returns batches (and committers), then invoke WriteBlock: ## Run the respective committers of the batches ## Append batches to disk  h2. How v1.1 of the Kafka-based orderer works right now  (Jason was right to do this so as to remove as much as legacy code as possible.) # Broadcast component receives message # Check whether it's a CONFIG_UPDATE message or not ## If it is a CONFIG_UPDATE message: ### Propose it to the message processor, get back the resulting config message, and a config sequence number ## If it is a NORMAL message: ### Run it through the message processor to get back a config sequence number # Invoke the processor's Order on the message and config sequence number: this wraps the original message (config update or normal message) and config sequence number into a KafkaRegular message, then posts this KafkaRegular message to the channel's Kafka partition for ordering # Consume the partition above, read the message from the ordered stream # Have the support classify the message to identify its type ## If it is a CONFIG_UPDATE message: ### ProcessNormal, i.e. get config sequence and apply chain filters ### Invoke the block cutter to cut the pending batch into a block and write that block ### Place the config update message into a block ### Trigger updates from this config message (i.e. create new chain, or update config of existing chain) ### Write block ## If it is a NORMAL message: ### ProcessNormal, i.e. get config sequence and apply chain filters ### Invoke the block cutter to have the message ordered ### If this returns batches, then invoke WriteBlock to append them to disk  h2. How v1.1 of the Kafka-based orderer should work when this JIRA is completed (additions in *bold*, corrections in {color:#ff0000}red{color}) # Add the following fields to the KafkaMessageRegular definition: ## uint64 config_seq = 2 ## bytes {color:#ff0000}config_update{color} = 3 ## int32 class = 4 (where class is an enum with UNKNOWN, CONFIG, NORMAL values as described here) # Broadcast component receives message # Check whether it's a CONFIG_UPDATE message or not ## If it is a CONFIG_UPDATE message: ### Propose it to the message processor, get back the resulting config message, and a config sequence number ### *Pass the config update, config message, and config sequence number to the processor's Configure method which does two things: (a) populates the KafkaRegular message (all 4 fields), and (b) enqueues it for ordering.* ## If it is a NORMAL message: ### Run it through the message processor to get back a config sequence number ### *Pass the normal message and the config sequence number to the processor's Order method which does two things: (a) populates the KafkaRegular message (3 out of 4 fields, since the config field here remains empty), and (b) enqueues it for ordering.* # -Invoke the processor's Order on the message and config sequence number: this wraps the original message (config update or normal message) and config sequence number into a KafkaRegular message, then- Enqueueing simply posts the KafkaRegular message to the channel's Kafka partition for ordering # Consume the partition above, read the message from the ordered stream # *Retrieve the current config sequence number* # -Have the support classify the message to identify its type- *Read the message's class field* ## *If it's UNKNOWN, run support.ClassifyMessage to identify its type* ### *If it's a CONFIG message, {color:#ff0000}run configtx.Validate() on it, and discard if you get an error or do as 2.2.1-2.2.4 below{color}* ### *If it's a NORMAL message, do as as 3.1.1-3.1.2 below* ## *If it is a CONFIG_UPDATE message:* ### *If the config sequence has advanced* #### *ProcessConfigUpdateMsg again* #### *Discard if an error is returned* #### *Otherwise run through the processor's Configure method and re-order* ### *Otherwise:* #### Invoke the block cutter to cut the pending batch into a block and write that block #### Place the config update message into a block #### Trigger updates from this config message (i.e. create new chain, or update config of existing chain) #### Write block ## *If it is a NORMAL message:* ### *If the config sequence has advanced:* #### *ProcessNormal again and di**scard if an error is returned* #### *Otherwise do as Step 2.1-2.1 below* ### *Otherwise:* #### Invoke the block cutter to have the message ordered #### If this returns batches, then invoke WriteBlock to append them to disk     ></body> </Action>
<Action id="29574" issue="19206" author="kchristidis" type="comment" created="2017-08-09 02:56:12.0" updateauthor="kchristidis" updated="2017-08-09 02:56:12.0"> <body><! CDATA A couple of observations on the flow above: # I'll be surprised if there are no flaws here, but this hopefully provides a decent outline to keep you going # I don't quite see why the class field should be added to the KafkaMessage proto definition instead of the KafkaMessageRegular one  ></body> </Action>
<Action id="29577" issue="19206" author="guoger" type="comment" created="2017-08-09 04:14:46.0" updateauthor="guoger" updated="2017-08-09 04:19:15.0"> <body><! CDATA bq. 4. Invoke the processor's Order on the message and config sequence number: this wraps the original message (config update or normal message) and config sequence number into a KafkaRegular message, then Enqueueing simply posts the KafkaRegular message to the channel's Kafka partition for ordering I suppose this should be bq. 4. Invoke the processor's -Order- {{Configure}} on the messages and config sequence number: this wraps the original message (config update or normal message) *and config message* and config sequence number into a KafkaRegular message, then Enqueueing simply posts the KafkaRegular message to the channel's Kafka partition for ordering {{Configure}} and {{Order}} would produce {{KafkaMessageRegular}} respectively, and {{enqueue}} simply takes it and posts to Kafka partition.  The protobuf message looks like: {code:java} // KafkaMessage is a wrapper type for the messages // that the Kafka-based orderer deals with. message KafkaMessage { oneof Type { KafkaMessageRegular regular = 1; KafkaMessageTimeToCut time_to_cut = 2; KafkaMessageConnect connect = 3; } }  // KafkaMessageRegular wraps a marshalled envelope. message KafkaMessageRegular { enum Class { UNKNOWN = 0; NORMAL = 1; CONFIG = 2; } bytes payload = 1; uint64 config_seq = 2; bytes config = 3; Class class = 4; } {code} Is there a particular reason you use {{in32}} for {{class}}, instead of an {{Enum}}?  ></body> </Action>
<Action id="29579" issue="19206" author="kchristidis" type="comment" created="2017-08-09 04:51:04.0" updateauthor="kchristidis" updated="2017-08-09 04:51:04.0"> <body><! CDATA Jay: Half of that step was supposed to be striked through. I updated the original message. In short, both processor.Configure and processor.Order should create KafkaMessageRegular and then enqueue(KafkaMessageRegular). In the Configure case, the message will have all 4 of its fields set. In the Order case there is no Config message to fill in, so only 3 out of 4 fields are set.  > Is there a particular reason you use {{in32}} for {{class}}, instead of an {{Enum}}?  No particular reason, was just writing this as I was thinking it. Enum is the better choice here, you are right.  ></body> </Action>
<Action id="29581" issue="19206" author="guoger" type="comment" created="2017-08-09 06:36:02.0" updateauthor="guoger" updated="2017-08-09 06:36:02.0"> <body><! CDATA {quote}# If it's UNKNOWN, run support.ClassifyMessage to identify its type ## If it's a CONFIG message, do as 2.1.1-2.1.3 below ## If it's a NORMAL message, do as as 3.1.1-3.1.2 below{quote} Since {{ConfigSeq}} is not available in the {{KafkaMessageRegular}} of v1.0 orderer, I think we should *always* re-validate message of {{UNKNOWN}} type?  ></body> </Action>
<Action id="29635" issue="19206" author="kchristidis" type="comment" created="2017-08-10 01:40:17.0" updateauthor="kchristidis" updated="2017-08-10 01:40:17.0"> <body><! CDATA > Since {{ConfigSeq}} is not available in the {{KafkaMessageRegular}} of v1.0 orderer, I think we should *always* re-validate message of {{UNKNOWN}} type?  Correct. Updated the write-up above, look for corrections/updates with {color:#ff0000}red color{color}.  ></body> </Action>
<Action id="29912" issue="19206" author="guoger" type="comment" body="https://gerrit.hyperledger.org/r/#/c/12507/" created="2017-08-16 15:17:32.0" updateauthor="guoger" updated="2017-08-16 15:17:32.0"/>
<Action id="30664" issue="19206" author="guoger" type="comment" body="patch chain start at: https://gerrit.hyperledger.org/r/#/c/12729/" created="2017-09-08 04:04:36.0" updateauthor="guoger" updated="2017-09-08 04:04:36.0"/>
