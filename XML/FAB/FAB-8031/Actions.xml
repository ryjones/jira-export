<Action id="39604" issue="27355" author="jmcnevin" type="comment" created="2018-02-02 19:59:33.0" updateauthor="jmcnevin" updated="2018-02-02 19:59:33.0"> <body><! CDATA I have to say, I bristle at the idea of needing to modify Postgres to make it operate in a way that Fabric expects.  Are you certain that there are no alternative ways of operating with temporary tables/stored procedures/triggers that can meet the requirements, even if doing so would incur a performance penalty?  If it is required that we use a custom fork of Postgres in order to use it as a state database, it's going to limit our deployment options (no ability to use managed database services), and slow down database upgrade cycles as we wait for the fork to catch up with stock postgres.  In addition, disabling pg_vacuum and using the cruft left behind by updates as a history database seems dangerous.  Are there any guarantees that that data will be maintained in the event of a database dump/restore?  ></body> </Action>
<Action id="39613" issue="27355" author="senthil1" type="comment" created="2018-02-03 05:28:11.0" updateauthor="senthil1" updated="2018-02-03 05:28:40.0"> <body><! CDATA  ~jmcnevin  We are in fact aware of another way to achieve this (from another team) but it has the following four limitations: # Only basic DML queries can be supported (no joins, no nested/sub-queries, no stored procedures, no triggers, cannot support provenance/history query) # Validation and commit of each transaction in a block must be done sequentially (by executing SQL queries) which would incur significant performance overhead. # Only a limited data types are supported (no array support mainly). # No support for JSON and related queries.  In order to provide the full power of RDBMS to fabric (and for better performance), we would need to modify PostgreSQL. If there are any other approach which can use only stored procedures and triggers to achieve this, we can discuss on it and modify our design accordingly.  Not all applications require provenance/historical queries. This feature can be enabled and disabled. I agree with your point on disabling pg_vacuum. It has two problems: (a) it bloats up the index (as we are still retaining the delete tuples), (b) it bloats up the tables as well. In a database, the size would really impact the performance. We could definitely come up with a middle approach in which we can enable pg_vaccum and specify till which block it should retain the deleted tuples (again it requires modifications to PostgreSQL). Even in fabric with KV store, there is a discussion on enabling purging of blocks and related data from state DB. This is because as the system continues to run for a longer period, the database would definitely bulk up and degrade the performance. Hence, we can achieve the same using pg_vaccum.  During database dump/restore, as it is now, it won’t consider the deleted tuples. As we would be changing the tuple visibility rule (for provenance queries), we would do the same for database dump so that it would capture all tuples in a table (irrespective of whether it is deleted or not).  ></body> </Action>
<Action id="67227" issue="27355" author="sykesm" type="comment" body="Stale" created="2020-01-22 22:25:27.0" updateauthor="sykesm" updated="2020-01-22 22:25:27.0"/>
