<Action id="40286" issue="21067" author="yacovm" type="comment" created="2018-02-16 11:42:43.0" updateauthor="yacovm" updated="2018-02-16 11:42:43.0"> <body><! CDATA I'm not sure how that differential update is achieved? The states are raw bytes, and you have to compute everything on the chaincode side. You can't compute anything in the peer side. The A := A-X semantic might work only when the chaincode treats values of keys as numbers, but what if they're not numbers?  Regarding the compound request - there has been a proposal (the one linked to this JIRA, FAB-3243) that indeed does just that. We certainly need an API method that does multiple GetStates, but I don't think we need multiple SetStates... we can just record all SetStates and send them batched at the end of the chaincode transaction.  Furthermore, I'm certain we can achieve *hundreds* of percentages of performance increase, without extending any API- if we can just make the chaincode shim multi-threaded, and have multiple gRPC streams that are connected to the chaincode shim, instead of just one.   ></body> </Action>
<Action id="40303" issue="21067" author="mastersingh24" type="comment" created="2018-02-16 18:22:01.0" updateauthor="mastersingh24" updated="2018-02-16 18:22:01.0"> <body><! CDATA Also - if we really wanted to do some type of "differential update", we should actually consider adding additional "field" commands (e.g. add / subtract) rather than just having put / get state functions. We could even have an operator with rule "subtract but must be greater than zero" which could be processed at validation time rather than during endorsement/simulation.  This would actually have the additional benefit of reducing collisions for frequently updated numeric values  ></body> </Action>
<Action id="40304" issue="21067" author="mastersingh24" type="comment" body="And I agree with  ~yacovm  - I don&apos;t believe we need a *SetStates* function .... this is an optimization which can be made in the shim" created="2018-02-16 18:23:16.0" updateauthor="mastersingh24" updated="2018-02-16 18:23:16.0"/>
<Action id="40401" issue="21067" author="miyamae" type="comment" created="2018-02-20 02:43:29.0" updateauthor="miyamae" updated="2018-02-20 02:43:29.0"> <body><! CDATA Thank you for your comments, Yacov and Gari. You have nice viewpoints! But, regarding multi-threading, we belive it is not necessarily the best solution especially for some kind of primitive chaincodes or functions such as sending some amount of token from Alice to Bob, because generating threads takes relatively large time (100us) and makes our programming not a little complicated for such small functions. Therefore, we believe introducing efficient APIs is one of the options we can choose.  ></body> </Action>
<Action id="40405" issue="21067" author="yacovm" type="comment" created="2018-02-20 07:58:42.0" updateauthor="yacovm" updated="2018-02-20 08:14:47.0"> <body><! CDATA I did not say the programmer is the one that is going to create these goroutines.  I said that the chaincode shim would be multi-threaded, and have multiple gRPC streams instead of just one. That means - it pre-allocates a number of streams and consequently a number of goroutines (1 per stream).  A simple chaincode in which Bob sends something to Alice is actually wasting *most of its time* doing *nothing* but waiting for responses to queries to come back from the peer. That's why having multiple goroutines do that, would increase the throughput.  Consider the following scenario:  Two transactions that come in the same time- T1, and T2. Assume without loss of generality that T1 gets handled first by the peer and is sent to the shim. The shim then sends a GetState and waits *t* time and doesn't do anything at this time.  Then, it receives the GetState result, and sends a SetState, then *waits for the result yet again* and then completes the transaction, and only afterwards - T2 is handled!  If we had 8 goroutines dispatch peer messages, we could increase throughput by 800%, because you could service 8 transactions at the same time by being able to send to the peer 8 GetState (for example) queries at the same time.  {quote}Therefore, we believe introducing efficient APIs is one of the options we can choose.{quote} We *can* choose that for sure, but we *should* prefer solutions that don't have an impact on the API if all we want in the first place is to increase the throughput.  ></body> </Action>
<Action id="40554" issue="21067" author="miyamae" type="comment" created="2018-02-22 05:12:30.0" updateauthor="miyamae" updated="2018-02-22 05:12:30.0"> <body><! CDATA Hi Yacov, let me understand your idea achieving 800% throughput more clearly. (1) Are you really assuming no changes are required in chaincodes?     (Do we only have to optimize shim codes?) (2) Are you assuming multiple clients?     (Do 8 clients invoke Tx(x=1...8) transactions concurrently?)  ></body> </Action>
<Action id="40557" issue="21067" author="yacovm" type="comment" created="2018-02-22 07:57:15.0" updateauthor="yacovm" updated="2018-02-22 07:57:15.0"> <body><! CDATA Right, we only need to change the peer chaincode code and the shim infrastructure code, but not any API change.  {quote}Are you assuming multiple clients?{quote} Either multiple clients or a single client sending in parallel multiple proposals. Otherwise the throughput will be capped at the maximum throughput a client can send to the system.  ></body> </Action>
<Action id="40622" issue="21067" author="miyamae" type="comment" created="2018-02-23 08:39:49.0" updateauthor="miyamae" updated="2018-02-23 08:39:49.0"> <body><! CDATA It sounds like "neither client nor chaincode does not have to be parallelized". How do you send 8 GetState queries to the peer at the same time?  ></body> </Action>
<Action id="40624" issue="21067" author="yacovm" type="comment" created="2018-02-23 09:21:18.0" updateauthor="yacovm" updated="2018-02-23 09:22:22.0"> <body><! CDATA {quote} How do you send 8 GetState queries to the peer at the same time?{quote}  I just have 8 different gRPC streams so I send them to the peer at the same time  ></body> </Action>
<Action id="40766" issue="21067" author="miyamae" type="comment" created="2018-02-26 03:19:02.0" updateauthor="miyamae" updated="2018-02-28 23:53:55.0"> <body><! CDATA Thank you, Yacov. I finally understand your idea. It might be good as an option. However, it's not perfect because thread-safe shim would not necessarily solve the latency problem for some kind gigantic chaincodes like large amount of matrix initialization (initialization of matrix with 32,000 elements would take 10 seconds or more). In addition, thread-safe shim might make shim codes unnecessarily complicated and keeping it safety might actually not be so easy. On the other hand, adding new efficient API such as Compound Request requires only a tiny codes and it's even simpler. By the way, do you have any plans for thread-safe shim at this moment, Yacov and Gari?  ></body> </Action>
<Action id="40775" issue="21067" author="yacovm" type="comment" created="2018-02-26 08:18:29.0" updateauthor="yacovm" updated="2018-02-26 08:18:29.0"> <body><! CDATA {quote} By the way, do you have any plans for multi-threading shim at this moment, Yacov and Gari?{quote}  I would love to do that, but I don't call the shots  ></body> </Action>
<Action id="67136" issue="21067" author="sykesm" type="comment" body="Stale" created="2020-01-22 22:07:16.0" updateauthor="sykesm" updated="2020-01-22 22:07:16.0"/>
