<Action id="25919" issue="17273" author="weeds" type="comment" body="Clayton and I talked with Chris Elder. He&apos;s waiting on results of FAB 4442 where Ratnkar is testing parameters for couchdb that was suggested.  Chris ran a much heavier load directly on ledger as compared to running full end to end in this particular test that results in FAB 4243. FAB 4442 is really running full end to end the way a client will run." created="2017-06-09 20:33:56.0" updateauthor="weeds" updated="2017-06-09 20:33:56.0"/>
<Action id="26016" issue="17273" author="denyeart" type="comment" created="2017-06-12 12:49:58.0" updateauthor="denyeart" updated="2017-06-12 13:16:55.0"> <body><! CDATA We don't expect a real system to be able to drive CouchDB as hard as it was driven during this isolated ledger stress test, therefore I will update to Medium.  Also, the problem does not cause any inconsistent/corrupt ledger state.  When the stress/resource problem is resolved, the system can move forward.   ~chris.elder , could you provide an update today? Are you able to reproduce at will?  Have you contacted Cloudant CouchDB experts and/or opened a CouchDB JIRA bug?  ></body> </Action>
<Action id="26056" issue="17273" author="chris.elder" type="comment" created="2017-06-12 18:57:20.0" updateauthor="chris.elder" updated="2017-06-12 18:57:20.0"> <body><! CDATA I took another look at the data in the spreadsheets.   I believe it makes sense to look at the non-Docker implementation of CouchDB and find where the processes fail.    In this case, it was specific to the number of chains (databases).  I added some server parameters but could not consistently reach 500 chains in load testing.  I will reach out to the IBM CouchDB experts to see if they have insight into large numbers of databases.  ></body> </Action>
<Action id="26187" issue="17273" author="chris.elder" type="comment" created="2017-06-13 19:22:44.0" updateauthor="chris.elder" updated="2017-06-13 19:22:44.0"> <body><! CDATA I had a discussion today with the CouchDB team.   There is a change in CouchDB 2.0 that make setting a little misleading.     The max_dbs_open configuration setting is a misleading.   This is not the count of databases, but the number of shards.  number of shards per node = (N*Q) / (number of nodes in cluster)  This required a much higher value since our defaults values are N=1 and Q=8.   In stress testing this required a max_dbs_open setting greater than 18000.  Also, it was found that ephemeral port configuration was required for the high end of the stress test.  net.inet.tcp.msl: 1000  net.inet.ip.portrange.first: 20000  net.inet.ip.portrange.last: 65535  These settings allowed the stress tests to complete the test with 500 channels and 10 concurrent threads.  The discussion above is targeted at CouchDB running locally, not in the docker image.  The CouchDB team informed that production issues with CouchDB have been encountered with docker.  However, all of the issues have been resolved with local tuning and no changes to CouchDB code.  Overall,  I think we have the information we need to lower the severity of this defect for the beta.   The key is that the overall end to end stress testing is working.   Work will need to continue on refining how CouchDB needs to be configured with the peer in a production environment.     ></body> </Action>
<Action id="26188" issue="17273" author="jonathanlevi" type="comment" body="This is great news. Thank you Chris" created="2017-06-13 19:24:21.0" updateauthor="jonathanlevi" updated="2017-06-13 19:24:21.0"/>
<Action id="26197" issue="17273" author="binhn" type="comment" body=" ~ChristopherFerris ,  ~JonathanLevi ,  given the new info from  ~chris.elder , I am advocating to lower priority on this defect to medium and remove it from RC blocking defect." created="2017-06-13 20:30:57.0" updateauthor="binhn" updated="2017-06-13 20:34:50.0"/>
<Action id="26204" issue="17273" author="jonathanlevi" type="comment" created="2017-06-13 21:30:00.0" updateauthor="jonathanlevi" updated="2017-06-13 21:30:00.0"> <body><! CDATA Totally. Thank you Binh.  (Chris has just updated this accordingly)  ></body> </Action>
<Action id="26315" issue="17273" author="chris.elder" type="comment" created="2017-06-14 18:31:27.0" updateauthor="chris.elder" updated="2017-06-14 18:31:27.0"> <body><! CDATA CouchDB stress testing/benchmarking are now passing running on a Linux environment with some environmental changes.   Tests passed with CouchDB running inside a docker container simulating the desired production environment for the peer.  Two changes were made to the OS:  #Increase the range for ephemeral ports to allow increased socket connections  sudo sysctl -w net.ipv4.ip_local_port_range="20000 60999"  #Reduce the timeout for the time sockets stay in FIN-WAIT-2 state before timing out to 5 sec  sudo sysctl -w net.ipv4.tcp_fin_timeout="5"  One change was made to the CouchDB local.ini file:   couchdb   max_dbs_open = 30000     This information should resolve this defect as it relates to the current level of stress testing.   Before closing there should be some additional discussion with Dave Enyeart and management about what productions levels we may expect in production and how best to make recommendations.     The good news from the testing is that there were no code changes required for this correction, only configuration changes.   In my opinion, the only changes that should be considered are possible changes to the CouchDB local.ini file.   These are not critical, since they can be changed at any time by the end user.  ></body> </Action>
<Action id="26399" issue="17273" author="denyeart" type="comment" created="2017-06-15 13:59:45.0" updateauthor="denyeart" updated="2017-06-15 13:59:45.0"> <body><! CDATA  ~chris.elder , can those OS config changes be made in the couch docker container? Or must they be made on the native OS on which the docker container runs?  Also, I believe you had some configuration updates prior to making these final updates (e.g. Erlang config that you mentioned earlier, and ulimit mentioned in FAB-3464).  Please summarize the entire set of config updates that were required to make CouchDB run well under stress.  We should document the minimal set of config updates, so this may require some more trials for you to determine the strict minimum number of config updates.  Once the full (and minimum) set of config updates is summarized in a defect comment, then I'd suggest switch this to fabric-docs component so that this this bug can be used to update the docs.  FAB-3464 is already opened to document ulimit.  This one will add to docs the other config updates that are required.  I'd suggest not to rush to update the fabric-couchdb image. Depending on a deployment's requirements they will need different configurations, so it is most important to get the information documented.  Later, we can update fabric-couchdb image once we have more experience with these settings and better understanding of typical workloads.  ></body> </Action>
<Action id="26567" issue="17273" author="manish-sethi" type="comment" created="2017-06-16 15:10:36.0" updateauthor="manish-sethi" updated="2017-06-16 15:30:27.0"> <body><! CDATA  ~chris.elder  - Were you able to get past 500 chains? On the workload front, I think that you are trying to deal with two challenges at the same time which is making it difficult to decipher. 1) number of databases 2) concurrency. Unfortunately, current test harness increases the concurrency if you increase the number of chains (The lowest tat you can set is - number concurrent client = 1 per chain).  Given what we are observing as throughput numbers in an end-to-end measurement, I would worry more about the number of databases as oppose to the concurrency.  If you can run a small experiment with a slight change in the experiment setting (if you haven't already done this and it's not very difficult for you), it would give us more insight. The proposed experiment is to reduce the number of concurrent client to 1 per chain (I guess, the default is 10) - introduce some 'think time' in the experiment code (e.g., `sleep` for a few millis at the end of function `runReadWriteClient`. This should keep us reasonably out of ephemeral ports issue because of reduced concurrency and then see if we can touch 1000, 2000 chains. If this takes us to high number of chains then we should be good for the current workload that we can anticipate. (You may like to reduce the setting `{color:#333333}NumTotalTx` for avoiding the test taking too long to complete because of the `sleep` of a few millis){color}  We can later focus on concurrency by investigating into some connection pool stuff in golang. In a nutshell, my suggestion would be to understand these two setting separately to get a better grasp of these.     Finally, as I discussed before, I would highly suggest to check with couch folks what is the max database numbers they have seen in their environments and what max concurrency have they experimented with. Just to be aware whether the high number of dbs are common practice and supported by them or we are the first one getting into this territory. In the latter case, I think that it would be better to use a single db for all the chains data (as we do in level) and achieve overall data balancing by the underlying shards of couch.  ></body> </Action>
<Action id="26785" issue="17273" author="denyeart" type="comment" created="2017-06-19 19:25:02.0" updateauthor="denyeart" updated="2017-06-19 19:25:02.0"> <body><! CDATA Discussed with  ~chris.elder .  The ulimit and ephemeral port settings are made on the host OS.  And the max_dbs_open setting is made in CouchDB local.ini. These should be documented using FAB-4872.  We will use this defect to increase the default setting for max_dbs_open.  Current default value for max_dbs_open in default.ini is 500.  This corresponds to 500 shards or 62 databases (there are 8 shards per database by default).  For highly concurrent environments with a large number of channels, a better default would be 1000 databases, which corresponds to max_dbs_open of 8000.  CouchDB uses LRU cache to manage open databases, and closes databases as needed.   Perhaps more important than picking a higher default value, is that the configuration value be exposed in the CouchDB local.ini configuration file, so that consumers are aware of the setting, and can easily adjust if needed.   ></body> </Action>
<Action id="26790" issue="17273" author="denyeart" type="comment" body="https://gerrit.hyperledger.org/r/#/c/10797/" created="2017-06-19 20:01:00.0" updateauthor="denyeart" updated="2017-06-19 20:01:00.0"/>
