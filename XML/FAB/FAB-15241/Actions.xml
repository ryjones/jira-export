<Action id="59853" issue="39431" author="scottz" type="comment" created="2019-05-08 18:21:35.0" updateauthor="scottz" updated="2019-05-08 19:08:31.0"> <body><! CDATA In master branch, the behave test jobs first started failing every day, continuing today, (with no post build report summary of behave pass/fail counts) with the IOError on Jan 24th, build 144. The actual failing testcase was in fabric-ca.feature, test FAB-11621 1.1. https://logs.hyperledger.org/production/vex-yul-hyp-jenkins-3/fabric-test-daily-behave-master-x86_64/144/  Nothing changed in fabric-test in the Behave framework or feature tests or Makefile on Jan 23 or Jan 24.  ></body> </Action>
<Action id="59930" issue="39431" author="scottz" type="comment" created="2019-05-11 02:05:35.0" updateauthor="scottz" updated="2019-05-11 02:05:35.0"> <body><! CDATA https://gerrit.hyperledger.org/r/#/c/31333/ It appears the behave framework can fail on ANY test that fails, producing the IOError msg, whenever the failing test produces at least 64K of output combined of stdout and stderr and CLI logging messages. This update reduces the amount of logs produced, mostly by eliminating some CLI Debug logs and some error logs that were not real errors.  ></body> </Action>
<Action id="59968" issue="39431" author="bharadwajambati1" type="comment" created="2019-05-13 18:16:08.0" updateauthor="bharadwajambati1" updated="2019-05-13 22:01:18.0"> <body><! CDATA  https://gerrit.hyperledger.org/r/#/c/31346/   Added an option to redirect the logs of the behave tests to a file in features/behave_tests.log. This will helps in preventing the IOError in the logs and continue to run the remaining test scenarios, even if the previous scenario failed.      Also reverted the previous change  ></body> </Action>
<Action id="60135" issue="39431" author="bharadwajambati1" type="comment" body=" https://gerrit.hyperledger.org/r/#/c/31427/  for release-1.4 branch" created="2019-05-17 22:17:36.0" updateauthor="bharadwajambati1" updated="2019-05-17 22:17:36.0"/>
