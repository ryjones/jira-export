<Action id="19224" issue="13011" author="tuand" type="comment" body="Hi  ~scottz  take first crack at reproducing ?   Also  ~bmos299 " created="2016-10-13 17:41:58.0" updateauthor="tuand" updated="2016-10-13 17:41:58.0"/>
<Action id="19225" issue="13011" author="jyellick" type="comment" created="2016-10-13 17:52:14.0" updateauthor="jyellick" updated="2016-10-13 17:55:03.0"> <body><! CDATA This is a known issue/limitation.  For a thorough discussion, please see https://github.com/hyperledger-archives/fabric/issues/1120  Essentially, once a replica advances its view, it will ignore messages in views with a lower number.  In this case, vp3 has erroneously advanced its view to 1, but the rest of the network is in view=0, so, vp3 will ignore the messages from the rest of the network until the view advances.  The question is whether this is a bug or not.  By academic definitions, this is working as designed.  PBFT guarantees that f+1 correct replicas have the current state at any time, and to have a guarantee about a query result, it must be done as a strong read which goes through consensus (which requires 2f+1 replicas to participate).  In this case, f=1 of the replicas is out of sync, and this would be considered 'okay'.  Still, we anticipated that this might not be desirable for some clients, so there is a periodic view change which can be turned on, which causes the network to periodically advance the view.  When this happens, the network's view will catch up to the out of sync replica's view, and this replica will be able to participate again.  However, changing views does cause overhead, and so enabling this feature will slow network throughput.  Also note, because this is not default config, it is a less tested configuration.  ></body> </Action>
<Action id="19227" issue="13011" author="scottz" type="comment" created="2016-10-14 01:18:47.0" updateauthor="scottz" updated="2016-10-14 01:18:47.0"> <body><! CDATA Even though the network can continue without it, I would say that if "vp3 has erroneously advanced its view", then it sounds like a real bug to me. Other statements from design have indicated that an "extra" peer will eventually catch up after a deterministic number of batches. If this peer vp3 does not do that, and/or continues causing confusion with its viewchanges, and has essentially become a non-participating member, then it sounds like it should be fixed.   What happens if other peers do the same thing? Even if all is fine should the peer Nevertheless the network is not operating optimally, so we are not providing the best service possible, which is being paid for.  The decision of when (i.e. whether or not to fix in v0.6 urgently) is a different decision.  ></body> </Action>
<Action id="19315" issue="13011" author="frankylu" type="comment" created="2016-10-20 14:08:13.0" updateauthor="frankylu" updated="2016-10-20 14:11:11.0"> <body><! CDATA maybe the paper just didn't have enough space to cover this level of detail :) The problem comes when the request wait time is not long enough for rest of the network to push seqNo exceed the watermark by at least one checkpoint. the quick solution out of people's mind would be to increase the request timeout so that a reconnected replica will wait long enough for the network to move beyond its high watermark. However, in real life there will be many systems running 24/7 so the TPS will vary greatly depending on the time of the day/week, so you may need to set the request timeout very long just to prevent they system from failing when the TPS is very low, but this will of course trigger other problems if a replica got disconnected when the TPS is high during some peak hour of a normal working day.  just wondering,  I don’t remember the paper covered this, but intuitively speaking, if the view change is triggered by a replica’s own problem, shouldn’t the recovered replica return back to the original view when no one else on the network would agree with its view change request? thoughts?  ~jyellick   ~marko.vukolic   ~cca88   from business stand point, if the purpose of blockchain is for independent organizations to co-own a data service, then I am not sure if any “client” can accept the fact that their out of sync peer will be out of the network forever (unless you wipe out all the data and restart the network).  making view change a timed mandatory event would sort of work though, albeit not a very efficient option and is difficult to pick the right interval (same 24/7 problem).    ></body> </Action>
<Action id="19319" issue="13011" author="jyellick" type="comment" created="2016-10-20 16:19:58.0" updateauthor="jyellick" updated="2016-10-20 16:19:58.0"> <body><! CDATA > Other statements from design have indicated that an "extra" peer will eventually catch up after a deterministic number of batches.  This is a true statement, but is perhaps misinterpreted.  The peer's _state_ will catch up after a deterministic number of batches, but this is not the same as saying that it will become an active participant in the PBFT network after a deterministic number of batches.  In fact, in this case the state will catch up, then it will fall behind, and catch up, and fall behind and so on until the network changes view.  Though this might sound somewhat pointless, the idea is that the peer's state will be 'nearly current' when the view advances so that it can quickly step in and participate.  > The decision of when (i.e. whether or not to fix in v0.6 urgently) is a different decision.  The reason that a 'fix' was not included in 0.5 was because it is an extremely non-trivial thing to fix.  As pointed out in the github issue linked, this would likely require introducing a new message type and logic around that message, which is not a minor undertaking.  > The problem comes when the request wait time is not long enough for rest of the network to push seqNo exceed the watermark by at least one checkpoint.   The replica has actually missed a transaction, and missing a transaction is valid grounds to issue a view change request.  By setting the request timer to a very high value, the replica can retrieve the missing transaction via state transfer, but this is a bit of an odd end-around, and I agree, it's not a good solution because it will make recovery times very slow when real faults do happen.  > just wondering, I don’t remember the paper covered this, but intuitively speaking, if the view change is triggered by a replica’s own problem, shouldn’t the recovered replica return back to the original view when no one else on the network would agree with its view change request?  I think it's hard to define "the replica's own problem", because the replica does not know whether the primary is being byzantine and not sending the message, or whether it somehow just 'missed' the message.  The proposal outlined by  ~marko.vukolic  in the Github issue is to issue 'Suspect' messages, which do not actually advance the view, but instead wait for a sufficient number of suspicions before doing so.  I'm not sure what the implications of continuing to participate in the network after sending a view change would be, but I suspect there are some corner cases this addresses as otherwise this would be the obvious behavior.  > from business stand point, if the purpose of blockchain is for independent organizations to co-own a data service, then I am not sure if any “client” can accept the fact that their out of sync peer will be out of the network forever (unless you wipe out all the data and restart the network).  The peer would rejoin the network if another failure ever occurred (causing a view change), but I agree, this is not optimal.    > making view change a timed mandatory event would sort of work though, albeit not a very efficient option and is difficult to pick the right interval (same 24/7 problem).  A timer could be started on startup or new-view, which triggers a view change after some period of time.  This would be a pretty trivial code change.  ></body> </Action>
<Action id="19375" issue="13011" author="kchristidis" type="comment" created="2016-10-22 03:57:58.0" updateauthor="kchristidis" updated="2016-10-22 04:47:53.0"> <body><! CDATA This is inline with what we discussed with Frank on the #fabric-consensus-dev channel a few weekends back as well.  I will give this a few days and then close it unless there are any objections.  ></body> </Action>
<Action id="19395" issue="13011" author="frankylu" type="comment" created="2016-10-23 04:21:13.0" updateauthor="frankylu" updated="2016-10-23 04:29:33.0"> <body><! CDATA >  The proposal outlined by Marko Vukolic in the Github issue is to issue 'Suspect' messages, which do not actually advance the view, but instead wait for a sufficient number of suspicions before doing so. I'm not sure what the implications of continuing to participate in the network after sending a view change would be, but I suspect there are some corner cases this addresses as otherwise this would be the obvious behavior.  I think 'suspect' message would be necessary to follow up protocols (eg. sbft) if we don't have another way to solve it.   Switching view after a fixed number of checkpoints is still problematic because it will mean view changes will happen more frequently during peak tx hours. basically, you will slow the system down whenever you need the most throughput performance.  > A timer could be started on startup or new-view, which triggers a view change after some period of time. This would be a pretty trivial code change.  This would be a better option than triggering view change after a fixed number of checkpoints, though probably not that trivial consider timer on most nodes needs to be in sync.     ></body> </Action>
<Action id="19399" issue="13011" author="scottz" type="comment" created="2016-10-23 17:16:10.0" updateauthor="scottz" updated="2016-10-23 17:16:10.0"> <body><! CDATA I read many of those other issues, and have a better understanding. Correct me if I am wrong; you are saying it is OK for VP3 behave as it is behaving. As a result of restarting, VP3 has advanced its view and is ahead of the rest of the network. It would become an active participant in the network again at some unknown future time when the network advances its view. * This could happen, for example, if VP2 stops, leaving only VP0 and VP1 in sync - so those two would request viewchanges and advance the network view to the point where VP3 could work with them to process transactions. * This could also happen if we use a non-default value for a config parm to force viewchanges after some time or number of transactions.)  Questions:  # Why did VP3 advance its view? Was that necessary? Nobody seemed to talk about that, so I suppose it might be part of the PBFT protocol (which I admit I am not an expert). # As a Network Operations Manager/Observer, how can I determine the health of the network? Can I tell how many peer nodes that can be counted on, at any given moment? That would be the sum of the number of valid nodes plus any such as VP3. Or it might the the sum of functional nodes minus the number of byzantines. Let me rephrase: a network management tool could ping all the peers in the network to see which are functioning. It could also query them all to see their chainheights or chaincode data values. It would observe VP3 is lagging. Is it considered byzantine? Or, could the tool determine whether VP3 is "giving an honest effort" and is in such a state that it could help the network (eventually) if it becomes necessary due to other node faults? How could it distinguish between an OK node like this and a truly faulty/byzantine node?   ></body> </Action>
<Action id="19417" issue="13011" author="jyellick" type="comment" created="2016-10-24 15:48:58.0" updateauthor="jyellick" updated="2016-10-24 15:48:58.0"> <body><! CDATA > Why did VP3 advance its view? Was that necessary? Nobody seemed to talk about that, so I suppose it might be part of the PBFT protocol (which I admit I am not an expert).  Vp3 observed the primary 'skip' a sequence number.  This happened because the primary broadcasted the message while vp3 was down.  When a primary skips a sequence number, this prevents execution and halts the network until view change, vp3 is contributing its vote because it thinks the network needs a view change to advance.  > As a Network Operations Manager/Observer, how can I determine the health of the network? Can I tell how many peer nodes that can be counted on, at any given moment? That would be the sum of the number of valid nodes plus any such as VP3. Or it might the the sum of functional nodes minus the number of byzantines. Let me rephrase: a network management tool could ping all the peers in the network to see which are functioning. It could also query them all to see their chainheights or chaincode data values. It would observe VP3 is lagging. Is it considered byzantine? Or, could the tool determine whether VP3 is "giving an honest effort" and is in such a state that it could help the network (eventually) if it becomes necessary due to other node faults? How could it distinguish between an OK node like this and a truly faulty/byzantine node?  Under true byzantine conditions, you can always be assured the there are f+1 correct peers actively participating in the network.  You may be able to identify replicas which are not actively participating by examining their chain heights, but this is not foolproof.  It's essentially impossible to determine byzantine from best effort, the best you could hope for is for the replica to report that it knows it is out of sync.  For future work, I think it would be a good idea to include a gRPC call to get replica state (whether its view is active, what view, what seqno, etc.), but in v0.5/0.6 there is nothing of this sort.  ></body> </Action>
<Action id="19421" issue="13011" author="binhn" type="comment" created="2016-10-24 17:12:36.0" updateauthor="binhn" updated="2016-10-24 17:12:36.0"> <body><! CDATA > Vp3 observed the primary 'skip' a sequence number. This happened because the primary broadcasted the message while vp3 was down. When a primary skips a sequence number, this prevents execution and halts the network until view change, vp3 is contributing its vote because it thinks the network needs a view change to advance.  For next rev of the algo, perhaps we should consider that if a peer has not (re)joined consensus and has not received a view change request from other peers, then it should wait rather than keep sending useless view change requests. This certainly doesn't offer the ability for a peer to rejoin consensus.   ></body> </Action>
<Action id="19423" issue="13011" author="scottz" type="comment" created="2016-10-24 18:00:01.0" updateauthor="scottz" updated="2016-10-24 18:00:01.0"> <body><! CDATA OK, I will not object to closing this issue as "design intent".   I will create two other issues, as suggested by Jason (an interface to provide status info) and Binh (optimization to reduce/eliminate the noisy useless viewchange requests in this situation which are occurring every 2 seconds).  ></body> </Action>
<Action id="19690" issue="13011" author="frankylu" type="comment" created="2016-11-08 05:47:34.0" updateauthor="frankylu" updated="2016-11-08 05:53:46.0"> <body><! CDATA Yes, if we think this problem as a pure academic topic when the protocol was designed then this issue is a "design intent", but if we think this implementation as something to be used by industries then it would become a "design gap"  I vote to keep this open until we get a confirmation that some mechanism (such as the proposed SUSPECT message ) is added to the either this protocol or SBFT.  ~marko.vukolic   ~kchristidis   ></body> </Action>
<Action id="19739" issue="13011" author="scottz" type="comment" body="This has been confirmed with testing. I am putting this back on the team&apos;s list of unassigned issues, and it can be fixed if it becomes critical in future." created="2016-11-11 18:28:54.0" updateauthor="scottz" updated="2016-11-11 18:28:54.0"/>
<Action id="20068" issue="13011" author="vukolic" type="comment" body="I am aware of this issue and minding it for v1 (simple(p)bft implementation). The SUSPECTS would be a heavyweight and invasive change. I am more inclined to have a solution in which such a replica, while perhaps remaining &quot;stuck&quot; alone in a view change, obtains periodically updates from other replicas via a separate very lightweight &quot;state-transfer-like&quot; mechanism." created="2016-12-12 14:36:26.0" updateauthor="vukolic" updated="2016-12-12 14:36:26.0"/>
