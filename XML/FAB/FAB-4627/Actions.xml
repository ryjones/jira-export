<Action id="26271" issue="17898" author="kchristidis" type="comment" body="This bug is filed as HIGH priority yet the orderer logs do not include any orderer logging statements. (Only from the Kafka library.) Why are these omitted? We should be logging at DEBUG level." created="2017-06-14 14:42:11.0" updateauthor="kchristidis" updated="2017-06-14 14:42:11.0"/>
<Action id="26273" issue="17898" author="kchristidis" type="comment" body="Also, the Docker Compose configuration files are missing." created="2017-06-14 14:54:15.0" updateauthor="kchristidis" updated="2017-06-14 14:54:15.0"/>
<Action id="26276" issue="17898" author="suryalnvs" type="comment" body="In the above mentioned test case, we are sending 300000 transactions which is making the log files grow large in size, when loglevel set to debug, which I am not able to add in here." created="2017-06-14 15:13:05.0" updateauthor="suryalnvs" updated="2017-06-14 15:13:05.0"/>
<Action id="26277" issue="17898" author="kchristidis" type="comment" created="2017-06-14 15:17:03.0" updateauthor="kchristidis" updated="2017-06-14 15:17:03.0"> <body><! CDATA But it's impossible for me to debug without a log file.  Let's post the file on Dropbox or Google Drive if we have to and add the link here.  ></body> </Action>
<Action id="26279" issue="17898" author="kchristidis" type="comment" body="Even an extract of the log files is better than nothing." created="2017-06-14 15:18:01.0" updateauthor="kchristidis" updated="2017-06-14 15:18:01.0"/>
<Action id="26280" issue="17898" author="kchristidis" type="comment" body="It might also be helpful to turn the Kafka verbosity to off (`KAFKA_VERBOSE=FALSE`) so that we can get the output of the orderer only." created="2017-06-14 15:18:48.0" updateauthor="kchristidis" updated="2017-06-14 15:18:48.0"/>
<Action id="26285" issue="17898" author="suryalnvs" type="comment" created="2017-06-14 15:41:00.0" updateauthor="suryalnvs" updated="2017-06-14 15:44:59.0"> <body><! CDATA Here is the link for the orderer logs with debug logging level  https://drive.google.com/drive/u/0/folders/0Bwi1M8GROKyQdFp0ZGFCcTB3U0k.  |https://drive.google.com/drive/u/0/folders/0Bwi1M8GROKyQdFp0ZGFCcTB3U0k   If you need any information/execution steps, do not hesitate to reach out to me.  ></body> </Action>
<Action id="26302" issue="17898" author="kchristidis" type="comment" created="2017-06-14 17:21:18.0" updateauthor="kchristidis" updated="2017-06-14 17:21:18.0"> <body><! CDATA How did you address this? https://jira.hyperledger.org/browse/FAB-4415  And what steps are you taking to make sure this doesn't happen?  I see these printouts in the logs: {noformat}  sarama  2017/06/14 15:20:20.289551 client.go:620: client/metadata got error from broker while fetching metadata: dial tcp 9.42.20.87:9092: getsockopt: connection refused  sarama  2017/06/14 15:20:20.298898 client.go:620: client/metadata got error from broker while fetching metadata: dial tcp 9.42.20.81:9092: getsockopt: connection refused  sarama  2017/06/14 15:20:20.306592 client.go:620: client/metadata got error from broker while fetching metadata: dial tcp 9.37.200.4:9092: getsockopt: connection refused{noformat} Which make me thing that the local networking issues you were facing FAB-4415 persist.  ></body> </Action>
<Action id="26304" issue="17898" author="kchristidis" type="comment" created="2017-06-14 17:25:57.0" updateauthor="kchristidis" updated="2017-06-14 17:25:57.0"> <body><! CDATA What is the timestamp in the log when you bring the first broker down? (What about the second one?)  Approximate timestamps will do.  Please update the JIRA with this information.  ></body> </Action>
<Action id="26307" issue="17898" author="kchristidis" type="comment" created="2017-06-14 17:39:19.0" updateauthor="kchristidis" updated="2017-06-14 17:39:19.0"> <body><! CDATA Just to confirm: {quote}During this restart process, when a kafka broker is taken down, to which the orderers are connected to, the deliver clients grpc connection are being dropped with SERVICE_UNAVAILABLE. All deliver clients encountered this error and dropped grpc connections at same time, when we stopped one particular kafka broker (not the first one) - so we suspect the orderers were all connected to that one. {quote} If you keep that broker down, will you be able to have your Deliver RPCs served eventually?  The answer should be yes. In which case this is not a bug. (If I'm wrong, please let me know.) {quote}Taking down one kafka broker out of 4, should not affect the orderer connections as relication factor is set to 3, minimum ISR is set to 2. {quote} I can see why you would expect that but this is not how things work. (And this is because of the way Kafka works.)  Even if you take down a number of brokers that's well within your crash fault tolerance limits (as is the case with your experiment), the connected clients will return SERVICE_UNAVAILABLE and will drop the connection. If you reconnect, the request will go through. This is needed because Kafka/ZK needs to assign a different leader to the channel, and the orderer needs to establish a connection to the new leader for that channel. (If you suggest that the orderer should hold off a little while, see if they can get a connection to the new broker, and _then_ trigger the SERVICE_UNAVAILABLE response, I can assure you that this gets tricky fast, and has repercussions on the orderer's responsiveness in general. It something that we could maybe look into later down the road, but it's low in my list of priorities.)  This is also inline with the Kafka semantics BTW: a failing consumer should keep retrying.  ></body> </Action>
<Action id="26309" issue="17898" author="kchristidis" type="comment" body="(Downgrading this and expecting confirmation from Surya on the above.)" created="2017-06-14 17:40:19.0" updateauthor="kchristidis" updated="2017-06-14 17:40:19.0"/>
<Action id="26320" issue="17898" author="suryalnvs" type="comment" body="No, when I take down a kafka broker, deliver client&apos;s grpc connection is dropped with the orderer and its not able to serve anymore requests." created="2017-06-14 19:01:44.0" updateauthor="suryalnvs" updated="2017-06-14 19:01:44.0"/>
<Action id="26322" issue="17898" author="kchristidis" type="comment" body="Got it. Please address the rest of the comments above." created="2017-06-14 19:11:55.0" updateauthor="kchristidis" updated="2017-06-14 19:11:55.0"/>
<Action id="26324" issue="17898" author="suryalnvs" type="comment" created="2017-06-14 19:46:19.0" updateauthor="suryalnvs" updated="2017-06-14 19:48:58.0"> <body><! CDATA regarding the timestamps, took down the kafka0 broker at *Stopping kafka0 at  2017-06-14 19:02:02.967123925 +0000 UTC*, kafka1 at *Stopping kafka1 at  2017-06-14 19:04:35.665246601 +0000 UTC*, kafka2 at *Stopping kafka2 at 2017-06-14 19:07:09.04119599 +0000 UTC*  Uploaded the latest logs, refer them with the timestamps mentioned above(added new orderer logs to  https://drive.google.com/drive/u/0/folders/0Bwi1M8GROKyQdFp0ZGFCcTB3U0k ).     When I ran same testcase using *beta version*, I haven't seen this behaviour of dropping grpc connection during sequential restart of the kafka-brokers  ></body> </Action>
<Action id="26328" issue="17898" author="c0rwin" type="comment" body=" ~suryalnvs  can you please also share peers logs as well? I need them to correlate with orderers log files." created="2017-06-14 20:23:04.0" updateauthor="c0rwin" updated="2017-06-14 20:23:23.0"/>
<Action id="26345" issue="17898" author="kchristidis" type="comment" created="2017-06-14 21:37:22.0" updateauthor="kchristidis" updated="2017-06-14 21:37:22.0"> <body><! CDATA Surya to post an update here.  Not a bug, this behavior is caused by the fact that the test uses a deliver client w/o retry logic.  After the beta we made it so that the orderer will disconnect all connected deliver clients if there is an issue with the orderer-to-Kafka communication. See:  https://gerrit.hyperledger.org/r/#/c/10323/   The issue here is that the test is bringing down the broker that is the leader for the channel in question. When that broker goes down, the orderer will return a service_unavailable (and disconnect the deliver client) while it establishes a connection to the new leader. This last for a second or two usually.  A deliver client w/ retry logic, such as the one the peer is equipped with, will handle this w/o issues.  ></body> </Action>
<Action id="26348" issue="17898" author="suryalnvs" type="comment" created="2017-06-14 21:44:31.0" updateauthor="suryalnvs" updated="2017-06-14 21:45:26.0"> <body><! CDATA  ~C0rWin  the test is not using peers, but simulating the process using deliver clients in OTE  (orderer traffic engine tool).  As per the discussion with Kostas, wiith the changes mentioned in this patchset  https://gerrit.hyperledger.org/r/#/c/10323/,  the grpc connection with the delivery clients will be closed, once the leader kafka broker is restarted, this is working as expected. Thank you  ~kchristidis   ></body> </Action>
