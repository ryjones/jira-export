<Action id="70950" issue="46412" author="yacovm" type="comment" created="2020-12-10 11:43:33.0" updateauthor="yacovm" updated="2020-12-10 11:43:33.0"> <body><! CDATA Gossip receives blocks from the orderer, and many peers in parallel, and dumps them all into a re-ordering buffer from which it reads in ascending order to commit into the ledger.   The buffer has a limited size, since your memory has a limited size.  If the next block you need is block 100 but you get blocks 200, 232, 598, etc. - if you put them inside the buffer, you won't have room for the blocks from 101 to, say, 120. Therefore gossip refuses to add blocks that are too far in the future into that buffer.   If the leader has progressed too much and a follower peer is too far in the past, the only way it can get blocks is if it asks for them explicitly from a remote peer via  a point to point block replication protocol (AKA "state transfer").  Starting from 2.2 this protocol is  disabled|https://github.com/hyperledger/fabric/blob/release-2.2/sampleconfig/core.yaml#L234  by default.   ></body> </Action>
<Action id="70954" issue="46412" author="JIRAUSER20661" type="comment" created="2020-12-10 13:11:59.0" updateauthor="JIRAUSER20661" updated="2020-12-10 13:11:59.0"> <body><! CDATA Thanks for the answer  ~yacovm . What is the correct approach then?  If the gossip block dissemination will be deprecated, is correct to receive blocks directly from orderer? In this case, this operation is considered to have an higher cost, so why this will be deprecated? I am sure that if I will make peers constantly align from orderer I will decrease performances and maybe create a bottleneck  ></body> </Action>
<Action id="70955" issue="46412" author="yacovm" type="comment" created="2020-12-10 13:39:00.0" updateauthor="yacovm" updated="2020-12-10 13:39:00.0"> <body><! CDATA If you want to offload your orderer and you fear it has insufficient bandwidth then use gossip but turn on state transfer.  Otherwise make all peers leaders so they all connect to the ordering service.   ></body> </Action>
<Action id="70956" issue="46412" author="JIRAUSER20661" type="comment" created="2020-12-10 14:36:03.0" updateauthor="JIRAUSER20661" updated="2020-12-10 14:36:03.0"> <body><! CDATA Thanks for the answer again  ~yacovm . I turned peer election to false and now peers correctly align with orderer, but this creates a bottleneck.  Aligning via orderer costs more as I said and the peers are not able to align missing blocks and at the same time process new transactions, I have a series of MVCC conflicts right away.  This seems the correct procedure because I read that gossip block dissemination will be deprecated, but this seems not to work perfectly at the moment. Anything else to suggest?  ></body> </Action>
<Action id="70957" issue="46412" author="yacovm" type="comment" created="2020-12-10 15:33:54.0" updateauthor="yacovm" updated="2020-12-10 15:33:54.0"> <body><! CDATA  {quote} Aligning via orderer costs more as I said and the peers are not able to align missing blocks and at the same time process new transactions, I have a series of MVCC conflicts right away.{quote}  Yes, during the block commit, there is a write lock on the entire channel. During chaincode execution, there is a read lock on the entire channel.   In  theory|https://arxiv.org/abs/1911.12711  this can be solved, if you don't care about couchDB rich queries, but this solution is not in Fabric at the moment and probably never will be.  {quote} This seems the correct procedure because I read that gossip block dissemination will be deprecated, but this seems not to work perfectly at the moment. Anything else to suggest?{quote} It will be deprecated but then according to you, it will create a bottleneck (what bottleneck?) {quote}I turned peer election to false and now peers correctly align with orderer, but this creates a bottleneck.{quote}      ></body> </Action>
<Action id="70958" issue="46412" author="yacovm" type="comment" body="I hope you don&apos;t mind I closed your issue, since there is no real bug here, it&apos;s just that Fabric has... certain problems." created="2020-12-10 15:35:07.0" updateauthor="yacovm" updated="2020-12-10 15:35:07.0"/>
<Action id="70959" issue="46412" author="JIRAUSER20661" type="comment" body="The bottleneck is that a peer starts being misaligned, so it starts getting blocks from the orderer, which is not fast as from gossip. So new transactions in this peer will not be done due to MVCC conflict. At the same time maybe other peers have this issue and they will start accumulating MVCC issues. At a certain point there will be 90% MVCC errors and just few transactions will be validated. This is what I experienced myself with my network." created="2020-12-10 15:50:02.0" updateauthor="JIRAUSER20661" updated="2020-12-10 15:50:02.0"/>
<Action id="70960" issue="46412" author="yacovm" type="comment" created="2020-12-10 16:01:58.0" updateauthor="yacovm" updated="2020-12-10 16:01:58.0"> <body><! CDATA {quote}The bottleneck is that a peer starts being misaligned, so it starts getting blocks from the orderer, which is not fast as from gossip. {quote}  How is it not as fast as gossip? The blocks are created at the orderers, so sending a block from a peer directly to an orderer should be faster than sending it first to some peer and then to another peer.  ></body> </Action>
<Action id="70961" issue="46412" author="JIRAUSER20661" type="comment" created="2020-12-10 16:35:52.0" updateauthor="JIRAUSER20661" updated="2020-12-10 16:36:13.0"> <body><! CDATA That's not actually true, gossip is faster, that's why is suggested do be used from documentation. Having just 1 peer receiving blocks and using it to disseminates is better.  From HLF doc:  https://hyperledger-fabric.readthedocs.io/en/release-2.1/gossip.html   _Static leader election allows you to manually define one or more peers within an organization as leader peers. Please note, however, that *having too many peers connect to the ordering service may result in inefficient use of bandwidth*._   ></body> </Action>
<Action id="70962" issue="46412" author="yacovm" type="comment" created="2020-12-10 16:55:01.0" updateauthor="yacovm" updated="2020-12-10 16:55:01.0"> <body><! CDATA Yes, having too many may result in inefficient use of bandwidth. But you have 3 peers in total, that's not a lot.    ></body> </Action>
<Action id="70963" issue="46412" author="JIRAUSER20661" type="comment" body="Well that&apos;s strange because it&apos;s really consuming a lot of bandwidth. As a rough, I am consuming around 2000 transactions each 90sec." created="2020-12-10 17:01:57.0" updateauthor="JIRAUSER20661" updated="2020-12-10 17:01:57.0"/>
<Action id="70964" issue="46412" author="yacovm" type="comment" body="A typical transaction is around 4KB so 2000 of them is 8MB which is really negligible even if you send this data 3 times. " created="2020-12-10 17:20:48.0" updateauthor="yacovm" updated="2020-12-10 17:20:48.0"/>
