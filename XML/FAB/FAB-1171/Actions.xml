<Action id="19827" issue="13504" author="kchristidis" type="comment" created="2016-11-21 18:29:54.0" updateauthor="kchristidis" updated="2016-11-21 18:29:54.0"> <body><! CDATA Thank you for providing these benchmarks.  ~mastersingh24  noted we usually see 100-200 kB transactions, and the largest one was 1MB. So, that would imply 2-8 transactions per block. That itself is not much of a problem, but I would note that the more blocks we have, the more signing we (as orderers) have to do. (On the receiving side, this doesn't necessarily translate to more signature verifications, since when you replay a chain you only need to verify the tip, and from thereon it's matter of checking the hashes.)  At any rate, a "desired" block size, and "max" block size is a good suggestion. I'll see how we can accommodate it, without increasing the complexity of the offering. Perhaps mark the desired block size option as optional?  ></body> </Action>
<Action id="19828" issue="13504" author="bcbrock" type="comment" body="What use case or benchmark needs or sees 100K to 200K transactions? Are you sure you&apos;re not off by 2 orders of magnitude? I would have expected 1K - 2K per transaction for a simple transaction. If there is so much overhead in the V1 architecture that a single, simple transaction requires 100KB of data then one might consider the V1 protocols to be in need of a major overhaul. With 100K blobs and 8 blobs/block, my very capable 2-socket server can only order and deliver less than 500 TX per second. So if this is true then we remain more than an order of magnitude away from meeting customer performance requirements, just in the ordering service. " created="2016-11-21 20:57:33.0" updateauthor="bcbrock" updated="2016-11-21 20:57:33.0"/>
<Action id="19898" issue="13504" author="sanchezl" type="comment" created="2016-11-30 05:04:53.0" updateauthor="sanchezl" updated="2016-11-30 05:04:53.0"> <body><! CDATA h5. Existing configuration property:  {{config.General.BatchSize}} # The maximum number of tx to permit in a block # Do we still need this?  h5. Proposed configuration properties: {{config.General.BlockSizeBytes}} # The _optimal_ size of block data payload in bytes # Block data payload will be no larger than this size, unless a single tx exceeds this size.  {{config.General.BlockMaxBytes}} # The absolute maximum size of a block's data payload in bytes # Required for {{OrdererType: kafka}} (maybe others?) # otherwise, if not specified, it's not enforced (or should there be a sensible default?)  h5. Other # We'll need to understand the overhead of the block structure, so that we can provide guidance to users on what exactly to expect when setting these values. # It would be great if we can agree ASAP if {{config.General.BatchSize}} should be removed (or not).   ></body> </Action>
<Action id="19902" issue="13504" author="bcbrock" type="comment" created="2016-11-30 14:23:01.0" updateauthor="bcbrock" updated="2016-11-30 14:23:01.0"> <body><! CDATA I would vote for keeping the {{config.General.Batchsize}}, at least for now. You never know what will turn out to be best for any end-to-end application - my experiments were only looking at orderer performance. The added complexity of supporting both seems very minor to me.   BTW, in some quick experiments yesterday I also saw that 400K blocks were optimal even with transactions of size 100K. This may be a function of the default 1MB message size in Kafka - at some point I'll need to increase this and see what happens.  ></body> </Action>
<Action id="19907" issue="13504" author="kchristidis" type="comment" body="+1 to what Bishop says, let&apos;s aim to support both. (I don&apos;t see us succeeding in removing the `BatchSize` option any time soon even if we tried too, as well.)" created="2016-11-30 16:44:14.0" updateauthor="kchristidis" updated="2016-11-30 16:44:14.0"/>
