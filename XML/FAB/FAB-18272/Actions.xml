<Action id="70527" issue="46208" author="wlahti" type="comment" created="2020-10-16 20:46:14.0" updateauthor="wlahti" updated="2020-10-16 20:46:14.0"> <body><! CDATA Not having much luck figuring this one out. The best I've been able to do is exclude the orderer's own endpoint from the block puller endpoints (using the Orderer.General.ListenAddress and Orderer.General.ListenPort). That avoids the underlying issue with the GRPCClient's NewConnection() call hanging the second time it tries to connect to itself (the first being the time it times out and the context is successfully closed).  Not sure if we really want the cluster BlockPuller to attempt to pull the block from its own endpoint or not though... It seems like we don't for the case of onboarding the system channel with a non-genesis block but I have no idea how things interact elsewhere.  ></body> </Action>
<Action id="70528" issue="46208" author="yacovm" type="comment" created="2020-10-16 21:28:30.0" updateauthor="yacovm" updated="2020-10-16 21:28:30.0"> <body><! CDATA If the dialer used by the orderer block replication gets stuck in connecting and never to times out, then as you have probably noticed, it will make the entire wait group wait indefinitely.   While I think that ideally we'd want to add the endpoint to the onboarding orderer only after it onboarded, there might be a much more severe problem here - as we know, Raft uses the same mechanism to catch up with the cluster when the node is too far behind. If a single unavailable node can make every node block replication forever, we have a bigger problem and this needs to be addressed.   ></body> </Action>
<Action id="70529" issue="46208" author="tock" type="comment" body=" ~wlahti  In the meantime we can split FAB-18273 to joining the system channel with a genesis vs non genesis. With genesis we&apos;re fine." created="2020-10-18 09:12:20.0" updateauthor="tock" updated="2020-10-18 09:12:20.0"/>
<Action id="70530" issue="46208" author="tock" type="comment" created="2020-10-19 08:07:03.0" updateauthor="tock" updated="2020-10-19 08:08:34.0"> <body><! CDATA  ~wlahti  After a discussion with  ~yacovm , he brought to my attention this test:  https://github.com/hyperledger/fabric/blob/69bc7319115545e8bae67877dcd8d4de5c87bda4/integration/raft/config_test.go#L733  which onboards a 4th node to a 3 node cluster by using a bootstrap block with block.number > 0. The difference is that the respective bootstrap block does not have the endpoint of the 4th node. The bootstrap block only has the 4th node in the consenters set, not the endpoints.   In order to verify the source of the problem we could add the endpoint of the 4th node as well in that test, and see what happens. This will simulate / replicate the situation we have in the failed test.  Then, we have a prescription for the user on how to onboard a new node with a system channel - basically - add the onboarding node's endpoint after it had finished on boarding. This is indicated by the orderer emitting the "Beginning to serve requests" message to the log...  ></body> </Action>
<Action id="70531" issue="46208" author="yacovm" type="comment" body="There is also  this|https://github.com/hyperledger/fabric/blob/69bc7319115545e8bae67877dcd8d4de5c87bda4/integration/raft/config_test.go#L298  which is simpler" created="2020-10-19 10:58:38.0" updateauthor="yacovm" updated="2020-10-19 10:58:38.0"/>
<Action id="70532" issue="46208" author="yacovm" type="comment" body="Also, you may want to disable this  indicator of successfully starting the process|https://github.com/hyperledger/fabric/blob/69bc7319115545e8bae67877dcd8d4de5c87bda4/integration/nwo/network.go#L1236 , as the test would fail before you realize why it failed." created="2020-10-19 11:09:27.0" updateauthor="yacovm" updated="2020-10-19 11:09:27.0"/>
<Action id="70533" issue="46208" author="wlahti" type="comment" body="I locally updated the test mentioned by Yacov  here|https://github.com/hyperledger/fabric/blob/69bc7319115545e8bae67877dcd8d4de5c87bda4/integration/raft/config_test.go#L298  to include the orderer2 endpoint. I see the same failure with that existing flow as we do with the channel participation API. " created="2020-10-19 16:24:26.0" updateauthor="wlahti" updated="2020-10-19 16:24:26.0"/>
<Action id="70538" issue="46208" author="wlahti" type="comment" created="2020-10-19 18:07:58.0" updateauthor="wlahti" updated="2020-10-19 18:07:58.0"> <body><! CDATA  ~yacovm  got to the bottom of this. It turns out that the ginkgomon.Runner's StartCheckTimeout  is the cause of the grpc connection hang. When the onboarding orderer node is included in the endpoints, the orderer takes longer to complete its startup. After 15 seconds (the default StartCheckTimeout we use in fabric IT), it kills the onboarding orderer process.   Bumping the StartCheckTimeout to 30 seconds does resolve the issue, but Yacov and I agree that including the onboarding orderer in the endpoints is not the best practice here and the tests should simply not include the orderer as an endpoint until it has completed onboarding.  ></body> </Action>
