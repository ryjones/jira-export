<Action id="57270" issue="37741" author="kchristidis" type="comment" body="Expecting an update on this tomorrow." created="2019-02-18 23:15:53.0" updateauthor="kchristidis" updated="2019-02-18 23:15:53.0"/>
<Action id="57361" issue="37741" author="kchristidis" type="comment" created="2019-02-20 14:50:40.0" updateauthor="kchristidis" updated="2019-02-20 14:50:40.0"> <body><! CDATA {quote}Since the recovery of a single orderer is expected to take less than 20 seconds{quote}  What is the source for this statement?  ></body> </Action>
<Action id="57490" issue="37741" author="kchristidis" type="comment" body="Friday&apos;s status: This is being re-run with step logging set to the debug level." created="2019-02-23 20:36:27.0" updateauthor="kchristidis" updated="2019-02-23 20:36:27.0"/>
<Action id="57492" issue="37741" author="suryalnvs" type="comment" created="2019-02-23 20:57:54.0" updateauthor="suryalnvs" updated="2019-02-23 21:00:17.0"> <body><! CDATA Reran this test with step logging level set to debug and able to reproduce the issue FAB-14274 . Added goroutines from the latest run.  logs url: https://app.us-south.logging.cloud.ibm.com/87cd83a6af/logs/view Timestamps to look for logs (rerun): from 02/22 10:16am EST Instance: regression-lab  ></body> </Action>
<Action id="57504" issue="37741" author="suryalnvs" type="comment" created="2019-02-24 05:57:13.0" updateauthor="suryalnvs" updated="2019-02-24 05:57:13.0"> <body><! CDATA Reran this with guoger/fabric-orderer:leaderless (custom image from Jay).  Test started at 11.27pm EST 02/23, initiated chaos-kube at 11.52pm EST 02/23 and observed the no raft leader on all the application channels at around 12.18am EST 02/24.  Also ran KILL -SIGUSR1 1 to get goroutines at Sun Feb 24 00:52:30 EST  logs url:  https://app.us-south.logging.cloud.ibm.com/87cd83a6af/logs/view  Timestamps to look for logs (rerun): from 02/23 11.27pm EST Instance: regression-lab     ></body> </Action>
<Action id="57518" issue="37741" author="kchristidis" type="comment" created="2019-02-24 18:17:06.0" updateauthor="kchristidis" updated="2019-02-24 18:17:06.0"> <body><! CDATA  ~suryalnvs : The fix in FAB-14274 was just merged. It should be part of tonight's build.  Let's kick off a test early tomorrow morning to confirm that we're good, and let's update the test task with the results.  ></body> </Action>
<Action id="57542" issue="37741" author="guoger" type="comment" created="2019-02-25 13:56:03.0" updateauthor="guoger" updated="2019-02-25 13:56:03.0"> <body><! CDATA If we kick-off a long running test with chaos-kube, is it possible to have some variations based on following 2 parameters: - random kill interval (say (0-10  min) - number of nodes to kill (1, 49%, 100%)  ></body> </Action>
<Action id="57543" issue="37741" author="kchristidis" type="comment" created="2019-02-25 14:01:09.0" updateauthor="kchristidis" updated="2019-02-25 14:01:09.0"> <body><! CDATA  ~suryalnvs  confirms that we're now good with the original variation of the test.  Keeping this open so that we can try some of the variations that Jay suggested above.  ></body> </Action>
<Action id="57620" issue="37741" author="suryalnvs" type="comment" created="2019-02-26 22:00:14.0" updateauthor="suryalnvs" updated="2019-02-26 22:00:14.0"> <body><! CDATA Started a new run for 12 hours with the following: * Batch size as 10 * 10 channels in the network * sending constant mode traffic with PTE on all channels * Initiated separate chaos-kube jobs for each orderer, group of two orderers, and for all three orderers using the following:  {code:java} helm install --kubeconfig=kubeconfig.regression  --set labels='k8s-app=orderer1st-ordererorg',namespaces='default',dryRun=false,rbac.create=true,interval=10m,minimumAge=4m --name chaos-orderer1st stable/chaoskube  helm install --kubeconfig=kubeconfig.regression  --set labels='k8s-app=orderer2nd-ordererorg',namespaces='default',dryRun=false,rbac.create=true,interval=10m,minimumAge=4m --name chaos-orderer2nd stable/chaoskube  helm install --kubeconfig=kubeconfig.regression  --set labels='k8s-app=orderer3rd-ordererorg',namespaces='default',dryRun=false,rbac.create=true,interval=10m,minimumAge=4m --name chaos-orderer3rd stable/chaoskube  helm install --kubeconfig=kubeconfig.regression  --set labels='k8s-app=orderer1st-ordererorg\,orderer2nd-ordererorg',namespaces='default',dryRun=false,rbac.create=true,interval=4m,minimumAge=3m --name chaos-orderer1st-orderer2nd stable/chaoskube  helm install --kubeconfig=kubeconfig.regression  --set labels='k8s-app=orderer1st-ordererorg\,orderer3rd-ordererorg',namespaces='default',dryRun=false,rbac.create=true,interval=4m,minimumAge=3m --name chaos-orderer1st-orderer3rd stable/chaoskube  helm install --kubeconfig=kubeconfig.regression  --set labels='k8s-app=orderer2nd-ordererorg\,orderer3rd-ordererorg',namespaces='default',dryRun=false,rbac.create=true,interval=4m,minimumAge=3m --name chaos-orderer2nd-orderer3rd stable/chaoskube  helm install --kubeconfig=kubeconfig.regression  --set labels='type=orderer',namespaces='default',dryRun=false,rbac.create=true,interval=2m,minimumAge=4m --name chaos-orderer stable/chaoskube  {code}    ></body> </Action>
<Action id="57645" issue="37741" author="suryalnvs" type="comment" body="Run for 12 hours was failed because of memory pressure on the orderer pods and worker nodes. I will increase the worker nodes to have more memory and will relaunch the test." created="2019-02-27 14:37:09.0" updateauthor="suryalnvs" updated="2019-02-27 14:37:09.0"/>
<Action id="57656" issue="37741" author="suryalnvs" type="comment" body="Restarted the test to run for 12 hours by adding 2 more worker nodes." created="2019-02-27 16:10:31.0" updateauthor="suryalnvs" updated="2019-02-27 16:10:45.0"/>
