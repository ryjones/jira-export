<Issue id="43760" key="FAB-17283" number="17283" project="10002" reporter="guoger" assignee="guoger" creator="guoger" type="10002" summary="Force follower to sync if its wal data is corrupte" priority="3" resolution="10001" status="6" created="2019-12-18 03:05:44.0" updated="2021-04-18 15:49:26.0" resolutiondate="2021-04-18 15:49:26.0" votes="0" watches="2" workflowId="57612"> <description><! CDATA Sometimes, wal data of a Raft node could be corrupt, in which case node would panic with: {code}  35m2019-12-10 13:06:22.537 UTC  orderer.consensus.etcdraft  commitTo -> PANI 020 0m tocommit(8) is out of range  lastIndex(3) . Was the raft log corrupted, truncated, or lost? channel=ordererchannel node=3 panic: tocommit(8) is out of range  lastIndex(3) . Was the raft log corrupted, truncated, or lost?  goroutine 38  running : github.com/hyperledger/fabric/vendor/go.uber.org/zap/zapcore.(*CheckedEntry).Write(0xc0001773f0, 0x0, 0x0, 0x0) 	/opt/gopath/src/github.com/hyperledger/fabric/vendor/go.uber.org/zap/zapcore/entry.go:229 +0x515 github.com/hyperledger/fabric/vendor/go.uber.org/zap.(*SugaredLogger).log(0xc00000e0f8, 0x4, 0x105c6a2, 0x5d, 0xc0003a9800, 0x2, 0x2, 0x0, 0x0, 0x0) 	/opt/gopath/src/github.com/hyperledger/fabric/vendor/go.uber.org/zap/sugar.go:234 +0xf6 github.com/hyperledger/fabric/vendor/go.uber.org/zap.(*SugaredLogger).Panicf(0xc00000e0f8, 0x105c6a2, 0x5d, 0xc0003a9800, 0x2, 0x2) 	/opt/gopath/src/github.com/hyperledger/fabric/vendor/go.uber.org/zap/sugar.go:159 +0x79 github.com/hyperledger/fabric/common/flogging.(*FabricLogger).Panicf(0xc00000e100, 0x105c6a2, 0x5d, 0xc0003a9800, 0x2, 0x2) 	/opt/gopath/src/github.com/hyperledger/fabric/common/flogging/zap.go:74 +0x60 github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft.(*raftLog).commitTo(0xc00014dab0, 0x8) 	/opt/gopath/src/github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft/log.go:203 +0x14d github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft.(*raft).handleHeartbeat(0xc0002ac140, 0x8, 0x3, 0x2, 0x5, 0x0, 0x0, 0x0, 0x0, 0x0, ...) 	/opt/gopath/src/github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft/raft.go:1324 +0x54 github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft.stepFollower(0xc0002ac140, 0x8, 0x3, 0x2, 0x5, 0x0, 0x0, 0x0, 0x0, 0x0, ...) 	/opt/gopath/src/github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft/raft.go:1269 +0x450 github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft.(*raft).Step(0xc0002ac140, 0x8, 0x3, 0x2, 0x5, 0x0, 0x0, 0x0, 0x0, 0x0, ...) 	/opt/gopath/src/github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft/raft.go:971 +0x12db github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft.(*node).run(0xc0002200c0, 0xc0002ac140) 	/opt/gopath/src/github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft/node.go:357 +0x1101 created by github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft.RestartNode 	/opt/gopath/src/github.com/hyperledger/fabric/vendor/go.etcd.io/etcd/raft/node.go:246 +0x31b {code}   We currently have two options here: - remove node from consenter set and readd (correct solution) - kill current leader, and the new leader has a fresh cache of follower's commit index, and effectively giving them a chance to catch up (violating safety property of Raft protocol)  Both of them are somewhat cumbersome. It would be nice to force follower to catch up instead of panic, even if some manual data transferring is needed  ></description> </Issue>
