<Action id="56003" issue="37041" author="sykesm" type="comment" created="2019-01-22 14:44:30.0" updateauthor="sykesm" updated="2019-01-22 14:44:30.0"> <body><! CDATA This issue persisted after bumping some limits and increasing the memory of the VM from 4G to 6G.  /cc  ~kchristidis ,  ~mastersingh24   ></body> </Action>
<Action id="56005" issue="37041" author="sykesm" type="comment" created="2019-01-22 14:45:49.0" updateauthor="sykesm" updated="2019-01-22 14:45:49.0"> <body><! CDATA kern.log: {code} Jan 21 16:12:11 vagrant kernel:  131564.302127  chaincode.test invoked oom-killer: gfp_mask=0x24201ca, order=0, oom_score_adj=0 Jan 21 16:12:11 vagrant kernel:  131564.302131  chaincode.test cpuset=/ mems_allowed=0 Jan 21 16:12:11 vagrant kernel:  131564.302137  CPU: 0 PID: 15660 Comm: chaincode.test Tainted: G           OE   4.4.0-131-generic #157-Ubuntu Jan 21 16:12:11 vagrant kernel:  131564.302139  Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006 Jan 21 16:12:11 vagrant kernel:  131564.302141   0000000000000286 a4e4dd439a8e380d ffff8800da1239e8 ffffffff81401c43 Jan 21 16:12:11 vagrant kernel:  131564.302144   ffff8800da123ba0 ffff8800da680e00 ffff8800da123a58 ffffffff81211a1e Jan 21 16:12:11 vagrant kernel:  131564.302147   ffffffff81cda777 0000000000000000 ffffffff81e6c1e0 0000000000000206 Jan 21 16:12:11 vagrant kernel:  131564.302150  Call Trace: Jan 21 16:12:11 vagrant kernel:  131564.302158    <ffffffff81401c43>  dump_stack+0x63/0x90 Jan 21 16:12:11 vagrant kernel:  131564.302163    <ffffffff81211a1e>  dump_header+0x5a/0x1c5 Jan 21 16:12:11 vagrant kernel:  131564.302167    <ffffffff81197dd2>  oom_kill_process+0x202/0x3c0 Jan 21 16:12:11 vagrant kernel:  131564.302170    <ffffffff811981f9>  out_of_memory+0x219/0x460 Jan 21 16:12:11 vagrant kernel:  131564.302174    <ffffffff8119e245>  __alloc_pages_slowpath.constprop.88+0x965/0xb00 Jan 21 16:12:11 vagrant kernel:  131564.302177    <ffffffff8119e668>  __alloc_pages_nodemask+0x288/0x2a0 Jan 21 16:12:11 vagrant kernel:  131564.302181    <ffffffff811e841c>  alloc_pages_current+0x8c/0x110 Jan 21 16:12:11 vagrant kernel:  131564.302183    <ffffffff8119429b>  __page_cache_alloc+0xab/0xc0 Jan 21 16:12:11 vagrant kernel:  131564.302186    <ffffffff81196840>  filemap_fault+0x160/0x440 Jan 21 16:12:11 vagrant kernel:  131564.302189    <ffffffff812a9e86>  ext4_filemap_fault+0x36/0x50 Jan 21 16:12:11 vagrant kernel:  131564.302192    <ffffffff811c3697>  __do_fault+0x77/0x110 Jan 21 16:12:11 vagrant kernel:  131564.302195    <ffffffff811c7485>  handle_mm_fault+0xfa5/0x1850 Jan 21 16:12:11 vagrant kernel:  131564.302199    <ffffffff810ced71>  ? __raw_callee_save___pv_queued_spin_unlock+0x11/0x20 Jan 21 16:12:11 vagrant kernel:  131564.302203    <ffffffff810ad686>  ? finish_task_switch+0x76/0x230 Jan 21 16:12:11 vagrant kernel:  131564.302207    <ffffffff8106d8a1>  __do_page_fault+0x1a1/0x410 Jan 21 16:12:11 vagrant kernel:  131564.302210    <ffffffff8106db32>  do_page_fault+0x22/0x30 Jan 21 16:12:11 vagrant kernel:  131564.302214    <ffffffff81855c58>  page_fault+0x28/0x30 Jan 21 16:12:11 vagrant kernel:  131564.302216  Mem-Info: Jan 21 16:12:11 vagrant kernel:  131564.302221  active_anon:945470 inactive_anon:21853 isolated_anon:0 Jan 21 16:12:11 vagrant kernel:  131564.302221   active_file:40 inactive_file:18 isolated_file:0 Jan 21 16:12:11 vagrant kernel:  131564.302221   unevictable:913 dirty:0 writeback:0 unstable:0 Jan 21 16:12:11 vagrant kernel:  131564.302221   slab_reclaimable:5689 slab_unreclaimable:5241 Jan 21 16:12:11 vagrant kernel:  131564.302221   mapped:980 shmem:3323 pagetables:4116 bounce:0 Jan 21 16:12:11 vagrant kernel:  131564.302221   free:21718 free_pcp:30 free_cma:0 Jan 21 16:12:11 vagrant kernel:  131564.302225  Node 0 DMA free:15904kB min:264kB low:328kB high:396kB active_anon:0kB inactive_anon:0kB active_file:0kB inactive_file:0kB unevictable:0kB isolated(anon):0kB isolated(file):0kB present:15992kB managed:15904kB mlocked:0kB dirty:0kB writeback:0kB mapped:0kB shmem:0kB slab_reclaimable:0kB slab_unreclaimable:0kB kernel_stack:0kB pagetables:0kB unstable:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB writeback_tmp:0kB pages_scanned:0 all_unreclaimable? yes Jan 21 16:12:11 vagrant kernel:  131564.302231  lowmem_reserve  : 0 3489 3935 3935 3935 Jan 21 16:12:11 vagrant kernel:  131564.302235  Node 0 DMA32 free:61320kB min:59612kB low:74512kB high:89416kB active_anon:3362948kB inactive_anon:77068kB active_file:124kB inactive_file:40kB unevictable:3652kB isolated(anon):0kB isolated(file):0kB present:3653568kB managed:3572772kB mlocked:3652kB dirty:0kB writeback:0kB mapped:3920kB shmem:12224kB slab_reclaimable:20524kB slab_unreclaimable:17600kB kernel_stack:3552kB pagetables:14664kB unstable:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB writeback_tmp:0kB pages_scanned:5104 all_unreclaimable? yes Jan 21 16:12:11 vagrant kernel:  131564.302241  lowmem_reserve  : 0 0 446 446 446 Jan 21 16:12:11 vagrant kernel:  131564.302245  Node 0 Normal free:9648kB min:7700kB low:9624kB high:11548kB active_anon:418932kB inactive_anon:10344kB active_file:36kB inactive_file:32kB unevictable:0kB isolated(anon):0kB isolated(file):0kB present:524288kB managed:457676kB mlocked:0kB dirty:0kB writeback:0kB mapped:0kB shmem:1068kB slab_reclaimable:2232kB slab_unreclaimable:3364kB kernel_stack:544kB pagetables:1800kB unstable:0kB bounce:0kB free_pcp:120kB local_pcp:120kB free_cma:0kB writeback_tmp:0kB pages_scanned:260 all_unreclaimable? no Jan 21 16:12:11 vagrant kernel:  131564.302251  lowmem_reserve  : 0 0 0 0 0 Jan 21 16:12:11 vagrant kernel:  131564.302254  Node 0 DMA: 0*4kB 0*8kB 0*16kB 1*32kB (U) 2*64kB (U) 1*128kB (U) 1*256kB (U) 0*512kB 1*1024kB (U) 1*2048kB (M) 3*4096kB (M) = 15904kB Jan 21 16:12:11 vagrant kernel:  131564.302267  Node 0 DMA32: 482*4kB (UME) 761*8kB (UME) 477*16kB (UME) 242*32kB (UME) 211*64kB (UME) 100*128kB (UME) 46*256kB (UME) 0*512kB 0*1024kB 0*2048kB 0*4096kB = 61472kB Jan 21 16:12:11 vagrant kernel:  131564.302279  Node 0 Normal: 82*4kB (UEH) 91*8kB (UMEH) 46*16kB (UEH) 42*32kB (UMEH) 28*64kB (UMEH) 23*128kB (UMEH) 7*256kB (UMEH) 0*512kB 0*1024kB 0*2048kB 0*4096kB = 9664kB Jan 21 16:12:11 vagrant kernel:  131564.302293  Node 0 hugepages_total=0 hugepages_free=0 hugepages_surp=0 hugepages_size=2048kB Jan 21 16:12:11 vagrant kernel:  131564.302294  3957 total pagecache pages Jan 21 16:12:11 vagrant kernel:  131564.302296  0 pages in swap cache Jan 21 16:12:11 vagrant kernel:  131564.302298  Swap cache stats: add 977699, delete 977699, find 159280/215098 Jan 21 16:12:11 vagrant kernel:  131564.302299  Free swap  = 0kB Jan 21 16:12:11 vagrant kernel:  131564.302300  Total swap = 0kB Jan 21 16:12:11 vagrant kernel:  131564.302301  1048462 pages RAM Jan 21 16:12:11 vagrant kernel:  131564.302303  0 pages HighMem/MovableOnly Jan 21 16:12:11 vagrant kernel:  131564.302304  36874 pages reserved Jan 21 16:12:11 vagrant kernel:  131564.302305  0 pages cma reserved Jan 21 16:12:11 vagrant kernel:  131564.302306  0 pages hwpoisoned {code}  ></body> </Action>
<Action id="56170" issue="37041" author="sykesm" type="comment" created="2019-01-24 17:03:40.0" updateauthor="sykesm" updated="2019-01-24 17:03:40.0"> <body><! CDATA Memory profiling implies this is due to a high number of calls to operations on the Deliver mock. Because each invocation to the mock gets recorded, all of the buffers envelopes and responses get held in memory.  The tests do not use use the recorded invocations for any assertions so I was able to comment out the recording and the tests seemed to pass.  ></body> </Action>
<Action id="56186" issue="37041" author="sykesm" type="comment" body="https://gerrit.hyperledger.org/r/28950" created="2019-01-24 21:00:38.0" updateauthor="sykesm" updated="2019-01-24 21:00:38.0"/>
<Action id="56189" issue="37041" author="sykesm" type="comment" body="With this change applied, I&apos;m able to successfully build and test fabric in a VM with 2G of memory." created="2019-01-24 22:06:18.0" updateauthor="sykesm" updated="2019-01-24 22:06:18.0"/>
