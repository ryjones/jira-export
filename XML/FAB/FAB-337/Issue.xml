<Issue id="12638" key="FAB-337" number="337" project="10002" reporter="scottz" creator="scottz" type="10004" summary="transactions processed more than once, after stop and start peers 2,1,0,2,1,0 sequentially in decreasing order twice" priority="3" resolution="10000" status="6" created="2016-09-09 20:50:53.0" updated="2018-07-20 14:10:09.0" resolutiondate="2017-04-07 20:06:12.0" votes="0" watches="1" workflowId="36195"> <description><! CDATA Problem Summary  This issue is a port to Jira from GitHub hyperledger fabric issue #2376 https://github.com/hyperledger-archives/fabric/issues/2376   The problem was originally found in master image 346f9fb, as well as v0.5 image 3e0e80a, in July. Sometimes transactions are processed more than once, after stopping and starting peers 2,1,0,2,1,0 sequentially in decreasing order twice. In the attached logs with a vagrant env with 4 peers in docker containers, the problem can be seen after the 2nd cycle, after peer0 is stopped the 2nd time. I collected debug logs; hopefully someone can determine which peer(s) submitted duplicate transactions. Blocksize is 2. This and other parameters are captured in the attached script output file GO_TEST__CAT_03_SnIQRnIQ_cycleDown.go__Aug092016  The entire zipfile including logs is attached to the github issue: https://github.com/hyperledger-archives/fabric/files/409933/dupTx_v05_3e0e80a.tar.gz.  (Note that testcase has since been renamed in the currently maintained test suite as CAT_111_SnIQRnIQ_cycleDownLoop.go.)  In this scenario, some transactions are processed more than once. The test script counts the transactions it sends, and the values for A & B are affected more than they should be. The duplicated processing of some invokes transactions (which I had sent only once into the network) occurs after stopping and then restarting peer 1 and then peer 0. After that, the value of B is higher than it should be.   How To Reproduce  Refer to attached stdout file for full details. The test executes the following. Between each step, we sleep several seconds (between 30 and 60, usually) and send 100 invokes and query each running peer.  Stop Peer 2 Start Peer 2 Stop Peer 1 Start Peer 1 Stop Peer 0 Start Peer 0 Stop Peer 2 Start Peer 2 Stop Peer 1 Start Peer 1 Stop Peer 0  Note: before stopping peer 0, we see these query results:  PASSED QUERY TEST: Expected A/B (997996/1002004) MATCHED on enough/appropriate Peers. ACTUALs (node:A/B): 0:997996/1002004 1:998059/1001941 2:997996/1002004 3:997996/1002004 PASSED CHAIN HEIGHT TEST: matches on enough/appropriate Peers. Expected CH (1021). Actual CHs: PEER0(1019) PEER1(986) PEER2(1019) PEER3(1019)  After stopping peer 0, and sending another 100 invoke requests, observe that the value of B (in all consensus peers) is greater than the expected value by 32! And the chainheight also is much higher than expected; instead of being 2 less than the expected value, the CH is 14 higher (a difference of +16). Clearly, some transactions were processed multiple times.  POST/Chaincode: QUERY all running peers for a and b, and chainheight STEP 3, cycle 2/2 after STOP PEER 0 and Invokes FAILED QUERY TEST: the required peers do NOT match!!!!!!!!!! EXPECTED A/B: 997896 1002104. ACTUALs: PEER 1 997864 1002136 PEER 2 997864 1002136 PEER 3 997864 1002136 PASSED CHAIN HEIGHT TEST: matches on enough/appropriate Peers. Expected CH (1072). Actual CHs: PEER1(1086) PEER2(1086) PEER3(1086)   ></description> </Issue>
