<Action id="37039" issue="25710" author="ales" type="comment" body="+1" created="2017-12-13 10:22:40.0" updateauthor="ales" updated="2017-12-13 10:22:40.0"/>
<Action id="37054" issue="25710" author="jyellick" type="comment" created="2017-12-13 14:35:06.0" updateauthor="jyellick" updated="2017-12-13 15:57:29.0"> <body><! CDATA {quote}_Duplicating the same information in the resource tree and LSCC adds complexity that may lead to security bugs if the synchronization is not done properly or does not happen in an atomic fashion,_ {quote} Although I initially accepted the amendment at the tail of FAB-7114, I have to agree with the above, the duplication is ugly and seem like a problem. If we were to remove the 'defaults' requirement from FAB-7114, I believe this problem would be solved. So, I see the following as the two competing proposals. ---- Possibility 1: Implement FAB-7114 without the 'defaults', where chaincodes are always defined in the resource tree, where the source of truth for the chaincodes in a channel is always the resource tree, and any information left in the LSCC table is an implementation detail.  Pros: * The peer code is already 90% present and largely merged. * There is a consistent workflow for multi-signature between channel config and resources (chaincode) config. * More flexibility exists for more novel permissions schemes. * The split between 'definition' and initial invocation is actually nice for building things like DB indices, containers, or other resources which must exist before invocation. * For applications which already handle the multi-sig workflows, there is little work to be done.  Cons: * The API change is more radical – SDKs have more work to do, users which do not understand channel config have more to learn. * Out of band signature collection can be perceived as problematic. * It's possible for a chaincode to be 'defined' but {{Init}} has not yet been called.  ---- Possibility 2: Implement the proposal described in this issue's description:  Pros: * The API stays largely similar for existing SDKs and applications. * The interface does not require out of band signature collection. * Possible that multi-tx commit is a pattern we want elsewhere. * For applications which do not handle multi-sig workflows, there is little work to be done.  Cons: * Complicates the already hacky lifecycle endorser code flow. * The code is not complete, and it's possible the implementation will be more challenging than expected. * Aggregation of signatures can either be done in the endorsement phase, which makes validation extremely difficult (as endorsements over LSCC are meaningless and must be validated via psuedo-simulation); or aggregation of signatures is done at commit time which requires treating instantiation transactions specially with custom commit logic which violates the standard endorser tx tenants.  ---- I write the above trying to be as impartial as possible in the hope that we can come to some sort of consensus quickly.  ></body> </Action>
<Action id="37058" issue="25710" author="yacovm" type="comment" created="2017-12-13 15:30:59.0" updateauthor="yacovm" updated="2017-12-13 15:56:07.0"> <body><! CDATA  ~jyellick   {quote} * Possible that multi-tx commit is a pattern we want elsewhere.{quote} I don't see how we can generalize this. Can you explain?  {quote} * Complicates the already hacky lifecycle endorser code flow. In particular, it requires commit logic which does not simply apply the RW set, but mutates it.{quote} Changing write sets in validation seems to me like a hacky and bug-prone idea, and also it breaks the idea that the ledger can be used for auditing and the stateDB contains only RWSets computed from the public ledger (unless if it's private data) Can't the peer calculate the needed data structure induced by the RWSets without having to apply it?  What if the LSCC RWSet would contain (for all deploy transactions *but the last one*): * *Key*: "client identity",  *Value*: signature of the client who's identity is the key, on the endorsement policy value   And for the last deploy transaction: * *Key*: "endorsementPolicy", *Value*: the endorsement policy * *Key*: "client identity",  *Value*: signature of the client who's identity is the key, on the endorsement policy value     Now, LSCC would have a validation rule that you can write to the key "endorsementPolicy" only if there are enough "supporting" signatures from clients that the combined set satisfies the deployment policy.  And, a rule that says that you can't write to a key "client identity" without a signature from yourself (and the replay should be taken care via MVCC)     Now, if we have 2 concurrent *sets of transactions* of administrators, assuming both sets contain enough and valid signatures for the deploy policy to be fulfilled, then only 1 would win in the end because of MVCC conflicts on the "*endorsementPolicy*" key.    * The out-of-band process would be that 1 administrator initiates the deploy (last) and the other also do the deploy, but they use a flag that doesn't write to the *endorsementPolicy* key. * At peer startup, it would look at LSCC and use the "endorsementPolicy" given enough signatures are found.     This way we don't need the validation code to mutate the RWSet.   ~angelo.decaro  - this isn't clear to me from the google doc or from the JIRA so I'll ask here for clarification: In the validation of the LSCC transaction - the identity/signature that is validated is that of the client(s), right?   ></body> </Action>
<Action id="37060" issue="25710" author="angelo.decaro" type="comment" body=" ~yacovm , I also agree that we should not mutate the RWSet. Sorry if the text mislead you." created="2017-12-13 16:03:12.0" updateauthor="angelo.decaro" updated="2017-12-13 16:03:12.0"/>
<Action id="37061" issue="25710" author="yacovm" type="comment" created="2017-12-13 16:06:11.0" updateauthor="yacovm" updated="2017-12-13 16:06:11.0"> <body><! CDATA {quote}Yacov Manevich, I also agree that we should not mutate the RWSet. Sorry if the text mislead you.{quote}  Then can you please elaborate how precisely this is going to be done, and also update the JIRA with this? because this is a very important detail..   ></body> </Action>
<Action id="37062" issue="25710" author="jyellick" type="comment" created="2017-12-13 16:14:09.0" updateauthor="jyellick" updated="2017-12-13 16:25:18.0"> <body><! CDATA  ~yacovm  {quote}> * Possible that multi-tx commit is a pattern we want elsewhere. I don't see how we can generalize this. Can you explain? {quote} The idea that different parties could each submit their own version of a transaction, and once sufficiently many commit, the transaction actually commits has some potential other applications. Say, a joint asset which has two owners, and each owner must submit a proposal to transfer it before it is transferred. This is a common concept in other systems like Ethereum.  The exact details of how this would be generalized, I'm not sure.  I just mean that as a concept, this has other applications, so we might not be introducing a new lifecycle specific but otherwise useless concept. {quote}Changing write sets in validation seems to me like a hacky and bug-prone idea, and also it breaks the idea that the ledger can be used for auditing and the stateDB contains only RWSets computed from the public ledger (unless if it's private data) Can't the peer calculate the needed data structure induced by the RWSets without having to apply it? {quote} {quote}This way we don't need the validation code to mutate the RWSet. {quote} There are two different possibilities I see. # The peer does custom mutation of the RW sets during the commit (not validation, as this is parallel) phase. This has the disadvantage of making the LSCC endorser transaction not commit as a standard endorser transaction, but it has the advantage of being fairly straightforward to implement in an obviously correct way. # The peer does sophisticated LSCC mutations during the endorsement phase. This has the advantage of committing in a standard way, but then the validation becomes extremely complex and difficult to implement, maintain, and audit for security.  For v1.0, we went with the second option, but the validation logic was (relatively) simple (checking that only the chaincode in question was the thing modified in the LSCC space). If there is aggregation of different competing instantiation proposals, this logic would be much more complex. In the proposal above for instance, there is no cleanup of pending proposals which did not successfully commit, nor of the ones which are successfully committing.  I'm not suggesting that it is impossible, but, one of the core problems with doing LSCC as an endorser transaction, is that endorser transactions are validated based on endorsement policy. Because the LSCC itself does not have an endorsement policy (and in fact, it cannot, if we wish to allow arbitrary endorsement policies for chaincodes) the endorsements over the LSCC data mean nothing. This means any mutations to the LSCC state space must be verified manually in the VSCC code. If we were starting from scratch, I would say this is a deal breaker, but as this is the existing approach, I understand the appeal in extending it.  ></body> </Action>
<Action id="37074" issue="25710" author="jyellick" type="comment" created="2017-12-13 22:09:29.0" updateauthor="jyellick" updated="2017-12-13 22:09:29.0"> <body><! CDATA The more I scrutinize this proposal in FAB-7444, the more I believe that LSCC should not have been implemented as an endorser transaction, and further, that it is a mistake to attempt to extend this mechanism.  Endorser transactions have an intent (proposal), a result of that proposal (RW set), and proof that the result is correct for the intent (endorsements). The peer validates that the result (RW set) of the intent (proposal) is accurate by evaluating the proof (endorsements) against the endorsement policy. LSCC does not and cannot have an endorsement policy, so it does not validate as an endorser transaction. Instead, there is a custom validation path, not shared by any other chaincodes, which attempts to in effect, re-execute a portion of the LSCC invocation and confirm that the result of the simulation is the same as the result in the transaction. The endorsements have no value. Treating LSCC transactions as endorser transactions is inconsistent, error prone, and I do not believe it would pass scrutiny if it were a new concept in the system.  At the very least, LSCC validation should have been performed by a different VSCC. And, if the validation mechanism is to re-execute the proposal, then there is zero value in including the output in the tx; the committing peer should simply execute it at commit time. Once these are taken into account, we are left back with something very much like the original resources based proposal, and I would ask why we are re-inventing the wheel? If we want to provide a non-out-of-band signature collection mechanism, this is something that could be trivially implemented in a user-space chaincode.  ></body> </Action>
<Action id="37077" issue="25710" author="yacovm" type="comment" created="2017-12-13 22:51:14.0" updateauthor="yacovm" updated="2017-12-14 09:27:21.0"> <body><! CDATA  ~jyellick  I 100% agree with you on:  {quote}Endorser transactions have an intent (proposal), a result of that proposal (RW set), and proof that the result is correct for the intent (endorsements). The peer validates that the result (RW set) of the intent (proposal) is accurate by evaluating the proof (endorsements) against the endorsement policy. LSCC does not and cannot have an endorsement policy, so it does not validate as an endorser transaction. Instead, there is a custom validation path, not shared by any other chaincodes, which attempts to in effect, re-execute a portion of the LSCC invocation and confirm that the result of the simulation is the same as the result in the transaction. The endorsements have no value. Treating LSCC transactions as endorser transactions is inconsistent, error prone, and I do not believe it would pass scrutiny if it were a new concept in the system.  And, if the validation mechanism is to re-execute the proposal, then there is zero value in including the output in the tx; the committing peer should simply execute it at commit time. {quote}  However - I believe this proposal is trying to re-invent the wheel because the current config-based lifecycle approach lacks a signature collection mechanism and therefore has (in my opinion) a severe deficiency.   So - given that the config based approach is already more or less finished and implemented, I suggest we go the extra mile and include in the v1.1 release: * A chaincode that collects signatures for the resource config updates, and channel config updates * Integrate the peer CLI and SDKs to work with that natively, to reduce as much as possible the learning curve of moving from v1.0 to v1.1  Now,  ~jyellick  - I think that signature collection chaincode should be included in fabric and will not be a deployed user-level chaincode but be a system chaincode. In fact - I think that it can even be LSCC itself.  The resource config could come with it being defined at channel creation, and users would be able to invoke LSCC to manage signature collection and then the resource config update would be composed from signatures taken from the LSCC via querying.   What do you (and others) think?  ></body> </Action>
<Action id="37091" issue="25710" author="denyeart" type="comment" created="2017-12-14 14:06:15.0" updateauthor="denyeart" updated="2017-12-14 14:06:15.0"> <body><! CDATA I completely agree with the core motivation of this proposal:  _Duplicating the same information in the resource tree and LSCC adds complexity that may lead to security bugs if the synchronization is not done properly or does not happen in an atomic fashion,_  I also completely agree with the Pros of this proposal that  ~jyellick  called out in the first comments:      •    The API stays largely similar for existing SDKs and applications.     •    The interface does not require out of band signature collection.     •    Possible that multi-tx commit is a pattern we want elsewhere.     •    For applications which do not handle multi-sig workflows, there is little work to be done.  And I’ll especially highlight the 3rd bullet in that going forward I think it will be important to support multi-sig workflows consistently across chaincode deployment and chaincode execution, and I prefer the 'internal' tally collection approach here over 'external' signature collection approaches (whether out-of-band as Jason suggests or via additional chaincodes as Yacov suggests).   On to the cons… I appreciate the concerns that Jason calls out in his latest comments, but in my opinion those are internal details that we could live with, rather than critical aspects for external consumers.  I would have to give priority to the external consumer aspects.  And like Jason said, a separate VSCC could be used for LSCC to make the internals more tolerable.  Additionally, there are some good things about the endorser flow, for example it does make sense for clients to specify an intent (to deploy chaincode), rather than having to know the internals of chaincode definition.  Finally, I would prefer a way to split definition and initial invocation as listed in the resource tree approach Pros:      •    The split between 'definition' and initial invocation is actually nice for building things like DB indices, containers, or other resources which must exist before invocation.  Potentially we could achieve this via LSCC, by having both a ‘Define’ step and an ‘Instantiate’ step in LSCC.  For scenarios where it makes sense to combine them, ‘Define and Instantiate’ could be called in a single transaction, and for scenarios where it makes sense to split them, ‘Define’ could be called before ‘Instantiate’, with each step needing to meet the signature requirements for deployment on the channel.  In sum, I generally am in favor of this proposal, but would like to hear feedback on the ideas here.  ></body> </Action>
<Action id="37103" issue="25710" author="manish-sethi" type="comment" created="2017-12-14 16:00:10.0" updateauthor="manish-sethi" updated="2017-12-14 16:00:10.0"> <body><! CDATA First, apologize for a lengthy note :-)  ~jyellick  - Though I agree with your definitions and hence difference between intent and endorsement but I have to disagree that this difference is limited to system transactions (e.g., chaincode lifecycle related transactions)  I am sure that you agree that this difference (and hence similar threats) would be present for the user chaincodes as well.   The larger issue that I feel here is that with the resource tree way of doing things, we are trying to treat the system transactions differently from user transactions in an attempt to make the system transactions 'more secure' than the data transactions of the user chaincode. However, even if someone is able to deploy a chaincode in a more secure manner, the data managed by a chaincode is still as trusted (or susceptible to maliciously mutate-able) as the richness of endorsement policies we allow for the user chaincodes.  As a business participant of a channel, my primary concern will ultimately be my business data. In other words, if we feel that endorsement policy mechanism is not enriched enough, making lifecycle step stronger does not make a convincing deal because, the business data is still managed by the endorsement policies.  The way I look at the resource tree transactions - it is equivalent to say that one executes transactions outside the Fabric and sign the final mutations and Fabric acts only as an information store for persisting the signed data and in addition, hosts a layer on top that evaluates data item level mutation policies.(which, in philosophy matches with a key value store that provides data modification policies at each cell level - e.g. a primitive example would be https://accumulo.apache.org/). However, this does not treat Fabric as a system to host the 'smart contract' logic that mutates the data.   Setting the context above, I would be inclined to actually treating the lifecycle transactions in a same way as if I would have written a business chaincode (and move away from the resource tree way of data manipulation) and try to workaround the shortcoming for the time being. This approach gives me more comfort mainly from the fact that this brings out the difference between intent and endorsement, the platform limitations and gaps around these and workarounds upfront that serves an example for user chaincodes.  Resource tree way of data manipulation is definitely not what any of us would want to serve as a reference for user chaincodes.  In fact, given a choice, I would like to get rid of entire resource tree stuff and manage the resource configuration by hosting the data manipulation logic on the peer (say a system chaincode) which exposes only high level admin functions such as define chaincode and does not offer the direct data manipulation.Philosophically, this is similar to way an rdbms would use the same data storage and transaction processing engine for the system data in the form of system tables.  On the specifics:  Multi-sigs ----------- I like enabling the multi-sig collection way described in the original proposal. At the implementation level, may be we can declare a first class transaction type  ENDORSER_MULTI_SIG  and treat it differently at the commit processing - such that instead of evaluating the read-set and applying it's write-set immediately, keep storing them in a channel scoped system chaincode (say multi-sig namespace).  We store the transaction envelope as the value and txid_\{creator} as it's key (txid to be computed based on chaincode name and arguments). Each time we process such transaction, we pull out previously stored transactions by performing a range query on txid and pass on the array to chaincode specific VSCC which either approves or response with insufficiency code - if Approved, we process the normal read-write set logic and delete the txid_\{creator} entries. This way, it could be used by a user chaincode also with the custom VSCC (by declaring the type ENDORSER_MULTI_SIG).  If we want to collect multi-sigs out of the band we can adopt one of the below listed approaches. (1) Signed intent + Generic endorsement (3 out of 5 etc.) LSCC takes an additional argument 'signatures' (which are collected out of band on the 'intent' - i.e. the function name + arguments)  and we have a channel scope LSCC endorsement policy at the time of channel creation. LSCC can always be treated a separate object on each channel.  (2) Signed intent + Specific endorsement  Same as the above, but endorsement is restricted to specific peer certificate - where at least one endorsing peer is present for each of the signatures in the intent In this case, we can allow content based enriched endorsement policies going forward, they can be applied out of the box.  (3) Signed RWSet Every one who should sign the intent, independently simulate the deploy transaction on LSCC on a peer they trust and signs the resulting rw-set  and pass around this for collecting the out of the band signatures. This requires a different transaction type though - (say MULTI_SIG - where  the tran envelop contains signatures and actual envelop)  (4) Signed intent and execute transaction at commit time Just submit the signed intent and transaction gets executed at commit time. Like (3), this also requires a different transaction type (say EXECUTE).  4th option is possible for system transactions because system chaincode is nothing but a the peer code and hence present on all the peers.  However, it goes fundamentally against the endorsement model if we advocate this for user chaincodes and indirectly goes back to 0.6 model of transaction execution (minus the final consensus on resulting changes)  Define step: ------------------- I prefer to have different steps 'Define' and 'Instantiate' as it gives system a chance to prepare chaincode related resources. But as Dave pointed out, both the steps can be well accommodated in the LSCC space.  ></body> </Action>
<Action id="37501" issue="25710" author="mastersingh24" type="comment" created="2017-12-15 11:31:48.0" updateauthor="mastersingh24" updated="2017-12-15 11:31:48.0"> <body><! CDATA {quote}In other words, if we feel that endorsement policy mechanism is not enriched enough, making lifecycle step stronger does not make a convincing deal because, the business data is still managed by the endorsement policies.{quote}   ~manish-sethi  - This is NOT what  ~jyellick  or I have been trying to say.  The problem is that endorsement policies do not satisfy the requirement that parties actually agreed to the contents of a transaction.  Put another way, endorsement policies are not signature-based agreement policies.  When a peer endorses a transaction, all it is saying is that for a set of given inputs, here are the outputs based on executing a piece of logic.  It's hard to word this all properly, so maybe an example will help.  Let's say that we have a simple chaincode which manages assets of type FOO.  Each asset of type FOO has a name and an owner where owner is represented by the bytes of the owner's public key: {code:java} type Foo { name string owner   byte } {code}  Let's say our chaincode has a function called transfer with the following pseudo-logic:   {code:java} func transfer(asset_name string, new_owner   bytes){ current_owner = getOwner(asset_name)  if TX_SIGNER = current_owner { setOwner(asset_name, new_owner) } else { return error("only the current owner can transfer an asset") } } {code}  The agreement to transfer the asset is represented by the fact the current_owner signed and submitted the transaction.  The chaincode is used to enforce this agreement.  Let's say there are 2 peers in the channel. So each peer executes this chaincode and then endorses the chaincode.  Each peer's signature only indicates the peer accepted the inputs, executed the logic and generated a set of outputs.  But, to restate, the agreement to transfer was indicated by the signature on the actual transaction itself.  I believe that we continue to conflate endorsement with actual signature-based agreements and that is always at the root of these discussions.   ~manish-sethi  - this is where the multi-sig stuff comes in.       ></body> </Action>
<Action id="37506" issue="25710" author="mastersingh24" type="comment" created="2017-12-15 13:25:14.0" updateauthor="mastersingh24" updated="2017-12-15 13:25:14.0"> <body><! CDATA {quote}*we are trying to treat the system transactions differently from user transactions in an attempt to make the system transactions 'more secure' than the data transactions of the user chaincode* {quote}  Again - NO.  This is not what we are trying to do.  What we are trying to do is figure out a way to ensure that actual HUMANS agree on the contents of very important policies and changes to those policies.  And as I attempted to outline in my comment above, endorsement does provide this.  ></body> </Action>
<Action id="37509" issue="25710" author="yacovm" type="comment" created="2017-12-15 14:03:28.0" updateauthor="yacovm" updated="2017-12-15 14:04:22.0"> <body><! CDATA  ~manish-sethi  I'm not sure why we need a multi-signature transaction to be a fabric first-class citizen.  All you want to do is transactions that have multiple users agreeing to the transactions but make them happen atomically, no? Can we not built this with standard chaincode without multi-signatures?     Here is an example that I believe works:  Lets say we have orgs A and B and Alice is from org A and Bob is from org B. Alice wants to give Bob her Apple in exchange for Bob's Banana.  Both peers in org A and org B have a chaincode that is written for these kinds of trades.  The chaincode's data model has a table for asset transfer in which each row has 4 columns: * Source Owner * Asset put for transfer * Target Owner * Commitment     Also, the chaincode logic dictates that every user in the channel can create a transaction that wipes out this asset transfer table, in case he/she feels she wants to abort the transaction. (for simplicity, there is only 1 such table, but of course we can have a table for each pair of users).  Now, Alice makes the first transaction, and generates a random string *x* and puts: * Alice * Apple * Bob * Hash( x )  Now Bob makes its own transaction, and puts: * Bob * Banana * Alice * Hash( x )  Now, Alice invokes a function in the chaincode that the function gets as input a string *x* and simply iterates over all rows of the asset transfer table, and for each row, checks if: Hash( x ) == Commitment  If so, then the asset is moved from the Source owner to the target owner.  * Alice, has no incentive to tell Bob the preimage of Hash( x ) until Bob puts its own commitment into the asset transfer table, so she waits until he puts it and only afterwards she reveals the pre-image to the chaincode. * If Alice is malicious and decides to remove her asset transfer and leave only Bob's - she can't because we said earlier that the chaincode logic dictates that you can only append new entries to the asset table, or delete everything, so Alice can't run away with Bob's Banana without giving him her Apple. * If we agree that we can enforce certain RWsets to be written into the blockchain via chaincode, then surely we agree this idea works, no?  ></body> </Action>
<Action id="37513" issue="25710" author="manish-sethi" type="comment" created="2017-12-15 15:24:16.0" updateauthor="manish-sethi" updated="2017-12-15 15:24:38.0"> <body><! CDATA  ~mastersingh24  - Yes, I understood the difference between parties agreement and endorsement and understand the need of multi-sig and signing by actual humans. The only argument I am making is that both the things are possible (and should be, if not) via endorser transaction way of accomplishing the things. For instance, taking human signature on chaincode parameters is one of the ways to get human signature on the content.  As you said, these things are not easy to write clearly and I am sure some of these things could not have been conveyed clearly in my post.  ></body> </Action>
<Action id="37531" issue="25710" author="mastersingh24" type="comment" created="2017-12-15 20:07:20.0" updateauthor="mastersingh24" updated="2017-12-15 20:07:34.0"> <body><! CDATA I agree that submitting a signatures as part of the payload is a valid mechanism.  We had actually discussed this a while back as well.  But no matter what, some type of information must be passed around out of band (unless you misuse blockchain as a database for passing messages around).  In the end, we seem to want to be very religious about using chaincode for everything.  I don't agree that this is the precedent that we want to set.  That being said, I think we can make things work and appease all concerns (whether practical or religious)  ></body> </Action>
