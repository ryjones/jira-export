<Action id="25900" issue="17704" author="kletkeman" type="comment" created="2017-06-09 18:32:36.0" updateauthor="kletkeman" updated="2017-06-09 18:32:36.0"> <body><! CDATA Note that this is not just an issue with simultaneous events being placed in the same block. It will also happen when events arrive on different peers in different global regions but on the same channel (where the asset resides). In this case, both will successfully execute on their regional endorsers, but using the same asset key versions, and both might even get into two separate blocks.  But that won't help, because the second one to be processed was still built on the older key versions and will fail.  ></body> </Action>
<Action id="26111" issue="17704" author="jimthematrix" type="comment" created="2017-06-13 04:44:38.0" updateauthor="jimthematrix" updated="2017-06-13 04:44:38.0"> <body><! CDATA hi  ~kletkeman  what you are describing, mvcc collisions, is the limitation of the current v1.0 design. There is nothing in the fabric that can be done to have much impact on improving the success rate under the conditions you are describing.   On the other hand, the key technique to maximize success rate is to use a unique key under the chaincode for writing data. At least rotate among a list of keys that would take about the same time to iterate as the transaction latency. For example, if the average transaction latency on a particular network is 2 seconds, and your peak submission rate is 2,000 concurrent transactions per second, then use at least 4,000 different keys to save the data such that by the time those keys are iterated through, the transactions will have been committed already.  I don't know of any other techniques that would improve the success rate under the v1.0 architecture. But maybe others  ~mastersingh24 ,  ~binhn  may have additional ideas.  Based on this understanding, I'm changing the issue from a Bug to an Improvement, and moved it to Future for consideration.  ></body> </Action>
<Action id="26142" issue="17704" author="kletkeman" type="comment" created="2017-06-13 13:35:20.0" updateauthor="kletkeman" updated="2017-06-13 13:35:20.0"> <body><! CDATA Hi Jim, thanks for responding. I'm not quite understanding how the use of a unique key would work. If we have a somewhat complex data model with relationships – let's posit and aircraft with a list of installed assemblies – then we would likely model the installed assemblies as a Java object with the keys being the assembly IDs. The assemblies themselves are stored with a class identifier (the only way to properly segregate both asset state and asset state history) and then the asset's ID. Any incoming event will be targeted specifically at that asset ID (e.g. aircraft tail number, to be propagated to installed assemblies if applicable – or some similar algorithm).  In this scenario, all asset references, either externally or internally, must contain the asset class (usually interpretable from context) and the asset ID (not interpretable from context, must be explicit).  If I then use a key *other* than **asset class + asset ID**, I am going to write to the asset state of that specific asset. Using a different key each time would allow me to write it out along with someone else writing it out as well, but with a different reading against the asset.   How would I tie these two versions of the current asset state together?  If I had 10 incoming events, how would I tie all 10 versions to the same asset? And how would I put them together when queried?  How would I build on them, since they are randomly scattered around world state?  Any index that I build under the hood almost certainly constitutes a common key once again, leading to the same rejection issue.  I feel as if I have somehow missed the point of the technique you are proposing. But I think it is more likely that there is no solution to this issue except for an intimately tied queued and extremely strict guidelines on chaincode behaviors and on incoming event cadencing.   Which means that IoT applications that were perfectly compatible with v0.6 are almost certainly not compatible at all with v1 fabrics.  What cadence of events against an asset was envisioned when this was designed?  ></body> </Action>
<Action id="40371" issue="17704" author="scottz" type="comment" created="2018-02-19 03:54:22.0" updateauthor="scottz" updated="2018-02-19 03:54:22.0"> <body><! CDATA Just browsing issues, but I wonder if I understand this correctly. I am pretty sure I do not fully understand your concerns and how they relate to Flow Control, but it does seem possible, depending on the constraints, that the chaincode design could be done in such a way to make this work more smoothly. Either: # write a chaincode transaction that uses one key (for the particular airplane, or a subsystem of the airplane, which has a large set of sensors) and updates all the items at once, or... # write a chaincode that uses individual keys for each sensor, so that changing the value of one sensor would not affect or prohibit transactions that change a different sensor which has its own unique key.  ></body> </Action>
<Action id="67052" issue="17704" author="sykesm" type="comment" body="Stale" created="2020-01-22 19:16:14.0" updateauthor="sykesm" updated="2020-01-22 19:16:14.0"/>
