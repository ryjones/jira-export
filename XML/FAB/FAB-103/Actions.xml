<Action id="39667" issue="12402" author="yacovm" type="comment" created="2018-02-05 14:43:05.0" updateauthor="yacovm" updated="2018-02-05 14:43:05.0"> <body><! CDATA I think this one is now important since we have couchDB support which uses reads over the network, and read-oriented endorsements (queries) can be faster if we have a cache and we don't need to go the the remote DB each time.  I guess what should be done is roughly: * A cache per channel * Invalidates specific keys of specific namespaces when the committer is instructed to write to them at commit time * Has a finite size and uses LRU eviction policy(?)  Can something also be done with versions? i.e, if we need the version of a key that is updated frequently (and hence invalidates the version number that is cached) - can we perhaps keep track of frequently changed key versions as well?   ~denyeart  ,  ~manish-sethi  ,  ~C0rWin   ~mastersingh24  opinions?  ></body> </Action>
<Action id="54531" issue="12402" author="denyeart" type="comment" created="2018-12-09 13:32:09.0" updateauthor="denyeart" updated="2018-12-09 13:32:09.0"> <body><! CDATA This work is proceeding, as the roundtrips to CouchDB has in fact proven to be a bottleneck.  See also related Jiras for more context.  ></body> </Action>
<Action id="59254" issue="12402" author="mhbauer" type="comment" body="Is this something I can help with? Is there a discussion or design somewhere to view and catch up on?  What measure is used to know that the changes are helping?" created="2019-04-15 19:18:29.0" updateauthor="mhbauer" updated="2019-04-15 19:18:29.0"/>
<Action id="59281" issue="12402" author="senthil1" type="comment" created="2019-04-16 17:09:39.0" updateauthor="senthil1" updated="2019-04-16 17:09:39.0"> <body><! CDATA  ~MHBauer    The current implementation has drawbacks. It could lead to out of memory error if there is a large number of channels in the peer. Hence, we are back to the whiteboard and designing a new caching library. We have been working on the design document ( https://docs.google.com/document/d/1Rxczkwni5oG6MBif1s0KN6_PR29tM4WP9IEOvbLMTu8/edit?usp=sharing ) We would complete the design by the end of this week and will send around for reviews.  _What measure is used to know that the changes are helping?_ As you might know, performance improvement due to a caching layer is heavily dependent on the read-write access pattern of the application. We can write a chaincode whose read would always hit the cache and also a chaincode whose read would always miss the cache. At least for the system namespace such as lscc, a simple caching layer such as this  https://gerrit.hyperledger.org/r/c/2828/|https://gerrit.hyperledger.org/r/c/28289//  improved the performance significantly (don't remember the numbers though). If chaincode read/write pattern is favorable for the cache, it will improve the performance as it reduces the number of disk IO and HTTP REST API calls (especially in the case of CouchDB).  ></body> </Action>
<Action id="59625" issue="12402" author="mhbauer" type="comment" created="2019-04-30 18:58:53.0" updateauthor="mhbauer" updated="2019-04-30 18:58:53.0"> <body><! CDATA  |https://jira.hyperledger.org/secure/ViewProfile.jspa?name=Senthil1   ~Senthil1   Design document looks comprehensive. Where is it reviewed? Where is it discussed?  " (don't remember the numbers though). " That's why I'm asking the question, if we don't have some consistent set of overall benchmarks or microbenchmarks over certain code segments, we can't know what's causing effects beyond large changes. Part of the work should be to establish at least some test to know what's going on over time.  ></body> </Action>
<Action id="59634" issue="12402" author="senthil1" type="comment" created="2019-05-01 04:22:43.0" updateauthor="senthil1" updated="2019-05-01 04:22:43.0"> <body><! CDATA  ~MHBauer  If you have any comments on the specific design aspect, please post your comments on the google doc itself using suggesting mode. If you would like to discuss on the high level approach, please post here.      Yes, like unit test, we would need to run performance benchmarks as CI jobs to know what's going on over time.  ~sykesm   ~denyeart  do you have any comments on benchmark CI jobs?  ></body> </Action>
