<Action id="30711" issue="20715" author="yacovm" type="comment" created="2017-09-11 07:00:08.0" updateauthor="yacovm" updated="2017-09-11 07:00:08.0"> <body><! CDATA {quote}Created docker-compose.yml Creating docker containers Pulling setup (hyperledger/fabric-ca-tools:latest)... Pulling repository docker.io/hyperledger/fabric-ca-tools ERROR: Error: image hyperledger/fabric-ca-tools:latest not found {quote}  ></body> </Action>
<Action id="30712" issue="20715" author="yacovm" type="comment" created="2017-09-11 07:22:38.0" updateauthor="yacovm" updated="2017-09-11 07:22:54.0"> <body><! CDATA When I run the e2e_cli I get these errors too: {code}2017-09-11 07:12:21.319 UTC  gossip/gossip  handleMessage -> WARN 3ba Message GossipMessage: tag:EMPTY alive_msg:<membership:<endpoint:"peer1.org1.example.com:7051" pki_id:"L\t2\256x\n\252\n\034\027wC\3468\336\236\031\223\022B^G%hX\324\207\325\350\177\271\345" > timestamp:<inc_num:1505113916294937712 seq_num:20 > > , Envelope: 83 bytes, Signature: 70 bytes isn't valid 2017-09-11 07:12:23.693 UTC  gossip/gossip  validateMsg -> WARN 45e StateInfo message GossipMessage: tag:CHAN_OR_ORG state_info:<metadata:"\000\000\000\000\000\000\000\002" timestamp:<inc_num:11651379494838206464 seq_num:1505113943180744558 > pki_id:"L\t2\256x\n\252\n\034\027wC\3468\336\236\031\223\022B^G%hX\324\207\325\350\177\271\345" channel_MAC:"\321'\021w>\341{\362\227\272\254\376\017\376=\326\3469\003\0340\260\277\006n\033\335\013+\322\022-" > , Envelope: 105 bytes, Signature: 71 bytes is found invalid: PKIID wasn't found 2017-09-11 07:12:23.693 UTC  gossip/gossip  handleMessage -> WARN 45f Message GossipMessage: tag:CHAN_OR_ORG state_info:<metadata:"\000\000\000\000\000\000\000\002" timestamp:<inc_num:11651379494838206464 seq_num:1505113943180744558 > pki_id:"L\t2\256x\n\252\n\034\027wC\3468\336\236\031\223\022B^G%hX\324\207\325\350\177\271\345" channel_MAC:"\321'\021w>\341{\362\227\272\254\376\017\376=\326\3469\003\0340\260\277\006n\033\335\013+\322\022-" > , Envelope: 105 bytes, Signature: 71 bytes isn't valid 2017-09-11 07:12:23.693 UTC  gossip/gossip  validateMsg -> WARN 460 StateInfo message GossipMessage: tag:CHAN_OR_ORG state_info:<metadata:"\000\000\000\000\000\000\000\002" timestamp:<inc_num:11651379494838206464 seq_num:1505113943180744558 > pki_id:"L\t2\256x\n\252\n\034\027wC\3468\336\236\031\223\022B^G%hX\324\207\325\350\177\271\345" channel_MAC:"\321'\021w>\341{\362\227\272\254\376\017\376=\326\3469\003\0340\260\277\006n\033\335\013+\322\022-" > , Envelope: 105 bytes, Signature: 71 bytes is found invalid: PKIID wasn't found 2017-09-11 07:12:23.693 UTC  gossip/gossip  handleMessage -> WARN 461 Message GossipMessage: tag:CHAN_OR_ORG state_info:<metadata:"\000\000\000\000\000\000\000\002" timestamp:<inc_num:11651379494838206464 seq_num:1505113943180744558 > pki_id:"L\t2\256x\n\252\n\034\027wC\3468\336\236\031\223\022B^G%hX\324\207\325\350\177\271\345" channel_MAC:"\321'\021w>\341{\362\227\272\254\376\017\376=\326\3469\003\0340\260\277\006n\033\335\013+\322\022-" > , Envelope: 105 bytes, Signature: 71 bytes isn't valid {code}  However, they only appear once and they don't appear periodically. It's expected because identity replication in gossip is asynchronous and takes time. If a peer receives a message signed by a peer it doesn't know about (yet) it can't verify the message and prints this warning.   Do these errors appear constantly in your setup (once in a while) or just once? If it's constantly - we have a problem.   ></body> </Action>
<Action id="30713" issue="20715" author="smithbk" type="comment" created="2017-09-11 07:26:04.0" updateauthor="smithbk" updated="2017-09-11 07:26:04.0"> <body><! CDATA Hmm ... step #2 in the instructions should build that image.  After doing the following, what does "docker images" show?  {code} 2) Build *fabric-ca* docker images # git clone github.com/hyperledger/fabric-ca and cd to fabric-ca # checkout https://gerrit.hyperledger.org/r/#/c/13195/ # export USE_FABRIC_LATEST=true # make docker {code}  ></body> </Action>
<Action id="30714" issue="20715" author="smithbk" type="comment" created="2017-09-11 07:38:07.0" updateauthor="smithbk" updated="2017-09-11 07:38:07.0"> <body><! CDATA The real problem I'm trying to solve is that chaincode instantiation fails and these are the only errors I see other than an eventual timeout.  I assumed the timeout was due to these gossip errors, but maybe I'm wrong.  See the timeout at the end.  {code} ^  33m2017-09-10 18:13:41.223 UTC  gossip/gossip  handleMessage -> WARN 436^  0m Message GossipMessage: tag:EMPTY alive_msg:<membership:<endpoint:"peer2-org1:7051" pki_id:"\242\355\225\366\321\177\354\275&E\351\210\255*w\343\205\373/t#>\333&2\242H\n\313\227\232\\" > timestamp:<inc_num:1505067166173445180 seq_num:49 > > , Envelope: 71 bytes, Signature: 70 bytes isn't valid ^  36m2017-09-10 18:13:41.714 UTC  gossip/channel  handleStateInfSnapshot -> DEBU 437^  0m Channel mychannel : Couldn't find org identity of peer ¢í<95>öÑ^?ì½&Eé<88>­*wã<85>û/t#>Û&2¢H Ë<97><9a>\ message sent from m<80>*^G<8d>³c¸5Ö5¤j;ô^U³m9<89>^W<88><84>^_c@ãí<8d>Ö¡4 ^  36m2017-09-10 18:13:41.716 UTC  gossip/channel  handleStateInfSnapshot -> DEBU 438^  0m Channel mychannel : Couldn't find org identity of peer ¢í<95>öÑ^?ì½&Eé<88>­*wã<85>û/t#>Û&2¢H Ë<97><9a>\ message sent from èÌ@MtÕÛ¡üõKrÜ'ïBíæjT«)kN<88>7Ú£w.Zv ^  33m2017-09-10 18:13:43.760 UTC  gossip/state  handleStateResponse -> WARN 439^  0m Payload with sequence number 2 was received earlier ^  36m2017-09-10 18:13:45.715 UTC  gossip/channel  handleStateInfSnapshot -> DEBU 43a^  0m Channel mychannel : Couldn't find org identity of peer ¢í<95>öÑ^?ì½&Eé<88>­*wã<85>û/t#>Û&2¢H Ë<97><9a>\ message sent from m<80>*^G<8d>³c¸5Ö5¤j;ô^U³m9<89>^W<88><84>^_c@ãí<8d>Ö¡4 ^  36m2017-09-10 18:13:45.718 UTC  gossip/channel  handleStateInfSnapshot -> DEBU 43b^  0m Channel mychannel : Couldn't find org identity of peer ¢í<95>öÑ^?ì½&Eé<88>­*wã<85>û/t#>Û&2¢H Ë<97><9a>\ message sent from èÌ@MtÕÛ¡üõKrÜ'ïBíæjT«)kN<88>7Ú£w.Zv ^  33m2017-09-10 18:13:53.767 UTC  gossip/state  handleStateResponse -> WARN 43c^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:14:03.773 UTC  gossip/state  handleStateResponse -> WARN 43d^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:14:13.782 UTC  gossip/state  handleStateResponse -> WARN 43e^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:14:23.789 UTC  gossip/state  handleStateResponse -> WARN 43f^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:14:33.797 UTC  gossip/state  handleStateResponse -> WARN 440^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:14:43.804 UTC  gossip/state  handleStateResponse -> WARN 441^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:14:53.812 UTC  gossip/state  handleStateResponse -> WARN 442^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:15:03.818 UTC  gossip/state  handleStateResponse -> WARN 443^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:15:13.824 UTC  gossip/state  handleStateResponse -> WARN 444^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:15:23.832 UTC  gossip/state  handleStateResponse -> WARN 445^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:15:33.839 UTC  gossip/state  handleStateResponse -> WARN 446^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:15:43.338 UTC  gossip/state  handleStateResponse -> WARN 447^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:15:53.344 UTC  gossip/state  handleStateResponse -> WARN 448^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:16:03.349 UTC  gossip/state  handleStateResponse -> WARN 449^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:16:13.355 UTC  gossip/state  handleStateResponse -> WARN 44a^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:16:23.365 UTC  gossip/state  handleStateResponse -> WARN 44b^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:16:33.372 UTC  gossip/state  handleStateResponse -> WARN 44c^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:16:43.376 UTC  gossip/state  handleStateResponse -> WARN 44d^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:16:53.383 UTC  gossip/state  handleStateResponse -> WARN 44e^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:17:03.390 UTC  gossip/state  handleStateResponse -> WARN 44f^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:17:13.396 UTC  gossip/state  handleStateResponse -> WARN 450^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:17:23.403 UTC  gossip/state  handleStateResponse -> WARN 451^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:17:33.411 UTC  gossip/state  handleStateResponse -> WARN 452^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:17:43.417 UTC  gossip/state  handleStateResponse -> WARN 453^  0m Payload with sequence number 2 was received earlier ^  33m2017-09-10 18:17:53.422 UTC  gossip/state  handleStateResponse -> WARN 454^  0m Payload with sequence number 2 was received earlier ^  36m2017-09-10 18:17:54.894 UTC  chaincode  launchAndWaitForRegister -> DEBU 455^  0m stopping due to error while launching Timeout expired while starting chaincode mycc:1.0(networkid:dev,peerid:peer2-org2,tx:c6de4530ae1216b0661f066cfc24916adf4b092038d1e49e8f203ed625a5f4dd) {code}  ></body> </Action>
<Action id="30715" issue="20715" author="smithbk" type="comment" created="2017-09-11 07:42:30.0" updateauthor="smithbk" updated="2017-09-11 07:42:30.0"> <body><! CDATA And I see the following errors later in logs: {code} ^  33m2017-09-10 18:32:25.359 UTC  gossip/comm  sendToEndpoint -> WARN 514^  0m Failed obtaining connection for peer2-org1:7051, PKIid: 162 237 149 246 209 127 236 189 38 69 233 136 173 42 119 227 133 251 47 116 35 62 219 38 50 162 72 10 203 151 154 92  reason: context deadline exceeded ^  33m2017-09-10 18:32:25.359 UTC  gossip/discovery  expireDeadMembers -> WARN 515^  0m Entering   162 237 149 246 209 127 236 189 38 69 233 136 173 42 119 227 133 251 47 116 35 62 219 38 50 162 72 10 203 151 154 92   ^  33m2017-09-10 18:32:25.359 UTC  gossip/discovery  expireDeadMembers -> WARN 516^  0m Closing connection to Endpoint: peer2-org1:7051, InternalEndpoint: , PKI-ID:  162 237 149 246 209 127 236 189 38 69 233 136 173 42 119 227 133 251 47 116 35 62 219 38 50 162 72 10 203 151 154 92 , Metadata:    ^  33m2017-09-10 18:32:25.359 UTC  gossip/discovery  expireDeadMembers -> WARN 517^  0m Exiting ^  33m2017-09-10 18:32:28.360 UTC  gossip/comm  sendToEndpoint -> WARN 518^  0m Failed obtaining connection for peer2-org1:7051, PKIid: 162 237 149 246 209 127 236 189 38 69 233 136 173 42 119 227 133 251 47 116 35 62 219 38 50 162 72 10 203 151 154 92  reason: context deadline exceeded ^  33m2017-09-10 18:32:31.361 UTC  gossip/comm  sendToEndpoint -> WARN 519^  0m Failed obtaining connection for peer2-org1:7051, PKIid: 162 237 149 246 209 127 236 189 38 69 233 136 173 42 119 227 133 251 47 116 35 62 219 38 50 162 72 10 203 151 154 92  reason: context deadline exceeded ^  33m2017-09-10 18:32:34.361 UTC  gossip/comm  sendToEndpoint -> WARN 51a^  0m Failed obtaining connection for peer2-org1:7051, PKIid: 162 237 149 246 209 127 236 189 38 69 233 136 173 42 119 227 133 251 47 116 35 62 219 38 50 162 72 10 203 151 154 92  reason: context deadline exceeded ^  33m2017-09-10 19:18:34.457 UTC  gossip/discovery  getDeadMembers -> WARN 51b^  0m Haven't heard from  109 128 42 7 141 179 99 184 53 214 53 164 106 59 244 21 179 109 57 137 23 136 132 31 99 64 227 237 141 214 161 52  for 1m29.871687032s ^  33m2017-09-10 19:18:34.458 UTC  gossip/discovery  getDeadMembers -> WARN 51c^  0m Haven't heard from  232 204 64 77 116 213 219 161 252 245 75 114 220 39 239 66 237 230 106 84 171 41 107 78 136 55 218 163 119 46 90 118  for 1m29.869761927s ^  33m2017-09-10 19:18:34.458 UTC  gossip/discovery  expireDeadMembers -> WARN 51d^  0m Entering   109 128 42 7 141 179 99 184 53 214 53 164 106 59 244 21 179 109 57 137 23 136 132 31 99 64 227 237 141 214 161 52   232 204 64 77 116 213 219 161 252 245 75 114 220 39 239 66 237 230 106 84 171 41 107 78 136 55 218 163 119 46 90 118   ^  33m2017-09-10 19:18:34.458 UTC  gossip/discovery  expireDeadMembers -> WARN 51e^  0m Closing connection to Endpoint: peer1-org1:7051, InternalEndpoint: , PKI-ID:  109 128 42 7 141 179 99 184 53 214 53 164 106 59 244 21 179 109 57 137 23 136 132 31 99 64 227 237 141 214 161 52 , Metadata:    ^  33m2017-09-10 19:18:34.458 UTC  gossip/discovery  expireDeadMembers -> WARN 51f^  0m Closing connection to Endpoint: peer1-org2:7051, InternalEndpoint: peer1-org2:7051, PKI-ID:  232 204 64 77 116 213 219 161 252 245 75 114 220 39 239 66 237 230 106 84 171 41 107 78 136 55 218 163 119 46 90 118 , Metadata:    ^  33m2017-09-10 19:18:34.458 UTC  gossip/discovery  expireDeadMembers -> WARN 520^  0m Exiting {code}  ></body> </Action>
<Action id="30716" issue="20715" author="yacovm" type="comment" created="2017-09-11 09:29:17.0" updateauthor="yacovm" updated="2017-09-11 09:29:17.0"> <body><! CDATA It seems your setup isn't good: {code} docker logs peer2-org1 2>&1 | less -R {code} Searching for WARN I get: {code} 2017-09-11 08:36:08.608 UTC  gossip/discovery  func1 -> WARN 19c Could not connect to {peer1-org1:7051       peer1-org1:7051} : x509: certificate signed by unknown authority {code}  It seems there is an error in the setup. Also I didn't see any environment variables when I did docker inspect other than: {code} "Env":   "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", "FABRIC_CFG_PATH=/etc/hyperledger/fabric"  , {code}  What about the localMspId and mspConfigPath ?  ></body> </Action>
<Action id="30740" issue="20715" author="smithbk" type="comment" created="2017-09-11 20:34:25.0" updateauthor="smithbk" updated="2017-09-11 21:15:52.0"> <body><! CDATA The env vars are set in a script but I also display them so they appear in the logs. For example, see the following in data/logs/peer2-org1.log: {code} ##### 2017-09-10 18:12:45 Starting peer 'peer2-org1' with MSP at '/opt/gopath/src/github.com/hyperledger/fabric/peer/msp' ##### CORE_PEER_TLS_ROOTCERT_FILE=/data/org1-ca-chain.pem CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/tls/server.key CORE_PEER_GOSSIP_ORGLEADER=false CORE_PEER_PROFILE_ENABLED=true CORE_PEER_LOCALMSPID=org1MSP CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/tls/server.crt CORE_PEER_TLS_ENABLED=true CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/msp CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=net_fabric-ca CORE_PEER_ID=peer2-org1 CORE_LOGGING_LEVEL=DEBUG CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer2-org1:7051 CORE_PEER_ADDRESS=peer2-org1:7051 CORE_PEER_GOSSIP_USELEADERELECTION=true CORE_PEER_GOSSIP_BOOTSTRAP=peer1-org1:7051 {code}  So when a non-anchor peer tries to connect to it's anchor peer (which is what appears to be happening above), where does the non-anchor peer get the TLS trusted certificate to use for the client side of the TLS connection?  I assume this is from the local MSP's tlscacerts and tlsintermediatecerts directories.  And if you could point me to the code that does that, it would be helpful.  I assume it will handle tlsintermediatecerts.  ></body> </Action>
<Action id="30746" issue="20715" author="yacovm" type="comment" created="2017-09-12 06:01:52.0" updateauthor="yacovm" updated="2017-09-12 06:01:52.0"> <body><! CDATA {quote}So when a non-anchor peer tries to connect to it's anchor peer (which is what appears to be happening above), where does the non-anchor peer get the TLS trusted certificate to use for the client side of the TLS connection?{quote}  If the the 2 peers are from different orgs, then it uses the channel's genesis block. Else - they are in the same org, and then it uses the local MSP's cacerts.  However from what I recall - this happens at the beginning so it's not an anchor peer, but a bootstrap peer (the code path that connects to both of them is the same). This implies that the local MSPs aren't setup right.   ></body> </Action>
<Action id="30750" issue="20715" author="smithbk" type="comment" body="I assume you meant it uses the &quot;local MSP&apos;s tlscacerts and tlsintermediatecerts&quot; and not the &quot;local MSP&apos;s cacerts&quot; to connect to a bootstrap peer.  Is this correct?" created="2017-09-12 10:16:21.0" updateauthor="smithbk" updated="2017-09-12 10:16:21.0"/>
<Action id="30751" issue="20715" author="yacovm" type="comment" body="yeah. " created="2017-09-12 10:20:55.0" updateauthor="yacovm" updated="2017-09-12 10:20:55.0"/>
<Action id="30868" issue="20715" author="smithbk" type="comment" created="2017-09-14 01:36:44.0" updateauthor="smithbk" updated="2017-09-14 10:56:13.0"> <body><! CDATA The previous issue is fixed but now hitting this.  Look familiar or any ideas?  Where exactly does the PKIID value originate and what does that indicate may be wrong from a configuration perspective?  {code} ^  33m2017-09-14 00:29:19.768 UTC  gossip/gossip  validateMsg -> WARN 417^  0m StateInfo message GossipMessage: tag:CHAN_OR_ORG state_info:<metadata:"\000\000\000\000\000\000\000\002" timestamp:<inc_num:11651379494838206464 seq_num:1505348957740534144 > pki_id:"\206\264\344\343\037\357\007\rZ\261\313\020y\221D\034\331\205g\265\303\233L\341\357\351*{\001C\275@" channel_MAC:"\263\017u\206=\330\340\022 \005K\261O\241\"M\377\233\360\345\212\025\351\020\r*\260\251Q\177tv" > , Envelope: 105 bytes, Signature: 70 bytes is found invalid: PKIID wasn't found github.com/hyperledger/fabric/gossip/identity.(*identityMapperImpl).Get /opt/gopath/src/github.com/hyperledger/fabric/gossip/identity/identity.go:149 github.com/hyperledger/fabric/gossip/gossip.(*gossipServiceImpl).validateStateInfoMsg /opt/gopath/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:1167 github.com/hyperledger/fabric/gossip/gossip.(*gossipServiceImpl).validateMsg /opt/gopath/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:413 github.com/hyperledger/fabric/gossip/gossip.(*gossipServiceImpl).handleMessage /opt/gopath/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:335 github.com/hyperledger/fabric/gossip/gossip.(*gossipServiceImpl).acceptMessages /opt/gopath/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:316 runtime.goexit /opt/go/src/runtime/asm_amd64.s:2086 github.com/hyperledger/fabric/gossip/gossip.(*gossipServiceImpl).validateStateInfoMsg /opt/gopath/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:1169 github.com/hyperledger/fabric/gossip/gossip.(*gossipServiceImpl).validateMsg /opt/gopath/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:413 github.com/hyperledger/fabric/gossip/gossip.(*gossipServiceImpl).handleMessage /opt/gopath/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:335 github.com/hyperledger/fabric/gossip/gossip.(*gossipServiceImpl).acceptMessages /opt/gopath/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:316 runtime.goexit /opt/go/src/runtime/asm_amd64.s:2086 {code}  ></body> </Action>
<Action id="30874" issue="20715" author="yacovm" type="comment" created="2017-09-14 12:28:40.0" updateauthor="yacovm" updated="2017-09-14 12:28:40.0"> <body><! CDATA {quote}The previous issue is fixed but now hitting this. Look familiar or any ideas? Where exactly does the PKIID value originate and what does that indicate may be wrong from a configuration perspective?{quote}  the PKI-ID is a representation of the certificate and MSP-ID in a minimized form (hashed).   This warning happens when you get a message that is signed by someone who's certificate you don't have yet.   ></body> </Action>
<Action id="30876" issue="20715" author="yacovm" type="comment" created="2017-09-14 13:31:37.0" updateauthor="yacovm" updated="2017-09-14 13:31:37.0"> <body><! CDATA I compiled your TLS fix and ran the stuff locally: *docker logs peer1-org1 2>&1 | grep handleMessage | grep "state_info_pull_req" | less -R* {code} 2017-09-14 13:27:34.663 UTC  gossip/gossip  handleMessage -> DEBU 71f9 Entering, 172.20.0.11:35466  120 251 148 194 77 163 134 253 185 23 78 199 102 2 202 1 248 30 195 137 210 198 244 248 202 9 191 61 42 70 108 146  sent us GossipMessage: tag:CHAN_OR_ORG state_info_pull_req:<channel_MAC:"J\340\375\223\333e\207jj~7.d\212\356\016\003\230\316\026*\240\201\246\320o\364\313_@\200\223" > , Envelope: 39 bytes, Signature: 0 bytes 2017-09-14 13:27:38.049 UTC  gossip/gossip  handleMessage -> DEBU 739d Entering, 172.20.0.13:7051  155 246 100 223 180 182 74 172 98 195 198 117 236 235 67 209 36 103 16 222 152 173 185 103 30 205 166 181 133 247 103 94  sent us GossipMessage: tag:CHAN_OR_ORG state_info_pull_req:<channel_MAC:"\235\231\273\03306#&\203_\375\036R\002Z\245\270w\232\363\333\2033\033\310\006\273v\240\223\253!" > , Envelope: 39 bytes, Signature: 0 bytes 2017-09-14 13:27:38.357 UTC  gossip/gossip  handleMessage -> DEBU 73a0 Entering, 172.20.0.10:7051  63 220 180 239 242 247 96 167 177 230 60 77 182 78 73 248 10 213 125 184 62 207 163 224 192 154 29 190 13 131 9 21  sent us GossipMessage: tag:CHAN_OR_ORG state_info_pull_req:<channel_MAC:"\332\353\366\210z\342\006\246\313G\336\263i\330gBL\002\246B\0207\336\254\223\203{|:\346K\320" > , Envelope: 39 bytes, Signature: 0 bytes {code}  A similar output is in *peer2-org1* and in for org2.   So it looks like the certificate replication works as expected, because if the peer sent "us" a request it means it verified our certificate.   ></body> </Action>
<Action id="30877" issue="20715" author="yacovm" type="comment" created="2017-09-14 13:34:52.0" updateauthor="yacovm" updated="2017-09-14 13:34:52.0"> <body><! CDATA The instantiate doesn't work because:  {code} 2017-09-14 13:33:39.282 UTC  shim  userChaincodeStreamGetter -> ERRO 001 Error trying to connect to local peer: x509: certificate signed by unknown authority (possibly because of "x509: ECDSA verification failure" while trying to verify candidate authority certificate "rca-org2-admin") Error starting Simple chaincode: Error trying to connect to local peer: x509: certificate signed by unknown authority (possibly because of "x509: ECDSA verification failure" while trying to verify candidate authority certificate "rca-org2-admin")  {code}   ></body> </Action>
<Action id="31608" issue="20715" author="yacovm" type="comment" body=" ~smithbk   I believe we can close this, right?" created="2017-10-04 16:19:38.0" updateauthor="yacovm" updated="2017-10-04 16:19:38.0"/>
