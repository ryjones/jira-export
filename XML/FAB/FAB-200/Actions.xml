<Action id="20086" issue="12500" author="binhn" type="comment" created="2016-12-14 04:14:51.0" updateauthor="binhn" updated="2016-12-14 04:14:51.0"> <body><! CDATA A few comments/questions: # Do we really need block number? Block is just an implementation artifact; the application only cares about transaction and can get transaction with a tx-id # I wonder if it would be more useful to only keep history of some keys but not the entire chain (I am assume a history-db per chain). There are potentially many keys and really concerned about performance and size of the db, given that no pruning when history is important # How should we treat provenance of divisible things? Example, I had a bag of apples, and I gave Bob 20% of it. If we keep track of key, would that be the same key?  ></body> </Action>
<Action id="20087" issue="12500" author="denyeart" type="comment" created="2016-12-14 06:18:59.0" updateauthor="denyeart" updated="2016-12-14 06:18:59.0"> <body><! CDATA  ~binhn  1. Are you talking about block number embedded in the history key? That is just an impl detail that application won't see.  We used blockNum:txNum so that the historic keys would be ordered by time (height), and therefore the API would implicitly return the history in order.  tx-id order would be random order.  Across the ledger we are using blockNum:txNum to indicate transaction height. 2. When using leveldb, the history db is really just another index to the blockchain (we already have 3 other blockchain indexes), and therefore won't get very large.  When using CouchDB on the other hand, history db will contain queryable ledger values and will therefore get large, but not quite as large as the actual blockchain ledger which contains full history of all read and write sets.  When we implement pruning functionality (post-v1), we'll need an option to prune the actual blockchain as well as history database. 3. I call this 'simple provenance' since it can handle the simple provenance scenarios, but not advanced provenance scenarios like divisions very well. Lance is working on advanced provenance scenarios as a MVP under the solutions team.  For the simple provenance solution here, if keyX gets divided and included in keyY, you could use the rich query in CouchDB to query for a field that contains keyX.  It would be up to the chaincode developer to structure their JSON such that divided assets get saved in a predictable field of the target. This would work for some simplistic division scenarios, but not advanced division scenarios such as recursive divisions.  ></body> </Action>
<Action id="20088" issue="12500" author="manish-sethi" type="comment" created="2016-12-14 13:25:02.0" updateauthor="manish-sethi" updated="2016-12-14 13:27:48.0"> <body><! CDATA  ~binhn  - About the dividing of the key, when you retrieve a transaction for a key, the last transaction related to the key would have the other keys also, to which this key was divided. And from thereon one can submit queries related to those keys. App would have to understand the meaning of the embedded keys because, at fabric layer we won't be able to interpret the meaning of this. Going forward, we can allow users to specify a graph query for history db where he can embed traversal queries in terms of embedded keys of transactions. (I guess, that's what Lance would have been doing but we can provide first class support at fabric level, if it's going to be a common query)   ~denyeart  - We should definitely think about resources consumed by the history db. In this regard, we should take the time range for all the queries related to historical queries (off course, a query can still provide full range). For us, the notion of time can be the range of block numbers to start with. This gives us an option to maintain history in a query-able form limited numbers of blocks (configure default to last 10,000,000 blocks). Because, in most of the query scenarios that I expect, typically folks would be interested in recent history. For querying much older history, we can take the request and process offline from blocks (e.g., load the required blocks in the history db and then query and finally delete the blocks. Or even better, process a long running query in spark/map-reduce job directly on the blocks for the given range). This is similar to banks (at least in India) where I can get my last few months/years transaction statement online but for much older statements, I have to raise a request and the statement is made available to me next business day.  In practice, the history maintenance may not limited to maintaining a fixed number of blocks and  it could be in fact a bit more sophisticated where we maintain a limited numbers of versions of a key (we can discuss the benefits and details later)  So, I propose to expose three methods in a history db ```  - GetRecentTxsForKey(key, numTrans) - GetTxsForKey(key, startBlockNum, endBlockNum) - ExecuteQuery(query, startBlockNum, endBlockNum)  If we want to expose the apis in terms of clock time, we would need to maintain an additional mapping between the clock time and block number.  ``` Also, we should maintain history database altogether on a separate disk (if not a separate machine altogether) so that it has minimum interference with the transnational workload.  ></body> </Action>
<Action id="20092" issue="12500" author="binhn" type="comment" created="2016-12-14 15:54:44.0" updateauthor="binhn" updated="2016-12-14 15:54:44.0"> <body><! CDATA  ~manish-sethi   ~denyeart   That makes sense to me.  I think we should offer a MVP on history. My concerns are that we are approaching data warehousing in OLTP environment, especially with the plan on couchdb, where we also store values.   ></body> </Action>
<Action id="20094" issue="12500" author="manish-sethi" type="comment" created="2016-12-14 18:46:26.0" updateauthor="manish-sethi" updated="2016-12-14 18:46:26.0"> <body><! CDATA  ~binhn  - your concern is very reasonable and I too have that. No, we are certainly not going to maintain history db and latest state in a single db. Even in the case of couch, there would be separate instance.   Further, as I mentioned before - I prefer to have the history db on a separate machine altogether. However, if it is not recommended for the reasons of deployment complexity, we should definitely keep it on a separate disk.  ></body> </Action>
<Action id="20097" issue="12500" author="denyeart" type="comment" created="2016-12-14 19:35:53.0" updateauthor="denyeart" updated="2016-12-15 14:01:45.0"> <body><! CDATA  ~binhn   ~manish-sethi  I agree with all the comments.  History database opens up a can of worms, especially if we store all the data in CouchDB. First objective is to get the basic function into v1 as beta, so that we have a starting point to discuss and collect feedback from the community on this advanced topic.  I expect it will take some time to work through all the decisions.  For example I do expect working with time windows is more valuable to history consumers than block windows, and therefore I think we need to investigate ordering service providing a timestamp on the block.   There will also be implications related to checkpointing/pruning when it is introduced post-v1. For example we may decide to prune blockchain and state and history db all together, and in the same process move the pruned data to a 'deep history' database (e.g. prior years). I believe this would meet the same objective Manish raised, but without complicating the API. For initial function, let's keep the API simple and return all history for a key.  ></body> </Action>
<Action id="24622" issue="12500" author="kletkeman" type="comment" created="2017-05-30 03:25:45.0" updateauthor="kletkeman" updated="2017-05-30 03:25:45.0"> <body><! CDATA Well, if you can specify that event and state are JSON objects (as we did in our platform at https://github.com/ibm-watson-iot/blockchain-samples/blob/master/contracts/platform/iotcontractplatform/cthistory.go), then history can be implemented as simply as a second write to a tag (we use "IOTCP.HIST.") plus the asset class and ID, plus an RFC3339nano formatted timestamp.  Retrieving a history range is then as simple as getting an iterator from time X inclusive to time Y exclusive. I added a simple filter to history queries that take a set of qualified JSON property names and values.   Just saying that an all singing all dancing database might be nice, but this implementation is part of the read / write set and I happen to like that particular behavior.  ></body> </Action>
