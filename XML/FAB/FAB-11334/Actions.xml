<Action id="54961" issue="32248" author="rhegde" type="comment" created="2018-12-19 12:45:32.0" updateauthor="rhegde" updated="2018-12-19 12:45:32.0"> <body><! CDATA Impact:  In CLSNet, we are already in a production where a channels is created between every participants. There is a case where participant may decide not to interact with the some  or may opt out completely and as a result there is a need to provision channel deletion.  It would be good to have at least a support to un-join peer for the channel and eventually process to delete the channel from the system.  Can we have a fix version for this implementation.   ~rsherwood ,  ~Clayton Sims   ~mastersingh24   I assume there is no manual process to do the same.  ></body> </Action>
<Action id="59569" issue="32248" author="markparz" type="comment" body=" ~Anzal  &amp; Sandeep Gupta has also been requesting this feature." created="2019-04-29 13:22:00.0" updateauthor="markparz" updated="2019-04-29 13:22:00.0"/>
<Action id="71676" issue="32248" author="JIRAUSER21494" type="comment" body="This issue was put forward on July 27th 2018. From my perspective, What this feature needs to do is to remove channel config on peer and delete all specific channel data on the ledger. With all peers exiting the channel, this channel will be deleted from blockchain system finally. It seems to have no problem causing blocking. So I wanna ask the progress until now.  ~rhegde  ~markparz " created="2021-04-14 01:28:39.0" updateauthor="JIRAUSER21494" updated="2021-04-14 01:28:39.0"/>
<Action id="71677" issue="32248" author="denyeart" type="comment" body=" ~wuqiaomin  This issue is currently being scoped out.   ~manish-sethi  could you clarify the Description field with current design thoughts?" created="2021-04-14 01:40:45.0" updateauthor="denyeart" updated="2021-04-14 01:40:45.0"/>
<Action id="71753" issue="32248" author="JIRAUSER21494" type="comment" created="2021-05-13 02:48:34.0" updateauthor="JIRAUSER21494" updated="2021-05-13 02:48:34.0"> <body><! CDATA I have some propose to complete this demand issue if there is still no idea.  For deleting channel config information, we need to remove channel config from peer so that the channel would not be initialized after restart the peer. if there exist anchor peer, a transaction which update channel config should be invoked to remove content about this peer in channel config. And then remove the "bootstrap" in "core.yaml". Nextly, we need to remove channel data in unjoined peer ledger. Thus, the database should be refactored to specify to the directory corresponding to each channel for opertating all data related to specified chanel.  ~denyeart    ~manish-sethi   ></body> </Action>
<Action id="71881" issue="32248" author="manish-sethi" type="comment" created="2021-06-22 00:06:33.0" updateauthor="manish-sethi" updated="2021-06-22 00:06:33.0"> <body><! CDATA For enabling a peer to unjoin a channel, we would need to make a trade off between simplicity of code v/s flexibility of operation. If we make it a prerequisite that peer should not be running, the primary task would be just to delete the data related to the channel. However, if we want to enable this operation while the peer is up, we would need to take care of additional tasks that include # Clear all in-memory caches for the channel # Stop all background goroutines that are launched in the context of the channel # Close all golang channels # Interrupt ongoing client operations for the channel  *Changes required in the running peer* Upon initial investigation of the code, following is a high-level summary of these additional tasks that are required if we allow this operation without requiring peer shutdown. As we start working, we will need to look at the related code and make sure no additional channel specific leakage is escaped and setting an object to nil does not cause a nil pointer panic in any background or client query related operation.  1)  Stop|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/gossip/gossip/channel/channel.go#L314  channel specific gossip operations so block pulling and committing is stopped. Also,  stop|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/gossip/service/gossip_service.go#L155  private data related background operations such as reconciler.  2) clear cached data in  newLifecycle cache|https://github.com/hyperledger/fabric/blob/16259ed70a4cd57513be40a0678213d9274a9ae8/core/chaincode/lifecycle/cache.go#L68  and  legacy chaincode MetadataManager|https://github.com/hyperledger/fabric/blob/16259ed70a4cd57513be40a0678213d9274a9ae8/core/cclifecycle/lifecycle.go#L22 . This can be achieved by enhancing the interface  ledger.StateListener|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/core/ledger/ledger_interface.go#L509  by adding a new function, say _DeletingLedger_(ledgerID string). Ledger can call back this function to give a hint that the above two components can delete the channel specific cache, as these two are registered as a ledger state update listeners.  Enhance stop/close of ledger sub-components to include the following items (3-8)  3) Clear cached data in  couchdb peer cache|https://github.com/manish-sethi/fabric/blob/04796e6f00aab5b4ff53dfe31469a682cf472ea3/core/ledger/kvledger/txmgmt/statedb/statecouchdb/cache.go#L17 . Perhaps we will need to reset the entire cache, as the library we use does not provide an option for finding the keys specific to a channelID  4) Enhance pvtdatastore code so as to stop or wait for the background goroutines to finish for tasks  purging expired entries|https://github.com/hyperledger/fabric/blob/04796e6f00aab5b4ff53dfe31469a682cf472ea3/core/ledger/pvtdatastorage/store.go#L604  and  detecting and updating the collection membership change info|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/core/ledger/pvtdatastorage/store.go#L684 .   5) Enhance kvledger code for keeping track of  BlocksIterators|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/core/ledger/kvledger/kv_ledger.go#L533  issued and close the open iterators, as some of the iterators may be waiting for next block to commit. This intern should cause terminating the grpc stream in  deliver service|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/common/deliver/deliver.go#L316  causing returning  Service_Unavailable|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/common/ledger/blockledger/fileledger/impl.go#L48  status to deliver clients. The deliver service for block with private data should  return an error|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/core/peer/deliverevents.go#L155  if it has already received the block but receives an error while retrieving pvtdata, because the private data store would be closed.  6) Ensure that the opened TxSimulators starts returning errors, either explicitly or because of the closing the underlying data stores  7) Some mechanism may be needed stop the ongoing  snapshot generation|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/core/ledger/kvledger/snapshot.go#L94  for the channel. This may be tricky as the data exporting cycle from a db may take long. This may require enhancement in the snapshot generation code to check for a stop flag periodically. Also, enhance  snapshotMgr.shutdown|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/core/ledger/kvledger/snapshot_mgmt.go#L255  function to stop/wait for background goroutine ( here|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/core/ledger/kvledger/snapshot_mgmt.go#L137  and  here|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/core/ledger/kvledger/snapshot_mgmt.go#L197 ) that generates a snapshot.  8) Close  commit notification channel|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/core/ledger/kvledger/kv_ledger.go#L898   9) Remove the channel object from the list of channels  *Persistent Data deletion* As far as deletion of persistent data is concerned, there is already a  low level api|https://github.com/hyperledger/fabric/blob/b5a4fe942ea819011e403aeb843ad6f62564ffd4/core/ledger/kvledger/kv_ledger_provider.go#L466  for deleting the data from various stores. We already leverage this function for cleaning up the partial data left behind when a failure occur during bootstrapping a channel using a snapshot. Following are the further changes that are required in this context.  1) Include the deletion of data for the channel from transient store 2) Introduce a  new status|https://github.com/hyperledger/fabric/blob/16259ed70a4cd57513be40a0678213d9274a9ae8/core/ledger/kvledger/msgs/ledger_metadata.pb.go#L26  "UNDER_DELETION" for the channel.  Set the status in the idStore|https://github.com/hyperledger/fabric/blob/16259ed70a4cd57513be40a0678213d9274a9ae8/core/ledger/kvledger/kv_ledger_provider.go#L629  and start deleting the ledger content. Finally, delete the ledger entry from the idStore. At the start of peer, like a ledger with this status should be deleted (as it would indicate a failure from previous delete, leaving behind the partial content. This is same as  we do|https://github.com/hyperledger/fabric/blob/16259ed70a4cd57513be40a0678213d9274a9ae8/core/ledger/kvledger/kv_ledger_provider.go#L122  with a ledger with status "UNDER_CONSTRUCTION".  *End user command* This would be similar to existing commands for  pause channel|https://github.com/hyperledger/fabric/blob/16259ed70a4cd57513be40a0678213d9274a9ae8/internal/peer/node/pause.go#L16   ></body> </Action>
<Action id="71902" issue="32248" author="manish-sethi" type="comment" body="As this is an infrequent operation, based on the discussions, keeping the scope limited in the first cut by requiring the peer to be shutdown." created="2021-06-29 03:07:00.0" updateauthor="manish-sethi" updated="2021-06-29 03:07:00.0"/>
<Action id="71907" issue="32248" author="JIRAUSER22046" type="comment" created="2021-06-30 19:30:41.0" updateauthor="JIRAUSER22046" updated="2021-06-30 19:36:58.0"> <body><! CDATA +1  we have been looking for the same option from couple of years now.   We have the below scenario:  One of the main peer joined in multiple channels, now one of the channel had reached 1 billion transactions, we want to remove the peer from that channel as we don't require to receive data any more and want to save the disk space and costing.   One option is to shutdown the existing peer, create a new peer and join into existing channels, but the problem is: existing channels have around 50 to 60 million transactions which would take around a week time to sync the new peer.            ></body> </Action>
