<Action id="55244" issue="36449" author="denyeart" type="comment" body=" ~raft 3  Please attach peer debug (env variable CORE_LOGGING_LEVEL=DEBUG)." created="2019-01-03 12:46:25.0" updateauthor="denyeart" updated="2019-01-03 12:46:25.0"/>
<Action id="55250" issue="36449" author="raft 3" type="comment" body=" ~denyeart  please see attached logs. They are very verbose, I just set log level to debug, restarted peer, tried an *install* and captured all logs." created="2019-01-03 14:03:41.0" updateauthor="raft 3" updated="2019-01-03 14:03:41.0"/>
<Action id="55283" issue="36449" author="raft 3" type="comment" created="2019-01-04 13:29:06.0" updateauthor="raft 3" updated="2019-01-04 13:29:06.0"> <body><! CDATA Also, during parallel upgrading, almost always we got errors on some peers like below: {code:java} Error: could not assemble transaction, err proposal response was not successful, error code 500, msg cannot get package for chaincode (<chaincode_name>:<version>){code} To my understanding, error states that version of chaincode is not installed, but it's actually installed, I can see it with: {code:java} peer chaincode list --installed{code} Also I can manually do an upgrade based on that version. I added a 10 seconds sleep between install and upgrade, helped a bit but didnt solve it completely.  ></body> </Action>
<Action id="55332" issue="36449" author="denyeart" type="comment" created="2019-01-05 14:58:40.0" updateauthor="denyeart" updated="2019-01-05 14:58:40.0"> <body><! CDATA Looks like lscc install step does indeed hang until timeout, the install never completes: {code:java}  36m2019-01-03 13:58:07.800 UTC  endorser  SimulateProposal -> DEBU 704 0m    e36c3e59  Entry chaincode: name:"lscc"   34m2019-01-03 13:58:07.800 UTC  endorser  callChaincode -> INFO 705 0m    e36c3e59  Entry chaincode: name:"lscc"   36m2019-01-03 13:58:07.800 UTC  chaincode  Execute -> DEBU 706 0m Entry  36m2019-01-03 13:58:07.801 UTC  chaincode-metadata  GetMetadataAsTarEntries -> DEBU 707 0m Created metadata tar  36m2019-01-03 13:58:07.801 UTC  cceventmgmt  HandleChaincodeInstall -> DEBU 708 0m HandleChaincodeInstall() - chaincodeDefinition=&cceventmgmt.ChaincodeDefinition{Name:"pivt", Hash:  uint8{0xdd, 0xf1, 0x37, 0xd5, 0x5, 0x5b, 0x64, 0x3a, 0x11, 0x10, 0xc6, 0x3b, 0x86, 0x27, 0x79, 0x6a, 0x23, 0xb0, 0xa1, 0xb7, 0xe6, 0xea, 0xb6, 0xce, 0x4, 0x82, 0xeb, 0x57, 0x75, 0x2e, 0x9c, 0xae}, Version:"1.1", CollectionConfigs:  uint8(nil)}{code}  ></body> </Action>
<Action id="55361" issue="36449" author="raft 3" type="comment" body=" ~denyeart Â please also see the new attached logs. In another identical network we ended up with the same state. These logs contains everything from the beginning, so it might give a clue." created="2019-01-07 11:02:05.0" updateauthor="raft 3" updated="2019-01-07 11:02:05.0"/>
<Action id="55600" issue="36449" author="mastersingh24" type="comment" body=" ~raft 3 Â  - any chance you can run with logging set to debug?" created="2019-01-14 11:40:07.0" updateauthor="mastersingh24" updated="2019-01-14 11:40:07.0"/>
<Action id="55602" issue="36449" author="raft 3" type="comment" body=" ~mastersingh24 Â the first set of logs &apos;peer_logs.txt&apos; is in debug mode" created="2019-01-14 11:45:39.0" updateauthor="raft 3" updated="2019-01-14 11:45:39.0"/>
<Action id="55799" issue="36449" author="sykesm" type="comment" created="2019-01-18 16:21:04.0" updateauthor="sykesm" updated="2019-01-18 16:21:04.0"> <body><! CDATA From the logs, it looks like we've entered core/ledger/cceventmgr.Mgr#HandleChaincodeInstall. We never see anything else (errors or otherwise) implying we're waiting for a lock or, less likely, there were no registered lifecycle listeners.  logs: {code}  36m2019-01-03 13:58:07.801 UTC  chaincode-metadata  GetMetadataAsTarEntries -> DEBU 707 0m Created metadata tar  36m2019-01-03 13:58:07.801 UTC  cceventmgmt  HandleChaincodeInstall -> DEBU 708 0m HandleChaincodeInstall() - chaincodeDefinition=&cceventmgmt.ChaincodeDefinition{Name:"pivt", Hash:  uint8{0xdd, 0xf1, 0x37, 0xd5, 0x5, 0x5b, 0x64, 0x3a, 0x11, 0x10, 0xc6, 0x3b, 0x86, 0x27, 0x79, 0x6a, 0x23, 0xb0, 0xa1, 0xb7, 0xe6, 0xea, 0xb6, 0xce, 0x4, 0x82, 0xeb, 0x57, 0x75, 0x2e, 0x9c, 0xae}, Version:"1.1", CollectionConfigs:  uint8(nil)} {code}  code: {code} // HandleChaincodeInstall is expected to get invoked during installation of a chaincode package func (m *Mgr) HandleChaincodeInstall(chaincodeDefinition *ChaincodeDefinition, dbArtifacts   byte, sccp sysccprovider.SystemChaincodeProvider) error { 	logger.Debugf("HandleChaincodeInstall() - chaincodeDefinition=%#v", chaincodeDefinition) 	// Write lock prevents concurrent deploy operations 	m.rwlock.Lock() 	for chainid := range m.ccLifecycleListeners { 		logger.Debugf("Channel  %s : Handling chaincode install event for chaincode  %s ", chainid, chaincodeDefinition) ... 		logger.Debugf("Channel  %s : Handled chaincode install event for chaincode  %s ", chainid, chaincodeDefinition) 	} 	return nil {code}  Not very familiar with this code but my guess is that we're blocked on the lock. It looks like HandleChaincodeDeploy obtains the read lock and install obtains the write lock. Getting a go routine dump during the hang would confirm this.  ></body> </Action>
<Action id="55878" issue="36449" author="manish-sethi" type="comment" created="2019-01-20 23:55:45.0" updateauthor="manish-sethi" updated="2019-01-21 00:12:00.0"> <body><! CDATA Looking at the logs (peer_logs.txt), I find that there are two chaincode upgrade transactions in a single block. In the code for release 1.3 (and I believe that this has not changed since then), the chaincode-events-listener of the discovery service code writes the event to a golang channel (and processes all the events only on block commit). This channel is initialized with capacity one and hence it gets stuck on the second call. CCing  ~yacovm .  Relevant logs from peer_logs.txt {code}  36m2019-01-03 13:57:45.978 UTC  cceventmgmt  HandleStateUpdates -> DEBU 475 0m Channel  puo2channel : Handling state updates in LSCC namespace - stateUpdates=  *kvrwset.KVWrite{(*kvrwset.KVWrite)(0xc421f4f9f0), (*kvrwset.KVWrite)(0xc421f4fa40)}  34m2019-01-03 13:57:45.978 UTC  cceventmgmt  HandleStateUpdates -> INFO 476 0m Channel  puo2channel : Handling LSCC state update for chaincode  info   34m2019-01-03 13:57:45.978 UTC  cceventmgmt  HandleStateUpdates -> INFO 477 0m Channel  puo2channel : Handling LSCC state update for chaincode  puo   36m2019-01-03 13:57:45.979 UTC  cceventmgmt  HandleChaincodeDeploy -> DEBU 479 0m Channel  puo2channel : Handling chaincode deploy event for chaincode   Name=info, Version=3723, Hash=  byte{0xce, ...} Name=puo, Version=3725, Hash=  byte{0x6d, ...}    36m2019-01-03 13:57:45.986 UTC  discovery/lifecycle  HandleChaincodeDeploy -> DEBU 486 0m Channel puo2channel got a new deployment: Name=info, Version=3723, Hash=  byte{0xce, ...}  36m2019-01-03 13:57:45.986 UTC  cceventmgmt  HandleChaincodeDeploy -> DEBU 487 0m Channel  puo2channel : Handled chaincode deploy event for chaincode   Name=info, Version=3723, Hash=  byte{0xce, ...} Name=puo, Version=3725, Hash=  byte{0x6d, ...}    36m2019-01-03 13:57:45.988 UTC  discovery/lifecycle  HandleChaincodeDeploy -> DEBU 48a 0m Channel puo2channel got a new deployment: Name=puo, Version=3725, Hash=  byte{0x6d, ...} ........... NO LOG ENTRY HERE FOR puo chaincode saying that "Handled chaincode deploy event for chaincode   Name=puo"  {code}  Relevant code snippets {code} // HandleChaincodeDeploy is expected to be invoked when a chaincode is deployed via a deploy transaction and the chaicndoe was already // installed on the peer. This also gets invoked when an already deployed chaincode is installed on the peer func (sub *Subscription) HandleChaincodeDeploy(chaincodeDefinition *cceventmgmt.ChaincodeDefinition, dbArtifactsTar   byte) error { 	Logger.Debug("Channel", sub.channel, "got a new deployment:", chaincodeDefinition) 	sub.pendingUpdates <- chaincodeDefinition 	return nil }   // NewChannelSubscription subscribes to a channel func (lc *Lifecycle) NewChannelSubscription(channel string, queryCreator QueryCreator) (*Subscription, error) { 	sub := &Subscription{ 		lc:             lc, 		channel:        channel, 		queryCreator:   queryCreator, 		pendingUpdates: make(chan *cceventmgmt.ChaincodeDefinition, 1), 	} {code}  ></body> </Action>
<Action id="55879" issue="36449" author="yacovm" type="comment" body=" ~manish-sethi  I guess the ChaincodeDeployDone is only called by the ledger after all the HandleChaincodeDeploy are called and not 1 by 1? " created="2019-01-21 00:07:18.0" updateauthor="yacovm" updated="2019-01-21 00:07:18.0"/>
<Action id="55880" issue="36449" author="manish-sethi" type="comment" body="Yes,  ~yacovm  that is correct." created="2019-01-21 00:10:09.0" updateauthor="manish-sethi" updated="2019-01-21 00:10:09.0"/>
<Action id="55882" issue="36449" author="yacovm" type="comment" created="2019-01-21 00:47:03.0" updateauthor="yacovm" updated="2019-01-21 00:54:18.0"> <body><! CDATA https://gerrit.hyperledger.org/r/#/c/28841/ , https://gerrit.hyperledger.org/r/#/c/28842, https://gerrit.hyperledger.org/r/#/c/28843 https://gerrit.hyperledger.org/r/#/c/28844    ></body> </Action>
<Action id="55883" issue="36449" author="yacovm" type="comment" body="I should&apos;ve realized that is how it works... no clue why I thought (wishful thinking?) it&apos;s 1 by 1 :(" created="2019-01-21 00:56:05.0" updateauthor="yacovm" updated="2019-01-21 00:56:05.0"/>
<Action id="56031" issue="36449" author="yacovm" type="comment" body=" ~denyeart  ,  ~bmos299  does SVT cover chaincode upgrades?" created="2019-01-22 20:31:07.0" updateauthor="yacovm" updated="2019-01-22 20:31:07.0"/>
<Action id="56033" issue="36449" author="bmos299" type="comment" body=" ~yacovm  yes.  Upgrade cc testing is performed.  I see FAB-8252.  In the past it was part of our fvt testing.  I do not see this in our daily run or a behave test.   ~scottz   ~suryalnvs   ~latitiah  was this tested in 1.3 and 1.4?  Now that we aren&apos;t doing fvt, this could be missed.   " created="2019-01-22 21:58:51.0" updateauthor="bmos299" updated="2019-01-22 21:59:30.0"/>
<Action id="56074" issue="36449" author="denyeart" type="comment" body="The test scenario that was missed was the scenario of having multiple chaincode upgrade transactions in the same block. This is not a very common scenario and therefore missed in both function and system tests." created="2019-01-23 06:18:51.0" updateauthor="denyeart" updated="2019-01-23 06:18:51.0"/>
<Action id="56105" issue="36449" author="latitiah" type="comment" created="2019-01-23 14:39:04.0" updateauthor="latitiah" updated="2019-01-23 14:51:32.0"> <body><! CDATA There are currently 3 different chaincode upgrade scenarios being tested through CI that are described in these 2 issues: FAB-7407 FAB-8759. All 3 scenarios have been passing without problems. If you are interested in seeing the steps and/or the results, here is a link to the test matrix https://jenkins.hyperledger.org/view/fabric-test/job/fabric-test-daily-behave-release-1.4-x86_64/test_results_analyzer/. Drill down into the peer tests and find the tests with the before-mentioned issue numbers. (ex.: https://jenkins.hyperledger.org/view/fabric-test/job/fabric-test-daily-behave-master-x86_64/143/testReport/peer/Peer%20Service/FAB_7407__Update_the_channel_policies___add_an_organization)  None of these test cases have the scenario of having multiple chaincode upgrade transactions in the same block or in parallel.    ></body> </Action>
<Action id="58861" issue="36449" author="raft 3" type="comment" body="Hey Guys, might there be a similar issue with chaincodeÂ *instantiation* in parallel? We are experimenting with install/instantiate in parallel but doesnt look much stable, fails sometimes. We are using version: *1.4.1-rc1*" created="2019-04-02 17:40:09.0" updateauthor="raft 3" updated="2019-04-02 17:40:09.0"/>
<Action id="66378" issue="36449" author="hakan.eryargi" type="comment" created="2019-12-23 16:33:40.0" updateauthor="hakan.eryargi" updated="2019-12-23 16:33:40.0"> <body><! CDATA I guess this issue isnt solved completely or there is another similar issue.Â   One of our peers stucked in a very similar state. After that, all chaincode installations failed with timeout error. Fortunately resolved after restarting the peer.  Complete peer logs are attached: peer.logs.23.12.2019  ></body> </Action>
