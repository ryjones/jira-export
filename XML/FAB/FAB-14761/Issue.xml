<Issue id="38660" key="FAB-14761" number="14761" project="10002" reporter="sykesm" assignee="wenjian" creator="sykesm" type="10004" summary="Throttle file access operations that pin go routine to a pthread" priority="3" resolution="10000" status="6" created="2019-03-21 20:08:03.0" updated="2020-02-17 18:50:13.0" resolutiondate="2020-02-17 18:37:18.0" votes="0" watches="10" workflowId="50305" security="10000"> <description><! CDATA FAB-13347 reports the following:   {quote} While using `channel.queryBlock(qi)` to query the blocks, if there are more than 10K threads, the peer crashes. {quote}  In response to that, we applied a very naive change at the highest comm layer to limit the concurrency of grpc requests with the understanding that it wasn't optimal. That change has (of course) impacted performance so, as a middle ground, we've moved the the throttle to qscc.  The reality is that the vast majority of system calls in the peer which cause the creation of new pthreads come from file access. In particular, os.Open/OpenFile and File.ReadAt were the source of the pinned threads in the test that resulted in a crash.  Auditing the code, most file access occurs during chanicode deployment, statedb access, and block access.  Examples: {code} common/ledger/blockledger/json/impl.go common/ledger/util/ioutil.go common/ledger/testutil/test_util.go common/ledger/blkstorage/fsblkstorage/block_stream.go common/ledger/blkstorage/fsblkstorage/blockfile_rw.go {code}  While file access is not the only source of pthread creation, it's significant enough to warrant some explicit limits to prevent resource exhaustion.  ></description> </Issue>
