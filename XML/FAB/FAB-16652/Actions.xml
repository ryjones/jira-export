<Action id="63963" issue="42415" author="muralisr" type="comment" created="2019-09-23 13:29:16.0" updateauthor="muralisr" updated="2019-09-23 13:29:16.0"> <body><! CDATA  ~soumyanayak  You mentioned the steps above worked after a change to configtx.yaml (if I understood you correctly). Can you also add the modified configtx.yaml please ?  Also, curious, step 2 is "upgrade" instead of "instantiate" ... was this chaincode already instantiated earlier ? I'm wondering if we are chasing something else entirely. If indeed you were upgrading, did you make sure the old chaincode docker image was deleted ?  Can you add the actual logs instead of the screen shot snippet ? The full logs may reveal the real culprit.     Thanks!  ></body> </Action>
<Action id="64122" issue="42415" author="soumyanayak" type="comment" created="2019-09-25 13:59:13.0" updateauthor="soumyanayak" updated="2019-09-25 13:59:13.0"> <body><! CDATA Hi Srinivasan ,   Please find attached the configtx.yaml file which was causing the issue. ^configtx.yaml .  Line no 111 was where i corrected the allignment in the attached YAMl file.     The first time i used instantiated command post which also this issues was there. Later just to replicate the error i was installing the same chaincode with different versions and using the upgrade command.     After upgrading , i did not delete the old containers but they were in exited state and the new container was in the list of active containers, but the very next moment when i run the command to list out the instantiated chaincodes, the active chaincode contaienr exited and there is a panic in peer with the logs as attached already - Peer_logs.png.     But correcting the allignment of line no 111 , everything got resolved.  Configtxgen tool also did not detect this allignment issue.     Will try to replicate again and attach the complete logs.  Regards,  Soumya  ></body> </Action>
<Action id="64124" issue="42415" author="muralisr" type="comment" created="2019-09-25 14:29:30.0" updateauthor="muralisr" updated="2019-09-25 14:31:33.0"> <body><! CDATA  ~soumyanayak  Thank you for the details... will look for logs.  Also when you get the new set of logs, please include all the CLI commands executed (including channel commands please).  ></body> </Action>
<Action id="64143" issue="42415" author="soumyanayak" type="comment" created="2019-09-26 08:07:22.0" updateauthor="soumyanayak" updated="2019-09-26 08:07:22.0"> <body><! CDATA Hi Srinivasan,  Below are the commands used for generation of genesis block, channel transaction file and anchor peer    * *Genesis Block* *Generation*  configtxgen -profile LegalDescriptionGenesis -outputBlock ./legaldescription-genesis.block -channelID ordererchannel    * *Legal Descripton Channel Transaction File –*   configtxgen -profile LegalDescriptionChannel -outputCreateChannelTx ./legaldescription-channel.tx -channelID legaldescriptionchannel    * *Anchor Peer Update Transaction File* –  configtxgen -profile LegalDescriptionChannel -outputAnchorPeersUpdate ./Org1anchors.tx -channelID legaldescriptionchannel -asOrg Org1     Post the above - the *legaldescription-genesis.block* file generated was copied to all the orderer machines and all the 5 RAFT orderers was started.     Then in peer machine -  *CLI Container Login* – sudo docker exec -it tools /bin/bash  *Channel Create Command - #Mutual TLS Mode* peer channel create -c legaldescriptionchannel -f /var/hyperledger/config/legaldescription-channel.tx --orderer $ORDERER_ADDRESS --tls --cafile $CORE_PEER_TLS_ROOTCERT_FILE --clientauth --keyfile $CORE_PEER_TLS_CLIENTKEY_FILE --certfile $CORE_PEER_TLS_CLIENTCERT_FILE     *Channel JOIN Command - #Mutual TLS Mode*  peer channel fetch 0 -c legaldescriptionchannel --orderer $ORDERER_ADDRESS --tls --cafile $CORE_PEER_TLS_ROOTCERT_FILE --clientauth --keyfile $CORE_PEER_TLS_CLIENTKEY_FILE --certfile $CORE_PEER_TLS_CLIENTCERT_FILE  peer channel join -o $ORDERER_ADDRESS -b ./legaldescriptionchannel_0.block     *Anchor Peer Update Command -* *#Mutual TLS Mode*   peer channel update -f /var/hyperledger/config/Org1anchors.tx -c legaldescriptionchannel -o $ORDERER_ADDRESS --tls --cafile $CORE_PEER_TLS_ROOTCERT_FILE --clientauth --keyfile $CORE_PEER_TLS_CLIENTKEY_FILE --certfile $CORE_PEER_TLS_CLIENTCERT_FILE     *Chaincode Installation Command* – peer chaincode install -n ldbc -v 1.0 -p ldbc  *Chaincode Instantiate Command –*  * peer chaincode instantiate -o $ORDERER_ADDRESS --tls --cafile $CORE_PEER_TLS_ROOTCERT_FILE -C legaldescriptionchannel -n ldbc -v 1.0 -c '\{"Args":  }' --clientauth --keyfile $CORE_PEER_TLS_CLIENTKEY_FILE --certfile $CORE_PEER_TLS_CLIENTCERT_FILE     *Chanicode Instantiated List Command --*  peer chaincode list --instantiated -C legaldescriptionchannel     Post the above command there was a panic in peer logs where peer exited and again the peer docker container was restarted automatcially as in peer docker-compose (restart: always). This leads to the chaincode container exiting.      Please find attached the logs of peer and orderer.  ></body> </Action>
<Action id="64144" issue="42415" author="soumyanayak" type="comment" created="2019-09-26 08:11:57.0" updateauthor="soumyanayak" updated="2019-09-26 08:11:57.0"> <body><! CDATA  ^orderer2.log   Around line no 2677 in Peer1.log . You can check.     Also the logs from CLI container   ></body> </Action>
<Action id="64145" issue="42415" author="soumyanayak" type="comment" created="2019-09-26 08:13:23.0" updateauthor="soumyanayak" updated="2019-09-26 08:13:23.0"> <body><! CDATA  ^chaincode_list_instantiated.txt      Also the logs of configtxgen tool which was able to generate the genesis blockc successfully even after the allignment issue –  ^genesisBlockGeneration.log   ></body> </Action>
<Action id="64194" issue="42415" author="muralisr" type="comment" created="2019-09-29 14:30:25.0" updateauthor="muralisr" updated="2019-09-29 14:32:36.0"> <body><! CDATA Thanks,  ~soumyanayak  ... the full stack trace from peer log is    {code:java} goroutine 682  running :  <--- the top shows chaincode stack but this is not the user chaincode .... github.com/hyperledger/fabric/core/chaincode/shim.(*Handler).triggerNextState(0xc000275ec0, 0x0, 0xc0001bcfc0) /opt/gopath/src/github.com/hyperledger/fabric/core/chaincode/shim/handler.go:35 +0x26 github.com/hyperledger/fabric/core/chaincode/shim.(*Handler).handleTransaction.func1.1(0xc000275ec0, 0xc002acfeb0, 0xc0001bcfc0) /opt/gopath/src/github.com/hyperledger/fabric/core/chaincode/shim/handler.go:247 +0x42  panic(0x10b2c20, 0x1ed23f0) <---- ... this is the real culprit, crash coming from system chaincode /opt/go/src/runtime/panic.go:513 +0x1b9 github.com/hyperledger/fabric/common/channelconfig.newAPIsProvider(0xc0001c5890, 0x0) /opt/gopath/src/github.com/hyperledger/fabric/common/channelconfig/acls.go:29 +0x229 github.com/hyperledger/fabric/common/channelconfig.(*ApplicationConfig).APIPolicyMapper(0xc0023a9f40, 0x13ce140, 0xc0023a9f40) /opt/gopath/src/github.com/hyperledger/fabric/common/channelconfig/application.go:76 +0x35 github.com/hyperledger/fabric/core/aclmgmt.(*policyEvaluatorImpl).PolicyRefForAPI(0xc0023ea680, 0x1279c94, 0x1e, 0x1187301, 0xc0023ea680) /opt/gopath/src/github.com/hyperledger/fabric/core/aclmgmt/resourceprovider.go:53 +0x55 github.com/hyperledger/fabric/core/aclmgmt.(*aclmgmtPolicyProviderImpl).GetPolicyName(0xc002acf7e0, 0x1279c94, 0x1e, 0xc000278420, 0x12835b01d807aa98) /opt/gopath/src/github.com/hyperledger/fabric/core/aclmgmt/resourceprovider.go:88 +0x47 github.com/hyperledger/fabric/core/aclmgmt.(*resourceProvider).CheckACL(0xc00039e120, 0x1279c94, 0x1e, 0xc002321de0, 0x17, 0x11bcd60, 0xc0022fc640, 0xd, 0xc0024f0130) /opt/gopath/src/github.com/hyperledger/fabric/core/aclmgmt/resourceprovider.go:165 +0x183 github.com/hyperledger/fabric/core/aclmgmt.(*aclMgmtImpl).CheckACL(0xc00039d390, 0x1279c94, 0x1e, 0xc002321de0, 0x17, 0x11bcd60, 0xc0022fc640, 0xa89369e5f9b444a4, 0x4ed8aa4a391c0cb3) /opt/gopath/src/github.com/hyperledger/fabric/core/aclmgmt/aclmgmtimpl.go:31 +0x79 github.com/hyperledger/fabric/core/scc/lscc.(*LifeCycleSysCC).Invoke(0xc00037d310, 0x13e71c0, 0xc000139290, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...) /opt/gopath/src/github.com/hyperledger/fabric/core/scc/lscc/lscc.go:957 +0x1e8f github.com/hyperledger/fabric/core/chaincode/shim.(*Handler).handleTransaction.func1(0xc000275ec0, 0xc0001bcfc0, 0xc002479f80) /opt/gopath/src/github.com/hyperledger/fabric/core/chaincode/shim/handler.go:273 +0x4eb created by github.com/hyperledger/fabric/core/chaincode/shim.(*Handler).handleTransaction /opt/gopath/src/github.com/hyperledger/fabric/core/chaincode/shim/handler.go:242 +0x53 {code}  This makes more sense now. It was the system chaincode (not user chaincode) crashing trying to access some config which could be affected by malformed configtx.yaml.  Will assign to self for investigation.  ></body> </Action>
<Action id="64195" issue="42415" author="muralisr" type="comment" body="Also, I see this now in the image snapshot as well  ~soumyanayak  .... should have seen this earlier (in my defense, the full logs helped with search etc ;-) )." created="2019-09-29 14:34:37.0" updateauthor="muralisr" updated="2019-09-29 14:35:16.0"/>
<Action id="64249" issue="42415" author="muralisr" type="comment" created="2019-10-02 00:00:16.0" updateauthor="muralisr" updated="2019-10-02 00:00:16.0"> <body><! CDATA  ~jyellick  At minimum, thinking we need at least the following fix to *common/channelconfig/acls.go*  {code:java} @@ -26,7 +26,7 @@ func newAPIsProvider(acls map string *pb.APIResource) *aclsProvider { for key, acl := range acls { // If the policy is fully qualified, ie to /Channel/Application/Readers leave it alone // otherwise, make it fully qualified referring to /Channel/Application/policyName -               if acl.PolicyRef 0  != '/' { +               if len(acl.PolicyRef) > 0 && acl.PolicyRef 0  != '/' { aclPolicyRefs key  = "/" + ChannelGroupKey + "/" + ApplicationGroupKey + "/" + acl.PolicyRef } else { aclPolicyRefs key  = acl.PolicyRef {code}  Is the above sufficient or should we go deeper ?  It will be nice to catch badly formatted configtx.yaml at `configtxgen` time but we probably don't want to do this now.     ></body> </Action>
<Action id="64264" issue="42415" author="jyellick" type="comment" created="2019-10-02 13:59:48.0" updateauthor="jyellick" updated="2019-10-02 13:59:48.0"> <body><! CDATA  ~muralisr  I'd suggest a more explicit check:  {noformat} if len(acl.PolicyRef) == 0 { logger.Warningf("Policy reference for resource '%s' is specified, but empty, falling back to default", key) continue } {noformat}  It would also be nice to verify this during generation time, though as it's non-fatal, I'd prefer not to verify this at parse time (as changes to parsing logic are always a bit dangerous from a determinism perspective).  ></body> </Action>
<Action id="64376" issue="42415" author="muralisr" type="comment" created="2019-10-08 14:10:27.0" updateauthor="muralisr" updated="2019-10-08 14:10:27.0"> <body><! CDATA  _It would also be nice to verify this during generation time, though as it's non-fatal, I'd prefer not to verify this at parse time (as changes to parsing logic are always a bit dangerous from a determinism perspective)._    ~jyellick  If I understood that correctly, the suggestion is to verify it during configtxgen in the post-parsing phase ? In any case I vote we open a separate lower priority task for that.      ></body> </Action>
<Action id="64388" issue="42415" author="muralisr" type="comment" body="https://gerrit.hyperledger.org/r/#/c/fabric/+/33898/ for the runtime part of the fix" created="2019-10-08 14:54:08.0" updateauthor="muralisr" updated="2019-10-08 14:54:08.0"/>
<Action id="64696" issue="42415" author="soumyanayak" type="comment" body="Apart from runtime part of the fix - *Srinivasan  -* are you also providing the fix for configtxgen tool ?– like while generating the artifacts itself using configtxgen the error would show. " created="2019-10-14 13:09:38.0" updateauthor="soumyanayak" updated="2019-10-14 13:09:38.0"/>
