<Action id="65152" issue="42774" author="vijaypunugubati" type="comment" created="2019-10-29 17:45:23.0" updateauthor="vijaypunugubati" updated="2019-10-29 17:45:23.0"> <body><! CDATA The above error hit again in recent builds and the failure is occurring intermittently.Â  *Build logs:*  * |https://logs.hyperledger.org/production/vex-yul-hyp-jenkins-3/fabric-merge-end-2-end-x86_64/6625/Docker_Container_Logs/ * https://logs.hyperledger.org/production/vex-yul-hyp-jenkins-3/fabric-merge-end-2-end-x86_64/6625/Docker_Container_Logs/   Â    https://jenkins.hyperledger.org/view/fabric/job/fabric-merge-end-2-end-x86_64/6625/console   ></body> </Action>
<Action id="65185" issue="42774" author="vijaypunugubati" type="comment" created="2019-10-30 13:43:48.0" updateauthor="vijaypunugubati" updated="2019-10-30 13:43:48.0"> <body><! CDATA  https://logs.hyperledger.org/production/vex-yul-hyp-jenkins-3/fabric-merge-end-2-end-x86_64/6625/Docker_Container_Logs/orderer-default-channel.log.gz|https://logs.hyperledger.org/production/vex-yul-hyp-jenkins-3/fabric-merge-end-2-end-x86_64/6632/Docker_Container_Logs/orderer-default-channel.log.gz   *Error from the orderer-default-channel-log.* {code:java} / 36m2019-10-29 17:12:13.257 UTC  viperutil  getKeysRecursively -> DEBU 001 0m Found map interface{} interface{} value for general  36m2019-10-29 17:12:13.257 UTC  viperutil  unmarshalJSON -> DEBU 002 0m Unmarshal JSON: value cannot be unmarshalled: invalid character 'O' looking for beginning of value  36m2019-10-29 17:12:13.257 UTC  viperutil  getKeysRecursively -> DEBU 003 0m Found real value for general.LocalMSPID setting to string OrdererMSP  36m2019-10-29 17:12:13.257 UTC  viperutil  unmarshalJSON -> DEBU 004 0m Unmarshal JSON: value cannot be unmarshalled: invalid character '/' looking for beginning of value  36m2019-10-29 17:12:13.257 UTC  viperutil  getKeysRecursively -> DEBU 005 0m Found real value for general.GenesisFile setting to string /var/hyperledger/orderer/orderer.genesis.block/ code placeholder {code}  ></body> </Action>
<Action id="65364" issue="42774" author="wenjian" type="comment" created="2019-11-07 21:57:16.0" updateauthor="wenjian" updated="2019-11-09 14:08:41.0"> <body><! CDATA I did the tests on my laptop and 2 ubuntu VMs, but was not able to reproduce the problem.  Ran tests using a sandbox Jenkins job:Â  https://jenkins.hyperledger.org/sandbox/view/All/job/Wenijan/ .  Below is the observation. Although javaenv and nodeenv images have nothing to do with byfn tests, somehow pulling javaenv/nodeenv images seems to trigger the channel creation failure. I added a sleep (60s) after pulling javaenv/nodeenv images and before running byfn tests, the problem was fixed on the sandbox. # When the job did not include the build sections pulling javaenv or nodeenv, the byfn tests passed (no error) # When the job included the build sections pulling javaenv or nodeenv, the tests failed with creating channel error # After pulling javaenv and nodeenv, if I added 60s sleep, the byfn tests passed - (no error) ( https://jenkins.hyperledger.org/sandbox/view/All/job/Wenijan/19/consoleFull )  Why did a short sleep fix the problem? Probably some resources on the VM are not released immediately. After a short delay, these resources are released.Â   Â   ></body> </Action>
<Action id="65384" issue="42774" author="wenjian" type="comment" created="2019-11-08 14:10:26.0" updateauthor="wenjian" updated="2019-11-08 14:27:38.0"> <body><! CDATA Looked at the logs of all 5 orderers. There were the following warning.Â  {quote}orderer-default-channel.log:2019-11-07 20:47:59.911 UTC  orderer.consensus.etcdraft  run -> WARN 7df WAL sync took 2.8505559050000002 seconds and the network is configured to start elections after 5 seconds. Your disk is too slow and may cause loss of quorum and trigger leadership election. channel=byfn-sys-channel node=1  orderer3-default-channel.log:2019-11-07 20:47:59.995 UTC  orderer.consensus.etcdraft  run -> WARN 4de WAL sync took 2.934159198 seconds and the network is configured to start elections after 5 seconds. Your disk is too slow and may cause loss of quorum and trigger leadership election. channel=byfn-sys-channel node=3  orderer4-default-channel.log:2019-11-07 20:47:59.911 UTC  orderer.consensus.etcdraft  run -> WARN 4db WAL sync took 2.85021231 seconds and the network is configured to start elections after 5 seconds. Your disk is too slow and may cause loss of quorum and trigger leadership election. channel=byfn-sys-channel node=4  orderer5-default-channel.log:2019-11-07 20:47:59.879 UTC  orderer.consensus.etcdraft  run -> WARN 6cf WAL sync took 7.332300035 seconds and the network is configured to start elections after 5 seconds. Your disk is too slow and may cause loss of quorum and trigger leadership election. channel=byfn-sys-channel node=5 {quote} Â   and the leader was lost {quote}{{orderer5-default-channel.log:2019-11-07 20:47:28.551 UTC  orderer.consensus.etcdraft  logSendFailure -> ERRO 433 Failed to send StepRequest to 2, because: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing dial tcp 172.18.0.8:8050: connect: connection refused" channel=byfn-sys-channel node=5 orderer-default-channel.log:^  34m2019-11-07 20:47:56.592 UTC^}}{{ orderer.consensus.etcdraft  run -> INFO 765  0m raft.node: 1 lost leader 5 at term 2 channel=byfn-sys-channel node=1 orderer2-default-channel.log:^  34m2019-11-07 20:47:56.921 UTC  orderer.consensus.etcdraft  run -> INFO 4d5^  0m raft.node: 2 lost leader 5 at term 2 channel=byfn-sys-channel node=2 orderer3-default-channel.log:^  34m2019-11-07 20:47:57.061 UTC  orderer.consensus.etcdraft  run -> INFO 4d9^  0m raft.node: 3 lost leader 5 at term 3 channel=byfn-sys-channel node=3 orderer4-default-channel.log:^  34m2019-11-07 20:47:57.061 UTC  orderer.consensus.etcdraft  run -> INFO 4d6^  0m raft.node: 4 lost leader 5 at term 3 channel=byfn-sys-channel node=4 orderer5-default-channel.log:^  34m2019-11-07 20:47:59.882 UTC  orderer.consensus.etcdraft  run -> INFO 6dd^  0m raft.node: 5 lost leader 5 at term 3 channel=byfn-sys-channel node=5}} {quote} Â   new leader election: {quote}orderer5-default-channel.log:2019-11-07 20:47:28.561 UTC  orderer.consensus.etcdraft  becomeLeader -> INFO 45e 5 became leader at term 2 channel=byfn-sys-channel node=5  orderer2-default-channel.log:2019-11-07 20:47:59.913 UTC  orderer.consensus.etcdraft  becomeLeader -> INFO 506 2 became leader at term 3 channel=byfn-sys-channel node=2 {quote}  ></body> </Action>
<Action id="65408" issue="42774" author="wenjian" type="comment" created="2019-11-09 14:24:56.0" updateauthor="wenjian" updated="2019-11-09 14:24:56.0"> <body><! CDATA On the sandbox build, I have increased TickInterval from 500ms to 2000ms. However, it didn't fix the problem - channel creation still failed. Looking at the orderer logs, it was very slow (took 7s) for raft to send ConsensusRequest.Â   1. orderer started to handle the channel creation request {quote}  36m2019-11-08 14:05:17.736 UTC  orderer.common.cluster  NewStream -> DEBU 676^  0m Created new stream to orderer5.example.com:11050 with ID of 2 and buffer size of 10  ^  36m2019-11-08 14:05:17.736 UTC  orderer.consensus.etcdraft  submitSent -> DEBU 677^  0m Sending msg of 28517 bytes to 5 on channel byfn-sys-channel took 161.926Âµs  ^  36m2019-11-08 14:05:17.736 UTC  orderer.common.broadcast  ProcessMessage -> DEBU 678^  0m  channel: mychannel  Broadcast has successfully enqueued message of type CONFIG_UPDATE from 172.18.0.11:40656  ^  36m2019-11-08 14:05:17.737 UTC  orderer.common.cluster.step  sendMessage -> DEBU 679^  0m Send of SubmitRequest for channel byfn-sys-channel with payload of size 28517 to orderer5.example.com(orderer5.example.com:11050) took 810.439Âµs  ^  36m2019-11-08 14:05:17.740 UTC  orderer.common.broadcast  Handle -> DEBU 67a^  0m Received EOF from 172.18.0.11:40656, hangup  ^  36m2019-11-08 14:05:17.740 UTC  orderer.common.server  func1 -> DEBU 67b^  0m Closing Broadcast stream  Â  {quote} 2. in next 7 seconds, it kept waiting for ConsensusRequest, but got the following {quote}^  36m2019-11-08 14:05:17.746 UTC  orderer.common.server  Deliver -> DEBU 680^  0m Starting new Deliver handler  ^  36m2019-11-08 14:05:17.746 UTC  common.deliver  Handle -> DEBU 681^  0m Starting new deliver loop for 172.18.0.11:40658 ^  36m2019-11-08 14:05:17.746 UTC  common.deliver  Handle -> DEBU 682^  0m Attempting to read seek info message from 172.18.0.11:40658  ^  36m2019-11-08 14:05:17.947 UTC  common.deliver  deliverBlocks -> DEBU 683^  0m Rejecting deliver for 172.18.0.11:40658 because channel mychannel not found  ^  36m2019-11-08 14:05:17.947 UTC  orderer.common.server  func1 -> DEBU 684^  0m Closing Deliver stream {quote} 3. after 7 seconds, it receivedÂ ConsensusRequest {quote}^  36m2019-11-08 14:05:24.711 UTC  orderer.common.cluster.step  handleMessage -> DEBU 743^  0m Received message from orderer5.example.com(172.18.0.4:59408): ConsensusRequest for channel byfn-sys-channel with payload of size 28727  ^  36m2019-11-08 14:05:24.713 UTC  orderer.common.cluster.step  handleMessage -> DEBU 744^  0m Received message from orderer5.example.com(172.18.0.4:59408): ConsensusRequest for channel byfn-sys-channel with payload of size 28  ^  36m2019-11-08 14:05:24.728 UTC  orderer.common.server  replicateDisabledChains -> DEBU 745^  0m No inactive chains to try to replicate {quote} Â   Increasing channel creation timeout to 30s didn't fix the problem.Â Â   ></body> </Action>
<Action id="65409" issue="42774" author="wenjian" type="comment" created="2019-11-09 14:42:08.0" updateauthor="wenjian" updated="2019-11-11 15:49:21.0"> <body><! CDATA Summary of sandbox tests and results  Test 1: Jenkins job does not include the scripts that pull javaenv&nodeenv - no error * Result: byfn tests passed (no error)  Test 2: Jenkins job includes the scripts that pull javaenv&nodeenv * Result: channel creation failed  Test 3: Jenkins job includes the scripts that pull javaenv&nodeenv, increase TickInterval to 2000ms * Result: channel creation failed  Test 4: Jenkins job includes the scripts that pull javaenv&nodeenv, increase TickInterval to 2000ms & set 30s timeout for 'peer channel create' * Result: channel creation failed  Test 5: Jenkins job includes the scripts that pull javaenv&nodeenv, add 60s sleep in Jenkins job after pulling javaenv/nodeenv scripts and before running byfn - no error * Result: byfn tests passed (no error)  Test 6: Jenkins job includes the scripts that pull javaenv&nodeenv, increase wait time in byfn.sh from 15s to 60s - no error * Result: byfn tests passed (no error)  Â   Add clarification to the above results:  The following byfn tests were all passed with 60s sleep on the sandbox build.Â  * defaultchannel * customchannel * couchdb * javascriptchaincode  However, build still failed at sdk tests (after passing byfn tests) that was a different issue.  Â   Â   Â   Â   Â   ></body> </Action>
<Action id="65413" issue="42774" author="denyeart" type="comment" body=" ~btl5037  Got any insight on the environment slowness and if it has gotten worse recently? What difference would we expect in Azure Pipelines? I&apos;m hesitant to invest in this if we expect it to only be a problem on the infrastructure we are moving away from." created="2019-11-09 17:32:07.0" updateauthor="denyeart" updated="2019-11-09 17:32:07.0"/>
<Action id="65432" issue="42774" author="btl5037" type="comment" body="Personally, I don&apos;t see any stock in continuing triaging it, there are some interesting tidbits here (most of all the fact this failure started occurring after we upgraded the version of Go we are using). Our intent once we moved to AZP with Fabric was to kill off the BYFN job on merge anyway and replace it with Unit Tests. We could just as easily do that now (run Unit Test on merge)." created="2019-11-11 14:36:58.0" updateauthor="btl5037" updated="2019-11-11 14:36:58.0"/>
<Action id="65434" issue="42774" author="btl5037" type="comment" body=" ~wenjian  can you confirm for me, in the post above it says if you add 60s sleep after the pull then the tests pass, is this true? In particular, does the entire test run pass, not just the defaultChannel?" created="2019-11-11 15:06:25.0" updateauthor="btl5037" updated="2019-11-11 15:06:52.0"/>
<Action id="65435" issue="42774" author="wenjian" type="comment" created="2019-11-11 15:45:38.0" updateauthor="wenjian" updated="2019-11-11 15:51:45.0"> <body><! CDATA  ~btl5037  I meant the 'byfn tests' passed. In the sandbox jenkins job, it ran the following byfn tests and they were passed with 60s sleep. * defaultchannel * customchannel * couchdb * javascriptchaincode  However, the entire build still failed at sdk tests: {quote} *10:46:03* at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)  *10:46:03* at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161)  *10:46:03* at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290)  *10:46:03* at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242)*10:46:03* at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)  *10:46:03* Tests run: 50, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 790.368 sec <<< FAILURE! - in org.hyperledger.fabric.sdkintegration.IntegrationSuite*10:46:03* setup(org.hyperledger.fabric.sdkintegration.End2endNodeIT) Time elapsed: 23.219 sec <<< FAILURE!  *10:46:03* java.lang.AssertionError:  *10:46:03* Not enough endorsers for install :1. could not build chaincode: failed external (no builders defined) and docker build: docker image build failed: docker build failed: Error returned from build: 1 "+ INPUT_DIR=/chaincode/input Â  {quote}  ></body> </Action>
<Action id="65520" issue="42774" author="vijaypunugubati" type="comment" body=" https://gerrit.hyperledger.org/r/#/c/ci-management/+/34296/ " created="2019-11-13 16:11:26.0" updateauthor="vijaypunugubati" updated="2019-11-13 16:11:26.0"/>
