<Action id="68297" issue="44550" author="yacovm" type="comment" body="https://github.com/hyperledger/fabric/pull/847" created="2020-03-12 18:40:44.0" updateauthor="yacovm" updated="2020-03-12 18:40:44.0"/>
<Action id="68301" issue="44550" author="sykesm" type="comment" body="There were several races in gossip. Looks like PR 847 fixes the one in the gossip/gossip package but not the ones in the gossip/state package." created="2020-03-12 19:45:12.0" updateauthor="sykesm" updated="2020-03-12 19:45:12.0"/>
<Action id="68303" issue="44550" author="yacovm" type="comment" created="2020-03-12 20:00:19.0" updateauthor="yacovm" updated="2020-03-12 20:00:19.0"> <body><! CDATA I know, I am making a PR for every data race.     https://github.com/hyperledger/fabric/pull/849  ></body> </Action>
<Action id="68305" issue="44550" author="yacovm" type="comment" body="https://github.com/hyperledger/fabric/pull/850" created="2020-03-12 20:31:17.0" updateauthor="yacovm" updated="2020-03-12 20:31:17.0"/>
<Action id="68317" issue="44550" author="yacovm" type="comment" created="2020-03-14 12:15:59.0" updateauthor="yacovm" updated="2020-03-14 12:15:59.0"> <body><! CDATA When running *for d in `ls`; do cd $d; go test -race -count 1 .; cd .. ; done* it seems that all data races have been cleared.     It's still not possible to run gossip with *./gossip/...* due to (I guess) port conflicts, but can you confirm the data races have been solved,  ~sykesm  ?  ></body> </Action>
<Action id="68318" issue="44550" author="sykesm" type="comment" created="2020-03-14 13:31:37.0" updateauthor="sykesm" updated="2020-03-14 13:31:37.0"> <body><! CDATA Not on my end.  {code} ==================                                                                                                                                                                    WARNING: DATA RACE                                                                                                                                                                    Write at 0x00c006090a80 by goroutine 170:                                                                                                                                             github.com/hyperledger/fabric/gossip/discovery.(*gossipDiscoveryImpl).learnExistingMembers()                                                                                        /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/discovery/discovery_impl.go:840 +0x6ef                                                                   github.com/hyperledger/fabric/gossip/discovery.(*gossipDiscoveryImpl).handleAliveMessage()                                                                                          /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/discovery/discovery_impl.go:541 +0xcfd                                                                   github.com/hyperledger/fabric/gossip/discovery.(*gossipDiscoveryImpl).handleMsgFromComm()                                                                                           /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/discovery/discovery_impl.go:337 +0x8e8                                                                   github.com/hyperledger/fabric/gossip/discovery.(*gossipDiscoveryImpl).handleMessages()                                                                                              /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/discovery/discovery_impl.go:305 +0x18a                                                                    Previous read at 0x00c006090a80 by goroutine 151:                                                                                                                                     github.com/hyperledger/fabric/gossip/discovery.(*NetworkMember).String()                                                                                                            <autogenerated>:1 +0x77                                                                                                                                                         fmt.(*pp).handleMethods()                                                                                                                                                           /usr/local/go/src/fmt/print.go:630 +0x4bf                                                                                                                                       fmt.(*pp).printArg()                                                                                                                                                                /usr/local/go/src/fmt/print.go:713 +0x193                                                                                                                                       fmt.(*pp).doPrintln()                                                                                                                                                               /usr/local/go/src/fmt/print.go:1173 +0xad                                                                                                                                       fmt.Sprintln()                                                                                                                                                                      /usr/local/go/src/fmt/print.go:281 +0x5f                                                                                                                                        github.com/hyperledger/fabric/common/flogging.formatArgs()                                                                                                                          /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/common/flogging/zap.go:105 +0x50                                                                                github.com/hyperledger/fabric/common/flogging.(*FabricLogger).Warning()                                                                                                             /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/common/flogging/zap.go:79 +0x70                                                                                 github.com/hyperledger/fabric/gossip/discovery.(*gossipDiscoveryImpl).expireDeadMembers()                                                                                           /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/discovery/discovery_impl.go:731 +0x44a                                                                   github.com/hyperledger/fabric/gossip/discovery.(*gossipDiscoveryImpl).periodicalCheckAlive()                                                                                        /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/discovery/discovery_impl.go:697 +0x30c                                                                    Goroutine 170 (running) created at:                                                                                                                                                   github.com/hyperledger/fabric/gossip/discovery.NewDiscoveryService()                                                                                                                /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/discovery/discovery_impl.go:122 +0x937                                                                   github.com/hyperledger/fabric/gossip/gossip.New()                                                                                                                                   /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:131 +0x160a                                                                        github.com/hyperledger/fabric/gossip/gossip.newGossipInstanceWithGrpcMcsMetrics()                                                                                                   /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/gossip/gossip_test.go:249 +0x892                                                                         github.com/hyperledger/fabric/gossip/gossip.TestDataLeakage.func1()                                                                                                                 /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/gossip/gossip_test.go:1071 +0x385                                                                         Goroutine 151 (running) created at:                                                                                                                                                   github.com/hyperledger/fabric/gossip/discovery.NewDiscoveryService()                                                                                                                /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/discovery/discovery_impl.go:121 +0x912                                                                   github.com/hyperledger/fabric/gossip/gossip.New()                                                                                                                                   /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/gossip/gossip_impl.go:131 +0x160a                                                                        github.com/hyperledger/fabric/gossip/gossip.newGossipInstanceWithGrpcMcsMetrics()                                                                                                   /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/gossip/gossip_test.go:249 +0x892                                                                         github.com/hyperledger/fabric/gossip/gossip.TestDataLeakage.func1()                                                                                                                 /home/sykesm/workspace/fabric/src/github.com/hyperledger/fabric/gossip/gossip/gossip_test.go:1071 +0x385                                                                        ==================  {code}  ></body> </Action>
<Action id="68319" issue="44550" author="yacovm" type="comment" body="I&apos;m unable to reproduce it locally but I pushed  https://github.com/hyperledger/fabric/pull/859  which should fix it" created="2020-03-14 19:33:46.0" updateauthor="yacovm" updated="2020-03-14 19:33:46.0"/>
<Action id="68732" issue="44550" author="yacovm" type="comment" body=" ~sykesm  are they still failing for you?" created="2020-04-06 11:47:01.0" updateauthor="yacovm" updated="2020-04-06 11:47:01.0"/>
<Action id="68735" issue="44550" author="sykesm" type="comment" created="2020-04-06 12:47:04.0" updateauthor="sykesm" updated="2020-04-06 12:47:04.0"> <body><! CDATA > Matthew Sykes are they still failing for you?  Sort of. They're running out of memory now so I have no idea if they're racing.  {code} ==24719==ERROR: ThreadSanitizer failed to allocate 0x80000 (524288) bytes of clock allocator (error code: 12) FATAL: ThreadSanitizer CHECK failed: ./gotsan.cpp:7064 "((0 && "unable to mmap")) != (0)" (0x0, 0x0) {code}  ></body> </Action>
<Action id="68736" issue="44550" author="yacovm" type="comment" body="Did you run them package by package or together?" created="2020-04-06 12:54:38.0" updateauthor="yacovm" updated="2020-04-06 12:54:38.0"/>
<Action id="68737" issue="44550" author="sykesm" type="comment" created="2020-04-06 13:06:23.0" updateauthor="sykesm" updated="2020-04-06 13:06:23.0"> <body><! CDATA I was setting up to run the tests multiple times but it's failing consistently on the first run.  This is the command I used: {code} (ulimit -a; set -e; for i in $(seq 1 1); do echo $i; go test -race -p 1 -cover -count 1 ./gossip/...; done) {code}  Memory is "unlimited" and running on a machine with 8G. The {{-p 1}} flag ensures they are run package by package (sequentially).  {code} 2020-04-06 09:01:47.381 EDT  gossip.comm  sendToEndpoint -> WARN 1f5d Failed obtaining connection for 1.2.3.4:43495, PKIid:3132372e302e302e313a3433343935 reason: context deadline exceeded ==29898==ERROR: ThreadSanitizer failed to allocate 0x80000 (524288) bytes of clock allocator (error code: 12) FATAL: ThreadSanitizer CHECK failed: ./gotsan.cpp:7064 "((0 && "unable to mmap")) != (0)" (0x0, 0x0) FAIL	github.com/hyperledger/fabric/gossip/gossip	111.562s {code}  ></body> </Action>
<Action id="68738" issue="44550" author="sykesm" type="comment" created="2020-04-06 13:17:32.0" updateauthor="sykesm" updated="2020-04-06 13:17:32.0"> <body><! CDATA I got one good run. Make me think the memory issues show up when test assertions fail.  !screenshot-1.png|thumbnail!   ></body> </Action>
<Action id="68739" issue="44550" author="yacovm" type="comment" created="2020-04-06 14:31:04.0" updateauthor="yacovm" updated="2020-04-06 14:32:59.0"> <body><! CDATA {quote}I got one good run. Make me think the memory issues show up when test assertions fail.{quote}  If assertions fail it's likely due to the test being too slow, and this is because of race detector + everything running in parallel in the gossip package.      When I disable the parallelism of the tests in the package, things are smooth:  {code} yacovm@~/gopath/src/github.com/hyperledger/fabric (master) $ (ulimit -a; set -e; for i in $(seq 1 1); do echo $i; go test -race -p 1 -cover -count 1 ./gossip/...; done) core file size          (blocks, -c) 0 data seg size           (kbytes, -d) unlimited scheduling priority             (-e) 0 file size               (blocks, -f) unlimited pending signals                 (-i) 126387 max locked memory       (kbytes, -l) 64 max memory size         (kbytes, -m) unlimited open files                      (-n) 4096 pipe size            (512 bytes, -p) 8 POSIX message queues     (bytes, -q) 819200 real-time priority              (-r) 0 stack size              (kbytes, -s) 8192 cpu time               (seconds, -t) unlimited max user processes              (-u) 4096 virtual memory          (kbytes, -v) unlimited file locks                      (-x) unlimited 1 ok  	github.com/hyperledger/fabric/gossip/api	0.032s	coverage: 97.4% of statements ?   	github.com/hyperledger/fabric/gossip/api/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/comm	18.574s	coverage: 93.0% of statements ok  	github.com/hyperledger/fabric/gossip/comm/mock	0.174s	coverage: 81.1% of statements ok  	github.com/hyperledger/fabric/gossip/common	0.032s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/discovery	75.528s	coverage: 86.4% of statements ok  	github.com/hyperledger/fabric/gossip/election	7.022s	coverage: 94.4% of statements ok  	github.com/hyperledger/fabric/gossip/filter	0.185s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/gossip	147.050s	coverage: 85.6% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/algo	4.677s	coverage: 96.9% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/channel	16.250s	coverage: 92.3% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/msgstore	8.185s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/pull	2.795s	coverage: 92.6% of statements ok  	github.com/hyperledger/fabric/gossip/identity	12.200s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/metrics	0.034s	coverage: 100.0% of statements ?   	github.com/hyperledger/fabric/gossip/metrics/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/privdata	19.957s	coverage: 84.6% of statements ?   	github.com/hyperledger/fabric/gossip/privdata/common	 no test files  ?   	github.com/hyperledger/fabric/gossip/privdata/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/protoext	0.033s	coverage: 95.5% of statements ok  	github.com/hyperledger/fabric/gossip/service	82.087s	coverage: 83.8% of statements ?   	github.com/hyperledger/fabric/gossip/service/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/state	23.051s	coverage: 80.1% of statements ok  	github.com/hyperledger/fabric/gossip/state/mocks	0.185s	coverage: 55.6% of statements ok  	github.com/hyperledger/fabric/gossip/util	4.284s	coverage: 73.6% of statements  {code}   Diff: {code} diff --git a/gossip/gossip/anchor_test.go b/gossip/gossip/anchor_test.go index eadaf49cb..e6dcf9f81 100644 --- a/gossip/gossip/anchor_test.go +++ b/gossip/gossip/anchor_test.go @@ -159,7 +159,6 @@ func memResp(nonce uint64, endpoint string) *protoext.SignedGossipMessage { type msgInspection func(t *testing.T, index int, m *receivedMsg)  func TestAnchorPeer(t *testing.T) { -	t.Parallel() 	// Actors: 	// OrgA: { 	// 	p:   a real gossip instance @@ -267,7 +266,6 @@ func TestAnchorPeer(t *testing.T) { }  func TestBootstrapPeerMisConfiguration(t *testing.T) { -	t.Parallel() 	// Scenario: 	// The peer 'p' is a peer in orgA 	// Peers bs1 and bs2 are bootstrap peers. diff --git a/gossip/gossip/gossip_test.go b/gossip/gossip/gossip_test.go index faaf21403..624e81989 100644 --- a/gossip/gossip/gossip_test.go +++ b/gossip/gossip/gossip_test.go @@ -340,7 +340,6 @@ func (g *gossipGRPC) Stop() { }  func TestLeaveChannel(t *testing.T) { -	t.Parallel() 	// Scenario: Have 3 peers in a channel and make one of them leave it. 	// Ensure the peers don't recognize the other peer when it left the channel  @@ -386,7 +385,6 @@ func TestLeaveChannel(t *testing.T) { }  func TestPull(t *testing.T) { -	t.Parallel() 	t1 := time.Now() 	// Scenario: Turn off forwarding and use only pull-based gossip. 	// First phase: Ensure full membership view for all nodes @@ -477,7 +475,6 @@ func TestPull(t *testing.T) { }  func TestConnectToAnchorPeers(t *testing.T) { -	t.Parallel() 	// Scenario: spawn 10 peers, and have them join a channel 	// of 3 anchor peers that don't exist yet. 	// Wait 5 seconds, and then spawn a random anchor peer out of the 3. @@ -554,7 +551,6 @@ func TestConnectToAnchorPeers(t *testing.T) { }  func TestMembership(t *testing.T) { -	t.Parallel() 	t1 := time.Now() 	// Scenario: spawn 20 nodes and a single bootstrap node and then: 	// 1) Check full membership views for all nodes but the bootstrap node. @@ -642,7 +638,6 @@ func TestMembership(t *testing.T) { }  func TestNoMessagesSelfLoop(t *testing.T) { -	t.Parallel()  	port0, grpc0, certs0, secDialOpts0, _ := util.CreateGRPCLayer() 	boot := newGossipInstanceWithGRPC(0, port0, grpc0, certs0, secDialOpts0, 100) @@ -703,7 +698,6 @@ func TestNoMessagesSelfLoop(t *testing.T) { }  func TestDissemination(t *testing.T) { -	t.Parallel() 	t1 := time.Now() 	// Scenario: 20 nodes and a bootstrap node. 	// The bootstrap node sends 10 messages and we count @@ -835,7 +829,6 @@ func TestDissemination(t *testing.T) { }  func TestMembershipConvergence(t *testing.T) { -	t.Parallel() 	// Scenario: Spawn 12 nodes and 3 bootstrap peers 	// but assign each node to its bootstrap peer group modulo 3. 	// Then: @@ -940,7 +933,6 @@ func TestMembershipConvergence(t *testing.T) { }  func TestMembershipRequestSpoofing(t *testing.T) { -	t.Parallel() 	// Scenario: g1, g2, g3 are peers, and g2 is malicious, and wants 	// to impersonate g3 when sending a membership request to g1. 	// Expected output: g1 should *NOT* respond to g2, @@ -1015,7 +1007,6 @@ func TestMembershipRequestSpoofing(t *testing.T) { }  func TestDataLeakage(t *testing.T) { -	t.Parallel() 	// Scenario: spawn some nodes and let them all 	// establish full membership. 	// Then, have half be in channel A and half be in channel B. @@ -1158,7 +1149,6 @@ func TestDisseminateAll2All(t *testing.T) { 	// Ensure all blocks are received  	t.Skip() -	t.Parallel() 	stopped := int32(0) 	go waitForTestCompletion(&stopped, t)  @@ -1235,7 +1225,6 @@ func TestDisseminateAll2All(t *testing.T) { }  func TestSendByCriteria(t *testing.T) { -	t.Parallel()  	port0, grpc0, certs0, secDialOpts0, _ := util.CreateGRPCLayer() 	g1 := newGossipInstanceWithGRPC(0, port0, grpc0, certs0, secDialOpts0, 100) @@ -1393,7 +1382,6 @@ func TestSendByCriteria(t *testing.T) { }  func TestIdentityExpiration(t *testing.T) { -	t.Parallel() 	// Scenario: spawn 5 peers and make the MessageCryptoService revoke one of the first 4. 	// The last peer's certificate expires after a few seconds. 	// Eventually, the rest of the peers should not be able to communicate with @@ -1600,7 +1588,6 @@ func checkPeersMembership(t *testing.T, peers   *gossipGRPC, n int) func() bool }  func TestMembershipMetrics(t *testing.T) { -	t.Parallel()  	wg0 := sync.WaitGroup{} 	wg0.Add(1) diff --git a/gossip/gossip/orgs_test.go b/gossip/gossip/orgs_test.go index 1afc60d7c..879b2e922 100644 --- a/gossip/gossip/orgs_test.go +++ b/gossip/gossip/orgs_test.go @@ -143,7 +143,6 @@ func newGossipInstanceWithGRPCWithExternalEndpoint(id int, port int, gRPCServer }  func TestMultipleOrgEndpointLeakage(t *testing.T) { -	t.Parallel() 	// Scenario: create 2 organizations, each with 5 peers. 	// Both organizations will have an anchor peer each 	// The first 2 peers of each org would have an external endpoint, the rest won't. @@ -271,7 +270,6 @@ func TestMultipleOrgEndpointLeakage(t *testing.T) { }  func TestConfidentiality(t *testing.T) { -	t.Parallel() 	// Scenario: create 4 organizations: {A, B, C, D}, each with 3 peers. 	// Make only the first 2 peers have an external endpoint. 	// Also, add the peers to the following channels: {code}   We can just remove the parallelism and then we should be able to run with race detector.... what do you think?  ></body> </Action>
<Action id="68742" issue="44550" author="sykesm" type="comment" created="2020-04-06 17:39:25.0" updateauthor="sykesm" updated="2020-04-06 17:39:25.0"> <body><! CDATA I did a local change to my tree that removed all calls to {{t.Parallel()}} from the gossip packages.  {code}sed -i '/t.Parallel\(\)/d' $(ag -lQ 'Parallel()' ./gossip){code}  After doing that, I was able to run the tests with the race detector enabled (and without the {{-p 1}} flag) 10 times.  {code} $ (set -e; for i in $(seq 1 10); do echo $i; time go test -race -cover -count 1 ./gossip/...; done) ... real	4m2.906s user	4m56.582s sys	0m42.212s 10 ok  	github.com/hyperledger/fabric/gossip/api	0.046s	coverage: 97.4% of statements ?   	github.com/hyperledger/fabric/gossip/api/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/comm	55.240s	coverage: 93.0% of statements ok  	github.com/hyperledger/fabric/gossip/comm/mock	0.202s	coverage: 81.1% of statements ok  	github.com/hyperledger/fabric/gossip/common	0.020s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/discovery	244.676s	coverage: 86.4% of statements ok  	github.com/hyperledger/fabric/gossip/election	36.895s	coverage: 94.4% of statements ok  	github.com/hyperledger/fabric/gossip/filter	0.205s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/gossip	138.604s	coverage: 85.3% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/algo	19.315s	coverage: 96.9% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/channel	48.013s	coverage: 92.3% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/msgstore	20.195s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/pull	4.067s	coverage: 92.6% of statements ok  	github.com/hyperledger/fabric/gossip/identity	12.191s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/metrics	0.018s	coverage: 100.0% of statements ?   	github.com/hyperledger/fabric/gossip/metrics/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/privdata	35.224s	coverage: 84.6% of statements ?   	github.com/hyperledger/fabric/gossip/privdata/common	 no test files  ?   	github.com/hyperledger/fabric/gossip/privdata/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/protoext	0.029s	coverage: 95.5% of statements ok  	github.com/hyperledger/fabric/gossip/service	102.731s	coverage: 83.8% of statements ?   	github.com/hyperledger/fabric/gossip/service/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/state	93.501s	coverage: 79.5% of statements ok  	github.com/hyperledger/fabric/gossip/state/mocks	0.184s	coverage: 55.6% of statements ok  	github.com/hyperledger/fabric/gossip/util	4.266s	coverage: 73.6% of statements  real	4m7.472s user	4m53.421s sys	0m43.351s {code}  I believe removing the _parallel_ markers from the tests is the right thing to do. I don't think it hurts much in terms of execution time (likely much less than being forced to run packages sequentially) but does seem to increase the test stability. I'd support that change. On my system, the runs with parallel packages took just over 4 minutes (see above) while runs with serial packages take over 13m (see below).  {code} $ (set -e; for i in $(seq 1 1); do echo $i; time go test -race -p 1 -cover -count 1 ./gossip/...; done) 1 ok  	github.com/hyperledger/fabric/gossip/api	0.029s	coverage: 97.4% of statements ?   	github.com/hyperledger/fabric/gossip/api/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/comm	57.415s	coverage: 94.3% of statements ok  	github.com/hyperledger/fabric/gossip/comm/mock	0.203s	coverage: 81.1% of statements ok  	github.com/hyperledger/fabric/gossip/common	0.018s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/discovery	247.124s	coverage: 86.4% of statements ok  	github.com/hyperledger/fabric/gossip/election	36.579s	coverage: 94.4% of statements ok  	github.com/hyperledger/fabric/gossip/filter	0.191s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/gossip	139.102s	coverage: 85.6% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/algo	19.317s	coverage: 96.9% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/channel	48.011s	coverage: 92.3% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/msgstore	20.198s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/gossip/pull	4.068s	coverage: 92.6% of statements ok  	github.com/hyperledger/fabric/gossip/identity	12.192s	coverage: 100.0% of statements ok  	github.com/hyperledger/fabric/gossip/metrics	0.018s	coverage: 100.0% of statements ?   	github.com/hyperledger/fabric/gossip/metrics/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/privdata	35.070s	coverage: 84.6% of statements ?   	github.com/hyperledger/fabric/gossip/privdata/common	 no test files  ?   	github.com/hyperledger/fabric/gossip/privdata/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/protoext	0.039s	coverage: 95.5% of statements ok  	github.com/hyperledger/fabric/gossip/service	84.775s	coverage: 83.8% of statements ?   	github.com/hyperledger/fabric/gossip/service/mocks	 no test files  ok  	github.com/hyperledger/fabric/gossip/state	92.966s	coverage: 79.5% of statements ok  	github.com/hyperledger/fabric/gossip/state/mocks	0.181s	coverage: 55.6% of statements ok  	github.com/hyperledger/fabric/gossip/util	4.244s	coverage: 73.6% of statements  real	13m42.966s user	5m6.330s sys	0m39.795s {code}  If you think the conflicting port range issues have been addressed, I think we can remove gossip from the `serial packages` list in the unit test script as well.   ></body> </Action>
<Action id="68743" issue="44550" author="yacovm" type="comment" created="2020-04-06 17:46:56.0" updateauthor="yacovm" updated="2020-04-06 17:46:56.0"> <body><! CDATA I suggest we do 1 thing at a time... first remove parallelism and add the data race detection flag, wait a week and see if AZP likes it or not.  If things appear stable then we can try to not execute them serially.   ></body> </Action>
<Action id="68749" issue="44550" author="yacovm" type="comment" body="OK so in the meantime I will close this JIRA and we can see if data races pop again and then re-open it." created="2020-04-06 21:52:54.0" updateauthor="yacovm" updated="2020-04-06 21:52:54.0"/>
