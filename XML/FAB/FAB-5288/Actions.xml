<Action id="28236" issue="19210" author="jyellick" type="comment" created="2017-07-12 13:18:23.0" updateauthor="jyellick" updated="2017-07-12 13:18:23.0"> <body><! CDATA > A peer that has joined the channel has the latest configuration block i would need to obtain blocks 0.. i, i in order to start servicing requests,  This is obviously problematic if {{i}} is very large.  > from other peers or from the ordering service by pulling blocks in a descending order  This sounds to me, like the ledger needs to support writing to blockstorage in a non-append mode.  I am far from an expert in this area, so please  ~denyeart  or  ~manish-sethi  please correct me, but the on disk format for the blocks is essentially a binary log, which has a sequence of marshaled blocks, concatenated together.  Adding a new block implies appending to the log and adding an index into the DB so that the block may be looked up by offset index into the file.  Because of this, the notion of prepending a block seems quite difficult to me, as it would invalidate all of the existing indices (and of course, filesystems do not generally support graceful prepends, they instead require writing the whole file).  A workaround for this could be to store the blocks not in the standard block storage until the whole chain has been retrieved, and then commit using the usual methods until caught up.  But, this sounds like throwaway work to me.  The **correct** way to implement this IMO is to allow a peer to join a channel with, not only a config block, but also a state database snapshot.  We need to support pruning eventually, and this meshes quite naturally.  Of course, maybe the work required to support pruning is too large to contain before this particular issue needs to be fixed, but I am wary of coding up a fix with function we know will become obsolete within a release or two.  ></body> </Action>
<Action id="28241" issue="19210" author="yacovm" type="comment" created="2017-07-12 14:09:39.0" updateauthor="yacovm" updated="2017-07-12 14:09:53.0"> <body><! CDATA {quote}This is obviously problematic if {{i}} is very large. {quote} I agree, however - I think we need to take into account also: * the simplicity/complexity of the various solutions, and the time to market * The fact that in a way - the first approach listed is orthogonal to the ledger pruning. All we need is a way to make the peer configure itself using the latest config block.  I also think that we could make the peer pull all blocks starting from genesis at the regular order, and then just do the validation at the end, no?  {quote}This sounds to me, like the ledger needs to support writing to blockstorage in a non-append mode. I am far from an expert in this area, so please  ~denyeart  or  ~manish-sethi  please correct me, but the on disk format for the blocks is essentially a binary log, which has a sequence of marshaled blocks, concatenated together. Adding a new block implies appending to the log and adding an index into the DB so that the block may be looked up by offset index into the file. {quote} What if we could have 2 logs? After all - you only join a channel once, right?  So why not have 2 logs, given you joined the channel at configuration block *i* * A ledger that appends backwards from *i* to 0 * A ledger that appends forward from *i* onward  {quote}The **correct** way to implement this IMO is to allow a peer to join a channel with, not only a config block, but also a state database snapshot. We need to support pruning eventually, and this meshes quite naturally. Of course, maybe the work required to support pruning is too large to contain before this particular issue needs to be fixed, but I am wary of coding up a fix with function we know will become obsolete within a release or two. {quote} I also agree that if the snapshot approach is going to be implemented in the future release I don't think it's worth doing the reverse ledger one.  However - I think that there are numerous questions that arise here (and we should also discuss this approach of course): * Where do you take the snapshot from? I assume it can only be a peer, since the OSN doesn't hold the state, only a raw ledger * How do you export the ledger? I assume you can't use the underlying DBMS support because you would need to export the data into the same format regardless if the peer is using couchDB or levelDB or whatever it'll be in the future. * How do you trust the peer that gives you the snapshot? What do you do if several peers ask you for a snapshot at the same time? * How does the peer even perform the snapshot? Can both levelDB and couchDB support an export of the database while the system is running? * I guess the peers would need to agree deterministic-ally on when to prune their ledger, right? But what if you have i.e a peer with ledger up to 130, and the other peers pruned the ledger at block 200. It means the peer has to receive all the blocks from 130 up to 200 from the ordering service. I'm saying that IMO we should carefully design it (should we go down this path).   ~jyellick  could you please add a possible solution to the JIRA description that lists this solution of state snapshot?     ></body> </Action>
<Action id="28242" issue="19210" author="jyellick" type="comment" created="2017-07-12 14:35:47.0" updateauthor="jyellick" updated="2017-07-12 14:43:54.0"> <body><! CDATA Per request of  ~yacovm  here is a very rough suggestion for how pruning might be used in conjunction with the join of a config block.  I see a few different ways to approach this:  1. *Simplest:* Whenever a peer receives a config block for a channel, it takes a copy on write style snapshot of the state database.  The CSCC or other exposes some interface to retrieve the hash of this state snapshot, or the state snapshot itself.  When joining a new member, the member asks "enough" of the other members for the hash of the state snapshot at the most recent config block, and retrieves a copy of the state snapshot from someone.  Then the peer is told to join the channel with the config block, the hash, and the state.  The peer loads the state, verifies it against the hash, and is able to process further blocks based on the config block.  2. *More complex:* Same as (1), except instead of exposing the state snapshot via CSCC, allow the state snapshot to be gossiped, so that peer need only be bootstrapped with the config block and the hash of the state at that config block.  This makes it much much easier to bootstrap a new peer, but, the very significant downside to this is the DoS possibilities, and the fact that it is difficult to handle the byzantine attack of a peer sending bad state.  (Yes, you can detect it, but this implies retrieving an entire new copy of the world state, which might be quite large.  Therefore, retrieving the state snapshot from multiple members is problematic, as any one can poison the state snapshot with bad data but only the final result is detected to be bad, forcing an entirely new copy to be retrieved).  3. *Most complex:* When a config block for a channel is received, the peers take a snapshot, compute its hash, and sign some block metadata about the hash of the world state.  The peers then gossip about the hash, collecting eachother's signatures, and including them into their own block metadata.  The config block could have a policy added, like "SnapshotStateAttestations", which could be evaluated against the signature set to determine whether the threshold of signatures had been met.  Then, to join a channel, the peer would only need the config block (with its additional gossip-ed metadata) which already contains this hash, and a way to retrieve the state (either supplied manually as in (1), or automatically as in (2).  My gut feeling is that (1) or (3) with gossip of state would be best.  IE, with (1) the process is simple to understand, simple to implement, but out of band and fairly manual.  Or, with (3) + state gossip, the process is a bit magical, and complex, but, it would make joining a peer to 'catch up' as simple as joining one on a new channel.  Additionally, we could relax the conditions for taking a state snapshot if this is too burdensome, for instance only taking a state snapshot when a particular config property is changed.  So long as it is possible to determine if the config block should have a corresponding state snapshot, this is sufficient.  ----  Edit: I did not see Yacov's post until I had already added this one.  With respect to how the state snapshot is taken, this is obviously a question for the ledger team.  My assumption is that it is possible to take a state snapshot, in a copy-on-write manner.  So that the peer may continue functioning normally, but also access the state from this snapshot.  In v0.5/0.6, there were multiple backends for storing the world state, but peers were still able to share state deltas and snapshots, so I assume this is possible.  Maybe this is more difficult in the new architecture,  ~denyeart   ~manish-sethi ?  With respect to deciding how many snapshots to keep, and how often to take them, this seems like a fairly easily solvable problem.  We need a convention, and whether it is every config block, or only when some property changes, or the first config block which happens at least {{n}} blocks after the last snapshot was taken, etc., it shouldn't matter too much.  ></body> </Action>
<Action id="28244" issue="19210" author="denyeart" type="comment" body=" ~jyellick  I agree that the pulling blocks in descending order would be a large amount of complexity and work for little value.  There is a large amount of re-use if we can pull blocks in typical ascending order, starting from genesis block (or a checkpoint in the future), validating trans and populating state db as we go.  Then compare hashes with i when you get that far along.  In the rare anomaly case that the hashes don&apos;t line up then there has indeed been a lot of wasted work, but I don&apos;t think we should optimize for a rare anomaly." created="2017-07-12 14:49:16.0" updateauthor="denyeart" updated="2017-07-12 14:49:16.0"/>
<Action id="28302" issue="19210" author="yacovm" type="comment" created="2017-07-13 11:07:58.0" updateauthor="yacovm" updated="2017-07-13 11:20:42.0"> <body><! CDATA {quote}3. *Most complex:* When a config block for a channel is received, the peers take a snapshot, compute its hash, and sign some block metadata about the hash of the world state. The peers then gossip about the hash, collecting eachother's signatures, and including them into their own block metadata. The config block could have a policy added, like "SnapshotStateAttestations", which could be evaluated against the signature set to determine whether the threshold of signatures had been met. Then, to join a channel, the peer would only need the config block (with its additional gossip-ed metadata) which already contains this hash, and a way to retrieve the state (either supplied manually as in (1), or automatically as in (2). {quote}    So I think the general direction should be as you said but what do you think of the following changes: # The ledger of each channel tracks the total size (in bytes) of the blocks in it. # Once a block *i* made the size overgrow a certain *global per channel* threshold - a snapshot is taken in the following way: ## A ledger iterator object is initialized with a high isolation level that doesn't "see" older writes (I'm sure that in every KV store with versioning on the keys this has minimal performance overhead - start the iteration with a version number and then just return for each key the maximal version that is lower or equal to the version for the iteration) and simply scans the entire stateDB and writes it into a dump file in a certain format (this is to be independent of the underlying DB - whether it is couchDB or levelDB or something else. ## The dump is hashed. ## Gossip already publishes periodically a per-channel information that includes the height (in blocks) of a peer. This message is signed, and we could put into that message also the hash of the latest state snapshot. The last block index at which the state snapshot was taken can be inferred implicitly since it's a *global per channel property*. # When a peer from a new org (or also- not from a new org) joins the channel - it gets the latest config block, connects as usual to the other peers, and sees the hashes of the last state snapshot, and can apply some policy logic (i.e majority, hash must match its own org, etc.) to select the "correct" state hash, and then it can select any peer with that published state hash and start fetching this state hash from that peer (it can be done in chunks if it's too big). # at the end of the state replication - the peer hashes and compares the published hash to the actual hash, and if a mismatch is found - select a different peer and goes to (3).     What do you think  ~jyellick   (and others?)  ></body> </Action>
<Action id="28313" issue="19210" author="jyellick" type="comment" created="2017-07-13 14:19:01.0" updateauthor="jyellick" updated="2017-07-13 15:04:01.0"> <body><! CDATA > Once a block i made the size overgrow a certain global per channel threshold - a snapshot is taken in the following way:  I think taking the snapshot at arbitrary blocks rather than at config blocks has too many drawbacks to be feasible:  Drawback 1: Imagine a channel which is created, with two peers, one in each org. This channel gets used for a year without incident, and now has 1 million blocks. Because it is such a busy channel, the orgs decide to each add a new peer. Because the channel has not been reconfigured, the only config block available is the genesis block, so even though the new peers may fetch the state corresponding to block 1 mllion, they still have to retrieve all 1 million blocks between the last config block and the state snapshot, which rather defeats the entire purpose of the snapshot-ing.  Drawback 2: Imagine a channel with config block at block 100, and state snapshot taken at block 110. The new peer joins with config block 100, commits it to its ledger. Now, the ledger must have some sort of special commit path for recording blocks 101-110 without attempting to actually apply the transactions, then at block 110, the state snapshot is retrieved, and then when block 111 is committed, the traditional code path comes back into play. The peer basically is in a state of limbo where it is receiving and committing blocks, but does not have valid state.  Drawback 3: Imagine a channel with 1 million blocks, whose last state snapshot was taken at block 999,999,999. This channel adds a new member at block 1,000,001. The new member must join using this latest config block, but there is no state snapshot. The new member must wait for the chain size to be exceeded to publish a new state snapshot it can proceed from.  I would propose, that state snapshots _must_ be tied to config blocks, to avoid these three problems.  From an orderer perspective, our loose plans are to periodically prune the ledger at config blocks. This means the orderer will have to have some mechanism to automatically re-emit a config block. So, we could use the size based scheme of "Every X MB of blocks re-emit a config block". This would include an indication that this config block is intended as a pruning target, and the peers could cue off of this to trigger the state snapshot process.  >  (it can be done in chunks if it's too big).  I would propose that the neutral snapshot data format be designed with this in mind.  Rather than have a single large blob, it would make much more sense to construct this as something like a Merkle tree or simple hash table.  Then, instead of gossiping a single hash, the chunk hashes could be published, and the peer could safely retrieve small chunks from multiple peers and validate them individually (very much like standard p2p data distribution schemes).  In v0.5/0.6, with world states that grew to be sufficiently large, we constantly ran into timeouts or other problems which would cause the state transfer to fail, and then the entire large world state had to be discarded and pulled again.  Validating chunks as they arrive is a must in my head.  ></body> </Action>
<Action id="28360" issue="19210" author="yacovm" type="comment" created="2017-07-13 21:48:10.0" updateauthor="yacovm" updated="2017-07-13 21:49:04.0"> <body><! CDATA {quote}I think taking the snapshot at arbitrary blocks rather than at config blocks has too many drawbacks to be feasible: {quote} So actually the crux of my comment wasn't in this part but rather at the gossip part - specifically, that each peer would create a snapshot and compute its hash and publish it periodically.   I have nothing against the ordering service triggering a snapshot via a config update, I think it makes sense.   However (in my previous reply) I had envisioned it working by newly joined peers pulling blocks only from the sequences that their bootstrapping snapshots left off (i.e in the snapshot it'll be mentioned the sequence at which it was taken at, and the peer would start pulling blocks with sequence greater of that sequence). I guess that requires storing the latest config block in the file system and not in the ledger (otherwise it won't make any sense).  Correct me if I'm wrong but Drawbacks 1-2 don't apply for this (are there new drawbacks, however?)    {quote}Drawback 3: Imagine a channel with 1 million blocks, whose last state snapshot was taken at block 999,999,999. This channel adds a new member at block 1,000,001. The new member must join using this latest config block, but there is no state snapshot. The new member must wait for the chain size to be exceeded to publish a new state snapshot it can proceed from. {quote}  The idea, is that we snapshot every time the ledger increases in some threshold bytes, and this would induce a "size driven frequency" on the ledger and then every new org would always have some snapshot to start from, or from the genesis block - and in such a case it shouldn't long to replicate (else - a snapshot would've been taken).    {quote}From an orderer perspective, our loose plans are to periodically prune the ledger at config blocks {quote} I understand, and it indeed makes sense to sync the peer snapshot cycle with the orderer pruning cycle. {quote}Then, instead of gossiping a single hash, the chunk hashes could be published {quote} I don't see much sense in publishing the entire tree / list of hashes. It's redundant information that isn't useful to most peers in the network, but you're 100% right about the splitting into chunks and using hash approach. Instead, I think just the cumulative hash (or in the Merkle tree case - the root hash) should be published, and the joining peer could select (via a majority / other policy) the peers it wishes to replicate data with, and the hash list / Merkle tree would be obtained from these peers.     ></body> </Action>
<Action id="28933" issue="19210" author="binhn" type="comment" created="2017-07-24 21:12:10.0" updateauthor="binhn" updated="2017-07-24 21:46:46.0"> <body><! CDATA I agreed that we should use the latest configtx for joining channel so that the peer has the proper configuration to participate. The remaining task is to replicate the ledger.  Let's assume no snapshots for a moment; that means, we need to get the entire ledger, and in this case, we should send the files (rather than blocks). The joining peer wouldn't get blocks and trying to write to files; it should just get the files and store them. After that, it can rebuild the state DBs and validate blockhash.   With snapshots, I like Jason's idea of re-issuing configtx on snapshot block to simplify things. So at snapshot, we should cut the ledger file since the previous files might be archived and pruned. The replication process would remain the same: replicating files starting with the latest snapshot.  Thoughts?  ></body> </Action>
<Action id="28936" issue="19210" author="jyellick" type="comment" created="2017-07-24 21:58:58.0" updateauthor="jyellick" updated="2017-07-24 21:58:58.0"> <body><! CDATA > we should send the files (rather than blocks).  I like the simplicity of replicating files, however, this seems like a problem if different peers are using different ledger types?  It also seems a little brittle if we decide to add or deprecate a ledger type in the future.  What sort of ABI stability do we have for these database files? (IE, if two peers are using different levels of the same DB, can they safely share files?)   ~denyeart   ~manish-sethi  what do you think? How hard would a DB independent state snapshot format be to implement?  ~yacovm  do you see gossiping files like this as easier/comparable/harder than gossiping a purpose built state structure?  ></body> </Action>
<Action id="28939" issue="19210" author="yacovm" type="comment" created="2017-07-24 22:35:00.0" updateauthor="yacovm" updated="2017-07-24 22:47:20.0"> <body><! CDATA I'm not a storage engine expert but I don't think that replicating databases while they are active is something that works with a high probability. redo logs , index files, data files are changed while the database is running and mutating the files. You can't read atomically such a large amount of data without risking the read to return an overall inconsistent snapshot of the files.  The only way I think that you can replicate the data files is if you: #  put the database into some state where it appends data only to redo logs # flush the memory buffers # copy the files aside # change the DB back to the normal operation mode # replicate the files that were copied aside  Also Jason is right about the heterogeneity of the DBs.  {quote}Yacov Manevich do you see gossiping files like this as easier/comparable/harder than gossiping a purpose built state structure?{quote}  We shouldn't gossip these files but rather send them p2p like we do in state transfer.  The state transfer currently gossips blocks that are to us sequenced blobs.  ></body> </Action>
<Action id="28972" issue="19210" author="binhn" type="comment" created="2017-07-25 14:10:25.0" updateauthor="binhn" updated="2017-07-25 14:10:25.0"> <body><! CDATA  ~yacovm ,  ~jyellick ,  ~denyeart   The ledger stores blocks in append-only files then updates the DBs (state, history, private) from the transactions in the blocks. The append-only files were what I referred to because the peer can rebuild the DBs from these files.   ></body> </Action>
<Action id="28974" issue="19210" author="yacovm" type="comment" created="2017-07-25 14:19:19.0" updateauthor="yacovm" updated="2017-07-25 14:23:10.0"> <body><! CDATA {quote}The ledger stores blocks in append-only files then updates the DBs (state, history, private) from the transactions in the blocks. The append-only files were what I referred to because the peer can rebuild the DBs from these files. {quote}   I see, I misunderstood you.  But, if we use the latest config block for joining a channel and then rebuilding the DB from the ledger we have another problem which I stated in the description of the JIRA: {quote}Problem: In both cases you have the last config block that is used to join the channel, but it may contain different root CA certs than was used in the past, and so - old blocks that the peer would get from the orderer or from other peers would contain endorsements or signatures on the block that the corresponding certificates no longer have a certificate validation path to the latest config block that was used to join channel with.{quote}  This would essentially cause the peer that joined to reach a different state than the peers that are in the channel already, because it would deem some transactions as invalid while they were validated by the old peers.  I also listed a solution for that: {quote}I assume that if we could make the validation code (VSCC) in the peer use the config blocks on the chain, and not the config block that was used to call join channel with, it would be solved.{quote}    ></body> </Action>
<Action id="28984" issue="19210" author="binhn" type="comment" created="2017-07-25 17:31:33.0" updateauthor="binhn" updated="2017-07-25 17:31:33.0"> <body><! CDATA  ~yacovm   yes, we would need new validation code to pick up the configtx from the ledger, but keep the latest configtx to connect to orderers or other orgs.    If we had quorum validation (part of checkpoint), we could assume the transaction validity and only check the block hashes (from genesis/snapshot block to the current config block)  ></body> </Action>
<Action id="28987" issue="19210" author="jyellick" type="comment" created="2017-07-25 18:14:52.0" updateauthor="jyellick" updated="2017-07-25 18:14:52.0"> <body><! CDATA > I assume that if we could make the validation code (VSCC) in the peer use the config blocks on the chain, and not the config block that was used to call join channel with, it would be solved.  My biggest issue with this, is that we take a critical, already complex code path (transaction validation) which must absolutely always be 100% deterministic, and we add more complexity, with more conditional branching, and introduce more opportunities for non-determinism.  We certainly can do this correctly, but I question the value of putting too much effort into this.  If we implement proper pruning/checkpointing, we can have a new peer join at the most recent config block, fetch a state snapshot for that block, and then simply follow the normal validation process forward.  This has no fetching of older blocks, no out of order committing, no new transaction validation path etc.  Since, we have to implement pruning/checkpointing at some point in the near future anyway, it seems more natural to apply development effort towards that goal, and greatly simplify this work.  ></body> </Action>
<Action id="28990" issue="19210" author="yacovm" type="comment" created="2017-07-25 19:48:17.0" updateauthor="yacovm" updated="2017-07-25 19:49:53.0"> <body><! CDATA {quote}My biggest issue with this, is that we take a critical, already complex code path (transaction validation) which must absolutely always be 100% deterministic, and we add more complexity, with more conditional branching, and introduce more opportunities for non-determinism.{quote}  I don't see the issue. we don't need to change anything in the validation code. Nothing at all.  We just need to be able to control the MSP manager instance of the channel - instead of having just 1 MSP manager per channel - have 2 of them:  * One that is always initialized according to the latest config block received that'll be used for communication * One that is always initialized with the genesis block and is updated as things work now. what am I missing?  {quote}Since, we have to implement pruning/checkpointing at some point in the near future anyway, it seems more natural to apply development effort towards that goal, and greatly simplify this work.{quote} I put the 2 options on the table so it can be decided, but I think that doing this one is not much work and pruning and snapshotting is much work and also additional integration work (p2p overhead right?)  I personally do not have any strong opinion about which decision to take, or time-lines.  I just want to lay out the options and ensure we see all options before us, and their drawbacks, etc.  ></body> </Action>
<Action id="28996" issue="19210" author="jyellick" type="comment" created="2017-07-26 02:25:15.0" updateauthor="jyellick" updated="2017-07-26 02:25:15.0"> <body><! CDATA > I don't see the issue. we don't need to change anything in the validation code. Nothing at all. We just need to be able to control the MSP manager instance of the channel - instead of having just 1 MSP manager per channel - have 2 of them:  This is nearly right, you would also need to maintain a second copy of the policy manager to ensure that the correct policy definition is being used in addition to the correct crypto material.  Then we need to make sure that in whatever context we validate signatures or evaluate policies, that we have the correct pair in use.  I don't think this is impossible, but having already taken one stab at removing the singleton MSP manager from the code (and failing), I think this is much more invasive than might sanely be expected.  The again, maybe this is a good occasion to rid ourselves of some of these anti-patterns.  > I put the 2 options on the table so it can be decided, but I think that doing this one is not much work and pruning and snapshotting is much work and also additional integration work (p2p overhead right?)  Understood.  Obviously I'm skeptical about the multiple validation contexts being "not much work", but I would be happy to be wrong.  ></body> </Action>
<Action id="29004" issue="19210" author="yacovm" type="comment" created="2017-07-26 07:21:24.0" updateauthor="yacovm" updated="2017-07-26 07:21:36.0"> <body><! CDATA {quote}This is nearly right, you would also need to maintain a second copy of the policy manager to ensure that the correct policy definition is being used in addition to the correct crypto material. Then we need to make sure that in whatever context we validate signatures or evaluate policies, that we have the correct pair in use.{quote}  Of course, I was sure it's implicitly deduced since the MSP is updated via the policy manager so you'll need a new one for the new MSP.     ></body> </Action>
<Action id="29041" issue="19210" author="jyellick" type="comment" created="2017-07-26 15:15:15.0" updateauthor="jyellick" updated="2017-07-26 15:15:15.0"> <body><! CDATA > Of course, I was sure it's implicitly deduced since the MSP is updated via the policy manager so you'll need a new one for the new MSP.  Not to nit-pick, but this is still not accurate.  The standard {{msp.MSPManager}} type is not mutable.  However, it is embedded as a member of the {{config/msp}} {{msp.MSPConfigHandler}}.  In general, pieces of the system retain a reference to this {{msp.MSPConfigHandler}} as an {{msp.MSPManager}}, in this way, when the underlying manager changes, their reference does not need to be updated.  The {{msp.MSPConfigHandler}} is updated by the {{configtx.ManagerImpl}}.  The {{policies.ManagerImpl}} is initialized with a {{policies.Provider}} map, one of which is for signature policies, which depends upon a reference to a {{msp.MSPManager}}.  This reference is actually given as the {{msp.MSPConfigHandler}} so that the reference is to the current {{msp.MSPManager}} on update.  Finally, the {{policies.ManagerImpl}} has the policies maintained via the {{configtx.ManagerImpl}}.  Although a little complex, simply maintaining two copies of this entire setup should be possible with no real problems.  The place where things get very difficult is with the {{msp.mgmt}} singletons.  Essentially, when a JoinChannel occurs, the peer takes the {{msp.MSPConfigHandler}} from the config, and sets it as the {{msp.MSPManager}} in the {{msp.mgmt}} singletons.  Then, the peer looks up the MSP manager via these singletons (rather than actually retaining a reference to the channel resources, and pulling the {{msp.MSPManager}} from there.  So the real question is, for all of those contexts which are actually using the {{msp.mgmt}} singletons, how do you route them to the correct {{msp.MSPManager}}?    ></body> </Action>
<Action id="30599" issue="19210" author="davidkhala" type="comment" created="2017-09-07 02:52:13.0" updateauthor="davidkhala" updated="2017-09-07 02:52:13.0"> <body><! CDATA It seems this work-flow bother me too. In my case, a new peer is created with new MSP and propose a channel update with this new MSP.  Then I tried to do 'join-channel' for the the newly created peer and it even succeeded(with the genesis block) But in next step to instantiate chaincode on this new peer, error occurred like:  {code:java} Error: Failed to deserialize creator identity, err MSP AMMSP is unknown {code}    ></body> </Action>
<Action id="48383" issue="19210" author="clayton sims" type="comment" body="This is related to Fab 106.   It is not in plan for 1.3" created="2018-08-03 14:58:06.0" updateauthor="clayton sims" updated="2018-08-03 14:58:06.0"/>
<Action id="57664" issue="19210" author="jyellick" type="comment" body=" ~mastersingh24  I think this is something you could tackle with some dialer/TLS overrides pretty easily?" created="2019-02-27 19:36:40.0" updateauthor="jyellick" updated="2019-02-27 19:36:40.0"/>
<Action id="57670" issue="19210" author="mastersingh24" type="comment" created="2019-02-27 21:31:12.0" updateauthor="mastersingh24" updated="2019-02-27 21:31:12.0"> <body><! CDATA I think we can do the following:  1) Add a a config section which allows you to specify a set of root CAs to trust for TLS communication with orderers which would be appended in addition to the list created from the config block 2) We can also add a config section which allows you to map orderer:port to a different orderer:port as well.  ></body> </Action>
<Action id="57671" issue="19210" author="jyellick" type="comment" body="Sounds good to me +1" created="2019-02-27 21:48:11.0" updateauthor="jyellick" updated="2019-02-27 21:48:11.0"/>
<Action id="57837" issue="19210" author="denyeart" type="comment" body=" ~mastersingh24  I set the FixVersion for v1.4.1 and v2.0 for the tactical approach mentioned here, is that your intent?" created="2019-03-04 16:04:31.0" updateauthor="denyeart" updated="2019-03-04 16:04:31.0"/>
<Action id="58444" issue="19210" author="denyeart" type="comment" created="2019-03-22 12:11:33.0" updateauthor="denyeart" updated="2019-03-22 12:11:33.0"> <body><! CDATA I've updated the title of this jira to indicate the tactical approach of allowing peer to override channel configuration, specifically orderer end points and root CAs to trust.  Alternatively a separate jira could be created for the tactical approach and we could revert back to the original name... either way is fine by me...  ></body> </Action>
<Action id="60456" issue="19210" author="denyeart" type="comment" created="2019-05-29 10:31:11.0" updateauthor="denyeart" updated="2019-06-10 12:06:40.0"> <body><! CDATA Note that TLS cert overrides went into v1.4.1 under  FAB-14420.  Need to port to master.  Also need to consider orderer endpoint overrides.  ></body> </Action>
<Action id="61465" issue="19210" author="baohua" type="comment" created="2019-07-04 01:44:19.0" updateauthor="baohua" updated="2019-07-04 01:44:19.0"> <body><! CDATA Some simple solution by using core.yaml config, the steps are like the following: # Allow peer to read the config (tls, endpoints, etc) from core.yaml and ignore what is specified in the config block when joined a channel; # In core.yaml, also specify some block height that once the local ledger size is larger than that, then switch to use the channel config.  ></body> </Action>
<Action id="65929" issue="19210" author="denyeart" type="comment" body=" ~mastersingh24  I&apos;ve linked the Jiras for orderer endpoint override and TLS cert override. What else is intended for this Jira specifically?" created="2019-12-02 20:41:23.0" updateauthor="denyeart" updated="2019-12-02 20:41:23.0"/>
<Action id="69552" issue="19210" author="denyeart" type="comment" body="Note - the overrides were finished in FAB-16544." created="2020-06-25 10:32:38.0" updateauthor="denyeart" updated="2020-06-25 10:32:38.0"/>
