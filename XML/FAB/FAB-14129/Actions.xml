<Action id="56843" issue="37556" author="yacovm" type="comment" body=" ~guoger " created="2019-02-11 13:34:56.0" updateauthor="yacovm" updated="2019-02-11 13:34:56.0"/>
<Action id="56845" issue="37556" author="guoger" type="comment" created="2019-02-11 14:16:32.0" updateauthor="guoger" updated="2019-02-11 15:53:39.0"> <body><! CDATA Seems that the same block is proposed twice... although I don't see an obvious reason. My plan is to submit a patch to add more debug logs, and when this problem surfaces again, we can have more info.  https://gerrit.hyperledger.org/r/29236 does this (no change to status of this CR)  ></body> </Action>
<Action id="56850" issue="37556" author="yacovm" type="comment" created="2019-02-11 14:36:26.0" updateauthor="yacovm" updated="2019-02-11 14:36:26.0"> <body><! CDATA {quote}The three orderer log are attached.{quote}  ~scottz  is it possible to get the full logs since the startup? The logs attached are about - 1 second of runtime...   ></body> </Action>
<Action id="57038" issue="37556" author="guoger" type="comment" created="2019-02-14 13:41:54.0" updateauthor="guoger" updated="2019-02-14 13:41:54.0"> <body><! CDATA My proposal for this: 1) merge https://gerrit.hyperledger.org/r/c/29236/3 so that if orderers crash again during other svt tests, due to the same reason, we have more info to investigate 2) put more defensive checks against replay of block. However hold off merging it for a little while, to see if this error can eventually happen again, so we can diagnose.  cc  ~kchristidis  ~yacovm  ~dongming   ></body> </Action>
<Action id="57269" issue="37556" author="kchristidis" type="comment" created="2019-02-18 22:45:35.0" updateauthor="kchristidis" updated="2019-02-18 22:45:35.0"> <body><! CDATA Jay's CR for better logging/diagnostic has been merged.  Until this issue re-occurs and we have full logs to go along with it, I'm marking it as Unverified.  ></body> </Action>
<Action id="57271" issue="37556" author="scottz" type="comment" created="2019-02-18 23:23:07.0" updateauthor="scottz" updated="2019-02-18 23:23:07.0"> <body><! CDATA We are keeping an eye on traffic runs in k8s lab for this, as we try to reproduce another bug, just in case we this one resurface.  It is doubtful, because with 10 IOPS per GB in that cluster, we have not seen it occur yet. The original problem was twice seen in a lab with slower disk read/writes (2 IOPS per GB), so  ~dongming  let's go back to a cluster like that to try to reproduce this with some more traffic runs and appropriate logs enabled.   ></body> </Action>
<Action id="57324" issue="37556" author="suryalnvs" type="comment" created="2019-02-19 21:12:54.0" updateauthor="suryalnvs" updated="2019-02-19 21:13:47.0"> <body><! CDATA Reproduced this issue twice when running FAB-14220 with IOPS 2 per GB within like 200 to 300 blocks. All orderers are crashing with same error {code:java} panic:  channel: testorgschannel3  Could not append block: block number should have been 228 but was 227.{code} Attached the zip of all orderer logs.  ></body> </Action>
<Action id="57345" issue="37556" author="guoger" type="comment" created="2019-02-20 09:23:03.0" updateauthor="guoger" updated="2019-02-20 09:23:03.0"> <body><! CDATA Added an integration test to reproduce this https://gerrit.hyperledger.org/r/c/29400  This is fixed in https://gerrit.hyperledger.org/r/c/29363  ></body> </Action>
<Action id="57491" issue="37556" author="kchristidis" type="comment" body="Current status: expecting a new SVT run to confirm that this is fixed." created="2019-02-23 20:44:36.0" updateauthor="kchristidis" updated="2019-02-23 20:44:36.0"/>
<Action id="57525" issue="37556" author="kchristidis" type="comment" body=" ~suryalnvs  confirms the issue is fixed." created="2019-02-25 03:42:24.0" updateauthor="kchristidis" updated="2019-02-25 03:42:24.0"/>
