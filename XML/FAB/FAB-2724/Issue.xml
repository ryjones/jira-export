<Issue id="15292" key="FAB-2724" number="2724" project="10002" reporter="denyeart" assignee="balaji.viswanathan" creator="denyeart" type="10004" summary="CouchDB - max number of connections issue during stress test" priority="1" resolution="10000" status="6" created="2017-03-10 13:07:57.0" updated="2018-07-20 14:11:58.0" resolutiondate="2017-04-25 10:53:03.0" votes="0" watches="6" workflowId="37749"> <description><! CDATA The issue of peer refusing to accept Txns from chaincode, followed by Txn timeout was due to couchdb hitting a max of 2048 connections. Couch uses mochiweb an erlang http library for its chttpd component.  The parameters in couch configuration for this are server_options http://docs.couchdb.org/en/2.0.0/config/http.html#httpd/server_options and defaults to max of 2048 connections. You can modify this to something like following and restart couch container.  /opt/couchdb/etc/local.ini server_options =  {backlog, 128}, {acceptor_pool_size, 16}, {max, 4096}   Doubling this will approximately double the number of Txn which go through, but not solve the problem completely.  The test was a script invoking 'initMarble' in a tight loop to insert 1000 marbles into couch. After around 200 or so invokes, the peer stopped responding and peer started timing out for all new transactions. The peer is stuck in a REST call to couch, all external REST to couchdb also wait/hang at this point. The number of connections on couchdb from peer hits ~2048 (verified using netstat) and doesn't clearup for quite a while. After mins when peer is idle, the #connections start coming down (ESTABLISHED -> TIMEWAIT). The client can then resubmit to peer.  golang net/http uses a Transport which does connection pooling (at transport level). And also golang http-client uses HTTP/1.1 for all requests to Couch. However, the number of connections keep increasing and most connections go into TIME_WAIT state before being released. If HTTP/1.1 is used and connections are reused, then we should not see this issue. likely that is not the case. net/http retains 100 idle connection in its pool, but i am not sure if its being exercised in this case.  Though this is likely a *stress* test scenario, i think a initial load of assets might have similar behaviour and/or when we have multiple chaincodes/channels on a peer. So, it's worth investigating.  ></description> </Issue>
