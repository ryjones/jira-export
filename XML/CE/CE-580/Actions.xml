<Action id="58129" issue="38421" author="baohua" type="comment" created="2019-03-14 01:12:54.0" updateauthor="baohua" updated="2019-03-14 01:12:54.0"> <body><! CDATA Hi  Please help include: * Code version * OS type * Step to repeat the issue.  Thanks!  ></body> </Action>
<Action id="58233" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-17 15:37:11.0" updateauthor="arindambhattacharjee" updated="2019-03-17 15:37:11.0"> <body><! CDATA Hello Baohua,     Thanks for your response.  I have successfully installed cello in my machine.  But now the issue is I can not create chain through user-dashboard (screenshot attached), even the chain health in Operator-Dashboard is showing as FAIL (screenshot attached ).     Logs screenshots are also attached.   Can you please help me on this, I'm doing a PoC on Cello to demonstrate the same.     CODE VERSION is Latest OS - UBUNTU 18.04     Please let me know if you need any more information.     Thanks,  Arindam  ></body> </Action>
<Action id="58235" issue="38421" author="baohua" type="comment" created="2019-03-18 01:55:48.0" updateauthor="baohua" updated="2019-03-18 01:55:48.0"> <body><! CDATA The chain is unhealthy, it means something wrong with the worker node.  Can you check your worker node to see the logs of all containers?  ></body> </Action>
<Action id="58236" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-18 04:23:48.0" updateauthor="arindambhattacharjee" updated="2019-03-18 04:23:48.0"> <body><! CDATA I have setup the worker node mentioned in documents. Like make setup-worker etc. Also checked that docker containers at worker node end are not running.  Can you please let me know what needs to be done at worker nodes end?  ></body> </Action>
<Action id="58241" issue="38421" author="baohua" type="comment" created="2019-03-18 12:24:26.0" updateauthor="baohua" updated="2019-03-18 12:24:26.0"> <body><! CDATA If no containers in worker node are running, then potential reasons could be: * master node failed to run service when create chain, there should be error log; * master node cannot access worker node's management api, this can be validated manually; * worker node does not have a valid docker environment.  ></body> </Action>
<Action id="58242" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-18 12:28:57.0" updateauthor="arindambhattacharjee" updated="2019-03-18 12:28:57.0"> <body><! CDATA both of the master node and worker node is present at Ubuntu 18.04/ master node is up and running. even when I was trying to create chain i got the below response : -   cello-operator-dashboard |  2019-03-18 12:17:40,887  INFO  resources.cluster_api   cluster_api.py:326 cluster_list()  -  {'status': 'creating', 'create_ts': 1552911460.0, 'id': '5185556299714939baaa9016ad1acd9d', 'network_typeCreating 5185556299714939baaa9016ad1acd9d_ca_org2 ... done grpc': 7450, 'peer0_org2_event': 7550, 'peer1_org2_grpc': 7650, 'peer1_org2_event': 7750, 'ca_org1_ecap': 7850, 'ca_org2_ecap': 7950, 'orderer': 8050}, 'service_url': {}, 'containers':   , 'health': '', 'apply_ts': None, 'service_ports':   , 'host': 'worker', 'name': 'chain01', 'release_ts': None, 'api_url': None, 'worker_api': 'tcp://172.16.1.6:2375', 'user_id': '', 'duration': None}  cello-operator-dashboard |  2019-03-18 12:17:40,958  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster Creating 5185556299714939baaa9016ad1acd9d_peer0_org2 ... done cello-operator-dashboard | Creating 5185556299714939baaa9016ad1acd9d_ca_org2 ... cello-operator-dashboard | Creating 5185556299714939baaa9016ad1acd9d_orderer ... Creating 5185556299714939baaa9016ad1acd9d_peer0_org1 ... done cello-operator-dashboard | Creating 5185556299714939baaa9016ad1acd9d_peer1_org2 ... cello-operator-dashboard | Creating 5185556299714939baaa9016ad1acd9d_peer0_org2 ... cello-operator-dashboard | Creating 5185556299714939baaa9016ad1acd9d_peer0_org1 ...  2019-03-18 12:17:46,057  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster        But after that chain Health is showing as FAIL, peer and ordering services are getting created successfully, but getting health status as failed.     Please help me on the troubleshooting the problem.  ></body> </Action>
<Action id="58262" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-18 17:00:55.0" updateauthor="arindambhattacharjee" updated="2019-03-18 17:00:55.0"> <body><! CDATA All the time it's showing cluster creation is OK and after that it's showing that cluster id not found, please find the below log : -      cello-operator-dashboard |  2019-03-18 16:59:36,957  INFO  modules.cluster   cluster.py:256 _create_cluster()  - Create cluster OK, id=da0ef8b670e04c2fb9dd00cf3a687689 cello-operator-dashboard |  2019-03-18 16:59:37,887  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-18 16:59:37,900  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-18 16:59:39,213  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-18 16:59:39,224  WARNING  modules.cluster   cluster.py:110 get_by_id()  - No cluster found with id=297256b64c594612a51e38c30adba5a2 cello-operator-dashboard |  2019-03-18 16:59:39,225  WARNING  modules.cluster   cluster.py:849 refresh_health()  - Cannot found cluster id=297256b64c594612a51e38c30adba5a2 cello-watchdog |  2019-03-18 16:59:40,161  INFO  __main__   watchdog.py:123 watch_run()  - Watchdog run checks with period = 15 s  ></body> </Action>
<Action id="58263" issue="38421" author="arindambhattacharjee" type="comment" body="If it&apos;s possible, can you please provide me the stable version of cello ( which has something stable to create chain and run chaincodes for demo purposes ) " created="2019-03-18 17:05:57.0" updateauthor="arindambhattacharjee" updated="2019-03-18 17:05:57.0"/>
<Action id="58277" issue="38421" author="baohua" type="comment" created="2019-03-19 01:38:43.0" updateauthor="baohua" updated="2019-03-19 01:38:43.0"> <body><! CDATA v0.9.0 is the latest stable version.  From the logs, seems the master node cannot create chain at the worker node.  I doubt the reason might be the master cannot call the docker API in the worker node, can you verify that?  Besides, you may collect the master node's logs at the moment of creating a chain, there can be some errors if not started successfully.  ></body> </Action>
<Action id="58279" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-19 05:00:44.0" updateauthor="arindambhattacharjee" updated="2019-03-19 05:00:44.0"> <body><! CDATA I have two different nodes - master and worker. Why mastet is not able to call the API, then maybe there is some bugs in the code, even I checked that HIGHTALL has pushed some code in GitHub as well newly, that could be the reason also, if I tried with standalone, the issue will be the same.  Please help me on this.   ></body> </Action>
<Action id="58328" issue="38421" author="baohua" type="comment" created="2019-03-20 08:05:55.0" updateauthor="baohua" updated="2019-03-20 08:06:08.0"> <body><! CDATA  ~ArindamBhattacharjee , can you help run some debug command to verify the docker api first?  e.g., docker -h x.x.x.x:2375 info.  Which will call the docker api and get response.  ></body> </Action>
<Action id="58329" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-20 08:09:32.0" updateauthor="arindambhattacharjee" updated="2019-03-20 08:09:32.0"> <body><! CDATA Hello Baohua,     It's working and able to fetch the details of worker, even I have added the worker host in the cello dashboard.     Thanks,  Arindam  ></body> </Action>
<Action id="58336" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-20 11:41:26.0" updateauthor="arindambhattacharjee" updated="2019-03-20 11:41:26.0"> <body><! CDATA See the below output of the docker API : -      docker -H 172.16.XX.XX:2375 info Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 31 Server Version: 18.09.3 Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: e6b3f5632f50dbc4e9cb6288d911bf4f5e95b18e runc version: 6635b4f0c6af3810594d2770f662f34ddc15b40d init version: fec3683 Security Options: apparmor seccomp Profile: default Kernel Version: 4.18.0-1013-azure Operating System: Ubuntu 18.04.2 LTS OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 1.883GiB Name: SABCHAINPOCWORKER01 ID: ALSX:PYOK:TE2W:C3XZ:T3CK:G6UB:LJOM:NFGV:7VX7:U74W:IOUV:67OQ Docker Root Dir: /blockchain/docker Debug Mode (client): false Debug Mode (server): false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Live Restore Enabled: false Product License: Community Engine  WARNING: API is accessible on http://0.0.0.0:2375 without encryption. Access to the remote API is equivalent to root access on the host. Refer to the 'Docker daemon attack surface' section in the documentation for more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface WARNING: No swap limit support        Even I have checked with standalone mode, chain health is always FAIL all the time, log is again giving below: -      cello-operator-dashboard |  2019-03-20 11:36:53,376  INFO  resources.cluster_api   cluster_api.py:220 cluster_create()  - /cluster action=POST cello-operator-dashboard |  2019-03-20 11:36:53,377  INFO  modules.cluster   cluster.py:276 create()  - Create cluster chain02, host_id=18f1b8ae19ec4491b47612b4d9cced9b, config=\{'network_type': 'fabric-1.0', 'consensus_plugin': 'solo', 'size': 4}, start_port=0, user_id= cello-operator-dashboard |  2019-03-20 11:36:53,618  INFO  resources.cluster_api   cluster_api.py:323 cluster_list()  - {} cello-operator-dashboard |  2019-03-20 11:36:53,719  INFO  resources.cluster_api   cluster_api.py:326 cluster_list()  -  \{'health': 'FAIL', 'service_url': {'peer0_org1_grpc': '172.16.1.5:7050', 'peer0_org1_event': '172.16.1.5:7150', 'peer1_org1_grpc': '172.16.1.5:7250', 'peer1_org1_event': '172.16.1.5:7350', 'peer0_org2_grpc': '172.16.1.5:7450', 'peer0_org2_event': '172.16.1.5:7550', 'peer1_org2_grpc': '172.16.1.5:7650', 'peer1_org2_event': '172.16.1.5:7750', 'ca_org1_ecap': '172.16.1.5:7850', 'ca_org2_ecap': '172.16.1.5:7950', 'orderer': '172.16.1.5:8050'}, 'size': 4, 'status': 'running', 'api_url': '', 'service_ports':  7050, 7150, 7250, 7350, 7450, 7550, 7650, 7750, 7850, 7950, 8050 , 'id': '522cde7b41f84fb49803329cde92dae6', 'worker_api': 'tcp://172.16.1.5:2375', 'host': 'Worker1', 'mapped_ports': \{'peer0_org1_grpc': 7050, 'peer0_org1_event': 7150, 'peer1_org1_grpc': 7250, 'peer1_org1_event': 7350, 'peer0_org2_grpc': 7450, 'peer0_org2_event': 7550, 'peer1_org2_grpc': 7650, 'peer1_org2_event': 7750, 'ca_org1_ecap': 7850, 'ca_org2_ecap': 7950, 'orderer': 8050}, 'release_ts': None, 'apply_ts': None, 'create_ts': 1553081674.0, 'duration': None, 'network_type': 'fabric-1.0', 'user_id': '', 'containers':  '522cde7b41f84fb49803329cde92dae6_orderer', '522cde7b41f84fb49803329cde92dae6_ca_org2', '522cde7b41f84fb49803329cde92dae6_ca_org1', '522cde7b41f84fb49803329cde92dae6_peer1_org1', '522cde7b41f84fb49803329cde92dae6_peer0_org1', '522cde7b41f84fb49803329cde92dae6_peer1_org2', '522cde7b41f84fb49803329cde92dae6_peer0_org2' , 'consensus_plugin': 'solo', 'name': 'chain01', 'host_id': '881d5f17c97143939049ee62542d2493'}, \{'health': '', 'service_url': {}, 'size': 4, 'status': 'creating', 'api_url': None, 'service_ports':   , 'id': '86c90a25f3f0425384ceec27c44df4f6', 'worker_api': 'tcp://172.16.1.6:2375', 'host': 'Worker2', 'mapped_ports': \{'peer0_org1_grpc': 7050, 'peer0_org1_event': 7150, 'peer1_org1_grpc': 7250, 'peer1_org1_event': 7350, 'peer0_org2_grpc': 7450, 'peer0_org2_event': 7550, 'peer1_org2_grpc': 7650, 'peer1_org2_event': 7750, 'ca_org1_ecap': 7850, 'ca_org2_ecap': 7950, 'orderer': 8050}, 'release_ts': None, 'apply_ts': None, 'create_ts': 1553081813.0, 'duration': None, 'network_type': 'fabric-1.0', 'user_id': '', 'containers':   , 'consensus_plugin': 'solo', 'name': 'chain02', 'host_id': '18f1b8ae19ec4491b47612b4d9cced9b'}  cello-operator-dashboard |  2019-03-20 11:36:53,826  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:36:53,829  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster Creating 86c90a25f3f0425384ceec27c44df4f6_orderer ... done cello-operator-dashboard | Creating 86c90a25f3f0425384ceec27c44df4f6_ca_org2 ... cello-operator-dashboard | Creating 86c90a25f3f0425384ceec27c44df4f6_ca_org1 ... cello-watchdog |  2019-03-20 11:36:54,848  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:36:55,625  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster Creating 86c90a25f3f0425384ceec27c44df4f6_ca_org2 ... done cello-watchdog |  2019-03-20 11:36:57,693  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster Creating 86c90a25f3f0425384ceec27c44df4f6_peer0_org2 ... cello-operator-dashboard | Creating 86c90a25f3f0425384ceec27c44df4f6_peer0_org1 ... cello-operator-dashboard | Creating 86c90a25f3f0425384ceec27c44df4f6_peer1_org2 ... Creating 86c90a25f3f0425384ceec27c44df4f6_peer1_org2 ... done cello-watchdog |  2019-03-20 11:36:58,363  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster  2019-03-20 11:36:58,927  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:36:58,949  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:36:59,887  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:37:00,663  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:37:01,332  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster  2019-03-20 11:37:01,811  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:37:01,865  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:37:02,081  INFO  modules.cluster   cluster.py:256 _create_cluster()  - Create cluster OK, id=86c90a25f3f0425384ceec27c44df4f6 cello-watchdog |  2019-03-20 11:37:02,726  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:37:03,392  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:37:04,040  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster  cello-operator-dashboard |  2019-03-20 11:38:01,639  INFO  resources.cluster_api   cluster_api.py:286 cluster_delete()  - /cluster action=DELETE cello-dashboard_rabbitmq | 2019-03-20 11:38:01.695  info  <0.659.0> accepting AMQP connection <0.659.0> (172.18.0.9:50894 -> 172.18.0.4:5672) cello-dashboard_rabbitmq | 2019-03-20 11:38:01.699  info  <0.659.0> connection <0.659.0> (172.18.0.9:50894 -> 172.18.0.4:5672): user 'cello' authenticated and granted access to vhost 'cello' cello-operator-dashboard |  2019-03-20 11:38:01,810  INFO  resources.cluster_api   cluster_api.py:323 cluster_list()  - {} cello-watchdog |  2019-03-20 11:38:01,823  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:01,941  INFO  resources.cluster_api   cluster_api.py:326 cluster_list()  -  \{'health': 'FAIL', 'service_url': {'peer0_org1_grpc': '172.16.1.5:7050', 'peer0_org1_event': '172.16.1.5:7150', 'peer1_org1_grpc': '172.16.1.5:7250', 'peer1_org1_event': '172.16.1.5:7350', 'peer0_org2_grpc': '172.16.1.5:7450', 'peer0_org2_event': '172.16.1.5:7550', 'peer1_org2_grpc': '172.16.1.5:7650', 'peer1_org2_event': '172.16.1.5:7750', 'ca_org1_ecap': '172.16.1.5:7850', 'ca_org2_ecap': '172.16.1.5:7950', 'orderer': '172.16.1.5:8050'}, 'size': 4, 'status': 'running', 'api_url': '', 'service_ports':  7050, 7150, 7250, 7350, 7450, 7550, 7650, 7750, 7850, 7950, 8050 , 'id': '522cde7b41f84fb49803329cde92dae6', 'worker_api': 'tcp://172.16.1.5:2375', 'host': 'Worker1', 'mapped_ports': \{'peer0_org1_grpc': 7050, 'peer0_org1_event': 7150, 'peer1_org1_grpc': 7250, 'peer1_org1_event': 7350, 'peer0_org2_grpc': 7450, 'peer0_org2_event': 7550, 'peer1_org2_grpc': 7650, 'peer1_org2_event': 7750, 'ca_org1_ecap': 7850, 'ca_org2_ecap': 7950, 'orderer': 8050}, 'release_ts': None, 'apply_ts': None, 'create_ts': 1553081674.0, 'duration': None, 'network_type': 'fabric-1.0', 'user_id': '', 'containers':  '522cde7b41f84fb49803329cde92dae6_orderer', '522cde7b41f84fb49803329cde92dae6_ca_org2', '522cde7b41f84fb49803329cde92dae6_ca_org1', '522cde7b41f84fb49803329cde92dae6_peer1_org1', '522cde7b41f84fb49803329cde92dae6_peer0_org1', '522cde7b41f84fb49803329cde92dae6_peer1_org2', '522cde7b41f84fb49803329cde92dae6_peer0_org2' , 'consensus_plugin': 'solo', 'name': 'chain01', 'host_id': '881d5f17c97143939049ee62542d2493'}, \{'health': 'FAIL', 'service_url': {'peer0_org1_grpc': '172.16.1.6:7050', 'peer0_org1_event': '172.16.1.6:7150', 'peer1_org1_grpc': '172.16.1.6:7250', 'peer1_org1_event': '172.16.1.6:7350', 'peer0_org2_grpc': '172.16.1.6:7450', 'peer0_org2_event': '172.16.1.6:7550', 'peer1_org2_grpc': '172.16.1.6:7650', 'peer1_org2_event': '172.16.1.6:7750', 'ca_org1_ecap': '172.16.1.6:7850', 'ca_org2_ecap': '172.16.1.6:7950', 'orderer': '172.16.1.6:8050'}, 'size': 4, 'status': 'deleting', 'api_url': '', 'service_ports':  7050, 7150, 7250, 7350, 7450, 7550, 7650, 7750, 7850, 7950, 8050 , 'id': '86c90a25f3f0425384ceec27c44df4f6', 'worker_api': 'tcp://172.16.1.6:2375', 'host': 'Worker2', 'mapped_ports': \{'peer0_org1_grpc': 7050, 'peer0_org1_event': 7150, 'peer1_org1_grpc': 7250, 'peer1_org1_event': 7350, 'peer0_org2_grpc': 7450, 'peer0_org2_event': 7550, 'peer1_org2_grpc': 7650, 'peer1_org2_event': 7750, 'ca_org1_ecap': 7850, 'ca_org2_ecap': 7950, 'orderer': 8050}, 'release_ts': None, 'apply_ts': None, 'create_ts': 1553081813.0, 'duration': None, 'network_type': 'fabric-1.0', 'user_id': '', 'containers':  '86c90a25f3f0425384ceec27c44df4f6_orderer', '86c90a25f3f0425384ceec27c44df4f6_ca_org1', '86c90a25f3f0425384ceec27c44df4f6_ca_org2', '86c90a25f3f0425384ceec27c44df4f6_peer0_org1', '86c90a25f3f0425384ceec27c44df4f6_peer0_org2', '86c90a25f3f0425384ceec27c44df4f6_peer1_org1', '86c90a25f3f0425384ceec27c44df4f6_peer1_org2' , 'consensus_plugin': 'solo', 'name': 'chain02', 'host_id': '18f1b8ae19ec4491b47612b4d9cced9b'}  cello-operator-dashboard |  2019-03-20 11:38:01,996  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:02,002  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:02,081  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:02,129  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=86c90a25f3f0425384ceec27c44df4f6 cello-watchdog |  2019-03-20 11:38:03,267  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:03,956  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:04,301  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:04,323  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=86c90a25f3f0425384ceec27c44df4f6 cello-watchdog |  2019-03-20 11:38:04,431  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:04,716  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:04,735  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=86c90a25f3f0425384ceec27c44df4f6 cello-watchdog |  2019-03-20 11:38:04,755  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:05,299  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:05,316  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:05,395  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:06,169  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:06,895  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:07,085  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:07,106  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-dashboard_rabbitmq | 2019-03-20 11:38:07.778  info  <0.672.0> accepting AMQP connection <0.672.0> (172.18.0.9:51396 -> 172.18.0.4:5672) cello-dashboard_rabbitmq | 2019-03-20 11:38:07.785  info  <0.672.0> connection <0.672.0> (172.18.0.9:51396 -> 172.18.0.4:5672): user 'cello' authenticated and granted access to vhost 'cello' cello-mongo | 2019-03-20T11:38:07.798+0000 I NETWORK  thread1  connection accepted from 172.18.0.6:36696 #10 (10 connections now open) cello-watchdog |  2019-03-20 11:38:08,308  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:08,997  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:09,467  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:09,798  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:10,414  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:10,435  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:10,449  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:10,485  WARNING  modules.cluster   cluster.py:110 get_by_id()  - No cluster found with id=86c90a25f3f0425384ceec27c44df4f6 cello-operator-dashboard |  2019-03-20 11:38:10,485  WARNING  resources.cluster_api   cluster_api.py:198 cluster_query()  - cluster not found with id=86c90a25f3f0425384ceec27c44df4f6 cello-watchdog |  2019-03-20 11:38:11,215  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:11,633  INFO  resources.cluster_api   cluster_api.py:286 cluster_delete()  - /cluster action=DELETE cello-operator-dashboard |  2019-03-20 11:38:11,702  INFO  resources.cluster_api   cluster_api.py:323 cluster_list()  - {} cello-operator-dashboard |  2019-03-20 11:38:11,828  INFO  resources.cluster_api   cluster_api.py:326 cluster_list()  -  \{'health': 'FAIL', 'service_url': {'peer0_org1_grpc': '172.16.1.5:7050', 'peer0_org1_event': '172.16.1.5:7150', 'peer1_org1_grpc': '172.16.1.5:7250', 'peer1_org1_event': '172.16.1.5:7350', 'peer0_org2_grpc': '172.16.1.5:7450', 'peer0_org2_event': '172.16.1.5:7550', 'peer1_org2_grpc': '172.16.1.5:7650', 'peer1_org2_event': '172.16.1.5:7750', 'ca_org1_ecap': '172.16.1.5:7850', 'ca_org2_ecap': '172.16.1.5:7950', 'orderer': '172.16.1.5:8050'}, 'size': 4, 'status': 'deleting', 'api_url': '', 'service_ports':  7050, 7150, 7250, 7350, 7450, 7550, 7650, 7750, 7850, 7950, 8050 , 'id': '522cde7b41f84fb49803329cde92dae6', 'worker_api': 'tcp://172.16.1.5:2375', 'host': 'Worker1', 'mapped_ports': \{'peer0_org1_grpc': 7050, 'peer0_org1_event': 7150, 'peer1_org1_grpc': 7250, 'peer1_org1_event': 7350, 'peer0_org2_grpc': 7450, 'peer0_org2_event': 7550, 'peer1_org2_grpc': 7650, 'peer1_org2_event': 7750, 'ca_org1_ecap': 7850, 'ca_org2_ecap': 7950, 'orderer': 8050}, 'release_ts': None, 'apply_ts': None, 'create_ts': 1553081674.0, 'duration': None, 'network_type': 'fabric-1.0', 'user_id': '', 'containers':  '522cde7b41f84fb49803329cde92dae6_orderer', '522cde7b41f84fb49803329cde92dae6_ca_org2', '522cde7b41f84fb49803329cde92dae6_ca_org1', '522cde7b41f84fb49803329cde92dae6_peer1_org1', '522cde7b41f84fb49803329cde92dae6_peer0_org1', '522cde7b41f84fb49803329cde92dae6_peer1_org2', '522cde7b41f84fb49803329cde92dae6_peer0_org2' , 'consensus_plugin': 'solo', 'name': 'chain01', 'host_id': '881d5f17c97143939049ee62542d2493'}  cello-watchdog |  2019-03-20 11:38:11,943  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:11,970  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=522cde7b41f84fb49803329cde92dae6 cello-operator-dashboard |  2019-03-20 11:38:11,975  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:12,172  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:12,186  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:12,188  WARNING  modules.cluster   cluster.py:110 get_by_id()  - No cluster found with id=86c90a25f3f0425384ceec27c44df4f6 cello-operator-dashboard |  2019-03-20 11:38:12,188  WARNING  resources.cluster_api   cluster_api.py:198 cluster_query()  - cluster not found with id=86c90a25f3f0425384ceec27c44df4f6 cello-watchdog |  2019-03-20 11:38:13,347  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:13,366  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=522cde7b41f84fb49803329cde92dae6 cello-watchdog |  2019-03-20 11:38:14,039  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:14,058  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=522cde7b41f84fb49803329cde92dae6 cello-watchdog |  2019-03-20 11:38:14,503  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:14,523  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=522cde7b41f84fb49803329cde92dae6 cello-watchdog |  2019-03-20 11:38:14,842  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:14,865  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=522cde7b41f84fb49803329cde92dae6 cello-watchdog |  2019-03-20 11:38:15,503  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:15,522  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=522cde7b41f84fb49803329cde92dae6 cello-operator-dashboard |  2019-03-20 11:38:15,559  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:16,256  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-20 11:38:16,273  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=522cde7b41f84fb49803329cde92dae6 cello-operator-dashboard |  2019-03-20 11:38:17,044  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:17,258  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-dashboard_rabbitmq | 2019-03-20 11:38:18.974  info  <0.690.0> accepting AMQP connection <0.690.0> (172.18.0.9:51874 -> 172.18.0.4:5672) cello-dashboard_rabbitmq | 2019-03-20 11:38:18.978  info  <0.690.0> connection <0.690.0> (172.18.0.9:51874 -> 172.18.0.4:5672): user 'cello' authenticated and granted access to vhost 'cello' cello-operator-dashboard |  2019-03-20 11:38:20,625  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:20,637  WARNING  modules.cluster   cluster.py:110 get_by_id()  - No cluster found with id=522cde7b41f84fb49803329cde92dae6 cello-operator-dashboard |  2019-03-20 11:38:20,637  WARNING  resources.cluster_api   cluster_api.py:198 cluster_query()  - cluster not found with id=522cde7b41f84fb49803329cde92dae6 cello-operator-dashboard |  2019-03-20 11:38:22,243  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:22,260  WARNING  modules.cluster   cluster.py:110 get_by_id()  - No cluster found with id=522cde7b41f84fb49803329cde92dae6 cello-operator-dashboard |  2019-03-20 11:38:22,260  WARNING  resources.cluster_api   cluster_api.py:198 cluster_query()  - cluster not found with id=522cde7b41f84fb49803329cde92dae6 cello-watchdog |  2019-03-20 11:38:22,344  INFO  __main__   watchdog.py:123 watch_run()  - Watchdog run checks with period = 15 s cello-watchdog |  2019-03-20 11:38:22,360  INFO  __main__   watchdog.py:125 watch_run()  - Found 2 hosts cello-operator-dashboard |  2019-03-20 11:38:22,386  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 11:38:22,404  WARNING  modules.cluster   cluster.py:110 get_by_id()  - No cluster found with id=522cde7b41f84fb49803329cde92dae6 cello-operator-dashboard |  2019-03-20 11:38:22,404  WARNING  resources.cluster_api   cluster_api.py:198 cluster_query()  - cluster not found with id=522cde7b41f84fb49803329cde92dae6  ></body> </Action>
<Action id="58338" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-20 11:47:29.0" updateauthor="arindambhattacharjee" updated="2019-03-20 11:51:11.0"> <body><! CDATA Also let you know that when I'm creating the cluster or chain, I haven't seen any docker ps at worker node's end, as per understanding during submitting the chain the docker images should be up and running at worker node's end.   Can you please try a demo at your's end, hopefully you will also get the same bug?     The same issue reported by another user - CE-546  ></body> </Action>
<Action id="58340" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-20 13:10:35.0" updateauthor="arindambhattacharjee" updated="2019-03-20 13:10:35.0"> <body><! CDATA Again the same thing, cluster got created, after that clusted id not found, check the below log : -     cello-operator-dashboard |  2019-03-20 13:05:55,178  INFO  resources.cluster_api   cluster_api.py:323 cluster_list()  - {} cello-operator-dashboard |  2019-03-20 13:05:55,238  INFO  resources.cluster_api   cluster_api.py:326 cluster_list()  -  \{'mapped_ports': {'peer0_org1_grpc': 7050, 'peer0_org1_event': 7150, 'peer1_org1_grpc': 7250, 'peer1_org1_event': 7350, 'peer0_org2_grpc': 7450, 'peer0_org2_event': 7550, 'peer1_org2_grpc': 7650, 'peer1_org2_event': 7750, 'ca_org1_ecap': 7850, 'ca_org2_ecap': 7950, 'orderer': 8050}, 'status': 'deleting', 'name': 'chain01', 'release_ts': None, 'user_id': '', 'id': 'f6fd5b0f579f4862892074cf28c8e269', 'service_url': \{'peer0_org1_grpc': '172.16.1.5:7050', 'peer0_org1_event': '172.16.1.5:7150', 'peer1_org1_grpc': '172.16.1.5:7250', 'peer1_org1_event': '172.16.1.5:7350', 'peer0_org2_grpc': '172.16.1.5:7450', 'peer0_org2_event': '172.16.1.5:7550', 'peer1_org2_grpc': '172.16.1.5:7650', 'peer1_org2_event': '172.16.1.5:7750', 'ca_org1_ecap': '172.16.1.5:7850', 'ca_org2_ecap': '172.16.1.5:7950', 'orderer': '172.16.1.5:8050'}, 'worker_api': 'tcp://172.16.1.5:2375', 'apply_ts': None, 'size': 4, 'health': '', 'containers':  'f6fd5b0f579f4862892074cf28c8e269_ca_org1', 'f6fd5b0f579f4862892074cf28c8e269_orderer', 'f6fd5b0f579f4862892074cf28c8e269_peer1_org2', 'f6fd5b0f579f4862892074cf28c8e269_ca_org2', 'f6fd5b0f579f4862892074cf28c8e269_peer1_org1', 'f6fd5b0f579f4862892074cf28c8e269_peer0_org1', 'f6fd5b0f579f4862892074cf28c8e269_peer0_org2' , 'consensus_plugin': 'solo', 'duration': None, 'service_ports':  7050, 7150, 7250, 7350, 7450, 7550, 7650, 7750, 7850, 7950, 8050 , 'api_url': '', 'host_id': '881d5f17c97143939049ee62542d2493', 'host': 'Worker1', 'create_ts': 1553086925.0, 'network_type': 'fabric-1.0'}  cello-operator-dashboard |  2019-03-20 13:05:55,421  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-dashboard_rabbitmq | 2019-03-20 13:05:56.068  info  <0.804.0> accepting AMQP connection <0.804.0> (172.18.0.9:58590 -> 172.18.0.5:5672) cello-dashboard_rabbitmq | 2019-03-20 13:05:56.072  info  <0.804.0> connection <0.804.0> (172.18.0.9:58590 -> 172.18.0.5:5672): user 'cello' authenticated and granted access to vhost 'cello' cello-watchdog |  2019-03-20 13:05:56,812  INFO  __main__   watchdog.py:123 watch_run()  - Watchdog run checks with period = 15 s cello-watchdog |  2019-03-20 13:05:56,826  INFO  __main__   watchdog.py:125 watch_run()  - Found 2 hosts cello-operator-dashboard |  2019-03-20 13:05:59,910  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 13:05:59,924  WARNING  modules.cluster   cluster.py:110 get_by_id()  - No cluster found with id=f6fd5b0f579f4862892074cf28c8e269 cello-operator-dashboard |  2019-03-20 13:05:59,924  WARNING  resources.cluster_api   cluster_api.py:198 cluster_query()  - cluster not found with id=f6fd5b0f579f4862892074cf28c8e269 cello-operator-dashboard |  2019-03-20 13:06:00,512  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-20 13:06:00,528  WARNING  modules.cluster   cluster.py:110 get_by_id()  - No cluster found with id=f6fd5b0f579f4862892074cf28c8e269 cello-operator-dashboard |  2019-03-20 13:06:00,528  WARNING  resources.cluster_api   cluster_api.py:198 cluster_query()  - cluster not found with id=f6fd5b0f579f4862892074cf28c8e269        Please provide me the release version of the code for QA environment, since I have the master branch code.  ></body> </Action>
<Action id="58423" issue="38421" author="arindambhattacharjee" type="comment" body="Do you have any update @baohua ?" created="2019-03-21 22:03:49.0" updateauthor="arindambhattacharjee" updated="2019-03-21 22:03:49.0"/>
<Action id="58425" issue="38421" author="baohua" type="comment" created="2019-03-22 04:36:43.0" updateauthor="baohua" updated="2019-03-22 04:37:04.0"> <body><! CDATA Sorry, I have no clue yet as you do not have the error log for the call.  However, would you like to attend the weekly meeting to discuss more?  ></body> </Action>
<Action id="58426" issue="38421" author="arindambhattacharjee" type="comment" body="Yes Baohua, I would like to join the weekly meeting. Can you please forward the meeting invitation to me?" created="2019-03-22 04:45:45.0" updateauthor="arindambhattacharjee" updated="2019-03-22 04:45:45.0"/>
<Action id="58428" issue="38421" author="arindambhattacharjee" type="comment" body="Please let me know how to join the weekly meeting, forward to me if any meeting invitation or Webex available. " created="2019-03-22 06:54:58.0" updateauthor="arindambhattacharjee" updated="2019-03-22 06:54:58.0"/>
<Action id="58432" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-22 07:53:30.0" updateauthor="arindambhattacharjee" updated="2019-03-22 07:53:30.0"> <body><! CDATA Also baohua, what I have seen that when the ordered peers getting generated that time some of the peer and ca status is not showing as "done" in the logs and after that chain health is showing as "FAIL", see the below log : -     Creating 4b8ce6678bfb4cf898011856d998c81c_orderer ... done 'health': '', 'id': '4b8ce6678bfb4cf898011856d998c81c', 'status': 'creating', 'host_id': '7948bdac9bf3417ea2bf4a25120ac32b', 'release_ts': None, 'create_ts': 1553240993.0, 'service_url': {}, 'consensus_plugin': 'solo', 'service_portsCreating 4b8ce6678bfb4cf898011856d998c81c_ca_org1 ... done cello-operator-dashboard |  2019-03-22 07:49:53,384  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster Creating 4b8ce6678bfb4cf898011856d998c81c_peer0_org2 ... done cello-operator-dashboard | Creating 4b8ce6678bfb4cf898011856d998c81c_orderer ... cello-operator-dashboard | Creating 4b8ce6678bfb4cf898011856d998c81c_ca_org1 ... Creating 4b8ce6678bfb4cf898011856d998c81c_peer1_org2 ... cello-operator-dashboard | Creating 4b8ce6678bfb4cf898011856d998c81c_peer0_org1 ... Creating 4b8ce6678bfb4cf898011856d998c81c_peer0_org2 ... cello-operator-dashboard | Creating 4b8ce6678bfb4cf898011856d998c81c_peer1_org1 ...  2019-03-22 07:49:55,819  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-22 07:49:55,871  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-22 07:49:56,090  INFO  modules.cluster   cluster.py:256 _create_cluster()  - Create cluster OK, id=4b8ce6678bfb4cf898011856d998c81c cello-operator-dashboard |  2019-03-22 07:49:58,449  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-dashboard_rabbitmq | 2019-03-22 07:49:59.639  error  <0.526.0> closing AMQP connection <0.526.0> (172.20.0.9:54820 -> 172.20.0.4:5672): cello-dashboard_rabbitmq | missed heartbeats from client, timeout: 60s cello-watchdog |  2019-03-22 07:50:01,714  INFO  __main__   watchdog.py:123 watch_run()  - Watchdog run checks with period = 15 s cello-watchdog |  2019-03-22 07:50:01,725  INFO  __main__   watchdog.py:125 watch_run()  - Found 1 hosts cello-watchdog |  2019-03-22 07:50:01,774  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-22 07:50:01,795  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-22 07:50:03,517  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-22 07:50:06,847  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-22 07:50:08,605  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-22 07:50:11,891  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-22 07:50:13,695  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-22 07:50:16,936  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-22 07:50:18,760  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-22 07:50:21,978  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-22 07:50:23,838  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-22 07:50:27,020  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-22 07:50:27,289  INFO  resources.cluster_api   cluster_api.py:286 cluster_delete()  - /cluster action=DELETE cello-dashboard_rabbitmq | 2019-03-22 07:50:27.321  info  <0.591.0> accepting AMQP connection <0.591.0> (172.20.0.9:56906 -> 172.20.0.4:5672) cello-dashboard_rabbitmq | 2019-03-22 07:50:27.324  info  <0.591.0> connection <0.591.0> (172.20.0.9:56906 -> 172.20.0.4:5672): user 'cello' authenticated and granted access to vhost 'cello' cello-operator-dashboard |  2019-03-22 07:50:27,355  INFO  resources.cluster_api   cluster_api.py:323 cluster_list()  - {} cello-operator-dashboard |  2019-03-22 07:50:27,402  INFO  resources.cluster_api   cluster_api.py:326 cluster_list()  -  \{'user_id': '', 'network_type': 'fabric-1.0', 'mapped_ports': {'peer0_org1_grpc': 7050, 'peer0_org1_event': 7150, 'peer1_org1_grpc': 7250, 'peer1_org1_event': 7350, 'peer0_org2_grpc': 7450, 'peer0_org2_event': 7550, 'peer1_org2_grpc': 7650, 'peer1_org2_event': 7750, 'ca_org1_ecap': 7850, 'ca_org2_ecap': 7950, 'orderer': 8050}, 'size': 4, 'health': 'FAIL', 'id': '4b8ce6678bfb4cf898011856d998c81c', 'status': 'deleting', 'host_id': '7948bdac9bf3417ea2bf4a25120ac32b', 'release_ts': None, 'create_ts': 1553240993.0, 'service_url': \{'peer0_org1_grpc': '10.176.31.144:7050', 'peer0_org1_event': '10.176.31.144:7150', 'peer1_org1_grpc': '10.176.31.144:7250', 'peer1_org1_event': '10.176.31.144:7350', 'peer0_org2_grpc': '10.176.31.144:7450', 'peer0_org2_event': '10.176.31.144:7550', 'peer1_org2_grpc': '10.176.31.144:7650', 'peer1_org2_event': '10.176.31.144:7750', 'ca_org1_ecap': '10.176.31.144:7850', 'ca_org2_ecap': '10.176.31.144:7950', 'orderer': '10.176.31.144:8050'}, 'consensus_plugin': 'solo', 'service_ports':  7050, 7150, 7250, 7350, 7450, 7550, 7650, 7750, 7850, 7950, 8050 , 'containers':  '4b8ce6678bfb4cf898011856d998c81c_orderer', '4b8ce6678bfb4cf898011856d998c81c_ca_org2', '4b8ce6678bfb4cf898011856d998c81c_ca_org1', '4b8ce6678bfb4cf898011856d998c81c_peer1_org2', '4b8ce6678bfb4cf898011856d998c81c_peer0_org1', '4b8ce6678bfb4cf898011856d998c81c_peer1_org1', '4b8ce6678bfb4cf898011856d998c81c_peer0_org2' , 'apply_ts': None, 'api_url': '', 'worker_api': 'tcp://10.176.31.144:2375', 'duration': None, 'host': 'ManagedApps2812', 'name': 'chain01'}  cello-operator-dashboard |  2019-03-22 07:50:27,453  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-22 07:50:28,900  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-22 07:50:32,061  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-watchdog |  2019-03-22 07:50:32,084  WARNING  modules.cluster   cluster.py:852 refresh_health()  - cluster is not running id=4b8ce6678bfb4cf898011856d998c81c cello-operator-dashboard |  2019-03-22 07:50:32,545  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-dashboard_rabbitmq | 2019-03-22 07:50:33.864  info  <0.604.0> accepting AMQP connection <0.604.0> (172.20.0.9:57056 -> 172.20.0.4:5672) cello-dashboard_rabbitmq | 2019-03-22 07:50:33.867  info  <0.604.0> connection <0.604.0> (172.20.0.9:57056 -> 172.20.0.4:5672): user 'cello' authenticated and granted access to vhost 'cello' cello-operator-dashboard |  2019-03-22 07:50:33,963  INFO  modules.cluster   cluster.py:107 get_by_id()  - find state active cluster cello-operator-dashboard |  2019-03-22 07:50:33,973  WARNING  modules.cluster   cluster.py:110 get_by_id()  - No cluster found with id=4b8ce6678bfb4cf898011856d998c81c  ></body> </Action>
<Action id="58500" issue="38421" author="arindambhattacharjee" type="comment" body="Is there any update?" created="2019-03-25 06:31:10.0" updateauthor="arindambhattacharjee" updated="2019-03-25 06:31:10.0"/>
<Action id="58501" issue="38421" author="arindambhattacharjee" type="comment" body="Please let me know if there is any update?" created="2019-03-25 06:32:06.0" updateauthor="arindambhattacharjee" updated="2019-03-25 06:32:06.0"/>
<Action id="58539" issue="38421" author="arindambhattacharjee" type="comment" body="Please let me know if you have any update" created="2019-03-26 06:49:19.0" updateauthor="arindambhattacharjee" updated="2019-03-26 06:49:19.0"/>
<Action id="58543" issue="38421" author="brendatian" type="comment" body="Did you build v0.9.0 cello images by yourself ? I am try to reproduce this issue，but now I couldn&apos;t managed to build userdashboard image. ~ArindamBhattacharjee " created="2019-03-26 09:25:06.0" updateauthor="brendatian" updated="2019-03-26 09:25:06.0"/>
<Action id="58545" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-26 09:37:34.0" updateauthor="arindambhattacharjee" updated="2019-03-26 09:37:34.0"> <body><! CDATA Hello  ~brendatian ,     I haven't built the v0.9.0 images by myself. It was pulled from docker hub and running on my environment. During that time I'm facing the issue ( During chain creation).  ></body> </Action>
<Action id="58607" issue="38421" author="brendatian" type="comment" body="I&apos;ve tried to get images from docker hub. But it seems there is no images compatible with my cpu arch，for example &apos;cello-engin&apos;, there is only &quot;s390x-0.9.0-snapshot-d956c29&quot;, but my arch is &quot;x86_64&quot;, I am not sure if it matters,  so I decide to build myself. Could you make sure we can just use the images in docker hub?  ~ArindamBhattacharjee " created="2019-03-27 02:48:15.0" updateauthor="brendatian" updated="2019-03-27 02:48:15.0"/>
<Action id="58627" issue="38421" author="arindambhattacharjee" type="comment" body="Myself is facing issue with the chain, during chain creation I&apos;m getting unhealthy chain. I want help to fix the same." created="2019-03-27 12:08:42.0" updateauthor="arindambhattacharjee" updated="2019-03-27 12:08:42.0"/>
<Action id="58637" issue="38421" author="arindambhattacharjee" type="comment" body=" ~hightall  you&apos;re one of the developers for Hyperledger cello, I&apos;m also from IBM India and need your help to resolve my problem." created="2019-03-27 14:54:48.0" updateauthor="arindambhattacharjee" updated="2019-03-27 14:54:48.0"/>
<Action id="58658" issue="38421" author="brendatian" type="comment" body="I have build 0.9.0 images successfully and tested &quot;create chain&quot; on operator-dashboard and &quot;appy chain&quot; on user-dashboard， It‘s OK.   !0.9.0_create_chain.JPG!!0.9.0_applychain.JPG!" created="2019-03-28 09:41:05.0" updateauthor="brendatian" updated="2019-03-28 09:41:05.0"/>
<Action id="58663" issue="38421" author="brendatian" type="comment" body="!0.9.0create_chain.PNG!!0.9.0apply_chain.PNG!" created="2019-03-28 10:25:51.0" updateauthor="brendatian" updated="2019-03-28 10:25:51.0"/>
<Action id="58664" issue="38421" author="brendatian" type="comment" body="!0.9.0create_chain.PNG!!0.9.0apply_chain.PNG!" created="2019-03-28 10:26:33.0" updateauthor="brendatian" updated="2019-03-28 10:26:33.0"/>
<Action id="58665" issue="38421" author="arindambhattacharjee" type="comment" body="Can you please help me with steps how to build the images with correct architecture? Thanks in advance! " created="2019-03-28 11:33:50.0" updateauthor="arindambhattacharjee" updated="2019-03-28 11:33:50.0"/>
<Action id="58687" issue="38421" author="brendatian" type="comment" created="2019-03-28 15:21:14.0" updateauthor="brendatian" updated="2019-03-28 15:21:14.0"> <body><! CDATA I think your problem most probable is because the directory "/opt/cello" on the worker node is not mount correctly,  so the containers in the cluster could not start up, you can check the docker logs of that containers. h1.    ></body> </Action>
<Action id="58690" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-28 15:27:35.0" updateauthor="arindambhattacharjee" updated="2019-03-28 15:27:35.0"> <body><! CDATA Hello,  Can you please let me know which os you’re using and the steps you are performing for the same? Because my operator dashboard and user-dashboard are working. But chain is  getting failed after creation but host status was showing active all the time   Thanks, Arindam  ></body> </Action>
<Action id="58703" issue="38421" author="brendatian" type="comment" created="2019-03-29 02:06:43.0" updateauthor="brendatian" updated="2019-03-29 02:06:43.0"> <body><! CDATA My architecture is x86_64 ubuntu 14.04， the os of my vm is very old and my network is not fluent, so I changed the docker file of the userdashboard.  My steps are not suitable for you I think. FYI, I encountered the same problem with you at the first time, so I suggest you just check your container logs, if  your log is similar to the picture below, you could go to check if "/opt/cello" on your worker node is mounted correctly.  !cluster_createfail.png!  ></body> </Action>
<Action id="58704" issue="38421" author="brendatian" type="comment" body="The directory,  &quot;/etc/hyperledger/fabric/msp/sigcerts&quot; , is mapped to a directory under &quot;/opt/cello&quot;, If &quot;/opt/cello&quot; is not mounted correctly, peer or orderer couldn&apos;t start because of lacking of that files." created="2019-03-29 02:09:59.0" updateauthor="brendatian" updated="2019-03-29 02:09:59.0"/>
<Action id="58720" issue="38421" author="arindambhattacharjee" type="comment" body="Can you please let me know how to proceed with the container logs and also how to mount the same?" created="2019-03-29 10:44:25.0" updateauthor="arindambhattacharjee" updated="2019-03-29 10:44:25.0"/>
<Action id="58727" issue="38421" author="brendatian" type="comment" created="2019-03-29 13:49:38.0" updateauthor="brendatian" updated="2019-03-29 13:49:38.0"> <body><! CDATA I have no environment now.  I suggest you can check according to steps: #  At worker node, try  to run  "umount /opt/cello" , if the directory is not mounted successfully, it would output "/opt/cello is not mounted" # If  "/opt/cello" is mounted, you should check the docker-compose file which is used to deploy this cluster and  find the mapping between host path and container path to see if the content in corresponding host path is right. For example,  "/etc/hyperledger/fabric/msp/signcerts" is mapped to "/opt/cello/fabric-1.x/...." ,  you could find the exact mapping in the docker-compose file.   ></body> </Action>
<Action id="58728" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-29 14:04:26.0" updateauthor="arindambhattacharjee" updated="2019-03-29 14:04:26.0"> <body><! CDATA Actually for me, when I have added the and setup the master and worker node. I didn't find the above docker processes are up and running.   Can we have a screen sharing session or can you please help me to set up an environment?  ></body> </Action>
<Action id="58729" issue="38421" author="arindambhattacharjee" type="comment" created="2019-03-29 14:11:00.0" updateauthor="arindambhattacharjee" updated="2019-03-29 14:11:00.0"> <body><! CDATA !cello-err02.JPG!  Got the same error, so let me know how to map the same?  ></body> </Action>
<Action id="58732" issue="38421" author="arindambhattacharjee" type="comment" body="Please provide the steps for mounting the directories with cello path" created="2019-03-29 15:13:10.0" updateauthor="arindambhattacharjee" updated="2019-03-29 15:13:10.0"/>
<Action id="58767" issue="38421" author="brendatian" type="comment" created="2019-04-01 02:25:53.0" updateauthor="brendatian" updated="2019-04-01 02:25:53.0"> <body><! CDATA # Had you checked if the "/opt/cello" is mounted using the method I described above ? # If the "/opt/cello" is not mounted, try to use " sudo mount -t nfs -o vers=4,loud ${MASTER_NODE}:/opt/cello" on your worker node to try to mount the directory and remember to replace ${MASTER_NODE} to your real master node ip. # If the command fails to execute, try to examine your os type:   1) install "nfs-common" if your os is ubuntu 2) install "nfs-utils" if your os is Centos or rethat # Then you can execute  " sudo mount -t nfs -o vers=4,loud ${MASTER_NODE}:/opt/cello" to try to mount again # Usually, the directory should  be mounted OK, you can check the content of the directory, it should be: !mount.png!     ></body> </Action>
<Action id="58768" issue="38421" author="brendatian" type="comment" body=" ~baohua  Baohua, 0.9.0 now is only a tag in cello repo, where should I add some doc or do some modification to the worker setup scripts?" created="2019-04-01 02:27:41.0" updateauthor="brendatian" updated="2019-04-01 02:27:41.0"/>
<Action id="58836" issue="38421" author="arindambhattacharjee" type="comment" created="2019-04-02 10:41:51.0" updateauthor="arindambhattacharjee" updated="2019-04-02 10:47:43.0"> <body><! CDATA Hello,  Thanks for your solution. But I'm facing a new issue when instantiating the chaincode, all the time it's getting failed, in the log the below error I'm getting  : -      cello-user-dashboard | error:  Peer.js : sendProposal - timed out after:45000 cello-user-dashboard | error:  client-utils.js : sendPeersProposal - Promise is rejected: Error: REQUEST_TIMEOUT cello-user-dashboard | at Timeout._onTimeout (/packages/fabric-1.0/node_modules/fabric-client/lib/Peer.js:117:19) cello-user-dashboard | at ontimeout (timers.js:475:11) cello-user-dashboard | at tryOnTimeout (timers.js:310:5) cello-user-dashboard | at Timer.listOnTimeout (timers.js:270:5) cello-user-dashboard | error:  Peer.js : sendProposal - timed out after:45000 cello-user-dashboard | error:  client-utils.js : sendPeersProposal - Promise is rejected: Error: REQUEST_TIMEOUT cello-user-dashboard | at Timeout._onTimeout (/packages/fabric-1.0/node_modules/fabric-client/lib/Peer.js:117:19) cello-user-dashboard | at ontimeout (timers.js:475:11) cello-user-dashboard | at tryOnTimeout (timers.js:310:5) cello-user-dashboard | at Timer.listOnTimeout (timers.js:270:5)   cello-operator-dashboard |  2019-04-02 10:45:33 +0000   27   ERROR  Error handling request /socket.io/?EIO=3&transport=websocket&sid=fc09dbf1b6544dacb7a1d9141fec96e6 cello-operator-dashboard | Traceback (most recent call last): cello-operator-dashboard | File "/usr/local/lib/python3.6/site-packages/gunicorn/workers/async.py", line 52, in handle cello-operator-dashboard | self.handle_request(listener_name, req, client, addr) cello-operator-dashboard | File "/usr/local/lib/python3.6/site-packages/gunicorn/workers/async.py", line 112, in handle_request cello-operator-dashboard | resp.close() cello-operator-dashboard | File "/usr/local/lib/python3.6/site-packages/gunicorn/http/wsgi.py", line 418, in close cello-operator-dashboard | self.send_headers() cello-operator-dashboard | File "/usr/local/lib/python3.6/site-packages/gunicorn/http/wsgi.py", line 334, in send_headers cello-operator-dashboard | tosend = self.default_headers() cello-operator-dashboard | File "/usr/local/lib/python3.6/site-packages/gunicorn/http/wsgi.py", line 315, in default_headers cello-operator-dashboard | elif self.should_close(): cello-operator-dashboard | File "/usr/local/lib/python3.6/site-packages/gunicorn/http/wsgi.py", line 238, in should_close cello-operator-dashboard | if self.status_code < 200 or self.status_code in (204, 304): cello-operator-dashboard | AttributeError: 'Response' object has no attribute 'status_code'  Even chain information is loading all the time. not getting any output. Please find the below screenshot : -   !chain-capture.JPG!        !chain-error.JPG!  ></body> </Action>
<Action id="58837" issue="38421" author="arindambhattacharjee" type="comment" body=" ~brendatian   ~baohua Kindly help me on the same." created="2019-04-02 10:42:05.0" updateauthor="arindambhattacharjee" updated="2019-04-02 10:42:23.0"/>
<Action id="58921" issue="38421" author="arindambhattacharjee" type="comment" body="Can you please help me on the above mentioned issue?" created="2019-04-03 21:05:58.0" updateauthor="arindambhattacharjee" updated="2019-04-03 21:05:58.0"/>
<Action id="58927" issue="38421" author="brendatian" type="comment" body=" ~ArindamBhattacharjee  I haven&apos;t meet your problem. if  need , please  open a new issue to trace. " created="2019-04-04 06:39:54.0" updateauthor="brendatian" updated="2019-04-04 06:39:54.0"/>
