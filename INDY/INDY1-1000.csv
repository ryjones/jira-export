Summary,Issue key,Issue id,Parent id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Affects Version/s,Fix Version/s,Component/s,Due Date,Votes,Labels,Labels,Labels,Labels,Labels,Description,Environment,Watchers,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,Σ Original Estimate,Σ Remaining Estimate,Σ Time Spent,Security Level,Inward issue link (Blocks),Inward issue link (Blocks),Inward issue link (Blocks),Outward issue link (Blocks),Outward issue link (Blocks),Outward issue link (Blocks),Inward issue link (Cloners),Inward issue link (Cloners),Inward issue link (Cloners),Outward issue link (Cloners),Inward issue link (Duplicate),Outward issue link (Duplicate),Inward issue link (Relates),Inward issue link (Relates),Inward issue link (Relates),Inward issue link (Relates),Outward issue link (Relates),Outward issue link (Relates),Outward issue link (Relates),Outward issue link (Relates),Outward issue link (Relates),Outward issue link (Relates),Outward issue link (Relates),Outward issue link (Relates),Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Custom field (Business Value),Custom field (Commit Levels),Custom field (Current Status),Custom field (Design),Custom field (Design Status),Custom field (Documentation Impact),Custom field (Documentation Status),Custom field (Epic Color),Custom field (Epic Link),Custom field (Epic Name),Custom field (Epic Status),Custom field (Executed),Custom field (Flagged),Custom field (Found in Commit),Custom field (Function Test Status),Custom field (Must Fix),Custom field (Original story points),Custom field (Parent Link),Custom field (Rank),Custom field (Release Note),Custom field (Release Note Required),Custom field (Root Cause Analysis),Custom field (SDK Impact),Custom field (Sample/Tutorial),Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Custom field (Steps to Reproduce),Custom field (Story Points),Custom field (System Test Impact),Custom field (Target end),Custom field (Target start),Custom field (Team),Custom field (Team),Custom field (Test Plan),Custom field (Test Result),Custom field (Test Result Details),Custom field (Test Type),Custom field (Triaged),Custom field (Usage),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Watchers),Custom field (Workaround),Custom field (gitCommitsReferenced),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
WELCOME TO INDY!,INDY-1,15828,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Lowest,Done,,RuffTimo,RuffTimo,19/Apr/17 9:41 AM,04/Mar/20 6:07 AM,28/Oct/23 2:46 AM,08/Oct/19 8:47 PM,,,,,0,,,,,,"Welcome to Indy, the only technology designed from the ground up to enable privacy-respecting independent identity (including self-sovereign identity) for people, organizations, and things.

Indy technology powers Sovrin, a global public utility governed by the Sovrin Foundation, which makes Independent Identity possible for everyone. Combined with verifiable claims, Independent Identity enables any person, organization, or thing to connect directly to any other person, organization, or thing, and to interact with trust and privacy.

If you've gotten this far you probably already know, Indy and Sovrin incorporate leading-edge technologies such as:

* Permissioned distributed ledger technology engineered for identity to support strong, continuous, contextual, and multi-point authentication
* First class support for verifiable claims
* Zero-knowledge proofs, for privacy-respecting claims exchange, portability of claims, and selective disclosure
* Cryptographic accumulators, for revocation of claims

Now that these technologies have come together, previously intractable privacy, fraud, and security problems can be fundamentally addressed, and entirely new and exciting paradigms for interaction become possible.

Thank you for helping with Indy... together we'll change the world!

Timothy Ruff & Jason Law
(CEO and CTO of Evernym, inventors of Indy and Sovrin)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-987,,,,Impediment,,,,,,"1|hzx1tr:",,,,,,,,,,,,,,,,,,,,,,,,,,RuffTimo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
How to log a good Indy bug,INDY-2,15829,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,stevetolman,stevetolman,19/Apr/17 11:42 AM,09/Oct/19 6:39 PM,28/Oct/23 2:46 AM,09/Oct/19 6:39 PM,,,,,0,,,,,,"Include a crisp and concise summary.

Ensure the Issue is unique. Please check existing issues to see if the issue is already logged.  If not then log a new ticket that includes the following.

In the description field (this field) include:
- Short but descriptive title
- Comprehensive description including:
-- Build number
-- Steps to Reproduce

In the various appropriate Jira fields include:
- Environment and configuration
- Attachment(s)/evidence/artifacts
-- Log files that show info about the issue (errors, warnings, etc.)
-- Screen shots
-- Code snippets where applicable
- In the Linked Issues field, please define how this ticket affects other tickets, if at all
- Priority
-- Leave blank for medium priority
-- For consistency, please follow the chart below as much as possible
 

||Severity||Ticket Priority||
| Hang, Data loss, Security holes | Highest |
| Broken - Unusable or difficult workaround | High |
| Broken - easy workaround | Medium |
| Annoyance | Low |


Please do NOT include:
- Opinions or editorials","Include OS, Indy platform version, and specific configuration settings that may prove useful.",,,,,,,,,,,,,,,,INDY-10,INDY-388,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-987,,,,Impediment,,,,,,"1|hzx1bz:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:39 PM;esplinr;This is documented in the Hyperledger Wiki:

https://wiki.hyperledger.org/display/indy/How+to+Contribute#HowtoContribute-ReportinganIssue;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
improve OSCAP template for ubuntu 16.04 nodes,INDY-3,16167,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dfarns,danielhardman,danielhardman,03/May/17 4:12 AM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,"One of the efforts that Sovrin is making to enhance the security of its validator pool is to require all sysadmins to run a weekly OSCAP scan against their node, and to submit the resulting report to Sovrin's Technical Governance Board. This allows us to see whether sysadmins have appropriately locked down their firewalls, whether they've set up SSH properly, etc. This work is described in [section 7.2 of Sovrin's Provisional Trust Framework|https://docs.google.com/document/d/18V1c0rOQYxNMleuV_2z7yQny0KdBnuDkWlN8DNUrioM/edit#heading=h.wwj5wrxedflt].

Although Sovrin-specific governance is outside the scope of concerns of Indy, it would still be valuable to the Indy community to provide an OSCAP template that sysadmins could use to vet the security posture of Indy nodes they create (whether destined for Sovrin or not); hence this issue is being logged in Indy's Jira.

What we want to do is test our initial OSCAP template against various servers, to see if the template works and provides value--and then to tweak in whatever way seems prudent. I have attached the initial template (ssg*.xml).

One Sovrin community member has done an initial pass of testing. He reported the following:

It seems like the OSCAP file have tests that are not consistent as I configured for instance 
{code:java}
fs.protected_symlinks=1
{code}
 but the report still marks it as
{code:java}
error
{code}. Another example is test 
{code:java}
_xccdf_org.ssgproject.content_rule_sshd_set_idle_timeout_
{code}
 although it is set in /etc/ssh/sshd_config to be 
{code:java}
ClientAliveInterval interval 600
{code}
.

The tool that's easiest to use with these OSCAP scans is called SCAP-Workbench. See https://www.open-scap.org/tools/scap-workbench/.

Please download and install the workbench, download the attached policy, and scan several production ubuntu 16.04 servers to see whether the policy works correctly on them. If the policy fails in the same places that are reported above, try to modify the policy language so the bugs are resolved. If the policy language cannot be fixed, then eliminate the problematic sections of the template. Either way, upload an improvement by attaching it to this ticket when it's resolved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/May/17 6:08 PM;sandeep24;pass-key.png;https://jira.hyperledger.org/secure/attachment/10701/pass-key.png","03/May/17 4:08 AM;danielhardman;ssg-sovrin-basic-node-ubuntu1604.xml;https://jira.hyperledger.org/secure/attachment/10697/ssg-sovrin-basic-node-ubuntu1604.xml","03/May/17 6:05 PM;sandeep24;workbench.png;https://jira.hyperledger.org/secure/attachment/10700/workbench.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0n3:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,lsc,sandeep24,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/May/17 6:10 PM;sandeep24;Hi Daniel

I have gone through the Oscap docs,got fair idea of what it does and installed Workbench as part of it on Windows . Is there a way to connect without loading key file here?
 !workbench.png|thumbnail!  which if I proceed asking for a key pass for which if I give ""yes"" as input is failing to connect to remote host.
 !pass-key.png|thumbnail! 

Also I tried to do the same from CLI, but somehow missing an option.

 ;;;","03/May/17 9:57 PM;danielhardman;It looks to me like you've tried to connect to a fresh ubuntu instance on amazon; these instances usually have sshd configured to require a private key to connect (so, ssh -i <keyfile> ubuntu@xyz). Instead, try scanning an ubuntu server that has sshd configured to accept password-based login.

Alternatively, you could ssh to a server using putty or a similar client, and then run the oscap command-line tool instead of trying to use the gui. Is this what you meant when you said you tried the same from the CLI?;;;","04/May/17 4:39 PM;lsc;I had the same issue where the workbench didn't allow me to login as i already enabled 2FA and SSH key access to the server. So i had to download and use the oscap-ssh tool and modified the shell script to scan my machine with 2FA (Google Authenticator) and SSH key authentication. Otherwise as Daniel said - use a vanilla Ubuntu box with normal plain password authentication.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - ClientZStack should have a provision to disconnect a client,INDY-4,16708,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,victor.muzychenko,lovesh.harchandani,ryjones,13/May/17 4:12 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,SovrinCOREteam,ZeroMQ,,,,"For multipart messages where the addr of the remote socket is not known (listener in ClientZStack), the remote cannot be disconnected, the consequence is that the node cannot forcefully disconnect the client, need to find some way to either send a FIN flag or something else. This mailing list thread and its replies might help, https://lists.zeromq.org/pipermail/zeromq-dev/2016-August/030774.html. Some links from zyre codebase https://github.com/zeromq/zyre/blob/055219523325cef4e87941e07abc39718d7350e4/src/zyre_node.c#L555 and https://github.com/zeromq/zyre/blob/055219523325cef4e87941e07abc39718d7350e4/src/zyre_node.c#L948. Once this is done, unskip testClientRetryRequestWhenAckNotReceived and ensure it works",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxv6f:",,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - No error messages when TCP connection is not available for ZMQ,INDY-5,16709,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,victor.muzychenko,kelly.wilson,ryjones,13/May/17 4:11 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,1.0,,,,0,SovrinCOREteam,,,,,"I spent many hours trying to figure this one out.The issue was I had setup a network before our ZMQ builds allowing UDP ports 9701-9799, but not TCP ports. This was working with RAET. When we had switched to ZMQ the system no longer worked because the TCP port range 9701-9799 was not allowed through my firewall.No error messages were thrown telling me there was an issue with TCP or to check my firewall.We found the issue by looking up the messages we were getting in debug mode within the Zstack.py file. After walking through the code it occured that we did not have TCP ports open.*We need an error message thrown if the TCP port range 9701-9799 is not open.**Here is the section of code we traced the issue to, but again this only returned DEBUG messages and an ERROR needs to be thrown.*{code}    def transmit(self, msg, uid, timeout=None):        # Timeout is unused as of now        assert uid in self.remotes        socket = self.remotes[uid].socket        if socket:            msg = self.prepMsg(msg)            try:                # noinspection PyUnresolvedReferences                socket.send(self.signedMsg(msg), flags=zmq.NOBLOCK)                logger.debug(                    '{} transmitting message {} to {}'.format(self, msg, uid))                return True            except zmq.Again as ex:                logger.debug('{} could not transmit message to {}'.format(self, uid))                return False        else:            logger.warning('{} has uninitialised socket for remote {}'.                        format(self, self.remotes[uid]))            return False{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxv6n:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - Merge PR & redeploy sovrin.org to correct link to GST,INDY-6,16710,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,kelly.wilson,admin,ryjones,13/May/17 4:12 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,sovrin.org,,,,,"The changes to sovrin repos mean that the link from the docs page sovrin.org points to the old GST file.I have edited the .html and submitted a pull request: https://github.com/sovrin-foundation/sovrin.org/pull/1The related ticket (SOV-229) involves improvements to the GST itself, but the link can and should be corrected independently of that.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxv6v:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Sovrin Project team (Evernym Jira ""SOV""): Log into Hyperledger's Jira and comment on this story when you've done it! :)",INDY-7,16833,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,18/May/17 5:45 AM,09/Oct/19 6:36 PM,28/Oct/23 2:46 AM,09/Oct/19 6:36 PM,,,,,0,6Months,,,,,"You may need to create a Linux Foundation account if you don't already have one. 

If you DO create a new LF account, please use the same email you use for github (if you can). If not, the @evernym mail should be fine. For DSR: Please use the same emails you use for logging into the Evernym JIRA domain.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-987,,,,Impediment,,,,,,"1|hzygnj:",,,,,,,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,anastasia.tarasova,andkononykhin,anikitinDSR,ashcherbakov,avkrishnan,cybermag,danielhardman,darrell.odonnell,Derashe,devin-fisher,dkulic,drummondreed,dsurnin,esplinr,faisal00813,gudkov,HeenaLulla,jamesmonaghan,jankokrstic,KitHat,krw910,ljiljanam,MRJCrunch,mzk-vct,nage,NataliaDracheva,ozheregelya,p5n,peacekeeper,pradeep1991singh,rajesh.kalaria,sergey.khoroshavin,Sergey.Kupryushin,sergey.minaev,SergeyPalamarchuk,sergey-shilov,SowjanyaPV7,spivachuk,stevetolman,TechWritingWhiz,TelegramSam,tharmon,Toktar,tylerq,viswa0269,VladimirWork,wagh12,zhigunenko.dsr,,,"18/May/17 5:52 AM;devin-fisher;I'm here - Devin Fisher;;;","18/May/17 5:55 AM;nage;Nathan, checking in.;;;","18/May/17 6:07 AM;danielhardman;Here I am!;;;","18/May/17 6:48 AM;krw910;Here I am;;;","18/May/17 6:54 AM;tharmon;僕はここにいる。;;;","18/May/17 7:11 AM;stevetolman;I'm here.;;;","18/May/17 11:44 AM;rajesh.kalaria;I am here.;;;","18/May/17 1:27 PM;pradeep1991singh;Here I am;;;","18/May/17 5:47 PM;ashcherbakov;I'm here;;;","18/May/17 6:10 PM;alexander.shekhovcov;I'm here;;;","18/May/17 6:11 PM;dsurnin;I'm here;;;","18/May/17 6:37 PM;aleksey-roldugin;I'm here;;;","18/May/17 7:25 PM;mzk-vct;I'm here;;;","18/May/17 9:01 PM;gudkov;I'm here;;;","18/May/17 9:11 PM;sergey.minaev;I'm here;;;","18/May/17 9:54 PM;TelegramSam;I'm here;;;","18/May/17 11:38 PM;jamesmonaghan;I'm here;;;","19/May/17 12:11 AM;andkononykhin;I'm here;;;","19/May/17 2:26 AM;mgbailey;I'm here;;;","19/May/17 3:48 AM;drummondreed;I'm here (once I figure out how to log in ;) );;;","19/May/17 4:47 AM;darrell.odonnell;I'm here.;;;","22/May/17 12:49 PM;avkrishnan;I'm here.;;;","24/May/17 6:29 PM;VladimirWork;I'm here.;;;","24/May/17 7:52 PM;spivachuk;I'm here;;;","26/May/17 1:53 AM;TechWritingWhiz;I'm here...;;;","29/May/17 8:19 PM;ozheregelya;I'm here.;;;","15/Jun/17 11:21 PM;MRJCrunch;Here I am;;;","16/Jun/17 4:04 PM;p5n;I'm here.;;;","16/Jun/17 6:00 PM;anastasia.tarasova;I'm here.;;;","16/Jun/17 11:02 PM;cybermag;I am here.;;;","28/Jun/17 12:51 AM;HeenaLulla;I am here.;;;","06/Jul/17 6:49 PM;peacekeeper;Here.;;;","07/Jul/17 12:11 AM;srottem;Here.;;;","02/Aug/17 7:32 PM;SowjanyaPV7;I am here.;;;","02/Aug/17 7:32 PM;faisal00813;Here;;;","02/Aug/17 7:40 PM;viswa0269;I am Here;;;","28/Aug/17 7:11 PM;sergey-shilov;Here I am;;;","08/Nov/17 1:11 AM;anikitinDSR;Here I am;;;","16/Jan/18 12:58 AM;Derashe;Here I am;;;","24/Jan/18 5:55 PM;zhigunenko.dsr;Here I am;;;","02/Feb/18 7:20 PM;donqui;'Here I am, this is me...';;;","02/Feb/18 7:36 PM;nemanja.veskovic;https://www.youtube.com/watch?v=YJyNoFkud6g;;;","02/Feb/18 9:42 PM;dkulic;Hi all!;;;","14/Feb/18 6:41 PM;jankokrstic;Here I am;;;","27/Feb/18 7:13 PM;sergey.khoroshavin;Here I am;;;","27/Feb/18 10:51 PM;Toktar;I'm here;;;","28/Feb/18 4:40 PM;SergeyPalamarchuk;Here I am;;;","04/Apr/18 7:25 PM;ljiljanam;Hello;;;","10/Apr/18 7:27 AM;esplinr;Hello world!;;;","23/Apr/18 5:47 PM;KitHat;Here I am;;;","04/May/18 2:29 PM;pradeep1991singh;Here again.;;;","07/May/18 1:49 PM;wagh12;Here I am ;;;","19/Jul/18 10:30 PM;Sergey.Kupryushin;Here I am;;;","09/Aug/18 9:34 PM;NataliaDracheva;Here I am.;;;"
Client crash on ubuntu 17.04,INDY-8,17051,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,dsurnin,dsurnin,24/May/17 8:29 PM,30/Mar/19 5:36 AM,28/Oct/23 2:46 AM,30/Mar/19 5:36 AM,,,,,0,should,,,,,"From the doc
https://docs.google.com/document/d/1fUrvt8rEekZmpfHjoeod7ZmWh3ISvSf-18vK5yTH6RY/edit#heading=h.16lpdsh8ojbu

""Installation and Setup (Node, Client) For Ubuntu 16 and above""

I Installed sovrin client on fresh ubuntu 17.04 as described there.

No errors or warnings. Changed pool_transaction_sandbox to the content of ""Pool 1 - pool_transactions_sandbox""

Tried to started sovrin client and had a crash
{code:java}
tmh@tmhn:~/.sovrin$ sovrin
Loading module /usr/local/lib/python3.5/dist-packages/config/config-crypto-example1.py
Module loaded.
Traceback (most recent call last):
 File ""/usr/local/bin/sovrin"", line 78, in <module>
 run_cli()
 File ""/usr/local/bin/sovrin"", line 53, in run_cli
 withNode=withNode
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 111, in __init__
 super().__init__(*args, **kwargs)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 265, in __init__
 self.print(""\n{}-CLI (c) 2017 Evernym, Inc."".format(self.properName))
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 1703, in print
 super().print(msg, token=token, newline=newline)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 622, in print
 self.cli.run_in_terminal(part)
 File ""/usr/lib/python3/dist-packages/prompt_toolkit/interface.py"", line 621, in run_in_terminal
 result = func()
 File ""/usr/lib/python3/dist-packages/prompt_toolkit/interface.py"", line 770, in print_tokens
 print_tokens(self.output, tokens, style or self.application.style)
 File ""/usr/lib/python3/dist-packages/prompt_toolkit/renderer.py"", line 515, in print_tokens
 attrs = attrs_for_token[token]
 File ""/usr/lib/python3/dist-packages/prompt_toolkit/renderer.py"", line 219, in __missing__
 result = self.get_style_for_token(token)
 File ""/usr/lib/python3/dist-packages/prompt_toolkit/styles/from_dict.py"", line 143, in get_attrs_for_token
 for token in split_token_in_parts(token):
 File ""/usr/lib/python3/dist-packages/prompt_toolkit/styles/utils.py"", line 17, in split_token_in_parts
 for part in token + (':', ):
TypeError: unsupported operand type(s) for +: 'NoneType' and 'tuple'{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-712,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzy8a7:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,dsurnin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 2:03 AM;dsurnin;Such a behavior I have with stable repo.;;;","25/May/17 9:22 PM;dsurnin;I tested master repo as well - the same behavior.

However if I used following command to install client
{code:java}
pip install sovrin-client-dev{code}
I do not have a crash.

So probably the issue connected with deb packets.;;;","03/Aug/17 12:44 PM;dsurnin;the issue was caused by promt-toolkit package. ubuntu 16.04 has promt-toolkit v0.57 but ubuntu 17.04 has v1.0.9.

it looks like these versions handles None values different ways. I replaced None values with empty containers so now the client does not crash on start

however I suggest to test all the client usecases and compare the output and behavior.

 

plenum a3538766b0f84241d2bccb5a548f599d4c580aba

does not have any automated tests;;;","09/Aug/17 12:03 AM;ozheregelya;*Build Info:*
   indy-node-dev 1.0.80
   indy-plenum-dev 1.0.82
 OS/Platform: Ubuntu 17.04
 Setup: 4 nodes, 1 client

*Steps to Validate:*
 1. Install all necessary packages.
 2. Run the CLI.
 3. Look at formatting in the CLI.
 4. Check correctness of work client on Ubuntu 17.04 and nodes on Ubuntu 16.04.2.

*Actual Results:*
 Client works with minor problems in formatting (INDY-721). Also installation on Ubuntu 17.04 does not work on the latest version (INDY-720).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"[send NODE] Node demotion is broken because of new parameters validation in ""send NODE"" command",INDY-9,17052,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,aleksey-roldugin,aleksey-roldugin,24/May/17 8:40 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,1.5,,,0,,,,,,"h6. Build:

sovrin-client 0.3.103
h6. Steps to Reproduce:

1. Run sovrin CLI and connect to test pool.
 2. Run following commands for node blacklisting:
{code:java}
sovrin@test> new key with seed 000000000000000000AlexeySteward1
Key created in keyring Default
Identifier for key is EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr
Current identifier set to EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr
sovrin@test> send NODE dest=6aRzgahqK9mfhCVwxpunLs54PLpQxEFUyJiWdbwQ6knZ data={'alias': 'Node5', 'services': []}
Sending node request for node identifier 6aRzgahqK9mfhCVwxpunLs54PLpQxEFUyJiWdbwQ6knZ by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1495622029208764)
Node request failed with error: client request invalid: UnauthorizedClientRequest(""Missing some of {'client_port', 'alias', 'node_port', 'client_ip', 'node_ip'}"",){code}
h6. Expected Result:

Command is ran without validation errors. The general behavior for ""send NODE"" command should be following: if some not mandatory parameters are absent, command should be run successfully. If command contains unexpected parameters they should be validated.

 

 ",,,,,,,,,,,INDY-31,INDY-88,,,,,,,,,,,,,,,INDY-133,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy1bz:",,,,,,H1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,danielhardman,krw910,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/May/17 10:56 PM;mzk-vct;Check for SERVICE field in _plenum/server/pool_req_handler.py_, method _authErrorWhileAddingNode_ was disabled because it is incompatible with related logic in client 
(check test testSuspendNodeWhichWasNeverActive). That logic should be updated.;;;","01/Jun/17 7:52 PM;alexander.shekhovcov;!https://jira.hyperledger.org/images/icons/emoticons/check.png|width=16,height=16!

 *Problem reason:*
 # SERVICES field was required for the NODE txn

*Changes:*
 # SERVICES field is optional for the NODE txn

*Committed into:*

*-*

*Risk factors:*

-
*Risk:* 
Low

*Covered with tests:*

 

testSuspendNode

testSuspendNodeWhichWasNeverActive

 

*Recommendations for QA:*

 ;;;","02/Jun/17 1:20 AM;krw910;This is working in stable build 0.3.15;;;","06/Jun/17 12:39 PM;krw910;This just reappeared in RC Build
*Client *
python3-stp=0.1.10
python3-ledger=0.2.14
python3-rlp=0.5.1
python3-sha3=0.2.1
python3-state-trie=0.1.1
python3-plenum=0.3.16
python3-sovrin-common=0.2.11
python3-anoncreds=0.3.3
sovrin-client=0.3.20

*Node *
python3-stp=0.1.10
python3-ledger=0.2.14
python3-rlp=0.5.1
python3-sha3=0.2.1
python3-state-trie=0.1.1
python3-plenum=0.3.16
python3-sovrin-common=0.2.11
sovrin-node=0.3.19 
 ;;;","07/Jun/17 2:17 AM;alexander.shekhovcov;Have not reproduced on the same versions of the packages:
{code:java}
sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'alias': 'Node5', 'services': []}
Sending node request for node identifier 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc by GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL (request id: 1496765484952464)
8aHWDaPUMfMxecenRqHs6XSpU2BPZF3tesUNpUrAvNzT disconnected from Node5C
Node request completed 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc{code}
And I have found all required for this feature code in the stable branch. ;;;","14/Jun/17 1:04 PM;danielhardman;Since this issue is blocked by INDY-88, I am sending it back to testing until that ticket is also ready for customer validation.;;;","15/Jun/17 2:57 AM;aleksey-roldugin;Verified in scope of [INDY-88|https://jira.hyperledger.org/browse/INDY-88].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: Validator Private Keys are world readable,INDY-10,17065,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,farooq_m_khan,farooq_m_khan,25/May/17 2:28 AM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,Must,,,,,"Validator Private Keys are world readable

Check output of this command as any user: cat /home/sovrin/.sovrin/Node1/private_keys/Node1.key_secret

This file should only be readable by the user account under which the Validator code is executed, so a permission of 400. 

It need not be writable anyone unless we provide option to change the Validators Key-Pair dynamically
  
  ","Ubuntu 16, QA-Pool-Shakedown-P1, Sovrin-Node Build # 0.3.11",,10800,10800,,0%,10800,10800,,,,,,,,,INDY-30,,,INDY-2,,,,,,,,,,,,,,,"25/May/17 2:40 AM;farooq_m_khan;Screen Shot 2017-05-24 at 11.09.36 PM.png;https://jira.hyperledger.org/secure/attachment/10860/Screen+Shot+2017-05-24+at+11.09.36+PM.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy23r:",,,,,,H2,H3,,,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,devin-fisher,farooq_m_khan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 7:49 AM;devin-fisher;I think this should be scrubbed. ;;;","29/Jun/17 11:06 PM;alexander.shekhovcov;(/)

*Problem reason:*
 - the node creates secret keys readable for all users

*Changes:*
 - set 600 for *.key_secret

 - set 644 for *.key

*Committed into:*
 [https://github.com/evernym/stp/pull/39]

*Risk:*
 Low

*Covered with tests:*

stp: 
 * test_zstack_creates_keys_with_secure_permissions
 * test_create_certs_from_fromkeys_sets_600_for_secret_644_for_pub_keys

 

*Recommendation:*

check if the secret keys are only be readable by the user account under which the Validator code is executed.

Possible paths to secret keys

 
{code:java}
~/.sovrin/<node-name>/sig_keys/<node-name>.key_secret
~/.sovrin/<node-name>/private_keys/<node-name>.key_secret
{code}
 

 ;;;","04/Jul/17 9:57 PM;aleksey-roldugin;h6. BUILD

sovrin-node 0.4.9

h6. VERIFICATION
Result of commands below performed by different from author user is the empty file with ""Permission denied"" message.
{code:java}
~/.sovrin/<node-name>/sig_keys/<node-name>.key_secret
~/.sovrin/<node-name>/private_keys/<node-name>.key_secret
{code}

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Intermittent failure of plenum's tests,INDY-11,17075,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,tylerq,andrey.goncharov,andrey.goncharov,25/May/17 5:00 AM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,"pool_transactions/test_nodes_with_pool_txns.py test module fails from time to time with ""Failed tests: testAdd2NewNodes
Error in tests: ERROR at setup of testNodePortCannotBeChangedByAnotherSteward, ERROR at setup of testNodePortChanged, ERROR at setup of testNodeKeysChanged""

I attached the log file",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 5:27 AM;andrey.goncharov;Test-Report.txt;https://jira.hyperledger.org/secure/attachment/10863/Test-Report.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxpr:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 12:41 AM;ashcherbakov;Problem reason: 
- problem in a test 

Changes: 
- wait until the node is added before adding the next node
The tests succeeded for me ~40 times.

Risk factors:
-  Nothing is expected.

Risk:
- Low
;;;","27/May/17 5:35 AM;krw910;The test continues to pass after 40+ runs so I am moving this ticket on.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A node should start catch up process if it realizes that it has lagged behind the other node.,INDY-12,17077,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,krw910,krw910,krw910,25/May/17 5:51 AM,30/Mar/19 5:36 AM,28/Oct/23 2:46 AM,30/Mar/19 5:36 AM,,1.5,,,0,,,,,,"A node might get disconnected from other nodes for long enough that it misses requests, now when it regains connectivity it will be lagging behind and will not be able to process newer PRE-PREPAREs, PREPAREs and COMMITs so would essentially stall. The only solution as of now is to restart the node. This needs to be fixed, we have CHECKPOINT in the code which is sent periodically, as of now it only helps in garbage collection. It should be used as opportunity to start a catch up process node come to a start where it can start processing new requests again.",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-103,INDY-335,,,,,,,"25/May/17 5:51 AM;krw910;980_Comments.PNG;https://jira.hyperledger.org/secure/attachment/10864/980_Comments.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxpj:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 5:49 AM;krw910;This did not work unless services were restarted. Here are my notes:

*{color:#205081}Versioning{color}*
*Node*
python3-stp=0.1.51
python3-ledger=0.2.28
python3-state-trie=0.1.15
python3-plenum=0.3.108
python3-sovrin-common=0.2.70
sovrin-node=0.3.116

*Client*
python3-stp=0.1.51
python3-ledger=0.2.28
python3-state-trie=0.1.15
python3-plenum=0.3.108
python3-sovrin-common=0.2.70
python3-anoncreds=0.3.8
sovrin-client=0.3.111

*{color:#205081}Test Setup{color}*
6 Active Nodes
1 Active Client

*{color:#205081}Test Steps{color}*
Ran the following script to setup for load test which creates 200 Trust Anchors one at a time
python3 add_keys.py Steward1 000000000000000000000000Steward1

I then ran the following to quickly add 500 NYMs to the ledger
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once

At this point I had 712 entries on each node and verified this by doing a line count of the transactions file.

I then sent the following command to add 1800 NYMs one at a time which takes about 30 minutes.
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 1800

While this was running I shut off the TCP ports in the 9,000 range on Node 6. After about 330 transactions I enabled the TCP ports in the 9,000 range. I did it this way to create a scenario where a node has fallen behind.
After enabling the ports on Node 6 I disabled the ports on Node 5 so I would have two nodes to compare to see if they caught up.

*{color:#205081}Results{color}*
*NODE 6*
After the test completed Nodes 1-4 were all in sync. The had transaction files named 1, 1001, and 2001 with a total count of 2,512 which is correct for the commands I sent.
Node 6 - Did not take any new transactions after enabling the ports for communication and did not catch up with the other nodes. I found that the service had thrown an exception after enabling the ports. ""sudo systemctl status sovrin-node""
{code}
     return self.gen.send(None)
   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 672, in serviceReplicas
     c = self.serviceReplicaInBox(limit)
   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1004, in serviceReplicaInBox
     msgCount += replica.serviceQueues(limit)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 519, in serviceQueues
     r = self.dequeuePrePrepares() if self.node.isParticipating else 0
   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 1414, in dequeuePrePrepares
     pp, sender, _ = self.prePreparesPendingFinReqs.pop(i)
 IndexError: pop index out of range
{code}

I then sent a single transaction to see if it would take anything new and Node 6 did nothing.

*NODE 5*
I then enabled the ports back on Node 5. I watch the log on Node 3 and it was communicating with Node 5, but Node 5 would not catch up with the missing transactions. I checked the service on Node 5 and it was running fine.

I then sent a single transaction to see if Node 5 would take the new transaction and it did not.

*RESTART NODE SERVICES*
I restarted the node services on Nodes 5 and 6. After the restart both nodes caught up and added a blank line entry to the transaction file before adding in what was missing so they each have one more line count than the other nodes.
;;;","30/May/17 2:29 AM;andrey.goncharov;[~krw910] I investigated the logs and it seems like the missing catch up is not the issue here. I recorded a [small demo for you with my findings|https://drive.google.com/file/d/0BxskuV-A2baheVcybDAyNGtTeEk/view?usp=sharing]. Since you sent so many transactions the most probable cause is a view change bug that should be fixed by Lovesh soon.;;;","30/May/17 7:20 AM;krw910;[~andrey.goncharov] that is what I was hoping you would say. This is why I said I was blocked before. I think we need to wait until the view change issue is resolved before moving forward with this test.;;;","30/May/17 9:55 PM;krw910;This is blocked by tickets INDY-13 and INDY-14. Whenever I run a large number of transactions, even one at a time, I run into these two tickets. I need to be able to create a fair number of transactions and have other coming in so that I can test a node falling behind and having to catch up.;;;","31/May/17 12:02 AM;krw910;When given enough time the node can catch up. There are scenarios where it has issues, but the first one it captured in INDY-70. Once INDY-70 has been fixed I will retest the other scenarios where I believe we may have an issue, but we think INDY-70 may address my other concern.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Vulnerability: Slow nodes can be stalled after a view change.,INDY-13,17078,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,25/May/17 6:00 AM,30/Mar/19 5:36 AM,28/Oct/23 2:46 AM,30/Mar/19 5:36 AM,,1.5,,,0,Must,,,,,"The election process needs to communicate what is the transaction and state root hash apart from the last ordered Pre-Prepare sequence number

eg: What if A is malicious, and C and D during a catch up get inconsistent catchup messages from A and B? Perhaps the PRIMARY declaration message needs a root hash, and f+1 consistent responses for both Last Ordered Batch number AND Txn Root Hash

*Remedy*: The election process needs to communicate what is the transaction and state root hash apart from the last ordered Pre-Prepare sequence number.

POA: [https://docs.google.com/document/d/1KixMMdD7cMfaA4yg-ghL72LEESOkcP8TPccvRrhgW5U/edit]",,,32400,32400,,0%,32400,32400,,,,,,INDY-69,INDY-75,INDY-334,,,,,,,,,,,,,,,,,,,"25/May/17 6:35 AM;danielhardman;POAsforSOV-10211020.pdf;https://jira.hyperledger.org/secure/attachment/10865/POAsforSOV-10211020.pdf",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1qv:",,,,,,H1,H2,H3,H4,H5,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 6:35 AM;danielhardman;I'm attaching a copy of the POA (Plan of Attack) doc because I don't know if the link to the google doc will be usable for everybody.;;;","01/Jun/17 12:23 AM;lovesh;Here is the doc for discussions regarding new view change protocol, https://docs.google.com/document/d/1oftK70I00wPGXFvFqiA2tmpwU7-kIjgNNieYkZcFkic/edit#;;;","02/Jun/17 10:01 PM;ashcherbakov;We've chosen Approach 4 from the doc above.;;;","27/Jun/17 11:45 PM;ashcherbakov;Problem reason: 
- view change was broken because of recent protocol changes (batches, state)

Changes: 
- a primary is now selected in a round-robin fashion instead of Election protocol
- we use catch-up to synchronize states during view change
- some bugs in catch-up were fixed

Build:
We have a build (created manually) from a simple-election branch:
- `sudo add-apt-repository ""deb https://repo.evernym.com/deb xenial simple-election""`
- `sudo add-apt-repository ""deb https://repo.sovrin.org/deb xenial simple-election""`

Risk factors:
- View change
- Load testing

Risk:
- Medium+

Covered with tests:
- https://github.com/evernym/plenum/tree/simple-election/plenum/test/view_change
- https://github.com/evernym/plenum/tree/simple-election/plenum/test/primary_selection
- https://github.com/evernym/plenum/tree/simple-election/plenum/test/view_change/slow_nodes
- https://github.com/evernym/plenum/tree/simple-election/plenum/test/node_catchup

Recommendations for QA (optional):
- run a load test
- check that even if a view change is don,e we can still process handling requests;;;","13/Jul/17 5:26 AM;krw910;Blocked by INDY-406;;;","18/Jul/17 12:41 PM;krw910;We are finding issues around the fix that was implemented for this ticket. However this ticket was to change how ""view change"" was handled. I have verified that we are no longer going through an election process, but we are indeed using a round robin approach. So I am closing this ticket and we will write new tickets for any issues that come from the change.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The Pre-Prepare needs to have both pre state root and post state root. Also reverting the state root needs to happen reactively.,INDY-14,17080,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,lovesh,lovesh,krw910,25/May/17 6:02 AM,09/Oct/19 6:48 PM,28/Oct/23 2:46 AM,09/Oct/19 6:48 PM,,,,,0,7Months,Could,LoveshReview,,,"Currently a primary reverts PRE-PREPARE when it sees that those will not have consensus and the view will change but this needs to stop. The PRE-PREPARE will contain state roots for both before applying it and after applying it. That information should be used to revert, eg: If B has applied 7, but ordered is 6, then it's uncommitted root hash will be 7 and it's committed root will be 6. When a new primary sends a new batch 7, then B checks if the post-hash in the PRE-PREPARE is the same as it's uncommitted root hash. If they are different, then B reverts the uncommitted back to committed root hash, and then applies batch 7. If they are the same, then it considers batch 7 already applied. A benefit that these pre-roots give us is a way to prove the maliciousness of the primary since if a primary is sending correct pre-root and incorrect post root, it is malicious and since the messages would be signed, they serve as a proof.
POA https://docs.google.com/document/d/1KixMMdD7cMfaA4yg-ghL72LEESOkcP8TPccvRrhgW5U/edit",,,,,,,,,,,,,,INDY-69,,,,,,,,,,,,,,,,,,,,,"25/May/17 6:36 AM;danielhardman;POAsforSOV-10211020.pdf;https://jira.hyperledger.org/secure/attachment/10866/POAsforSOV-10211020.pdf",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzy0uf:",,,,,,H2,,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,krw910,lovesh,sergey.khoroshavin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 6:36 AM;danielhardman;I'm attaching a copy of the POA (Plan of Attack) doc because I don't know if the link to the google doc will be usable for everybody.;;;","28/Jun/17 9:55 PM;lovesh;[~stevetolman] [~danielhardman] This is a lower priority issue;;;","10/Oct/18 10:52 PM;sergey.khoroshavin;*Triage*
This seems more like a feature request than a bug, so converting type of this issue. Also it looks like quite a major change in protocol, probably it needs more peer review.;;;","09/Oct/19 6:48 PM;ashcherbakov;We have audit ledger now which ensures data consistency during consensus (audit root hash is used);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to accept non uft8 - UnicodeDecodeError: 'utf-8' codec can't decode byte,INDY-15,17081,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,tylerq,krw910,krw910,25/May/17 6:14 AM,30/Mar/19 5:36 AM,28/Oct/23 2:46 AM,30/Mar/19 5:36 AM,,1.5,,,0,,,,,,"A transaction was sent that was not utf-8 which was not expected so the services on the nodes crashed.

 

{color:#d04437}*Error*{color}
{code:java}
await self._serviceStack(self.age)
File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
return self.gen.send(None)
File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 639, in _serviceStack
self._receiveFromListener(quota=self.listenerQuota)
File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 599, in _receiveFromListener
self._verifyAndAppend(msg, ident)
File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 580, in _verifyAndAppend
self.rxMsgs.append((msg.decode(), ident))
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xae in position 2: invalid start byte{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxq7:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 6:16 AM;krw910;Fix from Lovesh Harchandani
 [https://github.com/evernym/stp/commit/fd68242d94e86d958d94108747a9b4581421d0bd#diff-0236f66d0eed2d1c7c0fdf4394ac91efR580]

and here is the test

[https://github.com/evernym/stp/commit/fd68242d94e86d958d94108747a9b4581421d0bd#diff-7ffd3624d890e8f700882833e216fc4cR74];;;","25/May/17 6:17 AM;krw910;To test try sending something like this from CLI, `send ATTRIB dest=<some dest> raw={""k2"": ""v2\x9c""}` this should not end up in the ledger, and then `send ATTRIB dest=<some dest> raw={""k2"": ""v2""}`. Now you should see something in ledger what i am doing is adding a non utf-8 character `\x9c`;;;","25/May/17 6:47 AM;krw910;This fix is working and throws an appropriate error message.;;;","25/May/17 6:57 AM;danielhardman;I am going to reject this fix until we have a discussion, because it's not obvious to me that it's okay to require all attrib values to be utf-8. It seems to me that the ledger shouldn't make any assumptions about the nature of an attribute value–not even the assumption that it's text. What if the attribute value is a bitmap, for example?

If we decide that, no, attrib values must be utf8 text, then we can move the ticket back to done.;;;","25/May/17 10:06 AM;danielhardman;I discussed this with Jason, and he convinced me that requiring utf-8 text for all attrib values is a reasonable constraint for now. We may have to change this later, though.

This is a very narrow fix; it only applies to zmq messages, not to CLI input and so forth. Enforcing as part of a ZMQ read will pick up CLI stuff eventually, but there are other places that might have the same issue. I will explore those in separate tickets.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
We need to use ChunkedFileStorage for transactions in Ledger,INDY-16,17082,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,tylerq,ashcherbakov,krw910,25/May/17 6:21 AM,30/Mar/19 5:36 AM,28/Oct/23 2:46 AM,30/Mar/19 5:36 AM,,1.5,,,0,,,,,,"It turned out that we still use a simple text file storage for transactions (TextFileStorage). We need to use ChunkedFileStorage implementation.
 TextFileStorage stores all transactions in one huge file. It's not acceptable for MGL.
 ChunkedFileStorage supports rotation (every 1000 transactions) and easy indexing.

It was supposed to be done in the scope of batching.",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-104,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxqv:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,krw910,lovesh,tharmon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 6:21 AM;krw910;From [~mzk-vct]

Problem reason:
Initial problem was in usage of _defaultStore in Ledger - it is static method and it is overrided in Plenum.
There were some incompatibilities with Plenum and Sovrin Node that required modification of Ledger
Changes:
fixed usage of _defaultStore
move copying of default transactions files from Node (Plenum) to FileStore and successors of it
added some new tests
Builds:
sovrin-node=0.3.113
sovrin-client=0.3.105
Risk factors:
There was one test failing because of timeout, I had to skip it
https://evernym.atlassian.net/browse/SOV-1123
Covered with tests:
ledger/test/test_chunked_file_store.py
ledger/test/test_ledger_chunked_store.py
ledger/test/test_file_stores_equailty.py
all tests of plenum, node and client;;;","26/May/17 1:20 AM;krw910;Unable to upgrade existing nodes to the new chunked files. After upgrade the pool would not work. We need an upgrade path.;;;","26/May/17 10:24 PM;krw910;Note for [~krw910] when you test this upgrade from node build 110 to the build that has the migration fixed.;;;","27/May/17 2:17 AM;krw910;[~andrey.goncharov] after reviewing the implemetation with [~tharmon] and [~nage] we came up with some suggestions on how to improve the implementation of chunking up the files. We don't want to end up with 25 years of files in one directory as this can cause issues. We also felt that breaking up the files at a 1,000 transactions was small. Here are Nathan's suggestions. If you have questions around this please communicate with Nathan.

# We should have a file extension on each file.
# Better breaking up of the files -- If possible can we break up the chunks by size like 100 MB or 200 MB files? If that is not the right solution lets at least increase the transaction count per file.
# We should zero pad the files so the ordering is easier to deal with 000001, 000002, 000003 and so on.
# Having all the files in one directory can also be an issue. We need to think about how this will look in 20 years of running. We should break up the files into sub-directories. Determining how many files to have in a given directory will also help determine how many digits to use in zero padding the files.

Let me know if you have questions and we can get more clarity and input from Nathan as needed.;;;","27/May/17 2:21 AM;ashcherbakov;Please include [~lovesh] into this discussion. ;;;","27/May/17 4:06 AM;lovesh;[~krw910] [~tharmon] [~nage]
# I am ok with adding extensions, something like indicating which kind of ledger it is. 
# Breaking by size is not correct since that does not allow us to locate a particular transaction's file, increasing the size is ok but  1000 is a good number, since if the files are big then you are iterating over a large file to get to a transaction since our transactions are not fixed size. The way you look up a transaction with a sequence number in such an implementation is by getting 2 parts of data for a sequence number, a file name and a line offset (its a line offset, not a byte offset so you cant fseek).
# I dont understand why zero pad, since its unicode data
# Agree to having multiple directories.;;;","27/May/17 6:07 AM;tharmon;[~lovesh]

*#2*

-First of all, if I understand correctly, these are the historical record of what's gone into the ledger, so there should be no case where the validator is actually iterating over them. Lookups should be happening from the database backend, not the file system.-

-Second of all, this design needs to handle the needs of a large network with hundreds of thousands of transactions a day. So, no, 1000 is not a good size. All that's going to do is create a huge number of files on the filesystem. This can cause a number of difficulties, not just with client tools, but also with the memory paging in the OS.-

-In the one case where one would be reading through the files (i.e., doing a rebuild), this should be done via a sequential read, not slurping the file into memory, so there's really not a seek issue, either.-

-I can be convinced to of fixed transactions vs. fixed size, but if the filename is recording what transaction starts at that point, the only downside is that it becomes slower to determine which file to look in (if doing a seek, which I still don't understand the need for) because the names aren't necessarily consistent.-

*#3*

This forces two different things
 * The zero padding approach requires that we actually sit down and decide how many transactions need to be handled. Once we have that answer, determining the strategy becomes much easier.
 * As as system admin, I don't want files interleaving with one another in the directory listing just because the file naming scheme doesn't zero-pad. I want to be able to sort the files simply and easily, and creation time or last access time can't be trusted. So, it needs to be done with the filename.

To be clear, the filename {{1000.log}} should be {{0000000000000001000.log}} instead.;;;","27/May/17 6:49 AM;tharmon;Having had some additional conversations here, I'm withdrawing part of my above comment. That said, if we are, in fact, sequentially reading through these files to find specific transactions, we need to rethink this strategy. There are some techniques that we could use to remove this overhead, which will only grow as the ledger becomes larger.

Do we have any documentation that outlines exactly the interaction between the database and the files? Specifically, how is the read of these files implemented and under what circumstances is it done?;;;","29/May/17 6:02 PM;lovesh;[~tharmon] I did not realise that the zero pad was about file names. I still don't understand the value of zero padding the file name, is the concern that file with name `109.log` will appear before `2.log` in the output of `ls`, if yes then `ls -1v *.log` fixes that.
Regarding reading from these files, we don't have documentation but here is a brief: 
# A node reads from these files when another node is trying to sync with it and requests some transactions in a sequence with no gaps 
# A client is asking the reply for an already processed request which will be looked up by a sequence number.
The files are read into memory completely since keeping them small is the objective anyway.;;;","30/May/17 12:19 AM;andrey.goncharov;[~tharmon]

I've been testing my migration tool and found out that we won't be able to introduce a migration tool and apply our first migration at the same time. It happens because we can not update our update manager and have the result right away. In other words we can update the update procedure but it will take effect only for the next update and so on.

Still I can create a migration for you, but you will have to apply it manually for each node in the pool to do the migration to chunked file storage. Would you be willing to do that?;;;","30/May/17 9:56 PM;andrey.goncharov;[~tharmon] [~lovesh] Created a different story about [improving Chunked File Storage|https://jira.hyperledger.org/browse/INDY-104]. This story is about creating a migration for existing nodes;;;","30/May/17 11:16 PM;tharmon;[~andrey.goncharov], the test pool I need to upgrade is far enough behind that I'm expecting that we'll have to rip and replace in order to do the upgrade. That means we'll be reseting the ledger for that test pool, and that I'll have to be touching each machine. That's fine, as this is a test pool, but we should make sure we can identify these things moving forward so we can do staged releases when necessary.;;;","30/May/17 11:23 PM;andrey.goncharov;[~tharmon] thank you!

[~stevetolman] shouldn't we mark this ticket as invalid then?;;;","30/May/17 11:27 PM;tharmon;[~lovesh], I understand {{ls -1v *.log}} ""fixes"" this on Linux. However, in my opinion that's not a good enough reason to allow log files to interleave on a standard {{ls}} when zero padding fixes it on all operating systems. Also, when I put my sysadmin's hat on, interleaved log files is just plain sloppy.

Plus, as mentioned before, zero padding will force us to actually consider how many transactions and files this system will have to realistically support. This will then allow us to make sure we have a plan to appropriately store the number of files and transactions across multiple operating systems and file system types.

Regarding the chunk size of 1000, several of us (including [~danielhardman] and [~krw910]) were discussing this the other day. The small size makes sense if we are doing a sequential read of the files from a speed perspective. However, we could greatly speed the system up if we did the following:
 * Each transaction file was accompanied by a lookup file.
 * Each lookup file would contain:
 ** The hash of the associated transaction file
 ** Fixed length records that recorded the byte offset for each record in the transaction file.

This would allow the following lookup process:
 # Open the appropriate lookup file.
 # Seek to the appropriate record in the lookup file.
 # Read the byte offset for the record in the transaction file.
 # Close the lookup file.
 # Open the transaction file.
 # Seek to the appropriate record in the transaction file.
 # Read the transaction record.
 # Close the transaction file.

In cases where we wanted to do the sequential reads, we still could. We'd also have a known hash for each transaction file that could be quickly checked. It would also allow us to have far more than just 1000 records in the transaction file, which has a number of other benefits.;;;","31/May/17 12:47 PM;krw910;This was completed as originally planned. We held this ticket up because we could not upgrade to this change. We decided not to hold up this ticket for the upgrade since we have other tickets dealing with that.;;;","31/May/17 8:55 PM;lovesh;[~tharmon] What's wrong if we don't know the limit files/txns even though each file systems will have max limit on no of files. If we are maintaining metadata (lookup files) then why not maintain a BTree in the lookup file (just one lookup file for the complete ledger) and secondly is the hash needed to verify integrity of each file then we already have a merkle tree and nodes can request merkle root from any node for till a subset of txns but this is just one alternative, we dont loose much by storing hash of each file but i will rather maintain a btree like structure if we are keeping additional data, and if we are doing so much work, why not use an embedded database for ledger;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"[Error text] When one role has not enough permissions for action, corresponding error should be clearer",INDY-17,17083,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,25/May/17 6:23 AM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,1.5,,,0,,,,,,"Build:
sovrin-client 0.3.82

Description:
When one role has not enough permissions for some action, corresponding error should be clearer. For example, when some role that cannot add another roles tried to add one, he get's an error:

{code:java}
sovrin@test> send NYM dest=2kRdtJ2cv3dv4u4cjbnLUk89hxaAF6bmU4hMNQGVMW9x role=TRUSTEE
Adding nym 2kRdtJ2cv3dv4u4cjbnLUk89hxaAF6bmU4hMNQGVMW9x
Error: client request invalid: UnauthorizedClientRequest('100 cannot add 0',)
{code}

In this error numbers (100 and 0) should be changed to corresponding roles.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxnr:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 6:24 AM;krw910;Comment from [~ashcherbakov]

 

Problem reason:
 - We use encoded (int) values for roles in transactions, but we should use corresponding human-readable names of the roles in CLI/error messages/etc.

Changes:
 - Use role name instead of encoded value in error messages

Build:
 - sovrin-client (master): 0.3.98
 - sovrin-node (master): 0.3.105

Risk factors:
 - Error messages in CLI

Risk:
 - Low

Covered with tests:
 - sovrin_node/test/suspension/test_suspension.py: testTrusteeCannotChangeVerkey
 - sovrin_client/test/cli/test_nym_suspension.py: testTrusteeSuspendingTrustAnchor
 - sovrin_client/test/cli/test_pool_upgrade.py: test_pool_upgrade_rejected
 - sovrin_client/test/test_nym_attrib.py: testNonTrustAnchorCannotAddAttributeForUser, testOnlyUsersTrustAnchorCanAddAttribute, testStewardCannotAddUsersAttribute;;;","07/Jun/17 8:50 PM;ozheregelya;*Verified on following build:*
sovrin-client version: 0.3.122
sovrin-node version: 0.3.115
OS/Platform: Ubuntu 16.04.2 LTS
*Steps to Validate:*
1. Open the CLI (sovrin). 
2. Connect test (sovrin> connect test)
3. Try to add NYM as STEWARD role.
{code}
sovrin@test> new key with seed 000000000000000000000000Steward1
sovrin@test> send NYM dest=2kRdtJ2cv3dv4u4cjbnLUk89hxaAF6bmU4hMNQGVMW9x role=TRUSTEE
{code}
*Actual Results:*
Error message is:
{code}
sovrin@test> send NYM dest=2kRdtJ2cv3dv4u4cjbnLUk89hxaAF6bmU4hMNQGVMW9x role=TRUSTEE
Adding nym 2kRdtJ2cv3dv4u4cjbnLUk89hxaAF6bmU4hMNQGVMW9x
Error: client request invalid: UnauthorizedClientRequest('STEWARD cannot add TRUSTEE',)
{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade: Unable to upgrade Stable 0.3.7 to Stable 0.3.13,INDY-18,17084,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,tylerq,krw910,krw910,25/May/17 6:25 AM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,1.5,,,0,,,,,,"I am unable to upgrade Stable build (node) 0.3.7 to Stable build (node) 0.3.13

When trying to upgrade from build 0.3.7 to 0.3.13 I get the following error.

Another issue is that there was a change to the scheme where a new field in the transactions was added for signature. Even getting past the error below the upgrade should still fail.

{code}
Unpacking sovrin-node (0.3.13) over (0.3.7) ...
dpkg: error processing archive /var/cache/apt/archives/sovrin-node_0.3.13_amd64.deb (--unpack):
 trying to overwrite '/usr/local/lib/python3.5/dist-packages/data/transactions_live', which is also in package python3-sovrin-common 0.2.5
dpkg-deb: error: subprocess paste was killed by signal (Broken pipe)
~/.sovrin /
/
mv: cannot stat '/usr/local/bin/upgrade_sovrin_node_ubuntu1604.sh': No such file or directory
mv: cannot stat '/usr/local/bin/upgrade_sovrin_node_ubuntu1604_test.sh': No such file or directory
Preparing to unpack .../python3-sovrin-common_0.2.8_amd64.deb ...
Unpacking python3-sovrin-common (0.2.8) over (0.2.5) ...
Preparing to unpack .../python3-plenum_0.3.12_amd64.deb ...
Unpacking python3-plenum (0.3.12) over (0.3.10) ...
Preparing to unpack .../python3-stp_0.1.8_amd64.deb ...
Unpacking python3-stp (0.1.8) over (0.1.5) ...
Processing triggers for man-db (2.7.5-1) ...
Processing triggers for ureadahead (0.100.0-19) ...
Processing triggers for systemd (229-4ubuntu17) ...
Processing triggers for libc-bin (2.23-0ubuntu7) ...
Processing triggers for install-info (6.1.0.dfsg.1-5) ...
Processing triggers for ufw (0.35-0ubuntu2) ...
Processing triggers for hicolor-icon-theme (0.15-0ubuntu1) ...
Errors were encountered while processing:
 /var/cache/apt/archives/sovrin-node_0.3.13_amd64.deb
E: Sub-process /usr/bin/dpkg returned an error code (1)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxpz:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 6:26 AM;krw910;Comment from [~ashcherbakov]

Problem reason:
a new transaction field is added, so that serialized data contains less fields than it's now. An exception was thrown during de-serialization (it was expected that the number of serialized fields for a transaction is always equal to the current number of fields)
Changes:
it turned out there were no tests for CompactSerizliser (the serializer we currently use for ledger) - covered with tests
if we have more fields than in the current transaction - use a None value
make merkle tree of old transactions the same for the case when we added new fields
Committed into:
sovrin-node 0.3.111
sovrin-client 0.3.104
Risk factors:
update
adding new fields
Risk:
Medium
Covered with tests:
https://github.com/evernym/ledger/blob/master/ledger/test/test_compact_serializer.py - 21 new tests
https://github.com/evernym/ledger/blob/master/ledger/test/test_ledger.py: testRecoverLedgerNewFieldsToTxnsAdded;;;","30/May/17 9:57 PM;krw910;This is on hold until we get a new stable build that is upgrade able. We need to get INDY-12, INDY-13, INDY-14, and INDY-104 all fixed to have an upgrade able Stable build.;;;","31/May/17 12:59 PM;krw910;We will not have an upgrade path to test out the changes because we made new breaking changes in the next stable release that prevents testing this. So I am closing this ticket because we have upgrade tests covered in INDY-108;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Blocking Issue: Under high load from performance tests the nodes blacklist each other so no consensus can happen.,INDY-19,17085,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,tylerq,krw910,krw910,25/May/17 6:28 AM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,1.5,,,0,,,,,,"*We found this issue from looking into SOV-966*
The nodes blacklisted each other either after a certain number of transactions (12,000) or from getting to many simultaneous requests. I was sending between 500 and 2,000 at once from 1 to 4 machines.

*Steps:*
It was a collection of transactions over time. I was using 1 client sending 500 requests at once from 4 different machines when I think it all went down (so 2,000 simultaneous transactions).

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxqf:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 5:37 AM;krw910;The nodes do not seem to blacklist each other. We have some other issues going on which are captured in INDY-69 and INDY-70;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
find out if we are able to handle a corrupt ledger record,INDY-20,17086,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,danielhardman,krw910,krw910,25/May/17 7:01 AM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,1.5,,,0,,,,,,"We had added a non utf8 entry to the ledger as an ATTRIB which caused the services to throw an error and stop incoming traffic. See INDY-15

Now that we have the services running again the entry is still in the ledger for ATTRIBs. When that ATTRIB is read out of the ledger we will have the same issue.

Example input that is now being checked for is in INDY-15 is:

send ATTRIB dest=<NYM> raw={""k2"": ""v2\x9c""}

However further changes are needed for INDY-15",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy17j:",,,,,,H2,,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/17 12:59 AM;ashcherbakov;The issue we faced in INDY-15 was just about network communication (network stack faced a non-utf message). No non-utf data were added into the Ledger.
However, we should be able to handle a case when we have non-utf data in Ledger. It can be part of Input Sanitization task.;;;","27/May/17 4:28 AM;danielhardman;Just now I was experimenting with the `rlp` module in python, and I saw something that looked almost identical to what [~krw910] reported in his stack traces about a corrupted ledger:
{code:java}
>>> import rlp
>>> rlp.encode('abc')
b'\x83abc'
>>>{code}
The thing to note here is that we have run-length encoded text, and the RL prefix looks an awful lot like the garbage character that wasn't UTF-8 in the ledger where we expected it from an ATTRIB transaction.

So... My theory is that somewhere in our code, we are calling
{code:java}
rlp.encode(){code}
on the values that go into a ledger record for an ATTRIB txn, but not calling
{noformat}
rlp.decode(){noformat}
on the way back out.;;;","29/May/17 7:22 PM;ashcherbakov;[~danielhardman] I think we realized that the Ledger wasn't corrupted. It was only about network communication.;;;","14/Jun/17 2:49 PM;danielhardman;I want us not to crash when we encounter a ledger record that we cannot read. We could ignore it, or we could at a minimum exit cleanly while printing a message about which record is corrupt, with a suggestion that one way to fix the problem is to rebuild the ledger.

Ideally, a node that gets into this state should still start and run, just so it can receive POOL_UPGRADE transactions that allow it to get new software that is more capable of dealing with the corruption (maybe a migration script would reset or fix the corruption).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client CLI can't handle a whitespace character in the pool_transaction_file,INDY-21,17087,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,devin-fisher,devin-fisher,25/May/17 7:16 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Could,,,,,"I had a following pool_transcation_sandbox file:
\{""data"":\{""alias"":""Node1"",""client_ip"":""13.58.96.58"",""client_port"":9702,""node_ip"":""13.58.96.58"",""node_port"":9701,""services"":[""VALIDATOR""]},""dest"":""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"",""identifier"":""FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4"",""txnId"":""fea82e10e894419fe2bea7d96296a6d46f50f93f9eeda954ec461b2ed2950b62"",""type"":""0""}
\{""data"":\{""alias"":""Node2"",""client_ip"":""13.228.52.163"",""client_port"":9704,""node_ip"":""13.228.52.163"",""node_port"":9703,""services"":[""VALIDATOR""]},""dest"":""8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb"",""identifier"":""8QhFxKxyaFsJy4CyxeYX34dFH8oWqyBv1P4HLQCsoeLy"",""txnId"":""1ac8aece2a18ced660fef8694b61aac3af08ba875ce3026a160acbc3a3af35fc"",""type"":""0""}
\{""data"":\{""alias"":""Node3"",""client_ip"":""54.206.21.58"",""client_port"":9706,""node_ip"":""54.206.21.58"",""node_port"":9705,""services"":[""VALIDATOR""]},""dest"":""DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya"",""identifier"":""2yAeV5ftuasWNgQwVYzeHeTuM7LwwNtPR3Zg9N4JiDgF"",""txnId"":""7e9f355dffa78ed24668f0e0e369fd8c224076571c51e2ea8be5f26479edebe4"",""type"":""0""}
\{""data"":\{""alias"":""Node4"",""client_ip"":""52.78.239.183"",""client_port"":9708,""node_ip"":""52.78.239.183"",""node_port"":9707,""services"":[""VALIDATOR""]},""dest"":""4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA"",""identifier"":""FTE95CVthRtrBnK2PYCBbC9LghTcGwi9Zfi1Gz2dnyNx"",""txnId"":""aa5e817d7cc626170eca175822029339a444eb0ee8f0bd20d3b0b76e566fb008"",""type"":""0""} 
Notice the extra non-line breaking whitespace at the end.  I removed these and the error when away.  

 

Here is the error:
{code:java}
Traceback (most recent call last):
  File ""/usr/local/bin/sovrin"", line 78, in <module>
    run_cli()
  File ""/usr/local/bin/sovrin"", line 53, in run_cli
    withNode=withNode
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 111, in __init__
    super().__init__(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 140, in __init__
    fileName=self.config.poolTransactionsFile)
  File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 38, in __init__
    self.recoverTree()
  File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 73, in recoverTree
    self.recoverTreeFromTxnLog()
  File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 82, in recoverTreeFromTxnLog
    record = self.leafSerializer.deserialize(entry)
  File ""/usr/local/lib/python3.5/dist-packages/ledger/serializers/json_serializer.py"", line 46, in deserialize
    return json.loads(data)
  File ""/usr/lib/python3.5/json/__init__.py"", line 319, in loads
    return _default_decoder.decode(s)
  File ""/usr/lib/python3.5/json/decoder.py"", line 339, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File ""/usr/lib/python3.5/json/decoder.py"", line 357, in raw_decode
    raise JSONDecodeError(""Expecting value"", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1)

{code}",,,10800,180,,0%,10800,180,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0ov:",,,,,,,,,,,,,,,,,,,,,,,,,,devin-fisher,mark.hadley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jun/17 5:00 AM;mark.hadley;Which test, or which code base was this in?;;;","29/Jul/17 5:46 AM;mark.hadley;Unable to duplicate, even with a transaction file containing a non-line breaking whitespace at the end.

 Also,
 File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 82, in recoverTreeFromTxnLog
    record = self.leafSerializer.deserialize(entry)
no longer exists in ledger.py so I'm assuming that a previous ticket cleared up this error. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Support the commands ""send GET_ATTR"", ""send GET_SCHEMA"", ""send GET_CLAIM_DEF"" in CLI",INDY-23,17090,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,krw910,25/May/17 7:20 AM,30/Mar/19 5:36 AM,28/Oct/23 2:46 AM,30/Mar/19 5:36 AM,,,,,0,Must,,,,,"The transactions {{GET_ATTR}}, {{GET_SCHEMA}}, {{GET_CLAIM_DEF}} have already been implemented in sovrin-node. However, the corresponding commands {{send GET_ATTR}}, {{send GET_SCHEMA}}, {{send GET_CLAIM_DEF}} are not supported in CLI now. In scope of this task, support these commands in CLI.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jul/17 1:23 AM;ozheregelya;2017-07-18 16_40_01-Ubuntu Clean (clear_0) [Running] - Oracle VM VirtualBox.png;https://jira.hyperledger.org/secure/attachment/11699/2017-07-18+16_40_01-Ubuntu+Clean+%28clear_0%29+%5BRunning%5D+-+Oracle+VM+VirtualBox.png","19/Jul/17 1:23 AM;ozheregelya;2017-07-18 16_40_37-Ubuntu Clean (clear_0) [Running] - Oracle VM VirtualBox.png;https://jira.hyperledger.org/secure/attachment/11700/2017-07-18+16_40_37-Ubuntu+Clean+%28clear_0%29+%5BRunning%5D+-+Oracle+VM+VirtualBox.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8af:",,,,,,H4,H5,M1 Prelude,,,,,,,,,,,,,,,,,,danielhardman,DouglasWightman,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 7:21 AM;krw910;Comment from [~danielhardman]

I don't think this is directly required for MGL, since MGL is primarily about nodes being functional. However, I suspect that we will be able to do better probing/testing/pentesting/shakedowns if these are implemented, so perhaps we should consider doing the work now? Not sure.;;;","19/Jul/17 12:39 AM;ozheregelya;*Build Info:*
   client version: 0.4.39
   indy-anoncreds 0.4.15
   indy-node 0.4.40
   indy-plenum 0.4.52
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 7 nodes, 1 client

 

*Reason for Reopen:*
 Some cases work not as expected.

 

*Case 1:*
 GET_ATTRIB does not work at all.

*Steps to Reproduce:*
 1. Open the CLI.
 2. Perform following commands:
{code:java}
sovrin@test> send NYM dest=33A18XMqWqTzDpLHXLR5nT
Adding nym 33A18XMqWqTzDpLHXLR5nT
Nym 33A18XMqWqTzDpLHXLR5nT added
sovrin@test> send ATTRIB dest=33A18XMqWqTzDpLHXLR5nT raw={""endpoint"": {""ha"": ""10.0.0.202:5555"", ""pubkey"": ""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z""}}
Adding attributes {""endpoint"": {""ha"": ""10.0.0.202:5555"", ""pubkey"": ""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z""}} for 33A18XMqWqTzDpLHXLR5nT
Attribute added for nym 33A18XMqWqTzDpLHXLR5nT
sovrin@test> send GET_ATTR dest=33A18XMqWqTzDpLHXLR5nT
{code}
 *Actual Results:*
 Invalid syntax error appears.
{code:java}
Invalid syntax: 'send GET_ATTR dest=33A18XMqWqTzDpLHXLR5nT'
send GET_ATTR
-------------
 title: Get ATTR from sovrin
usage: send GET_ATTR dest=<target identifier>
example(s):
 send GET_ATTR dest=33A18XMqWqTzDpLHXLR5nT
{code}
 *Expected Results:*
 send GET_ATTR should work.

 

*Case 2:*
 Incorrect example in help for GET_SCHEMA (dest is absent).

*Steps to Reproduce:*
 1. Open the CLI.
 2. Perform command: help send GET_SCHEMA

*Actual Results:*
{code:java}
send GET_SCHEMA
---------------
 title: Gets schema from sovrin
usage: send GET_SCHEMA dest=<target identifier> name=<schema-name> version=<version>
example(s):
 send GET_SCHEMA name=Degree version=1.0
{code}
 *Expected Results:*
{code:java}
send GET_SCHEMA
---------------
 title: Gets schema from sovrin
usage: send GET_SCHEMA dest=<target identifier> name=<schema-name> version=<version>
example(s):
 send GET_SCHEMA dest=33A18XMqWqTzDpLHXLR5nT name=Degree version=1.0
{code}
 

 

*Case 3:* (minor case, may be moved to separated ticket with lower priority)
 Incorrect syntax highlighting.

*Steps to Reproduce:*
 1. Open the CLI.
 2. Type ""send GET_NYM"" command.
 => Command is highlighted with green.
 3. Type one of new commands: ""send GET_ATTR"", ""send GET_SCHEMA"", ""send GET_CLAIM_DEF"".

*Actual Results:*
 New commands are not highlighted.
!2017-07-18 16_40_01-Ubuntu Clean (clear_0) [Running] - Oracle VM VirtualBox.png|thumbnail!

*Expected Results:*
 New commands should be highlighted.

 

*Case 4:* (minor case, may be moved to separated ticket with lower priority)
 New commands are not shown in suggestions list.

*Steps to Reproduce:*
 1. Open the CLI.
 2. Start typing ""send GET_NYM"" command.
 => GET_NYM is shown in suggestions list.
 3. Type one of new commands: ""send GET_ATTR"", ""send GET_SCHEMA"", ""send GET_CLAIM_DEF"".

*Actual Results:*
 New commands are not shown in suggestions list.
!2017-07-18 16_40_37-Ubuntu Clean (clear_0) [Running] - Oracle VM VirtualBox.png|thumbnail!

*Expected Results:*
 New commands should be shown in suggestions list.

 

*Case 5:* (minor case, may be moved to separated ticket with lower priority or ignored because current behavior is acceptable, but inconsistent with GET_NYM command).
 No validation for dest parameter of send GET_SCHEMA command.

*Steps to Reproduce:*
 1. Open the CLI.
 2. send GET_SCHEMA dest=V4SGRU86Z58d6TV7PB0e6f name=Degree version=2.0

*Actual Results:*
 Getting schema V4SGRU86Z58d6TV7PB0e6f
 Schema not found

*Expected Results:*
 Error message about invalid characters (0 in this example) should be shown, same as for GET_NYM command (see INDY-111).

 

*Additional Information:*
 Following cases were verified and works without problems:
 1. sending GET_SCHEMA with valid parameters (existing schema).
 2. sending GET_SCHEMA with invalid parameters (not existing schema, invalid values of parameters).
 3. sending GET_CLAIM_DEF with valid parameters (existing claim).
 4. sending GET_CLAIM_DEF with invalid parameters (not existing claim, invalid values of parameters).

 

*Questions:*
 1. Is it OK that send GET_SCHEMA does not return seqId?
 2. Should roles affect behavior of these commands?;;;","20/Jul/17 1:34 AM;DouglasWightman;I fixed the highlighting and the examples (cases 1-4) but I wasn't sure we needed to address #5 as it already will give an error with an invalid ""dest"" and I believe the NYM commands are the only ones that check for the validity of ""dest"".  I will ask those with more knowledge about the 2 questions.;;;","23/Jul/17 11:13 AM;danielhardman;[~DouglasWightman] Is this really in code review? If so, what is the link to the PR?

 ;;;","23/Jul/17 9:20 PM;DouglasWightman;Yes, I posted the PR in the indy-pr-review hyperledger chat:

https://chat.hyperledger.org/channel/indy-pr-review?msg=cqGeKmriv4TDiPg68

I'll post it here too:

https://github.com/hyperledger/indy-node/pull/246;;;","25/Jul/17 11:17 PM;krw910;[~slafranca] run through the getting started tutorial first then try the commands in this ticket. Document the parameters to the commands so we can add them to a How To document.;;;","26/Jul/17 1:18 AM;slafranca;I ran the test scenario again using
{code:java}
indy-plenum=0.4.75
indy-anoncreds=0.4.18
indy-node=0.4.63
sovrin=0.2.11
{code}
The results of the test are as follows:
 *Case 1* {color:#14892c}passed{color}:
{code:java}
Alice@test> send GET_ATTR dest=33A18XMqWqTzDpLHXLR5nT
Invalid syntax: 'send GET_ATTR dest=33A18XMqWqTzDpLHXLR5nT
{code}
*Case 2* {color:#14892c}passed{color}
{code:java}
usage: send GET_SCHEMA dest=<target identifier> name=<schema-name> version=<version>

example(s):
        send GET_SCHEMA dest=33A18XMqWqTzDpLHXLR5nT name=Degree version=1.0
{code}
*Case 3* {color:#d04437}failed{color}
 The ""send GET_ATTR"" command is the only command that is not highlighted in green now

*Case 4* {color:#d04437}failed{color}
 The new commands: ""send GET_ATTR"", ""send GET_SCHEMA"", ""send GET_CLAIM_DEF"" do not appear in the drop down when you type 'send GET'

*Case 5* {color:#d04437}failed{color}
 The error message about invalid characters is not shown;;;","26/Jul/17 1:21 AM;DouglasWightman;For Case 1 the syntax is wrong and the example should be updated to show the correct syntax.;;;","26/Jul/17 1:25 AM;DouglasWightman;For cases 3 and 4 it appears as though my changes were not merged?  For Case 5 I mentioned that I didn't fix it because I didn't think it was necessary.;;;","27/Jul/17 1:34 AM;slafranca;*Case 3* {color:#14892c}passed{color}
New commands are highlighted in green now

*Case 4* {color:#14892c}passed{color}
The new commands: ""send GET_ATTR"", ""send GET_SCHEMA"", ""send GET_CLAIM_DEF"" appear in the drop down when you type 'send GET'

*Case 5* NTBF;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Installing client as root does not allow users to access the transaction files,INDY-24,17091,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,krw910,krw910,25/May/17 7:22 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,Must,,,,,"Install the client deb package as the root user.
Now switch to a user and try to run sovrin. You will not be able to because the pool_transactions file is not in an accessible location.

Trev Harmon has more details on this issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 12:23 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/10878/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzwzc7:",,,,,,14,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 12:22 AM;VladimirWork;Another steps to reproduce ""Permission denied"" error:

1. Login client as agent user.
2. cd /usr/local/bin.
3. sudo ./reset_client (because without sudo there is a ""Permission denied"" error) => YeS.
4. sovrin.

Actual results:
PermissionError: [Errno 13] Permission denied: '/usr/local/bin/cli.log'.

Expected results:
CLI should run normally (as it ran before reset client actions).

Workaround:
sudo sovrin.;;;","31/May/17 2:58 AM;ozheregelya;Regarding [~VladimirWork]'s comment:
 As far as I can see, this situation reproduces only when user _agent_ tries to run sovrin from /home/.sovrin/ directory. When _agent_ runs sovrin from /home/agent/.sovrin/ CLI is successfully started (the reason is in permissions of /home/.sovrin/pool_transactions_sandbox file: 
{noformat}
-rw-r--r--
{noformat}
 and owner is root).

I discussed these problems with [~alexander.shekhovcov] and clarified expected results.

*Case 1*
 Steps to Reproduce:
 1. Install sovrin-client or sovrin-node package as root user.

Actual Results:
 /home/.sovrin directory is created.

Expected Results:
 /root/.sovrin directory should be created.

*Case 2*
 Steps to Reproduce:
 1. Install sovrin-client package as one user (e.g. _root_).
 => .sovrin directory is created for this user.
 2. Try to run CLI using _sovrin_ command as any other user (e.g. _agent_).

Actual Results:
 _agent_ does not have .sovrin directory and pool_transactions files.

Expected Results:
 /home/agent/.sovrin directory with pool_transactions files should be created when agent tries to run CLI using _sovrin_ command.;;;","08/Sep/17 5:35 AM;krw910;[~ozheregelya] If there is something that still needs to be fixed please move this back ""To Develop"" and assigned to a developer.;;;","13/Sep/17 6:51 AM;krw910;Restest as part of INDY-833;;;","03/Oct/17 6:03 AM;ozheregelya;The initial problem is still presents: users still have permission denied error, but the reason of this problem is in log files which are written in current directory. There is the ticket for this problem, but in is in backlog since June: INDY-171.

Other problem is in genesis files for client. They are created in following directories now: /home/.sovrin, /home/sovrin/.sovrin, /home/indy/.indy. This behavior needs in additional clarification and it will be clarified in scope of incubation tasks. Anyway, case when the user can't connect to test environment because of absent genesis file has obvious workaround - creation new genesis file using script generate_sovrin_pool_transactions (or generate_indy_pool_transactions in new terminology).

So, current ticket should be closed. Logic with creation of .sovrin and .indy directories and according genesis files will be discussed and clarified in scope of incubation tasks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[shakedown] Need to limit the transaction size. ,INDY-25,17092,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,devin-fisher,devin-fisher,25/May/17 7:56 AM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,Must,Stability,,,,"Send extremely large request (attempt to fill memory). 
Not sure what size the nodes have but several GB. 
Should be tried with both ledger data and not ledger data. 
By that, I mean really large ledger entry 
and non-ledger data like whitespace in the message.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,INDY-765,,,,INDY-698,INDY-805,,,,,,,"03/Aug/17 3:52 AM;krw910;LargeJson248;https://jira.hyperledger.org/secure/attachment/11815/LargeJson248","10/Aug/17 9:45 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11864/Screenshot.PNG","03/Aug/17 3:52 AM;krw910;SmallJson100;https://jira.hyperledger.org/secure/attachment/11814/SmallJson100","27/May/17 3:46 AM;devin-fisher;shakedown.py;https://jira.hyperledger.org/secure/attachment/10874/shakedown.py",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8fj:",,,,,,M1 Prelude,10,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,devin-fisher,dsurnin,krw910,lovesh,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 2:35 AM;devin-fisher;Did several experiments of size leading up to the 1.4 GB described below.

 

Size: 1.4 GB Padded create NYM request

(normal JSON for NYM create with 1.4 GB of whitespace after the JSON)

 

FROM Client: Sent in 50 sec

 

TO Node:

Received and replayed 20 min

Slowly consumed resources over the 20 min. 

Standard CPU usage 25%

Started 150 MB and slowly consumed resources up to 1400 MB. 

In the last minute, there was a spike in resources. 

Jumped quickly to 3 GB to 4 GB.

Consistently used 150% CPU;;;","27/May/17 3:46 AM;devin-fisher;Added a code file I used to send the transaction.

Any questions direct to me.;;;","27/May/17 3:49 AM;devin-fisher;When this gets looked at by a product team member please remember that most transactions are small but ClaimDef can be a lot larger (not sure how large). They contain (at the moment) RSA keys for each attratbute. So, if we want a one size fits all solution it must be large enough to fit what every we think is the largest allowable ClaimDef.;;;","07/Jul/17 8:45 AM;stevetolman;Time box this to 1 hour.

Pick a reasonable maximum txn size - 128K - and reject all incoming txns that are larger than that size, with a good error message explaining why it was rejected.;;;","26/Jul/17 6:43 PM;dsurnin;I spent some time reviewing it and it looks like it does not fit into 1h timebox;;;","26/Jul/17 7:37 PM;lovesh;The limit like 128K should neither be hardcoded in code nor be in a conifg file but in the config ledger, the initial limit should be present as a genesis txn.;;;","26/Jul/17 8:48 PM;dsurnin;Document for discussion

https://docs.google.com/document/d/1aBqiORwMEcuhr9PHApQ1Vu7DxdR3IVhbLu3XiExNMsY/edit;;;","27/Jul/17 2:12 PM;dsurnin;From email from Daniel

For now, I don't want this to be configurable. I want something very simple and hard-coded. Later we can change it. I'd pick some limit that's big enough to receive a large schema doc, like maybe 128k or 64k.
I agree with discarding it in zmq.
 ;;;","02/Aug/17 12:20 PM;danielhardman;I agree with Lovesh's comment that it should be in the config ledger. The only reason I said to timebox to one hour and hardcode it was that I wanted it to be in the go-live build. Now that we're past go live, let's fix it right.;;;","02/Aug/17 6:02 PM;ashcherbakov;[~danielhardman] I would suggest to finish and close this story (as it's quite complete), and create a new story to enhance this logic with a parameter from config ledger. I think having two small stories is better than a big one.;;;","02/Aug/17 9:00 PM;dsurnin;Implemented as config parameter

plenum c4b0de5d794d7700d3814ddb6b7cbc7503728242

node 4674f7a9b807d9cf558027c6f75f0e4dc5443da6

 

tests

[stp_core/test/test_msg_len_validator.py|https://github.com/hyperledger/indy-plenum/commit/1b799a1fde972bcb0bb6a468c46efcb09fefea3a#diff-0a828705f5f9b2e666bf772ed1c7090c]

[stp_zmq/test/test_zstack.py|https://github.com/hyperledger/indy-plenum/commit/1b799a1fde972bcb0bb6a468c46efcb09fefea3a#diff-7ffd3624d890e8f700882833e216fc4c]

 ;;;","03/Aug/17 4:00 AM;krw910;[~dsurnin] I have attached two files ""LargeJson248"" and ""SmallJson100"". The files are a send ATTRIB transaction and is just a key pair with a large string. The large file is 246k and the small file is 86k.

*Version*
indy-plenum= 1.0.79
indy-anoncreds= 1.0.22
indy-node= 1.0.72
sovrin= 1.0.15

I did the following:

*Start sovrin CLI*
sovrin
connect test
new key with seed 000000000000000000000000Trustee1
send NYM dest=CA6NHp54iKYu4zTEobYKy7

Now you can sent the contents of one of the files. The contents look like ""send ATTRIB dest=CA6NHp54iKYu4zTEobYKy7 raw={""myname"":""<large string>""}

On the smaller transaction is works just fine.
On the larger transaction there are two issues:
*{color:#d04437}Issue 1{color}*
There was nothing in the CLI to tell me the transaction was not accepted. I could tell only because I did not get a message telling me it was added. I expected to see a message telling me that the transaction size was to large.

*{color:#d04437}Issue 2{color}*
After sending the large transaction I get an exception when exiting the CLI
{code}
sovrin@test> exit
Active wallet ""Default-f882f8"" saved (/home/ubuntu/.sovrin/wallets/test/default-f882f8.wallet)
Goodbye.
Traceback (most recent call last):
  File ""/usr/local/bin/sovrin"", line 78, in <module>
    run_cli()
  File ""/usr/local/bin/sovrin"", line 56, in run_cli
    looper.run(cli.shell(*commands))
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 284, in __exit__
    self.shutdownSync()
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 280, in shutdownSync
    self.loop.run_until_complete(self.shutdown())
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
    return future.result()
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
    raise self._exception
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
    result = coro.send(None)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 270, in shutdown
    await self.runFut
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 363, in __iter__
    return self.result()  # May raise too.
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
    raise self._exception
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
    result = coro.send(None)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 218, in runForever
    await self.runOnceNicely()
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 202, in runOnceNicely
    msgsProcessed = await self.prodAllOnce()
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 147, in prodAllOnce
    s += await n.prod(limit)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", line 188, in prod
    s = await super().prod(limit)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 240, in prod
    s = await self.nodestack.service(limit)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/kit_zstack.py"", line 109, in service
    c = await super().service(limit)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 438, in service
    return self.processReceived(pracLimit)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 548, in processReceived
    self.msgHandler((msg, frm))
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", line 103, in handleOneNodeMsg
    super().handleOneNodeMsg(wrappedMsg, excludeFromCli)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 301, in handleOneNodeMsg
    self.reqRepStore.addReject(msg, frm)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/persistence/client_req_rep_store_file.py"", line 73, in addReject
    self.delimiter, reason))
  File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/directory_store.py"", line 43, in appendToValue
    with open(self.keyFilePath(key), mode=""a+"") as f:
IsADirectoryError: [Errno 21] Is a directory: '/home/ubuntu/.sovrin/data/clients/6qv9puak2PM7fE9Y1YVGNtTcJXesfzuf2Je8nE76pBf1/Requests/'
{code};;;","03/Aug/17 4:03 AM;danielhardman;[~tharmon] and [~mgbailey] and [~TechWritingWhiz]: here is a new config parameter. I think the intention is to make it undocumented, so I'm not sure any of your plans or behaviors need to change. But I wanted you to be aware so you can ask questions as needed.;;;","10/Aug/17 12:08 AM;dsurnin;crash is fixed

notification is added

 

plenum 0a209bec9e6ba033380ad272b247ded0df2bed09

node 8273af9e1f475ec79ff199a9b3fc9c1ded8d73b6

 

additional test

plenum/test/cli/test_long_msg_err.py;;;","10/Aug/17 8:09 PM;VladimirWork;Build Info:
indy-node 1.0.87

Steps to Validate:
1. Send smaller transaction.
2. Send larger transaction.
3. Exit CLI.

Actual Results:
Smaller transaction is successfully added.
Larger transaction adding throws readable error.
CLI exiting doesn't throw any exceptions.

Additional Info:
Larger transactions sent by shakedown.py are also rejected:

Client EVemRztUB6TpbaTfBHwC4nmHgSjdVNoJEHw95JfaQacQ got msg from node Node4C: {'reqId': '', 'reason': ""Message will be discarded due to InvalidMessageExceedingSizeException('Message len 500000294 exceeded allowed limit of 131072',)"", 'identifier': '', 'op': 'REJECT'}.;;;","10/Aug/17 9:45 PM;VladimirWork; !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
input validation test: genesis txn file defines the same key more than once,INDY-26,17094,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,25/May/17 1:41 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,explore,,,,,See 1a in https://docs.google.com/document/d/1ae6Ud64gUjl-YC3ADDU5KuW_A-kPS9l9g6FGJCylFCs/edit?usp=sharing,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-845,,,,,,,,"01/Sep/17 8:01 PM;VladimirWork;Node4_with_duplicated_key_log.7z;https://jira.hyperledger.org/secure/attachment/12013/Node4_with_duplicated_key_log.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy0on:",,,,,,12,,,,,,,,,,,,,,,,,,,,danielhardman,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Sep/17 6:09 AM;krw910;[~VladimirWork] Please run through this scenario and let us know what issues are caused by having a duplicate key in the genesis file.;;;","01/Sep/17 8:01 PM;VladimirWork;Build Info:
1.1.128

Steps to Reproduce:
1. Install pool.
2. Duplicate any key in domain_transactions_sandbox_genesis at any node.
3. Start all nodes.

Actual Results:
Node with malformed this way genesis file cannot catch up with other nodes due to incorrect transaction tree root and marks all other nodes as suspicious so it doesn't participate in consensus (see log for more info).  [^Node4_with_duplicated_key_log.7z] ;;;","01/Sep/17 8:03 PM;VladimirWork;FYI [~krw910];;;","14/Sep/17 12:48 AM;danielhardman;Since this was a research task, I am marking it done. However, I have created INDY-845 to track a fix for this behavior.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze attack vectors in catchup process,INDY-27,17095,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,lovesh,lovesh,25/May/17 3:10 PM,30/Mar/19 5:36 AM,28/Oct/23 2:46 AM,30/Mar/19 5:36 AM,,,,,0,Security,,,,,"The catchup process can be exploited to do a DoS attack on nodes by requesting them proofs or transactions, a trivial way to counter this is to throttle catchup requests (*ConsistencyProof*, *CatchupReq*) on a per node basis. Also putting a limit on the number of transactions that can be requested in *CatchupReq* is one option, the limit can be either static or be approx. *(ledger size/count of caught up nodes)* since the protocol ensures that the lagging nodes distribute catchup requests to all nodes. 

Also the *CatchupReq* needs to be optimised, there needs to be a minimum size of catchup requests so if a node is trying to catchup only 50 txns from 10 nodes, each of thise 10 nodes will servce 5 txns and prepare a consistency proof for other txns. This is bad for the node catching up as it involves more network traffic and more computation to verify so many consistency proofs and for the node serving catchup reqs. But if the node sent only 2 catchup requests the network traffic greatly reduces and 25 txns can be read of a single chunk probably (if txns dont span across multiple chunks). A practical value of this ""minimum size"" is some multiple of chunk size of the ledger",,,,,,,,,,,,,,,,,INDY-232,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy17r:",,,,,,H2,,,,,,,,,,,,,,,,,,,,farooq_m_khan,lovesh,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 1:11 AM;stevetolman;Farooq, is this a ticket you can take and do the analysis on?;;;","15/Jun/17 3:58 AM;farooq_m_khan;My understanding is a new Validator cannot just be added to the system. Only a Steward can approve addition of a new Validator to the system. Without which a new node will not have the keys to establisy a ED25519 encrypted session with the pool

This defect is still a definite possiblility but to be able to do that a already trusted Validator needs to be compromized first and then the python code on the Validator needs to be patched so that it can carry out a DOS attack on other NODES

It is also possibel that the process of vetting the Steward is compromised in either case we need to find a solution to this problem 
 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLI Crashed when sending SCHEMA command,INDY-28,17096,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,tylerq,ashcherbakov,ashcherbakov,25/May/17 6:03 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,"I am not sure the correct way to send a schema, but I was using the example I was given when it caused the CLI to crash.

*Steps*
Start CLI
connect test
new key with seed 000000000000000000000000Trustee1
send SCHEMA name=Degree version=1.0 keys=undergrad,last_name,first_name,birth_date,postgrad,expiry_date
*{color:#d04437}
Error{color}*
{code}
sovrin@test> new key with seed 000000000000000000000000Trustee1
Key created in keyring Default
Identifier for key is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
Current identifier set to GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
sovrin@test> send SCHEMA name=Degree version=1.0 keys=undergrad,last_name,first_name,birth_date,postgrad,expiry_date
sovrin8laMjH is already started, so start has no effect
Error while running coroutine shell: TypeError(""genSchema() got an unexpected keyword argument 'ttrNames'"",)
Active keyring ""Default"" saved (/home/kelly/.sovrin/keyrings/agents/z53bfg/default.wallet)
Active keyring ""issuer"" saved (/home/kelly/.sovrin/keyrings/agents/z53bfg/issuer/issuer.wallet)
7stpEBTXS447Es7GYeg4rjX2t13viP3686ci2PzKCnAf is already stopped
Traceback (most recent call last):
  File ""/usr/local/bin/sovrin"", line 78, in <module>
    run_cli()
  File ""/usr/local/bin/sovrin"", line 56, in run_cli
    looper.run(cli.shell(*commands))
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 254, in run
    return self.loop.run_until_complete(what)
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
    return future.result()
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
    raise self._exception
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
    result = coro.send(None)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 245, in wrapper
    raise ex
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 233, in wrapper
    results.append(await coro)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1119, in shell
    self.parse(c)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1900, in parse
    r = action(matchedVars)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 712, in _sendSchemaAction
    typ=matchedVars.get(TYPE))
TypeError: genSchema() got an unexpected keyword argument 'ttrNames'
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxqn:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 6:42 PM;ashcherbakov;Problem reason: 
- send SCHEMA command was broken. Also there were no tests for it.

Changes: 
- fixed generation of schema (it needs to be async action)
- fixed send SCHEMA grammar (attributes should accept numbers)
- added a test

Committed into:
- deb: sovrin-client 0.3.108 (master)

Risk factors:
- CLI

Risk:
-  Low

Covered with tests:
- test_send_schema.py;;;","27/May/17 6:52 AM;krw910;I did not receive a crash this time.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migration script mechanism,INDY-29,17097,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,tylerq,andrey.goncharov,andrey.goncharov,25/May/17 6:27 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,"We may face a situation when there some changes in dependencies (for example, migration from orietndb to leveldb), or changes in transations.
 We can think about having some post-upgrade hooks that run a script to handle these changes.
 We already have post-install script, so post-upgrade hooks can be added there under if statement for a version of upgrade.

We need to have a general way to execute post-upgrade hooks

An example:
 [https://docs.google.com/document/d/1Zfp5e5kYOrVNmUJC61VipiPqsoRK6x05DTTVK19fe-I/edit#heading=h.d4kqpnu0eyg3]

A document that may help to write PoA: [https://docs.google.com/spreadsheets/d/1hcTd2iKMntilobmHxDKIkeMg62KT1J9C-AGRxF3rbSE/edit?ts=591a7f00#gid=0]

[PoA|https://docs.google.com/document/d/1b8asQ2FsOuwnJ6SlaYJMuF0J528SZ4ArsEkxo48R8yE/edit]

 

Comments from SOV in the attachment",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 6:27 PM;andrey.goncharov;afb7fb86ae.png;https://jira.hyperledger.org/secure/attachment/10869/afb7fb86ae.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxr3:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,andrey.goncharov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jun/17 2:41 AM;krw910;See demo in subtask INDY-108;;;","01/Jun/17 4:49 AM;krw910;I am taking this back until we see it working in a build.;;;","01/Jun/17 5:52 PM;andrey.goncharov;Logic implemented and merged into sovrin-node/master 0.3.120. Demo was provided in INDY-108;;;","02/Jun/17 12:54 AM;andrey.goncharov;[~krw910] here's a DEB based demo.

[https://drive.google.com/file/d/0BxskuV-A2bahNGduSWNhaXEwbFE/view?usp=sharing]

https://drive.google.com/file/d/0BxskuV-A2bahczFsYVpMdk1oY0k/view?usp=sharing;;;","02/Jun/17 3:22 AM;krw910;I have validated this through the master upgrade from 0.3.123 to 0.3.124 where Andrey included a dummy file. In the next build of master he will remove that file.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: Sovrin CLI Keyring files are world readable and have no security,INDY-30,17098,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,farooq_m_khan,farooq_m_khan,25/May/17 8:03 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,Must,,,,,"Users Keyring files(a.k.a Wallet files) are located at this location /home/<username>/.sovrin/keyrings/

These files have 2 problems, 
 # they are world readable and 
 # they do not need any password to open

Ubuntu or Mac keyring files all have highly restrictive permissions and also require password for access

Check permissions on files at: ~/.local/share/keyrings on a ubuntu system

 ","Ubuntu 16, QA-Pool-Shakedown-P2, Sovrin-Node Build # 0.3.11",,32400,32400,,0%,129600,64800,,,,,,,,,INDY-89,,,INDY-10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1zz:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,farooq_m_khan,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/17 9:51 PM;ozheregelya;The only sub-task was verified.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Build a validation component used to validate every incoming message to a node.,INDY-31,17100,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,25/May/17 9:10 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,1.5,,,0,,,,,,"An incoming message can either be a protocol message like 3 phase message, election message, propagate message, view change message, checkpoint message or it can be a request from client. The validation component should validate each field of any message checking that its acceptable, like a view change message should have view no as non-zero +ve integer, similarly for 3 phase messages, ppSeqNo should be non-zero +ve integer, etc. For client requests, each transaction's fields should be validated, like in a NODE txn, if a node port is given it has to be +ve integer, IP has to be a valid, node nym should be base58, for a NYM txn, dest should be base58 and of acceptable length, same for verkey (consider both types of verkeys)",,,,,,,,,,,,,,INDY-9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzxxrb:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/17 1:35 AM;danielhardman;This is great work, [~alexander.shekhovcov]! I had a look at your PR, and I am really pleased. Thank you.

I made some notes as I read the code, and wanted to be sure that I sent them to you: [~jlaw 1] >>

1. It looks like this mechanism does schema-style validation, where I can describe a canonical message, and I find out whether the incoming message conforms to the template. This is great; I’m delighted. However, in the world of document validation, there is another level of validation beyond this. Schemas typically test well-formedness, not correctness. For example, I could have a perfectly well formed driver’s license but have values for particular fields that make no sense whatsoever (e.g., a birthdate 1000 years in the future, a name for the issuing state that is in a foreign language, etc). So: is the scope of concern for this mechanism just well-formedness? (That could be a good answer; I haven’t pondered deeply, but I’m wondering what’s “right”.) If we receive a message that references a sequence number of a public key that doesn’t exist, the message is well-formed, but invalid; should errors in such cases resemble (or be emitted by) the same validation that does other testing?

2. Where can I go to see a list of all validation messages? I want to review the text and see them all in one place.

3. I would like a detailed comment, somewhere in the code, that explains how the mechanism is expected to work. This is not a granular comment about a specific class or method—it’s 4-8 paragraphs of text explaining to a developer how to use and maintain the validation mechanism.

4. What is the equivalent mechanism in libsovrin? Will Evgeniy’s work harmonize and build upon this? We need to guarantee that validation is the same in both places. <<[~gudkov] and <<[~ashcherbakov]

5. There are some TODO items that feel important, such as a validator or two that exist but always return valid, and a bunch of skipped tests.

6. It appears that we are rejecting messages with unknown fields. Should we be? (If we disallow unfamiliar fields, doesn’t that break our ability to have old node code work with newer clients, or vice versa?)

7. What about versioning? Presumably in the future we will accept version 1 messages, version 2 messages, version 3 messages, etc. How do we say, when we emit a message, “this is a ‘version 1’ message”? And how does the validation mechanism represent the possibility that a message could be V1, V2, or V3—and branch its validation logic by reacting to the declared version?;;;","26/May/17 3:38 AM;alexander.shekhovcov;[~danielhardman] thank you for comment! 

1. 
{quote}For example, I could have a perfectly well formed driver’s license but have values for particular fields that make no sense whatsoever (e.g., a birthdate 1000 years in the future, a name for the issuing state that is in a foreign language, etc). So: is the scope of concern for this mechanism just well-formedness?
{quote}
This validation can validate that a birthdate not in the future, and a driver licence is well-formedness (XXX-XXX...) but does not check what the licence was issued by authorities. 

It is supposed that we are going to have two levels of the validation:
 * message level (scope of the ticket): validate that a birthdate not in the future, a driver licence is well-formedness (XXX-XXX...)
 * ""business"" level (already implemented in the code): licence was issued by authorities

2. For now there are 3 places which contain the messages:
 * plenum/common/types.py
 * plenum/common/messages/client_request.py
 * sovrin_common/types.py

It is not a final layout. I am going to merge all plenum messages in one place. 

3. Sure. I am going to do that after #5. It will be helpful for me too. 

5. Agree. Those TODOs are quite urgent. Victor is implementing those rules.

6-7. Great point! If we implement the message versioning we would be able reject unknown fields and do not have problems with old/new clients/nodes. Rejecting unknown fields looks quite useful when a client misprinted during typing CLI command (for example extra white space after field name 'node_port ' ).

 

 ;;;","26/May/17 10:43 PM;alexander.shekhovcov;(/)

I can declare the basic validation is implemented. We are going to continue in the tickets:

https://jira.hyperledger.org/browse/INDY-35

https://jira.hyperledger.org/browse/INDY-72

and in the validation tickets with tag ""Input Sanitization""

*How to test:*

The plenum master pipeline is green.

Actual testing will be done by the case tickets with tag ""Input Sanitization"".

For example:

https://jira.hyperledger.org/browse/INDY-9

https://jira.hyperledger.org/browse/INDY-37

https://jira.hyperledger.org/browse/INDY-38

https://jira.hyperledger.org/browse/INDY-39

 

 

 

 

 ;;;","27/May/17 6:12 AM;krw910;[~aleksey-roldugin] work with [~spivachuk] on steps to manually test this ticket.;;;","07/Jun/17 10:06 PM;aleksey-roldugin;Since INDY-9, 37-39 are fixed this ticked is tested.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool was unable to function dealing with a bad network of 2 second latency and 20% dropped packets,INDY-32,17101,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,ashcherbakov,ashcherbakov,25/May/17 9:14 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,"This is a more extreme scenario. I have a 7 node global pool and used a script called traffic_shaping.sh to simulated a bad network. The script is attached. 

*{color:#205081}Setup{color}*
Global network pool of 7 nodes
3 client machines running performance scripts to drive traffic.

*{color:#205081}Test{color}*
To use traffic_shaping.sh:
Just put the following script in /etc/init.d, modify the values to fit your needs, make it executable, and run /etc/init.d/traffic_shaping.sh start to degrade performance accordingly.

Using traffic_shaping.sh on each of the nodes I set the following values:
{code}
# The network interface we're planning on limiting bandwidth.
IF=ens3     # Interface
# Latency
LAT_1=2000ms          # Base latency
LAT_2=100ms           # Plus or minus
LAT_3=50%            # Based on previous packet %
# Dropping packets
DROP_1=20%            # Base probability
DROP_2=50%           # Based on previous packet %
# Bandwidth
DNLD=50kbps          # DOWNLOAD Limit
UPLD=50kbps          # UPLOAD Limit
{code}

I started traffic_shaping.sh on each of the nodes and then started the following performance scripts one on each of three machines.

*Client 1*
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 2 -r 200

*Client 2*
python3 load_test.py --clients-list load_test_clients.list -t ATTRIB -c 2 -r 200

*Client 3*
python3 load_test.py --clients-list load_test_clients.list -t GET_NYM -c 2 -r 1000

The GET_NYM completed successfully, but on adding a NYM only 60 out of 400 completed and from adding an ATTRIB only 58 out of 400 completed.

*{color:#d04437}Issue{color}*
After adding the NYM and ATTRIB stalled I shut down the test and stopped traffic_shaping.sh from running. I then connected with the CLI and tried to add a NYM and was unable to.
I then check the service status on all the nodes and found the following error on Node 2

{code}
     return self.gen.send(None)
   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 660, in serviceReplicas c = self.serviceReplicaInBox(limit)
   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 992, in serviceReplicaInBox msgCount += replica.serviceQueues(limit)
   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 519, in serviceQueues r = self.dequeuePrePrepares() if self.node.isParticipating else 0
   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 1414, in dequeuePrePrepares pp, sender, _ = self.prePreparesPendingFinReqs.pop(i)
 IndexError: pop index out of range
{code}

I then restarted all the services and the CLI was not able to connect to any of the nodes. I tried again morning and the CLI was again able to connect and add new NYMs. I don't know how long it took for the system to recover.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1cn:",,,,,,H1,,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 9:15 PM;ashcherbakov;Jason Law added a comment - 2 days ago

Related to mutating a list that we have static indices for? https://github.com/evernym/plenum/blob/master/plenum/server/replica.py#L1414
;;;","07/Jun/17 7:00 PM;lovesh;The problem mentioned is resolved at https://github.com/evernym/plenum/blob/master/plenum/server/replica.py#L1502.;;;","14/Jun/17 10:57 AM;krw910;I ran successfully with 2 second latency and 20% dropped packets. The nodes did not stay in sync all at the same time, but enough nodes were in sync to come to consensus and when the other nodes did catch up they took part in consensus.;;;","14/Jun/17 11:47 AM;danielhardman;I inspected the code and recognize the fix for the mutating list. I also believe Kelly's test result. Therefore I am accepting the fix.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: Do not use Pseudo Random Number Generator in Sovrin-Common and State subprojects,INDY-33,17102,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,dsurnin,dsurnin,25/May/17 9:28 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,"Function randomString() in common/util.py and debug() in state/utils/utils.py is using the python provided random class which is not a Secure Random generator should be replaced with a SecureRandome generator

I believe this is a must have for Minimal Go Live.

PoA:
 # investigate possible replacements for currently used pseudo-random generators and choose the most suitable one (candidates are: os.urandom or random.SystemRandom, [python docs|https://docs.python.org/2/library/random.html])
 # improve code in mentioned places",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1cf:",,,,,,H1,,,,,,,,,,,,,,,,,,,,dsurnin,farooq_m_khan,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 9:30 PM;dsurnin;Farooq Khan comment - 12/May/17 9:08 AM
Function randomString() in common/util.py and debug() in state/utils/utils.py is using the python provided random class which is not a Secure Random generator should be replaced with a SecureRandome generator

Andrey Kononykhin comment - 6 days ago
Hello, Farooq Khan
I haven't found randomString() in Sovrin-Common but have found in plenum. Did you mean the plenum actually?

Farooq Khan comment - 6 days ago
Andrey Kononykhin you are correct It was in plenum

Farooq Khan comment - 6 days ago
Found one more instance of Psuedo Random Generator being used. This is even more critical than the other 2. STP:crypto/util.py

Farooq Khan comment - 6 days ago
Andrey Kononykhin For all our random number generation needs, I would recommend using libSodium provided APIs. I am not sure if it is available via NACL but that is something we should check. This will ensure portability and security both. libSodium uses appropriate secure random generators on each OS it is supported on.;;;","06/Jun/17 6:11 PM;farooq_m_khan;This has been fixed now, there is no way to test this however except a code review

check the code in plenum/plenum/common/util.py

Ignore the state/state/util/utils.py that is used for logging and need not be using secure random;;;","14/Jun/17 12:41 PM;krw910;You can see where we switched the random generator in pull request 192

https://github.com/evernym/plenum/commit/356b11ebff5e5c473f0e4e395b6de307d2ef36dc;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Monitor needs to compensate for extra work done by master's replicas,INDY-34,17103,,Story,To Develop,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,,andkononykhin,andkononykhin,andkononykhin,25/May/17 9:40 PM,29/Oct/19 11:32 PM,28/Oct/23 2:46 AM,,,,,,0,7Months,LoveshReview,Must,ViewChange,,"Currently the replicas of the master instance do state reads and writes, which makes them appear to do less work than backup instances and can lead to view change. The monitor needs to adjust.

*POA ([~lovesh])*:
Assume request size is almost equal
Effect of extra work on throughput:
throughput = work/time
time = x+y, x = time to create a batch (negligible), y = time for state interactions

In replica, track how much time it took for `create3PCBatch` and `processReqDuringBatch`. Reset this on each view change. 
In monitor, `getThroughputs` should subtract the time taken for doing state trie operations from the total time considered for the determination. In `isMasterReqLatencyTooHigh` substract the time from latency.",,,97200,97200,,0%,97200,97200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-2251,,,,,,,,,,"1|hzx133:",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 2:51 AM;andkononykhin;Hello [~jlaw 1] [~lovesh] and [~ashcherbakov]

I want to share the results of testing master's extra work and how it impacts our monitoring logic.

*Main conclusion*: 
    - master extra work lead to view change

Some stat 
 ---------

How tested: 
    I patched plenum code in the following ways: 
        1. improved logging for failed limits checks to show more valuable numbers 
        2. check all limits in any case (in current code - until first failed) 
        3. added synchronous sleeps inside replica.processReqDuringBatch 
          whic is running for both primary and non-primary replicas

Limits are default: 
    DELTA = 0.4 (throughput ratio) 
    LAMBDA = 60 (requests latency) 
    OMEGA = 5 (avg requests latency)

sleep   num NYM                    diff         diff            diffs (mean / max) 
 time    requests    repeatable  DELTA   OMEGA   LAMBDA 
 ------------------------------------------------------------------------------------------
 0       1000        quite               0.13 
                                                                                2.88 / 5.0 
                                                                                0.08 / 0.09 
                                                                                0.52 / 0.53 
                                                                                0.96 / 0.97 
                                                                               1.38 / 1.40 
                                                                                ...

0.1     200         quite                               19.62 
                                                    0.35      43.51

0.2     10          yes                     0.36 
                                                    0.11

0.3     10          yes                     0.13      1.0

0.4     10          yes                     0.18      3.0

Comments: 
    diff DELTA = DELTA - (masterThrp / backupThrp) 
    diff OMEGA = avgLatM - avgLatB - OMEGA 
    diff LAMBDA (mean) = mean([lat - LAMBDA]) 
    max LAMBDA =  mean([lat - LAMBDA])

I checked the case when we increase replicas work not only for master and didn't see any view changes for the same synthetic delays.

 Conclusions: 
    - without sync sleep master checks fails mostly for LAMBDA, 
      latencis were quite near LAMBDA. Make sense to try to tune LAMBDA or 
      use proposed logic of monitor adjustment.

   - in case of addtional load (sync sleep) other checks (DELTA, OMEGA) failed 
      with big difference with current limits. Seems no sense to adjust them.

*Current implementation of monitor adjustment* 
 --------------------------------------------

1. measure times for all code under 'isMaster' conditional in server/replica.py 
 2. all time snapshots are added to: 
    - total counter for master 
    - counter for each not ordered yet request (master only)

*Why it seems not accurate enough:* 
 ------------------------------------------------

1. master shares the same looper with backups. Thus, its extra work (and non extra too) delays 
 all not ordered requests for backups which await async loop too

2. each coming client request splitted (lead to) to many service requests inside pool. 
   Life cycle for each requests distributes among nodes according to RBFT. 
   Thus, it's not accurate to measure and adjust latency for requests only on one single node 
   cause other replicas increase latencies for all requests as well.

  So, it seems we need some attribute for request for extra work latencies accumulation. 
   But it's not clear enough how to accumulate that.

*As a conclusion about monitor adjustment logic:* 
   we may adjust monitor for each node independently but it neither not enough 
   nor accurate.

 

Thanks;;;","31/May/17 2:40 AM;lovesh;From the logs that i have looked at i saw view change happening since latency of one request was higher than the threshold, i propose that ""lets not consider master slow if latency of one request is greater than Lambda, but we consider master slow if 10% of  requests"". The idea is to bring pragmatism to RBFT's monitoring
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Input validation] Node-to-node messages validation,INDY-35,17104,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ashcherbakov,ashcherbakov,25/May/17 9:42 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,Must,,,,,"The base mechanism and some rules are created for node-to-node messages in the scope of INDY-31, but they are currently disabled because each rule needs to be checked and all tests must pass.

Messages to be validated:
- Nomination
- Reelection
- Primary
- Ordered
- Propagate
- PrePrepare
- Prepare
- Commit
- Checkpoint
- ThreePCState
- InstanceChange
- LedgerStatus
- ConsistencyProof
- CatchupReq
- CatchupRep
- ConsProofRequest


",,,540,540,,0%,540,540,,,INDY-406,INDY-413,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy207:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 7:41 PM;mzk-vct;Following messages implemented
 - PrePrepare
 - LedgerStatus
 - ConsistencyProof

Pull request https://github.com/evernym/plenum/pull/183;;;","31/May/17 9:27 PM;mzk-vct;https://github.com/evernym/plenum/pull/183 was merged, plenum build is 0.3.122-master;;;","16/Jun/17 10:03 PM;mzk-vct;Added tests for messages, please find them in plenum/test/input_validation/message_validation package;;;","06/Jul/17 7:52 PM;alexander.shekhovcov;(/)

*How to test:*

The NYM sending works (the common pool tests)

The tests:

_plenum/test/input_validation/*_;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create negative unit level tests,INDY-36,17106,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,spivachuk,spivachuk,spivachuk,25/May/17 9:59 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,This task to to add negative tests to the existing unit tests.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy0mv:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/17 10:04 PM;spivachuk;The test verifying that {{send NODE}} command fails in case {{data.node_ip}} parameter value contains a trailing space but the pool remains operable after this was merged to master branch of sovrin-client:
 [https://github.com/sovrin-foundation/sovrin-client/pull/178];;;","25/May/17 10:04 PM;spivachuk;Wrote tests checking \{\{send NODE}} command parameters validation. The tests can be found in the following pull request merged to master branch:
https://github.com/sovrin-foundation/sovrin-client/pull/181;;;","25/May/17 10:07 PM;spivachuk;Wrote tests checking \{\{send NYM}} command parameters validation. The tests can be found in the following pull request merged to master branch:
https://github.com/sovrin-foundation/sovrin-client/pull/183;;;","26/May/17 10:49 PM;spivachuk;Wrote tests checking {{send ATTRIB}} command parameters validation. The tests can be found in the following pull request merged to master branch:
https://github.com/sovrin-foundation/sovrin-client/pull/192;;;","02/Jun/17 7:39 PM;spivachuk;Wrote tests checking {{send GET_NYM}} command parameters validation. The tests can be found in the following pull request merged to master branch:
https://github.com/sovrin-foundation/sovrin-client/pull/205;;;","14/Jun/17 7:51 PM;spivachuk;Corrected the existing tests of input validation according to the answers from Daniel and the changed requirements for NYM identifiers. The changes can be found in the following pull request merged to master branch::
https://github.com/sovrin-foundation/sovrin-client/pull/220;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The parameter data.alias of send NODE command is not validated properly,INDY-37,17107,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,tylerq,alexander.shekhovcov,alexander.shekhovcov,25/May/17 10:07 PM,30/Mar/19 5:36 AM,28/Oct/23 2:46 AM,30/Mar/19 5:36 AM,,,,,0,,,,,,"The parameter \{\{data.alias}} of \{\{send NODE}} command is not validated properly. The following test in \{\{sovrin_client.test.cli.test_send_node_validation}} module fails by this reason:
* \{\{testSendNodeFailsIfAliasIsEmpty}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzxxon:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/17 10:31 PM;alexander.shekhovcov;Fixed as a part INDY-31. 

*How to test:*

Tests are enabled and green.;;;","27/May/17 6:12 AM;krw910;[~aleksey-roldugin] work with [~spivachuk] on steps to manually test this ticket.;;;","01/Jun/17 3:07 AM;aleksey-roldugin;Build:
sovrin-node 0.3.119

Verification:
Following command was sent with dest which belongs to existing in pool node and which belongs to new node. In both cases the result was 'validation error'.
{code:java}
sovrin@test> send NODE dest=4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe data={'client_port': 9702, 'client_ip': '10.0.0.105', 'alias': '', 'node_ip': '10.0.0.105', 'node_port': 9701, 'services':
['VALIDATOR']}
Sending node request for node identifier 4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1496253801707900)
Node request failed with error: client request invalid: InvalidClientRequest('validation error: empty string (alias=)',)

{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The parameter data.services of send NODE command is not validated properly,INDY-38,17108,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,tylerq,alexander.shekhovcov,alexander.shekhovcov,25/May/17 10:10 PM,30/Mar/19 5:36 AM,28/Oct/23 2:46 AM,30/Mar/19 5:36 AM,,,,,0,,,,,,"The parameter \{\{data.services}} of \{\{send NODE}} command is not validated properly. Now \{\{send NODE}} command permits unknown values in \{\{data.services}} array. Also it allows to specify a single value instead of an array as \{\{data.services}} parameter value while it must not allow this.

The following tests fail by to this reason:
* \{\{testSendNodeFailsIfServicesContainsUnknownValue}}
* \{\{testSendNodeFailsIfServicesIsValidatorValue}}
* \{\{testSendNodeFailsIfServicesIsEmptyString}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzxxov:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/17 10:32 PM;alexander.shekhovcov;Fixed as a part INDY-31. 

*How to test:*

Tests are enabled and green.;;;","27/May/17 6:12 AM;krw910;[~aleksey-roldugin] work with [~spivachuk] on steps to manually test this ticket.;;;","01/Jun/17 3:32 AM;aleksey-roldugin;Build:
sovrin-node 0.3.119

Verification:
Following command was sent with dest which belongs to existing in pool node and which belongs to new node. In both cases the result was 'validation error'.
{code:java}
sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'client_port': 9702, 'client_ip': '10.0.0.105', 'alias': 'Node1', 'node_ip': '10.0.0.105', 'node_port': 9701, 'servi
ces': ['DECIDER']}
Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1496254548461875)
Node request failed with error: client request invalid: InvalidClientRequest(""validation error: expected 'VALIDATOR' unknown value 'DECIDER' (services=['DECIDER'])"",)
{code}
{code:java}
 sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'client_port': 9702, 'client_ip': '54.233.109.18', 'alias': 'Node1', 'node_ip': '54.233.109.18', 'node_port': 9701,
'services': 'VALIDATOR'}
Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1496255286049929)
Node request failed with error: client request invalid: InvalidClientRequest(""validation error: expected types 'list, tuple', got 'str' (services=VALIDATOR)"",)
sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'client_port': 9702, 'client_ip': '54.233.109.18', 'alias': 'Node1', 'node_ip': '54.233.109.18', 'node_port': 9701,
'services': VALIDATOR}
""data"" must be in proper format

{code}
{code:java}
 sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'client_port': 9702, 'client_ip': '10.0.0.105', 'alias': 'Node5', 'node_ip': '10.0.0.105', 'node_port': 9701, 'servi
ces': ''}
Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1496255369024055)
Node request failed with error: client request invalid: InvalidClientRequest(""validation error: expected types 'list, tuple', got 'str' (services=)"",)

{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The parameter data of send NODE command permits unknown fields,INDY-39,17109,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,tylerq,alexander.shekhovcov,alexander.shekhovcov,25/May/17 10:10 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,"The parameter {{data}} of {{send NODE}} command permits unknown fields. The following test in {{sovrin_client.test.cli.test_send_node_validation}} module fails by this reason:
 * {{testSendNodeFailsIfDataContainsUnknownField}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzxxp3:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/17 10:32 PM;alexander.shekhovcov;Fixed as a part INDY-31. 

*How to test:*

Tests are enabled and green.;;;","27/May/17 6:13 AM;krw910;[~aleksey-roldugin] work with [~spivachuk] on steps to manually test this ticket.;;;","01/Jun/17 2:40 AM;aleksey-roldugin;Build:
sovrin-node 0.3.119

Verification:
Following command was sent with dest which belongs to existing in pool node and which belongs to new node. In both cases the result was 'validation error'.
{code:java}
sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'client_port': 9702, 'client_ip': '10.0.0.105', 'alias': 'Node5', 'node_ip': '10.0.0.105', 'node_port': 9701, 'servi
ces': ['VALIDATOR'], ' ': ' ', ';':';', '':''}
Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1496252227680593)
Node request failed with error: client request invalid: InvalidClientRequest('validation error: unknown field (=)',)
{code}
 

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The parameter data.services of send NODE command must be mandatory,INDY-40,17110,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,danielhardman,alexander.shekhovcov,alexander.shekhovcov,25/May/17 10:12 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,Must,,,,,"The parameter \{\{data.services}} of \{\{send NODE}} command must be mandatory. Currently this parameter is not mandatory. The following test in \{\{sovrin_client.test.cli.test_send_node_validation}} module fails by this reason:
* \{\{testSendNodeFailsIfServicesIsMissed}}",,,,,,,,,,,INDY-88,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy267:",,,,,,H3,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,dsurnin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/17 10:33 PM;alexander.shekhovcov;https://github.com/evernym/plenum/pull/173

*How to test:*

Tests are enabled and green.;;;","04/Jul/17 8:02 PM;dsurnin;services parameter of send NODE command must be optional, so the issue is invalid;;;","04/Jul/17 8:05 PM;alexander.shekhovcov;Actually nothing to do here. It turned out that _services_ has to be NOT mandatory in case then inactive node is added. The test  _testSendNodeFailsIfServicesIsMissed_ was renamed to _testSendNodeSucceedsIfServicesIsMissed_.

*How to test:*

Make sure that adding new node is possible without the _services_ parameter (was checked already). A new node should not start in this case.

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZMQ,INDY-41,17113,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:48 PM,11/Oct/19 7:15 PM,28/Oct/23 2:46 AM,11/Oct/19 7:14 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-2,,ZMQ,Done,,,,,,,,"1|hzyw6v:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZMQ,INDY-42,17114,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,tylerq,tylerq,25/May/17 11:48 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-5,,ZMQ,Done,,,,,,,,"1|hzxwwn:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Anchoring,INDY-43,17115,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:48 PM,09/Oct/19 5:20 PM,28/Oct/23 2:46 AM,09/Oct/19 5:20 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-7,,Anchoring,Done,,,,,,,,"1|hzxwx3:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Anoncreds,INDY-44,17116,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:49 PM,09/Oct/19 5:08 PM,28/Oct/23 2:46 AM,09/Oct/19 5:08 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-9,,Anoncreds,Done,,,,,,,,"1|hzxwxb:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Batching,INDY-45,17117,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:50 PM,09/Oct/19 5:08 PM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-2,,Batching,Done,,,,,,,,"1|hzxwxr:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Blacklisting,INDY-46,17118,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:50 PM,09/Oct/19 5:17 PM,28/Oct/23 2:46 AM,09/Oct/19 5:15 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-4,,Blacklisting,Done,,,,,,,,"1|hzxwxz:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CentOS,INDY-47,17119,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,nage,tylerq,tylerq,25/May/17 11:50 PM,18/Jul/19 1:01 AM,28/Oct/23 2:46 AM,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,IS-1318,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-6,,CentOS,To Do,,,,,,,,"1|hzxwyf:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CII badge,INDY-48,17120,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:50 PM,11/Oct/19 10:27 PM,28/Oct/23 2:46 AM,09/Oct/19 5:28 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-8,,CII badge,Done,,,,,,,,"1|hzxwyn:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consent Receipts,INDY-49,17121,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:51 PM,09/Oct/19 5:34 PM,28/Oct/23 2:46 AM,09/Oct/19 5:34 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-1,,Consent Receipts,Done,,,,,,,,"1|hzxwzz:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Demo Agent,INDY-50,17122,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:51 PM,09/Oct/19 5:22 PM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-3,,Demo Agent,Done,,,,,,,,"1|hzxx07:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DID/DDO support,INDY-51,17123,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,nage,tylerq,tylerq,25/May/17 11:51 PM,10/Oct/19 9:05 PM,28/Oct/23 2:46 AM,,,,,,0,,,,,,,,,,,,,,,,,,,,IS-146,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-5,,DID/DID-Doc,To Do,,,,,,,,"1|hzxx0f:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/19 10:57 PM;esplinr;Draft pull request:
https://github.com/hyperledger/indy-sdk/pull/1487;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DID TLS,INDY-52,17124,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,tylerq,tylerq,25/May/17 11:51 PM,09/Oct/19 5:35 PM,28/Oct/23 2:46 AM,09/Oct/19 5:35 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-7,,DID TLS,Done,,,,,,,,"1|hzxx0n:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 5:35 PM;esplinr;DID TLS should be done in Aries instead of Indy.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Guardianship,INDY-53,17125,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,tylerq,tylerq,25/May/17 11:51 PM,09/Oct/19 6:26 PM,28/Oct/23 2:46 AM,09/Oct/19 6:25 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-9,,Guardianship,Done,,,,,,,,"1|hzxx27:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:25 PM;esplinr;Our thinking on Guardianship has evolved a lot. It is expected to primarily be supported through DID Doc support and most work will be done in Aries Agents. Therefore we will close these old Indy issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Input Sanitization,INDY-54,17126,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,nage,tylerq,tylerq,25/May/17 11:52 PM,08/Feb/18 5:43 AM,28/Oct/23 2:46 AM,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-2,,Input Sanitization,To Do,,,,,,,,"1|hzyoxb:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Key Management,INDY-55,17127,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:52 PM,13/Nov/19 12:18 AM,28/Oct/23 2:46 AM,13/Nov/19 12:18 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-4,,Key Management,Done,,,,,,,,"1|hzyvdb:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Monitoring,INDY-56,17128,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:52 PM,11/Oct/19 6:35 PM,28/Oct/23 2:46 AM,11/Oct/19 6:35 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-6,,Monitoring,Done,,,,,,,,"1|hzyvef:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MacOS support,INDY-57,17129,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,nage,tylerq,tylerq,25/May/17 11:52 PM,13/Nov/19 12:19 AM,28/Oct/23 2:46 AM,13/Nov/19 12:19 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-8,,MacOS,Done,,,,,,,,"1|hzyve7:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Nov/19 12:19 AM;esplinr;Moving Indy to MacOS would provide platform diversity to the validator pool, but it isn't a current priority for us. We would be happy to help someone else who decides that they want to work on this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Observers,INDY-58,17130,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,nage,tylerq,tylerq,25/May/17 11:53 PM,09/Oct/19 5:30 PM,28/Oct/23 2:46 AM,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-1,,Observers,To Do,,,,,,,,"1|hzyvf3:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Revocation support,INDY-59,17131,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:53 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-3,,Revocation,Done,,,,,,,,"1|hzyvgf:",,,,,,,,,,,,,,,,,,,,,,,,,,lovesh,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Security Audit,INDY-60,17132,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:53 PM,09/Oct/19 7:06 PM,28/Oct/23 2:46 AM,09/Oct/19 7:05 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-5,,Security Audit,Done,,,,,,,,"1|hzyvhj:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
State Proofs work,INDY-61,17133,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:53 PM,11/Oct/19 8:47 PM,28/Oct/23 2:46 AM,11/Oct/19 8:47 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-7,,State Proofs,Done,,,,,,,,"1|hzyvi7:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Trust Framework-borne requirements,INDY-62,17134,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:54 PM,13/Nov/19 12:20 AM,28/Oct/23 2:46 AM,13/Nov/19 12:20 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-9,,Trust Framework,Done,,,,,,,,"1|hzyw4v:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Timestamps support,INDY-63,17135,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:54 PM,13/Nov/19 12:20 AM,28/Oct/23 2:46 AM,13/Nov/19 12:20 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-2,,Timestamps,Done,,,,,,,,"1|hzyviv:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Versioning support,INDY-64,17136,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:54 PM,09/Oct/19 11:17 PM,28/Oct/23 2:46 AM,09/Oct/19 11:17 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-4,,Versioning,Done,,,,,,,,"1|hzyw5j:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
W3C spec VC support,INDY-65,17137,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:55 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-6,,W3C Verifiable Claims,Done,,,,,,,,"1|hzyw67:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Windows support,INDY-66,17138,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:55 PM,11/Oct/19 7:19 PM,28/Oct/23 2:46 AM,11/Oct/19 7:17 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-8,,Windows,Done,,,,,,,,"1|hzyw6f:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 7:19 PM;esplinr;Indy Node used to work on Windows, but we haven't tested it in some time. It is not a priority for us to get Indy Node working on Windows at this point in time. We are happy to assist if someone else wants to do the work. We suggest creating new tasks for getting the current product working on Windows.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Zero-Knowledge Proof related work,INDY-67,17139,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,tylerq,tylerq,25/May/17 11:55 PM,09/Oct/19 11:17 PM,28/Oct/23 2:46 AM,09/Oct/19 11:17 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-1,,ZKP's,Done,,,,,,,,"1|hzyw6n:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The parameter data of send NODE command is not validated properly,INDY-68,17150,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,spivachuk,spivachuk,spivachuk,26/May/17 4:06 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,7Months,CloseCandidate,Could,,,"Now errors related to the format of {{data}} parameter of {{send NODE}} are reported by CLI as {{Invalid command}} while the command itself is valid.
The following tests in {{sovrin_client.test.cli.test_send_node_validation}} module fail by this reason:
* {{testSendNodeFailsIfDataIsBrokenJson}}
* {{testSendNodeFailsIfDataIsNotJson}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzwzbr:",,,,,,12,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 2:55 AM;alexander.shekhovcov;Looks like there is some validation on CLI level because the invalid requests are not received on the Node side. I guess the ticket should be solved on CLI side.;;;","06/Sep/17 6:20 AM;krw910;[~spivachuk] please provide a sample transaction that is valid, but rejected by the CLI. Once you have the example move the ticket to the bottom of the backlog for review.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool ledgers became out of sync and would not accept more NYM transactions,INDY-69,17155,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,26/May/17 8:51 AM,30/Mar/19 5:36 AM,28/Oct/23 2:46 AM,30/Mar/19 5:36 AM,,,,,0,Must,,,,,"I ran the load_test.py scripts against my performance pool of 7 global nodes. After 1800 transactions of send NYM the nodes began to be out of sync.

I also see a large amount of ""disconnected"" entries in the Node log files where the nodes are disconnecting from each other.

*I sent the following load script commands from one client*

python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500

python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once

python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 750 --at-once

python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 1000 --at-once

*I sent the following from 4 different clients at the same time, but nothing wrote to the ledger. I was out of sync before this point and the pool stopped accepting writes.*

python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once

*Here are line counts of my transactions file so show where I am out of sync. With the chunked files it gets out of sync in file 2.*
--------- Node1      Node2      Node3      Node4      Node5     Node6     Node7
File 1         1001         1001        1001        1001         1001        1001        1001
File 1001   1000         1001        1001          812         1000        1000        1000
File 2001     962           962          962           ---            963          962           963

So the two issues are I am out of sync and there is a large number of disconnects. They must be related in some way.

If you restart the services the pool should start to take transactions again. At least when I have seen this before that fixed the issue with taking more transactions. However the nodes that are out of sync would not get back in sync.




",,,0,0,,0%,0,0,,,INDY-13,INDY-14,INDY-70,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy24f:",,,,,,H3,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/17 10:04 PM;ashcherbakov;The current findings:
1) I don't see many disconnections, juat a few (which is normal I think)
2) The content of the Ledger's txns is the same. Some of the txns have empty line at the end, that's why we have 963 vs 962 lines. 
3) Node4 failed (INDY-70) with assertion
4) We have a problem with unexpectable view changes (INDY-34) and view change is broken until INDY-13, INDY-14 are fixed. So, it looks like it's the cause (once we face a view change, we can not sync up anymore).;;;","27/May/17 12:37 AM;ashcherbakov;I think we need to fix
1) INDY-70
2) INDY-13, INDY-14
and check whether the issue has gone.;;;","15/Jun/17 4:35 PM;ashcherbakov;Blocked by INDY-13;;;","04/Jul/17 7:52 AM;krw910;I have not had any crashes repeating the steps in the ticket.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node crashes if catch-up happens during 3pc batching,INDY-70,17162,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,lovesh,lovesh,26/May/17 7:01 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,,,,,,"A node named Node4 in a pool of 7 nodes, crashed.

This is the stacktrace
{code}
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 976, in serviceReplicaOutBox
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:     self.processOrdered(msg)
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1602, in processOrdered
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:     txnRoot)
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1878, in executeBatch
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:     txnRoot)
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 404, in executeDomainTxns
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:     stateRoot, txnRoot)
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1895, in commitAndSendReplies
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:     committedTxns = reqHandler.commit(len(reqs), stateRoot, txnRoot)
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 65, in commit
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:     r = super().commit(txnCount, stateRoot, txnRoot)
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/req_handler.py"", line 60, in commit
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]:     self.ledger.root_hash, txnRoot)
May 25 21:54:11 ip-10-0-0-14 start_sovrin_node[8938]: AssertionError: 5HkoM4ermiQSiNwFqKEKrcktiGn5vydiX8kHBazumHKj GjM6QtX5fr4vqeWMA7Z1Lyq6a7scTxKiPR5NGwxPhQ3y
{code}
 
The log has been backed up at *.sovrin/Node4_21_5_21.log* on Node4 under user sovrin",,,,,,,,,,,,,,INDY-69,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1en:",,,,,,Indy-1,H1,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jun/17 9:30 PM;ashcherbakov;Problem reason: 
- When we start processing 3PC batch, we save am expected state of the ledger. When we commit a batch, we compare expected state with the real (committed) one.
So, if we change the ledger state in between (example: catch-up), the compare will fail.

Changes: 
- Remove all 3PC messages which are already processed by catch-up; reset the uncommitted state.

Risk factors:
- catch-up
- 3PC messages  

Risk:
  Medium

Covered with tests:
- https://github.com/evernym/plenum/blob/master/plenum/test/batching_3pc/catch-up/test_3pc_paused_during_catch_up.py
- https://github.com/evernym/plenum/blob/master/plenum/test/batching_3pc/catch-up/test_catchup_during_3pc.py
- https://github.com/evernym/plenum/blob/master/plenum/test/batching_3pc/catch-up/test_catchup_during_3pc_continue_working.py

;;;","07/Jun/17 12:48 AM;ashcherbakov;Build:
- sovrin-node: 0.3.134
- sovrin-client: 0.3.132;;;","10/Jun/17 7:46 AM;krw910;I ran the exact same load tests as before and did not get any of the nodes into the failed state. I was running 1,000 transactions sent at once with no issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validation of send ATTRIB command parameters is incorrect,INDY-71,17163,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,mzk-vct,spivachuk,spivachuk,26/May/17 8:22 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,7Months,CloseCandidate,should,,,"The following tests in {{sovrin_client.test.cli.test_send_attrib_validation}} module fail by this reason:
* testSendAttribFailsIfRawIsBrokenJson
* testSendAttribFailsIfRawIsHex
* testSendAttribFailsIfRawIsHumanReadableText
* testSendAttribFailsIfRawIsDecimalNumber
* testSendAttribSucceedsForHexEncodedSha256Hash
* testSendAttribSucceedsForHexHashWithLettersInBothCases
* testSendAttribFailsForHashShorterThanSha256
* testSendAttribFailsForHashLongerThanSha256
* testSendAttribFailsForBase58EncodedHash
* testSendAttribFailsForBase64EncodedHash
* testSendAttribSucceedsForNonEmptyEnc",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx0u7:",,,,,,14,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 11:12 PM;alexander.shekhovcov;The tests:
 * testSendAttribSucceedsForHexHash
 * testSendAttribFailsForBase58Hash
 * testSendAttribFailsForBase64Hash
 * testSendAttribSucceedsForHexEnc
 * testSendAttribFailsForBase58Enc
 * testSendAttribFailsForBase64Enc
 * testSendAttribHasInvalidSyntaxIfRawAndHashPassedAtSameTime
 * testSendAttribHasInvalidSyntaxIfRawAndEncPassedAtSameTime
 * testSendAttribHasInvalidSyntaxIfRawHashAndEncPassedAtSameTime
 * testSendAttribHasInvalidSyntaxIfUnknownParameterIsPassed

will not be fixed in the scope of this issue because 'hash' and 'enc' are not supported for now. 

 ;;;","31/May/17 11:13 PM;alexander.shekhovcov;Causes INDY-128;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client to node parameters validation,INDY-72,17165,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,dsurnin,dsurnin,26/May/17 9:01 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,Must,,,,,Validate client to node communication parameters,,,1620,1620,,0%,68580,36720,,,,,,,,,,,,,,,,,,,INDY-136,INDY-124,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy1qn:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,dsurnin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check statuses of the tests disabled on Linux,INDY-73,17167,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,tylerq,spivachuk,spivachuk,26/May/17 9:50 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,shakedown1,,,,,"Check statuses on the tests disabled on Linux in the following repositories:
* ledger,
* stp,
* state,
* plenum,
* sovrin-common,
* sovrin-node,
* sovrin-client.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxpb:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 9:11 PM;spivachuk;* Checked and updated statuses of the tests disabled on Linux in plenum and sovrin-client repositories. Created tickets for the tests which had been disabled without ticket references.
* Verified that all the tests disabled on Linux have been annotated with references to open tickets. Created new tickets and updated the references for the disabled tests with references to closed tickets.
* Removed all the commented out @skip and @skipif decorators.
* Created implementation tickets for all the test stubs and incomplete tests which did not have ticket references previously in plenum and sovrin-client repositories.;;;","31/May/17 9:17 PM;spivachuk;The following pull requests were merged in scope of this task:
* https://github.com/evernym/plenum/pull/176
* https://github.com/evernym/plenum/pull/177
* https://github.com/evernym/plenum/pull/180
* https://github.com/sovrin-foundation/sovrin-client/pull/195
* https://github.com/sovrin-foundation/sovrin-client/pull/196;;;","31/May/17 9:27 PM;spivachuk;The following tickets have been created for disabled tests in scope of this task:
INDY-75, INDY-76, INDY-78, INDY-79, INDY-80, INDY-84, INDY-85, INDY-86, INDY-87, INDY-90, INDY-96, INDY-98, INDY-99, INDY-101, INDY-102, INDY-105, INDY-107;;;","01/Jun/17 1:07 AM;spivachuk;The current statistics on tests are as follows.

*ledger:*
* Total tests: 86
* Tests disabled on Linux: 0

*stp:*
* Total tests: 17
* Tests disabled on Linux: 0

*state:*
* Total tests: 56
* Tests disabled on Linux: 0

*plenum:*
* Total tests: 345
* Tests disabled on Linux: 45

*anoncreds:*
* Total tests: 81
* Tests disabled on Linux: 0

*sovrin-common:*
* Total tests: 18
* Tests disabled on Linux: 0

*sovrin-node:*
* Total tests: 43
* Tests disabled on Linux: 1

*sovrin-client:*
* Total tests: 352
* Tests disabled on Linux: 86;;;","01/Jun/17 2:39 AM;krw910;This task is complete and the tickets from this task have been logged.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Document: Steward Preparation Instructions,INDY-74,17169,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,TechWritingWhiz,TechWritingWhiz,26/May/17 11:41 PM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,05/Jun/17 12:00 AM,0,Documentation,,,,,"This item will be a document that explains the necessary instructions that a Steward would need to set up a validator node on the Sovrin network.

While initially running through the steps, it was realized that there are some steps within the process that for now will be added as placeholder values until decisions are made about the details of each of those portions of the instructions.

Place the document initially into a Google doc.

Initial draft due 5/30/17

Final draft due about 6/5/2017",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxx6v:",,,,,,,,,,,,,,,,,,,,,,,,,,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 7:56 AM;TechWritingWhiz;Initial draft complete. Shared google doc with Trev.;;;","08/Jun/17 7:38 AM;TechWritingWhiz;Version 1.0 of this document is ""DONE"" per Mike Bailey.  Marked ""Done"" per request. Mike will send out a PDF version as necessary.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testNodesConnectsWhenOneNodeIsLate fails,INDY-75,17171,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,27/May/17 12:05 AM,30/Mar/19 5:37 AM,28/Oct/23 2:46 AM,30/Mar/19 5:37 AM,,,,,0,disabled-tests,Must,shakedown1,,,testNodesConnectsWhenOneNodeIsLate in plenum repository fails.,,,32400,32400,,0%,32400,32400,,,INDY-13,,,,,,,,,,INDY-109,,,,,,,,,,,,,,"16/Jun/17 7:46 PM;andkononykhin;test-result.agent-ubuntu-04.txt;https://jira.hyperledger.org/secure/attachment/11180/test-result.agent-ubuntu-04.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy20f:",,,,,,H3,H4,,,,,,,,,,,,,,,,,,,andkononykhin,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 8:12 PM;andkononykhin;Jenkins log where test failed: [https://jenkins.evernym.com/job/Plenum/job/master/119/artifact/test-result.agent-ubuntu-04.txt]

(attached here as well: https://jira.hyperledger.org/secure/attachment/11180/test-result.agent-ubuntu-04.txt)

According to it we see:
 # first 3 Nodes (Alpha, Beta, Delta) during start went through 2 rounds of elections
 # all messages for not started node had been suspended
 # last Node (Gamma) started after election finally happened
 # Gamma received all suspended messages from each node at once: pinged Alpha - received all messages from it, pinged Beta - all msgs from it ...
 # set of messages from each node included several NOMINATEs, several REELECTIONs, several PRIMARYs
 # Gamma processed them one by one from each Node and seems it led to misbehaviors:

 # 
 ## Gamma expects REELECTION with round=1 but received both versions of REELECTION messages (round=1 and round=2). So, it discarded the latter.
 ## Gamma accumulated REELECTIONs, achieved quorum and initiated reelection (resetting accumulated nominations) itself at the time when first three nodes had been already decided about primaries (for me it means that old REELECTION messages should be treated as obsolete and ignored). As a result, Gamma had lack of nominations to choose the primary.

There are two options to fix that test:
 # update/increase default timeout in plenum/test/test_node.py:ensureElectionsDone: for now it expected 0 number of reelections  callingplenum/test/waits.py:expectedPoolElectionTimeout
 # wait for updated election logic in scopr of INDY-13 and adjust test to it

I don't think that option 1 resolves issue cause of mentioned misbehaviors, so I'm going to mark the task as blocked by INDY-13.

 ;;;","12/Jul/17 2:11 PM;krw910;I have verified this test is enabled and passed in the last build of plenum. The test is located [here|https://github.com/hyperledger/indy-plenum/blob/12ca9b5b86e4dde21204e0f3fa016c4cc3eae4d2/plenum/test/test_node_connection.py];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testMultipleRequests fails,INDY-76,17173,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,alexander.shekhovcov,spivachuk,spivachuk,27/May/17 12:27 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,7Months,AlexReview,Could,disabled-tests,,testMultipleRequests in plenum repository fails,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzy0un:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,lovesh,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/May/17 2:41 PM;lovesh;As the test's skip mentions the reason, this test relies on the stack having a mechanism for tracking statistics like how many messages were sent and received, but this test is not testing anything related to stats, so not urgent to fix;;;","13/Dec/17 5:34 PM;ashcherbakov;As we agreed to remove RAET, and ZMQ doesn't have this functionality, I think we can just remove this test.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Document: Change ""Acme Corp"" in documentation to something else ",INDY-77,17174,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,TechWritingWhiz,TechWritingWhiz,TechWritingWhiz,27/May/17 12:41 AM,08/Oct/19 9:12 PM,28/Oct/23 2:46 AM,08/Oct/19 9:12 PM,,,,,0,7Months,Could,Documentation,,,"Everywhere where ""Acme Corp"" or ""acmecorp.com"" exists in the documentation, change it to ""Plexane, Inc."" and ""plexaneinc.com"". Acme Corp, although is a fictional company in the Looney Tunes cartoon series, today it is a real company with a real website. Verified as of the creation of this ticket that ""Plexane, Inc"" is not pulling up in search engines at this time.

Interim fix: Where found, a phrase something similar to ""the fictional company..."" will be added for clarification.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-792,,,,,,,,,,"1|hzy0vj:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,SeanBohan_Sovrin,stevetolman,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 6:09 AM;stevetolman;This will also require a change to the code. Do not make this change without further discussion with engineering.;;;","13/Dec/17 3:26 AM;SeanBohan_Sovrin;[~TechWritingWhiz] - can we close this ticket?;;;","13/Dec/17 5:10 AM;TechWritingWhiz;[~SeanBohan_Sovrin] I'm going to say ""no"" because this is something that does need to be fixed. It just hasn't been a priority. We can close this ticket if we can track it somewhere else. Not resolving this could potentially incur negative legal scenarios in the future. When I realized this, I was instructed to create a ticket for this item.;;;","08/Oct/19 9:12 PM;ashcherbakov;This documentation is removed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Actualize the tests in plenum.test.input_validation.test_common_checks module,INDY-78,17178,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,alexander.shekhovcov,spivachuk,spivachuk,27/May/17 1:08 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,7Months,AlexReview,disabled-tests,should,,Actualize and enable the tests in plenum.test.input_validation.test_common_checks module.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx1nz:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/17 5:48 PM;ashcherbakov;We don't have this module any more.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Complete implementation of the tests in plenum.test.input_validation.test_handle_one_node_message module,INDY-79,17179,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,alexander.shekhovcov,spivachuk,spivachuk,27/May/17 1:12 AM,29/Oct/19 11:34 PM,28/Oct/23 2:46 AM,29/Oct/19 11:34 PM,,,,,0,7Months,disabled-tests,KellyRetest,should,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx1o7:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/19 11:34 PM;esplinr;This issue no longer applies to the Indy codebase.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Complete implementation of testMultipleInstanceChangeMsgsMarkNodeAsSuspicious,INDY-80,17180,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,spivachuk,spivachuk,27/May/17 1:20 AM,10/Oct/19 12:54 AM,28/Oct/23 2:46 AM,10/Oct/19 12:54 AM,,,,,0,7Months,Could,disabled-tests,KellyRetest,,Complete implementation of testMultipleInstanceChangeMsgsMarkNodeAsSuspicious in plenum repository.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx12f:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,spivachuk,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 5:55 AM;stevetolman;Please explain why this is important. What are we missing by not having this test? How risky is it not to have? These answers will help us better prioritize the ticket.;;;","17/Jul/17 7:20 PM;spivachuk;[~stevetolman], {{testMultipleInstanceChangeMsgsMarkNodeAsSuspicious}} must verify that if some node in a pool sends {{INSTANCE_CHANGE}} messages to other nodes too frequently then they blacklist this node. There are no other tests relying on this feature. This feature has not been implemented yet. I think that implementation of this feature and the test checking it may be scheduled for the time after Minimal Go-Live.;;;","06/Sep/17 6:25 AM;krw910;[~spivachuk] lets eliminate this test and write a new one once the feature is implemented.;;;","10/Oct/19 12:54 AM;ashcherbakov;The test is not relevant anymore. We should accept frequent Instance Changes;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[init_sovrin_node] Unsuccessful node initialization returns results the same as successful,INDY-81,17181,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,VladimirWork,VladimirWork,27/May/17 1:26 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,7Months,KellyRetest,should,,,"Build Info:
0.3.116

Steps to Reproduce:
1. Login any node in Pool 2.
2. Execute ""init_sovrin_node Node0 9701 9702 000000000000000000000000000node0"".

Actual Results:
/usr/local/bin/init_sovrin_node: line 14: /home/sovrin/.sovrin/sovrin.env: Permission denied
/usr/local/bin/init_sovrin_node: line 15: /home/sovrin/.sovrin/sovrin.env: Permission denied
/usr/local/bin/init_sovrin_node: line 16: /home/sovrin/.sovrin/sovrin.env: Permission denied
For node stack, stack name is Node0
Public key is 7cbe0c065a818cb03f5c60dad3f6fe93dbb5f1907e9d11d5f8af1efb1b0e325f
Verification key is 36716e17091b3a264b21466634693fb0b9dbd32b12d5c4bc6863f3e3b66fa772
For client stack, stack name is Node0C
Public key is 7cbe0c065a818cb03f5c60dad3f6fe93dbb5f1907e9d11d5f8af1efb1b0e325f
Verification key is 36716e17091b3a264b21466634693fb0b9dbd32b12d5c4bc6863f3e3b66fa772


Expected Results:
Unsuccessful node initialization must not return stack name and keys.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-987,,,,,,,,,,"1|hzy0vr:",,,,,,,,,,,,,,,,,,,,,,,,,,sergey-shilov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 1:26 AM;VladimirWork;FYI [~kelly.wilson], [~stevetolman], [~tylerq], [~ashcherbakov];;;","10/Oct/18 12:18 AM;sergey-shilov;This script does not exist any more, it is replaced by _init_indy_node_ script that has another logic and another paths are used. So this ticket is not relevant any more and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[shakedown] Our tests doesn't actually test batching correctly,INDY-82,17184,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,ashcherbakov,ashcherbakov,27/May/17 2:01 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"It turned out that our current tests override `Max3PCBatchSize` and `DELTA`.
It means that they don't actually test batching at all, and use other Monitor configuration than production nodes!
This needs to be fixed ASAP.

https://github.com/evernym/plenum/blob/master/plenum/test/conftest.py
{code}
overriddenConfigValues = {
    ""DefaultPluginPath"": {
        PLUGIN_BASE_DIR_PATH: testPluginBaseDirPath,
        PLUGIN_TYPE_STATS_CONSUMER: ""stats_consumer""
    },
    'EnsureLedgerDurability': False,
    'Max3PCBatchSize': 1,
    'DELTA': .8
}
{code}

There is also additional overriding in https://github.com/evernym/plenum/blob/master/plenum/test/batching_3pc/conftest.py
{code}
@pytest.fixture(scope=""module"")
def tconf(tconf, request):
    oldSize = tconf.Max3PCBatchSize
    oldTIme = tconf.Max3PCBatchWait
    tconf.Max3PCBatchSize = 3
    tconf.Max3PCBatchWait = 5
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1c7:",,,,,,H1,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 2:03 AM;ashcherbakov;[~stevetolman] [~lovesh.harchandani] [~kelly.wilson] [~jlaw 1] 
I think this needs to be fixed ASAP;;;","14/Jun/17 11:15 AM;krw910;I have verified the changes are in the code that removes the overrides causing the issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As an Indy developer, I want to easily create a canonical dev env",INDY-83,17185,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,danielhardman,danielhardman,27/May/17 2:45 AM,09/Oct/19 6:39 PM,28/Oct/23 2:46 AM,09/Oct/19 6:39 PM,,,,,0,7Months,KEEP,should,,,"This story gets at the problem that it is hard to take a naked machine and get to a point where a developer has all libraries and dependencies installed, has all code laid out in a canonical way, and can run all tests and observe them pass. This should not be.

The success criterion for this story is: A developer can begin with a freshly installed OS (ubuntu 16+ or Windows 10+ must work; OSX desirable), read some *brief* instructions, and get to a fully functional dev environment with very little interaction. Ideally, the instructions would say something like ""On Ubuntu, the packages you need are stored in a requirements.txt-style file at <url>, and you can install them all with this command: cat apt-packages.txt | sudo apt-get install""

Constraints on the solution (try very hard to achieve this; negotiate if it seems impossible):

1. Packages not written by Indy developers should be installed the way they will be installed for those who eventually run the software in production; that is, install as system packages, using the OS package manager. So for example, charm-crypto, pytest and so forth should all be installed system-wide with apt, yum, chocolatey, etc--NOT with pip.

2. Python virtual environments should not be required, but should be possible.

3. Components (github repos) should be assumed to live as siblings of one another under any convenient, common parent directory. They should discover one another's presence in that sibling location automatically, without any ""pip install -e"" type workflow.

4. Automated tests must be runnable from the command line at any folder inside the common parent with no difference in results, other than different scopes. Any dependencies should be discovered and resolved by the testrunner.

5. It should be possible to run a source code component in combination with os-package-manager packages for its dependencies. So, for example, if I only want to work on sovrin-node, I should be able to do ""apt-get install plenum ledger anoncreds"", and the dependencies should all seamlessly resolve--and if I later change my mind and want to work on anoncreds also, I should be able to get the code, and then do ""apt-get remove anoncreds"" and have the dependencies resolve seamlessly. Of course, having bleeding edge code in sovrin-node, but slightly stale code in a .deb for anoncreds might not work if the sovrin-node code depends on the latest-and-greatest anoncreds. So it should also be possible for a developer to install a bleeding edge anoncreds.deb with dpkg (not from a published repo), or to get the anoncreds source if it's *totally* bleeding edge.

6. The solution should be comfortable to use within 1 or 2 common python IDEs (including PyCharm, since we commonly use it). It should also be comfortable to use from the command line and with editors like vim and emacs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 2:47 AM;danielhardman;Screen Shot 2017-05-26 at 11.46.44 AM.png;https://jira.hyperledger.org/secure/attachment/10873/Screen+Shot+2017-05-26+at+11.46.44+AM.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-987,,,,,,,,,,"1|hzx19r:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,danielhardman,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/17 2:47 AM;danielhardman;I copied across some comments using a screenshot, instead of copying and pasting lots of text, just for expediency. See the attachment.;;;","23/Dec/17 12:30 AM;ashcherbakov;We are providing a set of docs and simple scripts to bootstrap dev environment:
- https://github.com/hyperledger/indy-node/tree/master/dev-setup/ubuntu
- https://github.com/hyperledger/indy-node/blob/master/docs/setup-dev.md

Current restrictions/limitations:
- the solution is based on Python virtualenv and pip
- the solution works for both plenum and node (in fact it covers most of the use cases)
- we have scripts for Ubuntu only (but in fact indy-node works on Ubuntu only now);;;","09/Oct/19 6:39 PM;ashcherbakov;With the current helper scripts and instructions it takes about a day for new members to create a dev environment. If we see that there are still issues with this - we will log a new ticket.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Complete implementation of testQueueingReqFromFutureView,INDY-84,17187,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,lovesh,spivachuk,spivachuk,27/May/17 2:53 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,disabled-tests,shakedown1,should,,,Complete implementation of testQueueingReqFromFutureView in plenum repository.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0nr:",,,,,,,,,,,,,,,,,,,,,,,,,,lovesh,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/May/17 12:44 AM;lovesh;This has been committed in branch `new-elec` and is passing.;;;","26/Jun/17 6:38 PM;lovesh;This has been committed in branch `simple-election` and is passing.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test_show_nonexistant_proof_request fails,INDY-85,17196,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,spivachuk,spivachuk,27/May/17 7:52 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,7Months,disabled-tests,KellyRetest,Must,shakedown1,test_show_nonexistant_proof_request in sovrin-client repository fails,,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-785,,,,,,,,,,"1|hzy12n:",,,,,,H2,,,,,,,,,,,,,,,,,,,,danielhardman,Derashe,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jun/17 5:18 AM;danielhardman;By the way, when fixing this test, let's also fix the misspelling in its name (""nonexistant"" >> ""nonexistent"")

 ;;;","16/Jun/17 2:51 PM;mark.hadley;Currently my understanding is that this test will be passed on to someone else. 

Also, this is in the cli tests which none of the cli test pass on my current environment. I ran this by Doug, and the same was with his environment: none of the sovrin_client/cli test pass. For reference, here's the error message that many of them give:

test setup failed
self = <CallInfo when='setup' exception: I/O operation on closed file>
func = <function call_runtest_hook.<locals>.<lambda> at 0x7f5dcf624510>
when = 'setup'

    def __init__(self, func, when):
        #: context of invocation: one of ""setup"", ""call"",
        #: ""teardown"", ""memocollect""
        self.when = when
        self.start = time()
        try:
>           self.result = func()

/home/hadleym/.local/lib/python3.5/site-packages/_pytest/runner.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/runner.py:145: in <lambda>
    return CallInfo(lambda: ihook(item=item, **kwds), when=when)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py:745: in __call__
    return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py:339: in _hookexec
    return self._inner_hookexec(hook, methods, kwargs)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py:334: in <lambda>
    _MultiCall(methods, kwargs, hook.spec_opts).execute()
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py:613: in execute
    return _wrapped_call(hook_impl.function(*args), self.execute)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py:250: in _wrapped_call
    wrap_controller.send(call_outcome)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/capture.py:130: in pytest_runtest_setup
    self.suspendcapture_item(item, ""setup"")
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/capture.py:155: in suspendcapture_item
    out, err = self.suspendcapture(in_=in_)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/capture.py:96: in suspendcapture
    outerr = cap.readouterr()
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/capture.py:318: in readouterr
    return (self.out.snap() if self.out is not None else """",
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <FDCapture 1 oldfd=5>

    def snap(self):
        f = self.tmpfile
>       f.seek(0)
E       ValueError: I/O operation on closed file

/home/hadleym/.local/lib/python3.5/site-packages/_pytest/capture.py:365: ValueError
E
sovrin_client/test/cli/test_proof_request.py:0 (test_show_nonexistant_proof_request)
self = <CallInfo when='teardown' exception: I/O operation on closed file>
func = <function call_runtest_hook.<locals>.<lambda> at 0x7f5dcf167048>
when = 'teardown'

    def __init__(self, func, when):
        #: context of invocation: one of ""setup"", ""call"",
        #: ""teardown"", ""memocollect""
        self.when = when
        self.start = time()
        try:
>           self.result = func()

/home/hadleym/.local/lib/python3.5/site-packages/_pytest/runner.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/runner.py:145: in <lambda>
    return CallInfo(lambda: ihook(item=item, **kwds), when=when)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py:745: in __call__
    return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py:339: in _hookexec
    return self._inner_hookexec(hook, methods, kwargs)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py:334: in <lambda>
    _MultiCall(methods, kwargs, hook.spec_opts).execute()
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py:613: in execute
    return _wrapped_call(hook_impl.function(*args), self.execute)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py:250: in _wrapped_call
    wrap_controller.send(call_outcome)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/capture.py:144: in pytest_runtest_teardown
    self.suspendcapture_item(item, ""teardown"")
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/capture.py:155: in suspendcapture_item
    out, err = self.suspendcapture(in_=in_)
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/capture.py:96: in suspendcapture
    outerr = cap.readouterr()
/home/hadleym/.local/lib/python3.5/site-packages/_pytest/capture.py:318: in readouterr
    return (self.out.snap() if self.out is not None else """",
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <FDCapture 1 oldfd=5>

    def snap(self):
        f = self.tmpfile
>       f.seek(0)
E       ValueError: I/O operation on closed file

/home/hadleym/.local/lib/python3.5/site-packages/_pytest/capture.py:365: ValueError;;;","23/Jun/17 1:52 AM;mark.hadley;When running the entire sovrin-client test suite, this test passes.
Also, when adding the '-s' argument to pytest when running this single test, the test passes.
;;;","23/Jun/17 1:56 AM;mark.hadley;[~spivachuk] was this the error above that you were seeing?;;;","23/Jun/17 3:45 AM;mark.hadley;[https://github.com/sovrin-foundation/sovrin-client/pull/233]

For spelling.;;;","23/Jun/17 4:30 AM;mark.hadley;INDY-315 is fixing this issue.;;;","10/Oct/18 7:09 PM;Derashe;This test passes;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testPingThriftBeforeSync aborts,INDY-86,17197,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,spivachuk,spivachuk,spivachuk,27/May/17 8:15 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,7Months,CloseCandidate,disabled-tests,shakedown1,should,"testPingThriftBeforeSync in sovrin-client repository aborts. It aborts due to incorrect implementation and is set to skip.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx127:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Aug/17 6:35 AM;krw910;[~spivachuk] Time box this to 30 minutes either fix or delete this test.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test_getting_started fails intermittently,INDY-87,17198,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,27/May/17 8:33 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,disabled-tests,Must,shakedown1,,,test_getting_started in sovrin-client repository intermittently fails with PortNotAvailable exception.,,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy20n:",,,,,,H1,H2,H3,H4,,,,,,,,,,,,,,,,,danielhardman,krw910,mark.hadley,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 2:43 PM;mark.hadley;I've been investigating this.  Ports are getting being used by either other processes when this is occurring, or when the 'test' is run in succession.  Haven't found a consistent reason, yet. Still looking into it.;;;","20/Jun/17 6:23 AM;mark.hadley;I was able to get the script to fail by running it 2 consecutive times.  Added a property that allows for reusing of the addresses.;;;","29/Jun/17 12:14 AM;mark.hadley;Blocked b/c of new error in code. See INDY-339.;;;","30/Jun/17 6:13 AM;mark.hadley;No long blocked for INDY-339.;;;","06/Jul/17 12:41 PM;danielhardman;Mark, what commit or PR contains your fix?;;;","06/Jul/17 11:33 PM;mark.hadley;[https://github.com/hyperledger/indy-stp/pull/36]

 ;;;","12/Jul/17 2:19 PM;krw910;The last build of indy-node shows this was run. It appears to be successful.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unexpected behavior of the testSendNodeSucceedsIfServicesIsMissed test,INDY-88,17214,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,29/May/17 6:47 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,The test makes downstream tests failed and hung testing.,,,,,,,,,,,,,,INDY-9,INDY-40,,,,,,,,,,,,INDY-228,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1br:",,,,,,H1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/May/17 11:35 PM;alexander.shekhovcov;(/)

 

*Problem reason:*
 # Adding a node without SERVICES actually joined the node to the pool. But the node was not started as a result the pool had more f malicious nodes.

*Changes:*
 # Do not start a new node if SERVICES does not contain VALIDATOR
 # removed test _testSendNodeSucceedsIfServicesIsMissed_
 # added test _testSendNodeFailsIfServicesIsMissed_

*Committed into:*

https://github.com/evernym/plenum/pull/185/commits/79812f369099d9785146ac4e7f62567b1845ad4f
 [https://github.com/sovrin-foundation/sovrin-client/pull/197/files]

*Risk factors:* 
 Commands which sent the add NODE txn without SERVICES will not join the node.

*Risk:* 
 Low

*Covered with tests:*

_testSendNodeFailsIfServicesIsMissed_

_testSuspendNodeWhichWasNeverActive_

_testAddNonActiveNodeThenActivate_

 

*Recommendations for QA:*

check if:
 * adding a node does not fail without SERVICES field and the node does not participate in the pool
 * updating node data does not fail without SERVICES field;;;","15/Jun/17 2:54 AM;aleksey-roldugin;h6. build

sovrin-node 0.3.138
 sovrin-client 0.3.136
h6. verification
h5. Case 1: adding a node does not fail without SERVICES field and the node does not participate in the pool
 # Send from CLI:
{code:java}
sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'
client_port': 9710, 'client_ip': '52.65.105.174', 'alias': 'Node5', 'node_ip': '
52.65.105.174', 'node_port': 9709, 'services': []}
Sending node request for node identifier 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1497456523692470)
3JmHZk3qC2mjCH7im2PWYfBWBb98AYccYBrBPMMfueeT looking for Node5C at 52.65.105.174:9710
Node request completed 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc
3JmHZk3qC2mjCH7im2PWYfBWBb98AYccYBrBPMMfueeT now connected to Node5C
{code}

 # Check that added node did not perform catch up.

h5. Case 2: updating node data does not fail without SERVICES field
 # Send from CLI:
{code:java}
sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'
alias': 'Node1', 'services': []}
Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL (request id: 1497458551565558)
3JmHZk3qC2mjCH7im2PWYfBWBb98AYccYBrBPMMfueeT disconnected from Node1C
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm disconnected from Node1C
Node request completed Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm could not find remote Node1C
{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Sovrin-CLI ""new client"" command crash",INDY-89,17215,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,farooq_m_khan,farooq_m_khan,29/May/17 7:26 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,CloseCandidate,Could,,,,"Start Sovrin Cli

Issue command ""*connect test*"" does not matter if the connection succeeds.

You will get some message a below
{code:java}
Saved keyring ""Default"" restored (/home/farooq/.sovrin/keyrings/test/default.wallet)
Active keyring set to ""Default""
Client sovrinYb7NqD initialized with the following node registry:
{code}
Issue command ""*new client sovrinYb7NqD*"" the name of the client that was initialized in the previous step. CLI crashes with an exception, see attached pic

 

CLI should gracefully handle and report the error
 
 ","Ubuntu 16, Sovrin-CLI Build # 0.3.17
 ",,,,,,,,,,,,,,,,INDY-91,,,INDY-30,,,,,,,,,,,,,,,"29/May/17 7:33 PM;farooq_m_khan;Screen Shot 2017-05-29 at 2.50.18 PM.png;https://jira.hyperledger.org/secure/attachment/10875/Screen+Shot+2017-05-29+at+2.50.18+PM.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy0vz:",,,,,,,,,,,,,,,,,,,,,,,,,,farooq_m_khan,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:56 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testNodeDiscardMessageFromUnknownView fails,INDY-90,17216,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,29/May/17 9:13 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,disabled-tests,shakedown1,,,,testNodeDiscardMessageFromUnknownView in plenum repository fails.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1db:",,,,,,H1,,,,,,,,,,,,,,,,,,,,andkononykhin,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jun/17 2:44 AM;andkononykhin;Hello, [~krw910]

I enabled and updated this test.

It [passed on Jenkins|https://jenkins.evernym.com/job/Plenum/view/change-requests/job/PR-194/10/console] (please, check for 'test_discard_view_no.py').

Thank you;;;","14/Jun/17 11:09 AM;krw910;I verified this in the logs of plenum build 142 on Jenkins;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Sovrin-CLI ""create genesis transaction file"" command clears the pool_transactions_sandbox contents",INDY-91,17217,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,farooq_m_khan,farooq_m_khan,29/May/17 9:21 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,CloseCandidate,Could,,,,"Start Sovrin Cli, you will get the message below
{code:java}
Loading module /usr/local/lib/python3.5/dist-packages/config/config-crypto-example1.py
Module loaded.

Sovrin-CLI (c) 2017 Evernym, Inc.
Node registry loaded.
    Node1: 13.56.34.166:9701
    Node2: 52.60.239.148:9703
    Node3: 54.94.255.14:9705
    Node4: 52.58.229.128:9707
Type 'help' for more information.
Running Sovrin 0.3.110
{code}
This means the file "".sovrin/pool_transactions_sandbox"" has entries for the above 4 Nodes.

Issue command ""*connect test*"" should connect to the nodes and give a success message

Issue command ""*create* genesis *transaction file*"" this command will empty the contents of ""*.sovrin/pool_transactions_sandbox*"" as a result you will not be able to connect to the nodes if you exit, unless you have a backup of pool_transactions_sandbox somewhere or know how to get it.

If the behavour of this command is intended to empty the *pool_transactions_sandbox*, this is a destructive command need a confirmation from user. If not this needs fixing so that the file is not emptied
 
 
 
 ","Ubuntu 16, Sovrin-CLI Build # 0.3.17
 ",,,,,,,,,,,,,,,,INDY-92,,,INDY-89,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1rr:",,,,,,,,,,,,,,,,,,,,,,,,,,farooq_m_khan,krw910,ozheregelya,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 6:55 AM;stevetolman;[~farooq_m_khan] This is working correctly so you can connect to the correct sandbox pool. If you are wanting to be able to switch between multiple sandboxes we would need to add that functionality to the CLI. Please let us know what you are wanting from this ticket.;;;","06/Sep/17 6:30 AM;krw910;Don't delete the existing file just rename it and then create the new file.;;;","05/Dec/17 9:18 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Sovrin-CLI, appends new line to pool_transactions_sandbox each time it is launched",INDY-92,17218,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,farooq_m_khan,farooq_m_khan,29/May/17 9:53 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Could,,,,,"Edit file "".sovrin/pool_transactions_sandbox"" and have some valid entries in it.

Check number of lines in file:
{code:java}
sed '/^$/d' .sovrin/pool_transactions_sandbox | wc -l
{code}
Launch CLI and exit, check number lines again

The number of lines increase by 1 each time Sovrin CLI is launched. 

 
 
 
 ","Ubuntu 16, Sovrin-CLI Build # 0.3.17
 ",,,,,,,,,,,,,,,,,,,INDY-91,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy24v:",,,,,,H3,,,,,,,,,,,,,,,,,,,,farooq_m_khan,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jul/17 7:39 AM;krw910;This appears to be working find in build 0.4.9;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Some syntax errors are reported inappropriately for send NODE command,INDY-93,17219,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,alexander.shekhovcov,alexander.shekhovcov,alexander.shekhovcov,29/May/17 11:30 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,CloseCandidate,Could,KellyRetest,,,"For {{send NODE}} command some syntax errors are reported by CLI with the message


{code:java}
Invalid command{code}
instead of
{code:java}
Invalid syntax{code}
The following tests in {{sovrin_client.test.cli.test_send_node_validation}} module fail by this reason:
 * {{testSendNodeHasInvalidSyntaxIfDestIsEmpty}}
 * {{testSendNodeHasInvalidSyntaxIfDestIsMissed}}
 * {{testSendNodeHasInvalidSyntaxIfDataIsEmptyString}}
 * {{testSendNodeHasInvalidSyntaxIfDataIsMissed}}
 * {{testSendNodeHasInvalidSyntaxIfUnknownParameterIsPassed}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy0w7:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Some syntax errors are reported inappropriately for send NYM command,INDY-94,17220,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,alexander.shekhovcov,alexander.shekhovcov,alexander.shekhovcov,29/May/17 11:36 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,CloseCandidate,Could,KellyRetest,,,"Syntax errors in the user input must be reported by CLI with the message:
{noformat}
Invalid syntax
{noformat}

For {{send NYM}} command some syntax errors are reported inappropriately. The following tests in {{sovrin_client.test.cli.test_send_nym_validation}} module fail by this reason:
* testSendNymHasInvalidSyntaxIfParametersOrderIsWrong
* testSendNymHasInvalidSyntaxIfIdentifierIsEmpty
* testSendNymHasInvalidSyntaxIfIdentifierIsOmitted
* testSendNymHasInvalidSyntaxIfIdentifierAndVerkeyAreOmitted
* testSendNymHasInvalidSyntaxIfUnknownParameterIsPassed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx1qv:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The parameter dest of send NODE command is not validated properly,INDY-95,17221,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,alexander.shekhovcov,alexander.shekhovcov,alexander.shekhovcov,29/May/17 11:40 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,7Months,Must,,,,"The parameter {{dest}} of {{send NODE}} command is not validated properly. The following tests in {{sovrin_client.test.cli.test_send_node_validation}} module fail by this reason:
* {{testSendNodeFailsIfDestIsSmallDecimalNumber}}
* {{testSendNodeFailsIfDestIsShortReadableName}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx1in:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,SeanBohan_Sovrin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/17 3:12 AM;SeanBohan_Sovrin;[~alexander.shekhovcov] -  is this still valid? if not pls close;;;","23/Dec/17 12:05 AM;ashcherbakov;Yes, it's done. I'm going to unskip the tests in my next PR;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement the tests in plenum.test.batching_3pc.test_client_requests module,INDY-96,17222,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,lovesh,spivachuk,spivachuk,29/May/17 11:54 PM,11/Oct/19 6:52 PM,28/Oct/23 2:46 AM,11/Oct/19 6:52 PM,,,,,0,7Months,disabled-tests,shakedown2,should,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx15b:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,lovesh,SeanBohan_Sovrin,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/May/17 9:20 PM;lovesh;Need state proofs to be implemented, we don't them as of now;;;","13/Dec/17 3:10 AM;SeanBohan_Sovrin;[~ashcherbakov] - guessing we already have tests - do we need tests here or can we close this?;;;","11/Oct/19 6:52 PM;ashcherbakov;We already have similar tests;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sending empty ATTRIB array caused node to stop connecting.,INDY-97,17223,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,30/May/17 12:20 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"Build Info:
0.3.103

Actual Results:
Node2C is not connected to Shakedown Pool 2.

Expected Results:
Node2C should be connected to Shakedown Pool 2.

Additional Information:
The first command without any result (error or success) was ""send ATTRIB dest=7 raw={}"" (empty raw parameter) - probably it caused problem with node.",,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,INDY-206,,,,,,,,,,,,,"26/Jun/17 6:38 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11373/Screenshot.PNG","30/May/17 12:23 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/10876/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy16n:",,,,,,H2,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/May/17 12:22 AM;VladimirWork;FYI [~kelly.wilson], [~stevetolman], [~tylerq], [~ashcherbakov];;;","30/May/17 12:27 AM;VladimirWork;ubuntu@singaporeShakeP2:~$ sudo systemctl status sovrin-node.service
? sovrin-node.service - Sovrin Node
   Loaded: loaded (/etc/systemd/system/sovrin-node.service; enabled; vendor pres
   Active: active (running) since Thu 2017-05-25 19:06:01 UTC; 3 days ago
 Main PID: 9347 (start_sovrin_no)
    Tasks: 3
   Memory: 113.4M
      CPU: 20h 8min 29.041s
   CGroup: /system.slice/sovrin-node.service
           +-9347 /usr/bin/python3 /usr/local/bin/start_sovrin_node Node2 9703 9

May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:   F
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:   F
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:   F
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:   F
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: Key
lines 1-20/20 (END)...skipping...
? sovrin-node.service - Sovrin Node
   Loaded: loaded (/etc/systemd/system/sovrin-node.service; enabled; vendor preset: enabled)
   Active: active (running) since Thu 2017-05-25 19:06:01 UTC; 3 days ago
 Main PID: 9347 (start_sovrin_no)
    Tasks: 3
   Memory: 113.4M
      CPU: 20h 8min 29.041s
   CGroup: /system.slice/sovrin-node.service
           +-9347 /usr/bin/python3 /usr/local/bin/start_sovrin_node Node2 9703 9704

May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:     self.updateState(txnsWithSeqNo(start, end, [txn]))
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/domain_req_handler.py"", line 66, in updateState
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:     self._updateStateWithSingleTxn(txn, isCommitted=isCommitted)
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 56, in _updateStateWithS
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:     self._addAttr(txn)
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 339, in _addAttr
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:     attr_key, value = parse(txn)
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 328, in parse
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]:     key, _ = data.popitem()
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: KeyError: 'popitem(): dictionary is empty'
;;;","23/Jun/17 9:04 PM;alexander.shekhovcov;The build 0.3.103 does not have input validation. The nowadays builds have the rule:
{code:java}
if len(raw) != 1:
    self._raise_invalid_fields(RAW, raw,
                               'should contain one attribute')
{code}
which is checked by `testSendAttribFailsIfRawContainsNoAttrs`.

Sending an empty `raw=\{}` field should return an error. Let's check it if it still does not work let me know.

 ;;;","26/Jun/17 6:38 PM;VladimirWork;Bug is not reproducing on the latest master. !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement testMonitorReconnects,INDY-98,17224,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,andrey.goncharov,spivachuk,spivachuk,30/May/17 12:49 AM,10/Oct/19 12:53 AM,28/Oct/23 2:46 AM,10/Oct/19 12:53 AM,,,,,0,10Months,Could,,,,Implement testMonitorReconnects in plenum repository.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx11z:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,SeanBohan_Sovrin,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Aug/17 6:20 AM;krw910;[~andrey.goncharov] Timebox this to 15 minutes. Either write the test or delete it.;;;","13/Dec/17 3:09 AM;SeanBohan_Sovrin;[~andrey.goncharov] - is there an update to this?;;;","07/Apr/18 3:52 AM;SeanBohan_Sovrin;[~spivachuk] - is this ticket still relevant?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testStopScriptIfNodeIsRunning fails,INDY-99,17225,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,30/May/17 1:51 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,disabled-tests,shakedown2,,,,testStopScriptIfNodeIsRunning in plenum repository fails.,,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy193:",,,,,,H1,,,,,,,,,,,,,,,,,,,,andkononykhin,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 9:56 PM;andkononykhin;Test was added: [https://github.com/evernym/plenum/commit/d68c7ee21a4ac339c84a8d61169719788919f9a5]

Seems it didn't work from the beginning cause code for expected exception wasn't enabled ([https://github.com/evernym/plenum/commit/d68c7ee21a4ac339c84a8d61169719788919f9a5#diff-f736d5294c674ac0820ea80f613523d5R258)]

Test was disabled: [https://github.com/evernym/plenum/commit/863020c7d14bf123297b0b7a2a269ba096d1d1a8]

For now we have already have test which treat case of changing HA for running node as valid: [https://github.com/evernym/plenum/blob/master/plenum/test/script/test_change_primary_node_ha.py#L17]

Thus, testStopScriptIfNodeIsRunning seems as obsolete and incorrect and should be removed.;;;","19/Jun/17 8:16 PM;andkononykhin;Hello, [~krw910]

I removed skipped test cause it had become obsolete  (explained in previous comment).

Seems, there is nothing to test here.

Thank you;;;","20/Jun/17 10:27 PM;krw910;Andrey's comment is that this test is now obsolete because the functionality is covered in another test.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Send NYM command is not executed on Shakedown Pool 1,INDY-100,17226,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,30/May/17 1:55 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Build Info:
0.3.103

Steps to Reproduce:
1. Connect test environment.
2. Execute ""send NYM"" with some destination parameter.

Actual Results:
There is no error/success message. NYM is not added.

Expected Results:
There should be error/success message. NYM should be added.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/May/17 1:55 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/10877/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1d3:",,,,,,H1,,,,,,,,,,,,,,,,,,,,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/May/17 1:56 AM;VladimirWork;FYI [~kelly.wilson], [~stevetolman], [~tylerq], [~ashcherbakov];;;","14/Jun/17 12:29 AM;stevetolman;Please retest with the current build.;;;","14/Jun/17 9:43 PM;VladimirWork;Shakedown Pool 1 is not available to test. Issue is not reproduced on other pools if content of /pool_transactions_sandbox/1 is correct, so bad data in this file could be the root cause of this issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement test_view_change_happens_post_timeout,INDY-101,17227,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,30/May/17 2:05 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,disabled-tests,Must,shakedown2,,,Implement test_view_change_happens_post_timeout in plenum repository.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy16v:",,,,,,H2,,,,,,,,,,,,,,,,,,,,lovesh,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/17 6:39 PM;lovesh;This has been committed in branch `simple-election` and is passing.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement test_view_change_not_gamable,INDY-102,17228,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,spivachuk,spivachuk,30/May/17 2:08 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,disabled-tests,Must,shakedown2,,,Implement test_view_change_not_gamable in plenum repository.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy18f:",,,,,,H2,,,,,,,,,,,,,,,,,,,,lovesh,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/17 6:41 PM;lovesh;This test is not applicable, since now we start view change as soon as a quorum of `INSTANCE_CHANGE` messages are received;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Design: A node should start catchup process if its ledger gets out of sync,INDY-103,17229,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,andrey.goncharov,andrey.goncharov,30/May/17 2:50 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"A node's ledger might get out of sync for different reasons (say, write to db failed), thus it will be lagging behind and will not be able to process newer PRE-PREPAREs, PREPAREs and COMMITs.  

This needs to be fixed, we have CHECKPOINT in the code which is sent periodically, as of now it only helps in garbage collection. It should be used as opportunity to start a catch up process node come to a start where it can start processing new requests again.

Alternatively we can find specific places in the code where we discard messages, check for discard reason and start catch up if the reason is unsynced ledger.

 

WARNING: If we bind to discards the protocol might get way too chatty. Discussion with Daniel and Jason is required!",,,,,,,,,,,,,,,,,INDY-335,,,,,,INDY-12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy22v:",,,,,,H3,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,danielhardman,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 11:29 PM;andrey.goncharov;Also I have a concern about current catch up design. As of now we stash incoming transactions if we're catching up and process them after the catch up is completed. But what if we have some internet connection problems? Then we still have an unsynced ledger after applying the transactions. This scenario looks to me way to complicated anyway. We store node's state for some time in separate places and just try to merge those states at some point. Can't we stop processing any transactions at all if we're catching up (do not even stash them), complete the catch up and send ledger status to all nodes when we think  the catch up is completed? This way if there were additional transactions while we were catching up we will trigger a new catch up. After a set of recursive catch ups we will have a valid up-to-date ledger. This way the state of our ledger depends on one component of the system only and it gets easier to maintain.

[~jlaw 1] [~danielhardman] [~lovesh] [~alexander.shekhovcov] what do you think?;;;","01/Jun/17 12:21 PM;danielhardman;I agree with Andrey's reasoning. +1 from me.;;;","03/Jun/17 12:08 AM;ashcherbakov;[~danielhardman] [~andrey.goncharov] [~lovesh] 
I totally agree that we should not stash too much. It's a good optimization, but unnecessary got MGL. I prefer to be more predictable and stable, although slower.
I think it's better to discard some of the messages (client requests for example) during some of the process (view change, catch-up), then to have very complicated and tangled logic which lead to instability. That's a type of trade-off we use to solve INDY-13.

However, in this particular example I feel like we have to stash incoming 3PC messages during catchup (especially during high-load). Otherwise a pool will be behind again after catch-up is finished. because other nodes may process and commit lots of new txns in the meantime.
I agree that there is a chance that catch-up may not help if not all 3PC messages are received/stashed. Actually I think it's rather a rare case.
Recursive catch-up may also not help. There is always a chance that it can be an infinite loop.

So, I see two options here:
- Send a LedgerStatus again after a catch-up is done, to check that we're up to date (after applying stashed 3PC messages received during catch-up).
But don't send it infinitely, have a limited number of re-tries (configurable).
- Send LedgerStatus according to some timeouts (configurable), or after Checkpoint is received.

As for INDY-13: we're going to implement a kind of recursive catch-up there, but during a view change, that is during 'pause the world', so it should not be infinite.

;;;","03/Jun/17 10:27 PM;lovesh;In a practical setting, not stashing will make the node repeatedly catchup, ""Catchup untill the lagging node is at same state as others"" is true only when the *time to catchup _n_ txns < time to 3PC _n_ txns*, which is going to be false usually. Regarding sending LedgerStatus again after catchup, the catchup process communicates the last 3PC state so if you are stashing 3PC messages, you know what to remove and what to process (this is what we do as of now). As to starting catchup whenever a node is behind, a simple (maybe naive) approach is to set a timer when the node realises 
*It has a prepared certificate for a seq no. but not for the previous one(s)* 
once this timer expires and the condition is still true and then it initiates a ""catchup"". This catchup does have to be as expensive as our current process which nodes do on startup but can be simply requesting txns from another node and checking the merkle root after applying them (to a temporary tree as we do now in catchup) and comparing the merkle root in the prepared certificate above.;;;","04/Jul/17 10:37 PM;andrey.goncharov;Design added: 
https://docs.google.com/document/d/1OCUsD46HLhqhqZBJmn5wLZ2gTS1mcu6CQszoAh1gUA0;;;","04/Jul/17 11:18 PM;andrey.goncharov;Assigned to Daniel for review. Lovesh I would also appreciate if you take a look.;;;","05/Jul/17 3:12 PM;lovesh;[~andrey.goncharov] We already have a specific message called CHECKPOINT that is sent every `CHK_FREQ` batches, communicating state. Let a node use that to determine if its behind. Now, solving the problem where system does not have writes for some time or write frequency is low so CHECKPOINTs take very long: every node has a timer that expires in `t` seconds, if it does not hear about a checkpoint in `t` seconds, it requests LEDGER_STATUS (not send, only node feeling the need to know sends it) from other nodes and decides if it need to catchup. I don't see any more scenario that needs to be taken care of. It requires minimal changes. The current value of `CHK_FREQ` is set to 10000, you can reduce it to 100. If this sounds passive, then node simply uses 3PC messages to determine if it is behind, eg. If you see COMMITs for seq no 100 but your seq no is 80, you know you have missed messages and the network is moved ahead. 
Another optimisation i suggest here is that the ""catchup"" (with consistency proofs, etc) should not be done if the number of missing transactions is small say less than 20. Use the `MessageReq` instead to request 3PC messages. In-fact, you don't request all 3PC messages, just request PRE-PREPARE+PREPARE for each batch from each node, if you have some later confirmed PRE-PREPARE. ;;;","05/Jul/17 10:11 PM;andrey.goncharov;[~lovesh] thank you! Added checkpoint option to the doc and updated my final recomendation.
https://docs.google.com/document/d/1OCUsD46HLhqhqZBJmn5wLZ2gTS1mcu6CQszoAh1gUA0;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ChunkedFileStorage for transactions in Ledger should be improved,INDY-104,17236,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,andrey.goncharov,andrey.goncharov,30/May/17 9:53 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"# We should have a file extension on each file.
 # We should zero pad the files so the ordering is easier to deal with 000001, 000002, 000003 and so on.
 # Having all the files in one directory can also be an issue. We need to think about how this will look in 20 years of running. We should break up the files into sub-directories. Determining how many files to have in a given directory will also help determine how many digits to use in zero padding the files.",,,,,,,,,,,,,,,,,,,,,,,INDY-16,,,,INDY-427,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1yv:",,,,,,H2,H3,H4,H5,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,DouglasWightman,lovesh,tharmon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 1:58 AM;tharmon;Relevant comment from INDY-16:

{quote}
[~lovesh], I understand {{ls -1v *.log}} ""fixes"" this on Linux. However, in my opinion that's not a good enough reason to allow log files to interleave on a standard {{ls}} when zero padding fixes it on all operating systems. 
Also, when I put my sysadmin's hat on, interleaved log files is just plain sloppy.

Plus, as mentioned before, zero padding will force us to actually consider how many transactions and files this system will have to realistically support. This will then allow us to make sure we have a plan to appropriately store the number of files and transactions across multiple operating systems and file system types.

Regarding the chunk size of 1000, several of us (including [~danielhardman] and [~krw910]) were discussing this the other day. The small size makes sense if we are doing a sequential read of the files from a speed perspective. However, we could greatly speed the system up if we did the following:

 * Each transaction file was accompanied by a lookup file.
 * Each lookup file would contain:
 ** The hash of the associated transaction file
 ** Fixed length records that recorded the byte offset for each record in the transaction file.

 This would allow the following lookup process:

# Open the appropriate lookup file.
# Seek to the appropriate record in the lookup file.
# Read the byte offset for the record in the transaction file.
# Close the lookup file.
# Open the transaction file.
# Seek to the appropriate record in the transaction file.
# Read the transaction record.
# Close the transaction file.

In cases where we wanted to do the sequential reads, we still could. We'd also have a known hash for each transaction file that could be quickly checked. It would also allow us to have far more than just 1000 records in the transaction file, which has a number of other benefits.
{quote};;;","27/Jun/17 8:25 PM;lovesh;[~DouglasWightman] Where is the POA for this?
;;;","27/Jun/17 8:26 PM;andrey.goncharov;[~lovesh] it was never created;;;","28/Jun/17 6:47 AM;DouglasWightman;[~lovesh] Daniel and I discussed the directions from Trev and he didn't feel a POA was needed.  If you'd like me to create one I will.;;;","28/Jun/17 9:46 PM;lovesh;[~DouglasWightman] Wanted to know if you are just implementing what is mentioned in the description or from comments too, like the lookup file. If it's only what is in the description then i am fine else i would like to know what and how the other things are done.;;;","28/Jun/17 10:36 PM;DouglasWightman;[~lovesh] at this point it is only what is in the description and not the comments (no lookup file).;;;","19/Jul/17 5:21 AM;danielhardman;If [~ashcherbakov] completes the ledger serialization refactor, then these changes will be obsolete, and we can close the ticket directly. If not, then we need to accept the PR for this work, and move it into the final build for this release.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Complete implementation of test_link_has_requested_proofs,INDY-105,17267,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,spivachuk,spivachuk,31/May/17 2:10 AM,11/Oct/19 6:40 PM,28/Oct/23 2:46 AM,11/Oct/19 6:40 PM,,,,,0,10Months,Could,disabled-tests,,,Complete implementation of test_link_has_requested_proofs in sovrin-client repository.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1en:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,SeanBohan_Sovrin,spivachuk,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 5:56 AM;stevetolman;Please explain why this is important. What are we missing by not having this test? How risky is it not to have? These answers will help us better prioritize the ticket.;;;","17/Jul/17 6:48 PM;spivachuk;[~stevetolman], {{test_link_has_requested_proofs}} must check the functionality concerning {{proofRequests}} field of {{sovrin_client.client.wallet.link.Link}} class. This field is absent in the current implementation. However, the functionality of creation and sending proofs in reply to proof requests has been implemented and there is a test checking it ({{testAliceSendClaimProofToAcme}}) which passes now on master branch.

So it is not critical not to have {{test_link_has_requested_proofs}} completed for Minimal Go-Live.;;;","13/Dec/17 3:08 AM;SeanBohan_Sovrin;[~spivachuk] - is this still valid? needed? finished?;;;","14/Dec/17 1:28 AM;spivachuk;[~SeanBohan_Sovrin], this task is still actual. The test is incomplete now.

But please note that the class {{sovrin_client.client.wallet.link.Link}} was renamed. Now its name is {{indy_client.client.wallet.connection.Connection}}.;;;","07/Apr/18 3:51 AM;SeanBohan_Sovrin;[~spivachuk] - is this ticket still valid?;;;","11/Oct/19 6:40 PM;ashcherbakov;We don't have this functionality anymore;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[send NYM] Key with Trustee role cannot update role of other key,INDY-106,17268,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,VladimirWork,VladimirWork,31/May/17 2:34 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
0.3.113 (Shakedown Pool 3)

Preconditions:
Start CLI and connect test environment.

Steps to Reproduce:
1. new key with seed 000000000000000000000TestSteward.
2. new key with seed 000000000000000000000000Trustee1.
3. send NYM dest=3QhWYKTpEaBVhkysHhfa1F4mTUfoK9oX5VZTVUM6Vk5a role=STEWARD.

Actual Results:
Error: client request invalid: UnauthorizedClientRequest('TRUSTEE cannot update role',).

Expected Results:
Nym ... added.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 2:34 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/10879/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1fr:",,,,,,H1,,,,,,,,,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 2:35 AM;VladimirWork;FYI [~kelly.wilson], [~stevetolman], [~tylerq], [~ashcherbakov];;;","14/Jun/17 2:25 AM;krw910;[~VladimirWork] the correct process to change roles is to first remove the current role using (role= ) then setting the new role like (role=STEWARD);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Complete implementation of testBobReqAvailClaimsFromAgents,INDY-107,17270,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,31/May/17 2:41 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Could,disabled-tests,,,,Complete implementation of testBobReqAvailClaimsFromAgents in sovrin-client repository.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/17 1:00 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11775/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8an:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,ashcherbakov,devin-fisher,spivachuk,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 3:14 AM;devin-fisher;[~spivachuk]  slacked me about this test and said that he was going to reenable the test.;;;","01/Jun/17 3:30 AM;spivachuk;[~devin-fisher], As I later got from the TODO comment, the test has some issues which should be resolved. So I disabled it and created this ticket. Assigned this ticket back to you.;;;","14/Jun/17 5:56 AM;stevetolman;Please explain why this is important. What are we missing by not having this test? How risky is it not to have? These answers will help us better prioritize the ticket.;;;","17/Jul/17 9:57 PM;spivachuk;[~stevetolman], I reviewed this test in more details and found that the test is actually complete, uses nonces for Bob that are different from nonces being used for Alice and passes on master branch now. So this test must be enabled.;;;","17/Jul/17 9:59 PM;spivachuk;Changes:
- Enabled testBobReqAvailClaimsFromAgents and removed TODO comment from it since the test is complete and passes.

Committed into:
- Commit hash: f86979e6e9944617a0b03866aef2f4fb7964971d
- Version: indy-node-dev 0.4.38

Risk factors:
- Nothing is expected.

Risk:
- Low;;;","26/Jul/17 10:06 PM;VladimirWork;[~spivachuk] [~ashcherbakov] I can't find testBobReqAvailClaimsFromAgents or something like that in /indy-node/sovrin_client/test/ so where can I find it? Should I just run this test with pytest in venv or is there another case to check this task?;;;","26/Jul/17 10:09 PM;ashcherbakov;[~VladimirWork] It's there: https://github.com/hyperledger/indy-node/blob/7a33f1e565e6610a90f3fc107ee23df8ae6501fa/sovrin_client/test/cli/test_tutorial.py#L1003
I think it's sufficient just to make sure that the test is
* not skipped 
* doesn't have TODO mentioned in the ticket
* passes on CI
* has valid implementation (from your point of view).;;;","27/Jul/17 1:00 AM;VladimirWork;* not skipped [+]
* doesn't have TODO mentioned in the ticket [+]
* passes on CI [+]
* has valid implementation (from your point of view) [+] !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prove the pool upgrade mechanism by performing a noticeable upgrade test,INDY-108,17285,17097,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,tylerq,krw910,krw910,31/May/17 11:07 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"This ticket is a placeholder task to prove the upgrade mechanism by performing an upgrade that has a noticeable difference. It can be done by laying down an additional file or making some other change that is driven by the new script migration process.

Give a demo of this when complete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxmn:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 6:45 PM;andrey.goncharov;Short demo (in two parts)

[https://drive.google.com/file/d/0BxskuV-A2baheTNLQTRhNWhtLTg/view?usp=sharing]

https://drive.google.com/file/d/0BxskuV-A2bahNjZaVHpEQ1ZBWGs/view?usp=sharing;;;","01/Jun/17 2:37 AM;krw910;[~andrey.goncharov] has provided a great demo showing how our new migration script mechanism works for the upgrade process.;;;","01/Jun/17 4:49 AM;krw910;I am taking this back until we have seen it work in a build.;;;","01/Jun/17 1:34 PM;danielhardman;[~andrey.goncharov], I wanted to offer some clarification about Kelly's desire to ""see it work in a build.""

We need to know that the whole process is working with .deb files from a repo, where the pool upgrade has a real install to run. It wasn't clear in your demo whether any new .deb file got laid down, or if the .deb portion of the work got short-circuited. If the pool_upgrade process you demoed did actually include a .deb distribution and install, then that part of the request is satisfied.

The other success criterion here is that the migration mechanism is the one that ends up getting committed to master as a result of INDY-29. Given when you recorded the demo, and when you and I had some exchanges about your PR, I'm not sure that's the case. Is it?;;;","01/Jun/17 2:03 PM;danielhardman;The reason why we are being so careful about this is that having a robust upgrade is the absolute top priority for a build on which we can base the installation of validator nodes for Alpha. If the software is flaky, but we can upgrade it, all is well. But if the upgrade doesn't work like a charm, we are in serious trouble because we will have to do manual upgrades. Thus, we must be totally confident of this one feature. Please indicate your level of confidence, [~andrey.goncharov], that the first build after the one with fixes from INDY-29 will upgrade flawlessly–we will use that plus the above criteria to decide if we are truly done.;;;","01/Jun/17 5:59 PM;andrey.goncharov;[~danielhardman] I took a shortcut and did a demo without DEBs. I'll provide a DEB based demo shortly.;;;","02/Jun/17 3:21 AM;krw910;I have validated this through the master upgrade from 0.3.123 to 0.3.124 where Andrey included a dummy file. In the next build of master he will remove that file.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testNodesConnectsWhenOneNodeIsLate in plenum fails intermittently,INDY-109,17290,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andkononykhin,andrey.goncharov,andrey.goncharov,31/May/17 6:52 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,shakedown2,,,,,testNodesConnectsWhenOneNodeIsLate in test_node_connection.py in plenum fails intermittently,,,,,,,,,,,,,,,,,,,,,,INDY-75,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxrj:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
VERKEY validator,INDY-110,17291,17165,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,31/May/17 6:57 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,,,,32400,32400,,0%,32400,32400,,,INDY-330,INDY-175,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxrz:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,alexander.shekhovcov,dsurnin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/17 5:13 PM;dsurnin;plenum build 0.3.126-master;;;","08/Jun/17 2:08 AM;VladimirWork;Need to clarify what unit tests are associated with this ticket.;;;","23/Jun/17 4:44 PM;dsurnin;https://github.com/evernym/plenum/commit/ce1e64fb78c00d6ba989f962f2ee6319bfb0a70e

Added VERKEY field validator

tests

[https://github.com/evernym/plenum/blob/master/plenum/test/input_validation/fields_validation/test_base58_field.py]

https://github.com/evernym/plenum/blob/master/plenum/test/input_validation/fields_validation/test_verkey_field.py;;;","28/Jun/17 1:43 AM;VladimirWork;INDY-330 is reported due to testing and is not fixed now.;;;","03/Jul/17 7:04 PM;VladimirWork;Character-based/length-based constraints for adding/updating verkeys/abbreviated verkeys are checked.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Apply TARGET_NYM (dest) validator for sovrin-node,INDY-111,17292,17165,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:04 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,Apply the new validation rules for sovrin-node (*sovrin_common/types.py*),,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxs7:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,alexander.shekhovcov,dsurnin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/17 8:47 PM;dsurnin;Validation was already been done in

plenum commit ea1c39118b3720bb6efb0dc9467554776577bf96

 

tests

plenum/plenum/test/input_validation/fields_validation/test_identifier_field.py;;;","27/Jun/17 10:06 PM;ozheregelya;*Build Info:*
sovrin-client version: 0.3.150
sovrin-node version: 0.3.163

OS/Platform: Ubuntu 16.04.2 LTS
h2. Reason for Reopen:
Following cases work incorrectly:

*Case 1:*
No validation for dest (same messages for invalid and not existing dest).
Steps to Reproduce:
1. send ATTRIB dest=E6kJUGoYKYTHJ raw=\{""role"": ""TRUST_ANCHOR""}
2. send ATTRIB dest=E6kJUGoYKYTHJ1279986l raw=\{""role"": ""TRUST_ANCHOR""}

*Actual Results:*
For dest with invalid length and invalid characters:
Error: client request invalid: InvalidClientRequest('dest should be added before adding attribute for it',)

*Expected Results:*
Error message should contain information that dest is incorrect (similar as for send NYM command).

*Case 2:*
No validation for dest (same messages for invalid and not existing dest).
Steps to Reproduce:
1. send GET_NYM dest=E6kJUGoYKYTHJ
2. send GET_NYM dest=E6kJUGoYKYTHJ1279986l

*Actual Results:*
For dest with invalid length and invalid characters:
NYM E6kJUGoYKYTHJ not found

*Expected Results:*
Error message should contain information that dest is incorrect (similar as for send NYM command).

*Case 3:*
*Steps to Reproduce:*
1. send NYM dest=E6kJUGoYKYTHJ1279986l

*Actual Results:*
For dest with invalid characters:
Error: client request invalid: InvalidClientRequest(""validation error: should not contains the following chars ['0'] (dest=E6kJUGoYKYTHJ127998600)"",)

*Expected Results:*
""should not contains"" should be changed to ""should not contain"".
h2. The rest cases were verified and work correctly:

*Case 1:*
*Steps to Reproduce:*
1. send ATTRIB dest=E6kJUGoYKYTHJ12799864 raw=\{""role"": ""TRUST_ANCHOR""}

*Actual Results:*
For valid dest all works without any errors.

*Case 2:*
*Steps to Reproduce:***
1. send GET_NYM dest=E6kJUGoYKYTHJ12799864

*Actual Results:*
For valid dest all works without any errors.

*Case 3:*
*Steps to Reproduce:*
1. send NYM dest=E6kJUGoYKYTHJ
2. send NYM dest=E6kJUGoYKYTHJ12799864

*Actual Results:*
For dest with invalid length:
Error: client request invalid: InvalidClientRequest('validation error: b58 decoded value length 10 should be one of [16, 32] (dest=E6kJUGoYKYTHJ)',)
For valid dest all works without any errors.;;;","30/Jun/17 9:44 PM;dsurnin;waiting a jenkins to make a build;;;","07/Jul/17 1:27 AM;dsurnin;all cases are fixed

plenum a6ca136e50ee46072f539b36cd70920adb23bcb9

client 23f410c5548483ae736f31d49c746872bfc11ca2

 

no additional tests were added, existing tests were updated;;;","08/Jul/17 1:20 AM;ozheregelya;Build Info:
  sovrin-client version: 0.4.24
  sovrin-node version: 0.4.11
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client

*Case 1:*
No validation for dest (same messages for invalid and not existing dest).
Steps to Reproduce:
1. send ATTRIB dest=E6kJUGoYKYTHJ raw=\{""role"": ""TRUST_ANCHOR""}
2. send ATTRIB dest=E6kJUGoYKYTHJ1279986l raw=\{""role"": ""TRUST_ANCHOR""}

*Actual Results:*
For dest with invalid length:
Error: client request invalid: InvalidClientRequest('validation error [ClientAttribOperation]: b58 decoded value length 10 should be one of [16, 32] (dest=E6kJUGoYKYTHJ)',)
For dest with invalid characters:
Error: client request invalid: InvalidClientRequest(""validation error [ClientAttribOperation]: should not contain the following chars ['l'] (dest=E6kJUGoYKYTHJ1279986l)"",)

*Case 2:*
No validation for dest (same messages for invalid and not existing dest).
Steps to Reproduce:
1. send GET_NYM dest=E6kJUGoYKYTHJ
2. send GET_NYM dest=E6kJUGoYKYTHJ1279986l

*Actual Results:*
Error: client request invalid: InvalidClientRequest('validation error [ClientAttribOperation]: b58 decoded value length 10 should be one of [16, 32] (dest=E6kJUGoYKYTHJ)',)
For dest with invalid characters:
Error: client request invalid: InvalidClientRequest(""validation error [ClientAttribOperation]: should not contain the following chars ['l'] (dest=E6kJUGoYKYTHJ1279986l)"",)

*Case 3:*
*Steps to Reproduce:*
1. send NYM dest=E6kJUGoYKYTHJ1279986l

*Actual Results:*
For dest with invalid characters:
send NYM dest=E6kJUGoYKYTHJ1279986l
h2. The rest cases are still working correctly:

*Case 1:*
*Steps to Reproduce:*
1. send ATTRIB dest=E6kJUGoYKYTHJ12799864 raw=\{""role"": ""TRUST_ANCHOR""}

*Actual Results:*
For valid dest all works without any errors.

*Case 2:*
*Steps to Reproduce:***
1. send GET_NYM dest=E6kJUGoYKYTHJ12799864

*Actual Results:*
For valid dest all works without any errors.

*Case 3:*
*Steps to Reproduce:*
1. send NYM dest=E6kJUGoYKYTHJ
2. send NYM dest=E6kJUGoYKYTHJ12799864

*Actual Results:*
For dest with invalid length:
Error: client request invalid: InvalidClientRequest('validation error: b58 decoded value length 10 should be one of [16, 32] (dest=E6kJUGoYKYTHJ)',)
For valid dest all works without any errors.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NONCE validator,INDY-112,17293,17165,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:05 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,See sovrin_common/type.py,,,32400,540,,0%,32400,540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxtz:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,alexander.shekhovcov,dsurnin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/17 9:56 PM;dsurnin;The NONCE field is used in Client Disclose txn only, which is not implemented now;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
VERSION validator,INDY-113,17294,17165,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:06 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,See sovrin_common/type.py,,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxsf:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,alexander.shekhovcov,dsurnin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 6:19 PM;dsurnin;Fix was made

waiting for Jenkins is available;;;","07/Jul/17 12:37 AM;dsurnin;merged

plenum 7a4abbf64955cf08a5d74c945d32ac763f47a9dc

common 8d12f5bd4ea420fb194edb19688876fb8c567cec

 

tests

plenum/test/input_validation/fields_validation/test_version_field.py

sovrin_common/test/types/*.py;;;","13/Jul/17 12:06 AM;VladimirWork;Version parameter validation is checked on sovrin-client 0.4.26 and sovrin-node 0.4.18 (due to 0.4.19 issues). Fields validation tests are passed. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ORIGIN validator,INDY-114,17295,18695,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dsurnin,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:06 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,See sovrin_common/types.py,,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxsn:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/17 5:28 PM;ashcherbakov;This is now `LimitedLengthStringField`, but it needs to be a valid DID one.;;;","13/Dec/17 5:38 PM;ashcherbakov;PR: https://github.com/hyperledger/indy-node/pull/489;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
REF validator,INDY-115,17296,17165,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:07 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"See sovrin_common/types.py

REF is reference to a transaction by sequence number so a validation for transaction sequence number needs to be added in plenum and used for REF",,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxsv:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,alexander.shekhovcov,lovesh,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jun/17 8:51 PM;lovesh;Here is the change https://github.com/evernym/plenum/commit/72d802fe633a33213ac9fa5f8356cef5d862ae56.;;;","28/Jun/17 11:13 PM;lovesh;[~krw910] It's not build yet since Jenkins is down;;;","04/Jul/17 9:48 PM;VladimirWork;REF constraints are checked: numeric only, first zeros are handled correctly (""0001"" is the same as ""1""). There is no maximum length for this parameter, but very large numbers (>100 characters) are handled correctly - it works as designed (discussed with Alexander S).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SIGNATURE_TYPE validator,INDY-116,17297,18695,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dsurnin,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:08 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,See sovrin_common/types.py,,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxt3:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/17 5:26 PM;ashcherbakov;Already implemented;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ACTION validator,INDY-117,17298,18695,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dsurnin,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:09 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,See sovrin_common/types.py,,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxtb:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/17 5:29 PM;ashcherbakov;This one is implemented;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
VERSION validator,INDY-118,17299,18695,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dsurnin,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:09 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,See sovrin_common/types.py,,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxtj:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/17 5:25 PM;ashcherbakov;This one is already implemented;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SHA256 validator,INDY-119,17300,17165,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:10 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,See sovrin_common/types.py,,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,INDY-372,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxtr:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,alexander.shekhovcov,lovesh,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jun/17 9:18 PM;lovesh;https://github.com/evernym/plenum/commit/f47cd40f588fa6384800a41fca278a5e69c3c6f4;;;","28/Jun/17 11:13 PM;lovesh;[~krw910] It's not built yet since Jenkins is down;;;","30/Jun/17 10:03 PM;VladimirWork;I haven't found any information about this parameter in Sovrin Transaction Types doc and CLI help. Could you clarify some points that will let me start testing, please:

- which transactions use this parameter
- are there any known use cases (common and probably specific) with this parameter

Thank you.;;;","03/Jul/17 9:26 PM;VladimirWork;SHA256 constraints are checked: 64 characters, 0..9 + a..f only.
Help message should be changed, INDY-372 was reported.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TIMEOUT validator,INDY-120,17301,18695,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dsurnin,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:10 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,See sovrin_common/types.py,,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxu7:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/17 5:29 PM;ashcherbakov;Already implemented;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JUSTIFICATION validator,INDY-121,17302,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,alexander.shekhovcov,alexander.shekhovcov,alexander.shekhovcov,31/May/17 7:11 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,7Months,blocked,WillNotFix,,,See sovrin_common/types.py,,,3600,3600,,0%,3600,3600,,,INDY-381,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy13b:",,,,,,H4,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,andrey.goncharov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 11:38 PM;andrey.goncharov;Two PRs created (awaiting Jenkins):

[https://github.com/sovrin-foundation/sovrin-common/pull/110]

https://github.com/sovrin-foundation/sovrin-client/pull/240;;;","03/Jul/17 11:15 PM;andrey.goncharov;Build:

master/sovrin-client 0.4.19

Commited into:

[https://github.com/hyperledger/indy-client/commit/c7ee84a71dac4d1fa9fb07004a78b68f59491e7b]

Added:
 * validation for JUSTIFICATION field
 ** it's optional
 ** if it's provided it can not be empty and it can not be longer than 1000 symbols;;;","14/Jul/17 5:38 AM;krw910;I am unable to get the justification parameter to work in the pool upgrade schedule. Please provide an example transaction. I have tried the parameter before the schedule parameter and it does not take. I can input the parameter after timeout=, but when sent the CLI throws an error that it is invalid.

indy-plenum=0.4.43
indy-anoncreds= 0.4.12
indy-node= 0.4.26
;;;","15/Jul/17 12:27 AM;alexander.shekhovcov;[~krw910] Could you provide your non-working request?
In the tests looks like the following works
{code}
send POOL_UPGRADE name=upgrade-13 version=0.5 sha256=db34a72a90d026dae49c3b3f0436c8d3963476c77468ad955845a1ccf7b03f55 action=start justification=""some text"" schedule={'AtDfpKFe1RPgcr5nnYBw1Wxkgyn8Zjyh5MzFoEUTeoV3': '2017-07-14T15:26:24.138269+00:00', 'DG5M4zFm33Shrhjj6JB7nmx9BoNJUq219UXDfvwBDPe2': '2017-07-14T15:26:33.138269+00:00', 'JpYerf4CssDrH76z7jyQPJLnZ1vwYgvKbvcp16AB5RQ': '2017-07-14T15:26:51.138269+00:00', '4yC546FFzorLPgTNTc6V43DnpFrR8uHvtunBxb2Suaa2': '2017-07-14T15:26:42.138269+00:00'} timeout=1
{code};;;","15/Jul/17 1:12 AM;alexander.shekhovcov;[~krw910] It turned out that `justification` is needed only for the UPGRADE CANCEL action. We should not use this field for START action.
Such command can looks like:
{code}
'send POOL_UPGRADE name=upgrade-13 version=0.5 sha256=db34a72a90d026dae49c3b3f0436c8d3963476c77468ad955845a1ccf7b03f55 action=cancel justification=""not gonna give you one""'
{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Input validation] Validation for view change messages,INDY-122,17303,17104,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mzk-vct,mzk-vct,31/May/17 7:15 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Implement validation for following messages:

 - Nomination
 - Primary
 - Reelection
 - InstanceChange",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxuf:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,mzk-vct,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jun/17 3:01 AM;mzk-vct;Pull request https://github.com/evernym/plenum/pull/186;;;","02/Jun/17 12:46 AM;mzk-vct;Pull request 186 was closed, changes will be be merged in https://github.com/evernym/plenum/pull/193 together with changes for 3pc messages;;;","02/Jun/17 3:50 AM;mzk-vct;Done, plenum build 0.3.126-master
;;;","08/Jun/17 2:04 AM;ozheregelya;Need to implement all necessary tests.;;;","16/Jun/17 10:04 PM;mzk-vct;Added tests for messages, please find them in plenum/test/input_validation/message_validation package
;;;","27/Jun/17 1:30 AM;ozheregelya;Following tests were added and passed without errors:
plenum/plenum/test/input_validation/message_validation/test_nomination_message.py
plenum/plenum/test/input_validation/message_validation/test_primary_message.py
plenum/plenum/test/input_validation/message_validation/test_reelection_message.py
plenum/plenum/test/input_validation/message_validation/test_instanceChange_message.py

 
{code:java}
(.venv) sovrin@sovrin-VirtualBox:~/git/plenum/plenum/test/input_validation$ pytest
============================================================================================ test session starts ============================================================================================
platform linux -- Python 3.5.2, pytest-3.1.2, py-1.4.34, pluggy-0.4.0
rootdir: /home/sovrin/git/plenum/plenum/test, inifile: pytest.ini
plugins: xdist-1.17.1
collected 104 items
test_client_node_op.py ......
test_client_nym_op.py ...
test_common_checks.py ssssss
test_handle_one_node_message.py ss
fields_validation/test_base58_field.py .....
fields_validation/test_bool_field.py ....
fields_validation/test_hex_field.py ....
fields_validation/test_identifier_field.py ..
fields_validation/test_iterable_field.py ..
fields_validation/test_ledger_id_field.py ..
fields_validation/test_merkle_tree_root_field.py ...
fields_validation/test_non_empty_string_field.py ..
fields_validation/test_non_negative_number_field.py ....
fields_validation/test_request_identifier_field.py ......
fields_validation/test_serializedvalue_field.py ....
fields_validation/test_time_among_field.py ...
fields_validation/test_timestamp_field.py ..
fields_validation/test_verkey_field.py ..
message_validation/test_batch_message.py ...
message_validation/test_checkpoint_meeting.py ...
message_validation/test_commit_message.py ...
message_validation/test_consistencyproof_message.py ...
message_validation/test_instanceChange_message.py ...
message_validation/test_ledgerstatus_message.py ...
message_validation/test_nomination_message.py ...
message_validation/test_ordered_message.py ...
message_validation/test_prepare_message.py ...
message_validation/test_preprepare_message.py ...
message_validation/test_primary_message.py ...
message_validation/test_propagate_message.py ...
message_validation/test_reelection_message.py ...
message_validation/test_threepcstate_message.py ...
=================================================================================== 96 passed, 8 skipped in 1.14 seconds ====================================================================================
{code}
 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Input validation] Validation for 3PC messages,INDY-123,17304,17104,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mzk-vct,mzk-vct,31/May/17 7:18 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Implement validation for following messages
 - Propagate
 - Prepare
 - Commit
 - Ordered",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxun:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,mzk-vct,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/17 2:41 AM;mzk-vct;Is going to be introduced with https://github.com/evernym/plenum/pull/193;;;","02/Jun/17 3:49 AM;mzk-vct;Done, plenum build 0.3.126-master;;;","08/Jun/17 2:05 AM;ozheregelya;Need to implement all necessary tests.;;;","16/Jun/17 10:04 PM;mzk-vct;Added tests for messages, please find them in plenum/test/input_validation/message_validation package
;;;","27/Jun/17 1:32 AM;ozheregelya;Following tests were added and passed without errors:

plenum/plenum/test/input_validation/message_validation/test_propagate_message.py
 plenum/plenum/test/input_validation/message_validation/test_prepare_message.py
 plenum/plenum/test/input_validation/message_validation/test_commit_message.py
 plenum/plenum/test/input_validation/message_validation/test_ordered_message.py
{code:java}
(.venv) sovrin@sovrin-VirtualBox:~/git/plenum/plenum/test/input_validation$ pytest
 ============================================================================================ test session starts ============================================================================================
 platform linux – Python 3.5.2, pytest-3.1.2, py-1.4.34, pluggy-0.4.0
 rootdir: /home/sovrin/git/plenum/plenum/test, inifile: pytest.ini
 plugins: xdist-1.17.1
 collected 104 items
 test_client_node_op.py ......
 test_client_nym_op.py ...
 test_common_checks.py ssssss
 test_handle_one_node_message.py ss
 fields_validation/test_base58_field.py .....
 fields_validation/test_bool_field.py ....
 fields_validation/test_hex_field.py ....
 fields_validation/test_identifier_field.py ..
 fields_validation/test_iterable_field.py ..
 fields_validation/test_ledger_id_field.py ..
 fields_validation/test_merkle_tree_root_field.py ...
 fields_validation/test_non_empty_string_field.py ..
 fields_validation/test_non_negative_number_field.py ....
 fields_validation/test_request_identifier_field.py ......
 fields_validation/test_serializedvalue_field.py ....
 fields_validation/test_time_among_field.py ...
 fields_validation/test_timestamp_field.py ..
 fields_validation/test_verkey_field.py ..
 message_validation/test_batch_message.py ...
 message_validation/test_checkpoint_meeting.py ...
 message_validation/test_commit_message.py ...
 message_validation/test_consistencyproof_message.py ...
 message_validation/test_instanceChange_message.py ...
 message_validation/test_ledgerstatus_message.py ...
 message_validation/test_nomination_message.py ...
 message_validation/test_ordered_message.py ...
 message_validation/test_prepare_message.py ...
 message_validation/test_preprepare_message.py ...
 message_validation/test_primary_message.py ...
 message_validation/test_propagate_message.py ...
 message_validation/test_reelection_message.py ...
 message_validation/test_threepcstate_message.py ...
 =================================================================================== 96 passed, 8 skipped in 1.14 seconds ===================================================================================={code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Input validation] Validation for catchup messages,INDY-124,17305,17104,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mzk-vct,mzk-vct,31/May/17 7:19 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Implement validation for following messages:
 - CatchupReq
 - CatchupRep
 - ConsProofRequest",,,,,,,,,,,,,,,,,,,,,,,INDY-72,,,,,,,,,,,,"11/Jul/17 10:09 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11636/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxuv:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,alexander.shekhovcov,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/17 1:22 AM;mzk-vct;It looks like all field validators required for these messages are implemented. 
To complete these story it is needed to check that all fields have correct types and that tests pass.;;;","06/Jul/17 7:44 PM;alexander.shekhovcov;(/)

*How to test:*

Check CATCHUP works.

The tests:

plenum/test/input_validation/message_validation/test_consistencyproof_message.py

plenum/test/input_validation/message_validation/test_catchuprep_message.py

plenum/test/input_validation/message_validation/test_catchupreq_message.py

 ;;;","11/Jul/17 10:09 PM;VladimirWork;Build Info:
sovrin-node: 0.4.18

Actual Results:
Node catchup works after transactions_sandbox file changing. Message validation tests are passed. !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Input validation] Validation for state messages,INDY-125,17307,17104,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mzk-vct,mzk-vct,31/May/17 7:20 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"Implement validation for following messages:
 - Checkpoint
 - ThreePCState
 - Batch",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxvb:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,mzk-vct,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/17 1:27 AM;mzk-vct;Validators for Checkpoint and ThreePCState are commented out, but seem to be implemented as well as required field validators.
To complete these story it is needed to implement verifier for Batch message,check that all fields for Checkpoint, ThreePCState have correct types and that tests pass.  

Please don't forget to write tests for new field validators if you implement any;;;","21/Jun/17 6:45 PM;mzk-vct;Implemented, pull request https://github.com/evernym/plenum/pull/223;;;","27/Jun/17 1:45 AM;ozheregelya;Following tests were added and passed without errors:

plenum/plenum/test/input_validation/message_validation/test_checkpoint_meeting.py
plenum/plenum/test/input_validation/message_validation/test_threepcstate_message.py
plenum/plenum/test/input_validation/message_validation/test_batch_message.py

 
{code:java}
(.venv) sovrin@sovrin-VirtualBox:~/git/plenum/plenum/test/input_validation$ pytest
============================================================================================ test session starts ============================================================================================
platform linux -- Python 3.5.2, pytest-3.1.2, py-1.4.34, pluggy-0.4.0
rootdir: /home/sovrin/git/plenum/plenum/test, inifile: pytest.ini
plugins: xdist-1.17.1
collected 104 items
test_client_node_op.py ......
test_client_nym_op.py ...
test_common_checks.py ssssss
test_handle_one_node_message.py ss
fields_validation/test_base58_field.py .....
fields_validation/test_bool_field.py ....
fields_validation/test_hex_field.py ....
fields_validation/test_identifier_field.py ..
fields_validation/test_iterable_field.py ..
fields_validation/test_ledger_id_field.py ..
fields_validation/test_merkle_tree_root_field.py ...
fields_validation/test_non_empty_string_field.py ..
fields_validation/test_non_negative_number_field.py ....
fields_validation/test_request_identifier_field.py ......
fields_validation/test_serializedvalue_field.py ....
fields_validation/test_time_among_field.py ...
fields_validation/test_timestamp_field.py ..
fields_validation/test_verkey_field.py ..
message_validation/test_batch_message.py ...
message_validation/test_checkpoint_meeting.py ...
message_validation/test_commit_message.py ...
message_validation/test_consistencyproof_message.py ...
message_validation/test_instanceChange_message.py ...
message_validation/test_ledgerstatus_message.py ...
message_validation/test_nomination_message.py ...
message_validation/test_ordered_message.py ...
message_validation/test_prepare_message.py ...
message_validation/test_preprepare_message.py ...
message_validation/test_primary_message.py ...
message_validation/test_propagate_message.py ...
message_validation/test_reelection_message.py ...
message_validation/test_threepcstate_message.py ...
=================================================================================== 96 passed, 8 skipped in 1.14 seconds ====================================================================================
{code}
 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Input validation] Mechanism for adding custom validators and passing parameters ,INDY-126,17308,17104,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mzk-vct,mzk-vct,31/May/17 7:32 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"There is a need in overriding message of existing validators, adding of new ones and passing parameters
Now there is only TaggedTuples variable in types.py for storing validators.
It can be used for some of above purposes, but with it is not right and clean way.
Usage of it is associated with making checks and some tricky boilerplate code.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxvj:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,alexander.shekhovcov,mzk-vct,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 8:07 PM;mzk-vct;There are some developments for it in *sanitation_message_registry* branch in Plenum;;;","06/Jul/17 7:48 PM;alexander.shekhovcov;(/)

*How to test:*

The NYM sending works (the common pool tests)

The tests:

the new one

_plenum/test/input_validation/test_message_factory.py_

and whole bunch of tests

_plenum/test/input_validation/*_

 

 ;;;","08/Jul/17 1:45 AM;ozheregelya;Build Info:
  sovrin-client version: 0.4.24
  sovrin-node version: 0.4.11
OS/Platform: Ubuntu 16.04.2 LTS

Sending NYMs works correctly, specified tests are running without any problems.

 
{code:java}
============================================================================================ test session starts ============================================================================================
platform linux -- Python 3.5.2, pytest-3.1.3, py-1.4.34, pluggy-0.4.0
rootdir: /home/sovrin/plenum/plenum/plenum/test, inifile: pytest.ini
plugins: xdist-1.18.1
collected 142 items
test_client_get_txn_op.py ..
test_client_node_op.py ......
test_client_nym_op.py ...
test_common_checks.py ssssss
test_handle_one_node_message.py ss
test_message_factory.py ..........
fields_validation/test_base58_field.py .....
fields_validation/test_bool_field.py ....
fields_validation/test_hex_field.py ....
fields_validation/test_identifier_field.py ..
fields_validation/test_iterable_field.py ..
fields_validation/test_ledger_id_field.py ..
fields_validation/test_limited_length_string_field.py ....
fields_validation/test_merkle_tree_root_field.py ...
fields_validation/test_non_empty_string_field.py ..
fields_validation/test_non_negative_number_field.py ....
fields_validation/test_request_identifier_field.py ......
fields_validation/test_serializedvalue_field.py ....
fields_validation/test_sha256_hex_field.py ....
fields_validation/test_time_among_field.py ...
fields_validation/test_timestamp_field.py ..
fields_validation/test_txn_seq_no_field.py .
fields_validation/test_verkey_field.py ..
fields_validation/test_version_field.py ........
message_validation/test_batch_message.py ...
message_validation/test_catchuprep_message.py ...
message_validation/test_catchupreq_message.py ...
message_validation/test_checkpoint_message.py ...
message_validation/test_commit_message.py ...
message_validation/test_consistencyproof_message.py ...
message_validation/test_instanceChange_message.py ...
message_validation/test_ledgerstatus_message.py ...
message_validation/test_nomination_message.py ...
message_validation/test_ordered_message.py ...
message_validation/test_prepare_message.py ...
message_validation/test_preprepare_message.py ...
message_validation/test_primary_message.py ...
message_validation/test_propagate_message.py ...
message_validation/test_reelection_message.py ...
message_validation/test_threepcstate_message.py ...
message_validation/test_viewchangedone_messsage.py ...
=================================================================================== 134 passed, 8 skipped in 0.78 seconds ===================================================================================
{code}
 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] Keyring is changed after disconnect if there is a keyring in persisted wallets of no-env context,INDY-127,17310,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,ozheregelya,ozheregelya,31/May/17 10:55 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,7Months,Could,KellyRetest,,," 

*Case 1*
 Steps to Reproduce:
 1. Create new keyring named ""oz2"".
 => It becomes active and it is saved to _/home/agent/.sovrin/keyrings/no-env_. Note that this keyring is in Un-persisted wallets.
 2. Create new keyring named ""oz3"".
 => It becomes active and it is saved to _/home/agent/.sovrin/keyrings/no-env_. Note that this keyring is in Un-persisted wallets, and oz2 keyring moves to Persisted wallets.
 3. Connect to test.
 => oz3 is active and it is moved to _/home/agent/.sovrin/keyrings/test_
 3. Run command _new key with seed 000000000000000000000000Steward1_
 4. Run command _disconnect_

Actual Results:
 Active keyring is changed to oz2 after disconnect.
 \{code}
 sovrin@test> disconnect
 Disconnecting from test ...
 Active keyring ""oz3"" saved (/home/agent/.sovrin/keyrings/test/oz3.wallet)
 Disconnected from test

Saved keyring ""oz2"" restored (/home/agent/.sovrin/keyrings/no-env/oz2.wallet)
 Active keyring set to ""oz2""
 \{code}

Expected Results:
 Active keyring should not be changed.

Additional Information:
 Workaround: change keyring manually, or do not create keyring after creating another one.

Here is my console output in [^out.txt]","Client version: 0.3.113

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/17 10:56 PM;ozheregelya;out.txt;https://jira.hyperledger.org/secure/attachment/10887/out.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy0wf:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:57 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement 'hash' and 'enc' fields support for ATTRIB txn in client,INDY-128,17312,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,mzk-vct,alexander.shekhovcov,alexander.shekhovcov,31/May/17 11:07 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,7Months,AlexReview,Could,,," 

The 'NotImplementedError' exceptions:

[https://github.com/sovrin-foundation/sovrin-client/blob/fa01e3eabcfcad88c54bfe51158c3de77659b600/sovrin_client/client/wallet/attribute.py#L74]

 

The tests which skipped by this issue:
 * testSendAttribSucceedsForHexHash
 * testSendAttribFailsForBase58Hash
 * testSendAttribFailsForBase64Hash
 * testSendAttribSucceedsForHexEnc
 * testSendAttribFailsForBase58Enc
 * testSendAttribFailsForBase64Enc
 * testSendAttribHasInvalidSyntaxIfRawAndHashPassedAtSameTime
 * testSendAttribHasInvalidSyntaxIfRawAndEncPassedAtSameTime
 * testSendAttribHasInvalidSyntaxIfRawHashAndEncPassedAtSameTime
 * testSendAttribHasInvalidSyntaxIfUnknownParameterIsPassed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzx0tz:",,,,,,14,,,,,,,,3.0,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/17 7:50 PM;ashcherbakov;This is about support of this fields on Client side (looks like they are supported on Node side).
Created a task in indy-sdk: https://jira.hyperledger.org/browse/IS-452
Closing this one as won't fix as indy-node's client will be deprecated.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Setup a node in a pool in a NAT scenario,INDY-129,17316,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,01/Jun/17 12:30 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"We need to test having a node in a NAT scenario. Here is a configuration that is being used in a test pool run outside our QA team.

Setup a node as close to this configuration as possible.

* The validator is running on a virtual machine.
* The IP address for the virtual machine is not bound to any of the VM's logical devices.
* The firewall is an enterprise edge device/system.
* The firewall forwards all TCP traffic on ports 9701 and 9702 to the VM, if these packets are from one of the other validators.
* All other packets are dropped by the firewall.
* The firewall is not doing stateful inspection.
* The node running the validator is also running the CLI and three other agents.
* Because traffic from the validator node is using the external IP address (which is what is stored in the ledger) and it does not appear to be from one of the other validators, the firewall will drop all of these packets.
* In order to get around this, they created a rule in the nat target of iptables that reroutes all traffic with the destination of the external IP address immediately to localhost.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1ef:",,,,,,Indy-1,H1,,,,,,,,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jun/17 6:32 PM;VladimirWork;Validator node and sovrin client are installed on my local virtual machine.
Firewall and NAT are configured according to features in description.
Node is added to Shakedown Pool 4 and connecting successfully.;;;","10/Jun/17 7:52 AM;krw910;We have Pool 3 and 4 of the shakedown pools running with a 5th node which is behind a NAT.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A blank line is entered in the transactions file anytime a node does a catch up.,INDY-130,17340,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,danielhardman,krw910,krw910,01/Jun/17 4:45 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Anytime a node falls behind and performs a catch up on the transactions a new line (blank) is entered in the transactions file. The new line causes the line count to be different than the other nodes. This should not cause a problem, but should not be present either.

*Steps*
# You need a 4 node setup. 
# Shutdown one of the nodes.
# Send some transactions.
# Restart the node that is down. 
# When that node starts up it will do a catch up.
# After the catch up you can do a line count on the transaction file on each node and see there is a line count differnce. 
# When you check the transactions file on the node that did the catch up you should find a blank line in the transactions file.

The transactions file is located in "".sovrin/data/nodes/<node name>/transactions_sandbox"" and the file is named ""1"" or ""1001"" depending on how many transactions you have.",,,,,,,,,,,,,,,,,,,,,,,INDY-215,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy24n:",,,,,,H1,H2,H3,,,,,,,,,,,,,,,,,,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 12:26 PM;krw910;This is fixed in the case of a node catching up. I logged a new ticket on blank lines being added when a transaction does not go through which is a different issue. The new ticket is INDY-215;;;","21/Jun/17 3:28 AM;krw910;[~danielhardman] I thought this was fixed, but must have just run into a scenario where I did not see it and thought it was fixed. We just found the pull request is still waiting for approval. [~DouglasWightman] said he had reviewed it with you. Can you get this PR through? 
https://github.com/evernym/ledger/pulls;;;","26/Jun/17 11:14 PM;danielhardman;PR has been approved and code is merged to master.;;;","04/Jul/17 7:39 AM;krw910;This appears to be working find in build 0.4.9;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
node_control_tool.py has too wide set of privileges,INDY-131,17358,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,andrey.goncharov,andrey.goncharov,01/Jun/17 5:04 PM,11/Oct/19 6:42 PM,28/Oct/23 2:46 AM,11/Oct/19 6:42 PM,,,,,0,6Months,shakedown2,should,,,"node_control_tool.py should NOT be run as root (uid==0); it should be run as an account that has elevated privileges to issue calls to apt-get and restart daemons. In other words, it should have limited sudo privileges. If it is run as true root, it is an attack surface.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx1if:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jun/17 3:30 AM;andrey.goncharov;[~danielhardman] This tool kicks off migration scripts. We want our migration scripts to have root privileges, don't we? I mean what if we bring in a new DB, that certainly requires root permissions. Maybe, we should leave node_control_tool running as root, at least for now. What do you think?;;;","21/Jun/17 3:39 AM;danielhardman;I believe (but do not know for certain) that the way sudo works is that a user can be granted privileges to launch a limited set of top-level processes–and that this process tree can retain the privileged status of the original command. If this is true, then we can make node_control_tool.py run as a limited user that has sudo privileges to run apt, launch the sovrin daemon, and run migration scripts by starting a launcher for the migration script that always has the same starting commandline. This would be strongly preferable to truly running as root, for security reasons.

https://unix.stackexchange.com/questions/215412/allow-certain-guests-to-execute-certain-commands;;;","21/Jun/17 3:50 AM;andrey.goncharov;[~danielhardman] My point is that we do not know what privileges our migrations might require. They are python scripts which can do basically anything. If we create a user with a restricted set of elevated permissions then we limit our migrations. ;;;","21/Jun/17 4:04 AM;danielhardman;You are still not engaging on my point: if I am correct (and I don't know if I am; I want you to find out) you don't need to be root to have unbounded privileges. You just need to be in the sudoers file with the *top level* commands you are authorized to run. All the child processes launched by these top-level processes are also allowed to run. We don't have to enumerate all of them in advance.

If that is wrong, then root is required. Let's find out if my understanding is true or false.;;;","30/Aug/17 6:29 AM;krw910;[~nage] we need some design around this issue.;;;","11/Oct/19 6:42 PM;esplinr;This issue represents best practice in Unix environments, but feedback on the system is that our current approach is satisfactory even to the security auditors. So we won't do this work unless someone can show why it is necessary.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve migration tool,INDY-132,17359,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,andrey.goncharov,andrey.goncharov,01/Jun/17 5:12 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,Must,,,,,"As of now migration tool can apply several migrations after an upgrade. Each migration contains only the version you're coming from. This way if you miss several upgrades you willl have several migrations applied (possibly).

From conversation with Daniel:
h4. *[dhh1128|https://github.com/dhh1128]* [2 days ago |https://github.com/sovrin-foundation/sovrin-node/pull/159#discussion_r119150885]
Owner
I am feeling concerned about two issues with this approach:
 # This creates multiple migration scripts per version change. I want one migration script per update. Anything more is unnecessary complexity. Also, it gives multiple points of failure instead of one, and it gives no responsibility to these individual scripts to know about or coordinate with one another. I think it increases the chances of failure.
 # This mechanism doesn't include in its name the version you are coming from, only the version you are headed to. I think this is problematic because we might have nodes upgrading from more than one starting point.
 
 
 [!https://avatars3.githubusercontent.com/u/2208904?v=3&s=56|width=28,height=28!|https://github.com/dhh1128]
h4. *[dhh1128|https://github.com/dhh1128]* [2 days ago |https://github.com/sovrin-foundation/sovrin-node/pull/159#discussion_r119151127]
Owner
Why are versions underscored here, but use dots in .deb? Can we use dots here?
 
 
 [!https://avatars3.githubusercontent.com/u/12794628?v=3&s=56|width=28,height=28!|https://github.com/keenondrums]
h4. *[keenondrums|https://github.com/keenondrums]* [23 hours ago |https://github.com/sovrin-foundation/sovrin-node/pull/159#discussion_r119313532]
Member
[@dhh1128|https://github.com/dhh1128]
 # I think we will have a single script almost always. yet I think we need to leave some room for us to wiggle, since it does not cost us anything.
 # It's actually the version you are coming from. I think it does not really matter what version you're updating to
 # Versions are underscored because they are python modules and a python module can not be dotted
 
 
 [!https://avatars3.githubusercontent.com/u/2208904?v=3&s=56|width=28,height=28!|https://github.com/dhh1128]
h4. *[dhh1128|https://github.com/dhh1128]* [17 hours ago |https://github.com/sovrin-foundation/sovrin-node/pull/159#discussion_r119392573]
Owner
I don't agree with the idea that ""it does not cost us anything."" Please collapse to 1 script and eliminate the sorting/collection. The cost of more than 1 script is complexity, as I pointed out. It's not just code complexity--it's communication/doc complexity, and complexity in testing/managing the coordination actions across multiple scripts.

Re [#2|https://github.com/sovrin-foundation/sovrin-node/pull/2]: versioning needs to include a src and a target version. Of these two, the _target_ is more important. We can't say, ""give me a script that upgrades version X to any version later than that"" -- it's just not practical. Instead, we want to say, ""give me a script that upgrades X to Y"". Then we can play all the migrations in order to get from X to Z.",,,,,,,,,,,,,,,,,,,,,,,INDY-200,,,,INDY-337,,,,,,,,"21/Jun/17 7:14 AM;danielhardman;Screen Shot 2017-06-20 at 4.13.03 PM.png;https://jira.hyperledger.org/secure/attachment/11217/Screen+Shot+2017-06-20+at+4.13.03+PM.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1r3:",,,,,,H2,H3,H4,H5,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jun/17 5:48 PM;andrey.goncharov;[~danielhardman] I proceeded with the merge of migration tool without changing the logic because we needed a stable build with it ASAP. 

You say we need to define an original version and a target version as well. But what if a node missed couple upgrades? Say it jumps from 0.3.100 straight to 0.3.102. Migration from 0.3.100 to 0.3.101 won't be applied then. That was the reason I left only original versions in migrations and allowed them to be applied in bulk. 

If you think we should disregard the case then we can update the logic.;;;","21/Jun/17 3:32 AM;danielhardman;My point is that we shouldn't support jumping from 0.3.100 to 0.3.102. We should require that all migrations proceed one step at a time. That way our test matrix only has to test one possible transition, not all possible transitions. ;;;","21/Jun/17 3:34 AM;danielhardman;I think it could be legal to do an apt upgrade that skips versions–but when we do, we should replay the migration steps one at a time until the gap has been filled. If we try to make it the case that a migration script can start from any version, it will become far too complex and error prone.;;;","21/Jun/17 3:52 AM;andrey.goncharov;[~danielhardman] with the current logic the scenario you described is exactly what's going to happen. Source code will be upgraded to the new version and migrations will be applied in sequence one by one.

Example:
We upgrade from 0.3.100 to 0.3.103. There are migrations for 0.3.101, 0.3.102. A node gets stopped, source code gets updated to 0.3.103, migration 0.3.101 gets applied, migration 0.3.102 gets applied, the node gets restarted.

 ;;;","21/Jun/17 3:59 AM;danielhardman;Okay, then we're not so far apart.

I still think it's problematic to name the script according only to the destination version. If we have a stable build at version 0.3.101 and another stable build at 0.3.104, but NOT a stable build at version 102 or 103, then wouldn't it be smarter to name our migration script something about 0.3.101_to_0.3.104, instead of just 0.3.104, to clarify which version we are starting from?;;;","21/Jun/17 4:02 AM;danielhardman;Also, as I read the code, it looks to me like we could have two migration scripts for one version, for example: 0.3.104_subtaskA and 0.3.104_subtaskB. If this is true, then I don't like it. In such a case, which script has the responsibility for the overall migration working? Answer: neither. I want exactly one script per migration step (where by ""migration step"" I mean the transition from version X to version Y).;;;","21/Jun/17 4:15 AM;andrey.goncharov;[~danielhardman] We name migrations by the version we start from, not destination. It's like an indicator that the code past that point includes some breaking changes and if the migration wasn't applied yet it should be. We can add destination version, I just do not understand its value. Especially in the case when a node misses several upgrades.

As to several scripts per version, yes, we support this in theory. But this is the responsibility of the review not to accept this kind of code. I mean I can easily filter out migrations starting from the same version but this leaves me with a question which ones I should pick? Say, we implement this strict requirement and allow only one migration per version and somehow two migrations for the target version found (0.3.104_subtaskA and 0.3.104_subtaskB), which one should I choose? ;;;","21/Jun/17 2:25 PM;stevetolman;Andrey, when you have completed this ticket, please send it to Daniel for the code review. I want to be sure there is strong alignment on the approach to solve this problem.;;;","22/Jun/17 6:33 AM;danielhardman;Here are some things about the current mechanism that feel like they need enhancement:
 * We are assuming a very tight coupling between package versions as manifest in a package manager, and source code. This coupling is going to create problems sooner or later. For example, when we are publishing RPMs and MSI/chocolatey packages, what if the versions that we publish on each OS aren't identical? Imagine that we have 1.deb, 2.deb, and 4.deb; 1.rpm, 3.rpm, and 4.rpm, and 2.msi and 4.msi. If 3.msi has never existed on Windows, should we be running a migration script for it? What if 3.msi existed, but was never considered stable?
 * Our error handling strategy is unclear and not robust enough. What happens when the third migration script out of 5 fails? Are we distinguishing between recoverable and unrecoverable errors? What is the responsibility of a failed migration script, in terms of cleaning up temporary state that it creates? Is a migration script idempotent? Will migration scripts test preconditions before they begin?
 * We don't have a plan for how to handle downgrades or how to upgrade to specific versions (as opposed to ""latest"").
 * We don't know how to troubleshoot. Will migration scripts write a log? If so, what will it be named, and what will it contain? Will the log be safe to email to someone, or will it contain private info about system config?
 * We are depending on human processes to enforce smart behavior, instead of just enforcing it automatically in code.

Regarding naming, the first enhancement I want is to eliminate the possibility that there can be two scripts for the same migration. The flexibility of having two or more scripts that divide a single responsibility is a bug and complication, not a feature, because it makes it unclear how responsibilities will be divided, and because there is no single place that bears responsibility for overall migration success. See [https://codecraft.co/2012/10/17/flexibility-is-no-virtue/] I think we could easily enhance the current system to address this concern, by simply disallowing arbitrary suffixes after a version number, in the regex we use to match migration scripts.

The second enhancement I want is to have each script named by the combination of versions it covers (the version it starts from, and the version it goes to–a template like <start_version>_to_<end_version>). See the graphic I attached. One reason for this is that it facilitates human understanding: I want it to be crystal clear to all developers, testers, and sysadmins who interact with the migration mechanism exactly what the scope of a given migration script might be. The responsibilities of a given migration script are not to accept any start version and go to a single target version, or to start from a specific version and upgrade it to any arbitrary version that's later; rather, its job is to make exactly one transition from version A to version B. This is what must be tested, and the script only applies in that context; it is a cell, not a row or column, in a test matrix.

Adopting the naming convention I'm asking for will also allow us, if we choose, to short-circuit steps. I hope we don't need that flexibility–and I certainly don't want to build support for it right now–but if we needed to have that support in the future (e.g., because an intermediate step is too time-consuming or because it's impossible), then establishing the right naming convention now gives us options. (If I have migration scripts named 1_to_2, 2_to_3, 3_to_4, and 1_to_4, I can do the migrations in one step by running 1_to_4, instead of in 3 steps.) Similarly, if we ever wanted to downgrade, having both versions in the naming convention would tell us which migration scripts need to be undone to get back to a particular version.

 ;;;","22/Jun/17 6:42 AM;danielhardman;Regarding error handling and troubleshooting, I suggest that we establish the following contract for migration scripts:
 # Migration scripts write to stdout only, and they don't write any sensitive data like keys, passwords, etc.
 # Each migration script writes to stdout a standard message on startup, and another standard message on shutdown. This standard message includes the date, the script name, and any other useful metadata we can think of. The message written on shutdown tells whether the migration script succeeded or failed, and what the exit code from the migration script process will be.
 # Migration scripts are not allowed to abend (e.g., from an unhandled exception) without writing the message describing the outcome.
 # Migration scripts return 0 on success, or an error (from errno.h?) on failure.
 # Migration scripts are idempotent. It is legal to run them over and over, and they detect whether they have any work to do. Once a migration script has successfully completed its job, running it again has no effect.
 # The code that runs migration scripts is responsible for redirecting stdout to a log file. This allows multiple migrations to be summarized in a single file. The only thing that the migration script runner echoes to the screen is a single line for each migration script, naming the script that's being run, and its outcome (either success or failure).;;;","22/Jun/17 5:44 PM;andrey.goncharov;??We are assuming a very tight coupling between package versions as manifest in a package manager, and source code. This coupling is going to create problems sooner or later. For example, when we are publishing RPMs and MSI/chocolatey packages, what if the versions that we publish on each OS aren't identical? Imagine that we have 1.deb, 2.deb, and 4.deb; 1.rpm, 3.rpm, and 4.rpm, and 2.msi and 4.msi. If 3.msi has never existed on Windows, should we be running a migration script for it? What if 3.msi existed, but was never considered stable???

We have two options here:
 * We guarantee that releases for different platfoms match
 * We create different migrations for different platforms

I understand your concerns and suggest to start creating different migration scripts for different platforms. We could create ubuntu, windows, centos folders in migrations folder to separate them.

 ??Our error handling strategy is unclear and not robust enough. What happens when the third migration script out of 5 fails? Are we distinguishing between recoverable and unrecoverable errors? What is the responsibility of a failed migration script, in terms of cleaning up temporary state that it creates? Is a migration script idempotent? Will migration scripts test preconditions before they begin???

As of now we create a ZIP archive with .sovrin folder before applying migrations. If anything goes wrong we restore original state of .sovrin from it. It was the easiest thing to do to provide somewhat of a backup strategy. Currently if a third migration out of five fails we will restore .sovrin from a ZIP file and rollback to a version we had before an upgrade. Since there's no easy way to save s state of our whole system before applying a migration I say any migration should clean up after itself in case of failure if it changes anything outside of .sovrin folder. I think for simplicity migration scripts can omit testing preconditions. If they fail to perform original state will be restored from a ZIP file.

??We don't have a plan for how to handle downgrades or how to upgrade to specific versions (as opposed to ""latest"").??

We can upgrade to specific versions now. We implemented recursive installation of downstream dependencies so we are not limited by apt-get's rule to prevents installation of not latest dependencies. Yet you're right we do not have a plan on how to handle downgrades. I mean node_control_tool could easily install from older debs now but we would still have, potentially, some migrations applied. I say we leave it up to a trustee. He should check that there were no critical (incompatible) migrations applied before submitting a downgrade.

??We don't know how to troubleshoot. Will migration scripts write a log? If so, what will it be named, and what will it contain? Will the log be safe to email to someone, or will it contain private info about system config???

??Migration scripts write to stdout only, and they don't write any sensitive data like keys, passwords, etc.??

??The code that runs migration scripts is responsible for redirecting stdout to a log file. This allows multiple migrations to be summarized in a single file.??

Currently we use standard sovrin logger from stp core. It writes all logs to NodeX.log file. Since sovrin-node-control is run by systemctl stdout gets captured by journalctl. Do you want to change this behavior?

??Migration scripts return 0 on success, or an error (from errno.h?) on failure.??

All migration scripts are python modules. In order to execute them we just import them. We catch any exception with an outer catch block. This way we do not need return codes. Do you want to change the logic?

??Adopting the naming convention I'm asking for will also allow us, if we choose, to short-circuit steps. I hope we don't need that flexibility–and I certainly don't want to build support for it right now–but if we needed to have that support in the future (e.g., because an intermediate step is too time-consuming or because it's impossible), then establishing the right naming convention now gives us options. (If I have migration scripts named 1_to_2, 2_to_3, 3_to_4, and 1_to_4, I can do the migrations in one step by running 1_to_4, instead of in 3 steps.) Similarly, if we ever wanted to downgrade, having both versions in the naming convention would tell us which migration scripts need to be undone to get back to a particular version.??

What if we migrate from 1 to 3 and have scripts 1_to_2 and 2_to_3? Do we apply them one by one? How in this case do we handle the following situations:
 * We migrate from 1 to 4 and have scripts 1_to_3, 2_to_4?
 * We migrate from 2 to 4 and have scripts 1_to_3 and 3_to_4?

I suggest we do a simple thing and apply all scripts in alphabetical order that satisfy the condition: (script's first version >= a version we're migrating from) and (script's second version <= a version we're migrating to). This way we're exposed to having invalid behavior in case of overlapping migrations (if we migrate from 1 to 4 and scripts are 1_to_3, 3_to_4 and 1_to_2, all of them will be applied), but it's very simple.

Also I'd like to add one more requirement for migrations:
 * If you create a migration script X_to_Y, you must create a script Y_to_X to allow downgrades.

What do you think about all of this, [~danielhardman] ?;;;","23/Jun/17 9:31 AM;danielhardman;>> I understand your concerns and suggest to start creating different migration scripts for different platforms. We could create ubuntu, windows, centos folders in migrations folder to separate them.

Let's name the folders by the package type (deb, rpm, msi), rather than by the OS.

>>As of now we create a ZIP archive with .sovrin folder before applying migrations.

This is close to being good enough. However, if migrations fail, it would be desirable to roll back the installed package, not just the ~/.sovrin folder. Maybe that should be a different ticket.

>>Currently we use standard sovrin logger from stp core. It writes all logs to NodeX.log file

Let's say we stick with that for now. We need to clearly delimit events associated with upgrade (and each step of a migration, separately) from the normal operation of the node, so I know which migration script was running when it happened.

>>All migration scripts are python modules. In order to execute them we just import them. We catch any exception with an outer catch block. This way we do not need return codes. Do you want to change the logic?

What happens if an import fails? Is the import inside the try block?

Do we have a timeout for each step in the migration?

>>I suggest we do a simple thing...

We can do this simple thing if we write a ticket for a more sophisticated behavior. The more sophisticated behavior, IMO, would be to compute the shortest possible list of migrations that get you from version X to version Y. So in your example, only 1_to_3 and 3_to_4 would be applied–not 1_to_2.

>>one more requirement for migrations:

This is a good idea, but I think we can postpone it for the time being. Adding support for downgrades can be done as a separate story, deferred until after go live.;;;","23/Jun/17 4:57 PM;andrey.goncharov;??What happens if an import fails? Is the import inside the try block???
 ??Do we have a timeout for each step in the migration???

Whole migrate function is inside try catch block, so if anything raises an exception (like broken import) the exception gets caught, migration sequence gets interrupted, original state of .sovrin gets restored and a rollback to original version gets performed.

??Do we have a timeout for each step in the migration???

We have a timeout for applying all migrations. I will get rid of it and add a timeout for applying each migration.

??This is close to being good enough. However, if migrations fail, it would be desirable to roll back the installed package, not just the ~/.sovrin folder. Maybe that should be a different ticket.??

We do rollbacks as well. Not only .sovrin is restored but a rollback to original version of source code is done.

??We can do this simple thing if we write a ticket for a more sophisticated behavior. The more sophisticated behavior, IMO, would be to compute the shortest possible list of migrations that get you from version X to version Y. So in your example, only 1_to_3 and 3_to_4 would be applied–not 1_to_2.??

I proceed with the simple behavior then. I'll create a ticket for implementing a more sophisticated one. 

 ;;;","23/Jun/17 10:09 PM;andrey.goncharov;[~danielhardman] please review.

PR: [https://github.com/sovrin-foundation/sovrin-node/pull/191]

Implemented:
 * Updated migrations README
 * Migration scripts naming convention changed from X_X_X_name to X_X_X_to_Y_Y_Y
 * Added timeout for each migration
 * Condition upon which migrations to apply get selected is changed;;;","27/Jun/17 5:12 PM;andrey.goncharov;[~krw910] this ticket will be tested in scope of INDY-200 test scenarios. If you find that ok then reassign it to Vladimir;;;","18/Jul/17 11:27 PM;VladimirWork;Testing activities were performed in scope of INDY-200.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test testSuspendNodeWhichWasNeverActive is disabled,INDY-133,17361,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,andrey.goncharov,andrey.goncharov,01/Jun/17 6:53 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,Must,,,,Test sovrin-client/testSuspendNodeWhichWasNeverActive should be renenabled. ,,,,,,,,,,,INDY-385,,,,,,,,,,,,INDY-9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-785,,,,,,,,,,"1|hzzx5b:",,,,,,H3,Ev 18.22,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,danielhardman,Derashe,krw910,mzk-vct,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jun/17 6:06 AM;stevetolman;Time box this ticket to one hour only.

Turn on the test and build. If the test succeeds, check it in. If it fails, try for an hour to fix it. If you still cannot fix it, shut it off, comment here, and move on.;;;","28/Jun/17 11:03 PM;mzk-vct;The reason is that there is no handling for in zstack PublicKeyNotFoundOnDisk and error message is not whitelisted.
This exception is expected since node newly added not is not going to be online in this test.;;;","28/Jun/17 11:03 PM;mzk-vct;Pull request for stp: https://github.com/evernym/stp/pull/37;;;","30/Jun/17 11:46 PM;mzk-vct;Pull request for stp was reverted, because it was decided to leave handling of PublicKeyNotFoundOnDisk as is since it very specific case.

To close this ticket it is needed to fix a bug in creation of public key file when SERVICES field of NODE request is empty (file is not created):
https://github.com/hyperledger/indy-plenum/blob/master/plenum/server/pool_manager.py#L228;;;","06/Jul/17 5:00 AM;krw910;[~mzk-vct] since I cannot do anything with this ticket I am assigning it back to you.;;;","06/Jul/17 10:51 PM;ashcherbakov;[~stevetolman] The timebox of 1 hour ended. Should we continue working on it and implement the changes proposed by Victor?;;;","07/Jul/17 5:55 AM;stevetolman;Thank you for the research on this. This ticket can move to the back log now since it does not look like a deep lurking issue.

Please log a bug about fixing creation of public key, block this ticket because of that new ticket, and then move this to the top of the back log.;;;","07/Jul/17 9:04 AM;danielhardman;Log the new ticket in the backlog.;;;","07/Jul/17 6:45 PM;mzk-vct;[~stevetolman] [~danielhardman] blocking ticket created, https://jira.hyperledger.org/browse/INDY-385;;;","06/Nov/18 10:30 PM;Derashe;PR: https://github.com/hyperledger/indy-node/pull/1012;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance input validation code,INDY-134,17366,,Story,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,alexander.shekhovcov,alexander.shekhovcov,alexander.shekhovcov,02/Jun/17 12:09 AM,29/Oct/19 11:41 PM,28/Oct/23 2:46 AM,,,,,,0,6Months,should,,,,"We moved quickly that why we have to do some enhancements which we had put off:

The enhancements:
 * Move to separate files all messages for plenum and sovrin-common
 * Replace TypeError exception with a custom one (ValueError)
 * Rework validation of verkey size (find a reliable way for verkey size validation and move this validation to the appropriate validator)
 * Write tests for field types (for example, just declare that field ALIAS should have NonEmptyStringField type)
  

(feel free to add items)",,,,,,,,,,,,,,,,,,,,,,,INDY-136,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx1q7:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/19 11:41 PM;esplinr;When we next touch the input validation, we should check to see if these problems have been addressed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Genesis transaction files are not in the provided link when the pool transactions file is empty,INDY-135,17368,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,krw910,krw910,02/Jun/17 12:45 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"The purpose of this test is to verify the correct message is shown when you are unable to connect to the validator pool from a client.

*{color:#205081}Setup{color}*
 *Make a copy of the pool_transactions_sandbox file*
 *Run the following commands*
 cd .sovrin
 cp pool_transactions_sandbox original_pool_trasnsactions_sandbox

*Delete contents of the pool_transactions_sandbox file*
 *Run the following commands*
 cd .sovrin
 sudo vim pool_transactions_sandbox
 Select all and delete in vim gg then dG

*Run the following commands*
 start sovrin
 connect test

*You should receive a message that the information needed to connect was not found.*
 Verify that the URL is correct

*The URL provided is*
 [https://github.com/sovrin-foundation/sovrin-client/tree/stable/data]

*{color:#d04437}The location does not contain the following files{color}*
 pool_transactions_sandbox
 transactions_sandbox

pool_transactions_live
 transactions_live",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1cv:",,,,,,H1,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 11:37 AM;krw910;I verified the link after doing a new install and having an empty pool transactions file. The genesis files are now in the correct location.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Changes validation of base58 field,INDY-136,17370,17104,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mzk-vct,mzk-vct,02/Jun/17 1:08 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,Decode base58 back to bytes and compare their number with expected instead of checking length of base58,,,,,,,,,,,,,,,,,,,,,,,INDY-72,,,,INDY-134,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxy67:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,alexander.shekhovcov,andkononykhin,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/17 1:44 AM;mzk-vct;Also it would be better to move _long_ and _short_ from Base58Field;;;","23/Jun/17 10:30 PM;alexander.shekhovcov;Will be done in the scope of INDY-175;;;","27/Jun/17 3:14 AM;andkononykhin;Hello, [~krw910]

The task is resolved by the changes made for INDY-175: [https://github.com/evernym/plenum/pull/226]

How to test: the same test steps as described in comment for checking odd-length verkey

Thank you;;;","05/Jul/17 12:17 AM;VladimirWork;Validation of base58 field is checked during testing INDY-110 (verkey validation) and INDY-175.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Initializing State loads the whole ledger into Memory,INDY-137,17372,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,devin-fisher,devin-fisher,02/Jun/17 1:51 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,," 

When initializing the state of Plenum the whole ledger is loaded into memory and then processed to create the state.  This operation could fail or be very inefficient if the ledger is large (the domain ledger should in time).

 

Currently, the implementation is doubly bad since getAllTxn load all txn into an OrderedDict and then they are enumerated into a list in initStateFromLedger. So there could be a two large data structures holding pointers to all the Txn.

 
{code:java}
@staticmethod
def initStateFromLedger(state: State, ledger: Ledger, reqHandler):
    # If the trie is empty then initialize it by applying
    # txns from ledger
    if state.isEmpty:
        txns = [_ for _ in ledger.getAllTxn().values()]
        reqHandler.updateState(txns, isCommitted=True)
        state.commit(rootHash=state.headHash)

def initDomainState(self):
    self.initStateFromLedger(self.states[DOMAIN_LEDGER_ID],
                             self.domainLedger, self.reqHandler){code}
 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1rb:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,devin-fisher,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/17 11:48 PM;lovesh;https://github.com/hyperledger/indy-ledger/pull/63
https://github.com/hyperledger/indy-plenum/pull/246
https://github.com/hyperledger/indy-node/pull/203;;;","13/Jul/17 5:25 AM;krw910;Blocked by INDY-406;;;","13/Jul/17 4:11 PM;krw910;To test this:

a simplistic way is to see if you start Node with a big ledger with the state database being deleted, does the memory consumption go a lot higher, that would indicate if the whole ledger is loaded into memory;;;","18/Jul/17 12:51 PM;krw910;Blocked by INDY-246. I need to be able to get up to 60,000 plus transactions in order to test this.;;;","24/Jul/17 6:28 AM;krw910;I removed the pool_state directory and started the sovrin-node service. Everything worked fine and came up quickly. I had almost 82,000 transactions at the time.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"[Input validation] Validation for PrePrepare, LedgerStatus, ConsistencyProof",INDY-138,17374,17104,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mzk-vct,mzk-vct,02/Jun/17 3:55 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Implement validation for PrePrepare, LedgerStatus, ConsistencyProof",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxy7b:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,mzk-vct,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/17 3:55 AM;mzk-vct;Following messages implemented

    PrePrepare
    LedgerStatus
    ConsistencyProof

Pull request https://github.com/evernym/plenum/pull/183
;;;","08/Jun/17 2:05 AM;ozheregelya;Need to implement all necessary tests.;;;","16/Jun/17 10:04 PM;mzk-vct;Added tests for messages, please find them in plenum/test/input_validation/message_validation package
;;;","27/Jun/17 1:31 AM;ozheregelya;Following tests were added and passed without errors:

plenum/plenum/test/input_validation/message_validation/test_preprepare_message.py
plenum/plenum/test/input_validation/message_validation/test_ledgerstatus_message.py
plenum/plenum/test/input_validation/message_validation/test_consistencyproof_message.py
{code:java}
(.venv) sovrin@sovrin-VirtualBox:~/git/plenum/plenum/test/input_validation$ pytest
============================================================================================ test session starts ============================================================================================
platform linux -- Python 3.5.2, pytest-3.1.2, py-1.4.34, pluggy-0.4.0
rootdir: /home/sovrin/git/plenum/plenum/test, inifile: pytest.ini
plugins: xdist-1.17.1
collected 104 items
test_client_node_op.py ......
test_client_nym_op.py ...
test_common_checks.py ssssss
test_handle_one_node_message.py ss
fields_validation/test_base58_field.py .....
fields_validation/test_bool_field.py ....
fields_validation/test_hex_field.py ....
fields_validation/test_identifier_field.py ..
fields_validation/test_iterable_field.py ..
fields_validation/test_ledger_id_field.py ..
fields_validation/test_merkle_tree_root_field.py ...
fields_validation/test_non_empty_string_field.py ..
fields_validation/test_non_negative_number_field.py ....
fields_validation/test_request_identifier_field.py ......
fields_validation/test_serializedvalue_field.py ....
fields_validation/test_time_among_field.py ...
fields_validation/test_timestamp_field.py ..
fields_validation/test_verkey_field.py ..
message_validation/test_batch_message.py ...
message_validation/test_checkpoint_meeting.py ...
message_validation/test_commit_message.py ...
message_validation/test_consistencyproof_message.py ...
message_validation/test_instanceChange_message.py ...
message_validation/test_ledgerstatus_message.py ...
message_validation/test_nomination_message.py ...
message_validation/test_ordered_message.py ...
message_validation/test_prepare_message.py ...
message_validation/test_preprepare_message.py ...
message_validation/test_primary_message.py ...
message_validation/test_propagate_message.py ...
message_validation/test_reelection_message.py ...
message_validation/test_threepcstate_message.py ...
=================================================================================== 96 passed, 8 skipped in 1.14 seconds ====================================================================================

{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validation of send GET_NYM command parameters is incorrect,INDY-139,17375,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,02/Jun/17 4:17 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,shakedown3,,,,"The following tests in {{sovrin_client.test.cli.test_send_attrib_validation}} module fail by this reason:
* testSendGetNymHasInvalidSyntaxIfDestIsEmpty
* testSendGetNymHasInvalidSyntaxIfUnknownParameterIsPassed",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy17b:",,,,,,H2,,,,,,,,,,,,,,,,,,,,andrey.goncharov,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/17 5:17 PM;andrey.goncharov;Problem reason: 
- invalid regexp

Changes: 
- fixed regexp

Committed into:
https://github.com/sovrin-foundation/sovrin-client/commit/90f3fc6dae288ff2d922fa88171d5c2a564f97d5
sovrin-client/master 0.3.147

Risk factors:
 Nothing is expected.

Risk:
 Low;;;","23/Jun/17 2:02 AM;krw910;I tried short strings, long strings, invalid characters, empty strings, NULL and a few others. Everything worked as expected.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Plenum crashes if any genesis transaction don't have required fields,INDY-140,17379,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,zhigunenko.dsr,devin-fisher,devin-fisher,02/Jun/17 5:44 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,6Months,should,,,,"Steps to reproduce:
 # Add a line in a working genesis pool transactions with ""\{}""
 # Start node

 

Error Message is not useful:
{code:java}
../server/node.py:163: in __init__
self.initPoolManager(nodeRegistry, ha, cliname, cliha)
../server/node.py:374: in initPoolManager
HasPoolManager.__init__(self, nodeRegistry, ha, cliname, cliha)
../server/pool_manager.py:54: in __init__
cliha=cliha)
../server/pool_manager.py:72: in __init__
self.initPoolState()
../server/pool_manager.py:99: in initPoolState
self.node.initStateFromLedger(self.state, self.ledger, self.reqHandler)
../server/node.py:1998: in initStateFromLedger
reqHandler.updateState(txns, isCommitted=True)
../server/pool_req_handler.py:57: in updateState
existingData = self.getNodeData(nodeNym, isCommitted=isCommitted)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <plenum.server.pool_req_handler.PoolRequestHandler object at 0x7f5451046f98>
nym = None, isCommitted = True

def getNodeData(self, nym, isCommitted: bool = True):
> key = nym.encode()
E AttributeError: 'NoneType' object has no attribute 'encode'{code}
 

(added unit test that shows the issue, should be in code but in case if don't get merged in)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/17 5:44 AM;devin-fisher;test_node_genesis.py;https://jira.hyperledger.org/secure/attachment/10899/test_node_genesis.py",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-785,,,,,,,,,,"1|hzy10n:",,,,,,,,,,,,,,,,,,,,,,,,,,devin-fisher,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 11:24 PM;zhigunenko.dsr;*Environment:*
indy-node                  1.6.78 (stable)

*Steps to Validate:*
1) stop node service
2) Add a line in a working genesis pool transactions with ""{}""
3) start node
4) add nym to the ledger

*Actual Results:*
1) service started successfully
2) transaction has been ordered;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Plenum fails to start with a blank line in pool_transactions file,INDY-141,17380,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,sergey.khoroshavin,devin-fisher,devin-fisher,02/Jun/17 5:53 AM,29/Oct/19 11:36 PM,28/Oct/23 2:46 AM,29/Oct/19 11:36 PM,,,,,0,6Months,should,,,,"Steps to reproduce:
 # Add a blank line (with extra white space). Can't just be \n. It must be a new line with some other whitespace character (space, tab, etc).
 # Start node

Error message is super helpful:

 
{code:java}
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../server/node.py:163: in __init__
self.initPoolManager(nodeRegistry, ha, cliname, cliha)
../server/node.py:374: in initPoolManager
HasPoolManager.__init__(self, nodeRegistry, ha, cliname, cliha)
../server/pool_manager.py:54: in __init__
cliha=cliha)
../server/pool_manager.py:72: in __init__
self.initPoolState()
../server/pool_manager.py:99: in initPoolState
self.node.initStateFromLedger(self.state, self.ledger, self.reqHandler)
../server/node.py:1997: in initStateFromLedger
txns = [_ for _ in ledger.getAllTxn().values()]
../../../ledger/ledger/ledger.py:230: in getAllTxn
result[seqNo] = self.leafSerializer.deserialize(txn)
../../../ledger/ledger/serializers/json_serializer.py:75: in deserialize
return self.loads(data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = ' '

@staticmethod
def loads(data):
if isinstance(data, (bytes, bytearray)):
data = data.decode()
> return json.loads(data)
E ValueError: Expected object or value

../../../ledger/ledger/serializers/json_serializer.py:65: ValueError
{code}
 

I've attached a unit test - test_empty_line - just in case it don't get merged into code

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/17 5:53 AM;devin-fisher;test_node_genesis.py;https://jira.hyperledger.org/secure/attachment/10900/test_node_genesis.py",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx1dr:",,,,,,,,,,,,,,,,,,,,,,,,,,devin-fisher,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 11:43 PM;zhigunenko.dsr;*Environment:*
indy-node                  1.6.78   (stable)

*Steps to Validate:*
1) stop service on existent node
2) erase data/NodeX/ folder
3) modify genesis file (tabs / spaces / mikst)
4) start service

*Actual results:*
Node catchuped ledger successfully;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Added node did not take new transactions after catch up,INDY-142,17382,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,andrey.goncharov,krw910,krw910,02/Jun/17 6:42 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*Stable Build*
*{color:#205081}Node {color}*
python3-stp=0.1.9
python3-ledger=0.2.14
python3-state-trie=0.1.1
python3-plenum=0.3.13
python3-sovrin-common=0.2.9
sovrin-node=0.3.15

*{color:#205081}Client {color}*
python3-stp=0.1.9
python3-ledger=0.2.14
python3-state-trie=0.1.1
python3-plenum=0.3.13
python3-sovrin-common=0.2.9
python3-anoncreds=0.3.3
sovrin-client=0.3.18


I added two new nodes to an existing pool which had 34 transactions already on the ledger. After adding the new node to the pool I continued with transactions adding another 28 transactions. I checked the nodes transactions count and the the original nodes had 62 transactions and the two new nodes only had 34 transactions. The new nodes only did a catch up to the point the pool was at when they were added and did not add any new transactions. 

The services are still running and show no errors. I am not restarting the services because I want to leave it in the bad state to be looked at first.

*Setup*
Taken from the acceptance documentation. 
Used AWS template to setup 10 machines. 
- 4 Nodes for the original pool
- 2 machines to install nodes and add to the pool during testing
- 4 machines to be used as clients and agents for the getting started tutorial

*Steps*
Followed all the steps as outlined in the acceptance test documents ""01 - Test Scenario"" to ""11 - Test Scenario"" in order.{color:#205081} (Hopefully you can just do a few transactions and add nodes to the pool to reproduce the issue){color}

After completing tests I had stepped away for about 3 hours then I checked the line count of the transactions file located on each node in 
.sovrin/data/nodes/<node name>/transactions_sandbox
File name ""1""

Nodes 1 - 4 had a line count of 62
Node 5 had a line count of 34
Node 6 had a line count of 35

I checked to see how many transaction writes are done after adding the nodes and it is about 24 so the missing 28 transactions seem to be all the ones that took place after adding the new nodes.

I did not give it time to catch up right away before starting into the other transactions. However I did not check the line counts for 3 hours and that is when I noticed the difference.

Kelly will send Alex the connection information. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxrr:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/17 6:56 AM;krw910;I am setting this to invalid. I went down the wrong path. I had demoted the nodes and then promoted them back to validators. After promoting them back to validators the client connected to them, but new transactions did not go through.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RAET transport is not functional,INDY-143,17404,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,sergey-shilov,andrey.goncharov,andrey.goncharov,02/Jun/17 9:48 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,6Months,raet,should,,,"If ""UseZStack = False"" is specified for every node in the pool in /home/sovrin/.sovrin/sovrin_config.py prior to start the pool can not start.

Steps to reproduce:
 * install sovrin-node from DEBs
 * add ""UseZStack = False"" to /home/sovrin/.sovrin/sovrin_config.py
 * start your pool
 * run systemctl status sovrin-node to see the error

Error:
{code:java}
Jun 02 12:32:38 150859c0c0f9 systemd[1]: Started Sovrin Node.
 Jun 02 12:32:40 150859c0c0f9 start_sovrin_node[85]: Traceback (most recent call last):
 Jun 02 12:32:40 150859c0c0f9 start_sovrin_node[85]: File ""/usr/local/bin/start_sovrin_node"", line 47, in <module>
 Jun 02 12:32:40 150859c0c0f9 start_sovrin_node[85]: cliha=cliha)
 Jun 02 12:32:40 150859c0c0f9 start_sovrin_node[85]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 80, in _init_
 Jun 02 12:32:40 150859c0c0f9 start_sovrin_node[85]: config=self.config)
 Jun 02 12:32:40 150859c0c0f9 start_sovrin_node[85]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 135, in _init_
 Jun 02 12:32:40 150859c0c0f9 start_sovrin_node[85]: self.ensureKeysAreSetup()
 Jun 02 12:32:40 150859c0c0f9 start_sovrin_node[85]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 2046, in ensureKeysAreSetup
 Jun 02 12:32:40 150859c0c0f9 start_sovrin_node[85]: raise REx(REx.reason.format(name) + self.keygenScript)
 Jun 02 12:32:40 150859c0c0f9 start_sovrin_node[85]: plenum.common.exceptions.KeysNotFoundException: Keys not found in the keep for Node1. To generate them run script i
 Jun 02 12:32:40 150859c0c0f9 systemd[1]: sovrin-node.service: Main process exited, code=exited, status=1/FAILURE
 Jun 02 12:32:40 150859c0c0f9 systemd[1]: sovrin-node.service: Unit entered failed state.
 Jun 02 12:32:40 150859c0c0f9 systemd[1]: sovrin-node.service: Failed with result 'exit-code'.{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzx1sf:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/18 9:17 PM;sergey-shilov;Raet is deprecated and removed, this ticket is not relevant and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
load_test.py fails with big number of client with OSError: [Errno 24] Too many open files: '/home/tmh/.sovrin/7wj47KRRaNjkoZu6fWg95X8hSGXAQfwVZe4AJgmcCKNJ/public_keys/7wj47KRRaNjkoZu6fWg95X8hSGXAQfwVZe4AJgmcCKNJ.key',INDY-144,17408,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,dsurnin,dsurnin,dsurnin,02/Jun/17 11:48 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Could,,,,,"install client and node in one machine;

run 4 nodes;

run load_test.py with big number of client: -1 for all or number >= 100
{code:java}
load_test.py -c -1
....
2017-06-02 17:44:52,294 | INFO | stacks.py (74) | start | EGFMdqDYLTE9BSBC5toNr58HG6YgvSXJYYBag2bPQnsq listening for other nodes at 0.0.0.0:17403
2017-06-02 17:44:52,294 | INFO | zstack.py (725) | connect | EGFMdqDYLTE9BSBC5toNr58HG6YgvSXJYYBag2bPQnsq looking for Node3C at 127.0.0.1:9706
2017-06-02 17:44:52,294 | INFO | zstack.py (725) | connect | EGFMdqDYLTE9BSBC5toNr58HG6YgvSXJYYBag2bPQnsq looking for Node1C at 127.0.0.1:9702
2017-06-02 17:44:52,295 | INFO | zstack.py (725) | connect | EGFMdqDYLTE9BSBC5toNr58HG6YgvSXJYYBag2bPQnsq looking for Node2C at 127.0.0.1:9704
2017-06-02 17:44:52,295 | INFO | zstack.py (725) | connect | EGFMdqDYLTE9BSBC5toNr58HG6YgvSXJYYBag2bPQnsq looking for Node4C at 127.0.0.1:9708
2017-06-02 17:44:52,295 | INFO | zstack.py (451) | start | 7wj47KRRaNjkoZu6fWg95X8hSGXAQfwVZe4AJgmcCKNJ starting with restricted as False and reSetupAuth as True
2017-06-02 17:44:52,362 | INFO | looper.py (267) | shutdown | Looper shutting down now...
Traceback (most recent call last):
File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 892, in loadPubKeyFromDisk
File ""/usr/local/lib/python3.5/dist-packages/zmq/auth/certs.py"", line 93, in load_certificate
OSError: [Errno 24] Too many open files: '/home/tmh/.sovrin/7wj47KRRaNjkoZu6fWg95X8hSGXAQfwVZe4AJgmcCKNJ/public_keys/7wj47KRRaNjkoZu6fWg95X8hSGXAQfwVZe4AJgmcCKNJ.key'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 921, in getPublicKey
File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 895, in loadPubKeyFromDisk
KeyError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File ""./load_test.py"", line 383, in main
File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 161, in add
File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", line 183, in start
File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 224, in start
File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stacks.py"", line 68, in start
File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 453, in start
File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 477, in open
File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 909, in publicKey
File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 923, in getPublicKey
stp_core.network.exceptions.PublicKeyNotFoundOnDisk: 7wj47KRRaNjkoZu6fWg95X8hSGXAQfwVZe4AJgmcCKNJ could not get 7wj47KRRaNjkoZu6fWg95X8hSGXAQfwVZe4AJgmcCKNJ's public key from disk. Make sure the keys are initialized for this remote or provided explicitly.{code}
 

 

 ",,,,,,,,,,,,,,,,,,,,,INDY-226,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0nb:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 1:50 AM;stevetolman;Please try again with the latest build.;;;","30/Aug/17 6:16 AM;krw910;This is based off an old process model and we don't believe this is still an issue ;based off current results running load_test.py.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"After catch up, ledger stalls",INDY-145,17414,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,03/Jun/17 3:28 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"We are still chasing this down, but here is what we know so far.

*{color:#205081}Scenario 1{color}*
* Started with 4 nodes in a pool.
* Added two more nodes to the pool and they did a catch up with the pool. I had 35 transactions.
* I then demoted the two new nodes setting 'services': [] and added the nodes back with setting 'services': ['VALIDATOR']
* I then sent another 28 transactions.
Nodes 1-4 (original nodes) had 63 transactions
{color:#d04437}Nodes 5-6 (added nodes) did not receive an new transactions after the initial sync. If I restart sovrin-node.serivce they would catch up again.{color}
{color:#d04437}However the new nodes never receive any new transactions and only catch up if you restart the service.{color}

*{color:#205081}Scenario 2{color}*
Same as above, but in this pool after adding the new nodes the catch process never happened.

*{color:#205081}Scenario 3{color}*
I shutdown the sovrin-node.service on Node 2 which is one of the original nodes. When I restarted the service it would not catch up or take new transactions.

Current thinking is that we are dealing with a consistency issue during catch where due to an inconstancy the node stops talking to the node that is sending the updated ledger information. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jun/17 2:54 AM;krw910;Node1_ServiceShutDown.log;https://jira.hyperledger.org/secure/attachment/10912/Node1_ServiceShutDown.log","04/Jun/17 2:54 AM;krw910;Node2_ServiceShutDown.log;https://jira.hyperledger.org/secure/attachment/10913/Node2_ServiceShutDown.log","04/Jun/17 2:54 AM;krw910;Node3_ServiceShutDown.log;https://jira.hyperledger.org/secure/attachment/10914/Node3_ServiceShutDown.log","04/Jun/17 2:54 AM;krw910;Node4_ServiceShutDown.log;https://jira.hyperledger.org/secure/attachment/10915/Node4_ServiceShutDown.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxnz:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ashcherbakov,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jun/17 7:11 AM;krw910;I have reproduced this again with two triggers:
 # If I demote a node and add it back to the pool it won't catch up or take new transactions.
 # If I stop the service on a node and then start the service again it won't catch up or take new transactions.

I did the first trigger on Node 5 and the second trigger on Node 6. *{color:#d04437}Now I cannot connect to the pool at all.{color}*

I am going to try again with a new pool where I restart the service on a node and see if it has the same issue.;;;","04/Jun/17 2:50 AM;krw910;Today I setup 3 pools
 *Pool 1 Scenario 1* - I am just going to let this one set idol for the day to see if we lose any connections.
 *Pool 2* *Scenario 2*- I am going to shut down the sovrin-node service on one node for 5 minutes and not send any transactions. After 5 minutes I will start the service again and send some transactions.
 *Pool 3* *Scenario 3*- I am going to send one ""send NYM"" transaction every 15 seconds so 4 per minute for 48 hours. I will check about every 5 hours to see how it is going.

*{color:#333333}Results on Pool 2 Scenario 2{color}*
 * Run 20 transactions on Pool 2 successfully to all nodes.
 * Shut down the sovrin-node service on Node 4 for 5 minutes.
 * Do not send any transactions
 * Now start the sovrin-node service on Node 4
 * Send 10 transactions

{color:#FF0000}At this point when I went to send the 10 transactions I found I was only connected to Node 4. During the 5 minutes I had the sovrin-node service shut off on Node 4 the other 3 nodes disconnected.{color}

{color:#14892c}Workaround was to restart the sovrin-node service on all 4 nodes. Once I did that I was able to send more transactions.{color}

I have added the log files for the issue on the Pool 2 scenario. They are named Node1_ServiceShutDown.log and so on for all 4 nodes.;;;","04/Jun/17 6:12 AM;krw910;I reproduced scenario 2 in a global pool setup with 4 nodes and 1 client. 
 This time when I first setup the nodes the client could connect to the pool, but NYMs could not be added. 
 I restarted all the nodes and then I was able to add NYMs.

I sent 20 transactions and confirmed that all nodes were in sync.
 I then shut the sovrin-node service off on Node 4 for 5 minutes.
 I did not perform any transactions.
 After 5 minutes I started the sovrin-node service on Node 4.
 At this point I tried to send transactions and was only able to connect with Node 4 from the Client. Nodes 1-3 were disconnected.

I am leaving that pool in the current state and will email the connection information.;;;","05/Jun/17 3:40 AM;ashcherbakov;Looks like we had the following problems:

*     A node can not process txns after it’s disconnected and re-connected (catch-up is ok, but new reqs are not ordered)
    FIXED in https://github.com/evernym/plenum/pull/201 - MERGED into plenum master

*     A node can not process txns after it’s demoted and added back (catch-up is ok, but new reqs are not ordered)
    FIXED in https://github.com/evernym/plenum/pull/201 - MERGED into plenum master

*     Connection problems after a node is demoted and added back
    FIXED in https://github.com/evernym/plenum/pull/201 - MERGED into plenum master

*     Connection problems after a node is disconnected and re-connected back
    IDEA: https://github.com/evernym/stp/tree/fix-re-connection
        Added reconnection tests https://github.com/evernym/stp/blob/fix-re-connection/stp_zmq/test/test_reconnect.py - test_reconnect_long FAILS on teh current master
        If I always re-connect (https://github.com/evernym/stp/blob/fix-re-connection/stp_zmq/zstack.py#L1173), then the test starts passing.
        Try to send ping if socket is not closed for a limited number of times only. Close the socket after if sending ping failed for X times.

TODO:

#     Create an RC build with the fixes (Andrey G.):
        Merge https://github.com/evernym/plenum/pull/201 - DONE
        Pin versions
        Merge to Stable branch
        Create an RC
#    Fix Issue 4 (disconnection) (Victor):
        Try to send ping if socket is not closed for a limited number of times only. Close the socket after if sending ping failed for X times.
        Make sure that https://github.com/evernym/stp/blob/fix-re-connection/stp_zmq/test/test_reconnect.py  tests pass


;;;","05/Jun/17 10:56 PM;ashcherbakov;Fixed in RC buils:
- sovrin-node==0.3.17
- sovrin-client==0.3.19;;;","06/Jun/17 2:16 AM;spivachuk;Tried to reproduce the issue with lost connections to nodes (Pool 2 Scenario 2 from the comments to this ticket) on a local pool generated by Vagrant script for the latest deb packages of sovrin-node and sovrin-client from ""xenial master"" APT repositories:
* The issue is not reproduced for the case when one node is stopped and then started.
* The issue is not reproduced for the case when one node is blacklisted and then enabled back.;;;","06/Jun/17 1:05 PM;krw910;As this ticket is written dealing with demoting a node I have to set this blocked. In the latest RC build we cannot demote a node. I have reopened INDY-9 which is blocking this ticket.;;;","06/Jun/17 6:15 PM;ashcherbakov;Problem reason: 
- Issue1:
The nodes didn't disconnect suspended (demoted) node - FIXED
- Issue2:
lats_ordere_pp_seq_no wasn't set for a replica after catch-up, that's why cought-up node didn't receive any new txns - FIXED
- Issue3:
We didn't close connection (socket) for disconnected Nodes, and sent pings - FIXED

Covered with tests:
- https://github.com/evernym/plenum/blob/master/plenum/test/node_catchup/test_catchup_demoted.py
- https://github.com/evernym/plenum/blob/master/plenum/test/node_catchup/test_node_catchup_after_disconnect.py
- https://github.com/evernym/stp/blob/master/stp_zmq/test/test_reconnect.py
;;;","10/Jun/17 2:37 AM;aleksey-roldugin;h6. build
sovrin-node 0.3.19

h6. verification
- Scenario 1 (added nodes stop making catch up after demotion-promotion) is verified.
- Scenario 2 (nodes didn't perform catch up after adding) is verified.
- Scenario 3 (node didn't perform catch up after stop-start sovrin-node.service) is reproduced again and moved to separate ticket [INDY-191|https://jira.hyperledger.org/browse/INDY-191]. It also linked with [INDY-159|https://jira.hyperledger.org/browse/INDY-159].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need devops fix of SOV-1131,INDY-146,17419,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,danielhardman,danielhardman,03/Jun/17 6:24 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,1.5,,,0,Must,,,,,"repo.sovrin.org needs some reconfiguration; needs to be handled by sysadmins that own the box",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1rj:",,,,,,H5,,,,,,,,,,,,,,,,,,,,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 1:22 PM;danielhardman;This is just a ticket to track a vulnerability that's being fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test_all_replicas_hold_request_keys fails on Jenkins,INDY-147,17470,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ashcherbakov,ashcherbakov,05/Jun/17 6:47 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy20v:",,,,,,H4,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,lovesh,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 5:37 AM;stevetolman;Alex, what are the consequences of this? Is it disabled? How important is this test?;;;","30/Jun/17 4:17 PM;lovesh;[~stevetolman] This was fixed as part of changes for INDY-13 and is present in master;;;","12/Jul/17 2:13 PM;krw910;I have verfied this test ran in the last good build of plenum and is enabled. The test is located [here|https://github.com/hyperledger/indy-plenum/blob/f1b737136632862df8ea87b6aa5f706ea5d67675/plenum/test/node_request/test_request_forwarding.py];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node crashed during the startup catchup if run with ledger file deleted,INDY-148,17472,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,dsurnin,dsurnin,05/Jun/17 7:09 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"install client and node in one machine from rc repo;

run 4 nodes locally as described https://github.com/sovrin-foundation/sovrin-node/blob/master/docs/Sovrin_Running_Locally.md;

run load_test.py to generate transactions;

on running node1 delete ledger file 

~/.sovrin/data/nodes/Node1/transactions_sandbox/1

stop and rerun node1;

have crash log like this
{code:java}
2017-06-05 12:51:14,849 | DEBUG | ledger_manager.py ( 416) | processCatchupRep | Node1 found 104 transactions in the catchup from Node2
2017-06-05 12:51:14,849 | DEBUG | ledger_manager.py ( 433) | processCatchupRep | Node1 merging all received catchups
2017-06-05 12:51:14,849 | DEBUG | ledger_manager.py ( 439) | processCatchupRep | Node1 merged catchups, there are 207 of them now, from 105 to 311
2017-06-05 12:51:14,849 | DEBUG | ledger_manager.py ( 447) | processCatchupRep | Node1 processed 0 catchup replies with sequence numbers []
2017-06-05 12:51:14,854 | TRACE | zstack.py ( 611) | _receiveFromListener | Node1 got 1 messages through listener
2017-06-05 12:51:14,858 | DEBUG | node.py (1190) | validateNodeMsg | Node1 received node message from Node4: CATCHUP_REP(ledgerId=1, txns={'29': {'txnTime': None, 'signature': '4iGGY5rCMBsUcCR1Uu1XypMqrZKk92B2B9BebGFEuwJhA3pXYAAogUySCUjVtC1KTw7UuPjgQYmKisJvvpjyZMFK', 'reqId': 1496413055063127, 'hash': None, 'verkey': '2Rxwpp75WXypqkuwbzhBvEXKTzwUG6Q6w1eJhUSuXnrz', 'enc': None, 'identifier': 'FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4', 'alias': None, 'type': '1', 'ref': None, 'raw': None, 'data': None, 'role': '101', 'dest': '2Rxwpp75WXypqkuwbzhBvEXKTzwUG6Q6w1eJhUSuXnrz', 'signature_type': None},...
2017-06-05 12:51:14,865 | INFO | node.py (1149) | handleOneNodeMsg | Node1 msg validated ({'ledgerId': 1, 'txns': {'29': {'txnTime': None, 'signature': '4iGGY5rCMBsUcCR1Uu1XypMqrZKk92B2B9BebGFEuwJhA3pXYAAogUySCUjVtC1KTw7UuPjgQYmKisJvvpjyZMFK', 'reqId': 1496413055063127, 'hash': None, 'verkey': '2Rxwpp75WXypqkuwbzhBvEXKTzwUG6Q6w1eJhUSuXnrz', 'enc': None, 'identifier': 'FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4', 'alias': None, 'type': '1', 'ref': None, 'raw': None, 'data': None, 'role': '101', 'dest': '2Rxwpp75WXypqkuwbzhBvEXKTzwUG6Q6w1eJhUSuXnrz', 'signature_type': None},...
2017-06-05 12:51:14,866 | DEBUG | node.py (1216) | postToNodeInBox | Node1 appending to nodeInbox CATCHUP_REP(ledgerId=1, txns={'29': {'txnTime': None, 'signature': '4iGGY5rCMBsUcCR1Uu1XypMqrZKk92B2B9BebGFEuwJhA3pXYAAogUySCUjVtC1KTw7UuPjgQYmKisJvvpjyZMFK', 'reqId': 1496413055063127, 'hash': None, 'verkey': '2Rxwpp75WXypqkuwbzhBvEXKTzwUG6Q6w1eJhUSuXnrz', 'enc': None, 'identifier': 'FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4', 'alias': None, 'type': '1', 'ref': None, 'raw': None, 'data': None, 'role': '101', 'dest': '2Rxwpp75WXypqkuwbzhBvEXKTzwUG6Q6w1eJhUSuXnrz', 'signature_type': None},...
2017-06-05 12:51:14,867 | DEBUG | ledger_manager.py ( 411) | processCatchupRep | Node1 received catchup reply from Node4: CATCHUP_REP(ledgerId=1, txns={'29': {'txnTime': None, 'signature': '4iGGY5rCMBsUcCR1Uu1XypMqrZKk92B2B9BebGFEuwJhA3pXYAAogUySCUjVtC1KTw7UuPjgQYmKisJvvpjyZMFK', 'reqId': 1496413055063127, 'hash': None, 'verkey': '2Rxwpp75WXypqkuwbzhBvEXKTzwUG6Q6w1eJhUSuXnrz', 'enc': None, 'identifier': 'FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4', 'alias': None, 'type': '1', 'ref': None, 'raw': None, 'data': None, 'role': '101', 'dest': '2Rxwpp75WXypqkuwbzhBvEXKTzwUG6Q6w1eJhUSuXnrz', 'signature_type': None},...
2017-06-05 12:51:14,925 | DEBUG | ledger_manager.py ( 416) | processCatchupRep | Node1 found 104 transactions in the catchup from Node4
2017-06-05 12:51:14,925 | DEBUG | ledger_manager.py ( 433) | processCatchupRep | Node1 merging all received catchups
2017-06-05 12:51:14,926 | DEBUG | ledger_manager.py ( 439) | processCatchupRep | Node1 merged catchups, there are 311 of them now, from 1 to 311
2017-06-05 12:51:14,935 | DEBUG | ledger_manager.py ( 543) | hasValidCatchupReplies | Node1 verifying proof for 104, 311, b'z{\x86\xc8u\x08ZU\x02\x81\xbf\xad\x90Uj@\x07m2uI\xc0mmr\x84\xca\x1f3\xb9L:', b's\xe6\xb4M\xd8\x03\xfd\x7f\xae\xf3E\x918j\xa5\xfd\xc9,`\x06\x9d\xe8\x8b]x\xdb\x198\x16\x82xl', [b'\x997YT\xabB\xc7B\xcb?\xb4\x90S\xf0\xd3\xbb\xd5\xe8W\x19\xaa\xb47\x99\to\x1fv\xb4\xe5\x99\x1a', b""Y\xfd`\xc0\x1bl\x8f\xaf\xdf\xdb\xe3'\x89\xff\x83\xda.0\xd6\x1b\xce\x11J\x93O\xfe,\xaf\xc7\x07\x87U"", b"")\xcb\x80\xf0k\xa7\x97\xda\xa0\xef\xc8\x8a\xef,\xa0\xb9PT\xdbE\xfa\xa3'\xf3\xd0H\x17 rb\x1f{"", b'\x0fX\xcb\x1e/\xee\xb0;I8Fb\xb3aO\xca\xd7\xd9c\xb9\x03>\x93gQ&\x1d\xe2\x9b\xa1\x12\x19', b'K*\x84]\xb5aq\x82\xba\xf5\x0fv\xa5\x84\x8aw""\x96+\x89\xba\xc1\xe7\xe7\r\x1c\x0bd\xe7b\x86\xb7', b'\xfe\xc9\xf1\xf2\xb1\x941t\xe8\x9a\xd7\x85r\xe5O\x0c\x82\x07\xf3T-8\x10J\x11FJL\xafd\xbe\x05', b""9wC\x879\xeaC\x90z\xabs\x0f\xfaY{\xca\xd3\xcc\xc6>A8'_\xcd.\x14\\\x8csv\xe1""]
2017-06-05 12:51:14,954 | WARNING | base_events.py (1308) | _run_once | Executing <Task finished coro=<Looper.runForever() done, defined at /usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py:213> exception=AttributeError(""'NoneType' object has no attribute 'encode'"",)> took 0.319 seconds
2017-06-05 12:51:14,954 | INFO | looper.py ( 267) | shutdown | Looper shutting down now...
Traceback (most recent call last):
 File ""/usr/local/bin/start_sovrin_node"", line 49, in <module>
 looper.run()
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 284, in __exit__
 self.shutdownSync()
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 280, in shutdownSync
 self.loop.run_until_complete(self.shutdown())
 File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
 return future.result()
 File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
 raise self._exception
 File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
 result = coro.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 270, in shutdown
 await self.runFut
 File ""/usr/lib/python3.5/asyncio/futures.py"", line 363, in __iter__
 return self.result() # May raise too.
 File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
 raise self._exception
 File ""/usr/local/bin/start_sovrin_node"", line 49, in <module>
 looper.run()
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 254, in run
 return self.loop.run_until_complete(what)
 File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
 return future.result()
 File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
 raise self._exception
 File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
 result = coro.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 218, in runForever
 await self.runOnceNicely()
 File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
 return self.gen.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 202, in runOnceNicely
 msgsProcessed = await self.prodAllOnce()
 File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
 return self.gen.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 147, in prodAllOnce
 s += await n.prod(limit)
 File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
 return self.gen.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 348, in prod
 c = await super().prod(limit)
 File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
 return self.gen.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 649, in prod
 c += await self.serviceNodeMsgs(limit)
 File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
 return self.gen.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 684, in serviceNodeMsgs
 await self.processNodeInBox()
 File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
 return self.gen.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1226, in processNodeInBox
 await self.nodeMsgRouter.handle(m)
 File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
 return self.gen.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/router.py"", line 63, in handle
 res = self.handleSync(msg)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/router.py"", line 52, in handleSync
 return self.getFunc(msg[0])(*msg)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/common/ledger_manager.py"", line 442, in processCatchupRep
 catchUpReplies)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/common/ledger_manager.py"", line 476, in _processCatchupReplies
 ledgerInfo.postTxnAddedToLedgerClbk(ledgerId, txn)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1414, in postTxnFromCatchupAddedToLedger
 self.updateSeqNoMap([txn])
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1899, in updateSeqNoMap
 txn[F.seqNo.name]) for txn in committedTxns)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/persistence/req_id_to_txn.py"", line 28, in addBatch
 for identifier, reqId, seqNo in batch])
 File ""/usr/local/lib/python3.5/dist-packages/plenum/persistence/req_id_to_txn.py"", line 28, in <listcomp>
 for identifier, reqId, seqNo in batch])
 File ""/usr/local/lib/python3.5/dist-packages/plenum/persistence/req_id_to_txn.py"", line 18, in getKey
 h.update(identifier.encode())
AttributeError: 'NoneType' object has no attribute 'encode'{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0p3:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/17 6:16 AM;krw910;With ledger serialization this is no longer a valid ticket.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
input validation test: a record in the database is corrupted,INDY-149,17473,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,05/Jun/17 7:18 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"{quote}suppose a record in the database is corrupted (e.g., a sector of the disk is bad, so certain records cause a read failure). What happens to a running sovrin-node process that attempts to read from that part of the database?
{quote}
 

See 3.a [https://docs.google.com/document/d/1ae6Ud64gUjl-YC3ADDU5KuW_A-kPS9l9g6FGJCylFCs/edit]

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-243,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1a7:",,,,,,H1,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jun/17 2:34 AM;alexander.shekhovcov;Ubuntu 16.04 VM 

*Steps:*
 # create LVM disk [https://wiki.ubuntu.com/Lvm]
 # set flakey mode for the lvm disk

{code:java}
sudo dmsetup load /dev/mapper/g1-d1 --table '0 2097152 flakey 8:5 2048 1 1'{code}
3. try to remount the disk and restart the node until the flakey behavioral has appeared 
{code:java}
sudo umount /dev/mapper/g1-d1 &&  sudo mount /dev/mapper/g1-d1 /home/sovrin/.sovrin/data/nodes/Node1/transactions_sandbox/ && sudo systemctl restart sovrin-node{code}
 

*Result:*

The node failed the startup procedure with exception:
{code:java}
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: Traceback (most recent call last):
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/bin/start_sovrin_node"", line 47, in <module>
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: cliha=cliha)
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 81, in __init__
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: config=self.config)
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 149, in __init__
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: self.primaryStorage = storage or self.getPrimaryStorage()
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 123, in getPrimaryStorage
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: defaultFile=defaultTxnFile)
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/plenum/common/ledger.py"", line 26, in __init__
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: super().__init__(*args, **kwargs)
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 61, in __init__
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: self.start()
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 210, in start
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: self.defaultFile)
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/plenum/common/ledger.py"", line 23, in _defaultStore
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: defaultFile=defaultFile)
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/chunked_file_store.py"", line 73, in __init__
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: self._initDB(dbDir, dbName)
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/chunked_file_store.py"", line 95, in _initDB
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: self._useLatestChunk()
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/chunked_file_store.py"", line 101, in _useLatestChunk
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: self._useChunk(self._findLatestChunk())
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/chunked_file_store.py"", line 137, in _useChunk
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: self.itemNum = self.currentChunk.numKeys + 1
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/file_store.py"", line 191, in numKeys
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: return sum(1 for l in self.iterator())
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/file_store.py"", line 155, in iterator
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: lines = self._getLines()
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/text_file_store.py"", line 31, in _getLines
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: return list(store_utils.cleanLines(self.dbFile))
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/store_utils.py"", line 11, in <genexpr>
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: return (line for line in stripped if len(line) != 0)
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/store_utils.py"", line 10, in <genexpr>
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: stripped = (line.strip(lineSep) for line in source)
июн 09 20:25:13 sovrin-node1 start_sovrin_node[4285]: OSError: [Errno 5] Input/output error
{code}
 

 

 ;;;","16/Jun/17 7:56 AM;danielhardman;[~alexander.shekhovcov]: This is a great discovery. Please create a new ticket that says ""fix the ledger so a corrupt database record doesn't prevent the service from starting"". Then you can move this ticket to Customer Validation and I will clear it out.

success criteria for the new ticket: either the service runs with a corrupted record (simply failing to retrieve that record with a graceful error) --or, if the database is too damaged to use, the service exits with a graceful error and says something like this to the log and the screen: ""The database is corrupt. To fix the problem, delete the database and rebuild."";;;","16/Jun/17 9:48 PM;alexander.shekhovcov;The new ticket https://jira.hyperledger.org/browse/INDY-243;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node crash with corrupted pool ledger file,INDY-150,17478,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,dsurnin,dsurnin,05/Jun/17 10:31 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"install client and node in one machine from rc repo;

run 4 nodes locally as described [https://github.com/sovrin-foundation/sovrin-node/blob/master/docs/Sovrin_Running_Locally.md];

on running node1 change pool ledger file 

~.sovrin/data/nodes/Node1/pool_transactions_sandbox/1

edit some base58 field - add character '#' to the field

stop and rerun node1;

have crash log like this
{code:java}
$ start_sovrin_node Node2 9703 9704
2017-06-05 16:30:19,986 | INFO | log.py ( 79) | setupRaet | Setting RAET log level 2
2017-06-05 16:30:20,000 | DEBUG | start_sovrin_node ( 38) | <module> | You can find logs in /home/tmh/.sovrin/Node2.log
2017-06-05 16:30:20,000 | DEBUG | start_sovrin_node ( 41) | <module> | Sovrin related env vars: []
2017-06-05 16:30:21,237 | DEBUG | __init__.py ( 59) | register | Registered VCS backend: git
2017-06-05 16:30:21,291 | DEBUG | __init__.py ( 59) | register | Registered VCS backend: hg
2017-06-05 16:30:21,358 | DEBUG | __init__.py ( 59) | register | Registered VCS backend: svn
2017-06-05 16:30:21,359 | DEBUG | __init__.py ( 59) | register | Registered VCS backend: bzr
2017-06-05 16:30:21,973 | DEBUG | selector_events.py ( 53) | __init__ | Using selector: EpollSelector
2017-06-05 16:30:21,974 | DEBUG | looper.py ( 123) | __init__ | Setting handler for SIGINT
2017-06-05 16:30:21,995 | DEBUG | ledger.py ( 203) | start | Starting ledger...
2017-06-05 16:30:22,000 | DEBUG | file_store.py ( 176) | appendNewLineIfReq | new line check for file: /home/tmh/.sovrin/data/nodes/Node2/transactions_sandbox/1
2017-06-05 16:30:22,000 | DEBUG | file_store.py ( 185) | appendNewLineIfReq | new line added for file: /home/tmh/.sovrin/data/nodes/Node2/transactions_sandbox/1
2017-06-05 16:30:22,001 | DEBUG | ledger.py ( 96) | recoverTree | Recovering tree from transaction log
2017-06-05 16:30:22,182 | DEBUG | ledger.py ( 102) | recoverTree | Recovered tree from transaction log in 0.18086004903307185 seconds
2017-06-05 16:30:22,192 | DEBUG | idr_cache.py ( 25) | __init__ | Initializing identity cache Node2
2017-06-05 16:30:22,220 | DEBUG | ledger.py ( 203) | start | Starting ledger...
2017-06-05 16:30:22,221 | DEBUG | file_store.py ( 176) | appendNewLineIfReq | new line check for file: /home/tmh/.sovrin/data/nodes/Node2/pool_transactions_sandbox/1
2017-06-05 16:30:22,221 | DEBUG | file_store.py ( 185) | appendNewLineIfReq | new line added for file: /home/tmh/.sovrin/data/nodes/Node2/pool_transactions_sandbox/1
2017-06-05 16:30:22,221 | DEBUG | ledger.py ( 96) | recoverTree | Recovering tree from transaction log
2017-06-05 16:30:22,233 | DEBUG | ledger.py ( 102) | recoverTree | Recovered tree from transaction log in 0.011491347977425903 seconds
2017-06-05 16:30:22,235 | INFO | looper.py ( 267) | shutdown | Looper shutting down now...
2017-06-05 16:30:22,247 | INFO | looper.py ( 274) | shutdown | Looper shut down in 0.011 seconds.
Traceback (most recent call last):
 File ""/usr/local/bin/start_sovrin_node"", line 47, in <module>
 cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 80, in __init__
 config=self.config)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 163, in __init__
 self.initPoolManager(nodeRegistry, ha, cliname, cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 101, in initPoolManager
 HasPoolManager.__init__(self, nodeRegistry, ha, cliname, cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/pool_manager.py"", line 12, in __init__
 cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/pool_manager.py"", line 23, in __init__
 super().__init__(node=node, ha=ha, cliname=cliname, cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/pool_manager.py"", line 75, in __init__
 cliname=cliname, cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/pool_manager.py"", line 115, in getStackParamsAndNodeReg
 nodeReg, cliNodeReg, nodeKeys = self.parseLedgerForHaAndKeys(self.ledger)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stack_manager.py"", line 91, in parseLedgerForHaAndKeys
 verkey = cryptonymToHex(txn[TARGET_NYM])
 File ""/usr/local/lib/python3.5/dist-packages/plenum/common/util.py"", line 317, in cryptonymToHex
 return hexlify(base58.b58decode(cryptonym.encode()))
 File ""/usr/local/lib/python3.5/dist-packages/base58.py"", line 66, in b58decode
 acc += p * alphabet.index(c)
ValueError: substring not found{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/17 10:17 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11091/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8av:",,,,,,H1,H2,H3,M1 Prelude,,,,,,,,,,,,,,,,,DouglasWightman,dsurnin,lovesh,ozheregelya,ryanmarsh,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jun/17 3:36 PM;lovesh;If its just the node that crashed, it's lower priority problem. We do not need to guard against people arbitrarily messing up data/configuration on their machines.;;;","15/Jun/17 5:50 AM;stevetolman;Mark, please invite Doug to help you with this code review.;;;","15/Jun/17 6:05 AM;mark.hadley;Code reviewed with Doug.;;;","15/Jun/17 10:18 PM;VladimirWork;There is no info about build version with this fix. Bug is still reproducing on the latest master (0.3.139).;;;","21/Jun/17 6:05 AM;stevetolman;Let us know when this is merged into master and ready to build.;;;","23/Jun/17 5:45 AM;mark.hadley;[~DouglasWightman]: I assigned to you. The PR failed.;;;","30/Jun/17 5:27 PM;lovesh;[~danielhardman] [~krw910] I think building guards against people arbitrarily messing up data/configuration on their machines is a lower priority issue, but i would suggest a general solution to the problem where every data store has an integrity check, if that fails we take appropriate action.;;;","30/Jun/17 11:36 PM;DouglasWightman;Based on a discussion today with [~danielhardman] I will rework this patch so that a corruption in the pool ledger stops the node and prints out an actionable error message.;;;","06/Jul/17 6:06 AM;stevetolman;Mark, please review this ticket/PR. You can ask Daniel to do the actual merge when the review is complete.;;;","13/Jul/17 1:34 AM;ozheregelya;*Build Info:*
  sovrin-client version: 0.4.26
  sovrin-node version: 0.4.19

OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client running locally.

Reason for Reopen:
Initial problem still reproduces.

Case 1:
Invalid character in dest field.
Steps to Reproduce:
1. Configure nodes to running locally.
2. Change .sovrin/data/nodes/Node1/pool_transactions_sandbox/1 to following:
{code:java}
{""data"":{""alias"":""Node1"",""client_ip"":""127.0.0.1"",""client_port"":9702,""node_ip"":""127.0.0.1"",""node_port"":9701,""services"":[""VALIDATOR""]},""dest"":""#w6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"",""identifier"":""Th7#pTaRZVRYnPiabds81Y"",""txnId"":""fea82e10e894419fe2bea7d96296a6d46f50f93f9eeda954ec461b2ed2950b62"",""type"":""0""}
{""data"":{""alias"":""Node2"",""client_ip"":""127.0.0.1"",""client_port"":9704,""node_ip"":""127.0.0.1"",""node_port"":9703,""services"":[""VALIDATOR""]},""dest"":""8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb"",""identifier"":""EbP4aYNeTHL6q385GuVpRV"",""txnId"":""1ac8aece2a18ced660fef8694b61aac3af08ba875ce3026a160acbc3a3af35fc"",""type"":""0""}
{""data"":{""alias"":""Node3"",""client_ip"":""127.0.0.1"",""client_port"":9706,""node_ip"":""127.0.0.1"",""node_port"":9705,""services"":[""VALIDATOR""]},""dest"":""DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya"",""identifier"":""4cU41vWW82ArfxJxHkzXPG"",""txnId"":""7e9f355dffa78ed24668f0e0e369fd8c224076571c51e2ea8be5f26479edebe4"",""type"":""0""}
{""data"":{""alias"":""Node4"",""client_ip"":""127.0.0.1"",""client_port"":9708,""node_ip"":""127.0.0.1"",""node_port"":9707,""services"":[""VALIDATOR""]},""dest"":""4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA"",""identifier"":""TWwCRQRZ2ZHMJFn9TzLp7W"",""txnId"":""aa5e817d7cc626170eca175822029339a444eb0ee8f0bd20d3b0b76e566fb008"",""type"":""0""}{code}
3. Try to start node.

 

*Actual Results:*
Following traceback is shown in console:
{code:java}
sovrin@sovrin-VirtualBox:~$ start_sovrin_node Node1 9701 9702
2017-07-12 18:37:21,753 | INFO | log.py ( 79) | setupRaet | Setting RAET log level 2
2017-07-12 18:37:34,666 | INFO | looper.py ( 267) | shutdown | Looper shutting down now...
2017-07-12 18:37:34,700 | INFO | looper.py ( 274) | shutdown | Looper shut down in 0.029 seconds.
Traceback (most recent call last):
 File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stack_manager.py"", line 96, in parseLedgerForHaAndKeys
 verkey = cryptonymToHex(txn[TARGET_NYM])
 File ""/usr/local/lib/python3.5/dist-packages/plenum/common/util.py"", line 287, in cryptonymToHex
 return hexlify(base58.b58decode(cryptonym.encode()))
 File ""/usr/local/lib/python3.5/dist-packages/base58.py"", line 66, in b58decode
 acc += p * alphabet.index(c)
ValueError: substring not found
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
 File ""/usr/local/bin/start_sovrin_node"", line 48, in <module>
 cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 83, in __init__
 config=self.config)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 152, in __init__
 self.initPoolManager(nodeRegistry, ha, cliname, cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 103, in initPoolManager
 HasPoolManager.__init__(self, nodeRegistry, ha, cliname, cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/pool_manager.py"", line 12, in __init__
 cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/pool_manager.py"", line 23, in __init__
 super().__init__(node=node, ha=ha, cliname=cliname, cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/pool_manager.py"", line 118, in __init__
 cliname=cliname, cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/pool_manager.py"", line 158, in getStackParamsAndNodeReg
 nodeReg, cliNodeReg, nodeKeys = self.parseLedgerForHaAndKeys(self.ledger)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stack_manager.py"", line 98, in parseLedgerForHaAndKeys
 raise ValueError(""Invalid verkey. Rebuild pool transactions."")
ValueError: Invalid verkey. Rebuild pool transactions.
{code}
 

*Expected Results:*
Traceback should not be shown, human readable error should logged to log file.

*Case 2:*
Invalid character out of any field.
Steps to Reproduce:
1. Configure nodes to running locally.
2. Change .sovrin/data/nodes/Node1/pool_transactions_sandbox/1 to following:
{code:java}
{""data"":{""alias"":""Node1"",""client_ip"":""127.0.0.1"",""client_port"":9702,""node_ip"":""127.0.0.1"",""node_port"":9701,""services"":[""VALIDATOR""]},""dest"":#""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"",""identifier"":""Th7MpTaRZVRYnPiabds81Y"",""txnId"":""fea82e10e894419fe2bea7d96296a6d46f50f93f9eeda954ec461b2ed2950b62"",""type"":""0""}
{""data"":{""alias"":""Node2"",""client_ip"":""127.0.0.1"",""client_port"":9704,""node_ip"":""127.0.0.1"",""node_port"":9703,""services"":[""VALIDATOR""]},""dest"":""8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb"",""identifier"":""EbP4aYNeTHL6q385GuVpRV"",""txnId"":""1ac8aece2a18ced660fef8694b61aac3af08ba875ce3026a160acbc3a3af35fc"",""type"":""0""}
{""data"":{""alias"":""Node3"",""client_ip"":""127.0.0.1"",""client_port"":9706,""node_ip"":""127.0.0.1"",""node_port"":9705,""services"":[""VALIDATOR""]},""dest"":""DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya"",""identifier"":""4cU41vWW82ArfxJxHkzXPG"",""txnId"":""7e9f355dffa78ed24668f0e0e369fd8c224076571c51e2ea8be5f26479edebe4"",""type"":""0""}
{""data"":{""alias"":""Node4"",""client_ip"":""127.0.0.1"",""client_port"":9708,""node_ip"":""127.0.0.1"",""node_port"":9707,""services"":[""VALIDATOR""]},""dest"":""4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA"",""identifier"":""TWwCRQRZ2ZHMJFn9TzLp7W"",""txnId"":""aa5e817d7cc626170eca175822029339a444eb0ee8f0bd20d3b0b76e566fb008"",""type"":""0""}{code}
3. Try to start node.

 

*Actual Results:*
Following traceback is shown in console:
{code:java}
sovrin@sovrin-VirtualBox:~$ start_sovrin_node Node1 9701 97022017-07-12 18:58:41,538 | INFO | log.py ( 79) | setupRaet | Setting RAET log level 2
2017-07-12 18:58:46,227 | INFO | looper.py ( 267) | shutdown | Looper shutting down now...
2017-07-12 18:58:46,238 | INFO | looper.py ( 274) | shutdown | Looper shut down in 0.010 seconds.
Traceback (most recent call last):
 File ""/usr/local/bin/start_sovrin_node"", line 48, in <module>
 cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 83, in __init__
 config=self.config)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 152, in __init__
 self.initPoolManager(nodeRegistry, ha, cliname, cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 103, in initPoolManager
 HasPoolManager.__init__(self, nodeRegistry, ha, cliname, cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/pool_manager.py"", line 12, in __init__
 cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/pool_manager.py"", line 23, in __init__
 super().__init__(node=node, ha=ha, cliname=cliname, cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/pool_manager.py"", line 118, in __init__
 cliname=cliname, cliha=cliha)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/pool_manager.py"", line 158, in getStackParamsAndNodeReg
 nodeReg, cliNodeReg, nodeKeys = self.parseLedgerForHaAndKeys(self.ledger)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stack_manager.py"", line 79, in parseLedgerForHaAndKeys
 for _, txn in ledger.getAllTxn():
 File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 213, in getAllTxn
 for seq_no, txn in self._transactionLog.get_range(frm, to))
 File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 213, in <genexpr>
 for seq_no, txn in self._transactionLog.get_range(frm, to))
 File ""/usr/local/lib/python3.5/dist-packages/ledger/serializers/json_serializer.py"", line 75, in deserialize
 return self.loads(data)
 File ""/usr/local/lib/python3.5/dist-packages/ledger/serializers/json_serializer.py"", line 65, in loads
 return json.loads(data)
 File ""/usr/lib/python3.5/json/__init__.py"", line 319, in loads
 return _default_decoder.decode(s)
 File ""/usr/lib/python3.5/json/decoder.py"", line 339, in decode
 obj, end = self.raw_decode(s, idx=_w(s, 0).end())
 File ""/usr/lib/python3.5/json/decoder.py"", line 355, in raw_decode
 obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 134 (char 133){code}
 

*Expected Results:*
Traceback should not be shown, node should be stopped, human readable error should logged to log file.

*Case 3:*
Invalid characters in identifier field.
Steps to Reproduce:
1. Configure nodes to running locally.
2. Change .sovrin/data/nodes/Node1/pool_transactions_sandbox/1 to following:
{code:java}
{""data"":{""alias"":""Node1"",""client_ip"":""127.0.0.1"",""client_port"":9702,""node_ip"":""127.0.0.1"",""node_port"":9701,""services"":[""VALIDATOR""]},""dest"":""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"",""identifier"":""Th7MpTaRZVRYnPiabds81Y"",""txnId"":""fea82e10e894419fe2bea7d96296a6d46f50f93f9eeda954ec461b2ed2950b62"",""type"":""0""}
{""data"":{""alias"":""Node2"",""client_ip"":""127.0.0.1"",""client_port"":9704,""node_ip"":""127.0.0.1"",""node_port"":9703,""services"":[""VALIDATOR""]},""dest"":""8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb"",""identifier"":""EbP4aYNeTHL6q385GuVpRV"",""txnId"":""1ac8aece2a18ced660fef8694b61aac3af08ba875ce3026a160acbc3a3af35fc"",""type"":""0""}
{""data"":{""alias"":""Node3"",""client_ip"":""127.0.0.1"",""client_port"":9706,""node_ip"":""127.0.0.1"",""node_port"":9705,""services"":[""VALIDATOR""]},""dest"":""DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya"",""identifier"":""4cU41vWW82ArfxJxHkzXPG"",""txnId"":""7e9f355dffa78ed24668f0e0e369fd8c224076571c51e2ea8be5f26479edebe4"",""type"":""0""}
{""data"":{""alias"":""Node4"",""client_ip"":""127.0.0.1"",""client_port"":9708,""node_ip"":""127.0.0.1"",""node_port"":9707,""services"":[""VALIDATOR""]},""dest"":""4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA"",""identifier"":""TW#CRQRZ2ZHMJFn9TzLp7W"",""txnId"":""aa5e817d7cc626170eca175822029339a444eb0ee8f0bd20d3b0b76e566fb008"",""type"":""0""}{code}
3. Try to start node.

 

*Actual Results:*
Node works without any issues.

*Expected Results:*
Expected behavior is unclear. Is it correct behavior that the node works with invalid pool_transactions_sandbox file?

 

 

*Additional Information:*
Expected ** Results were described based on discussion with [~dsurnin].
Please, let us know if implemented behavior will differ from described in Expected Results.;;;","25/Jul/17 12:28 AM;ryanmarsh;Kelly says that he wants this behavior with any of the mentioned cases: 
1-The nodes still starts up
2-We give a message, probably a warning, in the log file showing there is a problem with the ledger file.
3-The node checks with the other nodes and sees its file is incorrect or corrupt so it syncs with the pool and corrects the entry.

 

The question I have is, if node1 starts up with a corrupted file, where in the code can I trigger the event that Node1 checks with the other three nodes to see what they have in their ledgers so that it can sync up? I'm thinking that I'll call the processConsistencyProof function in ledger_manager.py but I'm not sure where the appropriate place to call that is. Any ideas/suggestions? ;;;","26/Jul/17 11:08 PM;ryanmarsh;Current Pull Request:  [https://github.com/hyperledger/indy-plenum/pull/306];;;","03/Aug/17 12:05 AM;ozheregelya;*Build Info:*
   indy-node 1.0.69
   indy-anoncreds 1.0.22
   indy-plenum 1.0.78
   sovrin 1.0.15
   python3-rlp 0.5.1
   python3-sha3 0.2.1
   python3-pyzmq 16.0.2
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 4 nodes (running locally), 1 client

*Case 1:*
 *Steps to Validate:*
 1. Configure nodes to running locally.
 2. Add invalid character to dest field in .sovrin/data/nodes/Node1/pool_transactions_sandbox/1.
 3. Try to start node.

*Actual Results:*
 2017-08-02 17:57:02,564 | INFO | looper.py ( 267) | shutdown | Looper shutting down now...
 2017-08-02 17:57:02,575 | INFO | looper.py ( 274) | shutdown | Looper shut down in 0.011 seconds.
 Invalid verkey. Rebuild pool transactions.

*Case 2:*
 *Steps to Validate:*
 1. Configure nodes to running locally.
 2. Add invalid character out of any field in .sovrin/data/nodes/Node1/pool_transactions_sandbox/1.
 3. Try to start node.

*Actual Results:*
 2017-08-02 18:01:08,444 | INFO | looper.py ( 267) | shutdown | Looper shutting down now...
 2017-08-02 18:01:08,456 | INFO | looper.py ( 274) | shutdown | Looper shut down in 0.012 seconds.
 Pool transaction file corrupted. Rebuild pool transactions.

*Case 3:*
 *Steps to Validate:*
 1. Configure nodes to running locally.
 2. Add invalid character to identifier field in .sovrin/data/nodes/Node1/pool_transactions_sandbox/1.
 3. Try to start node.

*Actual Results:*
 2017-08-02 18:02:59,275 | INFO | looper.py ( 267) | shutdown | Looper shutting down now...
 2017-08-02 18:02:59,287 | INFO | looper.py ( 274) | shutdown | Looper shut down in 0.012 seconds.
 Invalid identifier. Rebuild pool transactions.;;;","03/Aug/17 12:54 AM;ryanmarsh;Alex informed me that there is no way for the Node to recover when the initial file is corrupted. He said to display error message and terminate the process. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unexpected preprepare and commit messages for node with deleted pool ledger file,INDY-151,17480,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,dsurnin,dsurnin,05/Jun/17 10:39 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,shakedown1,should,,,,"install client and node in one machine from rc repo;

run 4 nodes locally as described [https://github.com/sovrin-foundation/sovrin-node/blob/master/docs/Sovrin_Running_Locally.md];

on running node1 delete pool ledger file 

~.sovrin/data/nodes/Node1/pool_transactions_sandbox/1

stop and rerun node1;

poll ledger file created with zero length;

node1 writes lots of ignore messages to the log;

run load_test.py;

it finishes ok;

however node1 writes preprepare and commit messages to log;

 

 

It needs to be validated, but it looks like the node1 cannot send messages to the other nodes, but receives commits.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jun/17 10:49 PM;dsurnin;log.txt;https://jira.hyperledger.org/secure/attachment/10923/log.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0pb:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/17 6:16 AM;krw910;This is no longer valid with the new ledger serialization.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool is not recovered after node restored,INDY-152,17481,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,dsurnin,dsurnin,05/Jun/17 10:52 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,shakedown1,should,,,,"install client and node in one machine from rc repo;

run 4 nodes locally as described [https://github.com/sovrin-foundation/sovrin-node/blob/master/docs/Sovrin_Running_Locally.md];

on running node1 and node2 delete pool ledger file 

~.sovrin/data/nodes/Node1/pool_transactions_sandbox/1

~.sovrin/data/nodes/Node2/pool_transactions_sandbox/1

stop and rerun node1 and node2;

run load_test.py - it fails as expected;

restore node2 pool ledger file

~.sovrin/data/nodes/Node2/pool_transactions_sandbox/1

rerun node2

run load_test.py - it fails again;",,,,,,,,,,,,,,,,,,,,,INDY-849,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0pj:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/17 6:20 AM;krw910;This is covered with INDY-849. The real issue is not with the pool ledger file it is with not being able to come back to consensus when the pool has dropped below f+1.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node cannot start after failure,INDY-153,17503,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,aleksey-roldugin,aleksey-roldugin,06/Jun/17 1:40 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,1.5,,,0,,,,,,"h6. BUILD:

sovrin-node 0.3.17
h6. STEPS TO REPRODUCE:
 # Make set up with 10 machines (4 nodes for genesis pool, 4 clients, 2 nodes for adding).
 # Add 2 nodes.
 # Check that they successfully performed catch up.
 # Perform some operations for adding NYM on client.

h6. Actual RESULT:
 - Node disconnects-connects-disconnects.
{code:java}
sovrin@test> new key with seed 0000000000000000000KellySteward1
Key created in keyring Default-G8VrmL
Identifier for key is EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr
Current identifier set to EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr
sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9710, 'client_ip': '10.0.0.105', 'alias': 'Node5', 'node_ip': '10.0.0.105', 'node_port': 9709, '
services': ['VALIDATOR']}
Sending node request for node identifier 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1496673374998911)
BGz5924BWP56KvxgaAbknPhoHTuVjgAbJtAe4NMaAfdp looking for Node5C at 10.0.0.105:9710
Node request completed 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc
BGz5924BWP56KvxgaAbknPhoHTuVjgAbJtAe4NMaAfdp now connected to Node5C
sovrin@test> new key with seed 0000000000000000000KellySteward2
Key created in keyring Default-G8VrmL
Identifier for key is DqCx7RFEpSUMZbV2mH89XPH6JT3jMvDNU55NTnBHsQCs
Current identifier set to DqCx7RFEpSUMZbV2mH89XPH6JT3jMvDNU55NTnBHsQCs
sovrin@test> send NODE dest=6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G data={'client_port': 9712, 'client_ip': '10.0.0.106', 'alias': 'Node6', 'node_ip': '10.0.0.106', 'node_port': 9711, '
services': ['VALIDATOR']}
Sending node request for node identifier 6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G by DqCx7RFEpSUMZbV2mH89XPH6JT3jMvDNU55NTnBHsQCs (request id: 1496673453996173)
BGz5924BWP56KvxgaAbknPhoHTuVjgAbJtAe4NMaAfdp looking for Node6C at 10.0.0.106:9712
Node request completed 6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G
BGz5924BWP56KvxgaAbknPhoHTuVjgAbJtAe4NMaAfdp now connected to Node6C
sovrin@test> new key with seed 000000000000000000000TestNODETGB
Key created in keyring Default-G8VrmL
Identifier for key is 7wTXmdcUkkpbEQTbA7E4qLdrAQATq7EkHfKBzNgNbERF
Current identifier set to 7wTXmdcUkkpbEQTbA7E4qLdrAQATq7EkHfKBzNgNbERF
sovrin@test> new key with seed 0000000000000TestNODETrustAnchor
Key created in keyring Default-G8VrmL
Identifier for key is FXBEVeDHLLSGdeGj22L9NgiFVrzKj7ocXYfe8RMVFxwQ
Current identifier set to FXBEVeDHLLSGdeGj22L9NgiFVrzKj7ocXYfe8RMVFxwQ
sovrin@test> new key with seed 00000000000TestNODEIdentityOwner
Key created in keyring Default-G8VrmL
Identifier for key is FShf9bpKn22ATP8Jd8FkzgeaQuPRHzcJozgFMRw9t3gb
Current identifier set to FShf9bpKn22ATP8Jd8FkzgeaQuPRHzcJozgFMRw9t3gb
sovrin@test> new key with seed 000000000000000000000000Trustee1
Key created in keyring Default-G8VrmL
Identifier for key is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
Current identifier set to GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
sovrin@test> send NYM dest=7wTXmdcUkkpbEQTbA7E4qLdrAQATq7EkHfKBzNgNbERF role=TGB
Adding nym 7wTXmdcUkkpbEQTbA7E4qLdrAQATq7EkHfKBzNgNbERF
BGz5924BWP56KvxgaAbknPhoHTuVjgAbJtAe4NMaAfdp disconnected from Node5C
Nym 7wTXmdcUkkpbEQTbA7E4qLdrAQATq7EkHfKBzNgNbERF added
sovrin@test> send NYM dest=DqCx7RFEpSUMZbV2mH89XPH6JT3jMvDNU55NTnBHsQCs role=TRUST_ANCHOR
Adding nym DqCx7RFEpSUMZbV2mH89XPH6JT3jMvDNU55NTnBHsQCs
Remote Node5C is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings
Error: client request invalid: UnauthorizedClientRequest('TRUSTEE cannot update role',)
BGz5924BWP56KvxgaAbknPhoHTuVjgAbJtAe4NMaAfdp now connected to Node5C
BGz5924BWP56KvxgaAbknPhoHTuVjgAbJtAe4NMaAfdp disconnected from Node5C
Remote Node5C is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings
Remote Node5C is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings
Remote Node5C is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings
Remote Node5C is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings
Remote Node5C is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings
{code}

 - Node failed to start (see attached logs)

{code:java}
sovrin-node.service - Sovrin Node Loaded: loaded (/etc/systemd/system/sovrin-node.service; enabled; vendor pres Active: inactive (dead) (Result: exit-code) since Mon 2017-06-05 14:50:45 UTC Process: 13367 ExecStart=/usr/local/bin/start_sovrin_node ${NODE_NAME} ${NODE_ Main PID: 13367 (code=exited, status=1/FAILURE) Jun 05 14:50:34 Node5.evernym.lab systemd[1]: sovrin-node.service: Main process Jun 05 14:50:34 Node5.evernym.lab systemd[1]: sovrin-node.service: Unit entered Jun 05 14:50:34 Node5.evernym.lab systemd[1]: sovrin-node.service: Failed with r Jun 05 14:50:45 Node5.evernym.lab systemd[1]: sovrin-node.service: Service hold- Jun 05 14:50:45 Node5.evernym.lab systemd[1]: Stopped Sovrin Node. Jun 05 14:50:45 Node5.evernym.lab systemd[1]: sovrin-node.service: Start request Jun 05 14:50:45 Node5.evernym.lab systemd[1]: Failed to start Sovrin Node.{code}

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-154,,,,,,,,"06/Jun/17 1:40 AM;aleksey-roldugin;1-from-pool_transactions_sandbox;https://jira.hyperledger.org/secure/attachment/10928/1-from-pool_transactions_sandbox","06/Jun/17 1:40 AM;aleksey-roldugin;1-from-transactions_sandbox;https://jira.hyperledger.org/secure/attachment/10927/1-from-transactions_sandbox","06/Jun/17 1:40 AM;aleksey-roldugin;Node5.log;https://jira.hyperledger.org/secure/attachment/10924/Node5.log","06/Jun/17 1:53 AM;aleksey-roldugin;domain_state.rar;https://jira.hyperledger.org/secure/attachment/10929/domain_state.rar","06/Jun/17 1:40 AM;aleksey-roldugin;journalctl-sovrin-node.txt;https://jira.hyperledger.org/secure/attachment/10925/journalctl-sovrin-node.txt","06/Jun/17 2:02 AM;aleksey-roldugin;pool_state.rar;https://jira.hyperledger.org/secure/attachment/10930/pool_state.rar",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxo7:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ashcherbakov,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jun/17 2:06 AM;lovesh; 
[~aleksey-roldugin] I see this error
{code}
return InsChgVotes(msg.viewNo, set())
TypeError: __new__() missing 1 required positional argument: 'last_ordered'
{code}

Plenum's master has correct definition of *InsChgVotes*, see https://github.com/evernym/plenum/blob/master/plenum/server/models.py#L12 but Plenum's stable has incorrect definition of *InsChgVotes*, see https://github.com/evernym/plenum/blob/stable/plenum/server/models.py#L15.
Or is it some node being on master codebase and some stable codebase;;;","06/Jun/17 2:27 AM;aleksey-roldugin;[~lovesh] Packages version on all 6 nodes are the same:
- python3-stp 0.1.10 amd64
- python3-ledger 0.2.14 amd64
- python3-plenum 0.3.15 amd64
- python3-sovrin-common 0.2.10
- sovrin-node 0.3.17 

Machines stack was created from template on AWS and I selected rc CodeBase there.;;;","06/Jun/17 1:16 PM;krw910;I saw a similar issue with the RC build today. It is the same as last Friday where I added two nodes, the both catch up but don't receive any of the new transactions.;;;","06/Jun/17 3:23 PM;krw910;I narrowed down the issue to the following cause.
I believe it is a transaction. I ran through the GST and added Node 5. I did not have any issues. On a hunch I ran through a test document we run just prior to adding the nodes which is the old ledger demo from January. It covers things like adding an abbreviated verkey 
send NYM dest=4QxzWk3ajdnEA37NdNU5Kt verkey= ~8RBNqGxt6TsUL4uHQmpy4r

After running through the tests here I ran into the issue on Node 6. After it did a catch up it no longer accepted new transactions, but all the nodes that were in the pool when I ran through the ledger demo are just fine.;;;","06/Jun/17 6:45 PM;lovesh;[~krw910] After suggestions from [~ashcherbakov] creating a separate ticket regarding your last comment, INDY-155;;;","06/Jun/17 6:49 PM;ashcherbakov;[~aleksey-roldugin] [~krw910] It looks like the root of the issue is a broken build. Let's check that the issue is not reproduced anymore on a new build.;;;","07/Jun/17 1:16 AM;aleksey-roldugin;[~ashcherbakov], [~krw910] the issue in not reproduced on the build:
 - sovrin-node 0.3.19
- sovrin-client 0.3.20;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node cannot perform catch up,INDY-154,17505,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,aleksey-roldugin,aleksey-roldugin,06/Jun/17 2:15 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"sovrin-node 0.3.17
h6. STEPS TO REPRODUCE:
 # Make set up with 10 machines (4 nodes for genesis pool, 4 clients, 2 nodes for adding).
 # Add 2 nodes.
 # Check that they successfully performed catch up.
 # Perform some operations for adding NYM on client.

h6. ACTUAL RESULT:
 - Node cannot perform catch up.

{code:java}
● sovrin-node.service - Sovrin Node
Loaded: loaded (/etc/systemd/system/sovrin-node.service; enabled; vendor preset: enabled)
Active: active (running) since Mon 2017-06-05 14:18:53 UTC; 57min ago
Main PID: 12706 (start_sovrin_no)
CGroup: /system.slice/sovrin-node.service
└─12706 /usr/bin/python3 /usr/local/bin/start_sovrin_node Node6 9711 9712

Jun 05 14:48:31 Node6.evernym.lab start_sovrin_node[12706]: self._record_inst_change_msg(msg, self.name)
Jun 05 14:48:31 Node6.evernym.lab start_sovrin_node[12706]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1787, in _record_inst_change_msg
Jun 05 14:48:31 Node6.evernym.lab start_sovrin_node[12706]: self.instanceChanges.addVote(msg, frm)
Jun 05 14:48:31 Node6.evernym.lab start_sovrin_node[12706]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/models.py"", line 138, in addVote
Jun 05 14:48:31 Node6.evernym.lab start_sovrin_node[12706]: super().addMsg(msg, voter)
Jun 05 14:48:31 Node6.evernym.lab start_sovrin_node[12706]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/models.py"", line 29, in addMsg
Jun 05 14:48:31 Node6.evernym.lab start_sovrin_node[12706]: self[key] = self.newVoteMsg(msg)
Jun 05 14:48:31 Node6.evernym.lab start_sovrin_node[12706]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/models.py"", line 131, in newVoteMsg
Jun 05 14:48:31 Node6.evernym.lab start_sovrin_node[12706]: return InsChgVotes(msg.viewNo, set())
Jun 05 14:48:31 Node6.evernym.lab start_sovrin_node[12706]: TypeError: __new__() missing 1 required positional argument: 'last_ordered'
{code}",,,,,,,,,,,,,,,,,,,,,,,INDY-153,,,,,,,,,,,,"06/Jun/17 2:15 AM;aleksey-roldugin;1-from-pool_transactions_sandbox;https://jira.hyperledger.org/secure/attachment/10934/1-from-pool_transactions_sandbox","06/Jun/17 2:15 AM;aleksey-roldugin;1-from-transactions_sandbox;https://jira.hyperledger.org/secure/attachment/10933/1-from-transactions_sandbox","06/Jun/17 2:15 AM;aleksey-roldugin;Node6.log;https://jira.hyperledger.org/secure/attachment/10931/Node6.log","06/Jun/17 2:15 AM;aleksey-roldugin;journalctl-sovrin-node.txt;https://jira.hyperledger.org/secure/attachment/10932/journalctl-sovrin-node.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxxof:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ashcherbakov,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jun/17 2:51 AM;lovesh;Same problem as INDY-153;;;","06/Jun/17 6:49 PM;ashcherbakov;[~aleksey-roldugin] [~krw910] It looks like the root of the issue is a broken build. Let's check that the issue is not reproduced anymore on a new build.;;;","07/Jun/17 1:17 AM;aleksey-roldugin;[~ashcherbakov], [~krw910] the issue in not reproduced on the build:
 - sovrin-node 0.3.19
- sovrin-client 0.3.20;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A newly added node is not able to perform process requests after catchup,INDY-155,17551,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,lovesh,lovesh,06/Jun/17 6:45 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,shakedown2,,,,"After completing catchup, the new node cannot process new PRE-PREPAREs because it does not agree to the state root mentioned in the PRE-PREPARE,
*reportSuspiciousNode | Node6 raised suspicion on node Node1 for Pre-Prepare message has incorrect state trie root; suspicion code is 17*
while the other nodes can process this PRE-PREPARE

*Instructions from Kelly for reproducing*
I believe it is a transaction. I ran through the GST and added Node 5. I did not have any issues. On a hunch I ran through a test document we run just prior to adding the nodes which is the old ledger demo from January. It covers things like adding an abbreviated verkey 
send NYM dest=4QxzWk3ajdnEA37NdNU5Kt verkey= ~8RBNqGxt6TsUL4uHQmpy4r
After running through the tests here I ran into the issue on Node 6. After it did a catch up it no longer accepted new transactions, but all the nodes that were in the pool when I ran through the ledger demo are just fine.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy19z:",,,,,,H1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ashcherbakov,danielhardman,lovesh,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jun/17 6:48 PM;ashcherbakov;[~lovesh] Isn't it the same issue as in INDY-145? Are the fixes for INDY-145 not enough?;;;","06/Jun/17 9:24 PM;lovesh;The problem is handling of null values in the serializer for identity ledger, the serializer does not differentiate between None and empty string but our code regarding verkey does. That causes problem when the ledger contains transactions that have verkey set to empty string and those transactions are communicated through catchup;;;","07/Jun/17 1:00 AM;lovesh;For a short term fix, we disable sending verkey as an empty string, the input validation should ensure that an empty verkey should not be allowed;;;","07/Jun/17 6:44 PM;lovesh;PRs for changes
# https://github.com/sovrin-foundation/sovrin-client/pull/216/files
# https://github.com/sovrin-foundation/sovrin-node/pull/174/files

*Relevant tests updated:* testSendNymVerkey, testSendNymSucceedsForUuidIdentifierAndEmptyVerkey, testSendNymSucceedsForCryptonymIdentifierAndEmptyVerkey, test_new_node_catchup_update_projection
*New test:* test_nym_addition_fails_with_empty_verkey;;;","15/Jun/17 2:04 AM;aleksey-roldugin;h6. build

sovrin-node 0.3.134
sovrin-client 0.3.136

h6. verification
NYM cannot be added with empty verkey:
{code:java}
send NYM dest=4QxzWk3ajdnEA37NdNU5Kt verkey= 
Invalid syntax: 'send NYM dest=4QxzWk3ajdnEA37NdNU5Kt verkey='

send NYM
--------
     title: Adds given identifier to sovrin

     usage: send NYM dest=<target identifier> role=<role> [verkey=<ver-key>]

     example(s):
        send NYM dest=BiCMHDqC5EjheFHumZX9nuAoVEp8xyuBgiRi5JcY5whi role=TRUST_ANCHOR
        send NYM dest=33A18XMqWqTzDpLHXLR5nT verkey=~Fem61Q5SnYhGVVHByQNxHj
{code}

h6. additional information:
Sending command through API was not tested.
;;;","15/Jun/17 5:28 AM;danielhardman;I am not sure that the short-term fix is a good idea. Will this break any test procedures or automation, or instructions to stewards on the alpha network? Does it prevent us from disabling an identity by setting verkey to null? How does this relate to the work that [~spivachuk] teed up, to change the syntax of our CLI so setting something to null requires the use of the ""null"" keyword? I would like several perspectives on whether the fix is appropriate for the time being: [~lovesh] [~krw910]

Also, do we have a ticket that tracks the need for a longer term fix, or will we lose track of this issue if this ticket is closed?;;;","16/Jun/17 5:58 PM;ashcherbakov;[~danielhardman]
* We had a long discussion with [~jlaw 1] and [~lovesh], and I think came to the consensus that using en empty string to disable Identity is not a valid use case, at least for now. 
* So, we don't have use cases when we need an empty value right now, and empty values are the same as None values.
* Nikita is notified about the issue. I think he's already updated the tests, I will double-check.
* Probably we need to update our documentations and say that sending an empty verkey is not a valid use case (it will be the same as None). Not sure whether we have a documentation to be updated.
* Agree that we need a ticket for long-term solutions. We were discussing using another Serialization for the ledger (not the custom one, but a protobuf for example).;;;","16/Jun/17 8:01 PM;spivachuk;[~danielhardman], [~ashcherbakov],
I made some corrections in tests ({{sovrin_client.test.cli.test_send_nym_validation}} module) in relation to prohibition of the empty value for {{verkey}} parameter of {{send NYM}} command. They are in the following PR:
https://github.com/sovrin-foundation/sovrin-client/pull/225;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
POOL_UPGRADE txn unclear error message,INDY-156,17555,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,06/Jun/17 9:17 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,," *Steps:*
 # send POOL_UPGRADE txn with name ""NAME""
 # make sure that the txn was accepted
 # send yet another POOL_UPGRADE txn with name ""NAME""

*Result:*
{code:java}
Pool upgrade failed: client request invalid: UnauthorizedClientRequest('TRUSTEE cannot do POOL_UPGRADE',)
{code}
*Expected result:*
 * The error message should be clear, for example ""Upgrade 'NAME' is already scheduled""

{code:java}
Pool upgrade failed: client request invalid: UnauthorizedClientRequest('Upgrade 'NAME' is already scheduled',)
{code}
 
 * Or we can end up with accepting a POOL_UPGRADE txn with a name which is use already. Maybe having two upgrades with the same name is not a problem. In such a case the txn should be accepted without an error.

 

*The details:*

1. Send POOL_UPGRADE with name _upgrade-060617_ 

 
{code:java}
send POOL_UPGRADE name=upgrade-060617 version=0.3.129 sha256=aad1242 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpk
X3Xo6pLhPhv': '2017-06-06T14:25:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-06-06T14:30:00.258870+00:00', 'DKVx
G2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-06T14:35:00.258870+00:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-06T14:
40:00.258870+00:00'} timeout=10{code}
2. Previous POOL_UPGRADE had a mistake in schedule so another POOL_UPGRADE is send with same name
{code:java}
send POOL_UPGRADE name=upgrade-060617 version=0.3.129 sha256=aad1242 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpk
X3Xo6pLhPhv': '2017-06-06T14:25:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-06-06T14:30:00.258870+00:00', 'DKVx
G2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-06T14:35:00.258870+00:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-06T14:
40:00.258870+00:00'} timeout=10
Sending pool upgrade upgrade-060617 for version 0.3.129
Pool upgrade failed: client request invalid: UnauthorizedClientRequest('TRUSTEE cannot do POOL_UPGRADE',){code}
The error message *""TRUSTEE cannot do POOL_UPGRADE""* does not reflect the actual cause

3. Send POOL_UPGRADE with another name
{code:java}
send POOL_UPGRADE name=upgrade-060617-2 version=0.3.129 sha256=aad1242 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-06-06T14:45:00.258870+03:00', '8ECVSk179mjsjKRLWiQ
tssMLgp6EPhWXtaYyStWPSGAb': '2017-06-06T14:50:00.258870+03:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-06T14:55:00.258870+03:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-06T15:00:
00.258870+03:00'} timeout=10
Sending pool upgrade upgrade-060617-2 for version 0.3.129
Pool upgrade successful
{code}
The upgrade is scheduled successfully.

 ",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,INDY-247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1rr:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,ashcherbakov,mark.hadley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jun/17 7:34 AM;mark.hadley;Alexander, I just need a bit of clarification: What was the mistake with the original schedule? I'm currently unable to reproduce.
After you comment on this, would you assign to me. Thank you.;;;","27/Jun/17 5:51 PM;ashcherbakov;[~alexander.shekhovcov] Can you please answer the question?;;;","27/Jun/17 7:41 PM;alexander.shekhovcov;[~mark.hadley] Sorry for confusion, the error in the schedule is not a problem itself. The problem sounds like ""the error message is not clear in case second POOL_UPGRADE comes with name which already exists"".

*Steps:*
 # send POOL_UPGRADE txn with name ""NAME""
 # make sure that the txn was accepted
 # send yet another POOL_UPGRADE txn with name ""NAME""

*Result:*
{code:java}
Pool upgrade failed: client request invalid: UnauthorizedClientRequest('TRUSTEE cannot do POOL_UPGRADE',)
{code}
*Expected result:*
 * The error message should be clear, for example ""Upgrade 'NAME' is already scheduled""

{code:java}
Pool upgrade failed: client request invalid: UnauthorizedClientRequest('Upgrade 'NAME' is already scheduled',)
{code}
 
 * Or we can end up with accepting a POOL_UPGRADE txn with a name which is use already. Maybe having two upgrades with the same name is not a problem. In such a case the txn should be accepted without an error.

 

 ;;;","29/Jun/17 8:31 AM;mark.hadley;[https://github.com/sovrin-foundation/sovrin-node/pull/197]

 ;;;","14/Jul/17 12:42 AM;mark.hadley;Updated the test to test that the exception caught was the correct one.

https://github.com/hyperledger/indy-node/pull/228;;;","15/Jul/17 2:15 AM;aleksey-roldugin;h6. BUILD

repository master
sovrin 0.2.9
indy-node 0.4.35

h6. VERIFICATION
# send POOL_UPGRADE txn with name ""NAME""
# make sure that the txn was accepted
# send yet another POOL_UPGRADE txn with name ""NAME""

h6. ACTUAL RESULT

{code:java}
Pool upgrade failed: client request invalid: InvalidClientRequest(""Upgrade 'update_to_node_35' is already scheduled"",)
{code}

h6. ADDITIONAL INFORMATION
Changes in _test_accept_then_reject_upgrade_ were also checked.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] The Node is not able to parse a CANCEL record from the upgrade_log,INDY-157,17556,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,alexander.shekhovcov,alexander.shekhovcov,06/Jun/17 9:26 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,should,,,,,"The Node raises the below exception during restart after upgrade
{code:java}
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: Traceback (most recent call last):
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: File ""/usr/local/bin/start_sovrin_node"", line 47, in <module>
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: cliha=cliha)
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 92, in __init__
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: self.upgrader = self.getUpgrader()
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 148, in getUpgrader
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: upgradeFailedCallback=self.postConfigLedgerCaughtUp)
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/upgrader.py"", line 90, in __init__
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: self.__defaultLog(dataDir, config)
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/upgrader.py"", line 71, in __defaultLog
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: return UpgradeLog(filePath=log)
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/upgrade_log.py"", line 21, in __init__
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: self.__load()
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/upgrade_log.py"", line 31, in __load
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: when = parseDate(item[2])
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: File ""/usr/lib/python3/dist-packages/dateutil/parser.py"", line 1008, in parse
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: return DEFAULTPARSER.parse(timestr, **kwargs)
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: File ""/usr/lib/python3/dist-packages/dateutil/parser.py"", line 404, in parse
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: ret = default.replace(**repl)
Jun 06 11:46:50 californiaShakeP1.qatest.evernym.com start_sovrin_node[20602]: ValueError: year is out of range{code}
*upgrade_log:*
{code:java}
2017-06-06 11:20:25.813834 scheduled 2017-06-06 14:25:00.258870+00:00 0.3.129
2017-06-06 11:36:14.433810 cancelled 11074 0.3.129
2017-06-06 11:42:15.287275 scheduled 2017-06-06 14:45:00.258870+03:00 0.3.129
2017-06-06 11:44:59.299328 scheduled 2017-06-06 14:45:00.258870+03:00 0.3.129
{code}
POOL_UPGRADE CANCEL txn:
{code:java}
send POOL_UPGRADE name=upgrade-060617 version=0.3.129 sha256=aad1242 action=cancel schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-06-06T14:40:00.258870+03:00', '8ECVSk179mjsjKRLWiQt
ssMLgp6EPhWXtaYyStWPSGAb': '2017-06-06T14:45:00.258870+03:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-06T14:50:00.258870+03:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-06T14:55:0
0.258870+03:00'} timeout=10{code}
 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-917,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyl5b:",,,,,,14,INDY 17.21,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,krw910,spivachuk,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jun/17 5:47 AM;stevetolman;Does this prevent an upgrade? (Does it cause a node not to upgrade?);;;","13/Jun/17 7:05 PM;alexander.shekhovcov;The issue does not prevent an upgrade directly. But if the CANCEL action is sent (somebody wants to cancel the upgrade process) we got non working pool after next restart upgrade or manual node restart.;;;","23/Aug/17 11:33 PM;krw910;The cancel operation does work so the scheduled upgrade is actually cancelled the issue is just with parsing the transaction once it has been written.;;;","19/Oct/17 9:47 PM;spivachuk;*Problem reason:*
- The current delay till the scheduled upgrade instead of the upgrade time was written to {{Upgrader.scheduledUpgrade}} tuple.

*Changes:*
- Fixed a bug with wrong ""when"" item in {{Upgrader.scheduledUpgrade}} tuple. This in turn fixed the bug with wrong ""when"" field in {{cancel}} messages of the upgrade log.
- Corrected tests according to the fix.
- Made some minor fixes (in tests) related to appending messages to the upgrade log.

*Committed into:*
- https://github.com/hyperledger/indy-node/pull/394
- indy-node 1.1.169 master

*Risk factors:*
- None is expected.

*Risk:*
- Low;;;","20/Oct/17 9:11 PM;VladimirWork;Build Info:
indy-node 1.1.171

Steps to Validate:
1. Install a pool.
2. Schedule an upgrade txn.
3. Cancel the txn from Step 2.
4. Restart any node.

Actual Results:
Pool works normally.

Additional Info:
There is an issue with wrong upgrade_log entries in primary node after restart, INDY-917 is reported.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
If view change is caused by demoting master's primary then primary re-election is performed only in master instance,INDY-158,17557,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,06/Jun/17 9:34 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,shakedown3,Stability,,,"The behavior of a view change depends on its trigger:
 * If the primary of the master protocol instance is stopped then primary re-election is done in all the protocol instances as it must.
 * If the primary of the master protocol instance is demoted then primary re-election is done only in the master protocol instance while it must be done in all the protocol instances.

The bug was reproduced on the following versions:
 * sovrin-node 0.3.129 master deb package,
 * sovrin-client 0.3.125 master deb package.

Steps to reproduce and actual results:
 # Install a local pool from Vagrant script with changed APT repositories from {{xenial stable}} to {{xenial master}} in {{sovrin-environments/vagrant/training/vb-multi-vm/scripts/agent.sh}} and {{sovrin-environments/vagrant/training/vb-multi-vm/scripts/validator.sh}}.
 # Connect via SSH to the client VM and launch {{sovrin}}.
 # In CLI execute: {{connect test}}
 # In CLI execute: {{new key with seed 000000000000000000000000Trustee1}}
 # Connect via SSH to any of the node VMs, open the node log and detect which node has been selected as the primary in the master protocol instance (search for the string ""selected primary"" through the log).
 # Stop the VM with the primary of the master protocol instance.
 # Wait half a minute.
 # Connect via SSH to any of the remaining node VMs, open the node log and search for results of election (search for the string ""selected primary"") for the last view change ({{view 1}}).
 *[ New primaries have been selected in all the protocol instances. ]*
 # Detect which node has been selected as the primary in the master protocol instance for the last view ({{view 1}}).
 # Find the identifier of this node in {{pool_transactions_sandbox}}. Copy it to the clipboard for further use.
 # Start the VM that was previously stopped.
 # Wait a minute.
 # In CLI execute:

{noformat}
send NODE dest=<PRIMARY_OF_MASTER_INSTANCE_ID> data= {""alias"": ""<PRIMARY_OF_MASTER_INSTANCE_ALIAS>"", ""services"": []}{noformat}

 # Wait half a minute.
 # Connect via SSH to any of the remaining node VMs, open the node log and search for results of election (search for the string ""selected primary"") for the last view change ({{view 2}}).
 *[ New primary has been selected only in the master protocol instance. ]*

Expected results:
 * Primary re-election must be performed in all the protocol instances regardless of the cause of the view change.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Aug/17 8:37 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11912/Node1.log","21/Aug/17 8:37 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11913/Node2.log","21/Aug/17 8:37 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11914/Node3.log","21/Aug/17 8:37 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11915/Node4.log","30/Aug/17 10:51 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11992/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydcf:",,,,,,H2,H3,H4,10,11,,,,,,,,,,,,,,,,andkononykhin,ashcherbakov,dsurnin,krw910,lovesh,mzk-vct,ozheregelya,spivachuk,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jun/17 12:25 AM;spivachuk;Found that sometimes in case the primary of the master protocol instance is demoted, primary re-election is done for no protocol instances.;;;","07/Jun/17 2:10 AM;spivachuk;After 1 of 4 nodes has been demoted:
* Sometimes it is possible to add nyms and then promote the demoted node back. Catch-up succeeds on the promoted node. After this it is also possible to add nyms.
* Sometimes it is not possible to add new nyms and promote the demoted node back.;;;","27/Jun/17 7:36 PM;lovesh;We are moving away from election as part of INDY-13;;;","28/Jun/17 5:56 AM;stevetolman;Please re-verify if this is a bug or not.;;;","30/Jun/17 12:03 AM;krw910;Lovesh says we have moved away from this with INDY-13. Once we get a new master build can you retest this to see if it is valid anymore. You can assign it back to me with your results.;;;","13/Jul/17 5:25 AM;krw910;Blocked by INDY-406;;;","14/Jul/17 3:11 AM;slafranca;I tested this with 
{code:java}
indy-plenum=0.4.43
indy-anoncreds=0.4.12
indy-node=0.4.26
{code}
The bug is not fixed.  There is a problem with shutting down the service on the node, this will be logged in a separate ticket.  For this ticket, follow the steps for demoting a primary.;;;","04/Aug/17 4:44 PM;ashcherbakov;Please check whether the issue is still reproduced.;;;","10/Aug/17 12:50 AM;mzk-vct;Seems to be fixed. Failed to reproduce on
{code}
indy-plenum=1.0.79
indy-anoncreds=1.0.22
indy-node=1.0.77
{code};;;","16/Aug/17 3:24 AM;krw910;[~mzk-vct] I can still reproduce the second half of this ticket. The first part works fine if you shut off the service to the primary node. The second part fails where if I demote the primary node the election does not happen.

I have 4 nodes. Node1 starts as the primary. 
I shut down its service and Node2 becomes the primary with Node3 in line to be the next primary. 
I bring up Node1 so all 4 are working then demote Node2. 
Node 3 does not become the primary and the pool stops taking transactions.

indy-plenum=1.0.95
indy-anoncreds=1.0.25
indy-node=1.0.105
sovrin=1.0.23;;;","18/Aug/17 1:30 AM;dsurnin;[~krw910] [~mzk-vct]

Today I tried to reproduce it with the latest master code on local machine. It looks like it works fine.

 

[~krw910]

Could you please check it with the build from latest master source code?;;;","21/Aug/17 9:22 PM;ozheregelya;*Build Info:*
  indy-node 1.0.67
  indy-anoncreds 1.0.22
  indy-plenum 1.0.77
  sovrin 1.0.23
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client

Steps to Reproduce:

1. Set up the pool of 4 nodes.
2. Look at node logs and check which node is primary:
{code:java}
root@ec5db9ad2c7d:/home/sovrin# tail -f .sovrin/Node4.log | grep ""selected primary""
2017-08-21 10:20:51,542 | DISPLAY | primary_selector.py ( 283) | _startSelection | PRIMARY ELECTION: Node4:0 selected primary Node1:0 for instance 0 (view 0)
2017-08-21 10:20:51,543 | DISPLAY | primary_selector.py ( 283) | _startSelection | PRIMARY ELECTION: Node4:1 selected primary Node2:1 for instance 1 (view 0){code}
=> Node1 is primary, Node2 is primary backup.
3. Demote primary node, look at node logs.
    In CLI:
{code:java}
sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services': []}{code}
    On node:
{code:java}
root@ec5db9ad2c7d:/home/sovrin# tail -f .sovrin/Node4.log | grep ""selected primary""
2017-08-21 10:20:51,542 | DISPLAY | primary_selector.py ( 283) | _startSelection | PRIMARY ELECTION: Node4:0 selected primary Node1:0 for instance 0 (view 0)
2017-08-21 10:20:51,543 | DISPLAY | primary_selector.py ( 283) | _startSelection | PRIMARY ELECTION: Node4:1 selected primary Node2:1 for instance 1 (view 0)
2017-08-21 10:23:10,293 | DISPLAY | primary_selector.py ( 283) | _startSelection | PRIMARY ELECTION: Node4:0 selected primary Node2:0 for instance 0 (view 1){code}
=> Node2 is selected as primary, but primary backup is not selected.
4. Promote Node1 back.
5. Send any transaction to make sure that CLI works.
=> Transaction is successfully send.
6. Exit the CLI.
7. Open CLI again, connect to test, try to send any transaction.
=> transaction was not send.

*Actual Results:*
- Primary backup was not selected after view change which was caused by demotion of primary node.
- CLI does not send transactions after restart, following message appears after connection to test:
{code:java}
C2ej5UixyQsc63zGMphXscgJjmeqsLwpQqkyipijbLSE could not verify catchup reply CATCHUP_REP{'consProof': ['8RGnCTaL3UzRxP2nkPNAvaQPDRvPPnVfMzbs6wF4Tccc', '4wBxHrzkLnvoiSza5bP7Ypzawnpv3CejBQY7B2W21pTE', '8t6iko6iXv1Yqryo7tVSeCqJhRgMBCCa2fXx5PZLg3Hd', '5xizCdcGJoYwSK5swMP4BDasTxDbULANZozqM2M2uRo3'], 'ledgerId': 0, 'txns': {'5': {'reqId': 1503311243389437, 'type': '0', 'signature': '5X3rw8me9LAutxNhZwsyyQc2iHjDrVxCwF5xhahbHtJqhNnddRt2zoGuAgugthmV7sUHWi85kV8tfBNSRu3b7xqb', 'dest': '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA', 'txnTime': 1503311243, 'identifier': 'V4SGRU86Z58d6TV7PBUe6f', 'data': {'services': [], 'alias': 'Node4'}}}} since Inconsistency: first root hash does not match. Expected hash: b'14175d8de952f91fb51e5a97a98bab4565e196ec47b2d109233cc96698b9cf6c', computed hash: b'91b838db75d37a99e393379ed4f9a23774a1e6052758301f6b68f33a2c2e1e8d'{code}

*Expected Results:*
Both of primary and primary backup should be selected during view change. CLI and pool should work without errors.

 

 ;;;","21/Aug/17 10:23 PM;ashcherbakov;Looks like a duplicate of INDY-463;;;","22/Aug/17 11:44 PM;krw910;[~ashcherbakov] You are correct that this ticket is the same as INDY-463 when dealing with demotion of a primary. However the bigger issue with INDY-463 is that if you demote Node 1 in a pool (The first node in the pool transactions file) you will never get the pool to function again if the entire pool is restarted. So they are similar to a point, but keep INDY-463 because it is dealing with a bigger issue around the new view change protocol. ;;;","23/Aug/17 12:09 AM;ashcherbakov;[~krw910] 
Yes, we keep all the tickets, and we've been working on the fixes for the issues you mentioned in the scope of INDY-463 and INDY-446.;;;","29/Aug/17 11:05 PM;andkononykhin;1. original description of that task is not about any failure: demoting one of 4 nodes decrements f-value from 1 to 0 and it causes a decrement of number of protocol instances. So we should expect primary selection only for that single left instance (master one).

2. original problem of primary selection after any demotion relates to INDY-463 and should be fixed by the [PR-354|https://github.com/hyperledger/indy-plenum/pull/354]

How to test: try different scenarios with nodes demotions

 ;;;","30/Aug/17 10:51 PM;VladimirWork;Build Info:
indy-node 1.1.125

Steps to Validate - Case 1:
1. Install pool with 4 nodes (Node1 is primary).
2. Shut down Node1 (Node2 is primary). 
3. Bring up Node1.
4. Demote Node2.

Actual Results:
Primary node is elected normally. Pool works normally.

Steps to Validate - Case 2:
1. Set up the pool of 4 nodes.
2. Look at node logs and check which node is primary
=> Node1 is primary, Node2 is primary backup.
3. Demote primary node, look at node logs
=> Node2 is selected as primary, but primary backup is not selected.
4. Promote Node1 back.
5. Send any transaction to make sure that CLI works
=> Transaction is successfully send.
6. Exit the CLI.
7. Open CLI again, connect to test, try to send any transaction.

Actual Results:
Pool works normally. Backup primary is not selected - it's ok according to Andrey K comment.

Steps to Validate - Case 3:
1. Set up the pool of 5 nodes.
2. Look at node logs and check which node is primary
=> Node2 is primary, Node3 is primary backup.
3. Demote primary node, look at node logs.

Actual Results:
Main primary and backup primary are selected normally (screenshot). !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[send NYM] Command doesn't work with stopped node in pool,INDY-159,17558,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,VladimirWork,VladimirWork,06/Jun/17 9:47 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,Must,,,,,"Build Info:
sovrin-node 0.3.19
sovrin-client 0.3.20

Overview:
""send NYM"" command doesn't work with stopped node in pool (1 of 4) and after restart stopped node it doesn't work too.

Steps to Reproduce:
1. Execute ""systemctl stop sovrin-node"" on one of nodes in the pool.
2. Create new key and execute some ""send NYM"" commands.
3. Execute ""systemctl start sovrin-node"" on stopped node.
4. Create new key and execute some ""send NYM"" commands.

Actual Results:
""send NYM"" command doesn't work after stopping node.
""send NYM"" command doesn't work after restarting node.

Expected Results:
""send NYM"" command should work in both cases.

Additional Information:
First few ""send NYM"" commands (1 or 2) work successfully after stopping a node, but all next do not.

Nodes' logs are backuped as NodeX_06.06.2017.log files.

Pool connection info:
https://docs.google.com/document/d/10xHeJPyngFc4WHxA-_OaATdvYCa8DSpv_YnQ7O0KBrU/edit#",,,0,0,,0%,0,0,,,,,,,,,,,,,,INDY-160,,,,,INDY-191,INDY-245,,,,,,,"09/Jun/17 6:33 PM;alexander.shekhovcov;Node1-p1-missing-pp.log;https://jira.hyperledger.org/secure/attachment/11003/Node1-p1-missing-pp.log","08/Jun/17 8:29 PM;alexander.shekhovcov;Node1-stop-case.log.tar.gz;https://jira.hyperledger.org/secure/attachment/10994/Node1-stop-case.log.tar.gz","09/Jun/17 6:33 PM;alexander.shekhovcov;Node2-p1-missing-pp.log;https://jira.hyperledger.org/secure/attachment/11004/Node2-p1-missing-pp.log","09/Jun/17 6:33 PM;alexander.shekhovcov;Node3-p1-missing-pp.log;https://jira.hyperledger.org/secure/attachment/11005/Node3-p1-missing-pp.log","09/Jun/17 6:33 PM;alexander.shekhovcov;Node4-p1-missing-pp.log;https://jira.hyperledger.org/secure/attachment/11006/Node4-p1-missing-pp.log","06/Jun/17 9:45 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/10943/Screenshot.PNG","15/Jun/17 10:48 PM;alexander.shekhovcov;node-2017-06-14.tar.gz;https://jira.hyperledger.org/secure/attachment/11093/node-2017-06-14.tar.gz","15/Jun/17 10:47 PM;alexander.shekhovcov;node-2017-06-14.tar.gz;https://jira.hyperledger.org/secure/attachment/11092/node-2017-06-14.tar.gz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy19j:",,,,,,H1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,ashcherbakov,krw910,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jun/17 9:50 PM;VladimirWork;FYI [~kelly.wilson], [~stevetolman], [~tylerq], [~ashcherbakov];;;","06/Jun/17 10:04 PM;VladimirWork;Workaround:
Restart all nodes in the pool.;;;","06/Jun/17 10:31 PM;aleksey-roldugin;After restarting service on all nodes every node can make catch up.;;;","08/Jun/17 8:50 PM;alexander.shekhovcov; 

Actually there are two issues here 
 # Lots lines – ""_missing PRE-PREPAREs between 7 and 2""_ in the log which should not break the pool
 # Though the pool does not work well

+Node1 got client request:+
{code:java}
2017-06-06 11:58:17,329 | TRACE | node.py (1336) | validateClientMsg | Node1C received CLIENT message: SafeRequest: {'reqId': 1496750297296355, 'identifier': 'CqH1opg44oVnX9QZA1PEL9VwnPnukviPNYtx
wEYZkmEB', 'signature': '4UdHxtPUsCAkcTLKFLc2LroFbqHSNEFWct4YHh82BfjBkyJ8trHM8iKg8KaVBLVrUz7btB7CCfJtVeaMiSn7YvxB', 'operation': {'role': '2', 'dest': 'FE1yjAc4ewAs8EDA7kFiAURxu7AeHFa2xMV63oX5T2wY', 'type': '1'}
}
...{code}
+the request is ordered:+

 
{code:java}
...
2017-06-06 11:58:17,386 | TRACE | replica.py (1627) | send | Node1:1 sending ORDERED{'stateRootHash': None, 'instId': 1, 'ppSeqNo': 10, 'viewNo': 2, 'txnRootHash': None, 'ledgerId': 1, 'ppTime': 1496750297325.4019, 'reqIdr': [('CqH1opg44oVnX9QZA1PEL9VwnPnukviPNYtxwEYZkmEB', 1496750297296355)]}
2017-06-06 11:58:17,386 | DEBUG | replica.py (1261) | doOrder | Node1:1 ordered request (2, 10)
2017-06-06 11:58:17,387 | DEBUG | replica.py ( 748) | processCommit | Node1:1 processed incoming COMMIT(2, 10)
2017-06-06 11:58:17,387 | DEBUG | replica.py ( 737) | processCommit | Node1:1 received COMMIT(2, 10) from Node2:1
2017-06-06 11:58:17,387 | DEBUG | replica.py ( 772) | tryOrder | Node1:1 cannot return request to node: already ordered
2017-06-06 11:58:17,387 | DEBUG | replica.py ( 748) | processCommit | Node1:1 processed incoming COMMIT(2, 10)
2017-06-06 11:58:17,389 | TRACE | node.py (1640) | processOrdered | Node1 got ordered requests from backup replica 1
2017-06-06 11:58:20,080 | DEBUG | zstack.py (1161) | reconcileNodeReg | Node1 matched remote Node2 HA(host='10.0.0.102', port=9703)
2017-06-06 11:58:20,080 | DEBUG | zstack.py (1161) | reconcileNodeReg | Node1 matched remote Node4 HA(host='10.0.0.104', port=9707)
2017-06-06 11:58:20,080 | DEBUG | zstack.py (1161) | reconcileNodeReg | Node1 matched remote Node3 HA(host='10.0.0.103', port=9705)
...{code}
+but the client does not get a reply so the client resend the request+
{code:java}
2017-06-06 12:00:00,266 | TRACE | node.py (1336) | validateClientMsg | Node1C received CLIENT message: SafeRequest: {'reqId': 1496750370218480, 'identifier': 'CqH1opg44oVnX9QZA1PEL9VwnPnukviPNYtxwEYZkmEB', 'signature': '2AXHWXTd2JtFngS88DbA8aSxmmFjfg4ktWHDEwPLRaDjwwNMaFj1BJ9cixjyRs95sUG7amjt8DRWXS2EQkQTp64N', 'operation': {'role': '2', 'dest': 'FE1yjAc4ewAs8EDA7kFiAURxu7AeHFa2xMV63oX5T2wY', 'type': '1'}}
2017-06-06 12:00:00,266 | DISPLAY | node.py (1382) | processClientInBox | Node1C processing b'xDsx(LV7P9<gN15vR3AL+NT=KTPslumTu}e7uHMk' request SafeRequest: {'reqId': 1496750370218480, 'identifier': 'CqH1opg44oVnX9QZA1PEL9VwnPnukviPNYtxwEYZkmEB', 'signature': '2AXHWXTd2JtFngS88DbA8aSxmmFjfg4ktWHDEwPLRaDjwwNMaFj1BJ9cixjyRs95sUG7amjt8DRWXS2EQkQTp64N', 'operation': {'role': '2', 'dest': 'FE1yjAc4ewAs8EDA7kFiAURxu7AeHFa2xMV63oX5T2wY', 'type': '1'}}
2017-06-06 12:00:00,266 | DEBUG | node.py (1537) | processRequest | Node1 received client request: SafeRequest: {'reqId': 1496750370218480, 'identifier': 'CqH1opg44oVnX9QZA1PEL9VwnPnukviPNYtxwEYZkmEB', 'signature': '2AXHWXTd2JtFngS88DbA8aSxmmFjfg4ktWHDEwPLRaDjwwNMaFj1BJ9cixjyRs95sUG7amjt8DRWXS2EQkQTp64N', 'operation': {'role': '2', 'dest': 'FE1yjAc4ewAs8EDA7kFiAURxu7AeHFa2xMV63oX5T2wY', 'type': '1'}} from b'xDsx(LV7P9<gN15vR3AL+NT=KTPslumTu}e7uHMk'
2017-06-06 12:00:00,269 | TRACE | propagator.py ( 130) | propagate | Node1 already propagated SafeRequest: {'reqId': 1496750370218480, 'identifier': 'CqH1opg44oVnX9QZA1PEL9VwnPnukviPNYtxwEYZkmEB', 'signature': '2AXHWXTd2JtFngS88DbA8aSxmmFjfg4ktWHDEwPLRaDjwwNMaFj1BJ9cixjyRs95sUG7amjt8DRWXS2EQkQTp64N', 'operation': {'role': '2', 'dest': 'FE1yjAc4ewAs8EDA7kFiAURxu7AeHFa2xMV63oX5T2wY', 'type': '1'}}
2017-06-06 12:00:00,269 | DEBUG | propagator.py ( 224) | tryForwarding | Node1 not forwarding request SafeRequest: {'reqId': 1496750370218480, 'identifier': 'CqH1opg44oVnX9QZA1PEL9VwnPnukviPNYtxwEYZkmEB', 'signature': '2AXHWXTd2JtFngS88DbA8aSxmmFjfg4ktWHDEwPLRaDjwwNMaFj1BJ9cixjyRs95sUG7amjt8DRWXS2EQkQTp64N', 'operation': {'role': '2', 'dest': 'FE1yjAc4ewAs8EDA7kFiAURxu7AeHFa2xMV63oX5T2wY', 'type': '1'}} to its replicas since already forwarded
{code}
 

 

[~lovesh] [~ashcherbakov] any thoughts? 

There were 2 view change in the log but I have not found any signs of the 'view change' problem.

 

 

 ;;;","09/Jun/17 10:18 PM;ashcherbakov;We investigated the logs and came to the following conclusions:

There are two issues:
*Issue 1*
- Reproduced locally
- How is shown: lots of missing PRE-PREPAREs between X and Y entries in the log
- Cause: The node doesn't delete nor ignore 3PC requests with pp_seq_no < last_ordered_pp_seq_no, that is requests that are already ordered, if they come after  last_ordered_pp_seq_no is set. When a node is discinnected and then connected again, it does catch-up and sets last_ordered_pp_seq_no according to the latest state (obtained from previous nodes), but later on it receives old 3PC messages (which is ok). 
- Going to fix in this ticket: Yes
- How to fix:
-- do not process new 3PC messages with ppSeqNo <= last_ordered_pp_seq_no; 
-- GC prePreparesPendingPrevPP queue

*Issue 2*
- Not Reproduced locally
- How is shown: the disconnected node (and probably the whole pool) can not process any new requests
- Cause: 
 When a node is connected back, it does catch-up, and other nodes tell that  last_ordered_pp_seq_no==2. But then it receives PrePrepare with  last_ordered_pp_seq_no==7, so it goes to infinite loop of waiting missing prep-prepares (between 2 an 7). However, it doesn't receive them.
We can see two possible issues why it doesn't receive them:
Issue 2.1: 2 view changes were done, so the nodes may be in a broken state (that's why the pool doesn't process any new requests). The pool may send a wrong last_ordered_pp_seq_no.
Issue 2.2: The connected node does catch-up, and by that time last_ordered_pp_seq_no==2. But other nodes still process new requests at this time, and come to last_ordered_pp_seq_no>2. However, 3PC messages for this state are not sent to the connected node, since it was disconnected at that time.
In other words: [nodes process res for ppSeqNo>2 and most of 3PC reqs needed for consensus] -> [Node is connected] -> [Node did a catch-up and get last_ordered_pp_seq_no==2] -> [other nodes finish processing reqs and come to the state with ppSeqNo>2] -> [The node is still at state with ppSeqNo==2].
As we don't re-run catch-up as of now, the node will remain in old state.
- Going to fix in this ticket: No
- How to fix:
-- Issue 2.1: caused INDY-13
-- Issue 2.2: caused by INDY-103


So, the PoA:
- Finish the fix for Issue1
- Disable view change and make sure that Issue 2 is not reproduced;;;","13/Jun/17 8:36 PM;alexander.shekhovcov;(/) 

*Problem reason:*
- the node stashes outdated pre-prepare messages

*Changes:*
- the node ignores outdated pre-prepare messages

*Committed into:*
https://github.com/evernym/plenum/commit/6b1cf9b4e353fe62c5b6c237cd5cfce0e628f8e1
sovin-node 0.3.135+

*Risk factors:*
 Nothing is expected.

*Risk:*
 Low

*Covered with tests:*
_test_ignore_pre_prepare_pp_seq_no_less_than_expected_

*Recommendations for QA:*
The fix covers Issue 1 (see Alex's comment). The issue 2 will be fixed in INDY-13 INDY-103.
 # Stop a node
 # Send 3 NYM txns 
 # Start the node
 # Send 1 NYM txn
 # Make sure the node log does not contain lots ""... missing PRE-PREPARE ..."" (see attached logs)
 # Repeat 1-5 at most 10 times

 

 ;;;","14/Jun/17 12:00 PM;krw910;[~alexander.shekhovcov] we have a problem with Master build 0.3.138.
If I stop the service on one out of 4 nodes I can send one successful transaction. The second transaction does not go through. I restarted the node that was down and the client connected, but still cannot completed a transaction. I restarted all the nodes but that still did not fix it. 
Fix - I had to bring all 4 nodes services down and start them up one at a time. When I saw the client connect to one I brought up the next one. Doing one at time after having them all off worked.;;;","14/Jun/17 7:21 PM;alexander.shekhovcov;[~krw910] I see sovrin-node 0.3.134 installed on the Shakedown pool 4 which is affected. Have you tried 0.3.135+? Have you used another pool for the tests?

Do you still have the logs?;;;","15/Jun/17 2:25 AM;stevetolman;Sasha, please stay on this ticket until it is completed.  Once you have an idea of an ETA, please share it with us in the ticket. 

We are going to start an rc build now but if you have this fixed by your end of day tomorrow (15 June), we will request and build another stable (rc) build and use that as our H1 release.;;;","15/Jun/17 11:00 PM;alexander.shekhovcov;[^node-2017-06-14.tar.gz]

Findings:
 * Node2 did not forward the request 1497408485465294 to the replicas after the node gets 2 propagates from node3 and node4
 * so 3pc is stopped because no quorum (node1 is not participating)
 * the pool sends ppSeqNo=1 in a CONSISTENCY_PROOF replay to node1 after the node1 is started
 * but next pre-prepare comes with ppSeqNo=4 from the primary
 * so node1 prints ""_missing PRE-PREPAREs between 4 and 1""_ 
 * PROPAGATE for 1497408485465294 comes to node3 and node4 before node3 and node4 receive 1497408485465294 from client;;;","17/Jun/17 12:11 AM;alexander.shekhovcov;We have an other issue here. 

Let's track the new issue here https://jira.hyperledger.org/browse/INDY-245. I suggest to close this ticket. ;;;","17/Jun/17 3:46 AM;krw910;This ticket has been fixed and can work. I ran into the same symptoms but from a different cause and that was captured in INDY-245;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool failure after upgrade (Unicorn),INDY-160,17560,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,alexander.shekhovcov,alexander.shekhovcov,06/Jun/17 11:02 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"*Steps:*
 # Before I came to the pool (shakedown 2) Node 2 had crashed with (looks like a separate issue)

{code:java}
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1004, in serviceReplicaInBox May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: msgCount += replica.serviceQueues(limit) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 522, in serviceQueues May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self.node.isParticipating) else 0 May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 438, in send3PCBatch May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: ppReq = self.create3PCBatch(lid) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 479, in create3PCBatch May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self.processReqDuringBatch(req, validReqs, inValidReqs, rejects) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 456, in processReqDuringBatch May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self.node.applyReq(req) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 393, in applyReq May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: return super().applyReq(request) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1485, in applyReq May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: return self.domainRequestApplication(request) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1491, in domainRequestApplication May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: return self.reqHandler.apply(request) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/domain_req_handler.py"", line 52, in apply May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self.updateState(txnsWithSeqNo(start, end, [txn])) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/domain_req_handler.py"", line 66, in updateState May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self._updateStateWithSingleTxn(txn, isCommitted=isCommitted) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 56, in _updateStateWithSingleTxn May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self._addAttr(txn) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 339, in _addAttr May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: attr_key, value = parse(txn) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 328, in parse May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: key, _ = data.popitem() May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: KeyError: 'popitem(): dictionary is empty'{code}
 

 

2. the _data_ folder is moved to _data-06_11-45_

3. the pool restarted

4. successful POOL_UPGRADE 
{code:java}
send POOL_UPGRADE name=upgrade-060617 version=0.3.129 sha256=aad1242 action=start schedule={'Gw6pDLhcBcoQesN72q
fotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-06-06T15:55:00.258870+03:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-06-06
T16:00:00.258870+03:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-06T16:05:00.258870+03:00','4PS3EDQ3dW1tci1B
p6543CfuuebjFrg36kLAUcskGfaA':'2017-06-06T16:10:00.258870+03:00'} timeout=10
{code}
5. after the nodes are upgraded each node's log contains infinite 
{code:java}
...
2017-06-06 14:08:58,602 | DEBUG | replica.py ( 823) | isNextPrePrepare | Node2:1 missing PRE-PREPAREs between 2 and 0
2017-06-06 14:08:58,616 | DEBUG | replica.py ( 823) | isNextPrePrepare | Node2:1 missing PRE-PREPAREs between 2 and 0
2017-06-06 14:08:58,629 | DEBUG | replica.py ( 823) | isNextPrePrepare | Node2:1 missing PRE-PREPAREs between 2 and 0
2017-06-06 14:08:58,642 | DEBUG | replica.py ( 823) | isNextPrePrepare | Node2:1 missing PRE-PREPAREs between 2 and 0
...{code}
the pool is not functional ",,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,INDY-159,,,,,,,,,,,,,,"06/Jun/17 11:12 PM;alexander.shekhovcov;Node1-4.tar.gz;https://jira.hyperledger.org/secure/attachment/10947/Node1-4.tar.gz","06/Jun/17 11:16 PM;alexander.shekhovcov;data-node1.tar.gz;https://jira.hyperledger.org/secure/attachment/10948/data-node1.tar.gz","06/Jun/17 11:16 PM;alexander.shekhovcov;data-node2.tar.gz;https://jira.hyperledger.org/secure/attachment/10949/data-node2.tar.gz","06/Jun/17 11:16 PM;alexander.shekhovcov;data-node3.tar.gz;https://jira.hyperledger.org/secure/attachment/10950/data-node3.tar.gz","06/Jun/17 11:16 PM;alexander.shekhovcov;data-node4.tar.gz;https://jira.hyperledger.org/secure/attachment/10951/data-node4.tar.gz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy187:",,,,,,H2,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jun/17 1:17 AM;lovesh;The error appears to be due to passing an ATTRIB transaction with an empty JSON;;;","23/Jun/17 8:41 PM;alexander.shekhovcov;Actually 2 issues here:
 # step 1 is described in the https://jira.hyperledger.org/browse/INDY-206 ticket
 # step 5 is resolved in the ticket https://jira.hyperledger.org/browse/INDY-245

I suggest to close this ticket because the ticket completely covered by INDY-206 and INDY-245.

 ;;;","27/Jun/17 7:42 AM;krw910;We have not seen this issue in the most recent upgrades of our test pools. INDY-245 has been verified as fixed which is one of the two issues. INDY-206 is still in the backlog at the time of this comment.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transaction ledger files are not restored,INDY-161,17561,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,dsurnin,dsurnin,06/Jun/17 11:03 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,shakedown1,should,,,,"install client and node in one machine from rc repo;

run 4 nodes locally as described [https://github.com/sovrin-foundation/sovrin-node/blob/master/docs/Sovrin_Running_Locally.md];

create around 7000 transactions;

so the directory ~/.sovrin/data/nodes/Node1/transactions_sandbox/ contains the following 

drwxrwxr-x 2 tmh tmh 4096 июн 6 16:08 .
drwxrwxr-x 13 tmh tmh 4096 июн 6 16:43 ..
-rw-rw-r-- 1 tmh tmh 278765 июн 6 15:30 1
-rw-rw-r-- 1 tmh tmh 252657 июн 6 15:32 1001
-rw-rw-r-- 1 tmh tmh 252609 июн 6 15:34 2001
-rw-rw-r-- 1 tmh tmh 252587 июн 6 15:56 3001
-rw-rw-r-- 1 tmh tmh 252598 июн 6 16:00 4001
-rw-rw-r-- 1 tmh tmh 252643 июн 6 16:04 5001
-rw-rw-r-- 1 tmh tmh 252639 июн 6 16:08 6001
-rw-rw-r-- 1 tmh tmh 53549 июн 6 16:43 7001

 

on running node1 delete files 4001 and 7001

stop and rerun node1;

files are not recreated;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jun/17 11:01 PM;dsurnin;Node1.log;https://jira.hyperledger.org/secure/attachment/10944/Node1.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0of:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Sep/17 6:06 AM;krw910;no longer valid now that we have serialized the ledger.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Alpha Functionality Summary Document,INDY-162,17564,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,TechWritingWhiz,TechWritingWhiz,06/Jun/17 11:20 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,12/Jun/17 12:00 AM,0,Documentation,,,,,"This ticket is created by request. A minimum go live functionality summary document needs to be created. It is currently slated for approximately 6/7-6/12/17. Please finish the document and assign to Misty Bledsoe for editing, so that it may be completed before 6/12/17.

 

The initial drafting is here: [https://docs.google.com/a/evernym.com/document/d/1tIzwhIUNTWaeNNWvkf085aqsSeOVQ2P6cNZ9UsrXTSs/edit?usp=sharing]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1bb:",,,,,,H1,,,,,,,,,,,,,,,,,,,,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Changing a node alias,INDY-163,17568,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,alexander.shekhovcov,alexander.shekhovcov,07/Jun/17 12:34 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Could,,,,,"For the current moment Steward is not able to change the Node's alias because
{code:java}
if nodeData.get(ALIAS) != data.get(ALIAS):
    return True 
{code}
in *isNodeDataConflicting* function of the plenum.

[~aleksey-roldugin] has faced with the case when he added a node with alias Node5 and a wrong 'dest' so nobody will be able to add a node with alias Node5 and the node name Node5 is forever reserved by the useless record.

 

If it is not an issue just mark this ticket as Invalid.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0pr:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/17 6:23 AM;krw910;This is working as designed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Revisit ledger serialisation (Design/research task),INDY-164,17571,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,lovesh,lovesh,07/Jun/17 1:12 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"Our current serialisation has some problems:
# Does not differentiate between null and empty strings
# Does not support versions
# Mandates indicating each possible field in the serialised data, and indicating each absent field with an empty string. This is inefficient and can lead to errors.

Possible solutions
# Use a standard serialisation protocol like Protobuf or Avro
# Have the first byte or 2 of each transaction as a bitset with bits being set for the fields present in the transaction, (assumes a total order defined on the fields) and then the values follow the included fields.

In both cases we should have a ledger viewer script that can be used to pretty print the transactions from ledger, piping the output of ledger files to a deserialiser can be used to build a less like utility for the ledger
",,,540,540,,0%,540,540,,,,,,INDY-373,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy233:",,,,,,H3,,,,,,,,,,,,,,,,,,,,ashcherbakov,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 10:04 PM;ashcherbakov;I assume that we need to have a PoA/proposal about the changes, and implement the changes in separate subtasks.;;;","03/Jul/17 10:44 PM;ashcherbakov;Created INDY-373 for implementation.;;;","03/Jul/17 10:44 PM;ashcherbakov;A document with Proposed Solutions and PoA:
https://docs.google.com/document/d/1v0z5yhw-fyaaQpDQNaXVhpzmqybjuZc9s-WidjTrY3U/edit#heading=h.tsyy1ibjsi2b

* It contains Comparison of different Options
* I did some testing for each of the options to compare the Ledger size (stored 1,000,000 NODE-like txns with both random and equal data in each txn)
* The Options is a combination of
** Serialization Option (JSON, BSON, MsgPack, Protobuf, Avro, Custom Serializer)
** Storage Option (Files or Key_value Storage (leveldb with snappy))

I Propose the following Options (by rank):
# MsgPack in LevelDB
#* Easy to use and implement
#* Compact because of both MsgPack and Snappy compression
#* Quite efficient in File Storage as well
# JSON in LevelDB
#* Easy to use and implement
#* Quite compact due to Leveldb (snappy) compression
#* The only change is to use levelDB for ledger storage
;;;","06/Jul/17 12:48 AM;ashcherbakov;[~danielhardman] [~gudkov] [~lovesh] [~jlaw 1] 
It would be great to know your opinion;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] Available claims are duplicated after restarting the faber.py script,INDY-165,17572,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,danielhardman,ozheregelya,ozheregelya,07/Jun/17 1:43 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,," 

*Case 1*
*Steps to Reproduce:*
1. Perform all steps of Getting Started tutorial.
=> script /usr/local/lib/python3.5/dist-packages/sovrin_client/test/agent/faber.py is running on agent02, ALICE is prompted on agent01. 
2. agent02: break the running of faber.py.
3. agent01: perform command in CLI: {code}request available claims from Faber{code}
=> ""Expanding Faber to ""Faber College"" bWjjA6 looking for Faber College at 10.0.0.202:5555"" is shown.
4. agent02: run the faber.py script again.
=> ""Available Claim(s): Transcript"" appears in agent01 CLI.
5. agent01: perform requesting available claims again: {code}request available claims from Faber{code}


*Actual Results:*
{code}
ALICE@test> request available claims from Faber
Expanding Faber to ""Faber College""

Signature accepted.
 Available Claim(s): Transcript,Transcript
{code}


*Expected Results:*
Claim Transcript should not be duplicated.


*Additional Information:*
This problem reproduces only for Faber. All works correctly for Acme and there are no available claims for Thrift.","Build Info:
Client version: 0.3.20

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1dz:",,,,,,H1,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jun/17 2:06 AM;ozheregelya;FYI [~krw910], [~stevetolman], [~tylerq], [~ashcherbakov];;;","14/Jun/17 1:03 PM;krw910;I have verified this on build 0.3.138;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Steward Scenarios,INDY-166,17583,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,TechWritingWhiz,TechWritingWhiz,07/Jun/17 4:20 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,22/Jun/17 12:00 AM,0,documentation,Must,,,,"Create a handful of scenarios that stewards can try. The items to choose from are located on the document called ""Hardening Plan"" under the section: ""Key Use Cases that Should Work"". Also decide on where these scenarios should ""live"" in order to point people to.  Three to five steps, approx 1/2 page each (ish)",,,32400,540,,0%,32400,540,,,INDY-205,INDY-218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1zr:",,,,,,H1,H4,,,,,,,,,,,,,,,,,,,danielhardman,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/17 10:29 PM;danielhardman;Misty, can you please include a link to your doc so I can test it?;;;","20/Jun/17 10:36 PM;TechWritingWhiz;Sorry: [https://docs.google.com/document/d/1OX3POcu7ac1hC5C9V5lw2RK8bJ2ahmT13rx82lh3QdQ/edit#heading=h.k7r4cc5k1xs1]

 ;;;","23/Jun/17 9:20 AM;danielhardman;I know I am a bottleneck on this ticket. I am struggling with it. The writing is fine, but I am really reluctant to release these instructions to alpha stewards, because the way we are telling them to accomplish certain tasks is broken. This is a problem with our code, not the doc. I am tempted to fix the code and then revise the doc, rather than releasing the doc as-is.;;;","27/Jun/17 7:32 AM;danielhardman;Need support for DIDs before the instructions we give to stewards can be optimal.;;;","27/Jun/17 7:33 AM;danielhardman;Need support for DIDs before the instructions we give to stewards can be optimal.;;;","27/Jun/17 7:37 AM;danielhardman;Need correct terminology in CLI before doc can be released.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need post-publication install test,INDY-167,17591,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,farooq_m_khan,danielhardman,danielhardman,07/Jun/17 6:07 AM,30/Mar/19 5:39 AM,28/Oct/23 2:46 AM,30/Mar/19 5:39 AM,,,,,0,should,,,,,"We do a lot of testing before packages (e.g., .deb files) are published in an official repo. This testing tells us a lot–but one thing it cannot tell us is whether the publication itself was handled correctly. We had a recent issue where a release candidate had passed all acceptance tests, but when we copied it from the ""rc"" repo to the ""stable"" repo, we forgot to copy a dependency. This mistake broke the Getting Started Guide and the ability for the public to install a stable build–and we didn't notice for a few hours.

We need some automation that does an install of the software on some sort of a schedule (e.g., once per hour). This automation should prove that:
 * The install of indy-node works on each core platform.
 * The indy client can be installed on the same machine as indy-node (they don't have conflicting dependencies)
 * uninstall works",,,97200,1620,,0%,97200,1620,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0pz:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 5:49 AM;stevetolman;Please talk with Kelly for requirements;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create proper documentation for new CI workflow,INDY-168,17604,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dfarns,andrey.goncharov,andrey.goncharov,07/Jun/17 5:37 PM,09/Oct/19 5:43 PM,28/Oct/23 2:46 AM,09/Oct/19 5:43 PM,,,,,0,6Months,should,,,,"Documentation should include:
 * description of how our pipelines work
 * quick overview of jenkins-shared
 * quick overview of sovrin-packaging
 * description of how our versioning system works",,,480,480,,0%,480,480,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-792,,,,,,,,,,"1|hzx1f3:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jun/17 6:38 PM;ashcherbakov;Current docs that may help:
https://docs.google.com/presentation/d/1SErM8juWOGQtP0O7AdEfoprUhYTMaYSpm1aiXYQoVws/edit#slide=id.p
https://docs.google.com/document/d/1gKf3F_r7WamoIYS_-ts2nruB2VIuiIpjmzPIVNf2VK0/edit#heading=h.kfq1n5pgiodo
https://docs.google.com/document/d/1gKf3F_r7WamoIYS_-ts2nruB2VIuiIpjmzPIVNf2VK0/edit#heading=h.kvlyvlhq1mft;;;","07/Jun/17 11:25 PM;andrey.goncharov;[Stable build manual|https://docs.google.com/document/d/1pFq6rqjUom5CKG_pLTjGLjOlwsm2gQpSbOT-uX_dPDg] created;;;","09/Oct/19 5:43 PM;ashcherbakov;Currently we have [https://github.com/hyperledger/indy-node/blob/master/docs/source/ci-cd.md]

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Set up archiving of old DEBs ,INDY-169,17606,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,dfarns,andrey.goncharov,andrey.goncharov,07/Jun/17 6:01 PM,29/Oct/19 11:40 PM,28/Oct/23 2:46 AM,,,,,,0,6Months,Could,,,,Currently we store all DEBs we ever produced in our repo. It causes 'freight cache' to be extremely slow. We should keep only a dozen of latest debs and archive old ones. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzx1fb:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/19 11:40 PM;esplinr;[~SteveGoob]: It looks like repo.sovrin.org still saves every master build. Should we have a cron job to remove them after six months?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
sovrin cli doesn't provide ability to change node's verkey using NODE command,INDY-170,17609,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,andkononykhin,andkononykhin,07/Jun/17 7:16 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"Node's key could be changed using API: there is special property 'verkey' which should be specified along with 'dest' (current node's id) in request.

Such functionality is missing in cli.

Steps to reproduce:
 # run sovrin cli
 # try help command 'help send NODE'
 # ensure that only 'dest' and 'data' properties are expected
 # try to specify verkey property for send NODE command
 # error will appear

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy26f:",,,,,,H3,,,,,,,,,,,,,,,,,,,,andkononykhin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin-Client: cli.log file is created at location of client execution,INDY-171,17610,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,farooq_m_khan,farooq_m_khan,07/Jun/17 7:17 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,should,,,,"Install Sovrin client on a Ubuntu machine

SSH into the machine and change directory to folder where you do not have permissions

example:
{code:java}
cd /usr/local/bin{code}
execute command:
{code:java}
sovrin{code}
This will fail with following error
{code:java}
Loading module /usr/local/lib/python3.5/dist-packages/config/config-crypto-example1.py
Module loaded.
Traceback (most recent call last):
  File ""/usr/local/bin/sovrin"", line 78, in <module>
    run_cli()
  File ""/usr/local/bin/sovrin"", line 53, in run_cli
    withNode=withNode
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 113, in __init__
    super().__init__(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 260, in __init__
    Logger().enableFileLogging(logFileName)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/common/log.py"", line 107, in enableFileLogging
    maxBytes=self._config.logRotationMaxBytes)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/common/logging/TimeAndSizeRotatingFileHandler.py"", line 14, in __init__
    utc, atTime)
  File ""/usr/lib/python3.5/logging/handlers.py"", line 202, in __init__
    BaseRotatingHandler.__init__(self, filename, 'a', encoding, delay)
  File ""/usr/lib/python3.5/logging/handlers.py"", line 57, in __init__
    logging.FileHandler.__init__(self, filename, mode, encoding, delay)
  File ""/usr/lib/python3.5/logging/__init__.py"", line 1008, in __init__
    StreamHandler.__init__(self, self._open())
  File ""/usr/lib/python3.5/logging/__init__.py"", line 1037, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/usr/local/bin/cli.log'
{code}
This is becuase cli attempts to create log files in ""cwd"" the log should be created in */var/log/*sovrin directory 

 
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy0wn:",,,,,,,,,,,,,,,,,,,,,,,,,,farooq_m_khan,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:58 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Result of send GET_NYM command may be unpredictable after demoting a node and further promoting it back,INDY-172,17611,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,Derashe,spivachuk,spivachuk,07/Jun/17 7:57 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,6Months,should,Stability,,,"Ledgers may be unsynchronized after demoting a node, sending transactions and further promoting this node back. In result the outcome of send GET_NYM command may be unpredictable.

The bug seems to be related to INDY-158.

The bug was faced on the following versions:
* sovrin-node 0.3.129 master deb package,
* sovrin-client 0.3.125 master deb package.

I have faced this bug using the steps below. However, it is not stably reproduced using these steps.

Steps and gotten results:
# Install a local pool from Vagrant script with changed APT repositories from {{xenial stable}} to {{xenial master}} in {{sovrin-environments/vagrant/training/vb-multi-vm/scripts/agent.sh}} and {{sovrin-environments/vagrant/training/vb-multi-vm/scripts/validator.sh}}.
# For each node VM: connect to it via SSH, switch the user to {{sovrin}}, open the identity ledger file {{~/.sovrin/data/nodes/<NODE_ALIAS>/transactions_sandbox/<CURRENT_LOG_FILE>}} in live mode (e.g. using {{tail -f}} command) and leave the session open.
# Connect to the client VM via SSH and launch {{sovrin}}.
# Execute: {{connect test}}
# Execute: {{new key with seed 000000000000000000000000Trustee1}}
# Execute: {{send NYM dest=1111111111111111}}
*[ The transaction creating NYM 1111111111111111 is added to the identity ledgers on all the nodes. ]*
*[ CLI reports: {{Nym 1111111111111111 added}} ]*
# Execute:
{noformat}
send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={""alias"": ""Node1"", ""services"": []}
{noformat}
*[ CLI reports that it has been disconnected from Node1C. ]*
*[ CLI reports that the node request has been completed. ]*
# Execute: {{send NYM dest=2222222222222222}}
*[ The transaction creating NYM 2222222222222222 is added to the identity ledgers on Node2, Node3 and Node4. ]*
*[ CLI reports: {{Nym 2222222222222222 added}} ]*
# Execute:
{noformat}
send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={""alias"": ""Node1"", ""services"": [""VALIDATOR""]}
{noformat}
*[ The transaction creating NYM 2222222222222222 is added to the identity ledger on Node1. ]*
*[ CLI reports that it has been connected to Node1C. ]*
*[ CLI reports that the node request has been completed. ]*
# Execute: {{send NYM dest=3333333333333333}}
*[ The transaction creating NYM 3333333333333333 is added to the identity ledgers on all the nodes. ]*
*[ CLI reports: {{Nym 3333333333333333 added}} ]*
# Execute:
{noformat}
send NODE dest=8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb data={""alias"": ""Node2"", ""services"": []}
{noformat}
*[ CLI reports that it has been disconnected from Node2C. ]*
*[ CLI reports that the node request has been completed. ]*
# Execute: {{send NYM dest=4444444444444444}}
*[ The transaction creating NYM 4444444444444444 is added to the identity ledgers on Node1, Node3 and Node4. ]*
*[ CLI reports: {{Nym 4444444444444444 added}} ]*
# Execute:
{noformat}
send NODE dest=8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb data={""alias"": ""Node2"", ""services"": [""VALIDATOR""]}
{noformat}
{color:red}*[ The transaction creating NYM 4444444444444444 is NOT added to the identity ledger on Node2. ]*{color}
*[ CLI reports that it has been connected to Node2C. ]*
*[ CLI reports that the node request has been completed. ]*
# Multiple times execute: {{send GET_NYM dest=4444444444444444}}
# Each time CLI reports: {{No verkey ever assigned to the identifier 4444444444444444}}
# Execute: {{send NYM dest=5555555555555555}}
{color:red}*[ The transaction creating NYM 5555555555555555 is added to the identity ledgers ONLY on Node1 and Node3. ]*{color}
*[ CLI reports: {{Nym 5555555555555555 added}} ]*
# Multiple times execute the following commands mixed together:
{{send GET_NYM dest=4444444444444444}}
{{send GET_NYM dest=5555555555555555}}
*[ For 4444444444444444 the CLI reports each time: {{No verkey ever assigned to the identifier 4444444444444444}} ]*
{color:red}*[ For 5555555555555555 the CLI reports sometimes: {{No verkey ever assigned to the identifier 5555555555555555}}, sometimes: {{NYM 5555555555555555 not found}} ]*{color}",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzx153:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jun/17 9:17 PM;spivachuk;Noticed that there are a lot of occurrences of the following message in the log of Node1:
{{<DATE_AND_TIME> | DEBUG    | replica.py           ( 823) | isNextPrePrepare | Node1:0 missing PRE-PREPAREs between 9 and 9}}
and there are a lot of occurrences of the following message in the log of Node3:
{{<DATE_AND_TIME> | DEBUG    | replica.py           ( 823) | isNextPrePrepare | Node3:0 missing PRE-PREPAREs between 9 and 9}};;;","06/Nov/18 11:31 PM;Derashe;Problem did not reproduced in test environment on indy-node version 1.6.656. So it will be closed in scope of bug triaging.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin-Environment: validator.sh script expects orientdb,INDY-173,17612,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Lowest,Done,danielhardman,farooq_m_khan,farooq_m_khan,07/Jun/17 9:37 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,shakedown3,,,,,"Follow the steps on page: [TestSovrinClusterSetup|[https://github.com/evernym/sovrin-environments/blob/master/vagrant/training/vb-multi-vm/TestSovrinClusterSetup.md]] to setup Validators using Vagrant

You will see following errors:

==> validator02: chmod:
 ==> validator02: cannot access '/etc/systemd/system/orientdb.service'
 ==> validator02: : No such file or directory

==> validator03: chmod:
 ==> validator03: cannot access '/etc/systemd/system/orientdb.service'
 ==> validator03: : No such file or directory

==> validator04: chmod:
 ==> validator04: cannot access '/etc/systemd/system/orientdb.service'
 ==> validator04: : No such file or directory

Trivial defect we need to remove the chmod for orientdb.server from the script since orientdb is no more used
  

There is also a minor typo in hosts file at: vagrant/training/vb-multi-vm/etc/hosts
  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1e7:",,,,,,H1,,,,,,,,,,,,,,,,,,,,farooq_m_khan,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 12:30 PM;krw910;I have verified the script on github and the reference to orientDB has been removed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] Invalid messages after sending proof with invalid <claim-name> or <remote>,INDY-174,17613,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,danielhardman,ozheregelya,ozheregelya,07/Jun/17 11:02 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"h2. Case 1

*Steps to Reproduce:*
 1. Open the CLI on Agent01.
 2. Try to perform 'send proof' command with invalid claim or invalid remote. E.g.
{code:java}
sovrin@test> send proof Job-Application to Acmr
sovrin@test> send proof Job-Applicatiom to Acme
{code}
 

*Actual Results:*
 The message ""No matching Proof Requests found in current keyring"" is shown several times. Then ""Invalid command: 'send proof Job-Application to Acmr'"" and whole help message is shown:
{code:java}
sovrin@test> send proof Job-Application to Acmr
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
No matching Proof Requests found in current keyring
Invalid command: 'send proof Job-Application to Acmr'
Sovrin-CLI, a simple command-line interface for a Sovrin Identity platform.
Commands:
help - Shows this or specific help message for given command
Usage:
help [<command name>]
connect - Lets you connect to the respective environment (test/live)
Usage:
connect test|live
disconnect - Disconnects from currently connected environment
status - Shows general status of the sandbox
prompt - Changes the prompt to given principal (a person like Alice, an organization like Faber College, or an IoT-style thing)
new node - Starts new node
new client - Starts new client
status node - Shows status for given node
status client - Shows status for given client
load plugins - load plugins from given directory
new keyring - Creates new keyring
rename keyring - Renames given keyring
use keyring - Loads given keyring and marks it active/default
save keyring - Saves active keyring
list keyrings - Lists all keyrings
new key - Adds new key to active keyring
use identifier - Marks given identifier active/default
list ids - Lists all identifiers of active keyring
client send - Client sends a message to pool
client show request status - Shows status of a sent request
create genesis transaction file - Creates genesis transaction file with in memory genesis transaction data
add genesis transaction - Adds given genesis transaction
new identifier - Creates new Identifier
send NYM - Adds given identifier to sovrin
send GET_NYM - Get NYM from sovrin
send ATTRIB - Adds attributes to existing identifier
send NODE - Adds a node to the pool
send POOL_UPGRADE - Sends instructions to nodes to update themselves
send SCHEMA - Adds schema to sovrin
send CLAIM_DEF - Adds claim definition for given schema
show - Shows content of given file
load - Creates the link
show link - Shows link info in case of one matching link, otherwise shows all the matching link names
sync - Synchronizes the link between the endpoints
ping - Pings given remote's endpoint
accept invitation from - Accept invitation from given remote
show claim - Shows given claim information
list claims - Refresh the list of claims
list links - List available links in active wallet
request claim - Request given claim
show proof request - Shows given proof request
set - Sets given value to given attribute name
send proofreq - Send a proof request
send proof - Sends given proof to given remote
request available claims from - Requests all available claims from given connection
license - Shows the license
exit - Exit the command-line interface ('quit' also works)
{code}
 

*Expected Results:*
 Only one ""No matching Proof Requests found in current keyring"" message should be shown only once. ""Invalid command"" message and help should not be shown.
 Additional Information:
 Count of messages is non-permanent. Sometimes it may be about 4, sometimes in may be up to 30.","Build Info:
sovrin-client version: 0.3.122
sovrin-node version: 0.3.115


 OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1dr:",,,,,,H1,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jun/17 11:03 PM;ozheregelya;FYI [~krw910], [~stevetolman], [~tylerq], [~ashcherbakov];;;","14/Jun/17 12:53 PM;krw910;Followed the steps in the Getting Started Tutorial and the steps in this ticket. The issue has been addressed so the message does not repeat.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[send NYM] Add verkey and update verkey commands don't work,INDY-175,17614,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,VladimirWork,VladimirWork,07/Jun/17 11:50 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
sovrin-node 0.3.19
sovrin-client 0.3.20

Overview:
Add verkey and update verkey commands don't work.

Steps to Reproduce:
1. Add new key identifier.
2. Login as Trustee and add initial verkey to new identifier.
3. Login as new identifier by its key and update its own verkey.

Actual Results:
Command ""list ids with verkeys"" returns incorrect verkeys (they differ from verkeys returned by ""send GET_NYM"").
Update verkey command (by its owner) throws not user-friendly error (screenshot) and doesn't work.

Expected Results:
Add verkey and update verkey commands should add and update verkey respectively.
All errors due to this commands execution should be human-readable.

Additional info:
This issue blocks complex confirmation of INDY-110.
",,,32400,32400,,0%,32400,32400,,,,,,INDY-110,,,,,,,,,,,,,,,,,,,,,"07/Jun/17 11:46 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/10978/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy167:",,,,,,H1,H2,,,,,,,,,,,,,,,,,,,andkononykhin,lovesh,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jun/17 11:51 PM;VladimirWork;FYI [~kelly.wilson], [~stevetolman], [~tylerq], [~ashcherbakov];;;","08/Jun/17 10:43 PM;VladimirWork;Update:

After 2nd step verkey is actually added (""send GET_NYM"" command returns it), so command ""list ids with verkeys"" returns incorrect verkeys.;;;","08/Jun/17 11:47 PM;VladimirWork;Another case to update verkey:

1. Create new identifier.
2. Login as Trustee and send NYM with verkey.
3. Login as identifier and send NYM with another verkey.

Actual result:
Error: client request invalid: InvalidClientRequest('U3ffnruvX9BRFAZqMTWfGM is neither Trustee nor owner of FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB',)

Expected result:
Verkey should can be changed by its owner.

Additional info:
sovrin@test> new identifier
Identifier created in keyring Default
Key for identifier is FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB
Current identifier set to U3ffnruvX9BRFAZqMTWfGM
sovrin@test> new key with seed 000000000000000000000000Trustee1
Key created in keyring Default
Identifier for key is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
Current identifier set to GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
sovrin@test> send NYM dest=FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB verkey=~1234567891234567
Adding nym FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB
Nym FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB added
sovrin@test> send GET_NYM dest=FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB
Getting nym FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB
Current verkey for NYM FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB is ~1234567891234567
sovrin@test> use identifier U3ffnruvX9BRFAZqMTWfGM
Current identifier set to U3ffnruvX9BRFAZqMTWfGM
sovrin@test> send NYM dest=FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB verkey=~987654321987654
Adding nym FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB
Error: client request invalid: InvalidClientRequest('U3ffnruvX9BRFAZqMTWfGM is neither Trustee nor owner of FjyeXLBc6Gp1Mmdo9hXtHpKwasQcyAeYo7qJGHBj2XBB',)
;;;","19/Jun/17 11:12 PM;lovesh;[~VladimirWork] [~andkononykhin] The screenshot shows the DID as too long and you are trying to add an abbreviated verkey, so the command should not work;;;","19/Jun/17 11:16 PM;andkononykhin;[~lovesh] actually this error haven't happened in my tests. But I saw another error message: ...
{code:java}
sovrin@test> list ids with verkeys 
Active keyring: Default (active identifier: GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL) 
 
Identifiers: 
  5zJvaEJG53fHT8Cdoj6JfjZRSwTkxZMtw5VjafusTM6Z, verkey: 5zJvaEJG53fHT8Cdoj6JfjZRSwTkxZMtw5VjafusTM6Z 
  8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz, verkey: 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
  GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL, verkey: GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL 
  rspyWa7YXktwLyQaBHc7qh3Lf1orcodSLCnUjWxCRt2, verkey: rspyWa7YXktwLyQaBHc7qh3Lf1orcodSLCnUjWxCRt2 
  DGEg6c3nGSUCmUoEyK59Cy1LvLcj3oFiMNjynmaSCiQE, verkey: DGEg6c3nGSUCmUoEyK59Cy1LvLcj3oFiMNjynmaSCiQE 

sovrin@test> send NYM dest=8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz verkey=8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Adding nym 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Nym 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz added 

sovrin@test> use identifier 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Current identifier set to 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
sovrin@test> send GET_NYM dest=5zJvaEJG53fHT8Cdoj6JfjZRSwTkxZMtw5VjafusTM6Z 
Getting nym 5zJvaEJG53fHT8Cdoj6JfjZRSwTkxZMtw5VjafusTM6Z 
Current verkey for NYM 5zJvaEJG53fHT8Cdoj6JfjZRSwTkxZMtw5VjafusTM6Z is rspyWa7YXktwLyQaBHc7qh3Lf1orcodSLCnUjWxCRt2 

sovrin@test> send GET_NYM dest=8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Getting nym 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Current verkey for NYM 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz is 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 

sovrin@test> send NYM dest=8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz verkey=GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL 
Adding nym 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Nym 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz added 

sovrin@test> send GET_NYM dest=8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Getting nym 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Current verkey for NYM 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL 

sovrin@test> use identifier 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Current identifier set to 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 

sovrin@test> send GET_NYM dest=8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Getting nym 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Current verkey for NYM 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL 

sovrin@test> send NYM dest=8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz verkey=8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Adding nym 8fjYiRG4RVBPLtx59Pox9nAWNjXnmAXyEz6M65nE3Gfz 
Error: client request invalid: InvalidSignature(){code}
 
UPDATE
I found that It is known case and is treated as valid according to this docs:  https://docs.google.com/document/d/1FSdnzw1Efpu60LRNFcO5fT8eTz83e4fFS8xpxgMsrKA/edit#
The reason: incorrect sequence of verkey change.;;;","19/Jun/17 11:35 PM;andkononykhin;Hello, [~danielhardman] [~lovesh]

Could you clarify the requirements for 'list ids' command.

As I discovered, it uses local data (stored in in-memory wallet) about ids and verkeys that is non synced with ledger. So, if we do 'send NYM' we could update verkey on ledger but it won't change in-memory data in client's wallet.

So, my questions are:
 # what expected result of 'list ids' command
 # should it be updated when we do 'send NYM' or/and 'send GET_NYM'
 # what other cli command should affect the wallet
 # what if we have several clients, how should they sync their data in wallets

Thank you;;;","26/Jun/17 11:00 PM;andkononykhin;Hello, [~krw910]

I'm done with task. Please test it.

The task is about several issues. I will explain them one by one. 

Originally reported issues:
                                                                                                                                                                                                                                                                               
1. 'list ids' output doesn't match 'send GET_NYM' 
   Not as issue. Works as designed. See my comment above 
   https://jira.hyperledger.org/browse/INDY-175?focusedCommentId=26746&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-26746

2. Update verkey command doesn't work.                                                                                                                                                                                                                                                                                
   Steps to reproduce.
                                                                                                                                                                                                                                                                               
   Case 1 (see description):
   Case 2 (see comment https://jira.hyperledger.org/browse/INDY-175?focusedCommentId=25745&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-25745)

   Not an issue cause steps to reproduce in these cases are not correct. 
   Actually we can easily create verkey using 'send NYM' command.
   Also it's possible to update it as well, but a bit tricky.
   Please, see https://docs.google.com/document/d/1FSdnzw1Efpu60LRNFcO5fT8eTz83e4fFS8xpxgMsrKA/edit# for more details   
                                                              
3. Update verkey command throws not user-friendly error (screenshot description)      
                                                                                                                                                                                                                                                                               
   Resolved by this PR: https://github.com/evernym/plenum/pull/222
                                                                                                                                                                                                                                                                               
Newfound issue:

4. Incorrect verkey is accepted

    Case 1 (see screenshort) includes step with incorrect verkey passed as original for new nym:
        (45 'F') FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF 

    Pool accepted it but all further messages from the client with such verkey were discared,
    cause decoded b58 byte-string has length 33. So, 'odd-length' exceptions were raised.

    Resolved by this PR: https://github.com/evernym/plenum/pull/226


How to test:

1) test that odd-length verkey is rejected:

    env packages (master):
        - python3-plenum = 0.3.154
        - pyhton3-sovrin-common = 0.2.96
        - sovrin-client  = 0.3.150
        - sovrin-node = 0.3.161
    
    1. launch client ('sovrin' tool)
    2. commands:
        - connect test
        - new identifier (grab VERKEY)
        - new key with seed 000000000000000000000000Trustee1
        - send NYM dest=ID verkey=FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF (copy-paste that, 45 'F')

        you will see the following error:
            Error: client request invalid: InvalidClientRequest('validation error: b58 decoded value length 33 should be one of [32] (verkey=FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF)',)

2) you can't see non-human readable message mentioned in description cause odd-length verkey is reject from the first place (first NYM command with verkey) as it was shown in previous test

Thank you;;;","27/Jun/17 6:41 PM;VladimirWork;Build Info:
sovrin-client = 0.3.150
sovrin-node = 0.3.161

Steps to Validate:
1. Add new identifier.
2. Login as Trustee.
3. Send NYM to added identifier with ""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF"" verkey.

Actual Results:
Error: client request invalid: InvalidClientRequest('validation error: b58 decoded value length 33 should be one of 32).
Errors with ""odd-length string"" text are not displayed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Suppressed generic exception in plenum's remote keys rotation routine,INDY-176,17619,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,andkononykhin,andkononykhin,08/Jun/17 2:21 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,shakedown4,,,,"It happens when node changes keys for one of remotes (plenum code):

[https://github.com/evernym/plenum/blob/master/plenum/common/stack_manager.py#L175]

Any kind of error is passed with only error notification to log:
{code:java}
2017-06-07 09:40:05,969 | DEBUG    | stack_manager.py     ( 160) | stackKeysChanged | Node1 clearing remote role data in keep of Node5 
2017-06-07 09:40:05,970 | DEBUG    | stack_manager.py     ( 162) | stackKeysChanged | Node1 removing remote Node5 
2017-06-07 09:40:05,970 | DEBUG    | zstack.py            ( 109) | disconnect | disconnecting remote Node5:HA(host='127.0.0.1', port=9709) 
2017-06-07 09:40:05,971 | TRACE    | zstack.py            ( 112) | disconnect | disconnecting socket 62 44081648 
2017-06-07 09:40:05,971 | TRACE    | zstack.py            ( 115) | disconnect | Node5:HA(host='127.0.0.1', port=9709) closing monitor socket 
2017-06-07 09:40:05,971 | DEBUG    | stack_manager.py     ( 185) | removeRemote | Node1 removed remote Node5 
2017-06-07 09:40:05,972 | ERROR    | stack_manager.py     ( 173) | stackKeysChanged | Exception while initializing keep for remote a bytes-like object is required, not 'str'{code}
Seems it doesn't lead to any breakage but looks strange.

Steps to reproduce:
 # start pool
 # add new node
 # perform node key rotation for added node (I used tool based on logic of test [testNodeKeysChanged|https://github.com/evernym/plenum/blob/master/plenum/test/pool_transactions/test_node_key_changed.py])

 

Env: debs, rc
 * python3-stp 0.1.9
 * python3-ledger 0.2.14
 * python3-plenum 0.3.13
 * python3-sovrin-common 0.2.9
 * sovrin-client 0.3.18
 * sovrin-node 0.3.15",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy173:",,,,,,H1,H2,,,,,,,,,,,,,,,,,,,andkononykhin,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 10:52 PM;andkononykhin;I checked that using mentioned rc packages: it was caused by passing verkey as string to zmq API where bytestring is expected.

It was fixed by that commit: [https://github.com/evernym/plenum/commit/ea1c39118b3720bb6efb0dc9467554776577bf96#diff-9c07832b246cbe747816eeedc2dec46cL166] and doesn't appear in master for now.

 ;;;","20/Jun/17 2:48 AM;danielhardman;Line 179 of stack_manager.py still contains the overly broad ""except"" clause: [https://github.com/evernym/plenum/blob/master/plenum/common/stack_manager.py#L179.] This pattern of catching all exceptions without understanding their semantics is usually a code smell. Please change it so that we are catching just the error(s) that we understand, by specific type, instead of catching a generic Exception. (Or, if catching a generic Exception is truly correct because, no matter what goes wrong, we know we want to catch it in this place, please add a comment justifying that decision.) Then, after you've had a PR accepted, assign the ticket back to me for customer validation again.;;;","22/Jun/17 8:16 PM;andkononykhin;[~danielhardman]
I've removed that exceptions suppression which could happen in intiRemoteKeys during updating keys for one of the node in the pool. Test has been provided.
(https://github.com/evernym/plenum/pull/225)

As we discussed with [~ashcherbakov] exception here means that we likely failed to update cert files, so the node won't be able to communicate with the other node which keys have been updated.

It's not the only place where something could go wrong. I mean both cases: suppressed generic exceptions and lack of try-catch blocks that cover all possible cases of failure. 
For now it seems we don't have general approach to handle exceptions ""on the top level"". I think it's an important issue out of that task's scope.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use CLI in automated scripts,INDY-177,17620,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,andkononykhin,andkononykhin,08/Jun/17 2:46 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,,,,,"It would be helpful to have ability to use sovrin-client in scripts. In particular, send multiple correlated commands and exit.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy0wv:",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:59 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin-Client: Incorrect sample path in getting Started Guide,INDY-178,17633,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Lowest,Done,,farooq_m_khan,farooq_m_khan,08/Jun/17 6:40 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,6Months,help-wanted,should,,,"CLI Details:

Running Sovrin 0.3.20

OS: Ubuntu 16 VM created using the vagrant scripts

 

[Getting Started Guide:Evaluate An Invitation|https://github.com/sovrin-foundation/sovrin-client/blob/master/getting-started.md#evaluate-an-invitation] this section points to incorrect path:
{code:java}
/<CLI_ROOT>/sample/faber-invitation.sovrin{code}
fable-invitation.sovrin file does not exist in this path.

 

If you try to locate it on the system, it is present at:
{code:java}
vagrant@agent01:~$ find / -name faber-invitation.sovrin 2>/dev/null
/usr/local/lib/python3.5/dist-packages/sample/faber-invitation.sovrin
{code}
The solution to the problem is not fixing the documentation its a bug in where the file is installed.

 

 
  
  ",,,,,,,,,,,,,,,,,INDY-179,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzy0x3:",,,,,,,,,,,,,,,,,,,,,,,,,,farooq_m_khan,Toktar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/17 11:48 PM;TechWritingWhiz;*Based on this comment: ""The solution to the problem is not fixing the documentation its a bug in where the file is installed."" this does not appear to be a documentation ticket. Removing the documentation label. Please assign this to the appropriate engineer.;;;","10/Oct/18 10:24 PM;Toktar;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin-Client: Show file command of not much use,INDY-179,17635,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,farooq_m_khan,farooq_m_khan,08/Jun/17 6:53 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,should,,,,"See the related defect INDY-179,

The ""*show <file>""* command does not support tabbing like a linux shell does, which means you have to know in advance where the file resides. To do that you have to get back to the linux file system. User could then very well use linux based editors like VI or NANO or others to read this file. Hence this command is redundant and not of much use.

 

 
  
  ",,,,,,,,,,,,,,,,,INDY-188,,,INDY-178,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzy0xb:",,,,,,,,,,,,,,,,,,,,,,,,,,farooq_m_khan,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 9:01 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Error when processing successive batches that do not change state,INDY-180,17636,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,lovesh,lovesh,08/Jun/17 8:36 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,shakedown3,,,,,"If successive batches do not change state and the previous batch is ordered after the next batch has started 3PC then it causes error in IdrCache. Eg. 2 same NYM transactions are done with different request ids quickly enough that first is not ordered but the second has started 3PC, then if these 2 transactions were the only ones in their respective batches, it causes a KeyError in IdrCache since the state root will not change after second txn",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1dj:",,,,,,H1,,,,,,,,,,,,,,,,,,,,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jun/17 5:59 PM;lovesh;Here is the change, https://github.com/sovrin-foundation/sovrin-node/commit/ad84e4a217746fd676b83ecba4d266f45f3f7c0c
and a test, https://github.com/sovrin-foundation/sovrin-node/commit/ad84e4a217746fd676b83ecba4d266f45f3f7c0c#diff-f1c448a66990b9ace49e85e9050bbaa2R1;;;","14/Jun/17 12:32 PM;krw910;I believe this has been fixed. I was running 8,000 transactions at the same time today did not run into any issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Each command should have a reply timeout in CLI,INDY-181,17637,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,andrey.goncharov,andrey.goncharov,08/Jun/17 9:42 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,should,,,,,"As a user I should get an error message in CLI if I send a command and I do not receive enough replies within a pre-defined timeout.

Steps to reproduce:
 # Create a pool of seven nodes
 # Turn off three of them
 # Send NYM

Result:

You never get a confirmation

Expected result:

You get an error message after a pre-defined timeout. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0q7:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Sep/17 5:51 AM;krw910;Since this time we have found that once the pool comes back to consensus the transaction will still go through. in some cases this could be 7 minutes. It is a function of the queue on the ledger and the time it is in the queue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
We do not have a mechanism to copy python3-rlp and python3-sha3 to Stable,INDY-182,17653,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,krw910,krw910,08/Jun/17 11:54 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"After we have approved an RC build we found that python3-rlp and python3-sha3 was not copied to the Stable repo. We currently do not have a mechanism when an RC build has been approved to copy those files to the Stable repo.

We copied them manually, but if there is a change to those files they will not be updated unless done manually.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1bj:",,,,,,H1,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jun/17 12:41 AM;andrey.goncharov;[~krw910] I fixed it right after copying them manually. It should be ok right now.;;;","14/Jun/17 11:00 AM;krw910;This has been fixed and the files are located where they should be to be moved from RC to Stable.;;;","14/Jun/17 1:06 PM;danielhardman;[~andrey.goncharov] Please point me at some code I can inspect to see what you fixed. I want to know that we have not simply copied these files, but instead have implemented a mechanism where dependencies get copied to the stable repos when appropriate. Once you've identified that mechanism so I can review it, you can set the ticket back to Customer Validation status and reassign to me.;;;","14/Jun/17 6:40 PM;andrey.goncharov;[~danielhardman] to fix the issue at the time I indeed just copied those files. Yet I updated our build script o do it automatically in the future. I need to point out it was not tested properly since it required to release a new stable. We will test it as soon as we build a new stable with some new dependencies.

It was fixed in this commit:

https://github.com/evernym/jenkins-shared/commit/e749c0c90d272c25bf1119039d7662084823f734;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need documentation on how to manually upgrade a node using the migration script mechanism,INDY-183,17654,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,08/Jun/17 11:59 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"If a node does not upgrade when a POOL_UPGRADE command is sent they will need to manually upgrade their node. 
If the upgrade process requires using the migration script we will need to provide a how to document in order to run it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1av:",,,,,,H1,,,,,,,,,,,,,,,,,,,,andrey.goncharov,krw910,ozheregelya,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 7:19 AM;stevetolman;Don't spend more than 1 hour on this ticket.;;;","14/Jun/17 6:35 PM;andrey.goncharov;Already done https://docs.google.com/document/d/11dpCw1bu_9FGj8MTbfqrM9PvwAPmWx2slYOCdzEnids;;;","16/Jun/17 10:48 PM;ozheregelya;The instruction was verified for upgrade from 0.3.138 to 0.3.140 version. All mistakes are corrected.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move libsovrin-java into Hyperledger INDY,INDY-184,17661,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,peacekeeper,peacekeeper,peacekeeper,09/Jun/17 1:38 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,libsovrin,,0,should,,,,,"I've been working on a Java wrapper for libsovrin aka indy-sdk:
 [https://github.com/projectdanube/libsovrin-java]

On a recent Sovrin Foundation call we agreed it would make sense to incorporate this into the rest of the Hyperledger INDY infrastructure.

What needs to be done?
 # Change license to Apache2.
 # Make sure all contributors have signed the Hyperledger CLA via CLAHub.
 # Change Java package names from com.danubetech.* to something else?
 # Decide whether it should be a separate repository as it is now, or whether it should be a subdirectory in the ""indy-sdk"" repository.
 # Move Github repository to Github ""hyperledger"" account and rename repository from ""libsovrin-java"" to ""indy-sdk-java"".

What else?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1mn:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,peacekeeper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jun/17 1:39 AM;peacekeeper;Regarding 2., I'm the only contributor at this point, and I think I've already signed the CLA when previously I submitted pull requests to indy-sdk.;;;","09/Jun/17 9:09 AM;danielhardman;There is a folder inside indy-sdk where a java wrapper could conveniently be checked in; see [https://github.com/hyperledger/indy-sdk/tree/master/wrappers.] However, it could also make sense to make a separate repo; which strategy we pick is a question where I don't have a strong opinion.;;;","09/Jun/17 3:55 PM;peacekeeper;I also don't have a strong opinion, I guess it comes down to code management, branching and versioning.

I think I'd have a slight preference for making it a separate repo. Other Hyperledger projects seem to do that too, e.g. ""fabric-sdk-go"" ""fabric-sdk-py"" ""iroha-scala"" ""iroha-python"" ""iroha-android"".;;;","16/Jun/17 1:01 AM;peacekeeper;We decided on today's Agent WG call to add the Java wrapper as a folder of indy-sdk rather than a separate repository. I will create a pull request for this, then I can become a committer on the project. This approach also ""forces"" us to keep the main library and the wrappers in sync.;;;","16/Jun/17 6:02 AM;peacekeeper;Created pull request: https://github.com/hyperledger/indy-sdk/pull/46;;;","29/Jun/17 7:07 AM;peacekeeper;This has been completed, the code has been moved here per pull request on June 16 2017:
[https://github.com/hyperledger/indy-sdk/tree/master/wrappers/java]

And the old repository has a pointer to this new location.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
When we have more than F malicious nodes we must not reach consensus,INDY-185,17663,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,andrey.goncharov,andrey.goncharov,09/Jun/17 2:18 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,MGL,Must,,,,"Example, if we have pool of 7 nodes, we can stop 3 nodes and still reach consensus.

Steps to reproduce:
 * Setup a pool of 7 nodes
 * Demote a node
 * Stop 2 nodes
 * Try to send a NYM

Result: 

NYM is added

Expected result:

Consensus should not be reached

 

Suggestions:

Currently we require 2f+1 nodes for writes, shouldn't it be n -f ?",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,INDY-220,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy213:",,,,,,H1,H2,H3,H4,,,,,,,,,,,,,,,,,aleksey-roldugin,alexander.shekhovcov,andrey.goncharov,ashcherbakov,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jun/17 9:25 PM;lovesh;Our current calculation is *f = floor(n-1/3)* so when you demote a node, n becomes 6 and f becomes 1, our write quorums size is equal to *2f+1* which turns out to be 3 and hence the transaction succeeds since you have 4 nodes after 2 more crash. This problem is not particularly severe transactions since failures are not stopping the transactions. The fundamental problem with such calculation is that quorums don't intersect, so you have 6 nodes and write quorum size is 3 so you have 2 non-intersecting quorums, also a client can do reads from *f+1* which is 2 and still miss every node from a write quorum of *2f+1* which is 3 nodes, the way to solve is to use write quorum {n-f | n-f >=2f+1};;;","15/Jun/17 5:17 PM;ashcherbakov;[~lovesh] Should we ask BFT community about this?;;;","16/Jun/17 11:47 PM;lovesh;I asked folks from hyperledger fabric, they pointed me to https://github.com/hyperledger/fabric/blob/v0.6/consensus/pbft/pbft-core.go#L460-L470 and they use *(n+f+2)/2* for prepared (including PRE-PREPARE) and committed quorum and *n-f* for view change quorum, so every correct node *(n-f)* should be part of view change but only correct node *(f+1)* needs to see each phase of the 3 phase commit. This is how you come to *(n+f+2)/2*: a byzantine quorum *q* needs to satisfy correctness so every quorum needs to intersect in 1 correct replica, thus *2q > n+f => (n+f)/2 < q*, so minimum value of *q* is *(n+f)/2 + 1* or *(n+f+2)/2*
;;;","19/Jun/17 9:51 PM;ashcherbakov;[~lovesh] Do we have an answer from  RFBT authors?;;;","19/Jun/17 10:58 PM;ashcherbakov;[~lovesh] [~alexander.shekhovcov] Regardless of what the final values for consensus will be, let's make sure that we have single places in code where these consensuses are specified for each of the case, so that we can change it easily.;;;","19/Jun/17 11:17 PM;lovesh;[~alexander.shekhovcov] No, we don;t have an answer from RFBT authors.;;;","20/Jun/17 6:44 PM;alexander.shekhovcov;The current quorums:
 * PROPAGATE quorum *> f + 1*
 * PREPARE quorum *>= 2 * f*
 * COMMIT quorum *>= 2 * f + 1*
 * REPLY quorum *>= f + 1*

The PROPAGATE quorum has strict ""> f + 1""

From ""RBFT: Redundant Byzantine Fault Tolerance""
{quote}*When a node receives f + 1 PROPAGATE*
 *messages for a given request, the request is ready to be*
 *given to the replicas of the f + 1 protocol instances running*
 *locally, for ordering.*
{quote}
Should we use also greater or equal?;;;","20/Jun/17 6:52 PM;ashcherbakov;From Lovesh:
lovesh [9:30 PM] 
@alexander.shcherbakov I have got answer from RBFT's author and he is supportive of using n-f but i have asked him a followup question on using n+f+2/2, i will tell you when he replies to that.
;;;","21/Jun/17 12:07 AM;ashcherbakov;Items from ART meeting with a suggestion how to proceed with the task:
- enumerate the places where this needs to change (some of which will not be obvious -- the calculation may be done differently in different places -- perhaps switch to using the “do we have quorum?” functions). We need one module where we define what the thresholds are.
- use n-f for a quorum of PREPARES and COMMITS
- use n-f for a quorum for View Change (INSTANCE_CHANGE)
- discuss (n+f+2)/2 for prepared and committed quorum and n-f quorum for view changes.
;;;","23/Jun/17 8:21 PM;alexander.shekhovcov;*(/)*

*Problem reason:*
- 6-nodes pool with 2 malicious is able to get consensus because 2*f+1=3 for N=6 

*Changes:*
- set the commit quorum (write consensus) N-f

*Committed into:*

https://github.com/evernym/plenum/pull/224

*Risk:*
Medium

*Covered with tests:*

test_6_nodes_pool_cannot_reach_quorum_with_2_faulty

*Recommendations for QA:*
Steps:
 # a 6 nodes pool is running
 # stop 2 non primary nodes
 # check the pool does not process transactions

 

 ;;;","27/Jun/17 5:23 AM;krw910;I verified this ticket using 7 nodes. We followed the formula. On writes we needed 2f+1 and on the reads we needed f+1.

 

So with 7 nodes we needed 5 good nodes to do any writes and 3 good nodes to do any reads.;;;","10/Jul/17 9:06 PM;ashcherbakov;The issue was re-opened since QA reported that 4 of 6 nodes could come to a write consensus (however n-f is 5).


*Problem reason:*
 - Could not reproduced the issue.
 - QA couldn't reproduce it as well
 - All related tests pass
 - However, found out that not all tests used correct values for consensus. Some of the tests still used old values (2f+1, etc.)

*Changes:*
 - Updates the tests to use correct values for consensus in all places
 - Added more tests
 - Moved catch-up-related quroum values (ledger_status, consistency_proof, etc.) into `quorums.py` (a common place for all quorums)

*Committed into:*

https://github.com/hyperledger/indy-plenum/pull/260

*Risk:*
Low

*Covered with tests:*

[test_quorum_disconnected.py|https://github.com/hyperledger/indy-plenum/pull/260/files#diff-afd973ef3aa5d2b26d79bfe2a41d6897]

[test_num_prepare_with_2_of_6_faulty.py|https://github.com/hyperledger/indy-plenum/pull/260/files#diff-6adb16b24a1fcba1dd48232a7c2b4f41]

[test_num_commit_with_2_of_6_faulty.py|https://github.com/hyperledger/indy-plenum/pull/260/files#diff-052d8d02b8bf538bbddcbb490a61536c]

[test_quorum_faulty.py|https://github.com/hyperledger/indy-plenum/pull/260/files#diff-a48b48e51a20ee4d0608a88bc910c411]

 

 ;;;","14/Jul/17 3:47 AM;aleksey-roldugin;h6. BUILD

repository master
 sovrin 0.2.9
 sovrin-client 0.4.26
h6. CASE 1

Verification:
 # Setup a pool of 7 nodes.
 # Demote a node.
 # Stop 2 nodes.
 # Try to send a NYM.

Result: 
 NYM is not added.
h6. CASE 2

Verification:
 # 6 nodes pool is running.
 # Stop 2 non primary nodes.
 # Check the pool does not process transactions.

Result: 
 Pool does not process transactions.
h6. Additional information

Both cases were also verified on some previous versions.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node crashes if ledger file doesn't have write permission,INDY-186,17664,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,dsurnin,dsurnin,09/Jun/17 2:28 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,should,,,,,"remove write permission on ledger file;

rerun node;

it fails with file access exception",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0qf:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 6:21 AM;stevetolman;Any crash should have an appropriate error message so the admin has an idea of what to look for.;;;","26/Sep/17 5:54 AM;krw910;The system handles this issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace db files with db files from different pool. Node cannot restore the valid state,INDY-187,17668,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,dsurnin,dsurnin,09/Jun/17 3:03 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,shakedown4,should,,,,"Copy db files from different pool to node;

restart node;

node will not be able to restore the state and will not be able to commit transactions;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0qn:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Sep/17 5:57 AM;krw910;This is covered in INDY-864;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin-Client: Show command cannot show files with space in the name,INDY-188,17669,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Lowest,Invalid,stevetolman,farooq_m_khan,farooq_m_khan,09/Jun/17 3:07 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,Could,,,,"Setup Details: Running Sovrin 0.3.20

 
{code:java}
sovrin> show ""/WindowsEnding fabre invitation""
Invalid command: 'show ""/WindowsEnding fabre invitation""'{code}
 Show command does not understand file names with space in them.

 
 
 ",,,,,,,,,,,,,,,,,,,,INDY-179,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzy0xj:",,,,,,,,,,,,,,,,,,,,,,,,,,farooq_m_khan,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 9:01 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] Trustee can change verkey for CID if it was created without verkey,INDY-189,17691,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,stevetolman,ozheregelya,ozheregelya,09/Jun/17 10:37 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*Case 1*
 *Steps to Reproduce:*
 1. Create new CID (new key).
 2. As trustee, send NYM without verkey (send NYM dest=ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP or send NYM dest=ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP role=STEWARD).
 => NYM is send, default verkey is set equal to identifier.
 3. Send NYM again (as trustee) with verkey.

 

*Actual Results:*
 Verkey is successfully changed.
{code:java}
sovrin@test> new key
Key created in keyring oltest
Identifier for key is ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP
Current identifier set to ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP
sovrin@test> new key with seed 000000000000000000000000Trustee1
Key created in keyring oltest
Identifier for key is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
Current identifier set to GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
sovrin@test> send NYM dest=ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP
Adding nym ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP
Nym ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP added
sovrin@test> send GET_NYM dest=ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP
Getting nym ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP
Current verkey is same as identifier ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP
sovrin@test> send NYM dest=ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP verkey=A
SxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP
Adding nym ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP
Nym ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP added
{code}
*Expected Results:*
 Verkey should not be changed.


 *Case 2*
 *Steps to Reproduce:*
 1. Create new CID (new key).
 2. As trustee, send NYM without verkey (send NYM dest=ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP or send NYM dest=ASxpwNExaEjXtuscbVdPSBD8UQ4rw1DaoKVafcdhhmwP role=STEWARD).
 => NYM is send, default verkey is set equal to identifier.
 3. Try to change verkey using newly created identifier.
{code:java}
sovrin@test> use identifier FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
sovrin@test> send NYM dest=FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM verkey=FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiq1
{code}
 

*Actual Results:*
 Error appears:
{code:java}
sovrin@test> new key
Key created in keyring Default-VzUs8R
Identifier for key is FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
Current identifier set to FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
sovrin@test> new key with seed 000000000000000000000000Trustee1
Key created in keyring Default-VzUs8R
Identifier for key is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
Current identifier set to GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
J2RSqs5vGxDJ9tykU2z6QkRymDigqaNJbmLf6amTykrh now connected to Node6C
sovrin@test> send NYM dest=FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
Adding nym FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
Nym FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM added
sovrin@test> use identifier FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
Current identifier set to FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
sovrin@test> send NYM dest=FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM verkey=F
vpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiq1
Adding nym FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
Error: client request invalid: InvalidClientRequest('FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM is neither Trustee nor owner of FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM',)
{code}
*Expected Results:*
 Error should not appear, verkey should be changed.


 Additional Information:
Workaround of Case 2 - do not send NYM without verkey for CID, or send second NYM with verkey equal to identifier as trustee.","Build Info:
sovrin-client version: 0.3.122
sovrin-node version: 0.3.115


 OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jan/18 10:27 PM;Dimple-Kanwar;Error1.png;https://jira.hyperledger.org/secure/attachment/14514/Error1.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy26n:",,,,,,H3,,,,,,,,,,,,,,,,,,,,danielhardman,Dimple-Kanwar,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jun/17 10:40 PM;ozheregelya;FYI [~krw910], [~stevetolman], [~tylerq], [~ashcherbakov];;;","14/Jun/17 1:19 PM;danielhardman;After reading the bug report carefully, I believe we mainly have a problem with the semantics of commands in the CLI–not a problem with the logic enforced on the ledger. I think the CLI is using the last identifier and keypair in ways that are not obvious.

If this theory is true, then the bug is a serious annoyance, but it would not be a show-stopper–EXCEPT that our QA needs reliable behavior in order to test the more important underlying ledger behaviors. So we have to fix the CLI so we can test with confidence.

I asked Lovesh for some insight about the intended behavior of the send NYM transaction, and this is how he clarified:

The CLI has an `activeIdentifier` (DID) which is used while making any transactions (nodes see activeIdentifier as the author of txns). `new key [with seed]` does 2 things, creates a `Signer` object which can be considered a wrapper object over an identifier (a DID) and a keypair and sets the `activeIdentifier` to the identifier of the newly created signer object. So if you run `new key` command 3 times you will have 3 DID+keypairs in your wallet with CLI's `activeIdentifier` set to the identifier of the last created signer object. The ledger till this point does not know of any DIDs that you created locally. Now say you send a read (say GET_NYM) to the nodes, the nodes will see a DID they have not seen before but they dont care about checking the ledger since its a read and service the read, but when CLI sends a write txn (NYM) , nodes see the new DID, check in the ledger, do not find it and reject the txn (edited)

So you still have 3 DIDs+keypairs in your local wallet but nothing on ledger, but if you ask any TrustAnchor to onboard any of these DIDs to the ledger, once he does it you can send write txns from CLI using that DID (by doing `become <did>`) and then your writes will not be discarded.

 ;;;","14/Jun/17 1:21 PM;danielhardman;Given Lovesh's clarification, I would like a programmer to re-analyze Olga's bug report and see if all behaviors are explained as correct. If yes, the ticket can be closed. If no, please describe where the code logic is going wrong (that is, convert Olga's external observations into a code diagnosis)–then fix the bug.;;;","19/Jun/17 10:18 PM;ozheregelya;[~danielhardman], sorry for late answer, unfortunately I didn't get notification about your comment.

Regarding Lovesh's clarification:
I absolutely agree that new key command sets `activeIdentifier` to newly created CID. But in my example I switched on Trustee using command:
{code:java}
new key with seed 000000000000000000000000Trustee1{code}
So, active identifier was changed to known for Ledger Trustee before sending NYM.

 

As far as I understand, new key [with seed] creates new CID and keypair, not DID and keypair. When I (as Trustee) send following command,
{code:java}
send NYM dest=FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM{code}
I expect that NYM with this CID will be added to Ledger and verkey (equal to identifier) will be also added to Ledger. After that I expect that identity owner will be able to use this identifier. Now this part works as expected, we can verify it by sending GET_NYM as newly created identifier:
{code:java}
sovrin@test> use identifier FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
Current identifier set to FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
sovrin@test> send GET_NYM dest=FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
Getting nym FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM
Current verkey is same as identifier FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM{code}
Now Ledger knows this identifier and according verkey. As Identity Owner, I want to change my verkey, but I can't:
{code:java}
sovrin@test> use identifier FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM Current identifier set to FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM sovrin@test> send NYM dest=FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM verkey=11111111111111111111111111111111111111111111 Adding nym FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM Error: client request invalid: InvalidClientRequest('X3WzhHXupshDbVLJxEtUX6fpkKWKdvgLCnQuPbWDJBf is neither Trustee nor owner of FvpJGZtJ24charRZcx9hpqPziTdDtGy7v4QHHMjjAiqM',){code}
 And Identity Owner will not be able to change his verkey until Trustee will send to Ledger his verkey. This logic is correct for DID (because verkey is empty for DID after sending NYM without verkey) but it is wrong for CID.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nodes try to connect to a new node added in the demoted state,INDY-190,17697,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,spivachuk,spivachuk,10/Jun/17 1:16 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,6Months,shakedown4,should,,,"See the attached logs for details.

Version:
* sovrin-node 0.3.110 master deb package

Steps to reproduce:
# Deploy a pool of 4 nodes.
# Start all the nodes.
# Start CLI.
# Connect to {{test}} environment.
# Create a new steward on behalf of {{Trustee1}}.
# Add a new node with the alias {{Node5}} and with {{services}} being an empty array to the pool registry on behalf of the created steward.

Actual results:
* The node with the alias {{Node5}} and with {{services}} being an empty array is added to {{pool_transactions_sandbox}} of the nodes and the client.
* The rest of the nodes try to connect to Node5.

Expected results:
* The node with the alias {{Node5}} and with {{services}} being an empty array is added to {{pool_transactions_sandbox}} of the nodes and the client.
* No nodes try to connect to Node5.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jun/17 1:16 AM;spivachuk;Node1.log;https://jira.hyperledger.org/secure/attachment/11010/Node1.log","10/Jun/17 1:16 AM;spivachuk;Node2.log;https://jira.hyperledger.org/secure/attachment/11009/Node2.log","10/Jun/17 1:16 AM;spivachuk;Node3.log;https://jira.hyperledger.org/secure/attachment/11008/Node3.log","10/Jun/17 1:16 AM;spivachuk;Node4.log;https://jira.hyperledger.org/secure/attachment/11007/Node4.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzx1j3:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/18 10:29 PM;Derashe;Issue does not reproduce anymore in actual version of code.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node does not perform catch up after stop-start sovrin-node.service,INDY-191,17700,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,aleksey-roldugin,aleksey-roldugin,10/Jun/17 2:27 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,1.5,,,0,,,,,,"h6. BUILD

sovrin-node 0.3.19
h6. PRECONDITIONS
 # Make set up with 10 machines (4 nodes for genesis pool, 4 clients, 2 nodes for adding).
 # Add 2 nodes.
 # Check that they successfully performed catch up.
 # Demote 1 node - send transactions - promote node - send transactions.
 # Check that all 6 nodes has similar amount of transactions.

h6. STEPS TO REPRODUCE
 # Stop sovrin-node.service on Node2.
 # Send transactions.
 # Check that all nodes except Node2 has similar amount of transactions.
 # Perform *restart* command for sovrin-node.service on the Node2.

h6. ACTUAL RESULT:

Node2 cannot perform catch up.
h6. ADDITIONAL INFORMATION
 - Steps in this ticket are similar to INDY-159 but in the current situation problem is only on Node2. Other nodes and NYM sending are working.
 - I leaved pool in which that problem was found in current state. Please find the necessary information for connection in [QA pools|https://docs.google.com/document/d/10xHeJPyngFc4WHxA-_OaATdvYCa8DSpv_YnQ7O0KBrU/edit#heading=h.ctvkto8bjdnl] document.",,,,,,,,,,,,,,,,,,,,,,,INDY-159,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1fb:",,,,,,H1,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,krw910,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jun/17 2:29 AM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~jlaw 1], [~ashcherbakov];;;","14/Jun/17 2:01 AM;stevetolman;Please retest.;;;","14/Jun/17 12:28 PM;krw910;Catch up did happen when a node service was off and started again. There are other issues around a node service being shut off, but when it was started it did catch up correctly.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix behavior when ledger is a link to /proc/self/mem,INDY-192,17702,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,alexander.shekhovcov,alexander.shekhovcov,10/Jun/17 2:40 AM,09/Oct/19 6:07 PM,28/Oct/23 2:46 AM,09/Oct/19 6:07 PM,,,,,0,6Months,Could,,,,"This ticket started as an exploratory test to see what would happen if a ledger file is completely invalid. We picked as one example of that invalid input the case where a ledger file was a symlink to /proc/self/mem. See 2.k [https://docs.google.com/document/d/1ae6Ud64gUjl-YC3ADDU5KuW_A-kPS9l9g6FGJCylFCs/edit]

What we learned is that the ledger service cannot start in such cases; it crashes with an unhandled exception.

The desired behavior is that the service starts up and listens for POOL_UPGRADE transactions in such a case. The identity/domain ledger would be stalled, but we want to be able to install new software that might be capable of fixing or ignoring a corruption–instead of having the whole node permanently incapacitated.

An alternative acceptable behavior might be to display a crisp error about an invalid ledger file and suggest to the user that they delete the bad file to start over, then exit cleanly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzy0xr:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jun/17 2:41 AM;alexander.shekhovcov; 

*Steps:*
{code:java}
ln -s /proc/self/mem /home/sovrin/.sovrin/data/nodes/Node1/transactions_sandbox/1
{code}
 

 

*Result:*

The Node raises the exception during start and does not start after a few tries (in case systemd service):

 
{code:java}
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: Traceback (most recent call last):
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/bin/start_sovrin_node"", line 47, in <module>
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: cliha=cliha)
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 81, in __init__
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: config=self.config)
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 149, in __init__
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: self.primaryStorage = storage or self.getPrimaryStorage()
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 123, in getPrimaryStorage
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: defaultFile=defaultTxnFile)
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/plenum/common/ledger.py"", line 26, in __init__
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: super().__init__(*args, **kwargs)
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 61, in __init__
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: self.start()
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 210, in start
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: self.defaultFile)
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/plenum/common/ledger.py"", line 23, in _defaultStore
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: defaultFile=defaultFile)
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/chunked_file_store.py"", line 73, in __init__
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: self._initDB(dbDir, dbName)
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/chunked_file_store.py"", line 95, in _initDB
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: self._useLatestChunk()
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/chunked_file_store.py"", line 101, in _useLatestChunk
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: self._useChunk(self._findLatestChunk())
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/chunked_file_store.py"", line 135, in _useChunk
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: self.currentChunk = self._openChunk(index)
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/chunked_file_store.py"", line 147, in _openChunk
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: return self._chunkCreator(ChunkedFileStore._chunkIndexToFileName(index))
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/chunked_file_store.py"", line 71, in <lambda>
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: ensureDurability)
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/text_file_store.py"", line 22, in __init__
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: self._initDB(dbDir, dbName)
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/text_file_store.py"", line 27, in _initDB
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: self.dbFile = open(self.dbPath, mode=""a+"")
июн 06 14:47:25 sovrin-node1 start_sovrin_node[18542]: OSError: [Errno 22] Invalid argument
{code};;;","09/Oct/19 6:07 PM;esplinr;This still applies to the current code base, but it is rare that the ledger file gets corrupted so we don't see it as a priority to fix.

If someone else wants to fix this, they can raise a PR and reopen this issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node stops to write new transactions to its ledger if it has blacklisted primary of master instance,INDY-193,17712,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,10/Jun/17 5:57 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,shakedown4,,,,"A node detected that the primary of the master protocol instance is malicious and blacklisted it on a catch-up, then succeeded with the catch-up but after this stops to write new transactions to its own ledger.

The bug was faced on the following versions:
 * sovrin-node 0.3.129 master deb package,
 * sovrin-client 0.3.125 master deb package.

Steps to reproduce and results:
 # Install a local pool from Vagrant script with changed APT repositories from {{xenial stable}} to {{xenial master}} in {{sovrin-environments/vagrant/training/vb-multi-vm/scripts/agent.sh}} and {{sovrin-environments/vagrant/training/vb-multi-vm/scripts/validator.sh}}.
 # Connect to any node VM, open the node log and identify which node has been elected as the primary of the master protocol instance (search for the string ""selected primary"" for this). Call this node <NodeX> in what follows.
 # Connect to <NodeX> VM via SSH, open the file {{/usr/local/lib/python3.5/dist-packages/plenum/common/ledger_manager.py}} and after the following line in {{LedgerManager.processCatchupReq}} method
{code:java}
txns = ledger.getAllTxn(start, end)
{code}
insert the following code to simulate a malicious node
{code:java}
        if (txns):
            # Corrupt a signature of some transaction
            some_seq_no = next(iter(txns.keys()))
            txns[some_seq_no]['signature'] = '67rpwLCuS5DGA8KGZXKsVQ7dnPb9goRLoKfgGbLfQg9WoLUgNY77E2jT11fem3coV9nAkguBACzrU1iyZM4B8roQ'
{code}
 # Connect to each node VM via SSH, open the identity ledger file in live mode and leave each session open.
 # Connect to the client VM via SSH and launch {{sovrin}}.
 # Execute: {{connect test}}
 # Execute: {{new key with seed 000000000000000000000000Trustee1}}
 # Execute: {{send NYM dest=1111111111111111}}
 *[ The transaction creating NYM 1111111111111111 is added to the identity ledgers on all the nodes. ]*
 *[ CLI reports: {{Nym 1111111111111111 added}} ]*
 # Stop the node service on some node other than <NodeX>. Call this node <NodeY> in what follows.
 *[ CLI reports that it has been disconnected from <NodeY>. ]*
 # Execute: {{send NYM dest=2222222222222222}}
 *[ The transaction creating NYM 2222222222222222 is added to the identity ledgers of all the nodes except <NodeY>. ]*
 *[ CLI reports: {{Nym 2222222222222222 added}} ]*
 # Execute: {{send NYM dest=3333333333333333}}
 *[ The transaction creating NYM 3333333333333333 is added to the identity ledgers of all the nodes except <NodeY>. ]*
 *[ CLI reports: {{Nym 3333333333333333 added}} ]*
 # Execute: {{send NYM dest=4444444444444444}}
 *[ The transaction creating NYM 4444444444444444 is added to the identity ledgers of all the nodes except <NodeY>. ]*
 *[ CLI reports: {{Nym 4444444444444444 added}} ]*
 # Start the node service on <NodeY>.
 *[ CLI reports that it has been connected to <NodeY>. ]*
 *[ The transactions creating NYMs 2222222222222222, 3333333333333333, 4444444444444444 are added (in 10-20 seconds) to the identity ledger of <NodeY>. ]*
 # Connect to <NodeY> VM via SSH, open the node log and search for the string ""blacklisting node"".
 *[ An occurrence in the following message is found: {{<NodeY> blacklisting node <NodeX> for reason Sent transactions that could not be verified}} ]*
 # Execute: {{send NYM dest=5555555555555555}}
 {color:#ff0000}*[ Actual: The transaction creating NYM 5555555555555555 is added to the identity ledgers of all the nodes except <NodeY>. ]*{color}
 {color:#0000ff}*[ Expected: The transaction creating NYM 5555555555555555 is added to the identity ledgers of all the nodes. ]*{color}
 *[ CLI reports: {{Nym 5555555555555555 added}} ]*",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jun/17 5:38 AM;DouglasWightman;Indy-193 Node4.log;https://jira.hyperledger.org/secure/attachment/11386/Indy-193+Node4.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1rz:",,,,,,H2,H4,H5,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,DouglasWightman,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/17 12:27 AM;DouglasWightman;At what point should the node service be restarted on <NodeX>?;;;","12/Jul/17 10:56 PM;spivachuk;In the case described in the ticket only one node has detected that the master's primary is malicious and so blacklisted it because only that node was one which performed catch-up while the only suspicion on the master's primary was corrupted transactions being sent in CATCHUP_REP message. However, this suspicious behavior itself does not affect the ability of the master's primary to participate in processing and ordering of new transactions. Later when more nodes go through catch-ups and blacklist the master's primary, at some moment the monitoring mechanism will detect degradation of the master instance performance comparing to the backup instances (in the utmost case it will happen when f+1 nodes blacklist the master's primary and thus processing of new transactions halts).

To trigger view change at the moment when the master's primary is blacklisted the first time we need to introduce notifying other nodes about some node is blacklisted and a mechanism of requesting known transactions from other node for verification only. Such the fix seems to be rather time-consuming while the issue seems not to be critical because blacklisting of some node by other nodes one by one during their catch-ups will eventually cause a view change. So I propose to schedule this work for the time after Minimal Go-Live.;;;","14/Jul/17 5:18 AM;danielhardman;I don't understand why this is in Customer Validation. [~spivachuk] answered [~DouglasWightman]'s question, but I don't see any comments about the issue being resolved. No tester has looked at it...;;;","14/Jul/17 8:09 PM;ashcherbakov;[~danielhardman] As follows from Nikita's comment, the situation described in the ticket is not an issue, but rather expected behaviour as of now. So, no changes/tests were implemented.
There is a way how we can improve this behaviour (the second paragraph of Nikita's comment), but it looks quite minor.;;;","14/Jul/17 11:30 PM;spivachuk;[~danielhardman], modification of the current behavior that would take place in scope of this ticket seems to be rather time-consuming while the issue seems not to be critical. Please see my comment above for the details.
So must we schedule this work for the time after Minimal Go-Live?;;;","18/Jul/17 1:22 AM;danielhardman;I'm marking this work done for now. I've created INDY-433 to track the follow-up work.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Define the requirements (or document it) of the reqId field,INDY-194,17717,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,devin-fisher,devin-fisher,10/Jun/17 6:35 AM,09/Oct/19 5:44 PM,28/Oct/23 2:46 AM,09/Oct/19 5:44 PM,,,,,0,6Months,should,,,,"The reqId is part of all transactions to the ledger and is created by the client of the network.

We should define what are the requirements of this field.  And consider what properties it needs.

 

If this has already been done, let's document it in a place developer can find and use.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-792,,,,,,,,,,"1|hzx1pb:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,devin-fisher,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 5:44 PM;ashcherbakov;We have this documented in https://github.com/hyperledger/indy-node/blob/master/docs/source/requests.md#common-request-structure;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Service crashed after running under various bad network conditions.,INDY-195,17738,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,krw910,krw910,11/Jun/17 8:49 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"This one will be difficult to reproduce. I am including some of the logs to point in the right direction.

*Attachment is shows the service crash on Node 3*

*--Further testing shows this seems to only happen if you are shutting down the sovrin-node service and starting it up again after a few minutes. This does not happen with loss of connection like the ports are shut off. This was done to simulate brown outs or temporary loss of connection.*

I was doing various bad network condition testing.
 I had been running using traffic_shaper.sh to simulate 20% dropped packets.
 All 7 nodes were running with 20% dropped packets. 
 I used load_test.py to simulated 2 clients sending 200 NYM transactions each one at a time.
 # While that script was running I launched the CLI and added one NYM manually.
 # The nodes all disconnected in the CLI and reconnected and then the NYM was added.
 # 
 # I then stopped the sovrin-node service just on Node 6 while the script to add NYMs was still running.
 # One minute later I started the sovrin-node service on Node 6.
 # About 10 minutes later I stopped running the traffic_shaper.sh on all the nodes while still running the load script.
 # Two nodes were out of sync at this time Nodes 3 and 5.
 # I stopped running the load script and checked the services on Nodes 3 and 5 to find they had crashed.

*Fix*
 {color:#14892c}I restarted the sovrin-node service on Nodes 3 and 5 and they got in sync with the pool. {color}
 {color:#d04437}I was not able to add any new transactions at this point.{color}
 {color:#14892c}I restarted all the nodes in the pool and the pool was functional again.{color}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jun/17 8:46 AM;krw910;journalctl.log;https://jira.hyperledger.org/secure/attachment/11018/journalctl.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1f3:",,,,,,H1,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jun/17 3:05 AM;krw910;From Lovesh:

fixed the consequence (state being same across consecutive unordered batches) of the root cause (setting same verkey twice very quickly so that both txns end up in consecutive batch and second is pre-prepared before first is ordered).

 

Fixed in Master 0.3.134;;;","14/Jun/17 12:34 PM;krw910;We still have an issue around stopping a service in INDY-159. Having said that I have not been able to reproduce this specific failure where the sovrin-node service crashed on start up with the error shown in the attached log.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
set version to 1.0 just prior to go-live,INDY-196,17773,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,13/Jun/17 12:23 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"James, Jason, and Drummond agree that when the software goes live, its version should be 1.0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8b3:",,,,,,H5,M1 Prelude,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jul/17 11:12 PM;alexander.shekhovcov;[~danielhardman] should I set version 1.0 just prior to go-live for indy-anoncreds, indy-plenum, indy-node?;;;","19/Jul/17 5:22 AM;danielhardman;Yes. Also for the sovrin package that Andrey G just created.;;;","19/Jul/17 9:17 PM;alexander.shekhovcov;I have done some preparation:

https://github.com/sovrin-foundation/sovrin/pull/4
https://github.com/hyperledger/indy-node/pull/243
https://github.com/hyperledger/indy-plenum/pull/290
https://github.com/hyperledger/indy-anoncreds/pull/78

When the time comes we should go through the following steps:

# merge https://github.com/hyperledger/indy-anoncreds/pull/78
# wait indy-anoncreds build is done
# merge https://github.com/hyperledger/indy-plenum/pull/290
# wait indy-plenum build is done
# update dependencies in the setup.py of the indy-node with new build versions of indy-anoncreds and indy-plenum
# merge https://github.com/hyperledger/indy-node/pull/243
# wait indy-node build is done
# merge https://github.com/sovrin-foundation/sovrin/pull/4
;;;","26/Jul/17 4:49 PM;ashcherbakov;[~danielhardman] [~alexander.shekhovcov] [~stevetolman] [~krw910]
The ticket is closed, while steps mentioned above are not complete (indy-node doesn't point to plenum 1.0 and anoncreds 1.0)
;;;","26/Jul/17 5:48 PM;ashcherbakov;* Merged PR for anoncreds (now anoncreds has 1.0 version)
* Changed dependencies in node to point to plenum and anoncreds 1.0;;;","26/Jul/17 11:16 PM;krw910;Build versions are: 
indy-plenum=1.0.21
indy-anoncreds=1.0.8
indy-node=1.0.28
sovrin=1.0.3
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
set default logging level to INFO,INDY-197,17788,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,13/Jun/17 4:56 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Current default log level is TRACE. Too verbose. By default, should be INFO. (But install should not override a log level in the config file that's not the default.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1b3:",,,,,,H1,,,,,,,,,,,,,,,,,,,,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 11:43 AM;krw910;This is not in build 0.3.138 wait and retest in the next build.;;;","16/Jun/17 12:22 AM;krw910;Default log level is back to INFO;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"during alpha, allow capture of sovrin logs for troubleshooting",INDY-198,17790,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,13/Jun/17 4:58 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"We want validator nodes to publish their sovrin logs so we can troubleshoot faster. This need not be a feature of the software–indeed, perhaps it should not be–but we at least need a quick and dirty script to publish the logs to some shared location.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 3:33 AM;dfarns;sovrin-log-xfer.sh;https://jira.hyperledger.org/secure/attachment/11049/sovrin-log-xfer.sh","13/Jun/17 5:55 AM;dfarns;sovrin-logger.pem;https://jira.hyperledger.org/secure/attachment/11021/sovrin-logger.pem","14/Jun/17 2:56 AM;dfarns;sovrin_logger;https://jira.hyperledger.org/secure/attachment/11047/sovrin_logger",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1ev:",,,,,,Indy-1,H1,,,,,,,,,,,,,,,,,,,danielhardman,dfarns,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jun/17 5:55 AM;dfarns;I've done some initial testing and it appears to work just fine... it will upload the log files to /home/ubuntu/logs on 34.225.141.74.
  
 The script has some variables at the top to easily edit and change things like the location of the public ssh key (*rpkey*), the username to log in with (*ruser*), the ip of the host (*rhost*) the destination for the logs (*rdir*), the username whose home directory contains the log files. 
  
 The script as well as a file that can be dropped into */etc/cron.d* are attached.
  
 [NOTE] the cron file assumes that the location of the script is */home/sovrin/sovrin-log-xfer.sh*
  
 Set up should be a simple as:
 # Place *sovrin-logger.pem* and *sovrin-log-xfer.sh* into */home/sovrin*
 # Ensure that that *sovrin-logger.pem* and *sovrin-log-xfer.sh* are owned by the sovrin user: *chown sovrin /home/sovrin/sovrin-**
 # Place *sovrin-logger* into */etc/cron.d* as root, and owned by root with *chown root.root /etc/cron.d/sovrin_logger*.
 # Change the permissions on the *.pem* file with *chmod 600 sovrin-logger.pem*.
 # Make sure that *sovrin-log-xfer.sh* is executable with *chmod a+rx* *sovrin-log-xfer.sh.*;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need reachability service to test firewall/NAT settings and sovrin ping,INDY-199,17791,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,danielhardman,danielhardman,13/Jun/17 5:03 AM,11/Oct/19 7:00 PM,28/Oct/23 2:46 AM,11/Oct/19 7:00 PM,,,,,0,6Months,should,,,,"This is somewhat like the test that's used during node setup, as documented in the Steward Preparation doc. However, the request here is for a feature that's baked into the software itself, that periodically checks to see that all nodes can reach each other, and that complains when it finds an anomaly. The complaining could be logged, but it would be even better if it used the alerting mechanism that sends email, as with health monitoring.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx147:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 7:00 PM;ashcherbakov;We have this information in the logs. Also we have this info in Validator Info. This looks sufficient for now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
upgrade the upgrader,INDY-200,17792,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,13/Jun/17 5:12 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"The upgrader doesn't handle errors robustly enough.

If it fails to run the migration script, it should restore the old software.

If it fails to start the new software, it should restore the old software.

It would be nice if it had a timeout, so the migration script can't time out.",,,32400,32400,,0%,32400,32400,,,INDY-408,,,,,,,,,,,,,,,,INDY-132,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1s7:",,,,,,H1,H2,H3,H4,H5,,,,,,,,,,,,,,,,aleksey-roldugin,andrey.goncharov,danielhardman,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jun/17 3:22 AM;andrey.goncharov;Merged in [https://github.com/sovrin-foundation/sovrin-node/commit/dc807597c8075624809ae24b888334c16f14586b]

Implemented:
 * Creating a ZIP archive with .sovrin before applying a migration
 * Removing the archive after the migration
 * Restoring from the archive if the migration fails
 * Rolling back to an old version of software if an upgrade fails
 * Recursive installation of downstream dependencies (it allows us to install older versions of sovrin-node and dependencies even if newer ones are available)

Covered with 5 tests:

[https://github.com/sovrin-foundation/sovrin-node/blob/master/sovrin_node/test/upgrade/test_node_control_tool.py];;;","21/Jun/17 3:38 AM;krw910;[~VladimirWork] please work with [~andrey.goncharov] to test all the scenarios mentioned in the fix. It will be easier to work with him in the same time zone to get through any issues.;;;","22/Jun/17 10:20 PM;andrey.goncharov;Created migrations-test repo for testing the ticket.

Created a doc with several test scenarios: https://docs.google.com/spreadsheets/d/19Nc2LoZsFYApFM3S6eOxy4UT9a5Be8p-4HKsTOpyXJc;;;","28/Jun/17 1:46 AM;VladimirWork;Testing is in progress due to faults finding and hotfixing by Andrey G. More info in a doc:
https://docs.google.com/spreadsheets/d/19Nc2LoZsFYApFM3S6eOxy4UT9a5Be8p-4HKsTOpyXJc/edit#gid=0;;;","12/Jul/17 7:12 PM;aleksey-roldugin;All cases are tested. Please find results in document:
 [https://docs.google.com/spreadsheets/d/19Nc2LoZsFYApFM3S6eOxy4UT9a5Be8p-4HKsTOpyXJc/edit#gid=0]

https://jira.hyperledger.org/browse/INDY-408 was found. Migrations to versions _1.8.6_  and _1.8.7_ should be retested after bug fix.;;;","20/Jul/17 11:51 PM;VladimirWork;The last case to test is checked in INDY-408, so according to comment above, the feature is done.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need to be able to upgrade (and other system trans) while ledger is stalled,INDY-201,17793,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,13/Jun/17 5:13 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"If the ledger is unable to process ordinary identity transactions, it should still be possible to process a POOL_UPGRADE transaction, and possibly other system transactions as well.",,,540,0,,0%,540,0,,,,,,,,,,,,,,,,,,,INDY-259,INDY-251,INDY-250,INDY-258,INDY-256,INDY-257,INDY-311,INDY-415,"04/Jul/17 10:43 PM;ozheregelya;jout.txt;https://jira.hyperledger.org/secure/attachment/11554/jout.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy21b:",,,,,,H1,H2,H3,H4,,,,,,,,,,,,,,,,,danielhardman,dsurnin,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 9:40 PM;dsurnin;Initial discussion from slack

 

dsurnin [5:48 PM] 
Jason, could you please review?
we would like to hear what you think about it

[5:48] 
dsurnin [5:23 PM] 
so, about 201

[5:23] 
descriptions says
""If the ledger is unable to process ordinary identity transactions""

[5:24] 
if we still need some nodes then we probably needs to identify the reasons why we cannot process transactions

[5:25] 
what do you think?

alexander.shcherbakov [5:31 PM] 
Also the question what do we mean by *stalled* pool. POOL_UPGRADE is a txn (in config ledger), so currently common rules are applied to it. Should we make an exception, and process it differently?

daniel.hardman [5:32 PM] 
Here is the reality that we are wrestling: if the pool is broken in some way (for example, the domain/identity ledger has been corrupted), we need to be able to upgrade the ledger as a way to possibly get it working again.

lovesh [5:32 PM] 
If we want system transactions to be processed any different than other transactions then we can do that since the ledger and state are different but then you put an exception in the protocol

[5:33] 
Also pool stalled is not same as nodes crashed, so need to address that too

daniel.hardman [5:34 PM] 
We don't want a malicious actor to be able to force a pool upgrade, so that's a reason not to accept a pool upgrade without traditional consensus. But if an upgrade would fix consensus, that's a reason to allow it... Jason is the one who asked for this--not me.

lovesh [5:38 PM] 
Well if we have transactions for each ledger going through a separate instance of consensus protocol so if we had 3 ledgers, we have 3 RBFT running, one for each ledger then this brings a clean separation and can help in stalls but this takes away the ability to have a total order among transactions (we are not using that total order today), so is this total order really important

daniel.hardman [5:42 PM] 
I think one of us needs to discuss this with Jason and understand his vision better. I think the way Dmitry originally framed the question (""If I have 4 nodes and 3 are down, should I upgrade just the 1 node""), the answer has to be ""No."" But if there are 26 nodes and 7 are down, it might make sense to say, ""Well, down nodes are not the same as malicious nodes for the purpose of upgrade. With 19 nodes up, we have a 3f+1 scenario where f = 8, and we so no evidence of any malicious nodes--only of down nodes. So we have perfect consensus on upgrade."" Something like that.

lovesh [5:43 PM] 
""we have a 3f+1 scenario where f = 6"", so you are saying if we have a high enough f then its ok

daniel.hardman [5:44 PM] 
Yes, that's the theory I'm playing with.

lovesh [5:44 PM] 
where f=6 is high enough but f=2 is not

[5:44] 
Ok

daniel.hardman [5:44 PM] 
Maybe as long as the new f is at least a majority of the old f

[5:44] 
Again, that's just a theory. I want to hear what Jason thinks.

lovesh [5:44 PM] 
By i think practically if we have a bug like dead pool it will affect majority of nodes

[5:45] 
Ok

dsurnin [5:45 PM] 
I will add Jason to the thread now

alexander.shcherbakov [5:45 PM] 
@daniel.hardman
1) what if we have 2f+1 nodes up, but their domain ledger is out of sync while config ledger is sync? -> looks like we should be able to upgrade (taken into account Lovesh's comment about possibility for separate consensus for each ledger)
2) What if we have 2f+1 nodes up, but theire config ledger is out of sync? -> No upgrade?????
3) What if we have less than 2f+1 nodes up (>f down) -> No upgrade? (edited)

daniel.hardman [5:46 PM] 
All of my thinking is predicated on the notion that having a node that's not responding at all is different from having a node that *is* responding.

dsurnin [5:46 PM] 
lets move the discussion to the new thread

new messages
lovesh [5:47 PM] 
Yes, my assumptions are same as your, if a node is down, there is nothing we can do unless the agent is capable enough

dsurnin [5:59 PM] 
and about blacklisted nodes
what if all nodes blacklisted one node

[5:59] 
should we updated blacklisted one?

lovesh [6:11 PM] 
for the correct solution we need to have a very comprehensive strategy where the consequences depend on type of blacklisting, but a naive that works is that you send messages to blacklisted nodes but not rely on received messages from blacklisted nodes, that way the blacklisted node will have consensus on upgrade and get upgraded. I am assuming the node is not really malicious and maybe some bug or a temporary compromise that like changing the ledger is causing it to be this way, if its really controlled by an ill-intentioned guy, why bother? (edited)

daniel.hardman [6:14 PM] 
It's also important to consider that if a node is malicious, upgrading it would be likely (though not guaranteed) to disrupt the maliciousness (since the upgrade may clean out data or do other housekeeping, in addition to just laying down bits). I'm not sure what the implications of this are, but I wanted to point out that the operation we're talking about approving by consensus will have already been approved by a consensus of human beings, and may be a way to fix maliciousness...


----- Today June 16th, 2017 -----
jlaw [7:53 AM] 
OK, sorry I'm just now responding. I'm going to give my take. If you disagree strongly with anything I've written, please speak up. :slightly_smiling_face:

*Nodes upgrade eagerly.* When a node is getting caught up, and it processes an upgrade txn, it should schedule it just like it normally would. If the date/time is in the past, then it upgrades immediately. Possibly a new story.

*An upgrade is idempotent.* A txn to upgrade to version 5 should be allowed even if an earlier upgrade to v.5 has gone through. Given four nodes, if three are at v.5 and one is at v.4, then the one at v.4 will be upgraded. When it comes time for a particular node to upgrade, and it's already at v.5, it doesn't do anything.

*Support ""reupgrade"".* That said, perhaps we should add 'reupgrade' field that defaults to False. When it is True, it will upgrade to v.5 even if it is already v.5. This allows for a case where a node thinks it upgraded properly, but it really didn't.

*Consensus may not be required.* Because all upgrades are backward compatible, it is OK if one node is upgraded to v.5 when all the other nodes are on v.4. A node can make a decision as to the validity of an upgrade txn independent of consensus. After validation of the upgrade txn, Perhaps if force=True, then a node should not wait for consensus on a POOL UPGRADE txn, and it should schedule the upgrade anyway. Of course if consensus can be reached, then txn still gets written.

This breaks the rule that there needs to be a POOL UPGRADE txn written before a NODE UPGRADE. In this case, a POOL UPGRADE txn won't be recorded. And because there is no consensus, the NODE UPGRADE won't be recorded. When the network comes back online and consensus can happen, the Node should submit it's NODE UPGRADE for historical purposes.

Very soon in the future, a single TRUSTEE will not be able to initiate an upgrade. It will need to be proposed first, and then voted on by TRUSTEEs and/or STEWARDS with some minimum threshold before it's considered approved. We need a story for this.

*Ledgers ""stall"" gracefully.* When a node is applying ledger txns to state, and runs into a ledger txn that causes an exception during deserialization or validation or processing, then the failure will be handled gracefully. A nice error message outlining the specific issue will be put to the log. That ledger will be set to a ""STALLED"" state. On startup, or on upgrade, or maybe even periodically, the node will reattempt to restart a stalled ledger, that is, process the ledger entry that failed. It will not proceed past the current state, and it will not participate in 3pc on any txns for that ledger. With this stalled concept, we don't need a separate consensus protocol for each ledger.

The combination of *Ledgers ""stall"" gracefully* and *Consensus may not be required* means we can recover from some nasty bugs.

Daniel's point about the consensus of humans already having happened is an important one. The ledger should allow an upgrade txn that 'doesn't make sense'. For example, we should not have some arbitrary 5 minute minimum space between node upgrades. Trust the upgrade txn if approved is sound.

Finally, I'm a little concerned that we're talking about upgrades in the enterprise computing frame of reference. We're not upgrading nodes. We don't upgrade nodes. Rather, Sovrin supports txns that each node independently verifies and validates and if everything looks good to the node, it upgrades itself. It's a subtle distinction, but an important one that will help us make smart choices as we work on improving the upgrade feature.

lovesh [9:27 AM] 
We have what's needed for ""Nodes upgrade eagerly"". 
We partially have ""An upgrade is idempotent"", i say partially since node on upgrade can run an additional script, we need to ensure changes done as part of the script are idempotent, we need a test which before any pool upgrade is sent applies the upgrade twice on each node and verifies the update to be idempotent.
We need to build ""Support ""reupgrade"", but should we have downgrade too? I understand that for now we can assume a Trustee is not malicious thus make consensus optional on POOL_UPGRADE, but when we have voting by Trustees for POOL_UPGRADE and the ledger is stalled, how would the voting happen since voting is done through a transaction. Or do we make an exception for voting txns? Regarding ""talking about upgrades in the enterprise computing frame of reference"", doesn't this contradict the above point ""Trust the upgrade txn if approved is sound."", because trusting the upgrade txn is similar to trusting the group of network admins/owners of the enterprise. Or do we say we have diffused trust not just between Sovrin validators but between Trustees too? (edited)

jlaw [9:52 AM] 
Just like we decreed that *all upgrades must be backward compatible*, we need to decree that *all upgrades are idempotent*.

We need to support downgrades. Til now, I've been assuming a downgrade is just another upgrade, but that's probably not good enough. Open to your thoughts.

Good catch on the voting. Option is to have each voter sign an approval out of band and the submitter bundles the votes with the upgrade txn. Imagine something like a CSR where the serialized upgrade proposal is emailed to Trustees or Stewards who load it in the CLI, review it, and then approve it, which spits out an approval .sovrin document that they email back to the submitter. Certainly adds complexity (human and machine), but it's a workable solution. Let's bat this one around and see if we can get something a bit more tight.

Yes, we have diffuse trust with trustees as well.

lovesh [10:04 AM] 
Ok, since the submitted upgrade txn is bundled with signed votes, nodes do not try to achieve consensus but just apply the txn to ledger, do the upgrade and get ""un-stalled""

alexander.shcherbakov [11:48 AM] 
@lovesh @jlaw and everyone.
Thank you for your thoughts.
I think all *bold* items need to be represented as separate stories.
I think the only item that should be done right now in the scope of INDY-201 is *Consensus may not be required*.

But my understanding of this item is that we should just make *scheduling of Update* and *processing POOL_UPGRADE txn* separate. That is we schedule Upgrade immediately regardless of consensus (probably only if force=True), and then we continue processing POOL_UPGRADE txn as usual (that is propagate, wait for consensus, and write into Config Ledger, etc.). 
Dmitry is going to write a PoA for this item with some details.;;;","16/Jun/17 9:42 PM;dsurnin;Document for the further discussion here

https://docs.google.com/document/d/1h2bRdzmoNf-XcUNR-vmDR30Svcin8GAvChrulV-tC54/edit;;;","22/Jun/17 10:01 PM;dsurnin;In scope of this task will be added optional parameter “Force=true|false” (false by default) to the POOL_UPGRADE command. Force=false - no changes needed, works the same way as now. Force=true - basicly all the second level checks are ignored, transaction does not wait for consensus, node schedule upgrade right after receiving and then tries to process it as a normal transactionIgnore 5 min timeout in case of force is true and timestamp is now or in the past

Client will send forced upgrade to the nodes even if the number of nodes is small, for now client does not send anything if the number of available nodes is insufficient;;;","24/Jun/17 12:18 AM;dsurnin;Implemented in

[https://github.com/evernym/plenum/commit/572090e9c4c4fe6671526824591c8d68287bb6fe]

[https://github.com/sovrin-foundation/sovrin-common/commit/7827d886fe3f67263646ff6f7a0a71650e9a67ab]

[https://github.com/sovrin-foundation/sovrin-node/commit/4b46a1e67611dfd26d5545542bd7a9118b83bed9]

[https://github.com/sovrin-foundation/sovrin-client/commit/66575aebbf8d63e336844d0a2c6dcd3c85586842]

 
 * optional parameter force
 * upgrade scheduled before consensus
 * send forced request from client to any number of connected nodes
 * forced upgrade allows to omit some nodes in schedule map
 * forced upgrade allows to send time in schedule map less or equal to current time

 

tests

[https://github.com/evernym/plenum/blob/master/plenum/test/input_validation/fields_validation/test_bool_field.py]

[https://github.com/sovrin-foundation/sovrin-client/blob/master/sovrin_client/test/cli/test_pool_upgrade.py]

[https://github.com/sovrin-foundation/sovrin-node/blob/master/sovrin_node/test/upgrade/test_pool_upgrade.py];;;","04/Jul/17 10:44 PM;ozheregelya;Build Info:
sovrin-client version: 0.4.19
sovrin-node version: 0.4.7

OS/Platform: Ubuntu 16.04.2 LTS

*Reason for Reopen:*
Necessary validation is absent.

*Case 1:*
No validation for role.
*Steps to Reproduce:*
1. Open the CLI.
2. Connect to test environment.
3. Do not use any role, or use Steward role.
4. Send POOL_UPGRADE with force=True parameter.

*Actual Results:*
Upgrade is successfully scheduled, node is broken after upgrade. Services are not able to start. Following errors are in journalctl: [^jout.txt]

*Expected Results:*
Only Trustee should be able to upgrade the node. Node should not be broken.

*Case 2:*
No validation for uniqueness of upgrade name.
*Steps to Reproduce:*
1. Open the CLI.
2. Connect to test environment.
3. Send POOL_UPGRADE with force=True parameter and not unique upgrade name.

*Actual Results:*
Upgrade is successfully scheduled.

*Expected Results:*
Error message should appear.;;;","07/Jul/17 12:50 AM;dsurnin;case 1 is fixed

node 051470bc9444acc058d2726ce166c3cbd94fa0d2

added test for this case

sovrin_node/test/upgrade/test_pool_upgrade_reject.py

 

case 2 were considered as a valid case;;;","14/Jul/17 1:13 AM;VladimirWork;New features of force parameter are checked. Case 1 fix is checked. Case 2 is not reproducing despite of comment about ""case 2 were considered as a valid case"". Single finding is in INDY-415.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
migrate repos from sovrin-foundation and evernym,INDY-202,17794,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,danielhardman,danielhardman,13/Jun/17 5:15 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Code in sovrin-foundation/sovrin-* and in evernym/[plenum|stp|ledger|anoncreds] all need to move into indy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy253:",,,,,,H3,,,,,,,,,,,,,,,,,,,,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
eliminate runtime warnings that show during tests,INDY-203,17795,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dsurnin,danielhardman,danielhardman,13/Jun/17 5:16 AM,11/Oct/19 6:38 PM,28/Oct/23 2:46 AM,11/Oct/19 6:38 PM,,,,,0,6Months,should,,,,"When we are running unit and integration tests, there are a few warnings. We need to either update the code to make the warnings disappear, or else prove to our satisfaction that the warnings are irrelevant, and disable them.",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1hz:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 11:18 PM;alexander.shekhovcov;[~danielhardman] Could you provide more details about the ticket? Maybe you have an example? Which project/projects?;;;","11/Oct/19 6:38 PM;ashcherbakov;This has been already done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin-Client: Ping command does not send a random message for each invocation,INDY-204,17797,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,stevetolman,farooq_m_khan,farooq_m_khan,13/Jun/17 5:46 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"Expected behavior of Ping command in sovrin-cli (as documented in getting started guide)
 # The ping she sends contains a random challenge.

 # The ping also includes Alice’s pairwise identifier and a signature.

 # Faber College verifies Alice’s signature.

 # Faber College digitally signs that challenge and sends it back.

 # Alice verifies that the response contained the same random challenge she sent.

 # Alice uses the verification key in the Faber College Link to verify the Faber College digital signature.

 

Acutal behaviour of Ping Command based on reading the current code:
 # Ping always sends the nounce for the particular agent link
 # Ping includes a time based identifier
 # Rest of behavior is consistent as expected.

 

So this is either a bug in the CLI or in the documentation. 
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1cf:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,farooq_m_khan,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/17 6:25 PM;farooq_m_khan;I had a discussion with Dmitry over Slack and he believes this is a issue, the fix is trivial we have to add real randomness in the data that is being sent in the ping command. As of now this data sent in the ping command is predictable and hence a security issue.;;;","04/Jan/18 4:36 AM;ozheregelya;There is no command `ping` in indy-cli.  [~ashcherbakov], [~gudkov], is it ok?;;;","09/Jan/18 5:42 PM;ashcherbakov;`ping` command is used for Agent-to-Agent communication in old CLI.
We decided that it should not be part of new CLI, so `ping` is not needed there.;;;","09/Jan/18 8:11 PM;ozheregelya;The issue is not actual for indy-cli, so it will be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ensure CLI support for DIDs,INDY-205,17799,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,13/Jun/17 6:13 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"Right now, CLI requires a 32-byte cryptonym for many operations. We need it to prefer the 16-byte DIDs, and to discourage (deprecate?) the 32-byte versions.",,,28800,28800,,0%,28800,28800,,,,,,INDY-210,INDY-166,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1zj:",,,,,,H1,H2,H3,H4,,,,,,,,,,,,,,,,,danielhardman,devin-fisher,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jul/17 3:56 AM;devin-fisher;Work is complete. 
Needs review.

The following must be merged before sovrin-client can by built and tested.
[https://github.com/hyperledger/indy-plenum/pull/239]
https://github.com/hyperledger/indy-common/pull/113;;;","11/Jul/17 9:32 AM;krw910;The work for this is done and I have run through the acceptance tests with a build that has the DID support. Tickets around this change are being logged, but this ticket is complete.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
An ATTRIB transaction with an empty JSON,INDY-206,17815,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,13/Jun/17 7:20 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,should,,,,,"One of the shakedown pools had the following stacktrace
{code:java}
May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1004, in serviceReplicaInBox May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: msgCount += replica.serviceQueues(limit) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 522, in serviceQueues May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self.node.isParticipating) else 0 May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 438, in send3PCBatch May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: ppReq = self.create3PCBatch(lid) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 479, in create3PCBatch May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self.processReqDuringBatch(req, validReqs, inValidReqs, rejects) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/replica.py"", line 456, in processReqDuringBatch May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self.node.applyReq(req) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 393, in applyReq May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: return super().applyReq(request) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1485, in applyReq May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: return self.domainRequestApplication(request) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 1491, in domainRequestApplication May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: return self.reqHandler.apply(request) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/domain_req_handler.py"", line 52, in apply May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self.updateState(txnsWithSeqNo(start, end, [txn])) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/plenum/server/domain_req_handler.py"", line 66, in updateState May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self._updateStateWithSingleTxn(txn, isCommitted=isCommitted) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 56, in _updateStateWithSingleTxn May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: self._addAttr(txn) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 339, in _addAttr May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: attr_key, value = parse(txn) May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 328, in parse May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: key, _ = data.popitem() May 29 14:06:23 singaporeShakeP2.qatest.evernym.com start_sovrin_node[9347]: KeyError: 'popitem(): dictionary is empty'{code}
Lovesh's comment:
{quote}The error appears to be due to passing an ATTRIB transaction with an empty JSON
{quote}
It should be check because if so the an empty JSON in ATTRIB breaks a pool.

 ",,,,,,,,,,,,,,,,,,,,,INDY-97,,,,,,,,,,,,,,"26/Jul/17 6:20 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11773/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8bb:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,spivachuk,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/17 6:17 AM;stevetolman;This is time boxed to 30 minutes. ;;;","14/Jul/17 11:35 PM;spivachuk;This bug must have been fixed in scope of INDY-97 which duplicates this ticket.;;;","26/Jul/17 6:20 PM;VladimirWork;Fixed in INDY-97, retested on 1.0.67. !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shakedown: Significant growth/reduction in pool,INDY-208,17819,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,alexander.shekhovcov,alexander.shekhovcov,13/Jun/17 9:52 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"*Cases:*
 * adding 10+ nodes
 * network issues – connecting/disconnecting 
 * possible crash of significant part of the pool
 * massive node demote / promote

 All test should be performed in the same time with client's load.

The task requires a pool with 40 nodes.

*Steps:*

The Pool contains 15 nodes. 
 # Add 4 nodes (19 pool)
 # Add 6 nodes (25 pool)
 # Add 8 nodes (34 pool)
 # Disconnect 10 nodes
 # Connect 10 nodes after sometime
 # Demote 10 nodes
 # Promote 10 nodes

 

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0mn:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 9:32 PM;alexander.shekhovcov;*Test 1:*
 # Having pool 15 nodes
 # Create and provision 4 nodes in another aws region
 # Add 4 nodes to the pool (do not start them)
 # Start load_test.py -c 5- -r 1000 --timeout 1-
 # start the sovrin-node service on 4 nodes

*Result:*

The 15+4 nodes pool is stable 

*Observations:*
 - Unstable connection 

Nodes logs
{code:java}
2017-06-14 12:28:52,040 | INFO | keep_in_touch.py (92) | _connsChanged | 4FU768D9YfyfvereU6DXiVNZjbqbopN8u6eH6FCGXo3c disconnected from Node18C
2017-06-14 12:28:52,040 | INFO | keep_in_touch.py (92) | _connsChanged | 4FU768D9YfyfvereU6DXiVNZjbqbopN8u6eH6FCGXo3c disconnected from Node19C
...
2017-06-14 12:31:29,662 | DEBUG | zstack.py ( 824) | transmit | Node16 transmitting message b'pi' to Node9
2017-06-14 12:31:29,662 | TRACE | batched.py ( 84) | flushOutBoxes | Node16 sending msg b'pi' to Node9
...{code}
CLI logs
{code:java}
FhGZZTVkq4kKU8qLrkmxgoWrTM3mYDFVHYdVa5vaoWhZ now connected to Node16C
FhGZZTVkq4kKU8qLrkmxgoWrTM3mYDFVHYdVa5vaoWhZ now connected to Node17C
FhGZZTVkq4kKU8qLrkmxgoWrTM3mYDFVHYdVa5vaoWhZ now connected to Node18C
...
FhGZZTVkq4kKU8qLrkmxgoWrTM3mYDFVHYdVa5vaoWhZ disconnected from Node19C
FhGZZTVkq4kKU8qLrkmxgoWrTM3mYDFVHYdVa5vaoWhZ now connected to Node19C
FhGZZTVkq4kKU8qLrkmxgoWrTM3mYDFVHYdVa5vaoWhZ disconnected from Node14C
FhGZZTVkq4kKU8qLrkmxgoWrTM3mYDFVHYdVa5vaoWhZ now connected to Node14C
{code}
 *  the pool became slow

{code:java}
================================
Test time: 1920.7919991016388
Average latency: 18.494004945645386
Throughput: 0.22646908160980003
Error rate: 0.0
Succeeded: 435
Failed: 0
================================
{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make i/o representations of keys consistent,INDY-209,17837,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,zhigunenko.dsr,mgbailey,mgbailey,14/Jun/17 1:52 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,1.6.79,,,0,6Months,Could,,,,"When dealing with keys of various types, which are really just large numbers, There are various ways to represent them to humans.  Sovrin seems to use them all - hexadecimal, base58, x85, etc.

These should be standardized, and a single representation should be used throughout Sovrin.

Example:  recently a note in the Alpha network was not communicating properly with other validators. The log message was this:

2017-06-13 15:00:14,025 | DEBUG | zstack.py ( 683) | handlePingPong | ev1 got ping from b'\{8pT}}%5v=qw0m>HUfdvJG<{/[zLO*P[s:$HKDZv'
 2017-06-13 15:00:14,025 | DEBUG | zstack.py ( 788) | sendPingPong | ev1 will be sending in batch
 2017-06-13 15:00:14,026 | WARNING | batched.py ( 103) | flushOutBoxes | ev1 rid b'\{8pT}}%5v=qw0m>HUfdvJG<{/[zLO*P[s:$HKDZv' has been removed
 2017-06-13 15:00:14,026 | DEBUG | message_processor.py ( 29) | discard | ev1 discarding message deque([b'po']) because rid b'\{8pT}}%5v=qw0m>HUfdvJG<{/[zLO*P[s:$HKDZv' no longer available

This was difficult to debug since ""b'\{8pT}}%5v=qw0m>HUfdvJG<{/[zLO*P[s:$HKDZv' "" does not correspond to any recognizable entry in a transaction file.

 

 *Acceptance criteria:*
 * init_indy_node must output a public key and verification key in base58
 * check that there are not other public places where we output non-base58",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1818,,,,,,,,"12/Nov/18 3:20 PM;Derashe;image-2018-11-12-09-22-22-079.png;https://jira.hyperledger.org/secure/attachment/16253/image-2018-11-12-09-22-22-079.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzwx8f:",,,,,,Ev 18.23,,,,,,,,3.0,,,,,,,,,,,,benjsmi,Derashe,esplinr,mgbailey,ozheregelya,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/18 5:25 AM;esplinr;Mike says that he still sees these inconsistencies in the latest Indy Node.

init_indy_node outputs a public key and verification key in hexadecimal
stewards then have to convert the verkey to base58 so it can be input into the validator credential on the ledger;;;","06/Nov/18 8:43 PM;Derashe;PR: [https://github.com/hyperledger/indy-plenum/pull/966]
 * init_indy_node script fixed
 * example in description was a bug (now it fixed), when we output pubkey instead of alias;;;","10/Nov/18 12:54 AM;benjsmi;Sorry I thought that was a ""view"" button not a ""change status"" button.

So this broader issue 209, I'm not sure... certain encodings are more appropriate for certain uses, obviously. I trust that you guys know what you're doing with it, but I just wanted to say, really INDY-1818 was just about that one step during Validator Setup.

But I could get behind seeing the same encoding in the output in each instance. But I would just be concerned that this might create *another* situation where the user must manually use a tool to recode the number s.t. it works in the new context, if that makes sense?;;;","12/Nov/18 3:20 PM;Derashe;Script tested. Output is in base58 format.

!image-2018-11-12-09-22-22-079.png|thumbnail!;;;","12/Nov/18 10:57 PM;ozheregelya;[~benjsmi], 
If steward will need hex of his key, following command may be used:
python3 -c ""from plenum.common.util import friendlyToHex; print(friendlyToHex('<Base 58 key>').decode())""

Example:
{code:java}
root@03b487911b4f:~# su - indy -c ""init_indy_node Node8 0.0.0.0 9701 0.0.0.0 9702 0000000000000000000000000000seol""Node-stack name is Node8
Client-stack name is Node8C
Generating keys for provided seed 0000000000000000000000000000seol
Init local keys for client-stack
Public key is 3MGSRsodJKAnHJPR5CQxjctnyH3A7NeGZXmDyUqcMRfC
Verification key is 4EG9n9ErTVqcZ7xSnhHH8PQVtYDfugw5SwqcezvYVrGg
Init local keys for node-stack
Public key is 3MGSRsodJKAnHJPR5CQxjctnyH3A7NeGZXmDyUqcMRfC
Verification key is 4EG9n9ErTVqcZ7xSnhHH8PQVtYDfugw5SwqcezvYVrGg
BLS Public key is 145neCsYuzMJvExpsc4kMz1urM5ybopAWFNN4RnJzPy3mY1aYoRZMMyQ4XnXqyuyoZ7nJDvcDMpsqukZzvQSw7H7xCDPZu7kzSmnrGKtcpitMqGKrNfjguzgfVZSrSazRsWw7nMCwZM3SyzW9A36xJtTuKt8b86D7eu13gx8L3hUP2i
Proof of possession for BLS key is RQkkyKYRGdXgAvA3x5kKvXE3zF5rgkEK4QbnE42euoUK955DNNE9gP1m6egDkWGu7zedWCG823MkLDBxNdXJwc1KxwMDR8cyjbPnqtXo4FFcAjsxBqnQJ1jNdsCB2hJMQoiLP4cuiCjXWjnCK8He4AJCctpzfNqNtvcfyWKwaMnTXd

root@03b487911b4f:~# python3 -c ""from plenum.common.util import friendlyToHex; print(friendlyToHex('4EG9n9ErTVqcZ7xSnhHH8PQVtYDfugw5SwqcezvYVrGg').decode())""
2ff8be342784a64965b13f1d4140fe5a812ccbd60bd4d363f429e4ffe0923ea1
{code}
To double check that this is the same value as was generated by previous version of script:
{code:java}
root@5ee184aea4bf:~# su - indy -c ""init_indy_node Node8 0.0.0.0 9701 0.0.0.0 9702 0000000000000000000000000000seol""
Node-stack name is Node8
Client-stack name is Node8C
Generating keys for provided seed 0000000000000000000000000000seol
Init local keys for client-stack
Public key is 22e872422508013037fe5672cb6110eefc583853b20620d632c4d46d458de717
Verification key is 2ff8be342784a64965b13f1d4140fe5a812ccbd60bd4d363f429e4ffe0923ea1
Init local keys for node-stack
Public key is 22e872422508013037fe5672cb6110eefc583853b20620d632c4d46d458de717
Verification key is 2ff8be342784a64965b13f1d4140fe5a812ccbd60bd4d363f429e4ffe0923ea1
BLS Public key is 145neCsYuzMJvExpsc4kMz1urM5ybopAWFNN4RnJzPy3mY1aYoRZMMyQ4XnXqyuyoZ7nJDvcDMpsqukZzvQSw7H7xCDPZu7kzSmnrGKtcpitMqGKrNfjguzgfVZSrSazRsWw7nMCwZM3SyzW9A36xJtTuKt8b86D7eu13gx8L3hUP2i
Proof of possession for BLS key is RQkkyKYRGdXgAvA3x5kKvXE3zF5rgkEK4QbnE42euoUK955DNNE9gP1m6egDkWGu7zedWCG823MkLDBxNdXJwc1KxwMDR8cyjbPnqtXo4FFcAjsxBqnQJ1jNdsCB2hJMQoiLP4cuiCjXWjnCK8He4AJCctpzfNqNtvcfyWKwaMnTXd

root@5ee184aea4bf:~# python3 -c ""from plenum.common.test_network_setup import TestNetworkSetup; print(TestNetworkSetup.getNymFromVerkey(str.encode('2ff8be342784a64965b13f1d4140fe5a812ccbd60bd4d363f429e4ffe0923ea1')))""
4EG9n9ErTVqcZ7xSnhHH8PQVtYDfugw5SwqcezvYVrGg

(or the another way:)
root@03b487911b4f:~# python3 -c ""from plenum.common.util import hexToFriendly; print(hexToFriendly('2ff8be342784a64965b13f1d4140fe5a812ccbd60bd4d363f429e4ffe0923ea1'))""
4EG9n9ErTVqcZ7xSnhHH8PQVtYDfugw5SwqcezvYVrGg{code}
 

 ;;;","13/Nov/18 6:45 PM;ozheregelya;Environment:
indy-node 1.6.674

Reason for Rejection:
Initial problem (encoded keys in logs) still reproduces.

Steps to Validate:
1. Run init_indy_node script.
=> Base58 keys are shown in output.
2. Look at node logs.

Actual Results:
In most part of the cases base58 keys displayed, but messages from description are still shown as is.

Expected Results:
Only ase58 keys should be shown in logs.;;;","13/Nov/18 10:06 PM;Derashe;Additional formatting: https://github.com/hyperledger/indy-plenum/pull/975;;;","15/Nov/18 10:53 PM;Derashe;Fixes for formatting merged. Indy Node version [1.6.681|https://github.com/hyperledger/indy-node/releases/tag/1.6.680-master]

Retest this, please.

 ;;;","19/Nov/18 10:36 PM;ozheregelya;Environment:
indy-node 1.6.684

Reason for Rejection:
Wrong format still appears in logs:
{code:java}
2018-11-19 11:41:02,979|TRACE|zstack.py|Node1 got ping from Fsp2dyt7D2B4GA53hKnEmLym5Y75ExGFz2ZBzcQMNKsB
2018-11-19 11:41:02,980|DEBUG|zstack.py|Node1 ponged b'?3qEFmOgUWAq&v2R#kSX38B=av>B8fg=Q2h{mN(+'{code}
 ;;;","21/Nov/18 4:19 PM;Derashe;Fix: https://github.com/hyperledger/indy-plenum/pull/982;;;","22/Nov/18 6:55 PM;zhigunenko.dsr;*Environment:*
indy-node                  1.6.694 

*Steps to Validate:*
1) Add new node to the pool
2) Check logs from original and new node

*Actual Results:*
- Base58 keys are shown in init_indy_node output
- Base58 keys are shown in ping-pong logs;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support for Cryptonyms being used as NYM identifiers needs to be removed,INDY-210,17839,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,spivachuk,spivachuk,14/Jun/17 2:23 AM,29/Oct/19 11:47 PM,28/Oct/23 2:46 AM,29/Oct/19 11:47 PM,,,,,0,6Months,Must,,,,"Cryptonyms are allowed to be used as NYM identifiers while they must not.

The following tests in {{sovrin_client.test.cli.test_send_nym_validation}} module fail for this reason:
* testSendNymFailsForCryptonymIdentifierAndOmittedVerkey
* testSendNymFailsForCryptonymIdentifierAndFullVerkey",,,,,,,,,,,INDY-205,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx1qn:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/19 11:46 PM;esplinr;Though in general it would be bad practice to use a verkey as the DID because it could not be rotated, it is useful in some scenarios where we want the simplest possible transaction. So we won't be enforcing this restriction.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin-Node: Python interpreter is not executed in Optimise mode,INDY-211,17841,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,farooq_m_khan,farooq_m_khan,14/Jun/17 3:03 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"Sovrin-Node is started via the ubuntu service file
{code:java}
/etc/systemd/system/sovrin-node.service{code}
However the python interpreter is not started in Optimise mode it is running in the default 'DEBUG' mode

The entry point python script should be executed with the '-O' option which will ensure it is running in optimised mode. 

This will have 2 side effects:
 # Strip all assert statements. This trades defense against corrupt program state for speed.
 # Strip all docstrings. So a wee bit of saving on memory requirment

 

So when triaging we need to consider the bullet # 1, do we want to play safe. Asserts are probably going still crash the program.

 
 
 
 
 ",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,INDY-810,,,,,,,,"26/Jul/17 6:55 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11774/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8bj:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,andkononykhin,ashcherbakov,farooq_m_khan,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jul/17 12:29 AM;andkononykhin;*Problem reason:*
 Node services are started in default non-optimized mode and it's non appropriate for production

*Changes:*
 Improved the way services are started.

*Committed into:*
 [https://github.com/evernym/sovrin-packaging/pull/17/files]

*Risk factors:*
 Nothing is expected.

*Risk:*
 Low

*Recommendations for QA (optional):*
 # Install indy-node==4.39
 # start services
 ** systemctl start sovrin-node
 ** systemctl start sovrin-node-control
 # check their statuses:
 ** systemctl status sovrin-node
 ** systemctl status sovrin-node-control
 # should see something like that:

{code:java}
sovrin-node.service - Sovrin Node
 Loaded: loaded (/etc/systemd/system/sovrin-node.service; disabled; vendor preset: enabled)
 Active: active (running) since Mon 2017-07-17 15:07:16 UTC; 1min 26s ago
 Main PID: 427 (python3)
 CGroup: /docker/93d52a6715c48e712b74a9787b0ab7034b1af9e0b5a0542ccf331d888e25e96e/system.slice/sovrin-node.s
 └─427 python3 -OO /usr/local/bin/start_sovrin_node Node2 9703 9704{code}
It means ""python3 -OO"" is used to run our script;;;","26/Jul/17 6:56 PM;VladimirWork;[~andkononykhin] [~ashcherbakov] There is a ""python3 -O"" on 1.0.67, not a ""python3 -OO"". Is it ok? !Screenshot.PNG|thumbnail! ;;;","26/Jul/17 7:02 PM;ashcherbakov;Actually there is a difference between '-O' and '-OO':
-O     : optimize generated bytecode slightly; also PYTHONOPTIMIZE=x
-OO    : remove doc-strings in addition to the -O optimizations
;;;","26/Jul/17 7:34 PM;alexander.shekhovcov;During installation we use a post-install script which calls:
{code}
py3compile -O -p {package_name} /usr/local/lib/python3.5/dist-packages/
{code}

Unfortunately,  py3compile does not support -OO. So for the sovrin-node service we also use -O for consistency.

In additional I'd suggest the following test scenario:

1. measure the time of running the load_test script, 10 clients 1000 requests (10000 total requests)
2. stop all sovrin-node services
3. clean up all compiled files
{code}
find /usr/local/lib/python3.5/dist-packages/ -name ""*.pyc"" -delete
{code}
4. make sure what there are no ""*.pyc"" files in /usr/local/lib/python3.5/dist-packages/
5. start all sovrin-node services and make sure what "".pyc"" are absent in /usr/local/lib/python3.5/dist-packages/
6. measure the time of running the load_test script, 10 clients 1000 requests (10000 total requests)

Compere the measurements #1 and #6. I expect #1 should be less than #6 at least 10%.
;;;","27/Jul/17 1:05 AM;VladimirWork;Step #1

        ================================
        Test time: 3865.5972917079926
        Average latency: 3.5295646245718
        Throughput: 2.58692234223435
        Error rate: 0.0
        Succeeded: 10000
        Failed: 0
        ================================

Step #6

	================================
        Test time: 4377.404090881348
        Average latency: 3.925942998981476
        Throughput: 2.2844589606957206
        Error rate: 0.0
        Succeeded: 10000
        Failed: 0
        ================================

#1 is about 13% less than #6.;;;","27/Jul/17 1:19 AM;VladimirWork;[~alexander.shekhovcov] [~ashcherbakov] Does -O work as well as -OO according to results above?;;;","27/Jul/17 6:42 PM;alexander.shekhovcov;-OO works like -O but in additional it removes doc strings. Removing doc string should affect only on sovrin-node start time. I do not expect significant improvement from -OO comparing -O. Moreover we have to carefully use -O (and -OO) because it removes assert statements from code, it can be dangerous. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace live transaction files in repo,INDY-212,17854,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mgbailey,mgbailey,14/Jun/17 7:01 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,Attached are the genesis transaction files for the Alpha deployment of the network.  Please place them in the proper location in the repo so that they will be distributed with the new release.  Daniel said that you did a recent ticket that is related.  Ask Daniel if you need to know where.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 7:00 AM;mgbailey;pool_transactions_live;https://jira.hyperledger.org/secure/attachment/11051/pool_transactions_live","15/Jun/17 11:25 PM;mgbailey;transactions_live;https://jira.hyperledger.org/secure/attachment/11097/transactions_live",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1an:",,,,,,H1,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,DouglasWightman,krw910,mgbailey,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 7:08 AM;DouglasWightman;I see a corresponding pool_transactions_live but no ""transactions_live"" that exists.  Is this a new file for a total of 4?

see: https://github.com/sovrin-foundation/sovrin-common/tree/stable/data;;;","14/Jun/17 4:24 PM;avkrishnan;[~DouglasWightman], [~mgbailey]

Per analysis by [~lovesh.harchandani], in the genesis transactions file, the user role has been specified as ""TRUSTEE"", it should actually have the numeric value ""0"". Please correct.;;;","15/Jun/17 4:42 PM;ashcherbakov;[~DouglasWightman] There is transaction_live file, but it's in sovrin-node repo:
https://github.com/sovrin-foundation/sovrin-node/blob/master/data/transactions_live;;;","15/Jun/17 11:31 PM;mgbailey;The transactions_live file has been corrected.  Please deploy these into the repo now.  Note: these files should be placed into .sovrin as part of the package deployment of both the sovrin-node and sovrin-client packages

 ;;;","15/Jun/17 11:48 PM;DouglasWightman;[~ashcherbakov] thanks for addressing my first comment, that helped me figure things out.;;;","16/Jun/17 4:13 AM;DouglasWightman;Problem reason: 
- update transactions files

Changes: 
- sovrin-common/pool_transactions_live and sovrin-node/transaction_live

Committed into:
https://github.com/sovrin-foundation/sovrin-common/commit/97e170bdd9eb3893397b54e1d1d21b8b3055b7dd
https://github.com/sovrin-foundation/sovrin-node/commit/b538bdf84df13e8b49fdce4ab1a14344d2ecda08

Risk factors:
 Nothing is expected.

Risk:
 Low

Covered with tests:
NA;;;","17/Jun/17 12:10 AM;krw910;The location the files need to be in is:

https://github.com/sovrin-foundation/sovrin-common/tree/stable/data;;;","17/Jun/17 12:25 AM;krw910;The link I provided points to Stable and the code is in master. I have verified that with a master install I get the live file and can connect to the network. On the next Stable build the files should be copied to the correct location and our acceptance tests will verify that they are in the correct spot.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
client_authn.py will authenticate using a cyrptonym without checking the ledger,INDY-213,17855,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,devin-fisher,devin-fisher,14/Jun/17 7:10 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,Must,,,,,"In client_authn.py the following lines of code do authentication:
{code:java}
verkey = self.getVerkey(identifier)
vr = DidVerifier(verkey, identifier=identifier)
isVerified = vr.verify(sig, ser)
{code}
But in the case where the verkey is not on the ledger and the identifier is a cryptonym, DidVerifier will get the verkey from the cryptonym. In this case it will not check that the cryptonym is on the ledger and will verify with only data sent by the client.

 

I don't have any reason this will effect authorization but it does effect authentication.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,INDY-448,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1sf:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,devin-fisher,lovesh,mark.hadley,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jun/17 5:01 AM;mark.hadley;So to make sure I'm understanding, the current functionality of client_authn.py is catching this, but the question is whether to add this authentication check into the DidVerifier object itself?;;;","28/Jun/17 5:09 AM;lovesh;We are getting of cryptonyms, does it make sense to work on this?;;;","11/Jul/17 6:45 AM;mark.hadley;https://github.com/hyperledger/indy-plenum/pull/267;;;","21/Jul/17 6:53 PM;ozheregelya;*Build Info:*
   indy-anoncreds 0.4.18
   python3-rlp 0.5.1
   python3-sha3 0.2.1
   python3-pyzmq 16.0.2
   indy-plenum 0.4.61
   indy-node 0.4.46
   sovrin 0.2.10
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 4 nodes, 1 client

*Steps to Validate:*
 # Open the CLI.
 # Generate the cryptonym.
 new identifier W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A with seed 000000000TestTrustAnchorTrustee1
 # As trustee send NYM:
 send NYM dest=W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A
 # Try to send transaction as newly created identifier.

*Actual Results:*
       Error: client request invalid: CouldNotAuthenticate();;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create rc build,INDY-214,17856,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,stevetolman,stevetolman,14/Jun/17 7:12 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"Create the first rc build after alpha milestone.

 

Use master versions

**
*Node* 
python3-stp=0.1.57
python3-ledger=0.2.28
python3-rlp=0.5.1
python3-sha3=0.2.1
python3-state-trie=0.1.15
python3-plenum=0.3.142
python3-sovrin-common=0.2.87
sovrin-node=0.3.138
 
*Client* 
python3-stp=0.1.57
python3-ledger=0.2.28
python3-rlp=0.5.1
python3-sha3=0.2.1
python3-state-trie=0.1.15
python3-plenum=0.3.142
python3-sovrin-common=0.2.87
python3-anoncreds=0.3.8
sovrin-client=0.3.136",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1fj:",,,,,,H1,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,krw910,rajesh.kalaria,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/17 5:26 PM;ashcherbakov;[~stevetolman] [~danielhardman] Is Rajesh already working on it?;;;","15/Jun/17 5:47 PM;rajesh.kalaria;[~ashcherbakov], I was working on it, but plenum PR build failed ([https://jenkins.evernym.com/job/Plenum/job/PR-217/1/artifact/test-result.agent-ubuntu-06.txt)|https://jenkins.evernym.com/job/Plenum/job/PR-217/1/artifact/test-result.agent-ubuntu-06.txt).], I discussed with Krishnan that someone will have to take a look. He pinged [~andrey.goncharov] to help there.;;;","15/Jun/17 5:58 PM;rajesh.kalaria;[~andrey.goncharov], FYI, I was following this doc ([https://docs.google.com/document/d/1pFq6rqjUom5CKG_pLTjGLjOlwsm2gQpSbOT-uX_dPDg/edit#)] to create RC build. So far I did this:
 * For state-trie, there wasn't any changes in master vs stable, so didn't do anything.
 * Merged ledger and stp successfully to stable.
 * When I was doing the same for plenum, it's PR build got failed ([https://jenkins.evernym.com/job/Plenum/job/PR-217/1/artifact/test-result.agent-ubuntu-06.txt).]

 ;;;","15/Jun/17 10:20 PM;andrey.goncharov;A new RC is created:

sovrin-client 0.3.21

sovrin-node 0.3.22;;;","16/Jun/17 12:21 AM;krw910;We have a RC build and it is under testing now.;;;","16/Jun/17 3:39 AM;krw910;Done and pushed to Stable. I verified the Stable build and turned it over to Mike for deployment.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
When a transaction is not able to be added to the ledger a blank line is added in its place to the transaction file.,INDY-215,17860,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,14/Jun/17 12:25 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,," In testing INDY-159 I found the following issue.

*Setup*
4 Nodes 1 Client 

*Steps*
# Added a NYM transaction to the pool
# Stopped the sovrin-node service on Node 1
# Sent another add NYM transaction
# When I sent the second transaction it was not processed. The CLI did not show 'Added NYM'
# I restarted the sovrin-node.service on Node 1 and sent a few more transactions which did not go through.
# I had to stop the sovrin-node service on all 4 nodes and bring them up one at a time.

*{color:#d04437}Issue{color}*
When I checked the transactions file they all were in sync, but I had several empty entries and realized that was where I was sending transactions and the pool did not reach consensus. 

Log files are attached from Node 1
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-130,,,,,,,,"14/Jun/17 12:24 PM;krw910;1;https://jira.hyperledger.org/secure/attachment/11056/1","14/Jun/17 12:24 PM;krw910;Node1.log;https://jira.hyperledger.org/secure/attachment/11055/Node1.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy23b:",,,,,,H3,,,,,,,,,,,,,,,,,,,,DouglasWightman,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/17 2:38 AM;DouglasWightman;As far as I can tell by following these steps, this is most likely a duplicate of INDY-130, sending to test.;;;","04/Jul/17 11:58 PM;ozheregelya;*Build Info:*
 sovrin-client version: 0.4.19
 sovrin-node version: 0.4.9
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 4 nodes, 1 client

*Steps to Validate:*
 1. Open the CLI. 
 2. Send several NYMs.
 3. Stop sovrin-node services on any two nodes in the pool.
 4. Send several NYMs.
 5. Restart stopped nodes.
 6. Restart all nodes.
 7. Check transactions files.

*Actual Results:*
 There are no empty lines in transactions files.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Version of Sovrin CLI is incorrect--missing PATCH.,INDY-216,17863,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,jlaw 1,jlaw 1,14/Jun/17 1:33 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Could,,,,,"Sovrin-CLI (c) 2017 Evernym, Inc.
Type 'help' for more information.
Running Sovrin 0.3",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-64,,,,,,,,,,"1|hzy0qv:",,,,,,,,,,,,,,,,,,,,,,,,,,jlaw 1,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Sep/17 6:08 AM;krw910;This only happens in a development environment in the release version it displays correctly. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLI reports wrong message when trying to connect to LIVE,INDY-217,17864,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,dsurnin,jlaw 1,jlaw 1,14/Jun/17 1:43 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,should,,,,"{quote}sovrin> connect live

The information required to connect this client to the nodes cannot be found. 
This is an error. To correct the error, get the file containing genesis transactions 
(the file name is `pool_transactions_sandbox`) from the github repository and place 
it in directory `/home/jlaw/.sovrin`.

The github url is https://github.com/sovrin-foundation/sovrin-client/tree/stable/data.
{quote}
 

It references pool_transactions_sandbox. It should reference pool_transactions_live.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx0sv:",,,,,,14,,,,,,,,,,,,,,,,,,,,jlaw 1,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 1:46 PM;jlaw 1;The URL referenced is also wrong.

Should be sovrin-common I think.;;;","26/Sep/17 6:17 AM;krw910;Retest after file / folder refactoring is complete.;;;","05/Dec/17 7:51 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
update CLI to reflect latest terminology,INDY-218,17865,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,14/Jun/17 2:35 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"The CLI uses some terminology that is now stale. For example, what we used to call a ""link invitation"" is now a ""connection request"". A ""keyring"" is now a wallet. An ""identifier"" is now a ""DID"". A ""link"" is now a ""connection"".

We need to update the terminology to make it consistent with current thinking.

 ",,,32400,32400,,0%,32400,32400,,,,,,INDY-166,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8br:",,,,,,H5,M1 Prelude,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,krw910,mark.hadley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jul/17 4:46 AM;mark.hadley;This ticket is changing the verbiage inside the CLI.
Are we wanting the actual commands to change (i.e. 'list links' command on the CLI becomes 'list connections') or are we just changing the help messages?;;;","15/Jul/17 7:04 AM;krw910;[~mark.hadley] one of the changes I would like to see is around the confirmation of the POOL_UPGRADE command. Right now when the transaction is sent you immediately get a message saying ""Pool Upgrade Successful"". The message is misleading because all that has happened is the transaction was processed. So I would like to see the message changed to something like ""Pool Upgrade Transaction Scheduled""  ;;;","20/Jul/17 5:35 AM;mark.hadley;[https://github.com/hyperledger/indy-node/pull/247]
[https://github.com/hyperledger/indy-plenum/pull/292]

 ;;;","21/Jul/17 5:46 AM;mark.hadley;[https://github.com/hyperledger/indy-plenum/pull/296]

 ;;;","22/Jul/17 11:44 AM;mark.hadley;Pulled this back to in-progress to work on updating the function/variable to also have the terminology.;;;","25/Jul/17 12:05 AM;mark.hadley;[https://github.com/hyperledger/indy-plenum/pull/304];;;","25/Jul/17 7:53 AM;mark.hadley;This is to change the older vocabulary to the newer way of thinking.

'keyring' -> 'wallet'
 'link' -> 'connection'
 'invitation' -> 'request'
 'identifier' -> 'DID'

This change many commands, for example 'new identifier' is now 'new DID'. The help message and the details within the commands reflect these changes.;;;","25/Jul/17 7:57 AM;mark.hadley;[https://github.com/hyperledger/indy-node/pull/260]
[https://github.com/hyperledger/indy-plenum/pull/304]

 ;;;","25/Jul/17 10:52 PM;mark.hadley;the indy-plenum PR has been merged. Waiting on indy-node PR to finish integration checks.;;;","26/Jul/17 12:39 AM;ashcherbakov;Fixed remaining issues and merged the PR.
Node build: 0.4.64;;;","27/Jul/17 1:17 AM;krw910;Latest terminology is working just fine.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin Alpha unstable / unable to add stewards,INDY-219,17867,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,mgbailey,mgbailey,14/Jun/17 2:42 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"Jason, as trustee was trying to add stewards.  The network was unstable, one of the validator processes went down, and disconnect / reconnect messages were being reported b the CLI.  This must be debugged urgently.  The transcript of the chat session with Jason follows:

jlaw [11:02 PM] 
So, it connected OK... but I don't know if it actually added the txn.

[11:02] 
>>>sovrin> connect live
Active keyring ""Default"" saved (/home/jlaw/.sovrin/keyrings/no-env/default.wallet)
Current active keyring got moved to 'live' environment. Here is the detail:
 keyring name: Default
 old location: /home/jlaw/.sovrin/keyrings/no-env/default.wallet
 new location: /home/jlaw/.sovrin/keyrings/live/default.wallet

Saved keyring ""Default"" restored (/home/jlaw/.sovrin/keyrings/live/default.wallet)
Active keyring set to ""Default""
Client sovrinwohTc0 initialized with the following node registry:
 danubeC listens at 128.130.204.35 on port 9722
 BIGAWSUSEAST1-001C listens at 34.224.255.108 on port 9796
 BYUC listens at 54.71.209.105 on port 9722
 ev1C listens at 54.94.255.14 on port 9702
Active client set to sovrinwohTc0
cpRcDUxGvbLGQRvqXTmJozvWXfmfPsPohiEs1D7dh1y listening for other nodes at 0.0.0.0:6101
cpRcDUxGvbLGQRvqXTmJozvWXfmfPsPohiEs1D7dh1y looking for BYUC at 54.71.209.105:9722
cpRcDUxGvbLGQRvqXTmJozvWXfmfPsPohiEs1D7dh1y looking for danubeC at 128.130.204.35:9722
cpRcDUxGvbLGQRvqXTmJozvWXfmfPsPohiEs1D7dh1y looking for ev1C at 54.94.255.14:9702
cpRcDUxGvbLGQRvqXTmJozvWXfmfPsPohiEs1D7dh1y looking for BIGAWSUSEAST1-001C at 34.224.255.108:9796
Connecting to live...
cpRcDUxGvbLGQRvqXTmJozvWXfmfPsPohiEs1D7dh1y now connected to BYUC
cpRcDUxGvbLGQRvqXTmJozvWXfmfPsPohiEs1D7dh1y now connected to BIGAWSUSEAST1-001C
Connected to live.
cpRcDUxGvbLGQRvqXTmJozvWXfmfPsPohiEs1D7dh1y now connected to danubeC
cpRcDUxGvbLGQRvqXTmJozvWXfmfPsPohiEs1D7dh1y now connected to ev1C
sovrin@live> send NYM dest=3RnYQprW2oA7X2Z78CxN53Hj8MAjmhGETTscVgXEbiXd role=STEWARD
Adding nym 3RnYQprW2oA7X2Z78CxN53Hj8MAjmhGETTscVgXEbiXd
sovrin@live>

[11:02] 
Seems I'd see more than the ""Adding nym..."" message

[11:03] 
How can I confirm it was added?

mike.bailey [11:04 PM] 
If it worked, it should look like this:

[11:04] 
sovrin@live> send NYM dest=FrCMTG7Njkfjsu25tVLEnQymMQwN8J6fZZGdSW5ycK7V
Adding nym FrCMTG7Njkfjsu25tVLEnQymMQwN8J6fZZGdSW5ycK7V
Nym FrCMTG7Njkfjsu25tVLEnQymMQwN8J6fZZGdSW5ycK7V added

jlaw [11:05 PM] 
I don't see the last line :confused: no error message

[11:05] 
There should be more info in the log, right?

mike.bailey [11:06 PM] 
there is a cli.log in the directory in your home directory

[11:06] 
sorry, getting tired

jlaw [11:08 PM] 
I see it. It looks like the client is continuing to retry ever 15 seconds.

[11:09] 
It's getting a REQACK back from the nodes, but there is no completed txn comming back it appears. So I think it's retrying.

mike.bailey [11:11 PM] 
I see this in the log in the evernym validator

[11:11] 
Jun 14 05:00:00 ip-172-31-46-122 start_sovrin_node[32680]: self._validateNewNym(req, op, originRole)
Jun 14 05:00:00 ip-172-31-46-122 start_sovrin_node[32680]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/domain_req_handler.py"", line 160, in _validateNewNym
Jun 14 05:00:00 ip-172-31-46-122 start_sovrin_node[32680]: Roles.nameFromValue(originRole),
Jun 14 05:00:00 ip-172-31-46-122 start_sovrin_node[32680]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_common/roles.py"", line 22, in nameFromValue
Jun 14 05:00:00 ip-172-31-46-122 start_sovrin_node[32680]: return Roles(value).name if value else 'None role'
Jun 14 05:00:00 ip-172-31-46-122 start_sovrin_node[32680]: File ""/usr/lib/python3.5/enum.py"", line 241, in __call__
Jun 14 05:00:00 ip-172-31-46-122 start_sovrin_node[32680]: return cls.__new__(cls, value)
Jun 14 05:00:00 ip-172-31-46-122 start_sovrin_node[32680]: File ""/usr/lib/python3.5/enum.py"", line 476, in __new__
Jun 14 05:00:00 ip-172-31-46-122 start_sovrin_node[32680]: raise ValueError(""%r is not a valid %s"" % (value, cls.__name__))
Jun 14 05:00:00 ip-172-31-46-122 start_sovrin_node[32680]: ValueError: 'TRUSTEE' is not a valid Roles

[11:13] 
It is actually in syslog, not in our ev1.log

jlaw [11:15 PM] 
That's odd. Is ev1.log being updated?

[11:15] 
That timestamp is 15 minutes ago.

mike.bailey [11:17 PM] 
It looks like the service is down. It is no longer responding to a connection request. The others do.

[11:17] 
The error message also makes no sense. TRUSTEE is a valid role.

[11:18] 
I will restart the service on the ev1 node. Crossing fingers.

[11:21] 
well, it came back up ok. I can connect to all nodes from a cli

jlaw [11:21 PM] 
Me too

mike.bailey [11:23 PM] 
the cli shows disconnections / reconnections happening. this is unusual

jlaw [11:23 PM] 
This is really strange:
>>>sovrin@live> send NYM dest=3RnYQprW2oA7X2Z78CxN53Hj8MAjmhGETTscVgXEbiXd role=STEWARD
Adding nym 3RnYQprW2oA7X2Z78CxN53Hj8MAjmhGETTscVgXEbiXd
7xZxp3XAFU4bMNSYiDnEohGCuAfeHZVNv6Eym39QWFrp disconnected from BIGAWSUSEAST1-001C
7xZxp3XAFU4bMNSYiDnEohGCuAfeHZVNv6Eym39QWFrp disconnected from BYUC
7xZxp3XAFU4bMNSYiDnEohGCuAfeHZVNv6Eym39QWFrp now connected to BIGAWSUSEAST1-001C
Remote BYUC is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings
7xZxp3XAFU4bMNSYiDnEohGCuAfeHZVNv6Eym39QWFrp now connected to BYUC

[11:23] 
I'm seeing the same.

 

The log for the ev1 validator node is on a log aggregation server.  To get access, copy down the attached pem file, chmod it to 600, then run:

ssh -i alpha-logger.pem ubuntu@34.225.141.74

The file is logs/ev1.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 2:55 PM;mgbailey;alpha-logger.pem;https://jira.hyperledger.org/secure/attachment/11058/alpha-logger.pem",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy19b:",,,,,,H1,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,krw910,mgbailey,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 2:43 PM;mgbailey;Jason was using client version 0.3.19-rc;;;","14/Jun/17 4:20 PM;avkrishnan;Per analysis by [~lovesh.harchandani], in the genesis transactions file, the user role was specified as ""TRUSTEE"", it should have been the numeric value ""0"". Fixing this should fix the issue.;;;","15/Jun/17 4:39 PM;ashcherbakov;[~avkrishnan] [~lovesh] [~danielhardman]
What kind of actions are expected in this ticket? Looks like TRUSTEE is used not in source code, but in some other scripts not maintained by Sovrin developers.;;;","16/Jun/17 11:53 PM;krw910;This was resolved with our last Stable build.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
F + 1 replies requirement for reads should be increased,INDY-220,17872,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,danielhardman,andrey.goncharov,andrey.goncharov,14/Jun/17 6:52 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Currently we require only F + 1 replies from the nodes to assume that our request was processed successfully. Since we require only 2F + 1 nodes to reach consensus to commit a transaction it opens us up for ""dirty reads"".

Example:
 * We have a pool of 5 nodes
 * We send a transaction to the pool
 * 3 nodes reach consensus and commit the transaction (F = 1, 2F +1 = 3)
 * A different client tries to read data updated by this particular transaction
 * It receives old data from 2 nodes which haven't committed the transaction yet (F + 1 = 2)",,,,,,,,,,,,,,,,,,,,,,,INDY-185,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy26v:",,,,,,H3,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 5:17 PM;ashcherbakov;[~danielhardman] [~lovesh] [~andrey.goncharov] [~alexander.shekhovcov]
As we incresed write consensus in the scope of INDY-185 to `n-f`, there is no need to increase read consensus.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The CLI initialization becomes too slow,INDY-221,17873,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,alexander.shekhovcov,alexander.shekhovcov,alexander.shekhovcov,14/Jun/17 8:24 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,should,,,,"The call CLI (cmd: _*sovrin)*_ takes tens seconds after sometime of using.

In the attachment there is a result of:
{code:java}
python3 -m cProfile -o sovrin.prof `which sovrin`
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/17 8:22 PM;alexander.shekhovcov;sovrin.prof;https://jira.hyperledger.org/secure/attachment/11059/sovrin.prof",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzygn3:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Sep/17 6:21 AM;krw910;[~alexander.shekhovcov] Can you provide some more detail on this issue so we know how important it is. What do you mean by ""after sometime of using""?;;;","05/Dec/17 9:27 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Useless error message for POOL_UPGRADE with too small time span between upgrades,INDY-222,17875,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,spivachuk,ozheregelya,ozheregelya,14/Jun/17 9:20 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,Could,should,,,"*Overview:*
 Useless error message when the user tries to send POOL_UPGRADE with too small time span between upgrades.

 *Steps to Reproduce:*
 1. Open the CLI, connect to test.
 2. Send POOL_UPGRADE like this.
{code:java}
sovrin@test> send POOL_UPGRADE name=upgrade-oz version=0.3.138 sha256=aad1242 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-06-25T11:50:00.000000+00:00', '8ECV
Sk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-06-25T11:51:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-06-25T11:52:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543Cfuue
bjFrg36kLAUcskGfaA': '2017-06-25T11:53:00.000000+00:00', '4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe': '2017-06-25T11:54:00.000000+00:00', 'Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8': '
2017-06-25T11:55:00.000000+00:00', 'BM8dTooz5uykCbYSAAFwKNkYfT4koomBHsSWHTDtkjhW': '2017-06-25T11:56:00.000000+00:00'} timeout=5
{code}
 

*Actual Results:*
 Following message
{code:java}
Sending pool upgrade upgrade-oz for version 0.3.138
Pool upgrade failed: client request invalid: InvalidClientRequest(""{'8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-06-25T11:51:00.000000+00:00', 'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-06-25T11:50:00.000000+00:00', 'Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8': '2017-06-25T11:55:00.000000+00:00', '4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe': '2017-06-25T11:54:00.000000+00:00', 'BM8dTooz5uykCbYSAAFwKNkYfT4koomBHsSWHTDtkjhW': '2017-06-25T11:56:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-06-25T11:52:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-06-25T11:53:00.000000+00:00'} not a valid schedule since time span between upgrades is 60 seconds which is less than specified in the config"",)
{code}

*Expected Results:*
 Message should be more useful. Need to show user the value specifier in the config.

*Additional Information:*
 n/a","Build Info:
sovrin-client version: 0.3.130
sovrin-node version: 0.3.135

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx0on:",,,,,,14,INDY 17.21,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 7:16 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node memory leak,INDY-223,17900,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,dsurnin,dsurnin,14/Jun/17 11:52 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"master repo were used;

run load_test.py on local pool with 4 nodes for 90000 transactions;

output of ps command shows continues growth of memory used by the node;",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,INDY-469,INDY-1493,,,,,,,"20/Jul/17 6:21 PM;alexander.shekhovcov;all-mem.png;https://jira.hyperledger.org/secure/attachment/11729/all-mem.png","20/Jul/17 6:20 PM;alexander.shekhovcov;mem-commited.png;https://jira.hyperledger.org/secure/attachment/11728/mem-commited.png","01/Aug/17 9:13 PM;mzk-vct;muppy-10users-10000requests.7z;https://jira.hyperledger.org/secure/attachment/11807/muppy-10users-10000requests.7z","27/Jul/17 9:56 PM;mzk-vct;summary.csv;https://jira.hyperledger.org/secure/attachment/11779/summary.csv","27/Jul/17 8:34 PM;mzk-vct;summary.csv;https://jira.hyperledger.org/secure/attachment/11778/summary.csv","01/Aug/17 9:18 PM;mzk-vct;sysstat.7z;https://jira.hyperledger.org/secure/attachment/11808/sysstat.7z","06/Jul/17 10:26 PM;lovesh;test_node_load_consistent_time.prof;https://jira.hyperledger.org/secure/attachment/11599/test_node_load_consistent_time.prof",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8bz:",,,,,,H3,M1 Prelude,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,danielhardman,dsurnin,lovesh,mzk-vct,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/17 6:00 AM;stevetolman;Assign this appropriately.;;;","28/Jun/17 11:19 PM;ashcherbakov;There is at least one queue which is not cleared:
`replica.py: ordered`;;;","06/Jul/17 10:26 PM;lovesh; [^test_node_load_consistent_time.prof] ;;;","06/Jul/17 11:22 PM;lovesh;Some memory measurement utilities were added, a perf test utility was updated. Here is the merged PR. https://github.com/hyperledger/indy-plenum/pull/254. More changes are in https://github.com/hyperledger/indy-plenum/tree/perf-tracking;;;","20/Jul/17 6:22 PM;alexander.shekhovcov;I've got some numbers:

+Shakedown pool #3, Node1, indy-node 0.4.48+

h3. Test #1
10 clients send 10000 requests

*Before:*
         PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
03:24:47 PM   2275632   1769372     43.74    227032   1217748    418176     10.34    813452    739092        44

*Command:*
python load_test.py -c 10 -r 1000

*After:*
         PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
03:45:17 PM   2104388   1940616     47.98    227036   1357352    464640     11.49    976404    745548       144

*Result:*
requests: 10000
kbmemused +171M (171244)
kbcached  +139M (139604)
kbcommit   +46M (46464)


h3. *Test #2*
10 clients send 100000 requests

*Before:*
         PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
03:49:37 PM   2104080   1940924     47.98    227036   1357936    464640     11.49    977024    745520        92

*Command:*
python load_test.py -c 10 -r 10000

*After:*
         AM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
02:20:18 AM    491300   3553704     87.85    227456   2826240    557512     13.78   2505724    785108        92

*Result:*
requests: 100000
kbmemused +1612M
kbcached  +1468M
kbcommit  +92M

h3. *Test #3*
Restart the node

*Before:*

                     total        used        free      shared  buff/cache   available
Mem:           3.9G        264M        427M         40M        3.2G        3.5G

*After:*

                    total        used        free          shared  buff/cache   available
Mem:           3.9G        141M        555M         40M        3.2G        3.6G

*Result:*
Restating the node frees only ~120M


*Conclusion:*

We still have a memory leak but for me it looks acceptable (for now at least). The memory leak is ~100M per 100000 requests.

*The data:*
 !all-mem.png|thumbnail! 
 !mem-commited.png|thumbnail! 

[sysstat|https://drive.google.com/open?id=0BwH79BR-U6L4bzdRQjdFdlNWbVE]
;;;","20/Jul/17 6:32 PM;lovesh;[~alexander.shekhovcov] Thanks a lot for doing this. We use pympler for benchmarking performance tests, what tool were you using?.
I am not completely sure if its acceptable but it's not too scary either;;;","20/Jul/17 6:41 PM;alexander.shekhovcov;I used `sysstat`. It must be fixed but I am not sure that it is a couple-hour task. I think in current state pool is able to process at least 1M requests without swapping or OOM. So we can reopen this ticket later or create another one.;;;","21/Jul/17 5:47 PM;alexander.shekhovcov;`sysstat` command *sar -ur 10 -o sysstat*;;;","22/Jul/17 1:23 AM;danielhardman;I think we have proved that this issue is not likely to cause disasters in the early days of the live network–but we haven't fixed the issue. Therefore, I vote that we move the ticket into the backlog and keep it open.;;;","27/Jul/17 10:00 PM;mzk-vct;I conducted an experiment - wrote [a script|https://github.com/mzk-vct/plenum/blob/memtrack/plenum/common/tools/memtrack.py] that takes all objects in memory whose size is *over* *50.000 bytes*, integrated it in one node and run load test: *python load_test.py -c 10 -r 10000* (as [~alexander.shekhovcov] did). It was printing results every five minutes.
 Here is a summary: [^summary.csv]

*In short:*
 1. On the start and before approximately first two thousands of requests there were no objects of size higher than 50.000 bytes.
 2. During whole runtime only 6-7 object had size over 50.000 bytes
 3. Max total size of these objects was 7269904 (~7 megabytes), it was ~23.86% of all memory consumed by objects.
 4. Some time after load test completed all large objects disappeared (their size decreased or they were deleted).

So, we can calculate that max total memory consumed by all objects was ~29 megabytes. 
 Of course there are some hidden things in internals of python that also consume memory.

This results differ from results of research of [~alexander.shekhovcov] that shows memory leak ~100M per 100.000 requests.
 I think that the reason is that sysstat shows not real, but virtual memory consumption, which is usually greater.

I propose closing this ticket and opening a new one when we face significant memory leak.;;;","27/Jul/17 10:39 PM;mzk-vct;After discussion with [~alexander.shekhovcov] we decided that since python memory management can have some tricky logic results of the experiment above are not precise enough.

We decided to make test for exhaustion - run load test for very huge amount of requests and see whether node will fall into swap.
I'll run it today and check results on the morning.

 ;;;","28/Jul/17 8:16 PM;mzk-vct;I run load test with *-c 20 -r 50000* parameters, 1.000.000 requests total. My script checks largest objects every 5 minutes, sysstat checks memory every 10 seconds.

I checked it after ~18 hours - only ~220.000 transactions were processed, whereas first 10.000 were processed in a first 10 minutes.

This means that throughput degrades over time. 
 Same thing I saw when run *test_node_load* test from *plenum/test/test_performance.py*.

So we definitely have an issue, I'm creating a ticket.

 

*About memory:*

Max number of objects > 50.000 bytes was 10, their totals size was ~16mb what was 37.5% of all memory consumed by all objects.
 But some minutes after this number dropped to ~12mb.

Sysstat records: first record, record when there were these 10 objects, and the last records (at the time I checked it) respectively:
{code:java}
 ========= kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty
 16:09:19 2991212 1053792 26.05 208704 564860 396148 9.79 533368 358260 64
 10:26:19 209780 3835224 94.81 202952 3068116 636356 15.73 2857908 770056 1168
 10:54:39 154440 3890564 96.18 203468 3126296 638652 15.79 2973924 708744 724
{code}
Load test still running, I'm going to wait more to see what happen then.;;;","28/Jul/17 8:21 PM;mzk-vct;Data file sizes:

{code}
11M    .sovrin/data/nodes/Node3/_merkleNodes
24K    .sovrin/data/nodes/Node3/config_state
10M    .sovrin/data/nodes/Node3/seq_no_db
24K    .sovrin/data/nodes/Node3/pool_state
14M    .sovrin/data/nodes/Node3/idr_cache_db
4.0K    .sovrin/data/nodes/Node3/config_transactions
20K    .sovrin/data/nodes/Node3/attr_db
11M    .sovrin/data/nodes/Node3/_merkleLeaves
472M    .sovrin/data/nodes/Node3/domain_state
8.0K    .sovrin/data/nodes/Node3/pool_transactions_sandbox
44M    .sovrin/data/nodes/Node3/transactions_sandbox
559M    .sovrin/data/nodes/Node3/
{code};;;","01/Aug/17 9:14 PM;mzk-vct;Made a test using [muppy|https://pythonhosted.org/Pympler/muppy.html]. 
*python load_test.py -c 10 -r 10000*

How memory consumption changed from the test start: 

{noformat}
                                           types |   # objects |   total size
================================================ | =========== | ============
                                    <class 'list |        8341 |      2.67 MB
                                     <class 'str |       15251 |      1.52 MB
                                    <class 'dict |        2333 |    732.38 KB
                                   <class 'float |       20990 |    491.95 KB
            <class 'orderedset._orderedset.entry |        3812 |    238.25 KB
                 <class 'collections.OrderedDict |         111 |    140.34 KB
                                     <class 'int |        3553 |    102.21 KB
                                     <class 'set |         320 |     87.50 KB
       <class 'plenum.server.propagator.Requests |           0 |     73.12 KB
         <class 'sovrin_common.types.SafeRequest |        1187 |     64.91 KB
  <class 'sortedcontainers.sorteddict.SortedDict |           1 |     47.92 KB
                                 <class 'weakref |         426 |     33.28 KB
           <class 'plenum.server.models.Prepares |           0 |     23.62 KB
            <class 'plenum.server.models.Commits |           0 |     23.62 KB
       <class 'plenum.server.propagator.ReqState |         300 |     16.41 KB
{noformat}


Results for all measurements with 5 minutes step:  [^muppy-10users-10000requests.7z] ;;;","01/Aug/17 9:19 PM;mzk-vct;Attaching sysstat file for [1.000.000 requests|https://jira.hyperledger.org/browse/INDY-223?focusedCommentId=29135&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-29135]  

[^sysstat.7z] ;;;","01/Aug/17 9:36 PM;mzk-vct;*Investigation summary:*
 # As tests show there is no significant objects growth
 # Most of the memory consumed then freed
 # However sysstat shows that file system cache contains a lot of data and it frees only when process stopped. Possible explanation of this is that leveldb maintains LSM of stored data. Also some of this memory may be consumed by zmq internals.
 # During this investigation significant throughput degradation was found - time required to handle one request growth, ticket created

*Recommendations:*
 # Investigate and fix throughput degradation because these two problems can be interrelated.
 # Since leak (if it really is) is not big do nothing with it until its influence become significant

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node crashes if out of disk space,INDY-224,17903,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,,dsurnin,dsurnin,14/Jun/17 11:59 PM,29/Oct/19 11:49 PM,28/Oct/23 2:46 AM,29/Oct/19 11:49 PM,,,,,0,6Months,should,,,,"During the test node crashed with leveldb exception ""no space left on device"".

Probably we should process such a case more gracefully",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzx1jb:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,esplinr,krw910,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 8:05 AM;stevetolman;We ought to refuse to start if there is less than a certain amount or percentage of available disk space (1GB?)

We should exit gracefully if we hit this condition and we should check for it on an ongoing basis and not crash unpredictably. ;;;","01/Sep/17 6:18 AM;krw910;We expect the out of disk space condition is handled by the system administrators using other means.

We need to enhance this with a way to gracefully fail and the appropriate message.;;;","29/Oct/19 11:49 PM;esplinr;Disk space is reported by validator-info, so system administrators can monitor the growth of disk space usage. If an individual machine runs out of space, a crash is appropriate. Network access will not be interrupted.

We don't object to someone making it fail more gracefully, but we will prioritize other tasks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Performance degrade on big ledger ,INDY-225,17906,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,dsurnin,dsurnin,15/Jun/17 12:04 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,should,,,,,"master repo were used;

run load_test.py on local pool with 4 nodes;

the first 1000 transactions were processed with average response latency of 0.7 sec;

after 30000 transactions the average response latency were increased to 2 sec;

after 50000 transactions the average response latency were increased to 3.5 sec;

60000 transactions  - 4 sec and keep growing;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1sn:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,dsurnin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/17 5:25 AM;krw910;Blocked by INDY-406;;;","18/Jul/17 12:51 PM;krw910;Blocked by INDY-246. I need to be able to get up to 60,000 plus transactions in order to test this.;;;","24/Jul/17 4:21 AM;krw910;With a constant stream will will start to see a little slow down. I tested this with 200,000 transactions and ran a benchmark of sending 1,000 transactions at a time. It was slightly slower than the initial 1,000 transactions, but not significant enough to be an issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[load_test.py] Unclear errors appear after running the script with 100 clients,INDY-226,17917,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,dsurnin,ozheregelya,ozheregelya,15/Jun/17 1:40 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,Could,,,,"*Overview:*
 Unclear errors appear after running the script with 100 clients.

*Steps to Reproduce:*
 1. Connect the client machine.
 2. Run the script with following parameters:
{code:java}
python3 load_test.py --clients-list load_test_clients.list --timeout 15 -t NYM -c 100 -r 10{code}
*Actual Results:*
 Lots of error messages appear. Full output is in file: [^err100.out]

*Expected Results:*
 Errors should not appear.

*Additional Information:*
 n/a","Build Info:
sovrin-client version: 0.3.130
sovrin-node version: 0.3.135

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,INDY-144,,,,,,,,,,,,,"15/Jun/17 1:40 AM;ozheregelya;err100.out;https://jira.hyperledger.org/secure/attachment/11069/err100.out",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzy0xz:",,,,,,Indy-1,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 9:02 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI and changing load tests.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade schedule for a huge pool,INDY-227,17920,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,alexander.shekhovcov,alexander.shekhovcov,15/Jun/17 2:18 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,Enhancement,should,,,,"If a pool contains a lot of nodes (20+) Trustee has to input a schedule for the POOL_UPGRADE txn. 

А schedule for 4 nodes looks like:
{code:java}
{'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-06-07T21:00:00.258870+03:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-06-07T21:05:00.258870+03:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-07T21:10:00.258870+03:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-07T21:15:00.258870+03:00'}
{code}
A schedule for 40 nodes will be huge.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzy0r3:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Sep/17 6:27 AM;krw910;We are investigating different options to improve the upgrade process. For this ticket we will not be changing how the transaction is sent. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
After adding node with empty services it's appeared as connected in CLI ,INDY-228,17922,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,Derashe,aleksey-roldugin,aleksey-roldugin,15/Jun/17 2:36 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,6Months,Could,,,,"h6. BUILD

sovrin-node 0.3.138
 sovrin-client 0.3.136
h6. PRECONDITIONS
 # Working pool (I used [Shakedown Pool 4|https://docs.google.com/spreadsheets/d/1dQs2101Xcb9HMJQufLgtmiHxA-apbjnbXn8CGiCDHp0/edit#gid=0])
 # Another validator node prepared for for adding (IP: 52.65.105.174; user/pass: ubuntu/no passwod; user/pass: sovrin/1)

h6. STEPS TO REPRODUCE

Send from CLI:
{code:java}
sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'
client_port': 9710, 'client_ip': '52.65.105.174', 'alias': 'Node5', 'node_ip': '
52.65.105.174', 'node_port': 9709, 'services': []}
Sending node request for node identifier 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1497456523692470)
3JmHZk3qC2mjCH7im2PWYfBWBb98AYccYBrBPMMfueeT looking for Node5C at 52.65.105.174:9710
Node request completed 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc
3JmHZk3qC2mjCH7im2PWYfBWBb98AYccYBrBPMMfueeT now connected to Node5C
sovrin@test> disconnect
Disconnecting from test ...
Active keyring ""userb"" saved (/home/sovrin/.sovrin/keyrings/test/userb.wallet)
Disconnected from test
sovrin> connect test

Saved keyring ""userb"" restored (/home/sovrin/.sovrin/keyrings/test/userb.wallet)
Active keyring set to ""userb""
Client sovrina1bcbe initialized with the following node registry:
    Node1C   listens at 52.62.180.225           on port 9702
    Node2C   listens at 13.58.134.249           on port 9704
    Node3C   listens at 52.9.79.203             on port 9706
    Node4C   listens at 34.209.130.170          on port 9708
    NodeNATC listens at nat2.dsr-company.com.ru on port 9702
Active client set to sovrina1bcbe
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm listening for other nodes at 0.0.0.0:6007
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm looking for Node4C at 34.209.130.170:9708
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm looking for Node1C at 52.62.180.225:9702
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm looking for Node2C at 13.58.134.249:9704
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm looking for NodeNATC at nat2.dsr-company.com.ru:9702
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm looking for Node3C at 52.9.79.203:9706
Connecting to test...
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm now connected to NodeNATC
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm now connected to Node2C
Connected to test.
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm now connected to Node3C
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm now connected to Node4C
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm looking for Node5C at 52.65.105.174:9710
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm now connected to Node1C
36qHbo3X8z3iAR8GtLzCeb2QqeqfxoZ8hwyVt1BvAqhm now connected to Node5C
{code}
h6. ACTUAL RESULT:
{code:java}
3JmHZk3qC2mjCH7im2PWYfBWBb98AYccYBrBPMMfueeT now connected to Node5C
{code}
h6. EXPECTED RESULT:

Client should not connect to node added with empty services.
h6. ADDITIONAL INFORMATION
 - Sending NYM from CLI will appear in logs on node added with empty services
 - Node added with empty services do not perform catch up (it's mentioned in INDY-88)",,,,,,,,,,,,,,,,,,,,,,,INDY-88,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1s7:",,,,,,,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,Derashe,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/17 2:39 AM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","04/Jan/18 4:32 AM;ozheregelya;Impossible to retest with indy-cli because of IS-502.;;;","09/Oct/18 8:36 PM;Derashe;For actual moment of time, sdk won't connect to node added with empty service field.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testShowJobCertClaim is failing on jenkins,INDY-229,18022,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,devin-fisher,devin-fisher,15/Jun/17 8:24 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Not sure why. The output from Jenkins is not helpful.
{code:java}
[ubuntuTest] In sovrin_client/test/cli/test_tutorial.py, 50 passed, 0 failed, 1 errors, 2 skipped, 98.7s time (35/38 progress)
[ubuntuTest] [0;30;41mFailed tests: testShowJobCertClaim[0m
{code}
Does not fail on my box.

I'm skipping it so we can get a stable build.

Both Daniel and I think this is low risk but we need to fix soon.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1af:",,,,,,H1,,,,,,,,,,,,,,,,,,,,devin-fisher,krw910,rajesh.kalaria,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/17 5:55 PM;rajesh.kalaria;[~krw910], [on behalf of Lovesh],  it has PR: [https://github.com/sovrin-foundation/sovrin-client/pull/222,] also, it consistently passes as can be see here [https://jenkins.evernym.com/job/Sovrin%20Client/view/change-requests/job/PR-222/]

 ;;;","17/Jun/17 1:47 AM;krw910;I verified on jenkins that test_tutorial was run and then checked the code to verify it was not skipped or commented out.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Submit Sovrin service fingerprints information to Nmap.,INDY-230,18026,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,andkononykhin,jkumar,jkumar,15/Jun/17 2:20 PM,29/Oct/19 11:54 PM,28/Oct/23 2:46 AM,29/Oct/19 11:54 PM,,,,,0,6Months,Could,Security,,,"Nmap scan outcome for sovrin-node service:

PORT     STATE SERVICE VERSION
9701/tcp open  unknown
9702/tcp open  unknown

2 services unrecognized despite returning data. If you know the service/version, please submit the following fingerprints at https://nmap.org/cgi-bin/submit.cgi?new-service :

==============NEXT SERVICE FINGERPRINT (SUBMIT INDIVIDUALLY)==============

SF-Port9701-TCP:V=7.40%I=7%D=6/14%Time=59412663%P=i686-pc-windows-windows%
SF:r(NULL,A,""\xff\0\0\0\0\0\0\0\)\x7f"")%r(GenericLines,A,""\xff\0\0\0\0\0\0
SF:\0\)\x7f"")%r(Help,A,""\xff\0\0\0\0\0\0\0\)\x7f"")%r(X11Probe,A,""\xff\0\0\
SF:0\0\0\0\0\)\x7f"")%r(TerminalServer,A,""\xff\0\0\0\0\0\0\0\)\x7f"");

==============NEXT SERVICE FINGERPRINT (SUBMIT INDIVIDUALLY)==============

SF-Port9702-TCP:V=7.40%I=7%D=6/14%Time=59412663%P=i686-pc-windows-windows%
SF:r(NULL,A,""\xff\0\0\0\0\0\0\0\)\x7f"")%r(GenericLines,A,""\xff\0\0\0\0\0\0
SF:\0\)\x7f"")%r(X11Probe,A,""\xff\0\0\0\0\0\0\0\)\x7f"")%r(LPDString,A,""\xff
SF:\0\0\0\0\0\0\0\)\x7f"")%r(TerminalServer,A,""\xff\0\0\0\0\0\0\0\)\x7f"");",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx1rj:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,jkumar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/19 11:54 PM;esplinr;We would be happy for someone to submit our fingerprint to Nmap, but we will be focused on other priorities.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Upgrade scheduled to future date happened in current date on part of nodes,INDY-231,18030,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,,ozheregelya,ozheregelya,15/Jun/17 6:14 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,should,,,,,"*Overview:*
There were several not successful attempts of POOL_UPGRADE (with invalid intervals between upgrades, without timeout, send transaction without connection to test environment, send transaction not as trustee) on following pool: https://docs.google.com/spreadsheets/d/1fkFQlkGFIs6b_tyiL-Wwu-E81SSJLanfdgYzJEhzmNM/edit#gid=359577200 
In each POOL_UPGRADE command date of upgrade was not today. After that valid transaction was send and part of nodes were upgraded.

*Steps to Reproduce:*
1. Open CLI in the client.
2. send POOL_UPGRADE transaction (full history of commands is in [^cli.log]).
{code:java}
send POOL_UPGRADE name=upgrade-oz version=0.3.138 sha256=aad1242 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-06-25T12:30:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-06-25T12:35:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-06-25T12:40:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-06-25T12:45:00.000000+00:00', '4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe': '2017-06-25T12:50:00.000000+00:00', 'Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8': '2017-06-25T12:55:00.000000+00:00', 'BM8dTooz5uykCbYSAAFwKNkYfT4koomBHsSWHTDtkjhW': '2017-06-25T13:00:00.000000+00:00'} timeout=5{code}
3. Look at nodes.

*Actual Results:*
Nodes 1, 2, 3, 4, and 7 were upgraded at specified time but the date was 2017-06-14, nodes 5 and 6 were not upgraded.

*Expected Results:*
Upgrade should be scheduled to 2017-06-25, nodes should not be upgraded.

*Additional Information:*
Logs of not upgraded node: [^Node5logs1.tar.gz] [^Node5logs.tar.gz]

Logs of upgraded node: [^Node7logs.tar.gz]

upgrade_log of not upgraded node:
{code:java}
2017-06-14 13:00:29.988500 scheduled 2017-06-25 12:50:00+00:00 0.3.138{code}
upgrade_log of upgraded node:
{code:java}
2017-06-14 12:26:17.608040 scheduled 2017-06-25 13:00:00+00:00 0.3.138
2017-06-14 12:59:59.612719 scheduled 2017-06-25 13:00:00+00:00 0.3.138
2017-06-14 13:00:17.123279 succeeded 2017-06-25 13:00:00+00:00 0.3.138{code}","Build Info:
 sovrin-client version: 0.3.130
 sovrin-node version: 0.3.132

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,INDY-382,,,,,,,,"15/Jun/17 5:59 PM;ozheregelya;Node5logs.tar.gz;https://jira.hyperledger.org/secure/attachment/11087/Node5logs.tar.gz","15/Jun/17 5:59 PM;ozheregelya;Node5logs1.tar.gz;https://jira.hyperledger.org/secure/attachment/11088/Node5logs1.tar.gz","15/Jun/17 5:40 PM;ozheregelya;Node7logs.tar.gz;https://jira.hyperledger.org/secure/attachment/11089/Node7logs.tar.gz","15/Jun/17 5:35 PM;ozheregelya;cli.log;https://jira.hyperledger.org/secure/attachment/11090/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyk4n:",,,,,,Indy-1,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,andkononykhin,krw910,mgbailey,ozheregelya,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jul/17 1:19 AM;ozheregelya;After exploration of INDY-280 I can see following cases in this ticket:

Case 1:
Scheduling upgrade to future date does not work at all. Upgrade is happened in specified time, but date is today or tomorrow. This problem is described in INDY-382.

Case 2:
Some nodes of pool were not upgraded by some reason. This problem is described in description of this ticket.;;;","05/Sep/17 5:31 PM;andkononykhin;Seems I found possible reason of the issue: incorrect usage of timedelta object API usage
 [https://github.com/hyperledger/indy-node/blob/1.1.131-master/sovrin_node/server/upgrader.py#L373]

timedelta.seconds not declared in [docs|https://docs.python.org/3.5/library/datetime.html#timedelta-objects] and it actually returns only seconds part of time diff.

As a fix [total_seconds()|https://docs.python.org/3.5/library/datetime.html#datetime.timedelta.total_seconds] should be used.;;;","05/Sep/17 5:51 PM;andkononykhin;Also I think it's better to switch to use absolute timestamp *when* instead of relative *delay* in Upgrader.scheduledUpgrade attribute:
https://github.com/hyperledger/indy-node/blob/1.1.131-master/sovrin_node/server/upgrader.py#L374

It will be helpful if we need to get scheduled timestamp later without parsing ledger.
Also current semantic of that part (delay/when) of the attribute varies in different methods of Upgrader class and it seems buggy.;;;","10/Oct/17 6:04 PM;spivachuk;Problem reason: 
- {{seconds}} property of {{timedelta}} class was previously used instead of its method {{total_seconds}} for converting node upgrade delay from {{timedelta}} to seconds in {{Upgrader}} class. So only seconds part of days-seconds-microseconds representation was used to schedule node upgrade (and due to that the node upgrade delay did not exceed one day).

Changes: 
- Fixed the bug in conversion of node upgrade delay from {{timedelta}} to seconds in {{Upgrader}} class.
- Added a test for the fix.

Committed into:
- https://github.com/hyperledger/indy-node/pull/390

Risk factors:
- Nothing is expected.

Risk:
- Low

Covered with tests:
- {{indy_client.test.cli.test_pool_upgrade_schedule.testPoolUpgradeScheduledOnProperDate}}
;;;","27/Oct/17 12:08 AM;mgbailey;[~krw910], will this be included in the next indy release?;;;","30/Oct/17 1:42 PM;krw910;[~mgbailey] Yes it should be in the next release.;;;","08/Nov/17 10:51 PM;ozheregelya;Build Info:
sovrin 1.1.31
indy-node 1.1.165
indy-anoncreds 1.0.32
indy-plenum 1.1.145

Steps to Validate:
1. Schedule upgrade for future (more than 24h since current moment).
2. Check that upgrade was happened in specified date.

Actual Results:
Upgrade happened in accordance with the schedule.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: DOS possibility in catchup process,INDY-232,18031,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,,farooq_m_khan,farooq_m_khan,15/Jun/17 7:07 PM,29/Oct/19 11:58 PM,28/Oct/23 2:46 AM,29/Oct/19 11:58 PM,,,,,0,6Months,Security,should,,,"This is a issue analyzed as part of INDY-27, copied the following comment from that ticket

 
{code:java}
My understanding is a new Validator cannot just be added to the system. Only a Steward can approve addition of a new Validator to the system. Without which a new node will not have the keys to establisy a ED25519 encrypted session with the pool
This defect is still a definite possiblility but to be able to do that a already trusted Validator needs to be compromized first and then the python code on the Validator needs to be patched so that it can carry out a DOS attack on other NODES
It is also possibel that the process of vetting the Steward is compromised in either case we need to find a solution to this problem
{code}
 

Possible solution to the problem suggested by Lovesh in the original ticket is to implement some kind of thresold based throttling.

But this issue needs deeper analysis, If we at all go to implement throttling we need to do this based on a adaptive threshold

Also we might want to consider developing a Anomaly detect system that feeds into a adaptive threshold maybe

 

 ",,,,,,,,,,,,,,,,,,,,INDY-27,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-996,,,,,,,,,,"1|hzx1h3:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,farooq_m_khan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 6:25 PM;farooq_m_khan;I had created a proposal on how to fix this and discussed with Jason yesterday night. [Proposal Google Doc|https://docs.google.com/document/d/1IXnCiaB7j4bDdIeaKQ0HZroc5TOWEC0IJoAxBCIp8YI/edit]

We have initial approval from Jason to try this out.
 ;;;","29/Oct/19 11:58 PM;esplinr;Our current threat model assumes that validator nodes are not abusing the pool consensus network (which is on its own NICs). There are a number of ways that a poorly behaved validator node can cause trouble, but the remediation is always to exclude the improper validator from the pool. This can be done with minimal downtime.

We will focus on other priorities.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PublicKeyNotFoundOnDisk after enabling an inactive node,INDY-233,18032,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,VladimirWork,alexander.shekhovcov,alexander.shekhovcov,15/Jun/17 7:43 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"*Steps:*
 # add a node with *SERVICES: []*
 # enable the node – send the NODE txn with  *SERVICES: ['VALIDATOR']*

*Result:*

Each of the node gets:

 
{code:java}
stp_core.network.exceptions.PublicKeyNotFoundOnDisk: Node1 could not get Node5's public key from disk. Make sure the keys are initialize
{code}
 

So enabling an inactive node causes pool restart (because systemd) or may cause a crash.

 

The problem can be here:
{code:java}
if VALIDATOR in txn[DATA].get(SERVICES, []):
    self.addNewNodeAndConnect(txn)
{code}
because `initRemoteKeys` has not been called as a part `self.addNewNodeAndConnect` in case SERVICES=[]

[https://github.com/evernym/plenum/blob/master/plenum/server/pool_manager.py#L185]

 

 

 ",,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,INDY-326,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzygqv:",,,,,,H4,13,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,danielhardman,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/17 9:08 AM;danielhardman;We think this can be timeboxed to 1 hour. If you agree, please keep the ticket and get it done quickly. If not, let's discuss.;;;","08/Jul/17 12:13 AM;alexander.shekhovcov;Already fixed here https://github.com/hyperledger/indy-plenum/commit/a7704683171d0ee3dab70e4983fc1362fc0a1258.

 

There is a test _testAddInactiveNodeThenActivate_ which should catch such a case.

*How to test:*
 # add a node with *SERVICES: []*
 # enable the node – send the NODE txn with  *SERVICES: ['VALIDATOR']*

The node become connected and the pool can handle requests.

 

 ;;;","25/Jul/17 11:03 PM;krw910;Moving out based off [~VladimirWork] comment below.

 I've just checked it - workaround with Trustee described in INDY-326 works, so INDY-233 can be pushed out of the release;;;","26/Aug/17 5:49 AM;krw910;Retest;;;","08/Sep/17 8:29 PM;VladimirWork;Exact steps from this ticket are not reproducible due to CLI validation: we can't send empty 'services' attribute, but we can send request *without* this attribute at all and this issue is reproducing on current master (1.1.132), INDY-326 with steps and logs is sent back to development.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactoring: Decouple node components,INDY-234,18046,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,mzk-vct,mzk-vct,15/Jun/17 11:02 PM,11/Oct/19 12:01 AM,28/Oct/23 2:46 AM,11/Oct/19 12:01 AM,,,,,0,6Months,Could,,,,"Make components more independent to let them be easily updated or replaced.
For example election logic is coupled with view change logic. 
Although there are inbox and outbox queues some communication is done by methods",,,1620,1620,,0%,2160,2160,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzx1p3:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Sep/17 6:11 AM;krw910;[~mzk-vct] Can you be more specific about what this ticket will change and its benefits?;;;","11/Oct/19 12:01 AM;ashcherbakov;We've done a lot of refactorings and improvements in the scope of PBFT View Change protocol.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Exclude primary election from view change,INDY-235,18053,18046,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,mzk-vct,mzk-vct,15/Jun/17 11:10 PM,13/Nov/19 12:21 AM,28/Oct/23 2:46 AM,13/Nov/19 12:21 AM,,,,,0,,,,,,"Primary election should be the next step after view change, but not a part of it",,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy30f:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Nov/19 12:21 AM;esplinr;Now that we have completed PBFT view change, this issue is no longer valid.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[RC acceptance testing] Node crashed after promotion,INDY-236,18069,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,aleksey-roldugin,aleksey-roldugin,16/Jun/17 1:03 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,Must,,,,,"h6. BUILD

sovrin-node 0.3.22
sovrin-client 0.3.21

h6. PRECONDITIONS
 # Pool from 10 machines: 6 nodes and 4 clients
 # 4 nodes appear as original pool, 2 other were successfully added

h6. STEPS TO REPRODUCE

# Demote Node1:
{code:java}
sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services': []}
Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL (request id: 1497537593487900)
G5ZfRFgnnpA4RP7E8gPusd3UEpKpavS1q6PjeWk561Us disconnected from Node1C
Fq5bVpEJAg56A4rnhGaCtiunHjZxYfY1Jt4p2dNRuG57 disconnected from Node1C
1thRpQudNCc9MMyGbdpEPzEPmXRWynMXr9MVz1aMkwD disconnected from Node1C
Node request completed Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv
{code}
# Demote Node6:
{code:java}
sovrin@test> send NODE dest=6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G data={'alias': 'Node6', 'services': []}
Sending node request for node identifier 6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G by GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL (request id: 1497538086040430)
G5ZfRFgnnpA4RP7E8gPusd3UEpKpavS1q6PjeWk561Us disconnected from Node6C
Fq5bVpEJAg56A4rnhGaCtiunHjZxYfY1Jt4p2dNRuG57 disconnected from Node6C
1thRpQudNCc9MMyGbdpEPzEPmXRWynMXr9MVz1aMkwD disconnected from Node6C
Node request completed 6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G
{code}
# Update Node5 (it wasn't demoted so this should not make any effectcs):
{code:java}
sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'alias': 'Node5', 'services': ['VALIDATOR']}
Sending node request for node identifier 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1497538210863065)
Node request completed 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc
{code}
# Promote Node6 (successful):
{code:java}
sovrin@test> send NODE dest=6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G data={'alias': 'Node6', 'services': ['VALIDATOR']}
Sending node request for node identifier 6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G by GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL (request id: 1497538289548552)
G5ZfRFgnnpA4RP7E8gPusd3UEpKpavS1q6PjeWk561Us looking for Node6C at 10.0.0.106:9712
Fq5bVpEJAg56A4rnhGaCtiunHjZxYfY1Jt4p2dNRuG57 looking for Node6C at 10.0.0.106:9712
1thRpQudNCc9MMyGbdpEPzEPmXRWynMXr9MVz1aMkwD looking for Node6C at 10.0.0.106:9712
Node request completed 6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G
G5ZfRFgnnpA4RP7E8gPusd3UEpKpavS1q6PjeWk561Us now connected to Node6C
Fq5bVpEJAg56A4rnhGaCtiunHjZxYfY1Jt4p2dNRuG57 now connected to Node6C
1thRpQudNCc9MMyGbdpEPzEPmXRWynMXr9MVz1aMkwD now connected to Node6C
{code}
# Promote Node1 (unsuccessful):
{code:java}
sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services': ['VALIDATOR']}
Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL (request id: 1497538346027633)
G5ZfRFgnnpA4RP7E8gPusd3UEpKpavS1q6PjeWk561Us looking for Node1C at 10.0.0.101:9702
Fq5bVpEJAg56A4rnhGaCtiunHjZxYfY1Jt4p2dNRuG57 looking for Node1C at 10.0.0.101:9702
1thRpQudNCc9MMyGbdpEPzEPmXRWynMXr9MVz1aMkwD looking for Node1C at 10.0.0.101:9702
Node request completed Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv
{code}


h6. ACTUAL RESULT
- Node1 probably was not promoted (it didn't make catch up)
- There are some errors in response to satus command:
{code:java}
sovrin@Node1:~/.sovrin$ sudo systemctl status sovrin-node
[sudo] password for sovrin:
● sovrin-node.service - Sovrin Node
   Loaded: loaded (/etc/systemd/system/sovrin-node.service; enabled; vendor preset: enabled)
   Active: active (running) since Thu 2017-06-15 13:39:26 UTC; 1h 21min ago
 Main PID: 10937 (start_sovrin_no)
    Tasks: 3
   Memory: 62.7M
      CPU: 16min 9.592s
   CGroup: /system.slice/sovrin-node.service
           └─10937 /usr/bin/python3 /usr/local/bin/start_sovrin_node Node1 9701 9702

Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node[10937]:     ledger.tree.consistency_proof(end, req.catchupTill)]
Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node[10937]:   File ""/usr/local/lib/python3.5/dist-packages/ledger/compact_merkle_tree.py"", line 211, in consistency_proof
Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node[10937]:     self._subproof(first, 0, second, True)]
Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node[10937]:   File ""/usr/local/lib/python3.5/dist-packages/ledger/compact_merkle_tree.py"", line 210, in <listcomp>
Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node[10937]:     return [self.merkle_tree_hash(a, b) for a, b in
Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node[10937]:   File ""/usr/local/lib/python3.5/dist-packages/ledger/compact_merkle_tree.py"", line 198, in merkle_tree_hash
Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node[10937]:     return self.hashStore.readLeaf(end)
Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node[10937]:   File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/file_hash_store.py"", line 81, in readLeaf
Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node[10937]:     raise IndexError(""No leaf at given position"")
Jun 15 14:49:32 Node1.evernym.lab start_sovrin_node[10937]: IndexError: No leaf at given position
{code}

h6. ADDITIONAL INFORMATION
- After restarting sovrin-node.service it made catch up and client connected to it.
- Please see attachments",,,,,,,,,,,INDY-389,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 1:03 AM;aleksey-roldugin;Node1.log;https://jira.hyperledger.org/secure/attachment/11105/Node1.log","16/Jun/17 1:03 AM;aleksey-roldugin;data.tar;https://jira.hyperledger.org/secure/attachment/11106/data.tar",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1sv:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,aleksey-roldugin,dsurnin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 1:04 AM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","16/Jun/17 1:33 AM;aleksey-roldugin;After demoting-promoting another node (Node5) client immediately connected to it however node didn't make catch up. But restarting sovrin-node.service helped in this case too.;;;","10/Jul/17 10:43 PM;dsurnin;crash is not reproduced, however it blocked by INDY-389;;;","12/Jul/17 11:39 PM;dsurnin;tested with the latest master

nodes are promoted, catch up is done;;;","15/Jul/17 3:18 AM;aleksey-roldugin;h6. BUILD

repository master
sovrin 0.2.9
indy-node 0.4.35

h6. PRECONDITIONS
 # Pool from 7 machines: 6 nodes and 1 client

h6. STEPS TO REPRODUCE

# Demote Node1:
{code:java}
sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services': []}
Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by V4SGRU86Z58d6TV7PBUe6f (request id: 1500055358796735)
3wY2RXNaUswRASh6rwXV6T2Tct1fBP9F1dLv7Twd1XPk disconnected from Node1C
Node request completed Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv
{code}
# Demote Node6:
{code:java}
sovrin@test> send NODE dest=Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8 data={'alias': 'Node6', 'services': []}
Sending node request for node identifier Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8 by V4SGRU86Z58d6TV7PBUe6f (request id: 1500055533854273)
3wY2RXNaUswRASh6rwXV6T2Tct1fBP9F1dLv7Twd1XPk disconnected from Node6C
Node request completed Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8
{code}
# Update Node5 (it wasn't demoted so this should not make any effectcs):
{code:java}
sovrin@test> send NODE dest=4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe data={'alias': 'Node5', 'services': ['VALIDATOR']}
Sending node request for node identifier 4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe by V4SGRU86Z58d6TV7PBUe6f (request id: 1500055646040310)
Node request completed 4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe
{code}
# Promote Node6 (successful):
{code:java}
sovrin@test> send NODE dest=Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8 data={'
alias': 'Node6', 'services': ['VALIDATOR']}
Sending node request for node identifier Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8 by V4SGRU86Z58d6TV7PBUe6f (request id: 1500055719811549)
3wY2RXNaUswRASh6rwXV6T2Tct1fBP9F1dLv7Twd1XPk looking for Node6C at 10.0.0.7:9712
3wY2RXNaUswRASh6rwXV6T2Tct1fBP9F1dLv7Twd1XPk now connected to Node6C
Node request completed Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8
{code}
# Promote Node1 (successful):
{code:java}
sovrin@test> send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'
alias': 'Node1', 'services': ['VALIDATOR']}
Sending node request for node identifier Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv by V4SGRU86Z58d6TV7PBUe6f (request id: 1500055775886415)
3wY2RXNaUswRASh6rwXV6T2Tct1fBP9F1dLv7Twd1XPk looking for Node1C at 10.0.0.2:9702
3wY2RXNaUswRASh6rwXV6T2Tct1fBP9F1dLv7Twd1XPk now connected to Node1C
Node request completed Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv
{code}

h6. ACTUAL RESULT
- Node1 made catch up
- There are no errors in response to status command;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool can stall if the primary goes offline as a new node is added if the transition happens when the pool is at the max f nodes,INDY-237,18072,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,ashcherbakov,krw910,krw910,16/Jun/17 2:39 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"If the pool has all the faulty nodes it can allow and the primary goes down as a new node, or faulty node, is coming on up the pool can get into a stalled state. 

*Setup*
Install only 4 nodes and 1 client 
If the nodes are started then stop all the nodes.

*Steps*
# Bring up only 3 of the 4 nodes.
# On one of the nodes switch to the sovrin user and go to the .sovrin directory.
# Search the node log for "":0 declaring primary as:"" to see which node is the current primary.
# Now shutdown the primary node at the same time you start Node 4.
# Send a add NYM transaction and it should not go through (won't show Added NYM in the CLI)

{color:#d04437}Issue{color}
With the primary going down we are in a failed state with not enough nodes to elect a new primary. When Node 4 comes up it was never disconnected from a primary because it was never connected. So Node 4 does not instantiate a view change and the protocol stalls.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx22n:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/17 6:21 AM;krw910;The protocol for view change was rewritten so this scenario is no longer reproducible. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ADD GENESIS TRANSACTION command does not work,INDY-238,18076,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,aleksey-roldugin,aleksey-roldugin,16/Jun/17 3:19 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,Could,,,,"h6. BUILD

sovrin-node 0.3.138
 sovrin-client 0.3.136
h6. PRECONDITIONS

Working pool (I used [Shakedown Pool 4|https://docs.google.com/spreadsheets/d/1dQs2101Xcb9HMJQufLgtmiHxA-apbjnbXn8CGiCDHp0/edit#gid=0])
h6. STEPS TO REPRODUCE

Send from CLI:
{code:java}
sovrin@test> add genesis transaction NYM dest=2ru5PcgeQzxF7QZYwQgDkG2K13PRqyigVw99zMYg8eML role=STEWARD
Genesis transaction added.
sovrin@test> add genesis transaction NODE for 2ru5PcgeQzxF7QZYwQgDkG2K13PRqyigVw99zMYg8eML by FvDi9xQZd1CZitbK15BNKFbA7izCdXZjvxf91u3rQVzW with data {""node_ip"": ""localhost"", ""nod
e_port"": ""9701"", ""client_ip"": ""localhost"", ""client_port"": ""9702"", ""alias"": ""AliceNode""}
Genesis transaction added
{code}
h6. ACTUAL RESULT:

Result is always following:
{code:java}
Genesis transaction added
{code}
But genesis pool_transactions_sandbox/transactions_sandbox and pool_transactions_sandbox/transactions_sandbox files didn't contain new transactions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1rz:",,,,,,,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 3:20 AM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","05/Dec/17 9:21 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Any unexpected input in the sovrin_config.py file to override settings causes the service to not start when it starts up.,INDY-239,18121,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,andrey.goncharov,krw910,krw910,16/Jun/17 5:08 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Could,,,,,"If you have even just one character entered into the sovrin_config.py file it will cause the service to crash on start up. So if a restart of the service is required like in an upgrade it would not start up.

*Steps*
In the .sovrin directory edit the sovrin_config.py file.
The default entry in the file is 
enableStdOutLogging=False

Now add an entry underneath that one like the letter v

{code}
enableStdOutLogging=False
v
{code}

*{color:#d04437}Issue{color}*
Restart the sovrin-node.service and you will see it crash.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0o7:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 11:49 PM;lovesh;[~krw910] Config file is python source code so any invalid python syntax like above will throw error, if you need to put some variables that you need to update later, prepend with comment like this `# v`;;;","30/Aug/17 6:56 AM;krw910;Using a python file for configuration is acceptable so this will not be fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
handle a corrupt ledger record,INDY-240,18130,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,alexander.shekhovcov,danielhardman,danielhardman,16/Jun/17 8:19 AM,13/Nov/19 12:24 AM,28/Oct/23 2:46 AM,13/Nov/19 12:24 AM,,,,,0,6Months,should,,,,"INDY-20 told us that we crash if a ledger record is corrupted.

I want us not to crash when we encounter a ledger record that we cannot read. We could ignore it, or we could at a minimum exit cleanly while printing a message about which record is corrupt, with a suggestion that one way to fix the problem is to rebuild the ledger.

Ideally, a node that gets into this state should still start and run, just so it can receive POOL_UPGRADE transactions that allow it to get new software that is more capable of dealing with the corruption (maybe a migration script would reset or fix the corruption).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzwyh3:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Nov/19 12:24 AM;esplinr;This looks like a good idea, but the problem it is addressing is very unlikely and has a clear recovery by relying on the other nodes in the pool. So we don't plan on implementing this improvement in the near future.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GET_NYM receive out-of-date data after successfully NYM,INDY-241,18138,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,ashcherbakov,sergey.minaev,sergey.minaev,16/Jun/17 9:00 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,should,,,,,"Scenario (obtained in integration tests of indy-sdk):

1) send NYM from client to 4nodes pool

2) receive f+1 same response on client with successful status

3) send GET_NYM (for record from step 1) from client without delay after step 2

4) sometimes receive 2 ""empty"" replies and 2 replies with data. So, if empty replies will be received firstly, client should decide that NYM not found

Logs from libsovrin test in [^indy_sdk_NYM_GET_NYM.log]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/17 9:00 PM;sergey.minaev;indy_sdk_NYM_GET_NYM.log;https://jira.hyperledger.org/secure/attachment/11181/indy_sdk_NYM_GET_NYM.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0nz:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,sergey.minaev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Aug/17 6:53 AM;krw910;The ledger eventually all gets in sync. There is no guarantee the read request will go to the same node to get the update to date response immediately.  ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Design: Client backward compatibility,INDY-242,18139,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ashcherbakov,ashcherbakov,16/Jun/17 9:34 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"We have a way to deal with nodes (and ledger data) backward-compatiblity: migration scripts.
 What about client-to-node and client-to-client (agent-to-agent) backward compatibility?

For example, the protocol (message formats) will be changed during the fixes required for libsovrin cross-compatibility issue (CLAIM_REQ format may be changed).

How a newly updated Agent (supporting new protocol) should communicate with an old CLI (using old protocol)? 

[DESIGN DOCUMENT|https://docs.google.com/document/d/1_Wm_EaTFmBCtXSwBopf0W7ong81Mpt1RVZsNSWJUPa0/edit]

 

 ",,,180,180,,0%,180,180,,,,,,INDY-374,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy21j:",,,,,,H3,H4,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,mgbailey,mzk-vct,stevetolman,tharmon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jun/17 6:23 AM;stevetolman;Please time box this to no more than 2 hours on an initial cut, get some feedback from architects, and two hours of improvement.;;;","03/Jul/17 11:15 PM;mzk-vct;Design document https://docs.google.com/document/d/1_Wm_EaTFmBCtXSwBopf0W7ong81Mpt1RVZsNSWJUPa0/edit#;;;","04/Jul/17 12:16 AM;mzk-vct;Design was discussed with [~ashcherbakov];;;","04/Jul/17 8:44 AM;mgbailey;I ran into this with sovrin-client 3.20 and 3.22.  I ran both CLI and Agent with 3.20, and all is well.  I ran both with 3.22, and all is well.  But run one in 3.20, and the other in 3.22, and there are issues.  I think this is bad behavior. It is unrealistic to expect/require that all agents (including CLI clients) will be running identical versions of sovrin-client.;;;","06/Jul/17 12:01 PM;danielhardman; I would like someone from Trev's organization ([~mgbailey], [~tharmon], or [~dfarns]), plus [~rajesh.kalaria] and either [~nage] or [~TelegramSam] to buy off on this approach.

I have left some comments in the doc.

I recommend that the proposal be presented at the next Architects Roundtable–possibly with some attempt to get comments between now and then.;;;","06/Jul/17 1:22 PM;tharmon;Here's my two cents, with a full understanding of what this may mean in terms of engineering time.

One of the purposes of this network is to provide permanent identities to disadvantaged populations. We can't simply disenfranchise members of that group because they aren't keeping their devices up to date (e.g., a refugee falls too far behind in updates on the 3000 mile overland crossing, and now can't access their identity).

So, I think Option 2 is the only real option.

{quote}
Support all old versions of protocols in client (ugly?)
{quote}

And yes, it's potentially really painful, though it needn't be ugly if we're careful how we architect it.;;;","06/Jul/17 1:25 PM;tharmon;In regard to the design document, I don't think either of the ""try and fail"" approaches are desirable.;;;","06/Jul/17 11:25 PM;ashcherbakov;[~danielhardman] [~mzk-vct] [~stevetolman] Should we keep this ticket in TODO column?;;;","07/Jul/17 6:00 AM;stevetolman;You can move this ticket to done directly when this is debated in the next architect roundtable.;;;","12/Jul/17 9:50 PM;ashcherbakov;[~danielhardman] [~stevetolman]

We debated yesterday during the ART. The design was created based on a timebox assumption (1-2 hours). so it doesn't contain all the details.

Should we close this ticket? Should we create a new one to provide more details about chosen approaches (like approach with versioning)?

 ;;;","14/Jul/17 5:02 AM;danielhardman;This is enough for now. We can do more work when we implement.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Handle a corrupted ledger file,INDY-243,18140,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,alexander.shekhovcov,alexander.shekhovcov,alexander.shekhovcov,16/Jun/17 9:48 PM,13/Nov/19 12:25 AM,28/Oct/23 2:46 AM,13/Nov/19 12:25 AM,,,,,0,6Months,Must,,,,"Fix the ledger so a corrupt database record doesn't prevent the service from starting.

Success criteria for the ticket: either the service runs with a corrupted record (simply failing to retrieve that record with a graceful error) – or, if the database is too damaged to use, the service exits with a graceful error and says something like this to the log and the screen: ""The database is corrupt. To fix the problem, delete the database and rebuild.""",,,,,,,,,,,,,,,,,,,,,,,INDY-149,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzwygv:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Nov/19 12:25 AM;esplinr;This looks like a good idea, but the problem it is addressing is very unlikely and has a clear recovery deleting the local database. So we don't plan on implementing this improvement in the near future.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test how a node deals with 3pc messages for a previous state,INDY-244,18142,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,16/Jun/17 10:24 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"*Description*
Test how a node deals with 3pc messages for a previous state, possibly already ordered state.

*Findings*
No bugs.",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy19r:",,,,,,H1,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/17 12:27 AM;spivachuk;Tested scenarios when 3PC-messages ({{PROPAGATE}}, {{PREPREPARE}}, {{PREPARE}}, {{COMMIT}}) are sent repeatedly. Checked multiplied repeated sending with no delay and with a delay that causes repeated 3PC-messages to get mixed with newer 3PC-messages (including newer {{ORDERED}} messages). Checked repeated sending from one node in the pool and from all the nodes in the pool.

Found no bugs. Repeated messages were discarded by receiving nodes in all the verified cases.;;;","20/Jun/17 12:32 AM;spivachuk;Also I would like to make clarification about {{AssertionError}} that I observed on June 16. It occurred when repeated {{ORDERED}} messages (gotten using changes in source code of plenum) were mixed with newer {{ORDERED}} messages. But {{ORDERED}} messages are not transferred via a network, {{ORDERED}} is an internal message inside a node. This is a message from a replica to the node containing it. So the case with repeated {{ORDERED}} messages was synthetic and may not occur due to network troubles. Thus that {{AssertionError}} did not represent a bug.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ATTRIB txn is not processing by n-f nodes,INDY-245,18238,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,17/Jun/17 12:01 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"*Steps:*
 # have a 4-nodes pool, all nodes are running
 # stop one node
 # send ATTRIB txn

*Result:*

The pool does not return replays

*Expected result:*

The pool returns replays

 

*Finding:*
 * Node2 did not forward the request 1497408485465294 to the replicas after the node gets 2 propagates from node3 and node4
 * so 3pc is stopped because no quorum (node1 is not participating)
 * the pool sends ppSeqNo=1 in a CONSISTENCY_PROOF replay to node1 after the node1 is started
 * but next pre-prepare comes with ppSeqNo=4 from the primary
 * so node1 prints ""_missing PRE-PREPAREs between 4 and 1""_ 
 * PROPAGATE for 1497408485465294 comes to node3 and node4 before node3 and node4 receive 1497408485465294 from client

 

 

 ",,,,,,,,,,,,,,,,,,,,,,,INDY-159,,,,INDY-246,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy18v:",,,,,,H1,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jun/17 2:13 AM;alexander.shekhovcov;*(/)*

*Problem reason:*
 - error in the serialization Propagate message with ATTRIB inside

*Changes:*
 - use proper class for the serialization Propagate message

*Committed into:*
 [https://github.com/evernym/plenum/pull/221]
 version

*Risk factors:*
 Nothing is expected.

*Risk:*
 Low

*Covered with tests:*
 _sovrin_node/test/attrib_txn/test_n_minus_f_pool_processes_attrib.py_

*Recommendations for QA:*

Repeat steps from the description

 ;;;","21/Jun/17 3:29 AM;krw910;I followed the same steps as before and did not run into any issues and the catch process worked when I restarted the node that was shut down.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing pre-prepare hangs 3pc processing,INDY-246,18241,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,17/Jun/17 1:42 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"Working on INDY-245 I found that if node misses a pre-prepare from the primary replica the node becomes unable to participate in 3pc later requests.

I wrote the following test (just temporary changed _testNumOfPrePrepareWithOneFault_):
{code:java}
@pytest.fixture(scope=""module"")
def setup(startedNodes):
    A = startedNodes.Alpha
    makeNodeFaulty(A,
                   partial(delaysPrePrepareProcessing, delay=60))
    A.delaySelfNomination(10)
    return adict(faulties=A)


@pytest.fixture(scope=""module"")
def afterElection(setup, up):
    for r in setup.faulties.replicas:
        assert not r.isPrimary
    return setup


def testNumOfPrePrepareWithOneFault(looper, startedNodes, afterElection,
                                    preprepared1, wallet1, client1):
    A = startedNodes.Alpha
    B = startedNodes.Beta
    A.resetDelays()
    requests = sendRandomRequests(wallet1, client1, 5)
    waitForSufficientRepliesForRequests(looper, client1,
                                        requests=requests)
    assert A.replicas[0].lastOrderedPPSeqNo == B.replicas[0].lastOrderedPPSeqNo{code}
I see that the Alpha:
 * gets pre-prepares after the delays were reset and stash them

{code:java}
2017-06-16 19:24:11,157 | DEBUG | replica.py (812) | __is_next_pre_prepare | Alpha:0 missing PRE-PREPAREs between 2 and 0
2017-06-16 19:24:11,157 | DEBUG | replica.py (1484) | enqueue_pre_prepare | Queueing pre-prepares due to unavailability of previous pre-prepares. PrePrepare PREPREPARE{'viewNo': 0, 'ppSeqNo': 2, 'digest': 'ca929a100002614c57ad9b34df75c09187562f2e71d136c86b8ef420b7425c6f', 'ledgerId': 1, 'discarded': 5, 'stateRootHash': 'baa69121f4fa752e60e1fd9285de388ff884dea5ff50a6c4f175e6a5e808e57e', 'reqIdr': [('MRE3tAh3Wseda9K3ZYMDhL', 1497630250115240), ('MRE3tAh3Wseda9K3ZYMDhL', 1497630250116196), ('MRE3tAh3Wseda9K3ZYMDhL', 1497630250117102), ('MRE3tAh3Wseda9K3ZYMDhL', 1497630250117993), ('MRE3tAh3Wseda9K3ZYMDhL', 1497630250118847)], 'txnRootHash': '8aabbc81eace7f6ce505b4c49b9bdfbff9276bbc4b2d42008d1f2651512ee41e', 'ppTime': 1497630251085.8435, 'instId': 0} from Delta:0
{code}
 * stashes prepares

{code:java}
2017-06-16 19:24:11,237 | DEBUG | replica.py (708) | processPrepare | Alpha:1 received PREPARE(0, 2) from Delta:1
2017-06-16 19:24:11,237 | DEBUG | replica.py (1525) | enqueuePrepare | Queueing prepare due to unavailability of PRE-PREPARE. Prepare PREPARE{'viewNo': 0, 'ppSeqNo': 2, 'digest': 'ca929a100002614c57ad9b34df75c09187562f2e71d136c86b8ef420b7425c6f', 'stateRootHash': None, 'txnRootHash': None, 'instId': 1} from Delta:1
2017-06-16 19:24:11,237 | DEBUG | replica.py (724) | processPrepare | Alpha:1 cannot process incoming PREPARE
{code}
 * stashes commits

{code:java}
2017-06-16 19:24:11,303 | DEBUG    | replica.py           (1549) | enqueueCommit | Queueing commit due to unavailability of PREPARE. Request COMMIT{'viewNo': 0, 'ppSeqNo': 2, 'instId': 0} from Gamma:0
{code}
 * and eventually does not reply

 

 Looks like only restarting the node fixes this problem.

h4. POA:
A node simply requests PRE-PREPAREs in when lacks PRE-PREPARE, PRE-PREPARE is needed since it has the requests which needs to be ordered. Missing PRE-PREPARE is not very common and to solve this uncommon problem, increasing size of each PREPARE is not acceptable. The request for PRE-PREPARE does not necessarily need to be made to the primary, it can be made to any non-primary or multiple nodes in parallel since quorum of PREPAREs will tell if the PRE-PREPARE is correct or not. So our protocol works even if a minority (<f) of replicas is partitioned from primary.
*When to request PRE-PREPARE*: If after receiving a PREPARE, a replica finds that it does not have a PRE-PREPARE for it, the replica checks if it has 2f-1 PREPAREs, if yes then it simply requests PRE-PREPARE from one or more of the nodes that sent PREPARE. A variation can be to wait for a timeout and then request PRE-PREPARE since the replica might miss more than 1 PRE-PREPARE and thus can request in bulk but we are being aggressive so not doing that. Also the replica waits for 2f-1 PREPAREs and not f+1 PREPAREs since even if it got a PRE-PREPARE, it cannot order it until it has >=2f PREPAREs.
A general message requesting component needs to be built. A node can send a *MessageReq(type: str, params: dict)* to any node, the other node responds with corresponding message in *MessageRep(type: str, params: dict, msg: Any)*. The *msg* will be null if the other node did not have what was requested, but it should send the *MessageRep* anyway. This mechanism should be used to request `PrePrepare`, `LedgerStatus` and `ConsistencyProof`.
{code}
Eg.
MessageReq(type: LedgerStatus, params: {ledger_id: 1})
MessageReq(type: PrePrepare, params: {instId: 0, viewNo: 0, ppSeqNo:5})
MessageReq(type: ConsistencyProof, params: {ledger_id: 1, seqNoStart: 20, seqNoEnd: 30})
{code}
",,,97200,97200,,0%,97200,97200,,,,,,,,,,,,,,,INDY-245,,,,INDY-454,,,,,,,,"17/Jun/17 1:43 AM;alexander.shekhovcov;indy-246.log;https://jira.hyperledger.org/secure/attachment/11185/indy-246.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8c7:",,,,,,H3,H4,H5,M1 Prelude,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,danielhardman,krw910,lovesh,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jun/17 1:56 AM;ashcherbakov;[~lovesh]
For me it looks like there is a problem in either RBFT, or in our implementation (especially with batching):
- Once a non-primary misses PRE_PREPARE, it is stalled until the next catch-up is done
- It seems for me that PREPARE needs to be like a 'Propagate of Pre-Prepares'. So, even if we miss a Pre-Prepare, but received 2f Prepares for a request, then we can send COMMIT. Currently we wait for the corresponding PrePrepare in this case (which corresponds to what RBFT paper says, but is it really correct?)
- Looks like we need to move all batching-related logic from PrePrepare to Prepare. That's we should validate and apply uncommitted state on recieves sufficient number of Prepares, not on receiving of PrePrepare (consider prepare as just a propagation of pre-prepares).


;;;","17/Jun/17 2:16 AM;lovesh;This is intentional,
A node will not accept a PREPARE without a PRE-PREPARE, if we act on this assumption that success indication of a later phase means we ignore problems with previous phase, then you really don't need to wait for PRE-PREPARE+2f PREPAREs, once you have 2f+1 COMMITs if you put roots in COMMITs too. Not having a PRE-PREPARE indicates a problem, either primary did not send you, or you lost it in network or it's just delayed. So if you miss PRE-PREPARE, you should not really start the whole catchup but just request that PRE-PREPARE from one node, it was a suggestion from the author of RBFT when i asked these questions that you do not send messages speculatively. If we want then if we have PRE-PREPARE for some batches but we miss PREPAREs and COMMITs (poor network) but start getting all 3PC messages then we can quickly check if these PRE-PREPARES were ordered or not and execute them if they were;;;","17/Jun/17 2:31 AM;ashcherbakov;Yes, I agree that catch-up (or even just a catch-up of missing Pre-Prepares) will help. 

But for me it's still not obvious that having 2f PREPARES for a request with f+1 PROPAGATE is not enough to assume that a request can be committed. 
We should not send PREPAREs to other nodes if we don't have the corresponding PRE-PREPARES.
But I think we can process (send COMMIT), if we have >2f PREPARES. It means that we have consensus about the PRE_PREPARE.;;;","17/Jun/17 2:32 AM;ashcherbakov;Also, the pool becomes very fragile without such a catch-up. It will be quite common than a PrePrepare is not received.;;;","17/Jun/17 2:44 AM;mzk-vct;PrePrepare has two goals:
1. Introduce request for ordering.
2. Ensure that we have only one (since only Primary can send PrePrepares) source of requests to exclude possible concurrent tricks.

When 2f+1 backup nodes receive PrePrepare we can declare that PrePrepare played its role and its life is over.
That's why I see no reason why node cannot join ordering if it has no PrePrepare, but received 2f+1 Prepares.
There is only one limitation - since nodes can forward Prepares malicious node can try to introduce request for ordering bypassing primary.
To avoid this we just need to prohibit node to propagate Prepares if it has no PrePrepare.

;;;","17/Jun/17 2:46 AM;lovesh;PREPAREs and PROPAGATEs are independent, former is for batch which may have more than 1 request while the latter is for request, also PROPAGATE has nothing to do with consensus, a request might be invalid (might invalidate state, double spend) but will be propagated. If COMMIT is the third phase, if we can send COMMITs then no reason why we cant send PREPAREs;;;","17/Jun/17 2:54 AM;ashcherbakov;[~lovesh]
Yes, they are independent in general, but I mean the following from RBFT paper:
_It  then  replies  to  the PRE-PREPARE message  by sending a PREPARE message to all other replicas, only if the node  it  is  running  on  already  received f+1  copies  of  the request._
So, it can have f+1 copies of the request only because of PROPAGATE (that's why they are related in some sense).;;;","27/Jun/17 7:31 PM;lovesh;If we accept a lack of PRE-PREPARE and try to compensate that with a PREPARE (>2f PREPARE) then PREPARE needs to include which requests are part of that batch (by including all identifier+requestId) since only PRE-PREPARE contains this information, the PREPARE only has a digest for them and post roots after applying those requests. 
I would suggest we simply do a request PRE-PREPARE in absence of PRE-PREPARE, it solves the problem. Missing PRE-PREPARE is not very common and to solve this uncommon problem, increasing size of each PREPARE is not acceptable.
The request for PRE-PREPARE does not necessarily need to be made to the primary, it can be made to any non-primary since quorum of PREPAREs will tell if the PRE-PREPARE is correct or not. So our protocol works even if a minority (<f) of replicas is partitioned from primary.;;;","28/Jun/17 5:32 PM;ashcherbakov;[~lovesh] Yes, I was assuming that we OK with lack of PRE_PREPARES, then
# The PREPARE message must be indentical to PRE-PREPARE (PREPARE is just Propagation of PRE-PREPARE)
# We need to move the logic for processing and validating Batches to the point, when we have a consensus of PREPAREs.

;;;","29/Jun/17 12:30 AM;ashcherbakov;A doc from Lovesh:
https://docs.google.com/document/d/1tH7LweHiV9eugbc_6TxftWquae4WYgmGpmBobeOlbq4/edit?ts=5953c82d#;;;","06/Jul/17 12:27 PM;danielhardman;I know we are blocked on this until someone (me, probably) specifies whether we should accept Lovesh's generic message request mechanism, or use the more specific variant that Alex favors. I sent an email about how I'd like to resolve the impasse. Let's talk after Thursday's standup.;;;","10/Jul/17 6:45 PM;lovesh;PR for the change: https://github.com/hyperledger/indy-plenum/pull/251. Relevant `tests test_node_requests_missing_preprepare`, `test_node_requests_missing_preprepare_malicious`, `test_node_request_preprepare`, `test_no_preprepare_requested`, `test_handle_delayed_preprepares`, `test_node_reject_invalid_req_resp_type`, `test_node_reject_invalid_req_resp_params`. Also some of the tests were updated which relied on delaying the PRE-PREPARE for simulating slowness, in those PREPARE was also delayed to since now PRE-PREPAREs can be requested;;;","13/Jul/17 5:25 AM;krw910;Blocked by INDY-406;;;","18/Jul/17 12:37 PM;krw910;Pool stopped working at running load test after 33,000 transactions repeating ""missing PRE-PREPARE"" in some of the log files.

Three of the nodes fell out of sync at about 26,000 transactions, but the pool kept working for another 7,000 transaction before it stopped allowing any new transactions to occur. 
The log level was set to debug  and with that many transactions there are over 1GB of logs so I cannot attach them. Here is a snippet from Node1.log showing ""missing PRE-PREPARE"".

{code}
2017-07-18 00:10:16,239 | DEBUG    | replica.py           ( 950) | __is_next_pre_prepare | Node1:0 missing PRE-PREPAREs between 6 and 4
2017-07-18 00:10:16,241 | DEBUG    | has_action_queue.py  (  61) | _serviceActions | Node1 running action <function HasActionQueue.startRepeating.<locals>.wrapper at 0x7f3436645a60> with id 3478
2017-07-18 00:10:16,241 | TRACE    | node.py              (1969) | checkPerformance | Node1 checking its performance
2017-07-18 00:10:16,241 | DEBUG    | notifier_plugin_manager.py (  69) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike: New value 10 is within bounds. Average: 20.178996228604614
2017-07-18 00:10:16,241 | INFO     | monitor.py           ( 296) | isMasterThroughputTooLow | Node1 master throughput ratio 0.0 is lower than Delta 0.4.
2017-07-18 00:10:16,241 | DEBUG    | throttler.py         (  30) | acquire | now: 265336.688094334, len(actionsLog): 6
2017-07-18 00:10:16,241 | DEBUG    | throttler.py         (  32) | acquire | after trim, len(actionsLog): 5
2017-07-18 00:10:16,241 | DEBUG    | throttler.py         (  42) | acquire | timeToWaitAfterPreviousTry: 3.568050833375483, timePassed: 10.00919619295746
2017-07-18 00:10:16,241 | DEBUG    | throttler.py         (  47) | acquire | timeToWaitAfterPreviousTry < timePassed was true, after append, len(actionsLog): 6
2017-07-18 00:10:16,241 | INFO     | node.py              (2035) | sendInstanceChange | Node1 sending an instance change with view_no 4 since Primary of master protocol instance degraded the performance
2017-07-18 00:10:16,242 | INFO     | node.py              (2037) | sendInstanceChange | Node1 metrics for monitor: Node1 Monitor metrics:: None
            Delta: 0.4
            Lambda: 60
            Omega: 5
            instances started: [235292.793769927, 235292.794086392, 235292.79439418, 235292.794818582]
            ordered request counts: {0: 0, 1: 27, 2: 27, 3: 27}
            ordered request durations: {0: 0, 1: 14.578874578030081, 2: 14.874403344118036, 3: 16.25337524403585}
            master request latencies: {}
            client avg request latencies: [{}, {'ATHPhYMbd8GVmMH53gobC1': (5, 0.5404794633970595), 'Q3FnaYVnAk3A1oQfvGJY7v': (5, 0.5594268773973454), 'HBtdADDEL9SYpDgGDdXxXg': (5, 0.5559135610004887), 'V4SGRU86Z58d6TV7PBUe6f': (1, 0.3419497249997221), 'SJ9Akdc6vNkBsNiNhTPEhG': (5, 0.5686641380016226), '5WznHUkz36Tb6TFVYTpJed': (6, 0.519084109007963)}, {'ATHPhYMbd8GVmMH53gobC1': (5, 0.5329394946049433), 'Q3FnaYVnAk3A1oQfvGJY7v': (5, 0.5830360744032077), 'HBtdADDEL9SYpDgGDdXxXg': (5, 0.5631893420009874), 'V4SGRU86Z58d6TV7PBUe6f': (1, 0.3942903550050687), 'SJ9Akdc6vNkBsNiNhTPEhG': (5, 0.5639786391984671), '5WznHUkz36Tb6TFVYTpJed': (6, 0.54406587301249)}, {'ATHPhYMbd8GVmMH53gobC1': (5, 0.6473643529985565), 'Q3FnaYVnAk3A1oQfvGJY7v': (5, 0.6009648302046117), 'HBtdADDEL9SYpDgGDdXxXg': (5, 0.5930604616005439), 'V4SGRU86Z58d6TV7PBUe6f': (1, 0.48810275198775344), 'SJ9Akdc6vNkBsNiNhTPEhG': (5, 0.626101103995461), '5WznHUkz36Tb6TFVYTpJed': (6, 0.571303124675372)}]
            throughput: {0: 0, 1: 1.8519948062855396, 2: 1.8151988604421523, 3: 1.6611934194965199}
            master throughput: 0
            total requests: 21007
            avg backup throughput: 1.7721708851771232
            master throughput ratio: 0.0
2017-07-18 00:10:16,242 | DEBUG    | node.py              (2543) | send | Node1 sending message INSTANCE_CHANGE{'viewNo': 4, 'reason': 25} to all recipients: ['Node3', 'virginaPerf10', 'seoulPerf8', 'Node2', 'Node7', 'saopauloPerf9', 'Node6', 'Node4', 'Node5']
{code}


*Setup*
10 Node pool each on their own machine spread globally. 
4 Client machines each running the CLI

*Running load tests*
I already had 246 transactions on my ledger before starting the load tests

*From one Client run the following one time (+200)*
python3 add_keys.py Steward1 000000000000000000000000Steward1

*From one Client run the following in order*
*Add 500*
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500
*Add 500*
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once
*Add 750*
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 750 --at-once
*Add  1,000*
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 1000 --at-once
*Add  2,000*
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 2000 --at-once

*Add 15,000*
./load_test_overmind.sh 5 3000 NYM ./load_test_clients.list


*Start at the same time from 4 separate client machines (+2,000)*
Client 1 - python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once
Client 2 - python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once
Client 3 - python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once
Client 4 - python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once

*Start at the same time from 4 separate client machines (+3,000)*
*{color:#d04437}(Dropped 2 transactions){color}*
Client 1 -  python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 750 --at-once
Client 2 -  python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 750 --at-once
Client 3 -  python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 750 --at-once
Client 4 -  python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 750 --at-once


*Start at the same time from 4 separate client machines (+8,000)*  
*{color:#d04437}(Became out of sync on Nodes 1,3,6){color}*
*{color:#d04437}Nodes 1,3,6 - 25,596{color}*
*{color:#d04437}Nodes 2,4,7,8,9,10 - 33,196{color}*
Client 1 -  python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 2000 --at-once
Client 2 -  python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 2000 --at-once
Client 3 -  python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 2000 --at-once
Client 4 -  python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 2000 --at-once

I was still able to add new transactions one at a time.
I then kicked off a larger test and only a few transaction were written before the pool stopped taking any new transactions.

*Start at the same time from 4 separate client machines (+60,000)*
Client 1 - ./load_test_overmind.sh 5 3000 NYM ./load_test_clients.list
Client 2 - ./load_test_overmind.sh 5 3000 NYM ./load_test_clients.list
Client 3 - ./load_test_overmind.sh 5 3000 NYM ./load_test_clients.list
Client 4 - ./load_test_overmind.sh 5 3000 NYM ./load_test_clients.list

*Final ledger counts show the following*
Node 1 has  25596 total transactions
Node 2 has  33219 total  transactions
Node 3 has  33219 total  transactions
Node 4 has  33221 total  transactions
Node 5 has  33219 total  transactions
Node 6 has  25596 total transactions
Node 7 has  33219 total transactions
Node 8 has  33219 total transactions
Node 9 has  33221 total transactions 
Node 10 has  33221 total transactions

;;;","18/Jul/17 11:34 PM;lovesh;[~krw910] Due to a bug with log rollover INDY-435 i am not able to see logs before this started happening.;;;","21/Jul/17 5:43 AM;krw910;Killed the pool again after 5,555 transactions. 

*Setup*
10 Node Global Pool
10 Clients

*Commands sent for the load tests*
{color:#205081}Add Trust Anchors using one client{color}
python3 add_keys.py Steward1 000000000000000000000000Steward1

{color:#205081}From each of the 10 clients{color}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once

I had three transactions that did not go through out of 5,000

At this point I had 5,221 transaction in each of the nodes ledger

{color:#205081}From each of the 10 clients{color}
./load_test_overmind.sh 5 3000 NYM ./load_test_clients.list

This should run 50 clients sending 150,000 total requests. They are not sending all at once, but 1 at a time. So the pool should be getting about 50 requests per second.

*{color:#d04437}After 334 transactions the pool stopped taking new transactions. {color}*

*The logs show the following:*

*{color:#205081}sovrin_config.py{color}*
logLevel=0
logRotationBackupCount=20
ACCEPTABLE_DEVIATION_PREPREPARE_SECS=300
enableStdOutLogging=False

*{color:#205081}Primary - All nodes show{color}*
Node5:0
Node6:1
Node7:2
seoulPerf8:3

*{color:#205081}Transactions{color}*
{color:#14892c}Nodes 1,3,4,5,6,7,8,10{color}
5555

{color:#d04437}Node 2{color}
5528

{color:#d04437}Node 9 (saopauloPerf9){color}
5542


*{color:#205081}Pre-PRE-PREPAREs{color}*
grep -i ""missing PRE-PREPAREs"" *.log*

*Node1*
Node1.log:0
Node1.log.2017-07-20:87
Node1.log.2017-07-20.1:0
Node1.log.2017-07-20.2:0
Node1.log.2017-07-20.3:0

*Node2*
Node2.log:0
Node2.log.2017-07-20:3
Node2.log.2017-07-20.1:0
Node2.log.2017-07-20.2:0
Node2.log.2017-07-20.3:0

*Node3*
Node3.log:0
Node3.log.2017-07-20:35
Node3.log.2017-07-20.1:0
Node3.log.2017-07-20.2:0
Node3.log.2017-07-20.3:0

*Node4*
Node4.log:0
Node4.log.2017-07-20:0
Node4.log.2017-07-20.1:0
Node4.log.2017-07-20.2:0
Node4.log.2017-07-20.3:0

*Node5*
Node5.log:0
Node5.log.2017-07-20:64
Node5.log.2017-07-20.1:0
Node5.log.2017-07-20.2:0
Node5.log.2017-07-20.3:0

*Node6*
Node6.log:0
Node6.log.2017-07-20:0
Node6.log.2017-07-20.1:0
Node6.log.2017-07-20.2:0
Node6.log.2017-07-20.3:0

*Node7*
Node7.log.2017-07-20:0
Node7.log.2017-07-20.1:0
Node7.log.2017-07-20.2:0
Node7.log.2017-07-20.3:0
raet.log:0

*Node8*
seoulPerf8.log:0
seoulPerf8.log.2017-07-20:25
seoulPerf8.log.2017-07-20.1:0
seoulPerf8.log.2017-07-20.2:0
seoulPerf8.log.2017-07-20.3:0

*Node9*
saopauloPerf9.log:0
saopauloPerf9.log.2017-07-20:57
saopauloPerf9.log.2017-07-20.1:0
saopauloPerf9.log.2017-07-20.2:0
saopauloPerf9.log.2017-07-20.3:0

*Node10*
virginaPerf10.log:0
virginaPerf10.log.2017-07-20:72
virginaPerf10.log.2017-07-20.1:0
virginaPerf10.log.2017-07-20.2:0
virginaPerf10.log.2017-07-20.3:0

;;;","21/Jul/17 6:26 PM;lovesh;Node2 and Node9 had encountered a KeyError which is resolved in https://github.com/hyperledger/indy-plenum/pull/297;;;","22/Jul/17 1:59 AM;alexander.shekhovcov;My findings:
* the pool is broken because not only Node2 and Node9 crashed with KeyError but at least Node6 and Node7 crashed too
* Node6, Node7 (and maybe some others) finished catchup successfully
* Node2, Node9 did not finished catchup because they got enough ledger status messages from others crashed nodes and they stopped their catchup

I am working on solution which increases the quorum for LedgerStatus messages.
https://github.com/hyperledger/indy-plenum/pull/299;;;","24/Jul/17 10:10 PM;alexander.shekhovcov;*""Node stops the catchup procedure if gets f+1 old LedgerStatus""* INDY-454 was created.;;;","24/Jul/17 10:26 PM;alexander.shekhovcov;Just summarizing:
* there was an issue ""Missing pre-prepare hangs 3pc processing"" which was fixed Lovesh
* during testing Kelly got ""KeyError"" which was fixed Lovesh too
* ""KeyError"" made the pool in state when INDY-454 happened. INDY-454 was fixed and move to test

So the ticket ready for testing again. ;;;","27/Jul/17 12:33 AM;krw910;This appears to be working. I am not getting the pre-prepare issues or KeyError. We have other issues around getting a burst of transactions, but this ticket is fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Incorrect error message,INDY-247,18242,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,VladimirWork,VladimirWork,17/Jun/17 2:10 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
sovrin-node 0.3.139
sovrin-client 0.3.141

Overview:
Incorrect error message for POOL_UPGRADE with already existing name.

Preconditions:
POOL_UPGRADE command with any name is sent.

Steps to Reproduce:
1. Send POOL_UPGRADE command with same name as already has been sent.

Actual Results:
Pool upgrade failed: client request invalid: UnauthorizedClientRequest('TRUSTEE cannot do POOL_UPGRADE',)

Expected Results:
There should be error about the existing upgrade name that already has been sent.",,,,,,,,,,,,,,,,,,,,,,INDY-156,,,,,,,,,,,,,"17/Jun/17 2:10 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11187/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy4iv:",,,,,,,,,,,,,,,,,,,,,,,,,,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jun/17 2:35 AM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[QA] Upgrade: How does the node upgrade with incoming transactions where it has to do a catch up after its upgrade,INDY-248,18243,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,VladimirWork,VladimirWork,17/Jun/17 2:19 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"Description:
How does the single node upgrade and whole pool upgrade with incoming transactions where it has to do a catch up after its upgrade.

Findings:

- all transaction types from all user roles were sent during the single node manual upgrade
- all transaction types from all user roles were sent during the whole pool upgrade by the POOL_UPGRADE command
- nodes catched up successfully except issue with the primary node disconnection (INDY-289 that has not 100% reproducibility - so pool may break or may not due to this manipulations)
- there are some issues with POOL_UPGRADE command usability and errors correctness (INDY-247, INDY-287, it will be investigated in details during other exploratory tasks about this command usage)
- there is a local issue to be investigated with Shakedown pool 3 that has some abnormal state that breaks a commands execution (INDY-288)

Reported bugs:

INDY-247
INDY-287
INDY-288
INDY-289",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy18n:",,,,,,H1,,,,,,,,,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jun/17 3:40 AM;krw910;We got some good findings out of this testing.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Plenum addNewNodeAndConnect doesn't support DID,INDY-249,18252,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,,devin-fisher,devin-fisher,17/Jun/17 4:39 AM,13/Nov/19 12:30 AM,28/Oct/23 2:46 AM,13/Nov/19 12:30 AM,,,,,0,6Months,Must,,,,"Adding a new node requires a cryptonym, don't support DID-identifier with abbreviated verkey.
{code:java}
def connectNewRemote(self, txn, remoteName, nodeOrClientObj, addRemote=True):
    verkey = cryptonymToHex(txn[TARGET_NYM])

    nodeHa = (txn[DATA][NODE_IP], txn[DATA][NODE_PORT])
    cliHa = (txn[DATA][CLIENT_IP], txn[DATA][CLIENT_PORT])

{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-51,,,,,,,,,,"1|hzwx4f:2c",,,,,,H2,,,,,,,,,,,,,,,,,,,,ashcherbakov,devin-fisher,esplinr,spivachuk,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jun/17 9:58 PM;ashcherbakov;[~danielhardman] [~devin-fisher]
What was the final decision? Do we need this ticket in this Sprint?;;;","01/Jul/17 3:54 AM;devin-fisher;The decision was to push this. At least its work will not be part of INDY-205. Once INDY-205 is complete we can reconsider this work.;;;","01/Jul/17 4:03 AM;stevetolman;This needs further discussion.;;;","12/Oct/18 2:27 AM;spivachuk;The current implementation still requires a node nym to be a cryptonym. So the issue is actual.;;;","13/Nov/19 12:30 AM;esplinr;It would be nice to have nodes identified with DIDs instead of with legacy Cryptonyms, but it doesn't provide any functionality that isn't already present. So we will not be prioritizing this work in the near future.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
POOL_UPGRADE needs to be able to send the same version that is installed and cause a reinstall,INDY-250,18253,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,17/Jun/17 5:10 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,The POOL_UPGRADE command needs to allow for the same version that is already installed to be reinstalled. Currently you cannot have the upgrade install the same version.,,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,INDY-201,INDY-257,,,,,,,,,,,"02/Aug/17 9:29 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11810/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8cf:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Aug/17 8:07 PM;andrey.goncharov;Added reinstall flag to pool upgrade transaction. If this flag is present then an upgrade to the same version won't be only committed to a ledger, but scheduled as well. 

Transaction example can be found here https://github.com/hyperledger/indy-node/commit/6e3ae4b34300e54b5ca71fd1edebdb6e45ba251e#diff-818acc511b818a6ebc77590b6a98aeceL58


https://github.com/hyperledger/indy-node/commit/6e3ae4b34300e54b5ca71fd1edebdb6e45ba251e;;;","02/Aug/17 9:29 PM;VladimirWork;Build Info:
indy-node 1.0.69

Steps to Validate:
1. Schedule upgrade to already installed version with reinstall=True parameter. !Screenshot.PNG|thumbnail! 

Actual Results:
Version is reinstalled successfully.;;;","03/Aug/17 3:51 AM;danielhardman;What is done with migration scripts on reinstall?;;;","03/Aug/17 4:13 PM;andrey.goncharov;[~danielhardman] no migration scripts are applied since it's basically an upgrade from X.X.X to the same X.X.X (unless you have a migration script from X.X.X to the same X.X.X which is ridiculous );;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
POOL_UPGRADE only installs the latest build. You are not able to specify a version other than the latest to upgrade to.,INDY-251,18254,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,17/Jun/17 5:12 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,CI/CD/Update,Must,,,,"Currently you have to upgrade to the latest version that is available. For example if I am on build 0.3.130 and the latest is 0.3.133 I have to upgrade to 0.3.133. 
I need to be able to specify a different build so I can upgrade to 0.3.131 instead.",,,10800,10800,,0%,10800,10800,,,INDY-316,,,,,,,,,,INDY-259,,INDY-201,,,,INDY-259,,,,,,,,"11/Aug/17 11:11 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11872/Screenshot.PNG","11/Aug/17 11:11 PM;VladimirWork;_Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11873/_Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8fr:",,,,,,10,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,krw910,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jun/17 6:25 AM;stevetolman;Please time box this to one hour. Talk to Steve/Daniel if you cannot complete it in that time frame.;;;","29/Jun/17 8:04 PM;andrey.goncharov;[~stevetolman] this ticket requires refactoring logic by which we assess if an upgrade was successful. It's not a complex change but it still need to be properly thought through. I think it's going to take around a day. What should we do with it?;;;","30/Jun/17 5:43 AM;stevetolman;We'll come back to this later. Thanks for the report.;;;","11/Aug/17 7:42 PM;andrey.goncharov;Problem reason: 
- condition in handeUpgradeTxn

Changes: 
- condition changed

Committed into:
https://github.com/hyperledger/indy-node/commit/3514339ecda21f64e23335f90a0f5a34b911b371
indy-node/master 1.0.96

Risk factors:
 Nothing is expected.

Risk:
 Low

Covered with tests:
https://github.com/hyperledger/indy-node/commit/3514339ecda21f64e23335f90a0f5a34b911b371#diff-54057c42e56bc1af228b08b9db4ed074R15

Recommendations for QA:
As of this commit downgrades are supported.

 

Test two scenarios:
 # Upgrade to a version which is not the last one
 ## Install indy-node of version X 
 ### X should be equal or greater than 1.0.96
 ## Make sure there's indy-node of versions X+1 and X+2
 ## Submit POOL_UPGRADE to X+1
 ## Make sure it completes successfully
 # Downgrade
 ## Install indy-node of version X+1
 ## Submit POOL_UPGRADE to X
 ## Make sure it completes successfully;;;","11/Aug/17 11:11 PM;VladimirWork;Build Info:
indy-node 1.0.96

Steps to Validate:
1. Send pool upgrade to not the last one version.
2. Send pool upgrade to previous version.

Actual Results:
Both upgrades are performed successfully. !Screenshot.PNG|thumbnail!  !_Screenshot.PNG|thumbnail! ;;;","15/Aug/17 5:27 PM;danielhardman;What happens when we downgrade? Does the migration script run? What versions does it look for in the name of the migration script (the more advanced version followed by the less advanced version?);;;","15/Aug/17 5:38 PM;andrey.goncharov;It follows the same rule version_you_come_from_to_version_you_upgrade_to. This means that if you downgrade from 1.0.100 to 1.0.90 then a migration script 1_0_100_to_1_0_90 is applied. Yet a reverse one (1_0_90_to_1_0_100) is not.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As part of moving to Hyperledger review and improve the release process,INDY-252,18255,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,stevetolman,krw910,krw910,17/Jun/17 5:24 AM,09/Oct/19 6:13 PM,28/Oct/23 2:46 AM,09/Oct/19 6:13 PM,,,,,0,6Months,should,,,,"The current process of releasing a Stable build once QA has tested it needs to be reviewed.

# Currently once QA has verified the build the QA lead goes into Jenkins and for each component in dependency order approves the build.
# Once QA has approved the component an email is sent to the product team.
# The product team would then go into Jenkins and do the same thing approving each component in dependency order.
# Once product has approved the build an email goes to the TGB group where someone else now runs through the same process. A TGB member goes into Jenkins and approves each component in dependency order.
# Now an email is sent to the Trustees
# A Trustee then goes into the CLI and send the POOL_UPGRADE transaction which is a large transaction that needs to be configured with the correct parameters.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzx11j:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:12 PM;esplinr;We have significantly improved the release process, and have graduated from Hyperledger Incubation.

The current release process is documented here:

https://github.com/hyperledger/indy-node/blob/master/docs/source/ci-cd.md;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Entries are being added to the sovrin_config.py file while running,INDY-253,18283,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,krw910,krw910,19/Jun/17 9:42 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,should,,,," I am not sure where the entries are coming from or at what point they are happening.

In the .sovrin directory on the nodes there is a sovrin_config.py file to override settings like the log level.
The default entry on installation is:
{code}
enableStdOutLogging=False
{code}

After running about 20,000 transactions and adding 3 more nodes to the pool I went to change the log level in the sovrin_config.py file. I noticed that it had added the default line to the config file an addtional 4 times.
{code}
enableStdOutLogging=False

enableStdOutLogging=False
enableStdOutLogging=False
enableStdOutLogging=False
enableStdOutLogging=False
{code}



 ",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1104,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx1lj:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/18 12:41 PM;krw910;[~ozheregelya] Can you see if this is still happening? ;;;","07/Nov/18 4:56 PM;Derashe;Did not reproduced;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[QA] Investigation of send ATTRIB command,INDY-254,18301,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,aleksey-roldugin,aleksey-roldugin,19/Jun/17 6:32 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"Description:
 Adding ATTRIBs: you can pass in anything. What are limitations; boundaries, etc.

Findings:
 * Only _raw_ parameter is supported for now (INDY-71, INDY-128)
 * _Raw_ parameter could have only JSON value, JSON value could have only 1 parameter but with any depth level (level 9 of nested depth tested)
 * If _raw_ parameter contains _endpoint_ parameter, this parameter should be ether null or JSON
 * If _endpoint_ contains _ha_ parameter, this parameter could have only value in format _ip_address:port_ with valid address and port
 * Testing with 1000 parameters inside JSON, parameters and keys with length of 257 symbols, parameters and keys with special characters was not revealed errors
 * Sending ATTRIB transaction is available for Trustee, Steward, Trust Anchor, TGB Member
 * Related issues found: INDY-261, INDY-264",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy25b:",,,,,,H1,H3,,,,,,,,,,,,,,,,,,,aleksey-roldugin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[QA] Send lot of invalid requests,INDY-255,18302,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,ozheregelya,ozheregelya,19/Jun/17 6:52 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"*Description:*
 Send lot of invalid requests (malformed txns, double spend like registering an already registered nym)

*Findings:*
 There is no special handling on malformed or redundant transactions. It was verified in both of points of view: from CLI and using load_test.py
 CLI: sending about 10 transactions with incorrect syntax manually and sending 10 NYMs with the same identifier in dest. The next invalid transaction is handled absolutely the same as the previous one. The system works correctly after these actions.

load_test.py: sending lots of send NYM transactions with incorrect syntax and with the same identifier in dest parameter.
 Interesting behavior was noticed while using load_teat.py
 - If we run script without --at-once key, all works as expected: first transaction succeeded, the rest ones are failed.
 - If we run script with --at-once key with the same parameters there are two different cases:
 -- 2-500 transactions: all transactions are succeeded, cluster is not crashed.
 -- 1000 transactions: about first 100-200 transactions are succeeded, the rest ones are failed. Pool is crashed after completion of the test.



The version of script which was used for testing is attached: [^load_test_inv.py]

*Summary:*
 - All works correctly in point of view CLI. 
 - All works correctly in case of running load_test.py without --at-once key.
 - There are problems in case of running script with --at-once key. They are described in INDY-292.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,INDY-292,,,,,,,,,,,,"21/Jun/17 10:52 PM;ozheregelya;load_test_inv.py;https://jira.hyperledger.org/secure/attachment/11305/load_test_inv.py",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy17z:",,,,,,H2,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jun/17 6:57 PM;ozheregelya;The wording of task is unclear, so I can see following cases to test in this topic:

In point of view CLI:
 * Send several malformed txns manually and check CLI behavior
 * Send several redundant txns manually and check CLI behavior

In point of view stability of the system:
 * Send lots of malformed txns using load_test.py and check that the system was not broken
 * Send lots of redundant txns using load_test.py and check that the system was not broken;;;","21/Jun/17 10:45 PM;ozheregelya;[~krw910], after exploration of this question I think that work on INDY-267 will not make sense until fixing of INDY-292 or adding special handling of malformed or redundant transactions.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make sure Nodes upgrade eagerly,INDY-256,18309,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,dsurnin,dsurnin,19/Jun/17 10:03 PM,11/Oct/19 6:48 PM,28/Oct/23 2:46 AM,11/Oct/19 6:48 PM,,,,,0,6Months,should,,,,"jlaw [7:53 AM] 
*Nodes upgrade eagerly.* When a node is getting caught up, and it processes an upgrade txn, it should schedule it just like it normally would. If the date/time is in the past, then it upgrades immediately. Possibly a new story.",,,,,,,,,,,,,,,,,,,,,,,INDY-201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx1fz:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 6:48 PM;esplinr;Our catch-up protocol expects catch-up to complete before an upgrade transaction would be processed. Trying to resume a partial catch-up after an upgrade would be complicated. We can re-examine this suggestion if we hit a problem where it would help.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
An upgrade should be idempotent,INDY-257,18310,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,dsurnin,dsurnin,19/Jun/17 10:05 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"*An upgrade is idempotent.* A txn to upgrade to version 5 should be allowed even if an earlier upgrade to v.5 has gone through. Given four nodes, if three are at v.5 and one is at v.4, then the one at v.4 will be upgraded. When it comes time for a particular node to upgrade, and it's already at v.5, it doesn't do anything.

lovesh [9:27 AM] 
We partially have ""An upgrade is idempotent"", i say partially since node on upgrade can run an additional script, we need to ensure changes done as part of the script are idempotent, we need a test which before any pool upgrade is sent applies the upgrade twice on each node and verifies the update to be idempotent.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,INDY-201,,,,INDY-250,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8cn:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,andrey.goncharov,dsurnin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Aug/17 8:05 PM;andrey.goncharov;Already implemented in the current code. You can submit an upgrade transaction to any version, it will be committed successfully, yet an upgrade to the same version or lower one won't be scheduled;;;","02/Aug/17 10:22 PM;VladimirWork;Upgrade to the same version is implemented and checked in INDY-250.
Upgrade the pool with some nodes have lesser version than the others also works correctly (e.g. one node is 1.0.69 and other nodes are 1.0.70):
- upgrade to 1.0.70 without reinstall parameter makes only one node to upgrade 1.0.69 -> 1.0.70
- upgrade to 1.0.70 with reinstall parameter makes one node to upgrade 1.0.69 -> 1.0.70 and 1.0.70 -> 1.0.70 for other nodes
- upgrade to not latest version also works (rechecked in case of regression testing after INDY-250 fix);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Ledgers ""stall"" gracefully",INDY-258,18311,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Deferred,dsurnin,dsurnin,dsurnin,19/Jun/17 10:07 PM,29/Oct/19 11:19 PM,28/Oct/23 2:46 AM,29/Oct/19 11:19 PM,,,,,0,6Months,Stability,,,,"*Ledgers ""stall"" gracefully.* When a node is applying ledger txns to state, and runs into a ledger txn that causes an exception during deserialization or validation or processing, then the failure will be handled gracefully. A nice error message outlining the specific issue will be put to the log. That ledger will be set to a ""STALLED"" state. On startup, or on upgrade, or maybe even periodically, the node will reattempt to restart a stalled ledger, that is, process the ledger entry that failed. It will not proceed past the current state, and it will not participate in 3pc on any txns for that ledger. With this stalled concept, we don't need a separate consensus protocol for each ledger.

The combination of *Ledgers ""stall"" gracefully* and *Consensus may not be required* means we can recover from some nasty bugs.",,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,,INDY-201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-785,,,,,,,,,,"1|hzx1nb:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,dsurnin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 4:28 PM;ashcherbakov;[~nage] [~danielhardman]
This story looks not so clear for me. Should it be in M1?;;;","17/Aug/17 2:40 PM;dsurnin;After meeting with Daniel it was decided to move the issue to backlog.

All the urgent cases are covered by catchup, force upgrade, downgrade and reupgrade.

 

Also we discussed the case of slow ledger and possibility of transformation of new ""stall"" state into automatic readonly state.

All these cases are not important for now.

 

All the cases that probably requires the ""stall"" state should be added as comment to this issue and team discussed

 

CC
[~danielhardman] [~nage] [~ashcherbakov];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
We need to support downgrades,INDY-259,18312,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,dsurnin,dsurnin,19/Jun/17 10:08 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"jlaw [9:52 AM] 
We need to support downgrades. Til now, I've been assuming a downgrade is just another upgrade, but that's probably not good enough. Open to your thoughts.",,,,,,,,,,,,,,,,,,,,,,INDY-251,INDY-201,INDY-251,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0rb:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,dsurnin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Aug/17 6:36 PM;andrey.goncharov;Marked as invalid since it's basically a duplicate of 251;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Testing: do a lot of concurrent writes and reads to same values,INDY-260,18317,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,spivachuk,spivachuk,19/Jun/17 10:59 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"*Description*
Test the following scenario:
* Do a lot of concurrent writes and reads to same values (like change verkey from different clients and read in parallel).

Write test scripts for performing this scenario.

*Findings*
Found the following bugs using the tests written in scope of this ticket: INDY-354, INDY-355.
",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy25j:",,,,,,H1,H2,H3,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 10:56 PM;spivachuk;Wrote a test of cyclic updating own verkeys by some users and cyclic reading them by other users in parallel.
Wrote a test of cyclic updating and reading own verkeys by multiple users in parallel.

The changes can be found in the following pull requests merged to master branch:
* https://github.com/sovrin-foundation/sovrin-client/pull/237
* https://github.com/sovrin-foundation/sovrin-client/pull/239
* https://github.com/sovrin-foundation/sovrin-client/pull/241;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validation error for send NYM command has poorly readable text,INDY-261,18322,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,aleksey-roldugin,aleksey-roldugin,19/Jun/17 11:18 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,Could,quality,,,"h6. BUILD

sovrin-node 0.3.140
sovrin-client 0.3.143


h6. STEPS TO REPRODUCE

Send from CLI:
{code:java}
sovrin@test> send NYM dest=gEAGFA6DCD05caBG
Adding nym gEAGFA6DCD05caBG
Error: client request invalid: InvalidClientRequest(""validation error: should not contains chars other than {'a', 'v', 'c', 'y', 'Y', 'i', 'P', 'U', 'F', 'N', '2', 'B', '1', 'R', 'h', 'T', '3', 'f', 'V', '5', 'b', 'o', 'E', 'q', 'M', '4', 'G', 'J', 'e', 'S', 'A', 'm', 'x', 'Z', 'W', 'z', 'Q', 'u', 'd', 'r', 'H', 's', 'X', '6', 'w', '9', 'p', 'g', 'j', '7', 'D', 't', 'C', 'K', '8', 'n', 'L', 'k'} (dest=gEAGFA6DCD05caBG)"",)
{code}

h6. ACTUAL RESULT
Finding particular letter in current validation message is hard for user. 

h6. EXPECTED RESULT
Validation error should tell that 'dest' should correspond to Base58 encoding. At list symbols in current message should be in alphabetical order.

h6. Additional Information:
Are there some unit tests covering cases below?
* any letter not supported in Base58 causes validation error
* all letters that are supported in Base58 do not cause validation errors",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy0y7:",,,,,,,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jun/17 11:18 PM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","05/Dec/17 9:03 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Adding more than f nodes to the pool at a time causes the pool to stop reaching consensus,INDY-262,18336,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,krw910,krw910,20/Jun/17 2:28 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,6Months,Could,,,,"I found this by adding 9 new nodes to a pool of 10.
Basically you cannot add more than f new nodes to a pool at a time. 

The reason is because currently as soon as a new node transaction has occurred the pool counts that node toward consensus.

When a node is catching up it is counted as a failed node and cannot participate in consensus. 

For example: You have a pool of 10 nodes so your f value is 3. If you add 4 new nodes that are 
all trying to catch up you are below the allowed f value so the pool cannot reach consensus.

-- The likelihood of this happening is low, but I am marking the issue as a high since it can bring down the pool. The only way out since you cannot come to consensus to demote a node is to copy the transaction files to enough nodes that brings them in sync so consensus can be reached.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzwyq7:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Sep/17 6:27 AM;krw910;We need a way to to know the new nodes have been verified ready to participate before counting them in the consensus formula.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need early validation of genesis transactions,INDY-263,18337,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,,danielhardman,danielhardman,20/Jun/17 2:52 AM,13/Nov/19 12:31 AM,28/Oct/23 2:46 AM,13/Nov/19 12:31 AM,,,,,0,6Months,should,,,,"INDY-219 showed that we could have an invalid genesis transactions file (in that case, one that used the symbolic identifier ""TRUSTEE"" instead of its numeric equivalent, 0) and not notice for a while.

I want it to be the case that an invalid genesis transactions file causes an immediate failure with a clear error message that identifies the problematic line. We may have already done this as part of our input validation effort; if not, we need to add additional logic.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzwyzj:",,,,,,,,,,,,,,3.0,,,,,,,,,,,,danielhardman,esplinr,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/17 1:39 AM;spivachuk;*PoA*

We see the following 3 options for validation of genesis transactions.

*1. Perform only static validation of genesis transactions using {{SafeRequests}} construction and invoke this validation from {{GenesisTxnInitiatorFromFile}}. {{SafeRequest}} will be created from a transaction dict (read from a genesis transactions file) transformed into a request dict using {{plenum.common.txn_util.txnToReq}} function. {{SafeRequest.__ init __}} performs static validation of the content being passed to it using {{FiledValidator}} class hierarchy.*

Static validation detects such unintentional errors as wrong or missed fields or wrong types of filed values. However, it does not detect authority or permission errors.


*2. Move adding of genesis transactions to {{Node}} level and use {{Node.applyReq}} method to add each genesis transaction (this will include transformation of transactions to requests in the way described in Option 1). Perform both static and dynamic validation of genesis transactions using {{SafeRequests}} construction and {{Node.doStaticValidation}} and {{Node.doDynamicValidation}} methods.*

Dynamic validation requires each genesis transaction to be completely processed in the usual way in order for it to be checked in everywhere before next transactions are validated. This is so because dynamic validation relies on previously processed transactions. Thus use of {{Node.applyReq}} method for adding genesis transactions one by one may be insufficient for dynamic validation to be performed properly. So this option seems to be risky. Eventually it may require additional actions besides {{Node.applyReq}} for processing genesis transactions and that in turn may lead to undesirable logic duplication in handling genesis and ordinary transactions.


*3. Move adding of genesis transactions to {{Node}} level and use {{Node.handleOneClientMsg}} method for this, i.e. emulate sending of client requests containing the genesis transactions to the node (this will include transformation of transactions to requests in the way described in Option 1) and introduce a special mode of node functioning for processing genesis transactions that will remove some constraints (e.g. the constraint requiring that identifier field is mandatory because genesis transactions may not have it).*

This option seems to be safer for dynamic validation than Option 2 because this option processes genesis transactions in the same way (mostly) as ordinary transactions. However, it requires consensus with other nodes to add genesis transactions to the ledgers.

--
Option 1 is the least time-consuming one. If the goal of genesis transactions validation is protection against human mistakes but not against malicious actions then Option 1 looks the most preferable.
;;;","13/Nov/19 12:31 AM;esplinr;This would be useful validation, but it doesn't change the behavior of the network as it is currently used. So we will not be prioritizing this work in the near future.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"[send ATTRIB] Validation error is unclear in case ""endpoint"" has not JSON value",INDY-264,18338,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,alexander.shekhovcov,aleksey-roldugin,aleksey-roldugin,20/Jun/17 3:11 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,should,,,,"h6. BUILD

sovrin-node 0.3.140
 sovrin-client 0.3.143
h6. STEPS TO REPRODUCE
 # Check help for send ATTRIB command:
{code:java}
sovrin@test> help send ATTRIB

send ATTRIB
-----------
     title: Adds attributes to existing identifier

     usage: send ATTRIB dest=<target identifier> [raw={<json-data>}] [hash=<hashed-data>] [enc: <encrypted-data>]

     example(s):
        send ATTRIB dest=33A18XMqWqTzDpLHXLR5nT raw={""endpoint"": ""127.0.0.1:5555""}
{code}

 # Send example command provided in help with valid dest:
{code:java}
sovrin@test> send ATTRIB dest=gEAGFA6DCD15caBG raw={""endpoint"":""127.0.0.1:5555""}
Adding attributes {""endpoint"":""127.0.0.1:5555""} for gEAGFA6DCD15caBG
Error: client request invalid: InvalidClientRequest() [caused by 'str' object has no attribute 'get']
{code}

h6. ACTUAL RESULT

Error could be unclear.
h6. EXPECTED RESULT

Error should tell that ""endpoint"" parameter could have only JSON value.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy0uv:",,,,,,,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/17 7:30 PM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","05/Dec/17 8:52 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Loading sovrin-node.service takes 10 minutes with 60,000 transactions on the ledger",INDY-265,18343,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,20/Jun/17 4:17 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"It takes a long time to load the sovrin-node.service the larger the ledger becomes. At 60,000 transactions it took over 10 minutes to load the service.

I had to restart my pool of 10 nodes and the debug output in the log showed I was at the following command for 8 minutes.

I have attached a screenshot from glances to show what the CPU and Memory looks like while loading.

{code}
2017-06-19 00:48:23,511 | INFO     | log.py               (  79) | setupRaet | Setting RAET log level 2
2017-06-19 00:48:23,521 | DEBUG    | start_sovrin_node    (  39) | <module> | You can find logs in /home/sovrin/.sovrin/Node1.log
2017-06-19 00:48:23,521 | DEBUG    | start_sovrin_node    (  42) | <module> | Sovrin related env vars: []
2017-06-19 00:48:24,638 | DEBUG    | __init__.py          (  59) | register | Registered VCS backend: git
2017-06-19 00:48:24,688 | DEBUG    | __init__.py          (  59) | register | Registered VCS backend: hg
2017-06-19 00:48:24,743 | DEBUG    | __init__.py          (  59) | register | Registered VCS backend: svn
2017-06-19 00:48:24,744 | DEBUG    | __init__.py          (  59) | register | Registered VCS backend: bzr
2017-06-19 00:48:25,311 | DEBUG    | selector_events.py   (  53) | __init__ | Using selector: EpollSelector
2017-06-19 00:48:25,312 | DEBUG    | looper.py            ( 123) | __init__ | Setting handler for SIGINT
2017-06-19 00:48:25,475 | DEBUG    | ledger.py            ( 203) | start | Starting ledger...
2017-06-19 00:48:25,477 | DEBUG    | file_store.py        ( 176) | appendNewLineIfReq | new line check for file: /home/sovrin/.sovrin/data/nodes/Node1/transactions_sandbox/54001
2017-06-19 00:48:25,477 | DEBUG    | file_store.py        ( 185) | appendNewLineIfReq | new line added for file: /home/sovrin/.sovrin/data/nodes/Node1/transactions_sandbox/54001
2017-06-19 00:48:25,477 | DEBUG    | ledger.py            (  96) | recoverTree | Recovering tree from transaction log
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/17 4:17 AM;krw910;Loading Service.JPG;https://jira.hyperledger.org/secure/attachment/11204/Loading+Service.JPG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1t3:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,krw910,lovesh,n-horiguchi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/17 2:44 AM;krw910;I restarted the service on a pool with 128,000 transactions and it takes 57 minutes to start up.;;;","23/Jun/17 6:57 AM;krw910;This looks like it is the same thing as INDY-137;;;","30/Jun/17 5:16 PM;lovesh;[~krw910] No, INDY-137 will only manifest of you delete the state database. Reason for this behavior is that we construct the entire HashStore (a data store used for storing Merkle Tree nodes) on startup, disregarding the existent HashStore data. We do this for the lack of a good integrity check mechanism. I think we need to create a general integrity check mechanism for all our data stores  ;;;","12/Jul/17 6:40 PM;lovesh;PR https://github.com/hyperledger/indy-plenum/pull/271
;;;","13/Jul/17 5:26 AM;krw910;Blocked by INDY-406;;;","13/Jul/17 4:12 PM;krw910;To test:

you don't need to delete the state database, just start the node with a big ledger and it should not take too much time, a good check would be to see that starting a node with 1K txns and 60K txns should take about the same time;;;","18/Jul/17 12:50 PM;krw910;Blocked by INDY-246. I need to be able to get up to 60,000 plus transactions in order to test this.;;;","23/Jul/17 7:28 AM;krw910;With 81,157 transactions it only took 5 seconds to load.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Get the primary node to change to a lagged or dead node in succession,INDY-266,18348,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:02 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"Primary changing to a very lagged node, or a dead node or dead nodes in succession.:

*Things tried:*
Case 1: view change during high load of CPU.
 When the primary node is overloaded, but there is no activity in the pool, view change does not happen. View change happens only when the pool processes some transactions.
 When view change happens and there are not overloaded nodes, one of them will be selected as new primary.
 If all nodes of the pool are overloaded, primary node is selected as usual.

Case 2: view change when some nodes have load by TCP protocol.
 Load by TCP protocol affects performance of the pool less than CPU load, but results are the same as for CPU load.

Case 3: primary changing to a dead node.
 Primary changing to a dead node is impossible by design. This case was additionally tested and changing primary to a dead node is impossible in current implementation.

*Findings:*
 The main thing which was noticed during exploration of this question is that node with average performance (which accords to performance of main part of nodes) will be preferable than the node with the best performance (e.g. when all nodes are slow, the only fast node will not be selected as primary).

*Additional Information:*
 Despite on this research, the logic of primary selection (and especially performance estimation) is still unclear. Probably it make sense to perform so,e research of performance estimation and check that it works correctly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0h3:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
submit same txn over and over (same txn): How do we handle redundant txns?	,INDY-267,18349,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:07 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"submit same txn over and over (same txn): How do we handle redundant txns?	


Things tried:


Findings:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0fr:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jan/18 3:42 AM;krw910;The pool is designed to allow you to enter the same transaction over and over. This is not an issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a NYM with lots reads then modify the NYM and do additional reads.,INDY-268,18350,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:08 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"adjust tests: 
plenum tests operate with a representative group of sovrin txns: 
current txns are NYMS. 

real life is create a NYM with a lot of reads, then modify the NYM, more reads etc.	


Things tried:


Findings:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0hb:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Mar/18 10:24 PM;zhigunenko.dsr;*Environment:*
indy-node 1.3.324
indy-plenum 1.2.259
libindy 1.3.1~406

Docker, 4 nodes

*Case1*
*Steps to reproduce:*
1. read NYM (400k+ times, single thread)
2. rotate key for NYM
3. read NYM (380k+ times, 15 threads)

*Actual results:*
All NYM readings are successful

*Case2*
*Steps to reproduce:*
1. read NYM in cycle
2. rotate key for NYM

*Actual results:*
Reader catch new verkey on ~1 sec

*Case3*
*Steps to reproduce:*
1. read NYM in cycle
2. add expected key

*Actual results:*
Reader catch expected key on ~1 sec;;;","09/Mar/18 1:14 AM;krw910;[~zhigunenko.dsr] Great work.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade: View change: change during upgrade	,INDY-269,18351,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:10 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,Cause a view change during an upgrade process. This should happen when the primary node goes down to upgrade.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0e7:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jul/17 6:27 PM;VladimirWork;Things tried and findings:

View change for both instances (0 and 1) works well during:
- Upgrade with force=True/force=False
- Upgrade with various sequences of nodes in schedule and time intervals between upgrades
- Upgrade with some manually restarted nodes during upgrade time
- ""Upgrade loop"" caused by incorrect version to upgrade;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
How do we handling encoding with ATTRIBs,INDY-270,18352,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,20/Jun/17 7:10 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"Adding ATTRIBs: how do we deal with encoding, especially with ATTRIBs

Things tried:
 * Sending different Unicode symbols as value of _raw_ parameter (ex. sovrin@test> send ATTRIB dest=v8HcafSBNPoJvRs3ZSXT8 raw= \{""test"":""©""}). Some times logs related to command were absent in Node<number>.log file on the nodes but it's not reproduced on latest tested build (sovrin-node 0.3.159, sovrin-client 0.3.143)
 * Running sovrin-client with not default (en_US.UTF-8) encoding and sending different Unicode symbols as value of _raw_ parameter.

Findings:
 INDY-328",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy25r:",,,,,,H3,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
How does the pool handle when a node runs out of resources.,INDY-271,18354,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,20/Jun/17 7:12 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"Intermittent issues where nodes run out of resources (memory, disk space and other resources)	",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,INDY-393,INDY-394,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8cv:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jul/17 11:56 PM;VladimirWork;Things tried:
- RAM/procssor cores/disk space limitations for one/several/all nodes in pool and for client
- Send and get NYM commands execution on pool with limitations

Findings:
- Node can't start if there is less than ~100MB RAM for it (so we need at least ~400 MB RAM and 1 processor for the machine with Ubuntu 16 and Docker to start 4 nodes pool)
- Node doesn't send/handle any messages to/from other nodes if it runs out of RAM/free disk space/processor time (there are only warnings about waiting for tasks execution in node log) so that node counts as switched off
- CLI can't connect to nodes that run out of RAM/free disk space/processor time
- There are CLI incorrect behavior and some minor problems with error handling during work with lack of resources (INDY-393, INDY-394);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
F-value tests: How many nodes can I lose before the network stops? Is it 2f+1? Is it n-f?	,INDY-272,18355,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:13 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"F-value tests: How many nodes can I lose before the network stops? Is it 2f+1? Is it n-f?	


Things tried:


Findings:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0en:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jan/18 3:54 AM;krw910;We drop below consensus at 2f. So 3f+1 with 10 nodes means we can tolerate 3 failures keeping 7 nodes functioning. At 2f we only have 6 nodes functioning putting us below the consensus protocol.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
F-value tests: How do we get the pool functioning again if node count is decreased below consensus.,INDY-273,18356,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ozheregelya,krw910,krw910,20/Jun/17 7:14 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"F-value tests: What if our network node count decreased below n-f, how do we get the consensus pool functioning again?	",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0ev:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/18 12:43 PM;krw910;[~ozheregelya] I think this was covered in test we ran last year. Can you put your findings into this ticket and mark it done?;;;","27/Aug/18 8:39 PM;ozheregelya;There are several cases:

Case 1: Less than F+1 nodes alive.
To get pool functioning after this we need to get stopped nodes functioning again, and start them simultaneously. Alive nodes will be restarted automatically (see INDY-1199). Or as an option, nodes which were not working may be started at any time, but when at least N-F nodes will be started, Trustee should register pool_restart using indy-cli.

Case 2: More than or equal F+1 node alive.
To get pool functioning after this we need to get stopped nodes functioning again, and start them at any time. Nodes which were not working will restore state from alive ones. Pool will start as soon as at least N-F nodes will work.

Case 3: More than F nodes were broken (lagged behind others and can't catch up) because of problems during View Change.
To get pool functioning after this stewards of broken nodes should perform following steps:
1. Run _sudo systemctl stop indy-node && sudo systemctl stop indy-node-control_
2. Run _sudo rm -r /var/lib/indy/<network>/data/* && sudo rm -r /var/log/indy/<network>/*_
3. Get _/var/lib/indy/<network>/_data from one of working nodes.
4. Put it to the according folder of his node and rename _data/<alive_node_name>_ to _data/<steward's_node_name>_
5. Remove file _data/<steward's_node_name>node_info_
6. Start the indy-node.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
F-value tests: Can we still read from the ledger if there are faulty nodes more than n-f	,INDY-274,18357,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:15 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"F-value tests: Can we still read from the ledger if there are faulty nodes more than n-f	


Things tried:


Findings:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0f3:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jan/18 3:50 AM;krw910;We handle reads at the expected f+1 value. We also introduced State Proofs where a client only needs to access one node.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
 How can a node deal with general incorrect state in messages,INDY-275,18358,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:15 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"How a node deals with incorrect 3pc messages: How can a node deal with general incorrect state in messages

*Things tried:*

*Case 1:*
*Steps to reproduce:*
1. Put erroneous pool_transaction_genesis on forthcoming node
2. Add node to pool
*Expected results:*
Node is demoted
*Actual results:*
Node is demoted

*Case 2:*
*Steps to reproduce:*
1. Put erroneous domain_transaction_genesis on forthcoming node
2. Add node to pool
*Expected results:*
Node is demoted
*Actual results:*
Node is demoted

*Case 3:*
*Steps to reproduce:*
1. Add nyms to one of existed nodes via add_json_txns_to_ledger.py
2. Add nym via CLI
*Expected results:*
Node is demoted
*Actual results:*
Node is demoted

*Findings:*
There is no influence from node with incorrect state to pool",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0hj:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
What happens when state trie is corrupted: Can we get back to valid state?	,INDY-276,18359,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,krw910,krw910,20/Jun/17 7:16 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"What happens when state trie is corrupted: Can we get back to valid state?	


Things tried:


Findings:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0hr:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,lovesh,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/17 10:07 PM;lovesh;[~krw910] It cannot get back to original state, but if you delete the state database and restart the node, the state database will be correctly populated;;;","27/Aug/18 8:53 PM;ozheregelya;Actual behavior is exactly the same as Lovesh said. It was tested and described as part of case 3 from INDY-273:
{quote}
To get pool functioning after this stewards of broken nodes should perform following steps:
1. Run _sudo systemctl stop indy-node && sudo systemctl stop indy-node-control_
2. Run _sudo rm -r /var/lib/indy/<network>/data/* && sudo rm -r /var/log/indy/<network>/*_
3. Get _/var/lib/indy/<network>/_data from one of working nodes.
4. Put it to the according folder of his node and rename _data/<alive_node_name>_ to _data/<steward's_node_name>_
5. Remove file _data/<steward's_node_name>node_info_
6. Start the indy-node.
{quote}
If there are enough nodes for catch up, steward can start node after step 2 and node will complete catch up.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
How do we deal with a hard fork,INDY-277,18360,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Duplicate,,krw910,krw910,20/Jun/17 7:17 AM,08/Oct/19 9:01 PM,28/Oct/23 2:46 AM,08/Oct/19 9:01 PM,,,,,0,explore,,,,,"Hard fork: extremely problematic items put on ledger forcing governance to deal with the problem - erase it, skip it, etc.	


Things tried:


Findings:",,,,,,,,,,,,,,,,,,,,,,INDY-2082,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0jj:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Oct/19 9:01 PM;esplinr;Our discussions on this topic led us to investigate Node Specific Tombstones, but we concluded not to implement anything now. (INDY-2082);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Test during load: test during an increasing load; watch catch ups	",INDY-278,18361,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:17 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"Test during load: test during an increasing load; watch catch ups	",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0jr:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Aug/17 7:59 PM;VladimirWork;Things tried:
Start and stop nodes and during load scripts run on one/several nodes (with various number of clients and transactions) to check catchups.

Findings:
INDY-475;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade: submit another upgrade when some nodes have already upgraded and some of them have not,INDY-279,18362,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:24 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"Upgrade: submit another upgrade when some nodes have already upgraded and some of them have not
h6.  Things tried
 * Schedule upgrade to existent version, wait until 2 nodes did upgrade, schedule upgrade to nonexistent version on time greater than time of the 1st scheduled upgrade => upgrade loop after 2nd upgrade ([INDY-316|https://jira.hyperledger.org/browse/INDY-316]).
{code:java}
sovrin@test> send POOL_UPGRADE name=update_to_node_160 version=0.3.160 sha256=aad1143 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv':'2017-06-24T15:15:00.2
58870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb':'2017-06-24T15:20:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-24T16:25:00.258870+00:00'
,'4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-24T16:30:00.258870+00:00',} timeout=10
Sending pool upgrade update_to_node_160 for version 0.3.160
Pool upgrade successful{code}
{code:java}
 sovrin@test> send POOL_UPGRADE name=update_to_node_161 version=0.3.161 sha256=aad1143 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv':'2017-06-24T17:15:00.2 58870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb':'2017-06-24T17:20:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-24T17:25:00.258870+00:00' ,'4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-24T17:30:00.258870+00:00',} timeout=10 Sending pool upgrade update_to_node_161 for version 0.3.161 Pool upgrade successful 8Jk2v4GEoUhrH5GkiyeFh5zK8GnDJR4mW11qVfsRzKmQ disconnected from Node1C 8Jk2v4GEoUhrH5GkiyeFh5zK8GnDJR4mW11qVfsRzKmQ now connected to Node1C 8Jk2v4GEoUhrH5GkiyeFh5zK8GnDJR4mW11qVfsRzKmQ disconnected from Node1C 8Jk2v4GEoUhrH5GkiyeFh5zK8GnDJR4mW11qVfsRzKmQ now connected to Node1C 8Jk2v4GEoUhrH5GkiyeFh5zK8GnDJR4mW11qVfsRzKmQ disconnected from Node1C 8Jk2v4GEoUhrH5GkiyeFh5zK8GnDJR4mW11qVfsRzKmQ now connected to Node1C 8Jk2v4GEoUhrH5GkiyeFh5zK8GnDJR4mW11qVfsRzKmQ disconnected from Node1C{code}
 

 * Schedule upgrade to existent version, immediately schedule upgrade to same version and same time but with another name => successful upgrade (I didn't determine which scheduled upgrade, 1st or 2nd, caused it)
  
{code:java}
sovrin@test> send POOL_UPGRADE name=update_to_node_160 version=0.3.160 sha256=aad1443 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv':'2017-06-
25T20:25:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb':'2017-06-30T20:30:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06
-25T20:35:00.258870+00:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-25T20:40:00.258870+00:00',} timeout=10
Sending pool upgrade update_to_node_160 for version 0.3.160
Pool upgrade successful{code}
{code:java}
sovrin@test> send POOL_UPGRADE name=update_to_node_160_1 version=0.3.160 sha256=aad1443 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv':'2017-0
6-25T20:25:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb':'2017-06-30T20:30:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-
06-25T20:35:00.258870+00:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-25T20:40:00.258870+00:00',} timeout=10
Sending pool upgrade update_to_node_160_1 for version 0.3.160
Pool upgrade successful
{code}

 * Schedule upgrade to existent version, wait until 2 nodes did upgrade, schedule upgrade to same version but on time greater than time of the 1st scheduled upgrade and with another name => successful upgrade after 1st scheduled upgrade, 2nd upgrade didn't lead to upgrade.
{code:java}
sovrin@test> send POOL_UPGRADE name=update_to_node_161 version=0.3.161 sha256=aad1443 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv':'2017-06-26T11:40:00.2
58870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb':'2017-06-26T11:45:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-26T12:00:00.258870+00:00'
,'4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-26T12:10:00.258870+00:00',} timeout=10
Sending pool upgrade update_to_node_161 for version 0.3.161
Pool upgrade successful
3iERzawXTAvW8wJvsKfSNxnwnuKYwxHcWgxyZLV7eUf4 disconnected from Node1C
3iERzawXTAvW8wJvsKfSNxnwnuKYwxHcWgxyZLV7eUf4 now connected to Node1C
3iERzawXTAvW8wJvsKfSNxnwnuKYwxHcWgxyZLV7eUf4 disconnected from Node2C
3iERzawXTAvW8wJvsKfSNxnwnuKYwxHcWgxyZLV7eUf4 now connected to Node2C{code}
{code:java}
sovrin@test> send POOL_UPGRADE name=update_to_node_161_1 version=0.3.161 sha256=aad1443 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv':'2017-06-26T12:10:00
.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb':'2017-06-26T12:15:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-26T12:20:00.258870+00:0
0','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-26T12:25:00.258870+00:00',} timeout=10
Sending pool upgrade update_to_node_161_1 for version 0.3.161
Pool upgrade successful
3iERzawXTAvW8wJvsKfSNxnwnuKYwxHcWgxyZLV7eUf4 disconnected from Node3C
3iERzawXTAvW8wJvsKfSNxnwnuKYwxHcWgxyZLV7eUf4 now connected to Node3C
3iERzawXTAvW8wJvsKfSNxnwnuKYwxHcWgxyZLV7eUf4 disconnected from Node4C
3iERzawXTAvW8wJvsKfSNxnwnuKYwxHcWgxyZLV7eUf4 now connected to Node4C
{code}

h6. Summary
 Scheduling 2nd upgrade to the same existing version does not leave to problems. Probably node discarding 2nd upgrade but there is no information about it in logs.",,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy25z:",,,,,,H3,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Upgrade: submit pool upgrade when one node is scheduled to upgrade in a huge period of time, like a week",INDY-280,18363,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,20/Jun/17 7:25 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"Upgrade: submit pool upgrade when one node is scheduled to upgrade in a huge period of time, like a week

*Things tried:*

Case 1: 
 Send two pool upgrade commands in a huge period of time for whole pool.

Case 2: 
 Upgrade one node using force=True parameter, and than send upgrade command for whole pool.
 1. Upgrade Node 2 using force option (schedule upgrade of Node 2 to 2017-07-25, 10:30)
{code:java}
sovrin@test> send POOL_UPGRADE name=upgrade-oz2 version=0.4.7 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 
action=start schedule={'8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-07-25T10:30:00.000000+00:00'} timeout=10 force=True{code}
2. Upgrade whole pool (upgrade should be scheduled to today, 2017-07-03. Upgrade of Node 2 should be scheduled to 10:10)
{code:java}
send POOL_UPGRADE name=upgrade-oz3 version=0.4.7 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-07-03T10:05:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-07-03T10:10:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-07-03T10:15:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-07-03T10:20:00.000000+00:00'} timeout=10{code}
  

*Findings:*

Case 1: 
 Similar situation as described in INDY-231. Pool was upgraded not in scheduled dates.

Case 2: 
 The behavior is incorrect. When the upgrade is scheduled twice, node was upgraded not on schedule. 

*Summary:* 
For both of cases behavior is incorrect. When the upgrade is scheduled twice, it happened not on schedule. This problem was described in INDY-382. It was moved to separated ticket because case described in INDY-231 is unclear (in INDY-231 not scheduled upgrade was happened after one POOL_UPGRADE command).",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,INDY-382,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8d3:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/17 11:35 PM;krw910;This was completed in another sprint, but had not been moved.;;;","27/Jul/17 11:36 PM;krw910;This was completed in another sprint, but had not been moved.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade: try pool upgrade when system's clock is tweaked,INDY-281,18364,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:25 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"Upgrade: try pool upgrade when system's clock is tweaked

*Things tried:* 

+Case 1:+ system's clock is tweaked on the client machine. 
 1. Set system time to the past. 
 2. Send POOL_UPGRADE later than new system time, but earlier than current time at the node.
 Result: Validation of schedule does not depend on system's clock on client machine. Upgrade has failed because of invalid schedule:
{code:java}
sovrin@sovrin-VirtualBox:~/.sovrin$ sudo date -s ""08/2/2017 12:19""
sovrin@test> send POOL_UPGRADE name=upgrade-3 version=1.0.72 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 ac
tion=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-03T08:45:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-08-03T08:50:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-08-03T08:55:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-08-03T09:00:00.000000+00:00'} timeout=10
Sending pool upgrade upgrade-3 for version 1.0.72
Pool upgrade failed: client request invalid: InvalidClientRequest(""{'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-08-03T08:55:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-08-03T08:50:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-08-03T09:00:00.000000+00:00', 'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-03T08:45:00.000000+00:00'} not a valid schedule since 2017-08-03 08:55:00+00:00 is less than current time"",){code}
+Case 2:+ system's clock is tweaked on one of the nodes. 

+Case 3:+ system's clock is tweaked on several nodes.

+Case 4:+ change system date/time when the upgrade is already scheduled.

*Findings:*

Case 2, 3 and 4 don't make sense. 
In Case 2 and Case 3 nothing happened after sending of POOL_UPGRADE transaction. But the problem is not in POOL_UPGRADE. Pool breaks after changing of system time on at least one node. 
In Case 4 POOL_UPGRADE was send successfully, upgrade was happened in accordance with new system time.",,,,,,,,,,,,,,,,,,,,,,,INDY-711,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0dr:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 6:22 PM;ozheregelya;[~krw910], as result of this exploration I created INDY-711 (Pool is broken after changing of system time on 1 - 3 nodes, but it works if time is changed only on node 4). In my opinion it make sense to retest this ticket after resolving of INDY-711.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade: Upgrade with demoted nodes. Can you send the transaction without listing the demoted nodes?,INDY-282,18365,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,20/Jun/17 7:26 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"Upgrade: Upgrade with demoted nodes. Can you send the transaction without listing the demoted nodes?

*Things tried:*

Case 1: Demote any node, send POOL_UPGRADE for whole pool.
 Case 2: Demote any node, send POOL_UPGRADE only for not demoted nodes (do not specify demoted nodes, use force=True parameter).

*Findings:*

Case 1: Demoted nodes are scheduled to upgrade after promotion.
 Case 2: Only specified nodes are scheduled to upgrade.

*Summary:*

Upgrade without listing the demoted nodes works as expected. No problems were found.",,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8db:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/17 11:35 PM;krw910;This was completed in another sprint, but had not been moved.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade: Upgrade the pool with demoted nodes. Promote those nodes back into the pool and submit the upgrade again.,INDY-283,18366,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:26 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"Upgrade: Upgrade the pool with demoted nodes. Promote those nodes back into the pool and submit the upgrade again.

*Things tried:* 

Case 1:
 1. Demote any node.
 2. Send POOL_UPGRADE.
 3. Promote demoted node.
 4. Check upgrade_log and process of upgrade on demoted node.

Result:
 Demoted node will be upgraded in specified time (or it will be upgraded right after promotion if upgrade time is in the past).

Case 2:
 1. Demote any node.
 2. Send POOL_UPGRADE.
 3. Promote demoted node.
 4. Send one more POOL_UPGRADE.
 5. Check upgrade_log and process of upgrade on demoted node.

Result:
 Demoted node will be upgraded in nearest of specified time (or it will be upgraded right after promotion if one of upgrade time is in the past).

*Findings:*
 Upgrade of demoted node works same way as for not demoted ones. But upgrade and upgrade scheduling looks little strange. It was discussed with developers, INDY-451 was created.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0dz:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Aug/17 7:20 PM;ozheregelya;Necessary ticket was created, so this one may be moved in 'to test'.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"How does pool deal with GBs of txns; huge ledgers?: ",INDY-284,18367,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:27 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,explore,,,,,"How does pool deal with GBs of txns; huge ledgers?: 

Things tried on pools with 200..500 MB ledgers:

- manual sending/getting NYMs/ATTRIBs
- pool upgrades with force/reinstall
- consensus and catchup checks after nodes restarting
- load tests run

Findings:

- running time of load tests with all types of txns grows up to 5..15% as compared with empty ledger test run (expected behaviour)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0fb:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Performance: Does performance degrade over time ,INDY-285,18368,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,20/Jun/17 7:28 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"test performance degrades over time - the amount of time to process 100 txns goes up over time: 


Things tried:


Findings:
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzy0jz:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jan/18 3:59 AM;krw910;Performance degrades over time as well as with the size of the pool and ledger. New story tickets have been created to handle these issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stability: Reading bad data out of the ledger,INDY-286,18369,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,krw910,krw910,20/Jun/17 7:29 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,In creating a ledger and reading it in we add in bad data to see how it is read out: ,,,,,,,,,,,,,,,,,,,,,,,INDY-356,,,,INDY-1099,INDY-1100,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzytx3:",,,,,,Exploratory Tests,Sprint 18.02 Stability,,,,,,,3.0,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/18 12:43 PM;krw910;[~ozheregelya] Can you find a way to test this scenario?;;;","23/Jan/18 12:37 AM;VladimirWork;Things found:

- transaction files are recreated from tree/state files and *vice versa* (but in some cases of this recreation cases pool gets broken)
- ledger can contain bad data (some txns' fields are deleted and it cause to some ledger entries loss) and works normally (commands like NYMs adding/getting work well)

Some unclear issues were discussed today and separate tickets were reported and linked to this ticket.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Command doesn't work,INDY-287,18414,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,20/Jun/17 5:16 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"Build Info:
sovrin-node 0.3.132 (Shakedown pool 3)

Overview:
Command doesn't work and breaks execution of following send NYM commands.

Preconditions:
Pool with not latest version.

Steps to Reproduce:
0. [Reproduce on Shakedown pool 3 only.]
1. Send POOL_UPGRADE command with valid parameters.
2. Send NYM command with valid paramteters.

Actual Results:
There is no success/error message for send POOL_UPGRADE.
There is no success/error message for send NYM.

Expected Results:
Both commands should work correctly.

Workaround:
Send NYM command start working after restarting all nodes (but send POOL_UPGRADE don't).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/17 5:19 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11210/Screenshot.PNG","20/Jun/17 5:13 PM;VladimirWork;first_POOL_UPGRADE_sending.txt;https://jira.hyperledger.org/secure/attachment/11209/first_POOL_UPGRADE_sending.txt","20/Jun/17 5:13 PM;VladimirWork;second_POOL_UPGRADE_sending.txt;https://jira.hyperledger.org/secure/attachment/11208/second_POOL_UPGRADE_sending.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0nj:",,,,,,,,,,,,,,,,,,,,,,,,,,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/17 5:17 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","29/Jun/17 6:38 AM;stevetolman;Please try to reproduce again with a newer build.;;;","03/Jul/17 6:33 PM;VladimirWork;Bug doesn't reproduce on Shakedown pool 3 with upgrade to newest master version (0.4.7).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Incorrect error message,INDY-288,18416,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,20/Jun/17 7:07 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,should,,,,,"Build Info:
sovrin-node 0.3.22

Overview:
Incorrect error message due to unsuccessful pool upgrade.

Preconditions:
Pool with not latest version.

Steps to Reproduce:
1. Send POOL_UPGRADE command with NOT latest or absent version parameter.

Actual Results:
2017-06-20 09:30:00,076 | INFO     | upgrader.py          ( 143) | processLedger | Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv processing config ledger for any upgrades
2017-06-20 09:30:00,077 | INFO     | upgrader.py          ( 170) | processLedger | Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv found upgrade for version 0.3.140 to be run at 2017-06-20T09:30:00.258870+00:00
2017-06-20 09:30:00,077 | INFO     | upgrader.py          ( 300) | _scheduleUpgrade | Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv's upgrader processing upgrade for version 0.3.140
2017-06-20 09:30:00,079 | INFO     | upgrader.py          ( 361) | _callUpgradeAgent | Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv's upgrader calling agent for upgrade
2017-06-20 09:40:00,096 | ERROR    | upgrader.py          ( 409) | _declareTimeoutExceeded | Upgrade to version {} scheduled on {} failed because timeout exceeded


Expected Results:
There should be correct error message about wrong version number.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/17 7:24 PM;VladimirWork;1.PNG;https://jira.hyperledger.org/secure/attachment/11306/1.PNG","22/Jun/17 7:24 PM;VladimirWork;2.PNG;https://jira.hyperledger.org/secure/attachment/11307/2.PNG","22/Jun/17 7:25 PM;VladimirWork;failed_upgrade.txt;https://jira.hyperledger.org/secure/attachment/11308/failed_upgrade.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyfqn:",,,,,,12,,,,,,,,,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/17 7:08 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","22/Jun/17 7:24 PM;VladimirWork;[There are several changes in the upgrader behavior related to this bug due to INDY-200 fixes:]

1. Upgrade to not latest version (e.g. 0.3.141 -> 0.3.152 (latest 0.3.154) is *successful*.

2. Upgrade to unexisting version breaks the pool: all nodes disconnect every few seconds to perform upgrade and connect back due to upgrade fails. This behavior should be fixed.;;;","06/Sep/17 6:16 AM;krw910;[~VladimirWork] please test this again and let us know if it is still an issue.;;;","06/Sep/17 6:26 PM;VladimirWork;1. Upgrade to not latest version works (it was tested during RC/Stable acceptance testing).
2. Upgrade to nonexistent version doesn't break the pool (it was fixed in INDY-316).

There is one issue with upgrade to nonexistent version now: when upgade fails node tries to reinstall the same version but now we have no migration script for this case and it will be fixed in INDY-755.

FYI [~krw910];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] [send NYM] Send NYM commands fail after view change during the pool upgrade,INDY-289,18428,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,VladimirWork,VladimirWork,20/Jun/17 11:53 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Could,,,,,"Build Info:
sovrin-node 0.3.140

Overview:
Send NYM commands fail after view change during the pool upgrade.

Steps to Reproduce:
1. Send POOL_UPGRADE command.
2. Send NYM commands when each node of pool disconnects to upgrade.

Actual Results:
Send NYM commands fail after disconnecting the primary node of master protocol instance and starting the view change procedure.

Expected Results:
Pool should work normally.",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-450,,,,,,,,"06/Jul/17 6:48 PM;VladimirWork;Node1.zip;https://jira.hyperledger.org/secure/attachment/11593/Node1.zip","04/Jul/17 7:28 PM;VladimirWork;Node1_log.txt;https://jira.hyperledger.org/secure/attachment/11548/Node1_log.txt","06/Jul/17 6:48 PM;VladimirWork;Node2.zip;https://jira.hyperledger.org/secure/attachment/11594/Node2.zip","04/Jul/17 7:28 PM;VladimirWork;Node2_log.txt;https://jira.hyperledger.org/secure/attachment/11549/Node2_log.txt","06/Jul/17 6:48 PM;VladimirWork;Node3.zip;https://jira.hyperledger.org/secure/attachment/11595/Node3.zip","06/Jul/17 6:48 PM;VladimirWork;Node4.zip;https://jira.hyperledger.org/secure/attachment/11596/Node4.zip","17/Jul/17 10:45 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11686/Screenshot.PNG","06/Jul/17 6:45 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11592/Screenshot.PNG","04/Jul/17 7:29 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11550/Screenshot.PNG","20/Jun/17 11:52 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11215/Screenshot.PNG","17/Jul/17 10:45 PM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/11687/_node1.txt","17/Jul/17 10:45 PM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/11688/_node2.txt","17/Jul/17 10:45 PM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/11689/_node3.txt","17/Jul/17 10:45 PM;VladimirWork;_node4.txt;https://jira.hyperledger.org/secure/attachment/11690/_node4.txt","20/Jun/17 11:52 PM;VladimirWork;pool_upgrade+view_change+send_NYM.txt;https://jira.hyperledger.org/secure/attachment/11214/pool_upgrade%2Bview_change%2Bsend_NYM.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1tb:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,lovesh,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/17 11:54 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","21/Jun/17 6:13 AM;stevetolman;Please retest once INDY-13 is fixed.;;;","04/Jul/17 7:29 PM;VladimirWork;Bug is reproducing during the pool upgrade from 0.4.7 to 0.4.9 with the same steps. New logs are in attachment. [^Node1_log.txt]  [^Node2_log.txt]  !Screenshot.PNG|thumbnail! ;;;","04/Jul/17 11:17 PM;lovesh;[~VladimirWork] The logs are at INFO level, can you please enable the TRACE logs while testing? Also can you give the entire log, these logs are about 10 seconds.;;;","05/Jul/17 8:37 PM;VladimirWork;Cannot reproduce during 0.4.8 -> 0.4.9 pool upgrade with trace logs on. Additional investigation is needed.;;;","06/Jul/17 6:48 PM;VladimirWork;Bug has been reproduced during 0.4.9 -> 0.4.10 pool upgrade. Trace logs from all nodes are in attachment. Send NYM failed in 09:15 server time due to Node 4 disconnection for upgrade. !Screenshot.PNG|thumbnail!  [^Node1.zip]  [^Node2.zip]  [^Node3.zip]  [^Node4.zip] ;;;","10/Jul/17 6:19 PM;lovesh;The problem is that the a node that started up after upgrade did not receive sufficient PROPAGATEs to so it could not consider the requests finalised and hence was stuck. A solution is to consider requests finalised after receiving PRE-PREPARE and sufficient PREPAREs, but choose the requests with digests that satisfy the PRE-PREPARE (and PREPAREs). If request is not present then ask other nodes for it;;;","11/Jul/17 9:24 PM;lovesh;PR, https://github.com/hyperledger/indy-plenum/pull/269;;;","17/Jul/17 10:46 PM;VladimirWork;[~lovesh] I can't break NYM adding due to this fix but I still can ""pause"" the NYM adding during 0.4.37 -> 0.4.38 pool upgrade (see screenshot) and all NYMs are added after the last node upgrade is completed - is it allowable behavior? Trace logs are in attachment. !Screenshot.PNG|thumbnail!  [^_node1.txt]  [^_node2.txt]  [^_node3.txt]  [^_node4.txt] ;;;","20/Jul/17 6:05 PM;VladimirWork;The initial bug is fixed but now we have some pauses in the NYM adding due to pool upgrade.
Is it allowable behavior or not? Please see my comment above for additional info.;;;","21/Jul/17 6:58 AM;danielhardman;I'm not sure. I wonder what [~lovesh] and [~ashcherbakov] and [~mzk-vct] think. Please weigh in, and tell me why you arrived at that opinion.;;;","21/Jul/17 5:06 PM;ashcherbakov;[~danielhardman] [~VladimirWork]
I think this behaviour is OK for now. We should not have upgrades too often, and sending a NYM during Upgrade has just some inconvenience, it's working in general.
I suggest we create a separate ticket for this issue with pausing and think later how we can fix it. I think this new issue should have rather minor priority (at least not High).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The CLI needs a new command to transfer ownership of an ID and to rotate verkey,INDY-290,18443,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,21/Jun/17 5:09 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,NewFeature,should,,,,"We need to add some new functionality to the CLI so that we can test the transfer of an ID. 

The suggested command would be ""new key for ID xxxxxxx""

The scenario is that someone like a Trust Anchor creates an ID and puts it on the ledger without  a verification key. Now they want to give that ID to an owner and the owner needs to provide a verification key. 
Today in the CLI with the way that wallets work you need to have the private key in the wallet of the new owner. The only way you can do that today is with the 'new key' command being run from the CLI on the target owners machine. 
So in order for the target owner to take ownership of a key would be to generate that public private key pair on their machine.

To generate this new public and private key that is associated with the ID you would run 'new key for ID <identifier from Trust Anchor>' on from the target owners machine and then send the verkey to the Trust Anchor and have them run 'send NYM <ID> verkey=<the owners verkey>",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,INDY-732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzye73:",,,,,,10,11,,,,,,,,,,,,,,,,,,,ashcherbakov,dsurnin,krw910,ozheregelya,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/17 4:37 AM;krw910;My conversation with Nikita on how to use the ""new identifier"" command to create a new verkey to take ownership of an identity or to rotate my verkey. These are just notes and a set of steps needs to be documented once I have tested the process.

*nikita.spivachuk*
`new key` and `new identifier` are actually different kinds of the same command. Both they generate a triplet <identifier, verification key, signing key>.
Below there are different kinds of `new key/identifier` command:

`new key [with seed <SEED>]` generates a cryptonym (which is used as both the identifier and verification key) and a corresponding signing key.

`new identifier [with seed <SEED>]` generates a 16-byte identifier, a full verification key and a corresponding signing key.

`new identifier abbr [with seed <SEED>]` generates a 16-byte identifier, an abbreviated verkey and a corresponding signing key.

`new identifier <ID> [with seed <SEED>]` generates the specified identifier (<ID>), a full verification key and a corresponding signing key. (edited)

So the command `new identifier <ID>` executed several times in succession with the same <ID> allows just to change the key pair while staying with the same identifier. (edited)


*nikita.spivachuk*
`new key`/`new identifier` command generates a triplet and activate it in the wallet.

There is also `use identifier <ID>` command that activates an already existing (in the wallet) triplet by its identifier (<ID>).


*kelly.wilson*
Awesome. So if I want to rotate my verkey all I do is run ""new identifier <ID>"" to get a new verkey/private key pairing? If I do that can I say ""use identifier"" and then ""send NYM dest=<ID> verkey=<new verkey>""?


*nikita.spivachuk*
>So if I want to rotate my verkey all I do is run ""new identifier <ID>"" to get a new verkey/private key pairing?
You execute `new identifier <ID>` where <ID> is your identifier.


*kelly.wilson*
How do you get that verkey on the ledger with your ID?


*nikita.spivachuk*
>If I do that can I say ""use identifier"" and then ""send NYM dest=<ID> verkey=<new verkey>""?
The command is `use identifier <ID>` where <ID> is an identifier already existing in the wallet.

There is no sense to execute `use identifier <ID>` right after `new identifier <ID>` if ids are the same. In such the case `use identifier <ID>` just activates the already active identifier just generated by `new identifier <ID>`. (edited)

*kelly.wilson*
Ok, I will try that out. So you are right if that works as designed we don't need INDY-290


*nikita.spivachuk*
If a verkey has already been set in the ledger for your identifier then the following scenario will NOT work:
`new identifier <ID>`
`send NYM dest=<ID> verkey=<GENERATED_VERKEY>` (edited)


*kelly.wilson*
So you cannot rotate your verkey that way. How do a rotate my verkey?


*nikita.spivachuk*
This will not work because the key pair in the wallet will be replaced with the new generated one and so the request `send NYM` will be signed using the new key which the ledger is not aware of.

As a workaround, one could use two CLIs, generate a new key pair in the first CLI, then update the verkey in the ledger from the second CLI and after that use the first CLI.;;;","13/Jul/17 6:41 PM;spivachuk;*An addition to the previous comment:*
The user can also use two keyrings in the same CLI (instead of two CLIs or two machines) in order to rotate their key.;;;","20/Jul/17 1:36 AM;krw910;I am unable to come up with any steps that allow me to rotate a verkey. I need step by step instructions. 
The main issue here is the wallet. 
I cannot create a new identifier to get a new verkey while in the wallet I am using. If I do I cannot send the NYM command because my signature no longer matches.
If I run ""use identifier"" from a different wallet then switch to my main wallet I can send the command, but now my verkey is in the other wallet and I cannot do any more operations from my main wallet.

We have to have step by step instructions on how to rotate a verkey and keep the same wallet. The need to be clear enough we can write up a document for the Trustees and Stewards. Once you have instructions please send them to me for verification.
;;;","20/Jul/17 4:49 PM;ashcherbakov;[~ozheregelya] [~VladimirWork] I think you did some experiments regarding this. Do you have an instruction?;;;","20/Jul/17 11:36 PM;ozheregelya;[~krw910], [~ashcherbakov] I've updated instruction for rotation of verkey: [https://docs.google.com/document/d/1_CQ1mldMNSgNGqR1urvjcXL2QXVxPz760_cLFXXMpTc/edit#|https://docs.google.com/document/d/1_CQ1mldMNSgNGqR1urvjcXL2QXVxPz760_cLFXXMpTc/edit]
 Here are steps:

1. Add new identity (DID):
{code:java}
User’s client:
sovrin@test> new keyring wallet1
Active keyring ""Default-dd49d5"" saved (/home/sovrin/.sovrin/keyrings/test/default-dd49d5.wallet)
New keyring wallet1 created
Active keyring set to ""wallet1""
sovrin@test> new key
Key created in keyring wallet1
Identifier for key is RrTkY1dPvpxJShvtHoPe8Y
Verification key is ~MKpejEBYGxdQzHRZ1CZk1Z
Current identifier set to RrTkY1dPvpxJShvtHoPe8Y

Trustee’s client:
sovrin@test> new keyring trusteeWallet
Active keyring ""Default-dd49d5"" saved (/home/sovrin/.sovrin/keyrings/test/default-dd49d5.wallet)
New keyring trusteeWallet created
Active keyring set to ""trusteeWallet""
sovrin@test> new key with seed 000000000000000000000000Steward1
Key created in keyring trusteeWallet
Identifier for key is Th7MpTaRZVRYnPiabds81Y
Verification key is ~7TYfekw4GUagBnBVCqPjiC
Current identifier set to Th7MpTaRZVRYnPiabds81Y
sovrin@test> send NYM dest=RrTkY1dPvpxJShvtHoPe8Y verkey=~MKpejEBYGxdQzHRZ1CZk1Z
Adding nym RrTkY1dPvpxJShvtHoPe8Y
Nym RrTkY1dPvpxJShvtHoPe8Y added
{code}
 

2. Create new keyring to backup active verkey before generating new one and generate new verkey:
{code:java}
User’s client:
sovrin@test> new keyring draftWallet
Active keyring ""wallet1"" saved (/home/sovrin/.sovrin/keyrings/test/wallet1.wallet)
New keyring draftWallet created
Active keyring set to ""draftWallet""
sovrin@test> new identifier RrTkY1dPvpxJShvtHoPe8Y
Identifier created in keyring draftWallet
New identifier is RrTkY1dPvpxJShvtHoPe8Y
New verification key is 8141LM6L6Lm3XXB76sGVDuBE5q8w94WLZBkRBkTZ2NTP
Current identifier set to RrTkY1dPvpxJShvtHoPe8Y
{code}
 

3. Sending newly generated verkey (stored in draftWallet) to the ledger using current verkey (stored in wallet1):
{code:java}
sovrin@test> use keyring wallet1
Active keyring ""draftWallet"" saved (/home/sovrin/.sovrin/keyrings/test/draftwallet.wallet)
Active keyring set to ""wallet1""
sovrin@test> use identifier RrTkY1dPvpxJShvtHoPe8Y
Current identifier set to RrTkY1dPvpxJShvtHoPe8Y
sovrin@test> send NYM dest=RrTkY1dPvpxJShvtHoPe8Y verkey=8141LM6L6Lm3XXB76sGVDuBE5q8w94WLZBkRBkTZ2NTP
Adding nym RrTkY1dPvpxJShvtHoPe8Y
Nym RrTkY1dPvpxJShvtHoPe8Y added
{code}
 

Now key pair for RrTkY1dPvpxJShvtHoPe8Y  in keyring wallet1 is invalid. But user is able to use keypair in draftWallet. If it is important to use keyring wallet1, user can rotate verkey one more time:
{code:java}
sovrin@test> new identifier RrTkY1dPvpxJShvtHoPe8Y
Identifier created in keyring wallet1
New identifier is RrTkY1dPvpxJShvtHoPe8Y
New verification key is 7DraUMinVb67g6uMxio955u7MSBSKKSMzfUoUxZCQYRK
Current identifier set to RrTkY1dPvpxJShvtHoPe8Y
sovrin@test> use keyring draftWallet
Active keyring ""wallet1"" saved (/home/sovrin/.sovrin/keyrings/test/wallet1.wallet)
Active keyring set to ""draftWallet""
sovrin@test> use identifier RrTkY1dPvpxJShvtHoPe8Y
Current identifier set to RrTkY1dPvpxJShvtHoPe8Y
sovrin@test> send NYM dest=RrTkY1dPvpxJShvtHoPe8Y verkey=7DraUMinVb67g6uMxio955u7MSBSKKSMzfUoUxZCQYRK
Adding nym RrTkY1dPvpxJShvtHoPe8Y
Nym RrTkY1dPvpxJShvtHoPe8Y added
{code}
 

As we can see, rotation of verkey is possible. But I agree with Kelly. It will be better to create new command for rotation verkey because current procedure of rotation verkeys looks like tricky workaround and it is really inconvenient for users.;;;","20/Jul/17 11:48 PM;ozheregelya;{quote}The scenario is that someone like a Trust Anchor creates an ID and puts it on the ledger without a verification key. Now they want to give that ID to an owner and the owner needs to provide a verification key. 
 Today in the CLI with the way that wallets work you need to have the private key in the wallet of the new owner. The only way you can do that today is with the 'new key' command being run from the CLI on the target owners machine. 
 So in order for the target owner to take ownership of a key would be to generate that public private key pair on their machine.
{quote}
Steps for this scenario:

Trustee/TrustAnchor client:
{code:java}
sovrin@test> new key
Key created in keyring trusteeWallet
Identifier for key is VWWqQERPa2LHGY86UNJKWY
Verification key is ~Xn8r1Fk5maDqfxgLityASU
Current identifier set to VWWqQERPa2LHGY86UNJKWY
sovrin@test> send NYM dest=VWWqQERPa2LHGY86UNJKWY
Adding nym VWWqQERPa2LHGY86UNJKWY
Error: client request invalid: CouldNotAuthenticate()
sovrin@test> new key with seed 000000000000000000000000Steward1
Key created in keyring trusteeWallet
Identifier for key is Th7MpTaRZVRYnPiabds81Y
Verification key is ~7TYfekw4GUagBnBVCqPjiC
Current identifier set to Th7MpTaRZVRYnPiabds81Y
sovrin@test> send NYM dest=VWWqQERPa2LHGY86UNJKWY
Adding nym VWWqQERPa2LHGY86UNJKWY
Nym VWWqQERPa2LHGY86UNJKWY added{code}
User client:
{code:java}
sovrin@test> new identifier VWWqQERPa2LHGY86UNJKWY
Identifier created in keyring draftWallet
New identifier is VWWqQERPa2LHGY86UNJKWY
New verification key is 4qvUoW4yGSpqxjjGLWtZETngiHT5JoGA5pSq8uwFqcA7
Current identifier set to VWWqQERPa2LHGY86UNJKWY{code}
User provides generated verkey (4qvUoW4yGSpqxjjGLWtZETngiHT5JoGA5pSq8uwFqcA7) to Trustee/TrustAnchor by some way and Trustee/TrustAnchor send it to ledger:
 Trustee/TrustAnchor client:
{code:java}
sovrin@test> send NYM dest=VWWqQERPa2LHGY86UNJKWY verkey=4qvUoW4yGSpqxjjGLWtZETngiHT5JoGA5pSq8uwFqcA7
Adding nym VWWqQERPa2LHGY86UNJKWY
Nym VWWqQERPa2LHGY86UNJKWY added{code}
Check that user can use his identifier:
{code:java}
sovrin@test> send NYM dest=VWWqQERPa2LHGY86UNJKWY
Adding nym VWWqQERPa2LHGY86UNJKWY
Nym VWWqQERPa2LHGY86UNJKWY added{code}
After these actions user can change his verkey himself as described in my previous comment after step 1.;;;","21/Jul/17 1:05 AM;ozheregelya;[~krw910], 
Also I'm not sure what do you mean
{quote}new command to transfer ownership
{quote}
The only association which I have is the end of guardianship. Guardianship of Trustee/TrustAnchor (or any other person who created the identity) ends automatically when Trustee/TrustAnchor set up the verkey for the identity (send NYM dest=VWWqQERPa2LHGY86UNJKWY verkey=4qvUoW4yGSpqxjjGLWtZETngiHT5JoGA5pSq8uwFqcA7).


To summarize, we have ways to do both of actions: transfer ownership and change the verkey. But it will be nice to have one command for rotation verkey instead of tricky scenario. 
So, what should we do with this ticket?;;;","21/Jul/17 5:52 AM;krw910;[~ozheregelya] what I meant by ""new command to transfer ownership"" is if when adding the NYM to the ledger they also added the verkey. Now to give that NYM to someone they need to generate a new verkey and have it changed which is basically the same as rotating a key.;;;","21/Jul/17 5:59 AM;krw910;Nikita Spivachuk Olga Zheregelya thanks for the steps. Unfortunately, those steps require the user to use the new wallet (draftwallet) they created to generate the new key pair after rotating their verkey. This is not acceptable because all the operations I have done as that user are in wallet1 which they can no longer use. 
The steps that have been provide require abandoning their wallet if they rotate their verkey.
We have to be able to rotate someones keys without losing their primary wallet.;;;","21/Jul/17 5:30 PM;ashcherbakov;[~krw910] [~ozheregelya] [~spivachuk]
As I understand, they use `draftwallet` as a temporarily buffer only. The user can continue working with wallet1, but he has to rotate the keys one more time (this time using wallet1 as a buffer, and doing real rotation with draftwallet).
So, it's possible to rotate the key and still use the same wallet, but the procedure is really not obvious and complicated. 

So, [~krw910] [~danielhardman] [~stevetolman], the question is whether this is OK for MGL (I think for MGL that's fine, as key rotation will probably be not very usual operation right after MGL). We can create a ticket in M1 to make this procedure more simple and obvious, and don't require using a temporarily wallet for rotation.;;;","21/Jul/17 5:31 PM;ashcherbakov;BTW [~krw910] [~stevetolman] Nikita's on vacation now (till Jul, 28).;;;","21/Jul/17 7:15 PM;ozheregelya;[~krw910],
{quote}what I meant by ""new command to transfer ownership"" is if when adding the NYM to the ledger they also added the verkey. Now to give that NYM to someone they need to generate a new verkey and have it changed which is basically the same as rotating a key.
{quote}
As I understand these procedure:
1. User generates identifier, verkey and signing key in his wallet.
2. He provides identifier and verkey to Trustee/TrustAnchor/etc.
3. Trustee/TrustAnchor/etc adds his identifier with verkey to the ledger.
4. After that user can use his identifier.

After these actions user's signing key was not shared to someone, so I'm not sure that user really have to change verkey.;;;","10/Aug/17 12:26 AM;dsurnin;[~krw910] [~danielhardman] [~ozheregelya] [~ashcherbakov]

It would be nice to emphasize that a command changes the key. What do you think about the name ""change key for ID xxxxx"" ?

Also only the identity owner can change the key, so we do not need to provide actual id - we must use current one.

As a result command can be ""change key"" or ""change current key""?

 

What do you think?;;;","11/Aug/17 7:05 PM;dsurnin;new command ""change current key [with seed <seed>]"" added

node 0e233a119cea2e5f7a69d882c38f5d5ccd01e1c6

test

sovrin-node/sovrin_client/test/cli/test_change_key.py;;;","12/Aug/17 1:44 AM;ozheregelya;Build Info:
  indy-node 1.0.100
  indy-anoncreds 1.0.25
  indy-plenum 1.0.91
  sovrin 1.0.22
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client

New command works correctly in following cases:
 * change current key for identity owner before sending in to ledger.
=> error
 * change current key for identity owner send to ledger but with empty verkey.
=> error
 * change current key for identity owner send to ledger with verkey.
=> works correctly, identity owner is able to sign transactions, old verkey is invalid.

Additional testing is needed for invalid cases (like crashing CLI during processing of command).;;;","17/Aug/17 10:37 PM;ozheregelya;Build Info:
  indy-node 1.0.110
  indy-anoncreds 1.0.25
  indy-plenum 1.0.97
  sovrin 1.0.23
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client

Following invalid cases were verified:
 * Interruption of changing verkey after sending to the ledger and before updating of wallet.
=> Information in the wallet and in the ledger are not synchronized. See INDY-732.
 * Changing verkey when the pool is unavailable.
=> Nothing happened (same as for send NYM to unavailable pool). Verkey in the wallet is not changed without changing value in the ledger.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Produce the Stable build from the H1 Sprint,INDY-291,18503,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,21/Jun/17 12:44 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Node 
python3-stp=0.1.57
python3-ledger=0.2.28
python3-rlp=0.5.1
python3-sha3=0.2.1
python3-state-trie=0.1.15
python3-plenum=0.3.147
python3-sovrin-common=0.2.92
sovrin-node=0.3.141


Client 
python3-stp=0.1.57
python3-ledger=0.2.28
python3-rlp=0.5.1
python3-sha3=0.2.1
python3-state-trie=0.1.15
python3-plenum=0.3.147
python3-sovrin-common=0.2.92
python3-anoncreds=0.3.10
sovrin-client=0.3.145
",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy16f:",,,,,,H2,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/17 10:56 PM;krw910;We produced the Stable build and have it ready for deployment.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validation works incorrectly with batching,INDY-292,18514,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,ozheregelya,ozheregelya,21/Jun/17 10:23 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,On-hold,,,,"*Overview:*
 Incorrect behavior occurs after sending lots of invalid NYMs at once. In this case invalid NYMs mean multiple sending of send NYM with the same dest and different verkeys.
 Note: load_test.py was modified for sending lots of invalid NYMs: row 176 signer.identifier was changed to constant identifier. Constant identifier should be changed before each running of the script. Here is this version of load_test script: [^load_test_inv.py]

*Case 1:*
 Behavior is differeSending invalid NYMs one by one.
 Steps to Reproduce:
 1. python3 load_test.py --clients-list load_test_clients.list --timeout 15 -t NYM -c 1 -r 14
 => The last output of script:
{code:java}
================================
Test time: 140.95470929145813
Average latency: 10.066737873213631
Throughput: 0.0
Error rate: 0.09932268365047384
Succeeded: 1
Failed: 13
================================{code}
It works as expected. Succeeded transaction added unique NYM, the rest NYMs were not added because creator of NYM can't update verkey.
 2. Change identifier value in the script to unique one.
 3. python3 load_test.py --clients-list load_test_clients.list --timeout 15 -t NYM -c 1 -r 14 --at-once
 => The last output of script:
{code:java}
================================
Test time: 1.0311000347137451
Average latency: 1.0199457577296667
Throughput: 13.577732061551808
Error rate: 0.0
Succeeded: 14
Failed: 0
================================{code}
Actual Results:
 All invalid transactions are succeeded when the script was run with --at-once key.

Expected Results:
 Only the first transaction should be succeeded, the rest ones should not be succeeded.

Case 2:
 Cluster is crashed after sending of 1000 invalid transactions at once (independently on turned on or turned off view changes).
 1. python3 load_test.py --clients-list load_test_clients.list --timeout 15 -t NYM -c 1 -r 1000 --at-once
 => the last output of script:
{code:java}
================================
Test time: 9160.375793457031
Average latency: 4133.603355242252
Throughput: 0.010807416882472507
Error rate: 0.09835841021320937
Succeeded: 99
Failed: 901
================================{code}
Actual Results:
 On 103th transaction Node1C and Node2C appeared in both ackNodes and nackNodes columns of pref_results spreadsheet: [^perf_results_1_1000_1497994390.csv]
 The rest transactions were failed. After completion of the test cluster does not send NYMs.

Expected Results:
 Only the first transaction should be succeeded, the rest ones should not be succeeded. Cluster should not crash.

Additional Information:
 Running of load script with following parameters (500 transactions instead of 1000):
{code:java}
python3 load_test.py --clients-list load_test_clients.list --timeout 15 -t NYM -c 1 -r 500 --at-once{code}
didn't break the cluster. For 500 transactions behavior is the same as for 14 transactions.

pref_results for 500 transactions: [^perf_results_1_500_1497994295.csv]
 Nodes logs: [^logs.tar.gz]","Build Info:
sovrin-node version: 0.3.140
OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,INDY-421,INDY-734,,,,,,,,,,,,,,,INDY-255,,,,,,,,"19/Jul/17 6:49 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11704/Node1.log","19/Jul/17 6:50 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11705/Node2.log","19/Jul/17 6:50 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11706/Node3.log","19/Jul/17 6:50 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11707/Node4.log","19/Jul/17 6:50 PM;ozheregelya;load_test_inv.py;https://jira.hyperledger.org/secure/attachment/11711/load_test_inv.py","21/Jun/17 10:50 PM;ozheregelya;load_test_inv.py;https://jira.hyperledger.org/secure/attachment/11304/load_test_inv.py","21/Jun/17 10:23 PM;ozheregelya;logs.tar.gz;https://jira.hyperledger.org/secure/attachment/11301/logs.tar.gz","21/Jun/17 9:08 PM;ozheregelya;perf_results_1_1000_1497994390.csv;https://jira.hyperledger.org/secure/attachment/11303/perf_results_1_1000_1497994390.csv","19/Jul/17 6:50 PM;ozheregelya;perf_results_1_1000_1500387883.csv;https://jira.hyperledger.org/secure/attachment/11710/perf_results_1_1000_1500387883.csv","19/Jul/17 6:49 PM;ozheregelya;perf_results_1_14_1500387141.csv;https://jira.hyperledger.org/secure/attachment/11708/perf_results_1_14_1500387141.csv","19/Jul/17 6:49 PM;ozheregelya;perf_results_1_14_1500387826.csv;https://jira.hyperledger.org/secure/attachment/11709/perf_results_1_14_1500387826.csv","21/Jun/17 9:08 PM;ozheregelya;perf_results_1_500_1497994295.csv;https://jira.hyperledger.org/secure/attachment/11302/perf_results_1_500_1497994295.csv",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydcn:",,,,,,10,11,,,,,,,,,,,,,,,,,,,DouglasWightman,lovesh,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/17 1:18 AM;lovesh;On hold as waiting for node logs;;;","19/Jul/17 7:17 PM;ozheregelya;The problem was reproduced again on following version:
  indy-anoncreds 0.4.15
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
  indy-plenum 0.4.50
  indy-node 0.4.39
  sovrin 0.2.9
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes (Shakedown Pool 4)



Here are necessary logs:
[^Node1.log][^Node2.log][^Node3.log][^Node4.log]

Here are test results:
[^perf_results_1_14_1500387141.csv]
[^perf_results_1_14_1500387826.csv]
[^perf_results_1_1000_1500387883.csv]

Here are new script for generation invalid queries:
[^load_test_inv.py];;;","27/Jul/17 11:48 AM;DouglasWightman;I've created a PR (https://github.com/hyperledger/indy-node/pull/264) for Case 1 and will work on Case 2 next.;;;","28/Jul/17 3:18 AM;DouglasWightman;I tried Case 2 for a few hours but did not get a crash and only 1 transaction made it to the ledger (as expected).  Sending this to testing for verification.;;;","01/Aug/17 11:01 PM;ozheregelya;*Case 1* is still reproduced with the same steps as described above.
Build Info:
  indy-node 1.0.68
  indy-anoncreds 1.0.22
  indy-plenum 1.0.77
  sovrin 1.0.14
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client

*Case 2* will be re-tested till tomorrow morning.;;;","01/Aug/17 11:24 PM;DouglasWightman;[~ozheregelya] this was checked into the m1 branch so I don't believe it has yet been merged to master.  I looked at the 1.0.68 code and my code change is not there.;;;","02/Aug/17 7:14 PM;ozheregelya;*Case 2* was re-tested on indy-node 1.0.68. The problem with pool crashing was not reproduced.;;;","02/Aug/17 10:44 PM;DouglasWightman;Now that m1 has been merged into master this can go to testing again for Case 1.;;;","03/Aug/17 12:26 AM;ozheregelya;*Build Info:*
  indy-node 1.0.69
  indy-anoncreds 1.0.22
  indy-plenum 1.0.78
  sovrin 1.0.15
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes (running locally), 1 client

*Case 1:*
*Steps to Validate:*
1. python3 load_test_inv.py --clients-list load_test_clients.list --timeout 15 -t NYM -c 1 -r 14
=>
{code:java}
================================
Test time: 262.6953225135803
Average latency: 18.761701737131393
Throughput: 0.003806691304708343
Error rate: 0.04948698696120846
Succeeded: 1
Failed: 13
================================{code}
2. python3 load_test_inv.py --clients-list load_test_clients.list --timeout 15 -t NYM -c 1 -r 14 --at-once
=>
{code:java}
================================
Test time: 263.16851019859314
Average latency: 131.89141993863242
Throughput: 0.003799846718915483
Error rate: 0.04939800734590128
Succeeded: 1
Failed: 13
================================{code}
*Actual Results:*
Validation works correctly with batching for small amount of invalid transactions.

 

*Case 2* will be re-verified tonight.;;;","08/Aug/17 11:36 PM;ozheregelya;*Build Info:*
   indy-node 1.0.69
   indy-anoncreds 1.0.22
   indy-plenum 1.0.78
   sovrin 1.0.15
   python3-rlp 0.5.1
   python3-sha3 0.2.1
   python3-pyzmq 16.0.2
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 4 nodes, 1 client

*Reason for Reopen:*
 It looks like batching works incorrectly at all.

 

*Case 3:*
 Steps to Reproduce:
 1. Run the +original+ load_test.py with following parameters:
{code:java}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 5 --at-once{code}
*Actual Results:*
 Only the first transaction was successfully send.
{code:java}
================================
 Test time: 481.6778497695923
 Average latency: 241.21067271232604
 Throughput: 0.0020760763661404483
 Error rate: 0.008304305464561793
 Succeeded: 1
 Failed: 4
 ================================{code}
*Expected Results:*
 All transactions should be send.

 

*Case 2:*
Steps to Reproduce:
 1. Run the +changed version+ of load_test_inv.py with following parameters:
{code:java}
 python3 load_test_inv.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once{code}
 *Actual results:*
 No one transaction was processed. Here are part of resulting file:
{code:java}
signerName,signerId,dest,reqId,transactionType,sentAt,quorumAt,latency,ackNodes,nackNodes,replyNodes
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,XpguzUtPqrxT4g56pSdTPq,1502185120379891,1,1502185120.556741,,121.20042657852173,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,tc3K6X6Zq4U4pT8e9LYp6,1502185120380533,1,1502185120.556741,,241.29323482513428,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,Vd4oVB3sTpScjtqVcodTzL,1502185120380988,1,1502185120.556741,,361.39144492149353,,,{code}
The rest messages in this file are similar. 

*Expected Results:* 
 The first transaction (with unique DID) should be successfully send.

 

*Additional Information:*
 Case 2 and Case 3 are reproducing now on shakedown pool 3. Case 3 works correctly for 100 transactions and does not work for more than 400 transactions.;;;","09/Aug/17 12:51 AM;ozheregelya;If the problem is not in the batching, feel free to turn this ticket back to me and I will create new one for this problem.;;;","11/Aug/17 7:07 AM;DouglasWightman;It was a problem with batching.  I've checked in tests that verify each scenario.  I've gone through the cases and verified they are working as expected on my system.;;;","15/Aug/17 6:29 AM;ozheregelya;[~DouglasWightman], I started to verify this ticket today and it looks like that some problems are still present. I run load_test.py with following parameters:
{code:java}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 1000 --at-once{code}
and I can see following data in output file:
{code:java}
signerName,signerId,dest,reqId,transactionType,sentAt,quorumAt,latency,ackNodes,nackNodes,replyNodes
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,CJE2c6GvHpHU1YCr3LeTyp,1502699971843291,1,1502699972.0264232,1502699991.6342106,19.607787370681763,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,PJcVFkSWTa66G887Nf1iqY,1502699971843796,1,1502699972.0264232,1502699991.6353345,19.608911275863647,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,EJiJZ3k2BY93F2UJ3wsfHF,1502699971843997,1,1502699972.0264232,1502699991.6362665,19.609843254089355,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,5gXynn8Lts5Z1ixhwCh2DA,1502699971844189,1,1502699972.0264232,1502699991.6372318,19.610808610916138,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,FDZb5b3H8GYZtNA1P4W3Ng,1502699971844372,1,1502699972.0264232,1502699991.6381798,19.611756563186646,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,Jas349CN5xdSnHTjdZ15jH,1502699971844555,1,1502699972.0264232,1502699991.6391242,19.612700939178467,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,LHeU5KRH3cnkFN2bXoTyD1,1502699971844754,1,1502699972.0264232,1502699991.6400764,19.6136531829834,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,RhAbt2CGtc4YB6y4Gb8JrJ,1502699971844937,1,1502699972.0264232,1502699991.6410425,19.614619255065918,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,5v1ftJrvPpt4f3pKrkjW4x,1502699971845127,1,1502699972.0264232,1502699991.6420004,19.615577220916748,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,A5mw3pC7dm32wZec1KZ8hG,1502699971845306,1,1502699972.0264232,1502699991.6429303,19.616507053375244,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,9awozSArSjBXcU1Dk2nuac,1502699971845484,1,1502699972.0264232,1502699991.6438646,19.617441415786743,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,G8iqvKdr2jmbpSZdkDeXbG,1502699971845661,1,1502699972.0264232,1502699991.6624665,19.636043310165405,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,T8XrfKTrhpHUU3m6cvcFyH,1502699971845839,1,1502699972.0264232,1502699991.6634805,19.637057304382324,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,GpJHH8dm9LCWAv7CUPgLXQ,1502699971846015,1,1502699972.0264232,1502699991.6644766,19.63805341720581,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,WeLwU2CzSuQatY9cwCQ4TL,1502699971846198,1,1502699972.0264232,1502699991.6654954,19.63907217979431,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,Q5ajf6Vfw6Jpp8ok2xX2Ct,1502699971846386,1,1502699972.0264232,1502699991.6664872,19.640064001083374,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,UoTREpaFimh8ms5Ct8H7Vn,1502699971846566,1,1502699972.0264232,1502699991.6674826,19.641059398651123,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,QWyPn4Lv8AYdg1TjVDdTaB,1502699971846744,1,1502699972.0264232,1502699991.6684709,19.6420476436615,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,CVQw13pdDdD1cKbK8s7uV9,1502699971846921,1,1502699972.0264232,1502699991.6694841,19.64306092262268,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,hfdReGC3z6oCQmNogTBoB,1502699971847097,1,1502699972.0264232,1502699991.6704772,19.64405393600464,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,MhkpiBaFZCb5mcKWGrk4Ss,1502699971847312,1,1502699972.0264232,1502699991.6714654,19.645042181015015,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,73Kaf2JK166x9xfUFkQmmS,1502699971847496,1,1502699972.0264232,1502699991.6724596,19.646036386489868,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,8eAWdvX7GqmeBHw9c1bRYH,1502699971847681,1,1502699972.0264232,1502699991.675266,19.648842811584473,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,FiGea2PUU1qKH8nNA7YR1S,1502699971847867,1,1502699972.0264232,1502699991.6762698,19.64984655380249,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,J9So2ttL7RZUL9VS46gHZf,1502699971848046,1,1502699972.0264232,1502699991.6772916,19.65086841583252,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,NYvLSGT3BjTmHhPL3PvkVh,1502699971848225,1,1502699972.0264232,1502699991.6782892,19.65186595916748,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,UQheKXmup3qhwxvY8VipMA,1502699971848403,1,1502699972.0264232,1502699991.6792955,19.652872323989868,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,QME8rP1DULz4D26PVcoQzr,1502699971848580,1,1502699972.0264232,1502699991.6802962,19.653872966766357,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,HnBKdLCuNu4aJfPQJr9QV3,1502699971848773,1,1502699972.0264232,1502699991.6813042,19.6548810005188,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,Xu69hNojtXSgkbxhbPdhBN,1502699971848954,1,1502699972.0264232,1502699991.6822977,19.655874490737915,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,82LFdZsHUbmPskxK8ayLvm,1502699971849130,1,1502699972.0264232,1502699991.6832812,19.65685796737671,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,7vpspSmewjoL4gsvove81H,1502699971849313,1,1502699972.0264232,1502699991.6842792,19.657855987548828,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,EaZSGsrFQ8CxYVLMiK6rKE,1502699971849491,1,1502699972.0264232,1502699991.6870937,19.660670518875122,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,H7reyaKGrfzR9Ktq4o6SzU,1502699971849668,1,1502699972.0264232,1502699991.6880975,19.66167426109314,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,8dyeWWFYPGp2bkeeUsRagk,1502699971849845,1,1502699972.0264232,1502699991.6891088,19.66268563270569,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,UWxaux8VjhaxkBXpFCuUpe,1502699971850021,1,1502699972.0264232,1502699991.6900961,19.663672924041748,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,PB6avfxsPkyqrHgNqGDiGg,1502699971850209,1,1502699972.0264232,1502699991.6910872,19.664664030075073,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,D2pDh5nK1kKWw59vLWPbSN,1502699971850389,1,1502699972.0264232,1502699991.6920767,19.665653467178345,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,VCLWt5DhVC3X9hDGJ5oFWN,1502699971850571,1,1502699972.0264232,1502699991.6930819,19.666658639907837,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,SCwZgzX22uSTjbxinh4m6L,1502699971850750,1,1502699972.0264232,1502699991.6940749,19.667651653289795,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,Ju9E3eVQoDeSUR7NT58yAT,1502699971850928,1,1502699972.0264232,1502699991.6950839,19.668660640716553,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,YDWsvtn9EQkjCbyrN6YhC1,1502699971851106,1,1502699972.0264232,1502699991.6960723,19.669649124145508,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,CKvxsZ3tSXtBJPGTqBKBeF,1502699971851282,1,1502699972.0264232,1502699991.6970713,19.670648097991943,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,7mnQ1QTshtVpHkoN28dvFh,1502699971851459,1,1502699972.0264232,1502699991.6998696,19.67344641685486,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,Fpmzyg3QvAdiZU6hnuTDCn,1502699971851639,1,1502699972.0264232,1502699991.7008924,19.674469232559204,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,8HWtrnYheSX5e4sfruBAJe,1502699971851817,1,1502699972.0264232,1502699991.701889,19.67546582221985,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,aai88CmEUB8ydg7E5dWqV,1502699971851999,1,1502699972.0264232,1502699991.702876,19.67645287513733,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,QVUH2oykLRtSp8xrVgT1FP,1502699971852178,1,1502699972.0264232,1502699991.703853,19.677429676055908,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,7M326GvUg4JH6Lu38VhpMn,1502699971852353,1,1502699972.0264232,1502699991.7048717,19.67844843864441,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,4bNTMC7z2VraasoiNNp6AG,1502699971852540,1,1502699972.0264232,1502699991.7058635,19.67944025993347,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,Y162ZjWnQfNrNEdcK2bkBp,1502699971852743,1,1502699972.0264232,1502699991.7068398,19.680416584014893,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,FHPwvv5D2tWu8kn3Z6cNcF,1502699971852924,1,1502699972.0264232,1502699991.7078238,19.681400537490845,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,AsGHEKEZaFk1RdrRbs2fwN,1502699971853122,1,1502699972.0264232,1502699991.7088318,19.682408571243286,""Node4C,Node2C,Node1C,Node3C"",,""Node3C,Node2C,Node1C,Node4C""
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,DKmP8RfD77wb5pBdesJF2v,1502699971853304,1,1502699972.0264232,,139.7894322872162,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,WeA9NnwnsCm9J3nTL13aZM,1502699971853488,1,1502699972.0264232,,259.99558305740356,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,3Z5oFybHNJVnpgtFtqVtxm,1502699971853668,1,1502699972.0264232,,380.1683430671692,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,7RMmrBS1GQSKjnfMZ8D1HJ,1502699971853844,1,1502699972.0264232,,500.36001205444336,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,6xp6Urg9crB3JA5VRSxM8R,1502699971854020,1,1502699972.0264232,,620.5443210601807,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,8TCF5AvLiXLjtozX9c2GDX,1502699971854200,1,1502699972.0264232,,740.7369396686554,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,DAwCAdbMG727TR1i1db9eM,1502699971854380,1,1502699972.0264232,,860.9516203403473,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,NNdXzjpPPEdwpcNxR3mpEC,1502699971854555,1,1502699972.0264232,,981.1625893115997,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,SiDkMULmszKhAzCp3KgZZb,1502699971854736,1,1502699972.0264232,,1101.3649950027466,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,6TMkea98vQVmxx9Wd6KyHW,1502699971854915,1,1502699972.0264232,,1221.5834085941315,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,81pd5hh1PwABRRsfm44S6i,1502699971855090,1,1502699972.0264232,,1341.7675545215607,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,MsiCriJKJHCXuRD2vTGU5i,1502699971855268,1,1502699972.0264232,,1461.9794297218323,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,MgVHrmTYTzSRdnNmvsg6tY,1502699971855445,1,1502699972.0264232,,1582.1879484653473,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,16cxgnCvNQcdzVaDji4t38,1502699971855622,1,1502699972.0264232,,1702.3843796253204,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,3bzGimxse8ztxmy5ZAvjV9,1502699971855803,1,1502699972.0264232,,1822.6034615039825,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,JWdtsfbTVTF9confz5kc9f,1502699971855984,1,1502699972.0264232,,1942.7915813922882,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,BDv14gx9bjdNwcQvBMLFWo,1502699971856165,1,1502699972.0264232,,2062.9994745254517,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,8AEaNCRv1FSGBcTJ6A4hyz,1502699971856343,1,1502699972.0264232,,2183.163420200348,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,8Y4u8FrpigSQuYFm8KaLne,1502699971856520,1,1502699972.0264232,,2303.3868401050568,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,QrwQykVuecbYvkkeCkEWwY,1502699971856713,1,1502699972.0264232,,2423.566365480423,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,JQVZYXtSLDxwxAU8kQwiZ1,1502699971856894,1,1502699972.0264232,,2543.782073736191,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,29iv7fn6vvpVgN6vECnaJw,1502699971857072,1,1502699972.0264232,,2664.0007886886597,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,8whBQ9vxntZTehMW3AFXQ9,1502699971857249,1,1502699972.0264232,,2784.2214982509613,,,
Sponsor1,RRbkXVEr8UZ1Z9RidHmu25,9y83gqPs55LevF8GYC2W3y,1502699971857425,1,1502699972.0264232,,2904.412412881851,,,{code}
It looks like nodes stopped receive messages after ~50 transactions. Do you have any thought about it? If you don't I will additionally explore this problem tomorrow and provide logs.

 

I reproduced this problem in shakedown pool 3, indy-node version is 1.0.102.;;;","15/Aug/17 6:38 AM;DouglasWightman;This is case 2 that is not fixed?  Are cases 1 and 3 working now?;;;","15/Aug/17 11:56 PM;DouglasWightman;I believe case 2 (batch of 1000 causes unresponsive node) is different enough that if it is not working it should be a separate ticket.

The other issues were related to batching.;;;","30/Aug/17 9:45 PM;ozheregelya;Build Info:
  indy-node 1.0.111
  indy-anoncreds 1.0.25
  indy-plenum 1.0.97
  sovrin 1.0.23
OS/Platform: Ubuntu 16.04.2 LTS
Setup: performance pool (7 nodes, 4 clients)

Both of cases: sending invalid transactions and valid ones work correctly. 
In case of valid transactions all transactions are written (one problem with sending lots of transactions is INDY-795) for sending transactions one by one and for sending them at once.
In case of invalid transactions only one transaction is written for sending transactions one by one and for sending them at once.
This behavior
{quote}
On 103th transaction Node1C and Node2C appeared in both ackNodes and nackNodes columns of pref_results spreadsheet: perf_results_1_1000_1497994390.csv
The rest transactions were failed. After completion of the test cluster does not send NYMs.
{quote}
is still reproduce, but it doesn't result breaking of the pool. It is moved t separated ticket INDY-793.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] Incorrect output of ping command,INDY-293,18518,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,ozheregelya,ozheregelya,22/Jun/17 12:13 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,Could,,,," 

*Overview:*
 Specifier of formatted output (%s) is shown instead of ip addresses.

*Steps to Reproduce:*
 1. Perform actions of scenario 5 until 'ping Faber' command. ([https://docs.google.com/document/d/1yCGqC1SGru_ajhwE5w94mTlqDXpsRXD-zc-W1PIyTGU/edit#|https://docs.google.com/document/d/1yCGqC1SGru_ajhwE5w94mTlqDXpsRXD-zc-W1PIyTGU/edit])
 2. Perform command 'ping Faber'.

*Actual Results:*
{code:java}
ALICE@test> ping Faber
 Expanding Faber to ""Faber College""
Pinging target endpoint: ('10.0.0.202', 5555)
 Ping sent.
 Pong received from %s
 Pong received.
{code}
 

*Expected Results:*
 Faber IP address should be shown instead of %s.","Build Info:
sovrin-client version: 0.3.145
sovrin-node version: 0.3.141

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy0yf:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 9:03 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need tool to prove two ledgers are identical,INDY-294,18527,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,danielhardman,danielhardman,22/Jun/17 4:53 AM,13/Nov/19 12:37 AM,28/Oct/23 2:46 AM,13/Nov/19 12:37 AM,,,,,0,6Months,should,,,,"Right now, if I am looking at two validator nodes and I want to know that their ledgers are perfectly synced, I can do a rudimentary test by doing a linecount of the two ledgers to see if they are equal. However, this doesn't tell us with 100% confidence that two machines are sync'ed, because of anomalies in line breaks in the ledgers.

What we'd like instead is a tool (libsovrin call? API? CLI command?) where I can say to a node: What's the root hash of your state trie?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzwzb3:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Nov/19 12:37 AM;esplinr;validator-info's ability to return the root hashes of the ledgers is sufficient for this use case.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need to notice problematic nodes,INDY-295,18528,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,danielhardman,danielhardman,22/Jun/17 4:57 AM,10/Oct/19 1:23 AM,28/Oct/23 2:46 AM,10/Oct/19 1:23 AM,,,,,0,6Months,should,,,,"In the ESN, we have a node that regularly experiences disconnects. All the other nodes seem to be up consistently, but this one node is often having trouble.

The same phenomenon is true of the Alpha network.

There is logic in our monitoring plugin where a given node can report problems–but to my knowledge we don't have any feature where all the other nodes will say, ""Hey, node X is constantly going down. Let's complain about it."" We want such problems to become obvious without us proactively scouring the logs ourselves.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzwyyf:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Dec/17 12:45 AM;ashcherbakov;We still don't have good global monitoring/dashboard/statistic. So, this is still the issue.;;;","10/Oct/19 1:23 AM;esplinr;Validator-Info now gives enough information to identity when some validator nodes are having issues. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need to publish (and refresh) the code for validator node console,INDY-296,18529,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,danielhardman,danielhardman,22/Jun/17 4:59 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,should,,,,,"We created some code for a validator node console. Should we publish it? If so, where? (The code is currently outdated and would need updating before it could be useful.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0rj:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/17 6:19 AM;krw910;This will be captured when we implement the monitoring tools.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Timing: Change system clock on one node; many nodes",INDY-297,18530,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,22/Jun/17 5:00 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"Timing: Change system clock on one node; many nodes


Thing tried:
Perform send/get NYM and POOL_UPGRADE commands in pool with one and half nodes with changed system time and time zone.
Change system time for whole pool during POOL_UPGRADE.

Findings:
POOL_UPGRADE command performs correctly during all time changes.
Each node checks system time for other nodes and marks them as malicious if system time doesn't match.",,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0kv:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Timing: Change the meaning of a duration,INDY-298,18531,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,krw910,krw910,22/Jun/17 5:02 AM,08/Oct/19 9:04 PM,28/Oct/23 2:46 AM,08/Oct/19 9:04 PM,,,,,0,explore,,,,,"Timing: Change the meaning of a duration

Things tried:


Findings:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0l3:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Mar/18 9:52 PM;zhigunenko.dsr;[~krw910] what do you mean about the timing and duration?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Timing: VM clock drift,INDY-299,18532,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid: Environment Issue,,krw910,krw910,22/Jun/17 5:03 AM,08/Oct/19 9:04 PM,28/Oct/23 2:46 AM,08/Oct/19 9:04 PM,,,,,0,explore,,,,,"Timing: VM clock drift


Things tried:


Findings:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0lb:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Oct/19 9:04 PM;ashcherbakov;A good advice but out of scope, nothing to be done in code;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Garbage collection of queues: ,INDY-300,18533,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,krw910,krw910,22/Jun/17 5:03 AM,08/Oct/19 9:05 PM,28/Oct/23 2:46 AM,08/Oct/19 9:05 PM,,,,,0,explore,,,,,"Garbage collection of queues: 

Things tried:


Findings:

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0lj:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Mar/18 9:48 PM;zhigunenko.dsr;[~krw910] what do you mean by that?;;;","08/Oct/19 9:05 PM;ashcherbakov;We do have a lot of metrics and graphs now, including RAM, GC metrics, queue size, etc.
This is checked on a regular basis in load tests;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
How is performance affected under load/time: ,INDY-301,18534,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,22/Jun/17 5:05 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"How is performance affected under load/time: 

Things tried:


Findings:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzy0k7:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/18 12:44 PM;krw910;We have results for this in the performance spreadsheet. We found that performance does degrade with time and it is being looked into in sprints 18.01 - 18.02;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Variation in node resources, like nodes with different ram, CPU, filesystems, bandwidth",INDY-302,18535,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid: Environment Issue,,krw910,krw910,22/Jun/17 5:11 AM,08/Oct/19 9:02 PM,28/Oct/23 2:46 AM,08/Oct/19 9:02 PM,,,,,0,explore,,,,,"Variation in nodes, like 3 nodes being 1GB ram and 1vCPU,  4 nodes 4 GB ram and 4vCPU, difference in filesystems, bandwidth

Things tried:


Findings:


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0kf:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Oct/19 9:02 PM;ashcherbakov;Sovrin has Minimal Hardware Requirements for Stewards. Nothing to be done in code.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Network latency/dropped packets,INDY-303,18536,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,krw910,krw910,22/Jun/17 5:25 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"Network latency/dropped packets
What can sovrin tolerate?

Things tried:


Findings:

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzwyov:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/18 12:46 PM;krw910;[~VladimirWork] I did early testing on this which showed poor performance. Once we have stability issues fixed this should be tried again to see what the network can tolerate.;;;","06/Sep/18 5:12 AM;ozheregelya;See results here: INDY-1253;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change IP of node repeatedly (do make the NODE txn though),INDY-304,18537,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,22/Jun/17 5:26 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"Change IP of node repeatedly (do make the NODE txn though)

*Things tried:*

*Case 1:*
*Steps to reproduce:*
1. Switch IP of node via NODE transaction
2. Switch IP of node via Docker 
*Expected results:*
The node reconnects to the pool _or_
Node is demoted but the rest of the pool is alive
*Actual results:* 
The node reconnects to the pool

*Case 2:*
*Steps to reproduce:*
1. Switch port of node via NODE transaction
2. Switch port of node via Docker 
*Expected results:*
The node reconnects to the pool _or_
Node is demoted but the rest of the pool is alive
*Actual results:* 
The node reconnects to the pool

*Case 3:*
*Steps to reproduce:*
1. Switch IP of node via NODE transaction
2. Switch IP of node via NODE transaction (set previous IP)
*Expected results:*
The node reconnects to the pool _or_
Node is demoted but the rest of the pool is alive
*Actual results:* 
The node reconnects to the pool

*Findings:*
There are no issues with redirecting IP/ports
Node successfully reconnects. ViewChange happens if needed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0lr:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node with multiple NICs: ,INDY-305,18538,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,krw910,krw910,22/Jun/17 5:27 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"Node with multiple NICs: 

Things tried:


Findings:

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0hz:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Mar/18 8:27 PM;zhigunenko.dsr;[~krw910] what do you mean by ""NIC"" ?;;;","27/Aug/18 9:07 PM;ozheregelya;See results in INDY-1249 and INDY-1332.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Some nodes are slow to process network data, thus keeping the senders busy",INDY-306,18539,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,krw910,krw910,22/Jun/17 5:29 AM,08/Oct/19 9:05 PM,28/Oct/23 2:46 AM,08/Oct/19 9:05 PM,,,,,0,explore,,,,,"Some nodes are slow to process network data, thus keeping the senders busy 

Things tried:


Findings:

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0lz:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Oct/19 9:05 PM;esplinr;The system currently passes performance tests. Future work will be tracked as a separate issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a lifelike representation of txn traffic in plenum tests,INDY-307,18540,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,krw910,krw910,22/Jun/17 5:32 AM,08/Oct/19 9:03 PM,28/Oct/23 2:46 AM,08/Oct/19 9:03 PM,,,,,0,explore,,,,,"adjust tests: plenum tests operate with a representative group of sovrin txns: Create a lifelike representation of txn traffic

Things tried:


Findings:

",,,,,,,,,,,,,,,,,,,,,,INDY-1607,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0kn:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Oct/19 9:03 PM;ashcherbakov;We have load tests for this now: INDY-1607;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
start node that is in inconsistent state ,INDY-308,18541,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,22/Jun/17 5:33 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"start node that is in inconsistent state 

Things tried:
1. malformed or absent keys files (private_keys, public_keys, sig_keys, verif_keys) in NodeX and NodeXC folders - node doesn't start
2. absent transactions files (pool_transaction_sandbox/1, transactions_sandbox/1, config_transactions/1) - node starts successfully, files create after catchup
3. malformed JSON transactions files pool_transaction_sandbox/1 and config_transactions/1 - node doesn't start
4. malformed non-JSON transactions file transactions_sandbox/1 - node starts successfully
5. absent ldb files (attr_db, config_state, domain_state, idr_cache_db, pool_state, seq_no_db) - node starts and files are recreated
6. malformed ldb files in config_state, domain_state, pool_state - node doesn't start
7. malformed ldb files in attr_db, idr_cache_db, seq_no_db - node starts succesfully

There is an inconsistent behavior in 6th and 7th points, INDY-356 is reported.

Findings:
INDY-356
",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,INDY-356,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0mf:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Dealing with stalled node state,INDY-309,18542,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,krw910,krw910,22/Jun/17 5:36 AM,08/Oct/19 8:48 PM,28/Oct/23 2:46 AM,08/Oct/19 8:48 PM,,,,,0,explore,,,,,"Stalled node state. How does the pool handle a stalled node? How does it affect consensus? Can it process and upgrade?

Things tried:


Findings:

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0fj:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,esplinr,krw910,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/18 4:45 PM;zhigunenko.dsr;[~krw910]
what do you mean by ""stalled state""?;;;","08/Oct/19 8:48 PM;esplinr;We don't think this applies anymore.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] Traceback is shown instead of user-friendly message after starting CLI with invalid content of pool_transactions_sandbox file,INDY-310,18549,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,ozheregelya,ozheregelya,22/Jun/17 6:25 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,should,,,,"*Overview:*
Traceback is shown instead of user-friendly message after starting CLI with invalid content of pool_transactions_sandbox file

*Steps to Reproduce:*
1. Copy transactions_sandbox file content to pool_transactions_sandbox file.
{code:java}
cp ../transactions_sandbox ../pool_transactions_sandbox{code}
2. Try to start the CLI.

*Actual Results:*
CLI was not started, traceback is shown. There are no understandable information about the reason of problem.
{code:java}
ubuntu@irelandStabilityAgent:~/.sovrin$ sovrin
Loading module /usr/local/lib/python3.5/dist-packages/config/config-crypto-example1.py
Module loaded.
Traceback (most recent call last):
 File ""/usr/local/bin/sovrin"", line 78, in <module>
 run_cli()
 File ""/usr/local/bin/sovrin"", line 53, in run_cli
 withNode=withNode
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 113, in __init__
 super().__init__(*args, **kwargs)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 141, in __init__
 ledger)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stack_manager.py"", line 77, in parseLedgerForHaAndKeys
 for _, txn in ledger.getAllTxn().items():
 File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 230, in getAllTxn
 result[seqNo] = self.leafSerializer.deserialize(txn)
 File ""/usr/local/lib/python3.5/dist-packages/ledger/serializers/json_serializer.py"", line 75, in deserialize
 return self.loads(data)
 File ""/usr/local/lib/python3.5/dist-packages/ledger/serializers/json_serializer.py"", line 65, in loads
 return json.loads(data)
 File ""/usr/lib/python3.5/json/__init__.py"", line 319, in loads
 return _default_decoder.decode(s)
 File ""/usr/lib/python3.5/json/decoder.py"", line 339, in decode
 obj, end = self.raw_decode(s, idx=_w(s, 0).end())
 File ""/usr/lib/python3.5/json/decoder.py"", line 357, in raw_decode
 raise JSONDecodeError(""Expecting value"", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0){code}
*Expected Results:*
User-friendly error message should appear.","Build Info:
sovrin-client version: 0.3.147
sovrin-node version: 0.3.140

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy0rr:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:50 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extend the response to the forced POOL_UPGRADE,INDY-311,18559,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,dsurnin,dsurnin,22/Jun/17 10:03 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,should,,,,,"Extend the response to the POOL_UPGRADE transactions with information how many nodes scheduled update, how many nodes wrote transaction to the ledger",,,,,,,,,,,,,,,,,,,,,,,INDY-201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzy0rz:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/17 6:26 AM;krw910;This would be really nice to have, but the system is not designed to do this. You can find the responses on a node in the upgrade logs.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node gets PROPAGATE from a client,INDY-312,18568,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,stevetolman,alexander.shekhovcov,alexander.shekhovcov,23/Jun/17 12:20 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,should,,,,"The test _test_new_node_catchup_update_projection_ generate the following message:
{code:java}
2017-06-22 17:59:35,988 | INFO | node.py (1170) | handleOneNodeMsg | Theta msg validated ({'request': {'reqId': 1498143567022608, 'operation': {'type': '1', 'verkey': '~V58citHknD8gdJqiXEHGQe', 'dest': '5JVfBVWLKvMiEL1JFC6LT5', 'role': '101'}, 'identifier': 'BPtrqHo3WyjmTNpVchEhWxp3qfDdssdFUNoM8kmKoEWw', 'signature': '3XBw87qoFX86RWoBTXu3rAitFta2imwqf9JUw4sJcMmCY5RE3UamkhHHVkG8STFJPVzrR3HijCib1YNXGLHB5oTo'}, 'senderClient': 'L-.wJiB4N{(8[Bxb?:ZboQS?6Q4s+yPXLnTa>Zsq'}, b'OJSTO>6%Ytu@@zuWh>08?F@>}fK:=XD+Ygg8)z{A')
{code}
The message has format:
{code:java}
({'senderClient': <client_id>, 'request': <client request>}, <from>)
{code}
*from* is a name of the sender who has sent the message.

In the example above node Theta gets message from node with name:
{code:java}
b'OJSTO>6%Ytu@@zuWh>08?F@>}fK:=XD+Ygg8)z{A'
{code}
Later, Theta prints:
{code:java}
2017-06-22 17:59:35,996 | WARNING | node.py (2122) | reportSuspiciousNode | Theta raised suspicion on node OJSTO for could not authenticate; suspicion code is 110

{code}
I suspect an error in the test or code either. 

 

I have to add a workaround in [https://github.com/evernym/plenum/pull/224/commits/2650afca2efa185f00f76350470e48039afc5e46#diff-b490c747b8f70e0c134e3cd446406b48R31.]

Please, take care about the workaround (remove or allow byte names).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jun/17 12:13 AM;alexander.shekhovcov;test_new_node_catchup_update_projection.py;https://jira.hyperledger.org/secure/attachment/11310/test_new_node_catchup_update_projection.py",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzy0s7:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jun/17 12:26 AM;alexander.shekhovcov;[~lovesh] Could you comment is it a problem or not?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Catch Up: When a demoted node is added back to the pool will it do a catch up,INDY-313,18572,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,23/Jun/17 12:49 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"Take a node in the pool and as a Trustee demote that node so it does not take part in consensus. 
 Run several transactions on the pool to make sure it is not taking part in consensus or committing transactions to its ledger.
 Now promote the node back into the pool. 
 Does the catch up process happen correctly?

Another test would be to just restart a demoted node and see if it not only catches up but does it also get added back into the pool for consensus by default.

*Things tried:*
 *Case 1:* Promoting node (as Trustee). This case duplicates valid steps of scenarios 7-8:
 1. Add 2 more nodes to pool.
 2. Demote them as Trustee.
 3. Send several NYMs.
 4. Promote the Nodes as Trustee.
 5. Check the transactions files.

*Case 2:* Restart demoted node.
 1. Add 2 more nodes to pool.
 2. Demote them as Trustee.
 4. Send several NYMs.
 5. Restart sovrin-node on the demoted node.
 6. Compare 
 wc -l .sovrin/data/nodes/Node4/transactions_sandbox/1
 wc -l .sovrin/data/nodes/Node5/transactions_sandbox/1

*Case 3:*
 This problem was discussed with developers. Probably it make sense to play with turned on / turned off view change. 
1. Turn off view change.
2. Restart services on Node1 - Node4.
3. Reset Node5 and Node6.
4. Perform steps of Case 1 and Case 2.

*Findings:*

Case 1: after promoting the node, there no messages about catch up in node logs. Files data/nodes/Node5/transactions_sandbox/1 and data/nodes/Node4/transactions_sandbox/1 are still different. Ticket for this problem is INDY-314.

Case 2: count of transactions for demoted and not demoted node are different. So, restart does not affect demotion of node.

Case 3: after several reset of pool, problem with catch up stopped to reproduce. Now catch up works for both of turned on and turned off view change.
Probably there were some problems with configuration of pool, or there were more tricky steps to reproduce. According comment and new logs were added to INDY-314. There is no updates regarding Case2 with turned off view changes, the system works as expected.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,INDY-314,,,,INDY-377,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy23j:",,,,,,H2,H3,,,,,,,,,,,,,,,,,,,aleksey-roldugin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jul/17 7:25 PM;aleksey-roldugin;h6. BUILD

sovrin-node 0.4.9
 sovrin-client 0.4.19

h6. VERIFICATION
*Case 1*
After promotions both nodes made catch up.

*Case 2*
After restart demoted nodes didn't make catch up. After promotion they did.

*Case 3*
Cases 1 and 2 with turned off view change gave same result as with turned on view change.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Catchup did not happen after promotion demoted node.,INDY-314,18576,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ozheregelya,ozheregelya,23/Jun/17 1:56 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,Must,,,,,"*Overview:*
 Catchup was not happened after promotion demoted node.

*Steps to Reproduce:*
 0. Create pool consists of 4 nodes, add 5 and 6 nodes.
 1. Compare count of transactions on all nodes:
{code:java}
wc -l data/nodes/Node4/transactions_sandbox/1
 15 1
 wc -l data/nodes/Node5/transactions_sandbox/1
 15 1{code}
2. Demote Node5 as Trustee.
 3. Send several transactions.
 4. Promote this Node5.
 5. Compare count of transactions again.
{code:java}
wc -l data/nodes/Node4/transactions_sandbox/1
 19 1
 wc -l data/nodes/Node5/transactions_sandbox/1
 15 1{code}
*Actual Results:*
 Transactions file was not synchronized, catchup did not happened.

*Expected Results:*
 Transactions file should be synchronized, catchup should happen.","Build Info:
sovrin-client version: 0.3.22
sovrin-node version: 0.3.24

OS/Platform: Ubuntu 16.04.2 LTS",,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,INDY-313,,,,,,,,"23/Jun/17 1:53 AM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11318/Node1.log","23/Jun/17 1:53 AM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11317/Node2.log","23/Jun/17 1:53 AM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11316/Node3.log","23/Jun/17 1:53 AM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11315/Node4.log","26/Jun/17 8:26 PM;ozheregelya;Node5-catchup.log;https://jira.hyperledger.org/secure/attachment/11375/Node5-catchup.log","23/Jun/17 1:53 AM;ozheregelya;Node5.log;https://jira.hyperledger.org/secure/attachment/11314/Node5.log","26/Jun/17 8:26 PM;ozheregelya;Node6-catchup.log;https://jira.hyperledger.org/secure/attachment/11376/Node6-catchup.log","23/Jun/17 1:53 AM;ozheregelya;Node6.log;https://jira.hyperledger.org/secure/attachment/11313/Node6.log","26/Jun/17 8:26 PM;ozheregelya;cli-catchup.log;https://jira.hyperledger.org/secure/attachment/11374/cli-catchup.log","23/Jun/17 1:53 AM;ozheregelya;cli.log;https://jira.hyperledger.org/secure/attachment/11319/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1tj:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,dsurnin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/17 8:26 PM;ozheregelya;Update: catch up was happened after reset the pool for the same case and the same steps to reproduce. Logs are attached.[^Node6-catchup.log][^Node5-catchup.log][^cli-catchup.log];;;","10/Jul/17 10:39 PM;dsurnin;not reproduced ;;;","14/Jul/17 9:21 PM;ozheregelya;The issue does not reproduce on the latest build.
Build Info:
  sovrin-client version: 0.4.28
  indy-node version: 0.4.28
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 7 nodes, 1 client;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Raet logging causes CLI tests to error,INDY-315,18577,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,mark.hadley,mark.hadley,23/Jun/17 2:58 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,6Months,Could,,,,"plenum/plenum/cli/cli.py
 Line 261
{code:java}
Logger().setupRaet(RAETVerbosity, RAETLogFile)
{code}
This line causes the CLI tests to fail because it it is closing and reiniting the stdout file descriptor, which is killing pytest's ability to capture output.

Commenting this line resolves the test failures.

If we want to have raet logging, this will need to be investigated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-41,,,,,,,,,,"1|hzy0yn:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,mark.hadley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jun/17 3:24 AM;mark.hadley;[https://github.com/evernym/plenum/pull/229]

 ;;;","10/Oct/18 8:19 PM;Derashe;We've get rid of raet and CLI is deprecated client;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sending a POOL_UPGRADE to a version that does not exist puts the pool into a continuous upgrade loop.,INDY-316,18582,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,23/Jun/17 6:13 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,CI/CD/Update,Must,,,,"If you send the pool upgrade transaction and set the version number to something higher than what the pool has installed, but to a version that does not exist the node get stuck in an upgrade loop.

So if your node version is 0.3.24 and the newest version if 0.3.25 you send the command with ""version=0.3.50"". Since 0.3.50 does not exist the nodes will loop trying to upgrade.

You can see this by watching the CLI when it is connected to the pool it will start to repeat disconnects and connects.

The logs are large and it is easy to reproduce so I am not including them.
",,,10800,10800,,0%,10800,10800,,,,,,INDY-251,,,,,,,,,,,,,INDY-723,,,,,,,,"10/Aug/17 5:52 PM;VladimirWork;CASE1.PNG;https://jira.hyperledger.org/secure/attachment/11862/CASE1.PNG","10/Aug/17 5:52 PM;VladimirWork;CASE2.PNG;https://jira.hyperledger.org/secure/attachment/11863/CASE2.PNG","11/Jul/17 1:52 AM;aleksey-roldugin;Node1.log;https://jira.hyperledger.org/secure/attachment/11619/Node1.log","11/Aug/17 6:42 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11869/Screenshot.PNG","12/Aug/17 12:49 AM;VladimirWork;_Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11878/_Screenshot.PNG","10/Aug/17 5:52 PM;VladimirWork;_journalctl_case1.txt;https://jira.hyperledger.org/secure/attachment/11860/_journalctl_case1.txt","10/Aug/17 5:52 PM;VladimirWork;_journalctl_case2.txt;https://jira.hyperledger.org/secure/attachment/11861/_journalctl_case2.txt","11/Jul/17 1:52 AM;aleksey-roldugin;sustemctl -u sovrin-node.service.log;https://jira.hyperledger.org/secure/attachment/11620/sustemctl+-u+sovrin-node.service.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8fz:",,,,,,10,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,andrey.goncharov,krw910,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/17 10:59 PM;ozheregelya;Please, pay attention that check of version should not be ignored when the force=True option is used in POOL_UPGRADE command.;;;","11/Jul/17 1:52 AM;aleksey-roldugin;The same situation occurs when version for upgrade exists but Node cannot upgrade to it for some reason:
{code:java}
2017-07-10 15:50:34,910 | ERROR    | upgrader.py          ( 109) | __init__ | Failed to upgrade node 'Node1' to version 1.8.4
{code}
After upgrade attempt Node rolls back to installed version and performs next upgrade attempt. It continues endlessly. Please find more info in _sustemctl -u sovrin-node.service.log_ and _Node1.log_.
h6. EXPECTED RESULT

Node stops attempting to upgrade after some time.;;;","09/Aug/17 12:34 AM;andrey.goncharov;Problem reason: 

- Missing condition, complex logic

Changes: 
- Logic simplified, missing conditions added

Committed into:
https://github.com/hyperledger/indy-node/commit/e55a99a94aa90e34e22f5d9008446a5c9231fcbd
sovrin-node/master 1.0.82

Risk factors:
Upgrade functionality might get affected.

Risk:
Medium

Covered with tests:
https://github.com/hyperledger/indy-node/commit/e55a99a94aa90e34e22f5d9008446a5c9231fcbd#diff-1f0c4e3f1f9f8b812891c08040f351caR1

Recommendations for QA (optional):
Run several different scenarios to test POOL_UPGRADE still works as expected;;;","10/Aug/17 5:52 PM;VladimirWork;Build Info:
indy-node 1.0.86

Steps to Reproduce - Case 1 (reinstall with force=True):
1. Setup 1.0.86 pool.
2. Send ""send POOL_UPGRADE name=upgrade86 version=1.0.86 sha256=ed0a366b4ef36d40c055672a8b83679e99246fec71a706b4ae4cb7958feace3f action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-10T07:30:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-08-10T07:35:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-08-10T07:40:00.258870+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-08-10T07:45:00.258870+00:00'} timeout=10 force=True reinstall=True
"".

Actual Results:
Some nodes get disconnected and after ~1 minute get connected again.
Upgrade to the same version is *not* performed.
Pool fails to send NYMs after nodes connecting.

Expected Results:
Upgrade should schedule with *any* time (so you can use exact command in step 2) when force=True and perform immediately if scheduled time is less than current time.


Steps to Reproduce - Case 2 (reinstall or upgrade with force=False):
1. Setup 1.0.86 pool.
2. Send ""send POOL_UPGRADE name=upgrade86 version=1.0.86 sha256=ed0a366b4ef36d40c055672a8b83679e99246fec71a706b4ae4cb7958feace3f action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-10T08:40:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-08-10T08:45:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-08-10T08:50:00.258870+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-08-10T08:55:00.258870+00:00'} timeout=10 force=False reinstall=True"".

Actual Results:
Upgrade is performed but nodes reconnect spontaneously and in fact cannot start correctly (so pool is breaked after upgrade).

Expected Results:
Upgrade shoul work normally. [^_journalctl_case1.txt]  [^_journalctl_case2.txt]  !CASE1.PNG|thumbnail!  !CASE2.PNG|thumbnail! 
;;;","10/Aug/17 11:25 PM;andrey.goncharov;[~VladimirWork]

Fixed in 

[sovrin/master 1.0.2|https://github.com/sovrin-foundation/sovrin/commit/0ffb03e38fcb410fbfff280fb905f3a5bb7bd6c5]2

[indy-node/master 1.0.|https://github.com/hyperledger/indy-node/commit/9f1ee314f60ad0e7c3f07c79d0007c733147e728]92

Please try the new build and get back with results;;;","11/Aug/17 6:42 PM;VladimirWork;Build Info:
indy-node 1.0.94

Steps to Validate:
1. Send pool upgrade command with nonexistent version parameter.

Actual Results:
Current version is reinstalled due to unable to find nonexistent version.
This works well with both force parameter values.

Additional Info:
Upgrading and reinstallation with any combinations of schedule/force/reinstall parameters are also checked during regression testing of pool upgrade command.;;;","11/Aug/17 10:07 PM;ozheregelya;{code:java}
root@37da9dab847e:/home/sovrin# systemctl status sovrin-node
● sovrin-node.service - Sovrin Node
 Loaded: loaded (/etc/systemd/system/sovrin-node.service; disabled; vendor preset: enabled)
 Active: inactive (dead)
Aug 11 11:07:11 37da9dab847e env[1387]: File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/upgrade_log.py"", line 34, in
Aug 11 11:07:11 37da9dab847e env[1387]: upgrade_id = item[4]
Aug 11 11:07:11 37da9dab847e env[1387]: IndexError: list index out of range
Aug 11 11:07:12 37da9dab847e systemd[1]: sovrin-node.service: Main process exited, code=exited, status=1/FAILURE
Aug 11 11:07:12 37da9dab847e systemd[1]: sovrin-node.service: Unit entered failed state.
Aug 11 11:07:12 37da9dab847e systemd[1]: sovrin-node.service: Failed with result 'exit-code'.
Aug 11 11:07:22 37da9dab847e systemd[1]: sovrin-node.service: Service hold-off time over, scheduling restart.
Aug 11 11:07:22 37da9dab847e systemd[1]: Stopped Sovrin Node.
Aug 11 11:07:22 37da9dab847e systemd[1]: sovrin-node.service: Start request repeated too quickly.
Aug 11 11:07:22 37da9dab847e systemd[1]: Failed to start Sovrin Node.
{code}
 ;;;","11/Aug/17 11:10 PM;andrey.goncharov;[~ozheregelya]

Fixed in indy-node/master 1.0.98 https://github.com/hyperledger/indy-node/commit/8ef345123fe2f1cd14d89bb9c70bd8130bbb364d;;;","12/Aug/17 12:50 AM;VladimirWork;Special case with upgrade from old version (1.0.78) is checked. Nodes start normally after the upgrade. !_Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Steward is able to send request to demote his own node,INDY-317,18597,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,krw910,ozheregelya,ozheregelya,23/Jun/17 6:43 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Could,,,,,"*Overview:*
Steward is able to send request to demote his own node.

*Case 1:*
*Steps to Reproduce:*
0. Create pool consists of 4 nodes, add 5 and 6 nodes.
1. As Steward of Node 5 send following command:
sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data=\{'alias': 'Node5', 'services': []}
Sending node request for node identifier 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1498209422595095)
Node request completed 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc

*Actual Results:*
Node was not demoted, but in CLI ""Node request completed 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc"" appear.

*Expected Results:*
Error message that Steward can't demote the node should appear.

*Case 2:*
*Steps to Reproduce:*
0. Create pool consists of 4 nodes, add 5 and 6 nodes.
1. As Trustee, blacklist Node 5.
2. As Steward of Node 5 send following command:
sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data=\{'alias': 'Node5', 'services': []}

*Actual Results:*
Node was promoted, following messages appear:
{code:java}
Sending node request for node identifier 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc by EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr (request id: 1498207392204695)
Node request completed 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc
7cb2iGMVsVMAAY13Q63S22RoemYa6Yjq8x7YydKBi54W looking for Node5C at 10.0.0.105:9710
7cb2iGMVsVMAAY13Q63S22RoemYa6Yjq8x7YydKBi54W now connected to Node5C{code}
*Expected Results:*
Error message that Steward can't demote or promote the node should appear.

*Additional Information:*
Logs for Case 2 attached.
This problem was discussed with Kelly and he said that similar problem was found and fixed about several moths ago.","Build Info:
sovrin-client version: 0.3.22
sovrin-node version: 0.3.24

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jun/17 6:43 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11322/Node1.log","23/Jun/17 6:43 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11323/Node2.log","23/Jun/17 6:43 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11324/Node3.log","23/Jun/17 6:43 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11325/Node4.log","23/Jun/17 6:43 PM;ozheregelya;Node5.log;https://jira.hyperledger.org/secure/attachment/11326/Node5.log","23/Jun/17 6:43 PM;ozheregelya;Node6.log;https://jira.hyperledger.org/secure/attachment/11327/Node6.log","23/Jun/17 6:43 PM;ozheregelya;cli.log;https://jira.hyperledger.org/secure/attachment/11321/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1xz:",,,,,,H5,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/17 4:11 AM;krw910;Requirement has changed and a Steward should be able to demote and promote their own node.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance the testing,INDY-318,18598,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,23/Jun/17 6:51 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,REFACTORING,should,,,,"The running time of the plenum tests is around 1 hour. So the approximated build history for the PR-224 looks like:
 * build #1: an error because of the changes in the PR
 * build #2: an intermittent error – test_primary_election_case6
 * build #3: all tests are passed
 * build #4: an intermittent error – testNodeDoesNotParticipateUntilCaughtUp (is triggered by changes in the master)
 * build #5: all tests are passed

Total build time is around 6 hours.  

*The scope:*
 # Speed up the tests
 ** find why a certain test is slow and speed up it
 # Keep the test suite running time under some certain time. Thirty minutes is a great target. 
 ** terminating the whole test suite after the defined time (sounds coarse but otherwise #1 is our permanent task)
 # Some tests do not pass in pycharm but does pass in CI's runner.py (in sovrin-client testAgentCliHelp, testAgentCliForInvalidCommand, ...)
 # Intermittent tests
 ** create a CI pipeline which will continuously build master branch in order to find intermittent tests
 # Sometimes a test fails only on CI and a developer have to wait until whole test suit is passed. It takes tens minutes.
 ** if it is possible CI should output errors as soon as it possible, a developer should not have to wait tens minutes until build finishes. 
 # Run the tests in parallel
 ** could we use *xdist*?",,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,,INDY-380,,,,,,,,,,,,"11/Aug/17 12:04 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11866/Screenshot.PNG","14/Aug/17 8:52 PM;VladimirWork;_Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11885/_Screenshot.PNG","01/Aug/17 8:59 PM;alexander.shekhovcov;enh-tests-time.txt;https://jira.hyperledger.org/secure/attachment/11806/enh-tests-time.txt","11/Aug/17 8:53 PM;alexander.shekhovcov;runner.py;https://jira.hyperledger.org/secure/attachment/11871/runner.py","01/Aug/17 8:56 PM;alexander.shekhovcov;tests.png;https://jira.hyperledger.org/secure/attachment/11805/tests.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8g7:",,,,,,M1 Prelude,10,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,andkononykhin,ashcherbakov,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jul/17 9:09 PM;andkononykhin;Hello, [~stevetolman]

As [~alexander.shekhovcov] described plenum testing slows down development greatly. And it became more sensitive after we had merged it with 3 other repos (state, stp, ledger), so each PR to them (their code) lead to testing plenum's code as well.

We discussed that with [~ashcherbakov] and we think that parallel testing mentioned by [~alexander.shekhovcov] is the preferred option here. And it's very important to achieve progress here asap. Could you consider adding this task to current sprint (e.g. M1)?

Thank you

 ;;;","01/Aug/17 1:44 AM;mzk-vct;*#3* not reproduced ;;;","01/Aug/17 9:09 PM;alexander.shekhovcov;*UPD:*

h4. 1. Speed up the tests

indy-plenum 1.0.77
Total test time: 98 mins

There are no extremely slow tests so this point will save only 10-20 mins if we somehow restrict all test by 60 sec. I suggest skip this.

 !tests.png|thumbnail! 
 [^enh-tests-time.txt] 

h4. 2. Keep the test suite running time under some certain time. 

See #1 above.

h4. 4. Intermittent tests

Fixed in INDY-400;;;","04/Aug/17 4:33 PM;ashcherbakov;Please timebox this to 1-2 more days. Try to come to some reasonable improvement, maybe not a perfect solution.;;;","10/Aug/17 6:41 PM;alexander.shekhovcov;(/) Done.

What have been done:
# [the plenum tests were split on 3 parts in order to run in parallel|https://github.com/hyperledger/indy-plenum/commit/b5899097b4ece6817db30c1082f57e2298905ffe#diff-58231b16fdee45a03a4ee3cf94a9f2c3R29]
# fixed runner.py, run the tests as modules (not as a files)
# [added an option PYTHONASYNCIODEBUG|https://github.com/hyperledger/indy-plenum/commit/b5899097b4ece6817db30c1082f57e2298905ffe#diff-db4046d22a6d11879df365370f43fc74R109]
# [removed extra searching in test logs |https://github.com/hyperledger/indy-plenum/commit/b5899097b4ece6817db30c1082f57e2298905ffe#diff-f405897ac326641a5dd89f55302ff528R247]
# remove some relation between tests
# added xdist support (but xdist is not used for now), also see GroupedLoadScheduling

*Result:*
indy-plenum: *20-30 min* on CI (3 executors)
indy-node: ~20 min on CI (1 executor)

The next steps may be:
* use xdist (all ready for that but some tests are failing)
* speed up the slowest tests (for example view_change suit works 10+ mins)

*How to test:*
* prepare virtual environment for indy-plenum
* install pytest-xdist pypi packet
* checkout indy-plenum repo
* cd into root directory of code
* download runner https://github.com/evernym/jenkins-shared/blob/master/resources/runner.py
* execute `python runner.py --dir plenum --nooutput`

Make sure all tests are passed.


;;;","11/Aug/17 12:04 AM;VladimirWork;Total 1 runs 525 passed, 1 failed, 0 errors, 67 skipped
Failed tests:
plenum/test/test_util.py:test_utc_epoch
Tests run. Returning 256 !Screenshot.PNG|thumbnail! ;;;","14/Aug/17 8:53 PM;VladimirWork;Total 1 runs 561 passed, 0 failed, 0 errors, 67 skipped
Tests run. Returning 0 !_Screenshot.PNG|thumbnail! ;;;","15/Aug/17 4:01 PM;VladimirWork;All plenum tests are passed successfully during 5 full runs (vm configuration should be at least 4GB RAM and 4 cores to avoid resource lack errors).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ID is shown instead of role when the Steward tries to promote his node,INDY-319,18599,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,ozheregelya,ozheregelya,23/Jun/17 6:53 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,Could,,,,"*Overview:*
 ID is shown instead of role when the Steward tries to promote his node.

*Case 1:*
 *Steps to Reproduce:*
 0. Create pool consists of 4 nodes, add 5 and 6 nodes.
 1. As Trustee, blacklist Node 5.
 2. As Steward of Node 5 send following command:
{code:java}
sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'alias': 'Node5', 'services': ['VALIDATOR']}{code}
*Actual Results:*
 Error message is ""Node request failed with error: client request invalid: UnauthorizedClientRequest(""2 not in allowed roles \{'0': []}"",)""

*Expected Results:*
 Role should be shown instead of ID.

*Additional Information:*
Need to verify this case for 
{code:java}
sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'alias': 'Node5', 'services': ['VALIDATOR']}{code}
after fix of INDY-317.","Build Info:
sovrin-client version: 0.3.22
sovrin-node version: 0.3.24

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-773,,,,,,,,,,"1|hzy0yv:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 9:04 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nodes can be made to order bad requests if primary and non primary collude and other honest nodes are slow,INDY-320,18600,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,lovesh,lovesh,23/Jun/17 7:44 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,should,,,,"A node gets a malicious PRE-PREPARE and then a PREPARE by another malicious non-primary supporting the malicious PRE-PREPARE and no other PREPARE are received before the node gets 2f+1 COMMITs, it will order wrong PRE-PREPARE.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-996,,,,,,,,,,"1|hzx1sn:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,lovesh,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jun/17 8:02 PM;ashcherbakov;[~lovesh] But if 2f+1 (n-f, or (n+f+2)/2, or whatever write consensus is) replicas think that PRE-PREPARE is correct, then we should be fine? We are waiting for COMMIT consensus in any case. We will not send PREPARE if the PRE_PREPARE is incorrect. Other valid nodes should also not send PREPARE. 
And we send COMMIT only if we get a consensus of PREPAREs, so most of the replicas think that PREPREPARE is correct.

In other words, we're waiting for consensus of PREPAREs (that is we have a consensus that the PRE_PREPARE from Primary is valid). If only 1 malicious non-primary ignores it and sends PREPARE for incorrect PRE-PREPARE, then we still should be fine. We will not recieve >2f PREPARES in this case.
;;;","29/Jun/17 6:36 AM;stevetolman;@Lovesh, we are going to leave this in the backlog unless you strongly disagree.;;;","23/Dec/17 12:41 AM;ashcherbakov;[~lovesh] is it still the issue? (I think not);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] Clients are not disconnected after 'disconnect' command.,INDY-321,18601,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,ozheregelya,ozheregelya,23/Jun/17 7:52 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,Could,,,,"*Overview:*
Clients are not disconnected after 'disconnect' command.

*Case 1:*
*Steps to Reproduce:*
1. Open the CLI.
2. Connect to test environment.
=>
{code:java}
Active client set to sovrinc202f9
7cb2iGMVsVMAAY13Q63S22RoemYa6Yjq8x7YydKBi54W listening for other nodes at 0.0.0.0:6001{code}
3. Disconnect and connect to test again.
=>
{code:java}
Active client set to sovrin979c9c
4wZcFMZyzjijDQib1g7x2engkg6vGYbBMNBMsyYwVxW9 listening for other nodes at 0.0.0.0:6002{code}
4. Restart any of nodes. Look at the CLI, during restart.

*Actual Results:*
Following messages are shown not only for current client (4wZcFMZyzjijDQib1g7x2engkg6vGYbBMNBMsyYwVxW9). It is shown for previously connected client (7cb2iGMVsVMAAY13Q63S22RoemYa6Yjq8x7YydKBi54W) too:
{code:java}
4wZcFMZyzjijDQib1g7x2engkg6vGYbBMNBMsyYwVxW9 disconnected from Node4C
7cb2iGMVsVMAAY13Q63S22RoemYa6Yjq8x7YydKBi54W disconnected from Node4C
7cb2iGMVsVMAAY13Q63S22RoemYa6Yjq8x7YydKBi54W now connected to Node4C
4wZcFMZyzjijDQib1g7x2engkg6vGYbBMNBMsyYwVxW9 now connected to Node4C{code}
*Expected Results:*
These messages should be shown only for current client.

*Additional Information:*
These messages for all clients are shown in logs too.","Build Info:
sovrin-client version: 0.3.22
sovrin-node version: 0.3.24

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy0z3:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 9:05 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Keyring files encryption,INDY-322,18604,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Won't Do,andkononykhin,andkononykhin,andkononykhin,23/Jun/17 8:57 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,6Months,,,,,For now keyring files are stored on disk and kept in memory without any encryption. This task created to discuss and implement logic of secure keyring data management.,,,97200,0,,0%,97200,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-55,,,,,,,,,,"1|hzy0sf:",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,ashcherbakov,farooq_m_khan,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jun/17 10:14 PM;andkononykhin;[~danielhardman] [~farooq_m_khan] [~ashcherbakov] [~jlaw 1] [~gudkov]

I've made some research and want to suggest the following PoA for the task.

*PoA*

[https://docs.google.com/document/d/1xz_XllrCACfJp4-kcY-N3pBO4sIKdF0ytGpBKdTqxBE/edit];;;","30/Jun/17 5:39 AM;stevetolman;Let's look at this when we cut over to using libsovrin.

(Converting this subtask to a story.);;;","01/Jul/17 7:22 PM;farooq_m_khan;[~andkononykhin] I added a few comments to the Google Doc you created, Thanks;;;","05/Jul/17 3:04 AM;andkononykhin;[~farooq_m_khan] Thank you. I added replies to poa docs.;;;","10/Jul/17 9:54 PM;farooq_m_khan;[~andkononykhin] I discussed my security concerns with approach number one of encrypting individual keys verses entire file. And my concerns were resolved. I am okay with you following either approach. Thanks;;;","10/Jul/17 11:06 PM;andkononykhin;[~farooq_m_khan] I see. Thank you for participating.;;;","23/Dec/17 12:39 AM;ashcherbakov;This is about old CLI. I think we should close it as Won't Fix.
The new libindy CLI supports encrypted wallets, but they are not encypted by default.
I suggest that [~gudkov] will think about it in terms of new CLI and create a task there if needed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Set more restrictive permissions for keyring files/dirs,INDY-323,18605,17098,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,andkononykhin,andkononykhin,23/Jun/17 9:05 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"For now keyring files have  the following permissions: 755 (drwxr-xr-x) for dirs,  644 (\-rw\-r\-\-r\-\-) for files.

Need to fix that to make them readable/writable only for owner (sovrin): 0700 (dirs), 0600 (files)",,,97200,32400,,0%,97200,32400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy5hj:",,,,,,H2,H3,H4,,,,,,,,,,,,,,,,,,andkononykhin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jul/17 12:51 AM;andkononykhin;Hello, [~krw910]

Task is resolved.

Please test it in the following way:

     Env: master repos, sovrin-node=0.4.14, sovrin-client=0.4.24
 # setup pool of nodes
 # run sovrin client and do *connect test* command. As usual you will see output about created / restored keyring
 # exit client and check  *.sovrin/keyrings* in the following way:

{code:java}
sovrin@2f3b4dcf5d9c:~/.sovrin$ ls -Ral keyrings/  
keyrings/: 
total 12 
drwx------  3 sovrin sovrin 4096 Jul  7 15:40 . 
drwxr-xr-x 18 sovrin sovrin 4096 Jul  7 15:40 .. 
drwx------  2 sovrin sovrin 4096 Jul  7 15:40 test 
 
keyrings/test: 
total 12 
drwx------ 2 sovrin sovrin 4096 Jul  7 15:40 . 
drwx------ 3 sovrin sovrin 4096 Jul  7 15:40 .. 
-rw------- 1 sovrin sovrin  834 Jul  7 15:40 default.wallet{code}
As you can see *.sovrin/keyrings* itself and all subdirs have 0700 permissions, and wallet file has 0600 as expected in current task.

 

Thank you;;;","12/Jul/17 9:39 PM;ozheregelya;*Build Info:*
  sovrin-client version: 0.4.26
  sovrin-node version: 0.4.18
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 7 nodes, 1 client

*Steps to Validate:*
1. Set up the pool.
2. Open the CLI, connect to test.
3. Check .sovrin/keyrings permissions and permissions for each wallet.

*Actual Results:*

 
{code:java}
sovrin@sovrin-VirtualBox:~/.sovrin/keyrings$ ll test/
total 16
drwx------ 2 sovrin sovrin 4096 jul 12 14:55 ./
drwx------ 4 sovrin sovrin 4096 jul 12 14:55 ../
-rw------- 1 sovrin sovrin 834 jul 12 14:01 default.wallet
-rw------- 1 sovrin sovrin 833 jul 12 14:55 oztest.wallet{code}
 

 
{code:java}
sovrin@sovrin-VirtualBox:~/.sovrin/keyrings$ ll live/
total 16
drwx------ 2 sovrin sovrin 4096 jul 12 14:57 ./
drwx------ 5 sovrin sovrin 4096 jul 12 14:56 ../
-rw------- 1 sovrin sovrin 834 jul 12 14:56 default.wallet
-rw------- 1 sovrin sovrin 834 jul 12 14:57 oz2test.wallet{code}
 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Node1 was broken after sending upgrade command,INDY-324,18609,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,aleksey-roldugin,aleksey-roldugin,23/Jun/17 11:16 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,Stability,,,,"h6. BUILD

sovrin-node 0.3.154
 sovrin-client 0.3.145

PRECONDITIONS
 Issue was found on [Pool 3|https://docs.google.com/spreadsheets/d/1dQs2101Xcb9HMJQufLgtmiHxA-apbjnbXn8CGiCDHp0/edit#gid=0].
h6. STEPS TO REPRODUCE
 # Send upgrade command from the client:

{code:java}
sovrin@test> send POOL_UPGRADE name=update_to_node_155 version=0.3.155 sha256=aad1143 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv':'2017-06-23T09:20:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb':'2017-06-23T09:25:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-06-23T09:30:00.258870+00:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-06-23T09:35:00.258870+00:00','C7Ts1WoZwBfq1VmRUE9vUtj9XGBp1EZfySh5mhMWsTPp':'2017-06-23T09:40:00.258870+00:00'} timeout=10
{code}
h6. ACTUAL RESULT
 - Node 1 wasn't upgraded (please see logs from node)
 - After upgrade of of Node4, Node1 was disconnected for some reason and crashed (2017-06-23 09:35:51,002 | INFO | looper.py ( 267) | shutdown | Looper shutting down now...)
 - At the same time Node1 has ""active (running)"" status.

h6. ADDITIONAL INFORMATION
{code:java}
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: Traceback (most recent call last):
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:   File ""/usr/local/bin/start_sovrin_node"", line 50, in <module>
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:     looper.run()
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:   File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 284, in __exit__
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:     self.shutdownSync()
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:   File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 280, in shutdownSync
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:     self.loop.run_until_complete(self.shutdown())
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:   File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:     return future.result()
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:   File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:     raise self._exception
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:   File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:     result = coro.send(None)
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:   File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 270, in shutdown
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:     await self.runFut
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:   File ""/usr/lib/python3.5/asyncio/futures.py"", line 363, in __iter__
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:     return self.result()  # May raise too.
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:   File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]:     raise self._exception
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jun/17 11:16 PM;aleksey-roldugin;Node1.log;https://jira.hyperledger.org/secure/attachment/11328/Node1.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8gf:",,,,,,10,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ashcherbakov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jun/17 11:20 PM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","28/Jun/17 2:47 AM;aleksey-roldugin;{code:java}
ubuntu@saopauloShakeP3:~$ sudo systemctl status sovrin-node
● sovrin-node.service - Sovrin Node
Loaded: loaded (/etc/systemd/system/sovrin-node.service; disabled; vendor preset: enabled)
Active: active (running) since Thu 2017-06-22 16:50:08 UTC; 5 days ago
Main PID: 14154 (start_sovrin_no)
Tasks: 4
Memory: 45.7M
CPU: 3h 54min 55.815s
CGroup: /system.slice/sovrin-node.service
└─14154 /usr/bin/python3 /usr/local/bin/start_sovrin_node Node1 9701 9702

Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: state.revertToHead(stateRootHash)
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: File ""/usr/local/lib/python3.5/dist-packages/state/pruning_state.py"", line 80, in revertToHead
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: head = self._trie._decode_to_node(headHash)
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: File ""/usr/local/lib/python3.5/dist-packages/state/trie/pruning_trie.py"", line 334, in _decode_
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: o = rlp.decode(self._db.get(encoded))
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: File ""/usr/local/lib/python3.5/dist-packages/state/db/persistent_db.py"", line 10, in get
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: return self._keyValueStorage.get(key)
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: File ""/usr/local/lib/python3.5/dist-packages/state/kv/kv_store_leveldb.py"", line 38, in get
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: return self._db.Get(key)
Jun 23 09:35:51 saopauloShakeP3.qatest.evernym.com start_sovrin_node[14154]: KeyError
{code};;;","04/Aug/17 4:56 PM;ashcherbakov;[~ozheregelya] Can you please check that the issue is still reproduced?;;;","04/Aug/17 6:59 PM;ozheregelya;Initial problem is not reproduced on the latest version:
h6. Build Info:

  indy-node 1.0.77 (upgrade from 1.0.72 to 1.0.77)
  indy-anoncreds 1.0.22
  indy-plenum 1.0.79
  sovrin 1.0.15
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes (shakedown pool 3), 1 client
h6. Steps to Reproduce:

1. Send POOL_UPGRADE:
{code:java}
sovrin@test> send POOL_UPGRADE name=upgrade-00000 version=1.0.77 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a
3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-03T16:45:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLg
p6EPhWXtaYyStWPSGAb': '2017-08-03T16:50:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-08-03T16:55:00.000000+0
0:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-08-03T17:00:00.000000+00:00'} timeout=10{code}
h6. Actual Results:

Pool was upgraded without any issues.

 ;;;","04/Aug/17 7:26 PM;ashcherbakov;I don't see any issues with the logs. Unfortunately, the logs are on INFO level (not Debug).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Installation of sovrin-client does not include pool_transactions_live file,INDY-325,18616,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,krw910,krw910,24/Jun/17 2:02 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"I am unable to connect to the alpha network because when I install the sovrin-client the pool_transactions_live file is not included.

The files are located here
https://github.com/sovrin-foundation/sovrin-common/tree/stable/data

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jul/17 5:43 AM;krw910;Missing Files.JPG;https://jira.hyperledger.org/secure/attachment/11745/Missing+Files.JPG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1tr:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,andrey.goncharov,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/17 1:55 AM;spivachuk;Problem state:
* Not reproduced for me.

OS:
* Ubuntu 16.04 VM

Software version:
* sovrin_node 0.4.20 master deb package;;;","13/Jul/17 5:24 AM;krw910;Unable to preform and install at this time due to dependency mismatch of plenum.;;;","18/Jul/17 6:48 AM;slafranca;Tested with: 
indy-plenum 0.4.50
indy-anoncreds 0.4.15 
indy-node 0.4.39

The pool_transactions_live file is not in the client directory (.sovrin).;;;","20/Jul/17 8:00 PM;andrey.goncharov;Can not reproduce on sovrin/master 0.2.10, indy-node/master 0.4.52;;;","20/Jul/17 11:57 PM;krw910;[~andrey.goncharov] I don't think we are looking at the same thing. The pool_transactions_live file is in the node location not in the location the client reads from to connect to a pool.

*Below is what I see from my screen.*
# I run the sovrin install as the user ""agent""
# After installation I run generate_sovrin_pool_transactions for the sandbox pool
# Now switch to the .sovrin directory of the user
# You can see below that there is no pool_transactions_live file
# Start sovrin
# Try to connect to live and you will see below that you cannot connect to live because there is no live file

I understand the file is on disk, but it is in the sovrin users area where the node is installed

*Directory after installation*
{code}
agent@agent01:~$ cd .sovrin/
agent@agent01:~/.sovrin$ ll
total 16
drwxrwxr-x 2 agent agent 4096 Jul 20 14:33 ./
drwxr-xr-x 4 agent agent 4096 Jul 20 14:44 ../
-rw-rw-r-- 1 agent agent 1260 Jul 20 14:33 pool_transactions_sandbox
-rw-rw-r-- 1 agent agent 738 Jul 20 14:33 transactions_sandbox
agent@agent01:~/.sovrin$
{code}

*{color:#d04437}Cannot connect to live{color}*
{code}
sovrin> connect live
Do not have information to connect to live
Usage:
connect <test|live>
sovrin>
{code};;;","21/Jul/17 12:17 AM;andrey.goncharov;[~krw910] oh, I get it now. Will fix;;;","21/Jul/17 12:46 AM;andrey.goncharov;Problem reason: 
- MIssing build instructions

Changes: 
- Build instructions added

Committed into:
https://github.com/sovrin-foundation/sovrin/commit/da9246ad226f2b6fd75bea157bb8d55f9f52acf0
sovrin/master 0.2.11

Risk factors:
 Nothing is expected.

Risk:
 Low;;;","22/Jul/17 2:05 AM;krw910;[~andrey.goncharov] I checked build 0.2.11 and the pool_transactions_live file is still not present after installation.
indy-plenum=0.4.66
indy-anoncreds=0.4.18
indy-node=0.4.55
sovrin=0.2.11
;;;","22/Jul/17 6:41 PM;andrey.goncharov;[~krw910] I recorded a demo that these files are present on a brand new VM for a newly created user agent after installing sovrin package. Please check your setup or try on a brand new VM. If you still have the issue please provide me with an access to the odd behaving machine.

https://drive.google.com/open?id=0BxskuV-A2bahR2xZV0g3eWxPQkk;;;","23/Jul/17 5:45 AM;krw910;[~andrey.goncharov] I could not get the video to play. I don't know what we are doing different, but I see the same issue with every fresh install. I have attached a screenshot and will slack you the login information for the machines. I just did an install today and have not touch them so they are all yours. Let me know when you are done with them.

*Install Line in AWS Template*

""DEBIAN_FRONTEND=noninteractive apt-get install -y tmux vim wget dialog figlet unzip make screen mlocate mc debsigs debsig-verify apt-transport-https python-pip python3-pip python3.5-dev libsodium18 sovrin\n"",

""su - agent -c ""generate_sovrin_pool_transactions --nodes 4 --clients 4 --ips '10.0.0.101,10.0.0.102,10.0.0.103,10.0.0.104'""

*Versions*
dpkg -l | grep 'indy-plenum'
dpkg -l | grep 'indy-anoncreds'
dpkg -l | grep 'indy-node'
dpkg -l | grep 'sovrin'
------------------
indy-plenum=0.4.67
indy-anoncreds=0.4.18
indy-node=0.4.56
sovrin=0.2.11
----------------------
;;;","23/Jul/17 8:58 PM;andrey.goncharov;[~krw910] please take a look at the demo I recorded on the very machine you have troubles with.

[https://drive.google.com/open?id=0BxskuV-A2bahYkJNUmZXQnFzWEU]

As to your installation on AWS, it looks like you run apt-get install directly from root. This way our scripts do not know where transaction files should be copied. If you connect to client1 machine you'll see there's .sovrin folder in /home. It most probably happens because you run install from root. I'd advise you to run install from the user you want to work as with elevated (sudo) privileges

P.S. I also slacked it to you in case you can't play it;;;","24/Jul/17 4:19 AM;krw910;Turns out our install scripts are installing as root and this is a know issue with installing as root. If you install as the user it works.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Steward cannot add validator status to their node if that parameter was left off when adding the node,INDY-326,18622,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,zhigunenko.dsr,krw910,krw910,24/Jun/17 4:15 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,should,,,,"If a Steward forgets to add the parameter ""services : ['VALIDATOR']"" when adding their node to the pool they are unable to correct it.

Adding a node by a Steward happens by sending the following command
{code}
send NODE dest=<nodeID> data={'client_port': 9702, 'client_ip': '<node IP>', 'alias': '<node name>', 'node_ip': '<node IP>', 'node_port': 9701, 'services': ['VALIDATOR']}
{code}

If the parameter 'services': ['VALIDATOR'] was left off when the command was sent they are not allowed to send the command a second time to correct it. 
{color:#d04437}You will get the following error:{color}
{code}
Node request failed with error: client request invalid: UnauthorizedClientRequest(""2 not in allowed roles {'0': []}"",)
{code}

{color:#14892c}The work around is to have a Trustee send the following two commands:{color}
{code}
send NODE dest=<nodeID> data={'alias': '<node name>', 'services': []}
{code}
followed by:
{code}
send NODE dest=<nodeID> data={'alias': '<node name>', 'services': ['VALIDATOR']}
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-233,,,,,,,,"08/Sep/17 8:26 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/12045/Screenshot.PNG","08/Sep/17 8:26 PM;VladimirWork;_node1.log;https://jira.hyperledger.org/secure/attachment/12046/_node1.log","08/Sep/17 8:26 PM;VladimirWork;_node2.log;https://jira.hyperledger.org/secure/attachment/12047/_node2.log","08/Sep/17 8:26 PM;VladimirWork;_node3.log;https://jira.hyperledger.org/secure/attachment/12048/_node3.log","08/Sep/17 8:26 PM;VladimirWork;_node4.log;https://jira.hyperledger.org/secure/attachment/12049/_node4.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-773,,,,,,,,,,"1|hzx0sn:",,,,,,14,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,VladimirWork,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Aug/17 5:43 AM;krw910;Retest now that Stewards can promote their nodes;;;","08/Sep/17 8:27 PM;VladimirWork;Build Info:
indy-node 1.1.132

Reason for Reopen:
Pool doesn't work after 'services': ['VALIDATOR'] request is performed.

Steps to Reproduce:
1. new key with seed StewardNode500000000000000000000
2. send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.0.0.105', 'alias': 'Node5', 'node_ip': '10.0.0.105', 'node_port': 9701}
3. send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.0.0.105', 'alias':'Node5', 'node_ip': '10.0.0.105', 'node_port': 9701, 'services': ['VA
LIDATOR']}
4. send NYM dest=PMfg4jbTSUVQzzGQhwLB7e

Actual Results:
Steps 2,3 are performed successfully. NYM adding in Step 4 is failed. Nodes 1,2,3 are restarted spontaneously after Step 3. Node 4 log has the next error:
Executing <Task finished coro=<Looper.runForever() done, defined at /usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py:217> exception=PublicKeyNotFoundOnDisk(""Node4 could not get Node5's public key from disk. Make sure the keys are initialized for this remote or provided explicitly."",)> took 0.238 seconds (the same as in INDY-233, see attached logs for more info).

Expected Results:
Nodes should not be restarted after the node promotion. Pool should work normally after the node promotion.;;;","23/Dec/17 12:36 AM;ashcherbakov;I believe this still needs to be fixed.;;;","07/Nov/18 7:55 PM;zhigunenko.dsr;*Environment:*
indy-node                  1.6.656

*Steps To Validate:*
1) Create pool with 4 nodes
2) Add new node without ['validator']
3) Promote node 5

*Actual Results:*
1) Node has been joined to pool
2) Catchup finished successfully;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[SEND ATTRIB] CLI may crash in case of unexpected symbols in raw variable,INDY-327,18647,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,stevetolman,aleksey-roldugin,aleksey-roldugin,24/Jun/17 10:13 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,CloseCandidate,should,,,,"h6. BUILD

sovrin-node 0.3.159
 sovrin-client 0.3.143

PRECONDITIONS
 Issue was found on [Pool 2|https://docs.google.com/spreadsheets/d/1dQs2101Xcb9HMJQufLgtmiHxA-apbjnbXn8CGiCDHp0/edit#gid=0].

h6. STEPS TO REPRODUCE
 # Run sovrin-client in environment with not UTF-8 encoding:

{code:java}
sovrin@sovrin-VirtualBox:~$ env LANG=C sovrin
{code}
or
{code:java}
sovrin@sovrin-VirtualBox:~$ env LANG=ru_RU.cp1251 sovrin
{code}
# Connect to test and run SEND ATTRIB command with any unexpected unicode symbol (ex. ©)

{code:java}
sovrin@test> send ATTRIB  dest=v8HcafSBNPoJvRs3ZSXT8 raw={""12"":""?""}
--- Logging error ---
Traceback (most recent call last):
  File ""/usr/lib/python3.5/logging/__init__.py"", line 982, in emit
    stream.write(msg)
UnicodeEncodeError: 'ascii' codec can't encode character '\xae' in position 147: ordinal not in range(128)
Call stack:
  File ""/usr/local/bin/sovrin"", line 78, in <module>
    run_cli()
  File ""/usr/local/bin/sovrin"", line 56, in run_cli
    looper.run(cli.shell(*commands))
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 254, in run
    return self.loop.run_until_complete(what)
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 375, in run_until_complete
    self.run_forever()
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 345, in run_forever
    self._run_once()
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 1312, in _run_once
    handle._run()
  File ""/usr/lib/python3.5/asyncio/events.py"", line 125, in _run
    self._callback(*self._args)
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 307, in _wakeup
    self._step()
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
    result = coro.send(None)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 233, in wrapper
    results.append(await coro)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1119, in shell
    self.parse(c)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1900, in parse
    extra={""cli"": False})
Message: 'CLI command entered: send ATTRIB  dest=v8HcafSBNPoJvRs3ZSXT8 raw={""12"":""\xae""}'
Arguments: ()
Adding attributes {""12"":""?""} for v8HcafSBNPoJvRs3ZSXT8
sovrin@test> --- Logging error ---
Traceback (most recent call last):
  File ""/usr/lib/python3.5/logging/__init__.py"", line 982, in emit
    stream.write(msg)
UnicodeEncodeError: 'ascii' codec can't encode character '\xae' in position 599: ordinal not in range(128)
Call stack:
  File ""/usr/local/bin/sovrin"", line 78, in <module>
    run_cli()
  File ""/usr/local/bin/sovrin"", line 56, in run_cli
    looper.run(cli.shell(*commands))
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 254, in run
    return self.loop.run_until_complete(what)
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 375, in run_until_complete
    self.run_forever()
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 345, in run_forever
    self._run_once()
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 1312, in _run_once
    handle._run()
  File ""/usr/lib/python3.5/asyncio/events.py"", line 125, in _run
    self._callback(*self._args)
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 307, in _wakeup
    self._step()
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
    result = coro.send(None)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 218, in runForever
    await self.runOnceNicely()
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 202, in runOnceNicely
    msgsProcessed = await self.prodAllOnce()
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 147, in prodAllOnce
    s += await n.prod(limit)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", line 188, in prod
    s = await super().prod(limit)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 239, in prod
    s = await self.nodestack.service(limit)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 1202, in service
    c = await super().service(limit)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 570, in service
    return self.processReceived(pracLimit)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 675, in processReceived
    self.msgHandler((msg, frm))
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", line 103, in handleOneNodeMsg
    super().handleOneNodeMsg(wrappedMsg, excludeFromCli)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 280, in handleOneNodeMsg
    extra={""cli"": printOnCli})
Message: 'Client 55ysjckjmJtgMyZccXdRPKEQRbCvLit9B4d7iPktAc9H got msg from node Node4C: {\'result\': {\'signature\': \'5HwSRwfUJavNkU5mb9GZjMzWh7CJw21qNk1n8b2fHUfE49ssnV2eoLos2z'
Arguments: ()
sovrin@test> 
Active keyring ""Default-a53dab"" saved (/home/sovrin/.sovrin/keyrings/test/default-a53dab.wallet)
Goodbye.
Traceback (most recent call last):
  File ""/usr/local/bin/sovrin"", line 78, in <module>
    run_cli()
  File ""/usr/local/bin/sovrin"", line 56, in run_cli
    looper.run(cli.shell(*commands))
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 284, in __exit__
    self.shutdownSync()
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 280, in shutdownSync
    self.loop.run_until_complete(self.shutdown())
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
    return future.result()
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
    raise self._exception
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
    result = coro.send(None)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 270, in shutdown
    await self.runFut
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 363, in __iter__
    return self.result()  # May raise too.
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
    raise self._exception
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
    result = coro.send(None)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 218, in runForever
    await self.runOnceNicely()
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 202, in runOnceNicely
    msgsProcessed = await self.prodAllOnce()
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 147, in prodAllOnce
    s += await n.prod(limit)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", line 188, in prod
    s = await super().prod(limit)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 239, in prod
    s = await self.nodestack.service(limit)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 1202, in service
    c = await super().service(limit)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 570, in service
    return self.processReceived(pracLimit)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 675, in processReceived
    self.msgHandler((msg, frm))
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", line 103, in handleOneNodeMsg
    super().handleOneNodeMsg(wrappedMsg, excludeFromCli)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 313, in handleOneNodeMsg
    result)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/persistence/client_req_rep_store_file.py"", line 83, in addReply
    self.delimiter, serializedReply))
  File ""/usr/local/lib/python3.5/dist-packages/ledger/stores/directory_store.py"", line 44, in appendToValue
    f.write(value)
UnicodeEncodeError: 'ascii' codec can't encode character '\xae' in position 218: ordinal not in range(128)
{code}

h6. EXPECTED RESULT
Probably values for attributes (for _raw_ parameter for now since _hash_ and _enc_ are not implemented) should have some validation.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy0v3:",,,,,,,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jun/17 10:13 PM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","29/Jun/17 4:27 AM;krw910;I think this is covered by INDY-15;;;","05/Dec/17 8:53 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Enhancement][GET_NYM] Command should not require key presence in keyring,INDY-328,18650,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Lowest,Won't Do,krw910,aleksey-roldugin,aleksey-roldugin,24/Jun/17 11:23 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,CloseCandidate,Could,,,,"h6. BUILD

sovrin-node 0.3.159
sovrin-client 0.3.143

h6. STEPS TO REPRODUCE
# Run sovrin-client.
# Create new keyring:
{code:java}
sovrin> new keyring testKeyring
New keyring testKeyring created
Active keyring set to ""testKeyring""
{code}
# Connect to test and try to run GET_NYM command:
{code:java}
sovrin@test> send GET_NYM dest=v8HcafSBNPoJvRs3ZSXT8
No key present in keyring

Usage:
    new key [with seed <32 byte string>]

{code}

h6. EXPECTED RESULT
Sending GET_NYM without key in keying should be allowed because 
* there is no check for key for GET_NYM operation in sovrin-node logic
* signing key with not added to ledger verkey could be used (in this case sender's authenticity cannot be verified)
{code:java}
sovrin@test> new key
Key created in keyring testKeyring
Identifier for key is E6bJzj9AesgcQVB6mrhp9n1iSd5eAt89oC4rivTCYs16
Current identifier set to E6bJzj9AesgcQVB6mrhp9n1iSd5eAt89oC4rivTCYs16
sovrin@test> send GET_NYM dest=v8HcafSBNPoJvRs3ZSXT8
Getting nym v8HcafSBNPoJvRs3ZSXT8
No verkey ever assigned to the identifier v8HcafSBNPoJvRs3ZSXT8
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0vb:",,,,,,,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jun/17 11:25 PM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","05/Dec/17 8:54 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
View Change can fail to complete in some cases,INDY-329,18663,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,lovesh,lovesh,26/Jun/17 5:43 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"A test leads to nodes have different prepared certificates, eg. in a 4 node scenario, here f+1 nodes have one prepared certificate and another f+1 nodes have a different prepared certificate. 

{code}
2017-06-24 15:38:32,204 | DEBUG    | replica.py           (425) | on_view_change_start | Gamma:0 setting last prepared for master to (1, 4)
2017-06-24 15:38:32,219 | DEBUG    | replica.py           (425) | on_view_change_start | Delta:0 setting last prepared for master to (1, 3)
2017-06-24 15:38:32,238 | DEBUG    | replica.py           (425) | on_view_change_start | Alpha:0 setting last prepared for master to (1, 4)
2017-06-24 15:38:32,256 | DEBUG    | replica.py           (425) | on_view_change_start | Beta:0 setting last prepared for master to (1, 3)
{code}

A possible solution to this after a few catchup rounds, any prepared certificates get rejected. Or we build the capability to request 3PC message which is the correct thing to do",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1tz:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jul/17 4:40 AM;lovesh;This has been resolved as part of INDY-13, relevant test `test_view_change_after_max_catchup_rounds` in `plenum/test/view_change/test_view_change_max_catchup_rounds.py`. Also capability is request messages from other nodes is built as part of INDY-246;;;","13/Jul/17 5:25 AM;krw910;Blocked by INDY-406;;;","18/Jul/17 12:44 PM;krw910;We are still seeing issues around Pre-Prepare which I believed are captured in INDY-246 which I just sent back so I am passing this ticket on and propose we mark this one done. We will track the Pre-Prepare issue with INDY-246.;;;","18/Jul/17 12:45 PM;krw910; 

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[send NYM] Incorrect verkey validation,INDY-330,18670,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,VladimirWork,VladimirWork,26/Jun/17 11:48 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"Build Info:
sovrin-client 0.3.145

Overview:
Incorrect verkey validation.

Steps to Reproduce - Case 1:
1. Add verkey ""8RBNqGxt6TsUL4uHQmpy4r~"" to any identifier ->
 validation error: value length 23 is not in ranges [range(43, 46)]
2. Add verkey ""~8RBNqGxt6TsUL4uHQmpy4r~"" to any identifier ->
 validation error: should not contains chars other than {%list of chars that doesn't contain ~%}
3. Add verkey ~8RBNqGxt6TsUL4uHQmpy4r to any identifier ->
 success (but this verkey contains the same 23 symbols as in step 1 and has the symbol that is not in list in the step 2).
4. Add verkey ""~"" any identifier ->
 validation error: value length 0 is not in ranges [range(15, 26)]

Expected Results:
Clarification is needed, see additional info.

Additional info:
Why the presence of ""~"" as the first symbol changes ranges of validation from (43, 46) to (15, 26) and this symbol is not in list of valid symbols?",,,,,,,,,,,,,,INDY-110,,,,,,,,,,,,,,,,,,,,,"26/Jun/17 11:47 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11377/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy73r:",,,,,,H4,,,,,,,,,,,,,,,,,,,,devin-fisher,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/17 11:50 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","27/Jun/17 12:41 AM;VladimirWork;Error messages have changed in the latest master (0.3.150), but the bug is still reproducing.;;;","29/Jun/17 6:33 AM;stevetolman;Devin, what should happen with this ticket? Is it invalidated by your ticket on verkeys?;;;","01/Jul/17 3:26 AM;devin-fisher;This looks like it is working as designed.  

The verkey is transmitted as base58. Normally it is 32-byte integer but can be abbreviated.  The '~' signifies that the verkey is abbreviated. When abbreviated it is only 16-byte integer. So that is why you are seeing the different ranges.

 

I think this ticket can be voided. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
make keep-alive mechanism more robust,INDY-331,18672,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,danielhardman,danielhardman,27/Jun/17 12:10 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"After a lot of experimentation, we have determined that the bug we are seeing with Unicorn, where a validator node seems to disconnect, is caused by failure of keepalives. We ran an experiment where we sent a transaction through the pool every few seconds, and the node maintained its connection for 24 hours without any trouble. This means the reason for the keepalive failure is likely that a firewall in front of the problem node decided to kill idle sessions and didn't send signals in all directions.

What we need to do is make our keepalive more robust. If the theory of [~dfarns] is correct, we may have a constant that has units of seconds where we thought it was milliseconds–but even if that turns out to be true, I recommend that we consider pinging any node that hasn't talked to us for, say, 15 seconds. This would shift the keepalive burden from low-level sockets config to higher-level protocol.
h4. App level heartbeats:

*Merits: cross-platform, transport agnostic and debuggability*
 A hybrid solution where for well tested platforms like Ubuntu 16/Centos7 etc, we default to using TCP keepalives only but for any others, TCP keepalives can happen too but app level heartbeat would happen too.
 Also this app level heartbeat can be changed in the config file, so even if i am on Ubuntu and doubtful that i am not getting messages, i can simply enable heartbeating in config files and restart the node, i will start seeing pings being sent and pongs received, of course i will not receive pings unless the other node disconnects or has changed it's config (though it can be used as DoS mechanism). If we switch to RAET we will set heartbeating to True in config by default",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-332,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1u7:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,danielhardman,krw910,liugreatsea,lovesh,mgbailey,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jun/17 12:11 AM;danielhardman;[~mgbailey] If you have any further color, please attach to the ticket.;;;","27/Jun/17 1:48 AM;mgbailey;Here is the test that show it.  Metis is disconnecting approximately every 4-5 hours. At about 15:00 6/23 UTC we start up a load generator that is putting a NYM into the ledger every 15 seconds, and leave it running.  At 13:47 6/24, nearly 24 hours later, something goes wrong with one of the nodes in the pool, and the load generator fails.  Soon after another disconnect occurs.  Then there is an 9 hour gap, and then the pattern of disconnecting every 4-5 hours resumes.  Here is grepped data from the logs:

2017-06-22 20:33:39,385 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-23 01:04:48,704 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-23 05:35:53,916 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-23 10:22:57,600 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-23 14:53:50,522 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
_2017-06-23 (load test starts ~15:00)_
_2017-06-24 (load test ends ~13:30)_
2017-06-24 14:42:09,591 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-24 23:27:54,432 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-25 04:14:54,018 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-25 08:46:03,325 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-25 13:17:12,640 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-25 17:48:21,955 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-25 22:19:47,644 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-26 02:51:13,341 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-26 07:22:06,266 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis
2017-06-26 11:52:59,200 | INFO | keep_in_touch.py ( 92) | _connsChanged | play disconnected from metis

This strongly supports the theory of insufficient keep-alives.  There are 2 things that remain mysteries: 1) Why was there 9 hours with no disconnects from 2017-06-24 14:42:09,591 to 2017-06-24 23:27:54,432? 2) Why did a node in the validator pool lose sync and start spewing messages to the logs and back to the log generator agent?;;;","29/Jun/17 9:45 PM;lovesh;Changes:
STP: https://github.com/evernym/stp/pull/38
Plenum: https://github.com/evernym/plenum/pull/237;;;","01/Jul/17 1:00 AM;lovesh;[~krw910] Test for heartbeats: test_heartbeats.py;;;","01/Jul/17 1:55 AM;krw910;Notes on overriding the sovrin_config.py file.

Keep Alive (Heartbeat)
This is to configure how the nodes will continue to check if the other nodes are able to communicate.

ENABLE_HEARTBEATS=True
HEARTBEAT_FREQ= 5 # seconds 

We also have a TCP Keep Alive
TCP_KEEPALIVE=True
KEEPALIVE_INTVL = 1     # seconds
KEEPALIVE_IDLE = 20     # seconds
KEEPALIVE_CNT = 10
;;;","13/Jul/17 5:25 AM;krw910;Blocked by INDY-406;;;","19/Jul/17 4:46 AM;krw910;The product is good enough to go Stable. I cannot reproduce this issue and we will need to wait until the alpha pool reports back.;;;","19/Jul/17 5:14 AM;danielhardman;[~mgbailey] we will have to instruct nodes that are experiencing problems to enable keepalives per the config settings described by Kelly. Otherwise, the fixes will not have any effect.;;;","19/Jul/17 8:16 AM;mgbailey;I am looking forward to trying it out!;;;","29/Jan/19 3:29 PM;liugreatsea;Sorry for my mis-operation to add some content. Roll back to the original one just now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Repeated lines to log, and lost sync in validator",INDY-332,18682,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,mgbailey,mgbailey,27/Jun/17 3:09 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"While testing for INDY-331, the load generator client script ended prematurely.  In the output from that script, we noticed many lines repeating:

 
{noformat}
2017-06-24 14:25:58,612 | INFO | client.py (280) | handleOneNodeMsg | Client Cr7ph7RQ9zEwyx5hzxBMrh6quMc3UteoSNz3pawR9v3c got msg from node asobiC: {'reqId': 1498312057549903, 'identifier': 'EK6VWvsoNSVwD3SaVGw68N5sA7aRbepTAwRcNMKQXdYc', 'op': 'REQACK'}
2017-06-24 14:25:58,612 | INFO | client.py (280) | handleOneNodeMsg | Client Cr7ph7RQ9zEwyx5hzxBMrh6quMc3UteoSNz3pawR9v3c got msg from node asobiC: {'reqId': 1498312057549903, 'identifier': 'EK6VWvsoNSVwD3SaVGw68N5sA7aRbepTAwRcNMKQXdYc', 'op': 'REQACK'}
2017-06-24 14:25:58,612 | INFO | client.py (280) | handleOneNodeMsg | Client Cr7ph7RQ9zEwyx5hzxBMrh6quMc3UteoSNz3pawR9v3c got msg from node asobiC: {'reqId': 1498312057549903, 'identifier': 'EK6VWvsoNSVwD3SaVGw68N5sA7aRbepTAwRcNMKQXdYc', 'op': 'REQACK'}
{noformat}
Eventually, the load generator failed.  Going to the logs on the 'asobi' node, we see a matching pattern of repeated log messages (file attached).  We are unable to go back to the beginning of this behavior in the asobi logs, since the logs rapidly filled up and rolled.

The issue to be examined is more with the validator node than with the load generator, which was not running a heavy load (1 transaction each 15 seconds ).  The validator had the following behavior:
 # Excessive repeated messages, 
 # A gap of more than a day with no logging after the last repeated message
 # Many fewer entries (1000+) in transactions_sandbox than in other validators

 ","sovrin-node 0.3.24, 

AWS,

Ubuntu 16.04",,,,,,,,,,,,,,,,,,,,,,INDY-331,,,,,,,,,,,,"27/Jun/17 3:08 AM;mgbailey;asobi_log.tgz;https://jira.hyperledger.org/secure/attachment/11385/asobi_log.tgz","11/Jul/17 10:35 AM;mgbailey;masakmasak.log2.tgz;https://jira.hyperledger.org/secure/attachment/11627/masakmasak.log2.tgz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzycg7:",,,,,,H3,10,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,krw910,mgbailey,mzk-vct,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 6:01 AM;stevetolman;Please time box this by spending an hour to review the logs and study the code to see if you can figure out how this is happening. After an hour, report your findings here and assign this ticket to Kelly.;;;","29/Jun/17 1:16 AM;mzk-vct;[~stevetolman] [~krw910]
I run add_keys multiple times and also send requests manually, using CLI, but failed to reproduce it on latest builds.
Since there is one hour limitation, I'm stopping investigation. ;;;","29/Jun/17 1:20 AM;mzk-vct;By the way, seed for *EK6VWvsoNSVwD3SaVGw68N5sA7aRbepTAwRcNMKQXdYc* is *000000000000000000000000Steward1*, which in the first on the *load_test_clients.list* list, so it could mean that this error happened on the start.;;;","29/Jun/17 1:27 AM;mzk-vct;There would be great to know whether there were not only *REQACK*s, but also *REPLY*s from asobiC.
The reason can be in fact that client tries to resend request if node does not replies after timeout. 
Another reason can be in a way stp or zeromq manages message delivery.
;;;","29/Jun/17 1:28 AM;mzk-vct;[~krw910] I wrote my thoughts about possible reason, but they are only guesses, because problem was not reproduced;;;","29/Jun/17 11:59 PM;krw910;I have not reproduced this either. If it happens again during load testing of INDY-13 I will capture the logs and stop tests until someone can take a look at the issue.;;;","30/Jun/17 5:42 AM;danielhardman;Given that we can't dup this right now, I think we should bookmark the issue and wait to see if it surfaces again.;;;","11/Jul/17 10:36 AM;mgbailey;I am seeing this behavior in more places.  While doing tests with the traffic generator over the weekend, this problem manifested in two nodes in the alpha network (OASFCU and probably DustStorm).  These are ESX nodes where we have seen disconnect / connect patterns like we have seen in metis.  In addition, we have now also seen this in an AWS node in the ESN network, masakmasak.  In all these cases, it appears that there is a disconnect/reconnect event, after which transactions are no longer written to the ledger on that node.  I am attaching masakmasak logs to this ticket. At 18:52:40 the sovrin process seems to restart on its own volition.  From that point on, no further transactions are written to the ledger on that node. [^masakmasak.log2.tgz] While the mysterious process restart is bod, the failure to catchup and synchronize with the pool is worse.  [~danielhardman], [~stevetolman], we need to reopen this.  It is happening too often, and will bite us.;;;","19/Jul/17 4:48 AM;krw910;This appears to be working just fine. We will need to keep an eye on it with the alpha pool.;;;","19/Jul/17 5:16 AM;danielhardman;I don't think I can mark this ""Done"", since we never duplicated it. I am going to put it back in the backlog; if we encounter it again soon, we can begin working on it again; otherwise, we will eventually stumble across it and decide it's no longer an issue.;;;","03/Aug/17 6:57 PM;ashcherbakov;[~danielhardman] [~nage] What should we do with this task?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLI should show what role is assigned to a NYM when doing a GET_NYM,INDY-333,18685,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,27/Jun/17 4:58 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,should,,,,,"GET_NYM should also include what role is assigned to a NYM, if any.

Current a GET_NYM only returns the ID and Verkey. Jason ran a GET_NYM after removing a role from a NYM to verified it was removed and was not able to see that information. ",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyl4n:",,,,,,14,INDY 17.21,,,,,,,,,,,,,,,,,,,krw910,mark.hadley,ozheregelya,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/17 2:35 AM;mark.hadley;https://github.com/hyperledger/indy-client/pull/253;;;","30/Aug/17 6:05 AM;krw910;[~mark.hadley] Please do another pull request in the current Indy-client.;;;","31/Aug/17 7:09 AM;krw910;[~ashcherbakov] Please assign this ticket to a developer other than Mark.;;;","20/Sep/17 8:14 PM;sergey-shilov;Task is done, changes are in master:
https://github.com/hyperledger/indy-node/pull/349
https://github.com/hyperledger/indy-node/pull/352
https://github.com/hyperledger/indy-node/pull/354

Problem: CLI did not show role assigned to NYM in output of GET_NYM command.

Now role is displayed in addition to ID and Verkey if it is assigned to NYM.

Written test:
sovrin_client/test/cli/test_send_get_nym_validation.py:test_get_nym_returns_role

Also GET_NYM command output may be checked using CLI directly:
1. Send NYM with role, then send GET_NYM
2. Check role is presented in CLI output
3. Clear role assigned to NYM by sending the same NYM with empty role, then send GET_NYM
4. Check role is not presented in CLI output;;;","03/Oct/17 4:20 AM;ozheregelya;*Build Info:*
 indy-node 1.1.150
 indy-anoncreds 1.0.25
 indy-plenum 1.1.137
OS/Platform: Ubuntu 16.04.2 LTS

*Steps to Validate:*

1. Create new identity with any role, send GET_NYM and check output.
2. Remove role, send GET_NYM and check output.
3. Update role, send GET_NYM and check output

*Actual Results:*
{code:java}
sovrin@test> send NYM dest=K298qdBdPFFw7A4xEnBYF1 role=STEWARD verkey=~FxJc5tZWhUEWSnT2zG3A2J
Adding nym K298qdBdPFFw7A4xEnBYF1
Nym K298qdBdPFFw7A4xEnBYF1 added
sovrin@test> send GET_NYM dest=K298qdBdPFFw7A4xEnBYF1
Getting nym K298qdBdPFFw7A4xEnBYF1
Current verkey for NYM K298qdBdPFFw7A4xEnBYF1 is ~FxJc5tZWhUEWSnT2zG3A2J with role STEWARD
sovrin@test> send NYM dest=K298qdBdPFFw7A4xEnBYF1 role=
Adding nym K298qdBdPFFw7A4xEnBYF1
Nym K298qdBdPFFw7A4xEnBYF1 added
sovrin@test> send GET_NYM dest=K298qdBdPFFw7A4xEnBYF1
Getting nym K298qdBdPFFw7A4xEnBYF1
Current verkey for NYM K298qdBdPFFw7A4xEnBYF1 is ~FxJc5tZWhUEWSnT2zG3A2J
sovrin@test> send NYM dest=K298qdBdPFFw7A4xEnBYF1 role=TRUST_ANCHOR
Adding nym K298qdBdPFFw7A4xEnBYF1
Nym K298qdBdPFFw7A4xEnBYF1 added
sovrin@test> send GET_NYM dest=K298qdBdPFFw7A4xEnBYF1
Getting nym K298qdBdPFFw7A4xEnBYF1
Current verkey for NYM K298qdBdPFFw7A4xEnBYF1 is ~FxJc5tZWhUEWSnT2zG3A2J with role TRUST_ANCHOR{code}
 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to add a NYM after node count came back up after being below consensus,INDY-334,18687,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,27/Jun/17 5:20 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"I have a pool of 7 nodes so I can lose 2 nodes without any issues. Once I lose 3 nodes the pool can no longer reach consensus. Once I had 5 active nodes again the pool still could not reach consensus.

*Setup*
Have a 7 node pool

*Steps*
# Send a few transactions on a 7 node pool to make sure everything is running.
# Stop the sovrin-node service on node 7 (6 out of 7 active)
# Send a transaction to make sure the pool can still reach consensus (It should work)
# Stop the sovrin-node service on node 6 (5 out of 7 active)
# Send a transaction to make sure the pool can still reach consensus (It should work)
# Stop the sovrin-node service on node 5 (4 out of 7 active)
# Send a transaction to make sure the pool can still reach consensus (It should not work)

*At this point the pool should not be able to reach consensus*
Start the sovrin-node service on node 5 (5 out of 7 active)
Now I have 5 out of 7 active nodes which is enough for consensus as we can see above.
Send a transaction to make sure the pool can still reach consensus (It should work)

*{color:#d04437}Issue{color}*
Once I returned to have enough nodes to reach consensus the pool was still unable to reach consensus.
Send a transaction to make sure the pool can still reach consensus (It should work)

{color:#205081}I then restarted both nodes 6 and 7 so I had all nodes active in the pool again. {color}
Send a transaction to make sure the pool can still reach consensus (It should work)
The pool still could not reach consensus.

{color:#205081}I disconnected the CLI and reconnected to the pool.{color}
Send a transaction to make sure the pool can still reach consensus (It should work)
The pool still could not reach consensus.

{color:#205081}Workaround{color}
In the end I had to stop all nodes in the pool and start them up one at a time and then the pool was functional again.


",,,0,0,,0%,0,0,,,INDY-13,INDY-389,INDY-401,,,,,,,,,,,,,,INDY-383,INDY-455,INDY-804,,,,,,"05/Jul/17 10:17 PM;VladimirWork;Node1.log;https://jira.hyperledger.org/secure/attachment/11559/Node1.log","05/Jul/17 10:17 PM;VladimirWork;Node2.log;https://jira.hyperledger.org/secure/attachment/11560/Node2.log","05/Jul/17 10:17 PM;VladimirWork;Node3.log;https://jira.hyperledger.org/secure/attachment/11561/Node3.log","05/Jul/17 10:17 PM;VladimirWork;Node4.log;https://jira.hyperledger.org/secure/attachment/11562/Node4.log","24/Jul/17 11:30 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11759/Screenshot.PNG","05/Jul/17 10:17 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11558/Screenshot.PNG","24/Jul/17 11:31 PM;VladimirWork;node1.txt;https://jira.hyperledger.org/secure/attachment/11760/node1.txt","24/Jul/17 11:31 PM;VladimirWork;node2.txt;https://jira.hyperledger.org/secure/attachment/11761/node2.txt","24/Jul/17 11:31 PM;VladimirWork;node3.txt;https://jira.hyperledger.org/secure/attachment/11762/node3.txt","24/Jul/17 11:31 PM;VladimirWork;node4.txt;https://jira.hyperledger.org/secure/attachment/11763/node4.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxqdb:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,lovesh,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 9:40 PM;ashcherbakov;[~krw910] Do we have log files? Did we check that the nodes we stopped were not a Primary in any instance? Otherwise a View Change is started, and the ledger may be stalled because of INDY-13.;;;","05/Jul/17 10:18 PM;VladimirWork;There is a similar case with 4 nodes pool !Screenshot.PNG|thumbnail!  [^Node1.log]  [^Node2.log]  [^Node3.log]  [^Node4.log] :

Build Info:
sovrin-node 0.4.9

Overview:
Send NYM command doesn't work with 3 online nodes of 4.

Steps to Reproduce:
1. *Stop* one node of four.
2. Send NYM command -> NYM is successfully added.
3. *Restart* another one node.
4. Send NYM command.

Actual Results:
NYM is not added.

Expected Results:
NYM should be added because 3 online nodes of 4 is enough to do that.


Logs from all nodes are in attachment.;;;","15/Jul/17 12:55 AM;mzk-vct;Changes were done in https://jira.hyperledger.org/browse/INDY-389
Check whether they helped

Build numbers:
node==0.4.35
plenum==0.4.47
;;;","24/Jul/17 11:31 PM;VladimirWork;There is the same behavior on indy-node 0.4.60: 

1. Stop one node of four (Node 1).
2. Send NYM command -> NYM is successfully *added* (3 of 4 nodes are active now).
3. Restart another one node (Node 2).
4. Send NYM command -> NYM adding is *failed* (3 of 4 nodes are active now).

Additional info is in attachment. !Screenshot.PNG|thumbnail!  [^node1.txt]  [^node2.txt]  [^node3.txt]  [^node4.txt] 

NYM is successfully added after Node 4 is stopped and Node 3 is restarted, so reproduce it exactly the same: with Node 1 is stopped and Node 2 is restarted.;;;","25/Jul/17 1:39 AM;ashcherbakov;*Problem reason*
If the Primary is disconnected, and no view change happened (probably because of lack of consensus), then the Primary didn't use correct ppSeqNo for the next Batch.

*Fix*
Set ppSeqNo to the last_ordered_pp_seq_no in the case above.

*PR*
PR: https://github.com/hyperledger/indy-plenum/pull/305

*Covered with tests*
 test_recover_stop_primaries;;;","25/Jul/17 1:58 AM;lovesh;[~ashcherbakov] If primary was just disconnected and not crashed, the why would it not use the correct `ppSeqNo` for next batch. If it crashed, view change should probably be triggered since nodes tolerate primary disconnection for only  `ToleratePrimaryDisconnection` which is 2 sec, as of now. If a node starting up does not get current state as i am assuming happened here (because other nodes did not detect disconnection), it should request CURRENT_STATE and LEDGER_STATUS;;;","25/Jul/17 2:08 AM;ashcherbakov;[~lovesh] It's reproduced only if we don't have a quorum of InstanceChanges. The CurrentState is Propagated correctly, the disconnected Primary is catch-up and completed view change successfully, The only issue is that is has ppSeqno=0, so when it tries to send next batch, other nodes discard it since it's already ordered. That's why the fix is set ppSeqNo for the Primary to lastOrderedPpSeqNo.
;;;","25/Jul/17 2:12 AM;lovesh;[~ashcherbakov] By ""completed view change successfully"" you mean view changes? if yes then it would not be primary and pp_seq_no will start from 1;;;","25/Jul/17 2:16 AM;ashcherbakov;[~lovesh] No, by view change I mean view change happened to Propagate Primary (that is processing of VCD messages from other nodes).
So, again:
1) We have 3 nodes
2) We re-start primary (Node1)
3) View change doesn't happen since not enough InstanceChange
4) Node1 recieves f+1 CurrentState messages. This is enough to recover (because of INDY-389).
5) Node1 does a 'fake' View change to propagate the Primary and View number (from Current State)
6) Node1 is ready to participate
7) node 1 send next batch with ppSeqNo=0, while it should not be 0 (the view is still the same);;;","25/Jul/17 5:16 AM;ashcherbakov;[~VladimirWork] [~krw910]
Fixed in indy-node 0.4.62;;;","25/Jul/17 7:55 PM;VladimirWork;Build Info:
indy-node 0.4.63

Steps to Validate:
1. Stop one node of four (Node 1).
2. Send NYM command -> NYM is successfully added.
3. Restart another one node (any).
4. Send NYM command.

Actual Results:
NYM is successfully added.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement: A node should start catchup process if its ledger gets out of sync,INDY-335,18690,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,andrey.goncharov,stevetolman,27/Jun/17 5:58 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"A node's ledger might get out of sync for different reasons (say, write to db failed), thus it will be lagging behind and will not be able to process newer PRE-PREPAREs, PREPAREs and COMMITs.  

This needs to be fixed, we have CHECKPOINT in the code which is sent periodically, as of now it only helps in garbage collection. It should be used as opportunity to start a catch up process node come to a start where it can start processing new requests again.

Alternatively we can find specific places in the code where we discard messages, check for discard reason and start catch up if the reason is unsynced ledger.

 

[The design|https://docs.google.com/document/d/1OCUsD46HLhqhqZBJmn5wLZ2gTS1mcu6CQszoAh1gUA0/edit#heading=h.oqftj4wkhga5].

 

WARNING: If we bind to discards the protocol might get way too chatty. Discussion with Daniel and Jason is required!

 ",,,97200,97200,,0%,97200,97200,,,,,,,,,,,,INDY-103,,,INDY-12,,,,,,,,,,,,"24/Jul/17 2:14 AM;ozheregelya;logs1.tar.gz;https://jira.hyperledger.org/secure/attachment/11746/logs1.tar.gz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8dj:",,,,,,H4,M1 Prelude,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ozheregelya,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/17 10:51 PM;alexander.shekhovcov;(/)

*Problem reason:*
 - A node's ledger might get out of sync for different reasons (say, write to db failed), thus it will be lagging behind and will not be able to process newer PRE-PREPAREs, PREPAREs and COMMITs. The node has to be restarted in order to participate in consensus again. 

*Changes:*
 - a node starts the catchup procedure in case the node stashes two checkpoints with quorum. It is an emergency recovery mechanism. 

*Committed into:*
 [https://github.com/hyperledger/indy-plenum/pull/270]

indy-node 0.4.30

*Risk factors:*
 Can cause unexpected behavior because the catchuping of a broken node is not tested well.

*Risk:*
 Medium

*Covered with tests:*

test_node_catchup_after_checkpoints

*Recommendations for QA:*
 1. Make a non-primary node is not participating in consensus without disconnection it (disconnecting/connecting starts catchup itself). 

2. Make sure the node does not process requests ""missing PRE-PREPAREs between X and Y"" is quite a common reason.

3. Send more than 200 requests (one checkpoint == 100 batches)

4. Make sure the node catchup and participating

 

We decided do not implement starting the catchup procedure by timeout in case a node misses checkpoints because it is rather risky to start the catchup procedure in an arbitrary moment. Anyway, this ticket implements an emergency recovery mechanism which has to be safe enough for main functionality. 

We can implement the timeout option later after MGL.

 

 ;;;","24/Jul/17 2:14 AM;ozheregelya;*Build Info:*
   indy-node 0.4.52
   indy-anoncreds 0.4.18
   indy-plenum 0.4.64
   sovrin 0.2.10
   python3-rlp 0.5.1
   python3-sha3 0.2.1
   python3-pyzmq 16.0.2
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 4 nodes, 1 client

*Steps to Reproduce:*

1. Set up pool of 4 nodes.
 2. Write random information into home/sovrin/.sovrin/data/nodes/Node4/transactions_sandbox/1
{code:java}
||||1|V4SGRU86Z58d6TV7PBUe6f|~CoRER63DVYnWZtK8uAzNbx||||||0||
V4SGRU86Z58d6TV7PBUe6f||||1|Th7MpTaRZVRYnPiabds81Y|~7TYfekw4GUagBnBVCqPjiC||||||2||
V4SGRU86Z58d6TV7PBUe6f||||1|EbP4aYNeTHL6q385GuVpRV|~RHGNtfvkgPEUQzQNtNxLNu||||||2||
V4SGRU86Z58d6TV7PBUe6f||||1|4cU41vWW82ArfxJxHkzXPG|~EMoPA6HrpiExVihsVfxD3H||||||2||
V4SGRU86Z58d6TV7PBUe6f||||1|TWwCRQRZ2ZHMJFn9TzLp7W|~UhP7K35SAXbix1kCQV4Upx||||||2||
V4SGRU86Z58d6TV7PBUe6f||||1|7JhapNNMLnwkbiC2ZmPZSE|~LgpYPrzkB6awcHMTPZ9TVn||||||||
Th7MpTaRZVRYnPiabds81Y|1500558332385065|2qsX8mt6cgLJNdhHZ93HU4P9nC95TdA7ZPKHCissHXAURDhdzZhtw6rTWh18D62efyoNg542McyUwN7gMAgMhYRZ|1500558332|1|RrTkY1dPvpxJShvtHoPe8Y|~MKpejEBYGxdQzHRZ1CZk1Z||||||||
RrTkY1dPvpxJShvtHoPe8Y|1500559298686229|59a8PsivEnAc6KZ7yyq2ftN3sTYBUnYaqGhm1gZRvDxX6vSvSqpZDjhkmCSoemdToPzSdECNSFbyCe9A7gXZehPc|1500559298|1|RrTkY1dPvpxJShvtHoPe8Y|8141LM6L6Lm3XXB76sGVDuBE5q8w94WLZBkRBkTZ2NTP||||||||
RrTkY1dPvpxJShvtHoPe8Y|1500559769713363|4pMLbHGEuUSZQoeiN7BiT9w41WjQ25Lym3dDS5ktWf9qAVPicrNXZ6Vwdc1U2Qp9Dou1iXrLqfPMVgsycHbYB56H|1500559769|1|RrTkY1dPvpxJShvtHoPe8Y|7DraUMinVb67g6uMxio955u7MSBSKKSMzfUoUxZCQYRK||||||||
Th7MpTaRZVRYnPiabds81Y|1500561721619998|4gwd5rTAPvWa8xLuVV7WCn91iCvbztzMgyBpZTVRSeR5iE3Yw1S856HV2ehbuPRhHX3kv2SYfxz77cmL5QqEhBNB|1500561721|1|VWWqQERPa2LHGY86UNJKWY|||||||||
Th7MpTaRZVRYnPiabds81Y|1500561976072049|3BX2N8WiYzneYguE3f9zPVJJkpPG9bAu7pyWYoJWLy1Kn9pQZLrkbJzJXe9do2ZNwhLyMG3Tmd62adyuoVtPbv9u|1500561976|1|VWWqQERPa2LHGY86UNJKWY|4qvUoW4yGSpqxjjGLWtZETngiHT5JoGA5pSq8uwFqcA7||||||||
VWWqQERPa2LHGY86UNJKWY|1500561988523410|5EHM7wSqZWCij9QYXQqrFeAs9RmyPHAoMRP899t5cNpk4HMB9cM4MNMQooP8L5YyCASfrPEfyuH7bNpsPte8hmUd|1500561988|1|VWWqQERPa2LHGY86UNJKWY|||||||||
Th7MpTaRZVRYnPiabds81Y|1500568279362189|3JfjA5Dz66qLTo7ozxokAEnsAjcCCWZyWkBaCe11kRCnpKPqomE5Pwzc4jtb8YD3wdBTZVh84A4fTrZ6QjPGbRH4|1500568279|1|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A|||||||||
V4SGRU86Z58d6TV7PBUe6f|1500568361305289|2zW4ouSgvcwcwfKTyWnBwVY2cWCSvtnt5ggGD9653GjBaraQaq8r2Hbd3wva4zzsFCf9zdtsd1jVofnwPHhbd1rs|1500568361|1|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A|||||||0||
Th7MpTaRZVRYnPiabds81Y|1500568442641013|wGUoFSdZ3AJTn9abTJB3vaW5R5g2sqoAiEyR38eoPA9aNXwRtqcuRzBCUDks4E5MEK8JCFkC4o5B4gjn1mj4VP8|1500568442|1|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A||||||||
W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A|1500568452134573|3aJr54MFsCvAu3b78uzS3xsKNHdHxyAXmXtgqEyqThGqR64J28nNicSTPufFyN9c5JoYgkR4RQ9TSGu1E6sy661E|1500568452|1|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv851|||||||||
Th7MpTaRZVRYnPiabds81Y|1500633526998862|3qe1Uay5nthHe2jFTrAr7GiyMZUiZeko5mLtfRewnuAbjRXv4BGDyDF4LxhLgnkYc69599iJGYydZtEBcqpVste7|1500633527|1|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv999|||||||||
adsfcasdffsadfasdfadsfdsfTh7MpTaRZVRYnPiabds81Y|1500633919216149|3FADUPQd4iQTuht1uzuYLkDCPQJBUVfyiMdS9Geot1Vz6AibNPMSV8FCppmwDDZ6PaFPG3uytpx771bK3vfoFFzF|1500633919|1|Hh6q3aMwJ7xtk7CHusCk9R|||||||||
asdfasdfadsf
safddsafasdfasdfadsf
sadfsadfsadf{code}
3. Send several NYMs to test nodes communication, compare transactions files.
{code:java}
root@ec2fb355fd7e:/home/sovrin/.sovrin# wc -l data/nodes/Node4/transactions_sandbox/1
21 data/nodes/Node4/transactions_sandbox/1{code}
{code:java}
root@c0ecf5b26ddb:/home/sovrin/.sovrin# wc -l data/nodes/Node3/transactions_sandbox/1
 23 data/nodes/Node3/transactions_sandbox/1{code}
4. Using add_keys.py and load_test.py send more than 200 transactions.
 5. Compare transaction files again.
{code:java}
21 data/nodes/Node4/transactions_sandbox/1
root@ec2fb355fd7e:/home/sovrin/.sovrin# vim Node4.log
{code}
{code:java}
root@c0ecf5b26ddb:/home/sovrin/.sovrin# wc -l data/nodes/Node3/transactions_sandbox/1
 523 data/nodes/Node3/transactions_sandbox/1{code}
*Actual Results:*
 Files are different, catchup has not happened.

*Expected Results:*
 Catchup should happen, files should be the same.

[^logs1.tar.gz];;;","24/Jul/17 2:20 AM;ozheregelya;This ticket needs in additional discussion, so it is reassigned to [~VladimirWork].;;;","25/Jul/17 9:41 PM;alexander.shekhovcov;Needs a fix because it turned out that replicas do not move their watermarks after catchup finished.

The issue breaks only recovery feature and does not break main functionality. ;;;","27/Jul/17 12:24 AM;alexander.shekhovcov;fixed:

In case of triggering catchup a replica changes its watermark bounders.

*How to test:*

1. patch a node code:
{code}
vim /usr/local/lib/python3.5/dist-packages/plenum/server/node.py
{code}
go to ""def sendToReplica""

before
{code}
if self.msgHasAcceptableInstId(msg, frm) and
{code}

add 
{code}
from datetime import datetime
if int(datetime.now().minute / 10) % 2:
    logger.warning(""The node misses all replica messages"")
    return
{code}

so the node will not process 3pc messages between each odd ten minutes in an hour, for example 
14:00:00-14:09:59 - works
14:10:00-14:19:59 - does not work
14:20:00-14:29:59 - works
...

2. save the file and restart the sovrin-node service

3. in non-working interval send 150 NYM requests
4. check that the node ledger is behind
5. in working interval send more then 200 NYMs 
6. check that the node ledger is actual

Make sure what the node is non-primary and does not have disconnection during the testing (except step #2).


;;;","31/Jul/17 9:13 PM;VladimirWork;Build Info:
indy-node 1.0.68

Steps to Validate:
1. Patch a node code according to comment above.
2. Save the file and restart the sovrin-node service.
3. In non-working interval send 150 NYM requests.
4. Check that the node ledger is behind.
5. In working interval send more then 200 NYMs.

Actual Results:
All nodes' ledgers are actual.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client to node parameters validation - Part II,INDY-336,18695,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dsurnin,stevetolman,stevetolman,27/Jun/17 6:42 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,AlexReview,should,,,Validate client to node communication parameters.,,,,,,,2700,2700,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx1qf:",,,,,,,,,,,,,,,,,,,,,,,,,,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance migration tool,INDY-337,18707,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,andrey.goncharov,andrey.goncharov,andrey.goncharov,27/Jun/17 7:45 PM,13/Nov/19 12:40 AM,28/Oct/23 2:46 AM,13/Nov/19 12:40 AM,,,,,0,6Months,KEEP,Must,,,"Currently all migration scripts are applied in alphabetical order that satisfy the condition: (script's first version >= a version we're migrating from) and (script's second version <= a version we're migrating to).

This behavior needs to be enhanced. A shortest possible list of migration should be calculated and applied. 
Example:
 * We migrate from 1 to 10
 * We have migrations 1_to_2, 2_to_4, 1_to_6, _8___to__9. Only 1_to_6 and 8_to_9 should be applied.

This task still requires some thinking on how to handle situations like this:
 * We migrate from 1 to 10
 * We have migrations 1_to_2, 2_to_4, 6_to_8, 1_to_7, 5_to_9",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,INDY-132,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzx13r:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,esplinr,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/17 6:32 AM;stevetolman;Is there anything about this ticket that hasn't already been done with the upgrade the upgrader ticket?;;;","11/Jul/17 2:20 AM;andrey.goncharov;[~stevetolman] the whole ticket is a split. It covers functionality requested bu Daniel here https://jira.hyperledger.org/browse/INDY-132?focusedCommentId=27233&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-27233;;;","13/Nov/19 12:40 AM;esplinr;We agreed that this is a real issue, but we don't think we need to work on it at this time.

We don't expect that we will ever need this tool in practice. Migrations are rare, and we can control how the script is named to avoid the issue.

If this becomes a problem in the future, we will work on it then.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Transaction should contain only its fields,INDY-338,18710,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,ashcherbakov,mzk-vct,mzk-vct,27/Jun/17 10:09 PM,30/Mar/19 5:39 AM,28/Oct/23 2:46 AM,30/Mar/19 5:39 AM,,,,,0,,,,,,"When we get transaction from ledger it contains not only field that it supposed to, but all set of possible fields from other transaction types (set to None).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy5xj:",,,,,,,,,,,,,,,,,,,,,,,,,,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test_getting_started_guide.py has error from walleted.py,INDY-339,18723,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mark.hadley,mark.hadley,28/Jun/17 2:12 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"Cannot run:

 
{code:java}
$ python client/test/training/test_getting_started_guide.py
Without receiving the follow error:
Traceback (most recent call last):
   File ""/home/hadleym/evernym/sovrin-client/sovrin_client/test/training/test_getting_started_guide.py"", line 169, in <module>
     getting_started()
   File ""/home/hadleym/evernym/sovrin-client/sovrin_client/test/training/test_getting_started_guide.py"", line 42, in getting_started
     link_to_faber = alice_agent.load_invitation_str(FABER_INVITE)
   File ""/home/hadleym/evernym/sovrin-client/sovrin_client/agent/walleted.py"", line 757, in load_invitation_str
     return self.loadInvitationDict(invitation)
   File ""/home/hadleym/evernym/sovrin-client/sovrin_client/agent/walleted.py"", line 767, in loadInvitationDict
     return self._mergeInvitation(invitation_dict)
 AttributeError: 'WalletedAgent' object has no attribute '_mergeInvitation'
Process finished with exit code 1
{code}
 

It seems that 
 sovrin-client/sovrin_client/agent/walleted.py
 function loadInvitationDict is not tested correctly.",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1uf:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,krw910,mark.hadley,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/17 6:19 AM;mark.hadley;This may be an environment specific error, although this still needs attention.

The environment specific error was that I had a file

~/.sovrin/pool/Alice/

with invites already associated, so when the script comes through, it sees a previous invitation (the faber invitation) and attempts to call ./sovrin_client/agent/walleted._mergeInvitation().  This is the normal logic when an invitation already exists.

This function '_mergeInvitation()' does not exist because of a typo. The function is '_mergeInvitaion' (notice the missing second 't').

No current tests test for this behavior, so its never thrown this error before.

 ;;;","14/Jul/17 10:54 PM;spivachuk;*Problem reason:*
- There was a typo in the name of one of Wallet methods. The name was ""_mergeInvitaion"" instead of ""_mergeInvitation"". This method was referenced somewhere as ""_mergeInvitaion"", somewhere as ""_mergeInvitation"".
- The proof request was missed in Acme invitation link from sovrin_client tests.
- Printing of claim contents was broken.
- The invitee's identifier was used in place of the inviter's one in the message about accepting an invitation.

*Changes:*
- Corrected the name of Walleted._mergeInvitation method and references to it.
- Fixed a bug with a missed proof request in Acme invitation link from sovrin_client tests.
- Fixed broken printing of claim contents.
- Corrected printing of proof requests.
- Fixed a bug with a wrong identifier in the message about accepting an invitation.

*Committed into:*

indy-anoncreds:
- commit hash: ad229c5d3370d61123617549acba5e507ad2340d
- version: indy-anoncreds-dev 0.4.15

indy-node:
- commit hash: ec0c600ebaadc009361276455dcdd78ff79c73d2
- version: indy-node-dev 0.4.33

*Risk factors:*
- Nothing is expected.

*Risk:*
- Low;;;","17/Jul/17 5:08 AM;krw910;Latest build with the fix for test_getting_started_guide ran successfully.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
improve error message for wrong verkey length,INDY-340,18729,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,danielhardman,danielhardman,28/Jun/17 5:23 AM,23/Oct/19 12:15 AM,28/Oct/23 2:46 AM,23/Oct/19 12:15 AM,,,,,0,6Months,KEEP,should,,,"Currently, when our input validation reports an error about an incorrect length of a verkey, it uses awkward and confusing wording (though its content is correct).

Steps to Validate:
1. Add new identifier.
2. Login as Trustee.
3. Send NYM to added identifier with ""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF"" verkey.

Actual Results:
Error: client request invalid: InvalidClientRequest('validation error: b58 decoded value length 33 should be one of 32).

 

Preferred wording:

Error: client request invalid: InvalidClientRequest('validation error: b58 decoded value length = 33, but should be 32.

Note that I am asking that we be smart enough that if the acceptable values is only one item long (""should be one of 32""), we should change the verbiage to be simply ""should be 32"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|i011bm:",,,,,,Ev-Node 19.21,,,,,,,,1.0,,,,,,,,,,,,ashcherbakov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/19 12:15 AM;ashcherbakov;Done in https://github.com/hyperledger/indy-plenum/pull/1378;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] NYMs cannot be added after upgrade with specific conditions and force=True flag ,INDY-341,18738,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,anikitinDSR,aleksey-roldugin,aleksey-roldugin,28/Jun/17 6:32 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,KellyRetest,should,,,"h6. BUILD

sovrin-node 0.3.161
 sovrin-client 0.3.150
h6. PRECONDITIONS
 * 4-nodes pool
 * 1 node is blacklisted
 * 1 node is turned off (by command _sudo systemctl stop sovrin-node_)

h6. STEPS TO REPRODUCE
 # Run sovrin-client and connect to test (connected only to 2 nodes).
 # Run POOL_UPGRADE
 ** Schedule contains identifiers of all nodes except turned off node.
 ** Time for all identifiers is in the past (near 5 minutes before current moment)
 ** Force=True
 # RESULT:
 ** 2 running nodes is upgraded immediately, blacklisted node is not upgraded.
 ** NYM cannot be added since f+1 condition is not met (2 nodes are running in 4 nodes pool)
 # Run _sudo systemctl restart sovrin-node_ on turned off node => RESULT: node is turned on, client connected to it.
 # Try to add NYM => RESULT: NYM is not added (but f+1 condition is met).
 # Run POOL_UPGRADE with force=True flag specifying only recently turned on node => Result: node is upgraded.
 # Try to add NYM.

h6. ACTUAL RESULT

NYM is not added. Lines count check (wc -l .sovrin/data/nodes/<Node number>/transactions_sandbox/1) shows different count on all 4 nodes but the last transaction is the same on every node except blacklisted. However file from blacklisted node and from turned on node contains near 1000 empty strings.
h6. ADDITIONAL INFORMATION

Restart services on nodes fixes that issue. Attachment contains logs of all 4 nodes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 6:32 PM;aleksey-roldugin;Node1.log;https://jira.hyperledger.org/secure/attachment/11392/Node1.log","28/Jun/17 6:32 PM;aleksey-roldugin;Node2.log;https://jira.hyperledger.org/secure/attachment/11391/Node2.log","28/Jun/17 6:32 PM;aleksey-roldugin;Node3.log;https://jira.hyperledger.org/secure/attachment/11390/Node3.log","28/Jun/17 6:32 PM;aleksey-roldugin;Node4.log;https://jira.hyperledger.org/secure/attachment/11389/Node4.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx0p3:",,,,,,14,INDY 17.21,,,,,,,,,,,,,,,,,,,aleksey-roldugin,anikitinDSR,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 6:32 PM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","12/Oct/18 7:01 PM;anikitinDSR;Pool of 3 worked nodes it's a singular case, and there is no guaranties for NYM ordering. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Enhancement] Validation message about string length should tell that length is meant in bytes,INDY-342,18739,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,aleksey-roldugin,aleksey-roldugin,28/Jun/17 7:12 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,6Months,Could,KellyRetest,,,"h6. BUILD

sovrin-node 0.3.161
sovrin-client 0.3.150

h6. SUMMARY
Current message for SEND_NYM command with invalid length is following:
* ""b58 decoded value length {} should be one of {}""

h6. EXPECTED RESULT
Message should tell that length is meant in bytes
* for example ""b58 decoded value length in bytes {} should be one of {}""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy0zb:",,,,,,,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 7:12 PM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","05/Dec/17 9:17 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactoring,INDY-343,18743,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,lovesh,lovesh,28/Jun/17 11:00 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,CloseCandidate,Could,,,,"Some low priority refactoring needs to done
# Refactor the use of `set_last_ordered_for_non_master`
# Don't access Node's id to set proper value, have a method.
# # Use Req_Ledger_Status consistently for all ledger types in node",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzy0zj:",,,,,,,,,,,,,,,,,,,,,,,,,,lovesh,SeanBohan_Sovrin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Apr/18 3:41 AM;SeanBohan_Sovrin;[~lovesh] can we close this ticket? Is it still relevant?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Packaging .pyc files,INDY-344,18754,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,devin-fisher,devin-fisher,29/Jun/17 2:07 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"We are currently packaging .pyc files into the dep files.

We should not package bytecode files in any of your packages (deb, rpm, etc)

But the .pyc files need to be generated during the install process. We will want to look at standard processes to make sure that they are generated correctly and completely.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,INDY-346,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1un:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,alexander.shekhovcov,devin-fisher,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jul/17 12:43 AM;alexander.shekhovcov;(/)

*Problem reason:*
 * the fpm tool packs python byte-code into a debian package by default

*Changes:*
 * exclude pyc and pyo during packaging
 * add a postinst hook which compiles bytecode after install
 * add a prerm hook which removes bytecode before remove a package

*Committed into:*

[https://github.com/evernym/sovrin-packaging/commit/9799a13327d877b57daf667d6c7355cfbacf759f]

sovrin-node 0.4.15+

sovrin-client 0.4.25+

*Risk factors:*
 Installation/removing all maintained deb packages.

*Risk:*
 Medium

*Covered with tests:*
 The packaging procedure is not supposed to be tested.

*Recommendation:*
 * Install sovrin-node and sovrin-client
 * Check if pyc files exist 

{code:java}
node-admin@sovrin-node1:~$ find /usr/local/lib/python3.5/dist-packages/sovrin_node -name ""*.pyc"" | wc -l
57
node-admin@sovrin-node1:~$ find /usr/local/lib/python3.5/dist-packages/sovrin_client -name ""*.pyc"" | wc -l
118
node-admin@sovrin-node1:~$ find /usr/local/lib/python3.5/dist-packages/plenum -name ""*.pyc"" | wc -l
463
node-admin@sovrin-node1:~$ find /usr/local/lib/python3.5/dist-packages/charm -name ""*.pyc"" | wc -l
152
...{code}
 * Check if there are no pyc files in the deb packages

{code:java}
node-admin@sovrin-node1:~$ dpkg -L sovrin-node | grep -E ""*.pyc$"" | wc -l
0
node-admin@sovrin-node1:~$ dpkg -L sovrin-client | grep -E ""*.pyc$"" | wc -l
0
node-admin@sovrin-node1:~$ dpkg -L python3-plenum | grep -E ""*.pyc$"" | wc -l
0
node-admin@sovrin-node1:~$ dpkg -L python3-charm-crypto | grep -E ""*.pyc$"" | wc -l
0
...{code}
 * Remove sovrin-node and sovrin-client

 

 

 ;;;","14/Jul/17 6:46 PM;alexander.shekhovcov;Please check packages:

[python3-base58|https://repo.evernym.com/deb/pool/xenial/master/p/python3-base58/]

[python3-charm-crypto|https://repo.evernym.com/deb/pool/xenial/master/p/python3-charm-crypto/]

[python3-intervaltree|https://repo.evernym.com/deb/pool/xenial/master/p/python3-intervaltree/]

[python3-ioflo|https://repo.evernym.com/deb/pool/xenial/master/p/python3-ioflo/]

[python3-ledger|https://repo.evernym.com/deb/pool/xenial/master/p/python3-ledger/]

[python3-orderedset|https://repo.evernym.com/deb/pool/xenial/master/p/python3-orderedset/]

[python3-prompt-toolkit|https://repo.evernym.com/deb/pool/xenial/master/p/python3-prompt-toolkit/]

[python3-pyzmq|https://repo.evernym.com/deb/pool/xenial/master/p/python3-pyzmq/]

[python3-raet|https://repo.evernym.com/deb/pool/xenial/master/p/python3-raet/]

[python3-rlp|https://repo.evernym.com/deb/pool/xenial/master/p/python3-rlp/]

[python3-sha3|https://repo.evernym.com/deb/pool/xenial/master/p/python3-sha3/]

[python3-timeout-decorator|https://repo.evernym.com/deb/pool/xenial/master/p/python3-timeout-decorator/]

[indy-anoncreds|https://repo.evernym.com/deb/pool/xenial/master/i/indy-anoncreds/]

[indy-plenum|https://repo.evernym.com/deb/pool/xenial/master/i/indy-plenum/]

[indy-node|https://repo.sovrin.org/deb/pool/xenial/master/i/indy-node/];;;","14/Jul/17 7:57 PM;ozheregelya;Build Info:
  sovrin-client version: 0.4.28
  indy-node version: 0.4.28
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 7 nodes, 1 client

Steps to Validate:
1. Install indy-node.
2. Perform following commands:
{code:java}
find /usr/local/lib/python3.5/dist-packages/sovrin_node -name ""*.pyc"" | wc -l
find /usr/local/lib/python3.5/dist-packages/sovrin_client -name ""*.pyc"" | wc -l
find /usr/local/lib/python3.5/dist-packages/plenum -name ""*.pyc"" | wc -l
find /usr/local/lib/python3.5/dist-packages/charm -name ""*.pyc"" | wc -l{code}
{code:java}
dpkg -L python3-base58 | grep -E ""*.pyc$"" | wc -l
dpkg -L python3-charm-crypto | grep -E ""*.pyc$"" | wc -l
dpkg -L python3-intervaltree | grep -E ""*.pyc$"" | wc -l
dpkg -L python3-ioflo | grep -E ""*.pyc$"" | wc -l
dpkg -L python3-orderedset | grep -E ""*.pyc$"" | wc -l
dpkg -L python3-prompt-toolkit | grep -E ""*.pyc$"" | wc -l
dpkg -L python3-pyzmq | grep -E ""*.pyc$"" | wc -l
dpkg -L python3-raet | grep -E ""*.pyc$"" | wc -l
dpkg -L python3-rlp | grep -E ""*.pyc$"" | wc -l
dpkg -L python3-sha3 | grep -E ""*.pyc$"" | wc -l
dpkg -L python3-timeout-decorator | grep -E ""*.pyc$"" | wc -l
dpkg -L indy-anoncreds | grep -E ""*.pyc$"" | wc -l
dpkg -L indy-plenum | grep -E ""*.pyc$"" | wc -l
dpkg -L indy-node | grep -E ""*.pyc$"" | wc -l{code}
3. Uninstall indy-node.

Actual Results:
{code:java}
root@caf95bae7ce1:/home/sovrin# find /usr/local/lib/python3.5/dist-packages/sovrin_node -name ""*.pyc"" | wc -l
57
root@caf95bae7ce1:/home/sovrin# find /usr/local/lib/python3.5/dist-packages/sovrin_client -name ""*.pyc"" | wc -l
123
root@caf95bae7ce1:/home/sovrin# find /usr/local/lib/python3.5/dist-packages/plenum -name ""*.pyc"" | wc -l
478
root@caf95bae7ce1:/home/sovrin# find /usr/local/lib/python3.5/dist-packages/charm -name ""*.pyc"" | wc -l
152{code}
{code:java}
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-base58 | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-charm-crypto | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-intervaltree | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-ioflo | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-orderedset | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-prompt-toolkit | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-pyzmq | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-raet | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-rlp | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-sha3 | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L python3-timeout-decorator | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L indy-anoncreds | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L indy-plenum | grep -E ""*.pyc$"" | wc -l
0
root@caf95bae7ce1:/home/sovrin# dpkg -L indy-node | grep -E ""*.pyc$"" | wc -l
0{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Identify all valid commands that can be used in the sovrin_config.py file,INDY-345,18755,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,29/Jun/17 2:17 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"*Description*
The sovrin_config.py file is used to override configuration settings like setting the log level.

The task is to identify all possible configuration changes and their valid inputs. Once done do not document in this ticket.

Send all information to Kelly or put your findings into the document "".Override Configuration Settings"" in Kelly's shared google document in the ""Testing/How To"" location. Once this task is complete Kelly will get the information to the tech writer for official documentation.

*Findings*
Created a document *Configuration Settings* describing purposes and formats of all the stp/plenum/sovrin configuration settings. It is located in the shared folder *Development -> Testing -> How To*. It can also be viewed at the following link:
https://docs.google.com/document/d/1NSq0ecO_zg02Pq4E1ej4_8wg0aQqn54I61M6EMVx3oQ",,,97200,97200,,0%,97200,97200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1uv:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,danielhardman,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jul/17 9:26 PM;spivachuk;As discussed with [~lovesh], plenum/sovrin settings were combined with stp settings while this ticket was being in progress. That was done in the following commit:
https://github.com/hyperledger/indy-plenum/commit/f1b737136632862df8ea87b6aa5f706ea5d67675
So stp settings must be added to *Configuration Settings* document.

Re-opened the ticket to add stp settings to *Configuration Settings* document.;;;","12/Jul/17 3:31 AM;spivachuk;Added description of purposes and formats of stp settings to *Configuration Settings* document.;;;","12/Jul/17 1:08 PM;krw910;[~danielhardman] [~spivachuk] did a great job putting together a list of configuration overrides. I will send a link to the document.;;;","14/Jul/17 5:15 AM;danielhardman;[~krw910], will you link to a doc with all the supported config switches, and then move this ticket to ""Done""?;;;","14/Jul/17 11:41 PM;krw910;I have created a link to view this document. It has not passed through our technical writer so it is the raw view at this time.

https://docs.google.com/document/d/1tqpHNdAhgLY0hftIY-tIxp2TkmXNWrMyHv_LzT8czkE/edit?usp=sharing;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Non-reproducible builds ,INDY-346,18756,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,devin-fisher,devin-fisher,29/Jun/17 2:18 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"Sovrin-Node deb package is not reproducible!

This is because the process of creating the deb artifact is not controlled by data in the sovrin-node repo but instead is controlled by the sovrin-packaging repo.  In particular, sovrin-node has pre and post install scripts that come from sovrin-packaging. And sovrin-packaging is not tag in the same way as sovrin-node during our build and publish process.

 

(Devin's option)

We need to relook at our process. We should design is such that all configuration, code and anything else that effect any artifact of our CI or build process must be contained in the repo that is being packaged. 

Doing this has at least two benifits:
 # Makes the whole build pipeline reproducible from a tag in git.
 # Lowers the friction of non-evernym contributors to the code base (they don't have to know about sovrin-packaging or other repos) Especially since sovrin-packaging is a private repo.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,INDY-344,,,,,,,,,,,,"04/Aug/17 7:31 PM;VladimirWork;_deb_size_diff.PNG;https://jira.hyperledger.org/secure/attachment/11828/_deb_size_diff.PNG","04/Aug/17 7:31 PM;VladimirWork;_info_diff.PNG;https://jira.hyperledger.org/secure/attachment/11829/_info_diff.PNG","04/Aug/17 7:31 PM;VladimirWork;_md5_diff.PNG;https://jira.hyperledger.org/secure/attachment/11830/_md5_diff.PNG","04/Aug/17 7:31 PM;VladimirWork;_plenum_manifest_diff.PNG;https://jira.hyperledger.org/secure/attachment/11831/_plenum_manifest_diff.PNG","04/Aug/17 7:31 PM;VladimirWork;_sourcestxt_diff.PNG;https://jira.hyperledger.org/secure/attachment/11832/_sourcestxt_diff.PNG","04/Aug/17 7:45 PM;VladimirWork;ci-builds.tar.gz;https://jira.hyperledger.org/secure/attachment/11833/ci-builds.tar.gz","24/Jul/17 7:40 PM;VladimirWork;debian_control.PNG;https://jira.hyperledger.org/secure/attachment/11754/debian_control.PNG","24/Jul/17 7:40 PM;VladimirWork;debian_md5sums.PNG;https://jira.hyperledger.org/secure/attachment/11755/debian_md5sums.PNG","04/Aug/17 7:45 PM;VladimirWork;docker-builds.tar.gz;https://jira.hyperledger.org/secure/attachment/11834/docker-builds.tar.gz","24/Jul/17 7:40 PM;VladimirWork;info.PNG;https://jira.hyperledger.org/secure/attachment/11756/info.PNG","24/Jul/17 7:40 PM;VladimirWork;manifest.PNG;https://jira.hyperledger.org/secure/attachment/11757/manifest.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8gn:",,,,,,H3,M1 Prelude,10,,,,,,,,,,,,,,,,,,alexander.shekhovcov,andkononykhin,andrey.goncharov,danielhardman,devin-fisher,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/17 11:49 PM;andrey.goncharov;I'd like to weigh in:
 # We can specify sovrin-packaging to use for building the artifact in Jenkinsfile (it can be as simple as a hash of a commit in sovrin-packaging) 
 # We can move post-install and pre-install hooks from sovrin-packaging to corresponding repos, leaving sovrin-packaging with only common build logic;;;","04/Jul/17 3:58 AM;andkononykhin;It seems reasonable and helpful, and in general I don't mind moving mentioned things (as well as I guess lists of excluded files/dirs) but I'm not sure that it follows widely used practice.

Why do we need to publish our way of package maintenance? It's not a secret but it's our own way. What if someone wants to build package for non-systemd oses?;;;","04/Jul/17 7:00 AM;devin-fisher;[~andrey.goncharov] We should be able to reproduce a build with a git tag (not a deb manifest) or what is the point of having them.  We create magic If we maintain the git hash to a separate repo in the built repo.  We want to a developer of INDY to be able to do all of their work reading the code in repo they are working on. I wonder if its worth a lot of custom effort it just to maintain common build logic. How much logic do we envision having? From what I can see there is not much logic in sovrin-packaging that deals with build activities. Most of the complexity of pack_debs.py is dealing with non-uniformity (deb-build.json).  The rest of the repo is dealing with publishing to DEB repos which is not needed to reproducible builds.  Additionally, we hope to move to two main repos in INDY soon. So I question is it worth maintaining common logic when that logic should be a little orchestration and an fpm command.

We want any build we do to be reproducible. Not just the DEB file builds we do now.

[~andkononykhin] We have to be open about the process that we use for INDY or we (evernym or DSR) will be the only ones that can work on the build side of the project. But we don't want that. It would be nice if a lot of people could work on it. The Linux Foundation has full-time employees that share this burden in the future. But only if we build it in a way that is open.

Also, can you elaborate what you mean by ""follows widely used practice."" I'd like to understand that.

 ;;;","04/Jul/17 8:10 PM;andkononykhin;[~devin-fisher]
{quote}Also, can you elaborate what you mean by ""follows widely used practice."" I'd like to understand that.{quote}
It's my impression after checking several repos with source code. I haven't seen packages build routine. I think install routine without packaging is more frequent case.
{quote}We have to be open about the process that we use for INDY or we (evernym or DSR) will be the only ones that can work on the build side of the project.
{quote}
I think you are right but it's not only lack of sharing build routine. I think it's more lack of docs problem.

[~alexander.shekhovcov] is working on moving from fpm in scope of INDY-344 and it seems that it's better to wait his solution before making decision about current task implementation.;;;","14/Jul/17 12:08 AM;alexander.shekhovcov;PoA:
 * place the build scripts in the repos indy-node, indy-plenum, indy-anoncreds
 * leave building 3rd parties (base58, pbc, reat, ...) in the private repo sovrin-packaging
 * leave uploading scripts in the private repo sovrin-packaging;;;","14/Jul/17 11:31 PM;andkononykhin;Assigned to me temporarily: need to improve jenkins scripts to support in-repo defined logic of debs build ;;;","18/Jul/17 10:11 PM;alexander.shekhovcov;(/)
*Problem reason:*
- deb packages are not reproducible

*Changes:*
- place the build logic in the repos: indy-node, indy-plenum, indy-anoncreds
- change maintainer fields
- copy packages from repo.evernym.com to repo.sovrin.org because the maintainer field was changed 
- other build enhancements

*Committed into:*
https://github.com/hyperledger/indy-plenum/pull/280
https://github.com/hyperledger/indy-anoncreds/pull/73
https://github.com/hyperledger/indy-node/pull/237
https://github.com/evernym/sovrin-packaging/tree/feature/reproducible-build
https://github.com/evernym/jenkins-shared/tree/test

indy-anoncreds 0.4.16+
indy-node 0.4.41+
indy-plenum 0.4.58+

*Risk factors:*
 Installation / removing deb packages.

*Risk:* 
 Low

*Covered with tests:*
Testing is not supposed.

*Recommendations for QA:*
1. Install indy-node and do common checks
2. Remove indy-node indy-anoncreds indy-plenum. Removing should not generate any errors and warning

;;;","21/Jul/17 5:28 PM;VladimirWork;Build Info:
sovrin 0.2.11
indy-node 0.4.53
indy-anoncreds 0.4.18
indy-plenum 0.4.64

Steps to Validate:
1. Install sovrin pool and do common checks (send and get NYMs).
2. Remove sovrin -> indy-node -> indy-anoncreds -> indy-plenum.
3. Remove indy-plenum on other node.

Actual Results:
There are no errors/warnings due to installation and removal of packages. Removal of underlying packages also removes all upper packages.;;;","22/Jul/17 1:00 AM;danielhardman;[~VladimirWork], I don't understand how the test procedure that you described will prove that builds are reproducible. My assumption about testing is that we'd use a procedure sort of like this:
 * do a build
 * allow code to evolve
 * do another build that references the same code commits as the original
 * prove that the second build produces a package that is identical to the first one, except perhaps for timestamps and similar noise;;;","24/Jul/17 5:50 PM;alexander.shekhovcov;[~VladimirWork] I suggest the following procedure:
 # Clone indy-node sources
 ** {{git clone git@github.com:hyperledger/indy-node.git}}
 # Checkout the 0.4.53-master tag
 ** {{cd indy-node && git checkout 0.4.53-master}}
 # Make the build using docker
 ** remove ""-dev"" prefixes in setup.py
 ** set __version__=(0,4,53) in_ _metadata__.py
 ** {{cd build-scripts/ubuntu-1604 && ./build-indy-node-docker.sh <ablosute path to cloned repo>}}
 # Compare deb from CI and just built deb 

 * 
 ** docker run -it --rm -v indy-node-deb-u1604:/build ubuntu:16.04 bash
 ** apt update && apt install wget mc
 ** wget [https://repo.sovrin.org/deb/pool/xenial/master/i/indy-node/indy-node_0.4.53_amd64.deb]
 ** open mc and compare content of just downloaded deb and the deb file in the /build/ folder

Post the difference here and let's discuss.

 

 ;;;","24/Jul/17 7:40 PM;VladimirWork;Differences are in attachment. !debian_control.PNG|thumbnail!  !debian_md5sums.PNG|thumbnail!  !info.PNG|thumbnail!  !manifest.PNG|thumbnail! ;;;","24/Jul/17 8:39 PM;alexander.shekhovcov;We still have a part of the build code which lives in CI and sets up source code before build. The build code does:
# replacing `-dev` suffix in setup.py
# creating manifest.txt
# altering some dependencies for indy-node because automatic adding `python3-*` makes indy-node dependent on python3-python-dateutil which does not exist. So we have to use `sed` to replace some lines in setup.py.

[~devin-fisher] [~danielhardman] Could we assume the ticket resolved with the above assumptions?

It is fairly simple to move those steps in the build scripts but testing can take time. I concern about what we can finish testing before MGL. ;;;","31/Jul/17 10:21 PM;alexander.shekhovcov;PRs:
https://github.com/hyperledger/indy-plenum/pull/313
https://github.com/hyperledger/indy-node/pull/267
https://github.com/hyperledger/indy-anoncreds/pull/84
https://github.com/sovrin-foundation/sovrin/pull/7

Waiting when the master branch is unblocked.

*How to test:*
1. download the latest packages https://repo.sovrin.org/deb/pool/xenial/master/i/ https://repo.sovrin.org/deb/pool/xenial/master/s/sovrin/
2. checkout master branches
3. make local builds 
{code}
build-scripts/ubuntu-1604/build-<package name>-docker.sh <path-to-sources> <version> 
{code}
Run a container and attach a volume
{code}
docker run -it --rm -v <package name>-deb-u1604:/build ubuntu:16.04
{code}

4. compare local builds with CI builds

repos:
indy-anoncreds
indy-plenum
indy-node
sovrin

I expect difference in some dates for example in changelog.gz. Anyway let's discuss here the got difference. 




;;;","03/Aug/17 10:55 PM;alexander.shekhovcov;Ready for testing:
indy-anoncreds 1.0.23+
indy-plenum 1.0.82+
indy-node 1.0.75+
sovrin 1.0.18+;;;","04/Aug/17 7:31 PM;VladimirWork;Differences are in attachment. !_deb_size_diff.PNG|thumbnail!  !_info_diff.PNG|thumbnail!  !_md5_diff.PNG|thumbnail!  !_plenum_manifest_diff.PNG|thumbnail!  !_sourcestxt_diff.PNG|thumbnail! ;;;","04/Aug/17 7:46 PM;VladimirWork; [^ci-builds.tar.gz]  [^docker-builds.tar.gz] ;;;","04/Aug/17 10:26 PM;VladimirWork;Build Info:
indy-node 1.0.76
sovrin 1.0.18
indy-plenum 1.0.82
indy-anoncreds 1.0.24

Steps to Validate:
1. Get the CI builds:

wget https://repo.sovrin.org/deb/pool/xenial/master/i/indy-node/indy-node_1.0.76_amd64.deb
wget https://repo.sovrin.org/deb/pool/xenial/master/s/sovrin/sovrin_1.0.18_amd64.deb
wget https://repo.sovrin.org/deb/pool/xenial/master-latest/i/indy-plenum/indy-plenum_1.0.82_amd64.deb
wget https://repo.sovrin.org/deb/pool/xenial/master-latest/i/indy-anoncreds/indy-anoncreds_1.0.24_amd64.deb

2. Get the sources of the same versions and build it with docker:

git clone https://github.com/hyperledger/indy-node.git
cd indy-node && git checkout 1.0.76-master
cd build-scripts/ubuntu-1604 && ./build-indy-node-docker.sh /home/sovrin/indy-node/ 1.0.76

git clone https://github.com/hyperledger/sovrin.git
cd sovrin && git checkout 1.0.18-master
cd build-scripts/ubuntu-1604 && ./build-sovrin-docker.sh /home/sovrin/sovrin/ 1.0.18

git clone https://github.com/hyperledger/indy-plenum.git
cd indy-plenum && git checkout 1.0.82-master
cd build-scripts/ubuntu-1604 && ./build-indy-plenum-docker.sh /home/sovrin/indy-plenum/ 1.0.82

git clone https://github.com/hyperledger/indy-anoncreds.git
cd indy-anoncreds && git checkout 1.0.24-master
cd build-scripts/ubuntu-1604 && ./build-indy-anoncreds-docker.sh /home/sovrin/indy-anoncreds/ 1.0.24

3. Get the docker builds:

docker run -it --rm -v indy-node-deb-u1604:/build ubuntu:16.04
docker cp f4b08d15a8ad:/build/indy-node_1.0.76_amd64.deb /home/sovrin/docker-builds/indy-node_1.0.76_amd64.deb

docker run -it --rm -v sovrin-deb-u1604:/build ubuntu:16.04
docker cp 4439ff24b064:/build/sovrin_1.0.18_amd64.deb /home/sovrin/docker-builds/sovrin_1.0.18_amd64.deb

docker run -it --rm -v indy-plenum-deb-u1604:/build ubuntu:16.04
docker cp e059d2bcde58:/build/indy-plenum_1.0.82_amd64.deb /home/sovrin/docker-builds/indy-plenum_1.0.82_amd64.deb

docker run -it --rm -v indy-anoncreds-deb-u1604:/build ubuntu:16.04
docker cp 4c5cca29718d:/build/indy-anoncreds_1.0.24_amd64.deb /home/sovrin/docker-builds/indy-anoncreds_1.0.24_amd64.deb

4. Compare CI and docker builds.

Actual Results:
There are whole deb size differences only, but not in each file size inside it and the content of files is the same in each build pair.
The deb size differences can be caused by the different compression actions during the build process with CI and Docker and it can be investigated additionally if needed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: Validator Precheck: Run OpenSSH on a non-standard port,INDY-347,18757,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid: Environment Issue,,krw910,krw910,29/Jun/17 3:04 AM,08/Oct/19 8:49 PM,28/Oct/23 2:46 AM,08/Oct/19 8:49 PM,,,,,0,explore,,,,,"OpenSSH server should be run on a non-standard port to prevent attackers from detecting it by port scanning and subsequently trying to bruteforce it.
This again one of those that can be added to Pre-Check during Validator Startup

*Things Tried*


*Findings*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0i7:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 3:06 AM;krw910;SOV-1072;;;","08/Oct/19 8:49 PM;esplinr;This good advice is about securing the machine where Indy Node runs, and is not about Indy Node itself.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: Validator Precheck: Coredump should be disabled on Linux based Validator Nodes,INDY-348,18758,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid: Environment Issue,,krw910,krw910,29/Jun/17 3:08 AM,08/Oct/19 8:49 PM,28/Oct/23 2:46 AM,08/Oct/19 8:49 PM,,,,,0,explore,,,,,"Core Dump is not disabled on Validator, having this enabled has 2 problems: 1. It risks having private keys in memory which may lead to a S, T, I or E
2. It risks filling up HDD on Validator potentially causing a D

To understand the S,T,R,I,D,E mnemonic read: https://docs.google.com/document/d/1kRCbPk3zB0qR5WOkgjUJXwD1pzYZCI0jDjqiwKhZkxs/edit#

There are quite a few such OS environment specific Threats in the system. These should not be fixed individually. It will be better to create a kind of Validator Pre-Check module that runs during a Validator startup and fails it if these checks are not passed.

*Findings*

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0if:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 3:09 AM;krw910;SOV-1071;;;","08/Oct/19 8:49 PM;esplinr;This good advice is about securing the machine where Indy Node runs, and is not about the system itself.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: Validator Precheck: OpenSSH ClientAliveInterval and ClientAliveCountMax is not set,INDY-349,18759,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid: Environment Issue,,krw910,krw910,29/Jun/17 3:10 AM,08/Oct/19 8:50 PM,28/Oct/23 2:46 AM,08/Oct/19 8:50 PM,,,,,0,explore,,,,,"ClientAliveInterval and ClientAliveCountMax is not set. Allowing client connections to stay alive risks unattended ssh sessions to be misused, potentially causing S, T, R, I, D 

To understand the S,T,R,I,D,E mnemonic read: https://docs.google.com/document/d/1kRCbPk3zB0qR5WOkgjUJXwD1pzYZCI0jDjqiwKhZkxs/edit#

This again one of those that can be added to Pre-Check during Validator Startup


*Findings*

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0in:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 3:11 AM;krw910;SOV-1073;;;","08/Oct/19 8:50 PM;ashcherbakov;A good advice, but this is something to be done by Stewards.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: Validator Precheck: OpenSSH X11Forwarding is set to yes,INDY-350,18760,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid: Environment Issue,,krw910,krw910,29/Jun/17 3:15 AM,08/Oct/19 8:50 PM,28/Oct/23 2:46 AM,08/Oct/19 8:50 PM,,,,,0,explore,,,,,"OpenSSH server X11Forwarding is set to yes, this risks allowing X11 traffic through the ssh connection enabling remote graphic content. This could slow down the Validator for no reason, potentially causing D 

To understand the S,T,R,I,D,E mnemonic read: https://docs.google.com/document/d/1kRCbPk3zB0qR5WOkgjUJXwD1pzYZCI0jDjqiwKhZkxs/edit#

This again one of those that can be added to Pre-Check during Validator Startup

*Findings*

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0iv:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 3:24 AM;krw910;SOV-1074;;;","08/Oct/19 8:50 PM;esplinr;This good advice is about securing the machine where Indy Node runs, and is not about the system itself.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: Validator Precheck: Validators not checking NTP sycnhronization,INDY-351,18761,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid: Environment Issue,,krw910,krw910,29/Jun/17 3:27 AM,08/Oct/19 8:52 PM,28/Oct/23 2:46 AM,08/Oct/19 8:52 PM,,,,,0,explore,,,,,"We do not check if Validator Nodes are synchronized against NTP servers this can cause quite a few time related issues, potentially causing D 

To understand the S,T,R,I,D,E mnemonic read: https://docs.google.com/document/d/1kRCbPk3zB0qR5WOkgjUJXwD1pzYZCI0jDjqiwKhZkxs/edit#

This again one of those that can be added to Pre-Check during Validator Startup


*Findings*

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0j3:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 3:27 AM;krw910;SOV-1075;;;","08/Oct/19 8:52 PM;esplinr;Node depends on good time synchronization, but it is currently treated as something outside of the system itself.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: Validator Precheck: Genesis file permissions,INDY-352,18762,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,29/Jun/17 3:29 AM,08/Oct/19 8:58 PM,28/Oct/23 2:46 AM,08/Oct/19 8:58 PM,,,,,0,explore,,,,,"Genesis File : ~/.sovrin/sovrin.env Permissions need to be restrictive, at the moment the permission is 0664
Additionally the genesis file should also be relocated to better location as per the Linux Filesystem Hierarchy Standard 

Malicious users/programs can delete Genesis file or alter its contents so a Node or Agent does not know where to connect which will cause it to fail after restart, potentially causing a T, D


To understand the S,T,R,I,D,E mnemonic read: https://docs.google.com/document/d/1kRCbPk3zB0qR5WOkgjUJXwD1pzYZCI0jDjqiwKhZkxs/edit#

This again one of those that can be added to Pre-Check during Validator Startup

*Findings*

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0jb:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 3:29 AM;krw910;SOV-1076;;;","03/May/18 7:14 PM;zhigunenko.dsr;1.
{noformat}
-rw-r--r-- /etc/indy/indy.env owner: indy - one of node config files
{noformat}
Collateral damage if deleted: node failed to start (indy-node.service: Failed to load environment files: No such file or directory)
If edited: Node is unreachable for other after restart

2.
{noformat}
~/.indy-cli/networks/network_name
-rw-r--r--  owner: indy domain_transactions_genesis
-rw-r--r--  owner: indy pool_transactions_genesis
{noformat}
Collateral damage if deleted: none, even after node restart. Node successfully write new txns

3.
{noformat}
/var/lib/indy/sandbox/
-rw-r--r--  owner: indy domain_transactions_genesis
-rw-r--r--  owner: indy pool_transactions_genesis
{noformat}
Collateral damage if deleted: none, even after node restart. Node successfully write new txns;;;","03/May/18 7:39 PM;zhigunenko.dsr;[~krw910] Please notify if any additions needed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need minimal timestamp info on the ledger,INDY-353,18763,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,29/Jun/17 3:38 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,1,Must,,,,,"daniel.hardman [10:37 AM] 
What are we going to do about timestamps on the ledger? Should we go live without any timestamps? Should we write a consensus timestamp txn to the ledger once a minute?

lovesh [12:28 PM] 
We have not decided about timestamps yet but a very basic implementation is for the primary to assign a timestamp to a batch of txns and non-primaries to accept the batch only if the timestamp is later than that of a previous batch and lies in a duration (+/- x minutes) around their time, this is how bitcoin does it. We are yet to come to a stage where the time is calculated on the basis of mean/median time or some std deviations away from it (edited)

daniel.hardman [12:36 PM] 
That sounds quite reasonable. I don't think it's necessary to do anything super fancy yet, but I think we need at least minimal timestamp data on the ledger from the beginning of its history.

*Update:*
While implementing this consider what needs to be done when one node finds the timestamp from primary unacceptable? After it see sufficient PREPAREs, it should accept the PRE-PREPARE and take an action to fix its clock.
This process is not exactly like bitcoin, as in bitcoin nodes exchange timestamps when they connect to each other and the median value of those timestamps is part the calculation for validating timestamp of the next block",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1v3:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,danielhardman,Komhar,krw910,lovesh,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/17 12:25 AM;mzk-vct;As far as I know every change that we do should not be obstacle for upgrading the node. So, what timestamps are going to be assigned to transactions that are already in ledger?
Also, how exactly it is going to be stored? ;;;","13/Jul/17 1:22 AM;lovesh;Old transactions will not be assigned any timestamp. We will store UTC timestamp, with second precision for each transaction even though transactions of a batch will have the same time;;;","13/Jul/17 8:26 PM;mzk-vct;Will timestamps somehow affect transaction hashes and hence tree root? ;;;","13/Jul/17 8:44 PM;lovesh;Yes;;;","14/Jul/17 3:03 AM;lovesh;PR, https://github.com/hyperledger/indy-plenum/pull/278;;;","18/Jul/17 5:33 AM;krw910;With the latest builds you will start to see a time stamp in the ledger for the transactions. It will look like the following:
V4SGRU86Z58d6TV7PBUe6f|1500090331922505|5iBLSL3iujkNsX4RiGN7RjDk5UVtE8GHsn8XHsRsmhUUN9Jz8GEmYtpPrso8e96jo3YafhYSwPkd9QXYA3wYyst4|1500090332|1|Pqs6Tyj1huDsjKYsiF8w4f|~WwZD24Fk4ka7ZY47MPopoo||||||2||

The time stamp is the entry that shows 1500090332
The 1500090332 is the utc epoch and a converter can be found at this site https://www.epochconverter.com/ so you can see the human readable version of the time.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Valid write transactions may be rejected as having invalid signatures (case 1),INDY-354,18768,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,spivachuk,spivachuk,29/Jun/17 7:41 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,Must,Stability,,,,"This bug was occurred when running the following test script with the following parameters

{{test_some_write_keys_others_read_them --writers 4 --readers 20 --iterations 10}}

using the following configuration:
* sovrin-client master 0.3.150 (a local VM),
* sovrin-node master 0.3.154 (Shakedown Pool 3).

See the attached logs for details.

NOTE:
The following files added in scope of this ticket have been copied manually to the VM with sovrin-client since Jenkins was being off at that moment and so there was no way to issue a new version:
* sovrin-client/sovrin_client/utils/
* sovrin-client/sovrin_client/utils/__init__.py
* sovrin-client/sovrin_client/utils/user_scenarios.py
* sovrin-client/scripts/test_some_write_keys_others_read_them
* sovrin-client/scripts/test_users_write_and_read_own_keys",,,,,,,,,,,INDY-836,,,,,,,,,,,,,,,,INDY-355,,,,,,,,"30/Jun/17 12:06 AM;spivachuk;Node1.log;https://jira.hyperledger.org/secure/attachment/11495/Node1.log","30/Jun/17 12:06 AM;spivachuk;Node2.log;https://jira.hyperledger.org/secure/attachment/11496/Node2.log","30/Jun/17 12:09 AM;spivachuk;Node3.log;https://jira.hyperledger.org/secure/attachment/11498/Node3.log","30/Jun/17 12:06 AM;spivachuk;Node4.log;https://jira.hyperledger.org/secure/attachment/11497/Node4.log","29/Jun/17 9:59 PM;spivachuk;common.log;https://jira.hyperledger.org/secure/attachment/11446/common.log","29/Jun/17 9:59 PM;spivachuk;nyms-creator-000000000000000000000000Steward1.log;https://jira.hyperledger.org/secure/attachment/11447/nyms-creator-000000000000000000000000Steward1.log","29/Jun/17 9:59 PM;spivachuk;reader-1856Ee3A3BDAc536a347b7e4BcAD43A0.log;https://jira.hyperledger.org/secure/attachment/11457/reader-1856Ee3A3BDAc536a347b7e4BcAD43A0.log","29/Jun/17 9:59 PM;spivachuk;reader-1ADdB6FDfb9EdeFEbBA3E0DFEbaC0D42.log;https://jira.hyperledger.org/secure/attachment/11448/reader-1ADdB6FDfb9EdeFEbBA3E0DFEbaC0D42.log","29/Jun/17 9:59 PM;spivachuk;reader-1bD3Bd0d657DAD747E42fAe2CBeFF655.log;https://jira.hyperledger.org/secure/attachment/11449/reader-1bD3Bd0d657DAD747E42fAe2CBeFF655.log","29/Jun/17 9:59 PM;spivachuk;reader-3Fd1C6bc4D4ec25DF653BBFa6abbA068.log;https://jira.hyperledger.org/secure/attachment/11451/reader-3Fd1C6bc4D4ec25DF653BBFa6abbA068.log","29/Jun/17 9:59 PM;spivachuk;reader-3cdE73a5d83725f7Be9539aD4C4A0b35.log;https://jira.hyperledger.org/secure/attachment/11450/reader-3cdE73a5d83725f7Be9539aD4C4A0b35.log","29/Jun/17 9:59 PM;spivachuk;reader-6af3b459fAfedACaDae3c2deC3E844fF.log;https://jira.hyperledger.org/secure/attachment/11452/reader-6af3b459fAfedACaDae3c2deC3E844fF.log","29/Jun/17 9:59 PM;spivachuk;reader-956e6e015aa8A55bf0df2097B250D83E.log;https://jira.hyperledger.org/secure/attachment/11456/reader-956e6e015aa8A55bf0df2097B250D83E.log","29/Jun/17 9:59 PM;spivachuk;reader-95Dc0478fC2F0D6Eb8AAebedAF3D4Df8.log;https://jira.hyperledger.org/secure/attachment/11455/reader-95Dc0478fC2F0D6Eb8AAebedAF3D4Df8.log","29/Jun/17 9:59 PM;spivachuk;reader-9712C2FdE5bebCe89c27C4eCb97F9Df0.log;https://jira.hyperledger.org/secure/attachment/11458/reader-9712C2FdE5bebCe89c27C4eCb97F9Df0.log","29/Jun/17 9:59 PM;spivachuk;reader-9dFc2Dba637fC0818554d6eC8cdfFa8f.log;https://jira.hyperledger.org/secure/attachment/11453/reader-9dFc2Dba637fC0818554d6eC8cdfFa8f.log","29/Jun/17 9:59 PM;spivachuk;reader-9eCD5a3CCaBf6A5dF95E2B4d8cB6F149.log;https://jira.hyperledger.org/secure/attachment/11454/reader-9eCD5a3CCaBf6A5dF95E2B4d8cB6F149.log","29/Jun/17 9:59 PM;spivachuk;reader-AccAA1e3dd5485bC73ee4dfbbFF4Aacb.log;https://jira.hyperledger.org/secure/attachment/11459/reader-AccAA1e3dd5485bC73ee4dfbbFF4Aacb.log","29/Jun/17 9:59 PM;spivachuk;reader-Cd66fa35fD5dAAd3B9C609FFbFF656FC.log;https://jira.hyperledger.org/secure/attachment/11464/reader-Cd66fa35fD5dAAd3B9C609FFbFF656FC.log","29/Jun/17 9:59 PM;spivachuk;reader-DD1Bdf345Fcf9690cf2644deE24C9f96.log;https://jira.hyperledger.org/secure/attachment/11465/reader-DD1Bdf345Fcf9690cf2644deE24C9f96.log","29/Jun/17 9:59 PM;spivachuk;reader-Ddf875d29d1E777E7d8f5d3eA74Fd7C0.log;https://jira.hyperledger.org/secure/attachment/11466/reader-Ddf875d29d1E777E7d8f5d3eA74Fd7C0.log","29/Jun/17 9:59 PM;spivachuk;reader-aec0bF4004D8b10cEC4ed9af2dE7cb0f.log;https://jira.hyperledger.org/secure/attachment/11460/reader-aec0bF4004D8b10cEC4ed9af2dE7cb0f.log","29/Jun/17 9:59 PM;spivachuk;reader-aef590c7512b62d6CA6e047623a0B6DC.log;https://jira.hyperledger.org/secure/attachment/11461/reader-aef590c7512b62d6CA6e047623a0B6DC.log","29/Jun/17 9:59 PM;spivachuk;reader-cBDC74b1C8DdfC7bf116c70146Aa4f3e.log;https://jira.hyperledger.org/secure/attachment/11462/reader-cBDC74b1C8DdfC7bf116c70146Aa4f3e.log","29/Jun/17 9:59 PM;spivachuk;reader-cc40d94E2E792997F7ABeE37eEeCd915.log;https://jira.hyperledger.org/secure/attachment/11463/reader-cc40d94E2E792997F7ABeE37eEeCd915.log","29/Jun/17 9:59 PM;spivachuk;reader-f8A1B9B4920AC1CBF4c0DCcAEF9462F2.log;https://jira.hyperledger.org/secure/attachment/11467/reader-f8A1B9B4920AC1CBF4c0DCcAEF9462F2.log","29/Jun/17 9:59 PM;spivachuk;writer-4DF3bfc4bED8B3ACAdB1AF9ee06A3FF6.log;https://jira.hyperledger.org/secure/attachment/11468/writer-4DF3bfc4bED8B3ACAdB1AF9ee06A3FF6.log","29/Jun/17 9:59 PM;spivachuk;writer-4eccEd3EcEbB0F4be7D4AacBb9a56e5d.log;https://jira.hyperledger.org/secure/attachment/11469/writer-4eccEd3EcEbB0F4be7D4AacBb9a56e5d.log","29/Jun/17 9:59 PM;spivachuk;writer-C55304EEBDbB3F2Ff7A7fB4aD44a17fD.log;https://jira.hyperledger.org/secure/attachment/11470/writer-C55304EEBDbB3F2Ff7A7fB4aD44a17fD.log","29/Jun/17 9:59 PM;spivachuk;writer-dcecE6BFCdb4bBAB1e4f127Ffd18DDBa.log;https://jira.hyperledger.org/secure/attachment/11471/writer-dcecE6BFCdb4bBAB1e4f127Ffd18DDBa.log",,,,,,,,,INDY-781,,,,,,,,,,"1|hzx0yf:",,,,,,INDY 17.24: Node Perf,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,ozheregelya,spivachuk,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 7:13 AM;stevetolman;[~spivachuk], [~mzk-vct] We are moving this ticket and ticket indy-355 to the M1 sprint unless you can give us good reasons to keep them in H5.;;;","15/Jul/17 2:44 AM;spivachuk;[~stevetolman], the issue revealed in both these tickets seems to be caused by that in the current implementation a node replies to a write transaction before it is completely applied to the ledger.

The load test used in this ticket checks the case when some users in parallel update their own verkeys cyclically while other users in parallel read the verkeys of the former cyclically. The load test used in INDY-355 checks the case when all users in parallel update and read their own verkeys cyclically. The behavior with replying to transactions before they are completely applied to the ledger can result in our case in that the signature of a next transaction updating the user's verkey is verified against an expired verkey instead of the last set verkey. And this seems to be the reason of the issue observed. The issue is reproduced under a load of about 20 simultaneous users.

We guess that this issue should not occur if there are pauses between successive write transactions related to the same nym. However, this guess may not be the case because the test {{test_users_write_and_read_own_keys}} (used in INDY-355) performs verification before each next verkey update that the verkey set for the user last time is returned when reading from the ledger and this verification succeeds each time.

I think that we should clarify the conditions when the issue occurs in order to prioritize it right. To do this we should add delays to the user actions cycles and check whether the issue is reproduced or not when these delays are increased or decreased.;;;","29/Aug/17 5:10 PM;ashcherbakov;Looks like the issue is fixed in the scope of INDY-761. We need to test this one after INDY-761 is done.;;;","12/Sep/17 11:11 PM;ozheregelya;Specified in description script is still using CIDs instead of DIDs and adding to the ledger CID of default steward does not help. This problem with test scripts described in INDY-836. So, this ticket can't be tested before fix of INDY-836.;;;","28/Sep/17 5:39 PM;ashcherbakov;The behaviour described in this ticket is OK, since we can not guarantee that just written value will be immediately available to use (this is specific of consensus protocols). 
A client needs to check seqNo/txnTime in the Reply to decide whether the reply is fresh enough.;;;","07/Nov/17 11:39 PM;ashcherbakov;This should be solved by the client checking the tinestamp/seqNo of the Reply to make sure that this is the desired and fresh enough reply;;;","28/Nov/17 6:58 AM;krw910;[~ozheregelya] take a look at this ticket. If it is not fixed and needs to be reopened push it to the bottom of the backlog with comments. We don't want to add more development work to this sprint.;;;","28/Nov/17 5:25 PM;ashcherbakov;[~krw910] I don't think there is something to be checked or fixes here. The behaviour in the ticket is expected. 
There is no timestamp check on the client (and on the tests used in this task).;;;","29/Nov/17 2:03 AM;ozheregelya;As I can see in previous Alex's comment and in Daniel's comment in INDY-716 (https://jira.hyperledger.org/browse/INDY-761?focusedCommentId=31257&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-31257 ), this is expected behavior. By the way, test script from description still doesn't work. I think I should close this ticket as won't fix.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Valid write transactions may be rejected as having invalid signatures (case 2),INDY-355,18769,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,spivachuk,spivachuk,29/Jun/17 8:10 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,Must,Stability,,,,"This bug was occurred when running the following test script with the following parameters

{{test_users_write_and_read_own_keys --users 20 --iterations 10}}

using the following configuration:
* sovrin-client master 0.3.150 (a local VM),
* sovrin-node master 0.3.154 (Shakedown Pool 3).

See the attached logs for details.

NOTE:
The following files added in scope of this ticket have been copied manually to the VM with sovrin-client since Jenkins was being off at that moment and so there was no way to issue a new version:
* sovrin-client/sovrin_client/utils/
* sovrin-client/sovrin_client/utils/__init__.py
* sovrin-client/sovrin_client/utils/user_scenarios.py
* sovrin-client/scripts/test_some_write_keys_others_read_them
* sovrin-client/scripts/test_users_write_and_read_own_keys",,,,,,,,,,,INDY-836,,,,,,,,,,,,INDY-354,,,,,,,,,,,,"30/Jun/17 12:10 AM;spivachuk;Node1.log;https://jira.hyperledger.org/secure/attachment/11499/Node1.log","30/Jun/17 12:10 AM;spivachuk;Node2.log;https://jira.hyperledger.org/secure/attachment/11500/Node2.log","30/Jun/17 12:10 AM;spivachuk;Node3.log;https://jira.hyperledger.org/secure/attachment/11501/Node3.log","30/Jun/17 12:10 AM;spivachuk;Node4.log;https://jira.hyperledger.org/secure/attachment/11502/Node4.log","29/Jun/17 10:09 PM;spivachuk;common.log;https://jira.hyperledger.org/secure/attachment/11472/common.log","29/Jun/17 10:09 PM;spivachuk;nyms-creator-000000000000000000000000Steward1.log;https://jira.hyperledger.org/secure/attachment/11473/nyms-creator-000000000000000000000000Steward1.log","29/Jun/17 10:09 PM;spivachuk;user-2DCcBBcE119caaB285C17ecaaC5c7C77.log;https://jira.hyperledger.org/secure/attachment/11474/user-2DCcBBcE119caaB285C17ecaaC5c7C77.log","29/Jun/17 10:09 PM;spivachuk;user-3dfd4311DABFF02B4451Fd8AbdcE7CF4.log;https://jira.hyperledger.org/secure/attachment/11475/user-3dfd4311DABFF02B4451Fd8AbdcE7CF4.log","29/Jun/17 10:09 PM;spivachuk;user-49EB05Ba2CCB345053e4dbAE12BBa7CC.log;https://jira.hyperledger.org/secure/attachment/11479/user-49EB05Ba2CCB345053e4dbAE12BBa7CC.log","29/Jun/17 10:09 PM;spivachuk;user-7Fd4dbcf514BDa5271A4Ac2fB2599Ff8.log;https://jira.hyperledger.org/secure/attachment/11476/user-7Fd4dbcf514BDa5271A4Ac2fB2599Ff8.log","29/Jun/17 10:09 PM;spivachuk;user-802F0823b3FcbcCf0CdD27E5c722ea16.log;https://jira.hyperledger.org/secure/attachment/11480/user-802F0823b3FcbcCf0CdD27E5c722ea16.log","29/Jun/17 10:09 PM;spivachuk;user-855EDdc74E2E79ed0DffefFc241eD56D.log;https://jira.hyperledger.org/secure/attachment/11481/user-855EDdc74E2E79ed0DffefFc241eD56D.log","29/Jun/17 10:09 PM;spivachuk;user-9F35Ea399Bc7EFF0e4Dff5b4FaF3B1b8.log;https://jira.hyperledger.org/secure/attachment/11478/user-9F35Ea399Bc7EFF0e4Dff5b4FaF3B1b8.log","29/Jun/17 10:09 PM;spivachuk;user-9f16c61AbECeBE3c8BEBAD4d1c6A0E1B.log;https://jira.hyperledger.org/secure/attachment/11477/user-9f16c61AbECeBE3c8BEBAD4d1c6A0E1B.log","29/Jun/17 10:09 PM;spivachuk;user-CAc2B33Baa507AbDaEBeB62EbDEeeE4E.log;https://jira.hyperledger.org/secure/attachment/11485/user-CAc2B33Baa507AbDaEBeB62EbDEeeE4E.log","29/Jun/17 10:09 PM;spivachuk;user-De5987fce99aD6d1EfE27975e4d24f88.log;https://jira.hyperledger.org/secure/attachment/11486/user-De5987fce99aD6d1EfE27975e4d24f88.log","29/Jun/17 10:09 PM;spivachuk;user-Eb37f494aA282c5dC7b5c1fE7a8a4b4d.log;https://jira.hyperledger.org/secure/attachment/11487/user-Eb37f494aA282c5dC7b5c1fE7a8a4b4d.log","29/Jun/17 10:09 PM;spivachuk;user-Ed9c0da29Fa6b9af21Ff9aAFad24cfBB.log;https://jira.hyperledger.org/secure/attachment/11488/user-Ed9c0da29Fa6b9af21Ff9aAFad24cfBB.log","29/Jun/17 10:09 PM;spivachuk;user-F0fc55FeeEDb3deDC1cdeC0F7d0d3Caf.log;https://jira.hyperledger.org/secure/attachment/11490/user-F0fc55FeeEDb3deDC1cdeC0F7d0d3Caf.log","29/Jun/17 10:09 PM;spivachuk;user-F7127CaD464DFe62dbf3B30FF8Eb1Db4.log;https://jira.hyperledger.org/secure/attachment/11492/user-F7127CaD464DFe62dbf3B30FF8Eb1Db4.log","29/Jun/17 10:09 PM;spivachuk;user-FC495F847D0acd1FEFED7C7D4ffe440d.log;https://jira.hyperledger.org/secure/attachment/11493/user-FC495F847D0acd1FEFED7C7D4ffe440d.log","29/Jun/17 10:09 PM;spivachuk;user-aFCD971734Faa14CA1eA17D75b91B447.log;https://jira.hyperledger.org/secure/attachment/11482/user-aFCD971734Faa14CA1eA17D75b91B447.log","29/Jun/17 10:09 PM;spivachuk;user-b6f47de94Cdf8a9E102cfECC6bD1a737.log;https://jira.hyperledger.org/secure/attachment/11483/user-b6f47de94Cdf8a9E102cfECC6bD1a737.log","29/Jun/17 10:09 PM;spivachuk;user-cA4D33f567936AbEAdF92AC6454cde4c.log;https://jira.hyperledger.org/secure/attachment/11484/user-cA4D33f567936AbEAdF92AC6454cde4c.log","29/Jun/17 10:09 PM;spivachuk;user-efC88E124EEf809Bcc196DeFCdDAbCfA.log;https://jira.hyperledger.org/secure/attachment/11489/user-efC88E124EEf809Bcc196DeFCdDAbCfA.log","29/Jun/17 10:09 PM;spivachuk;user-f6F4ecc3E71Cd5ac8BbA2aFD6909a3aB.log;https://jira.hyperledger.org/secure/attachment/11491/user-f6F4ecc3E71Cd5ac8BbA2aFD6909a3aB.log",,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx0yn:",,,,,,INDY 17.24: Node Perf,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,ozheregelya,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Aug/17 5:10 PM;ashcherbakov;Looks like the issue is fixed in the scope of INDY-761. We need to test this one after INDY-761 is done.;;;","12/Sep/17 11:11 PM;ozheregelya;Specified in description script is still using CIDs instead of DIDs and adding to the ledger CID of default steward does not help. This problem with test scripts described in INDY-836. So, this ticket can't be tested before fix of INDY-836.;;;","28/Sep/17 5:40 PM;ashcherbakov;The behaviour described in this ticket is OK, since we can not guarantee that just written value will be immediately available to use (this is specific of consensus protocols). 
A client needs to check seqNo/txnTime in the Reply to decide whether the reply is fresh enough.;;;","07/Nov/17 11:39 PM;ashcherbakov;This should be solved by the client checking the tinestamp/seqNo of the Reply to make sure that this is the desired and fresh enough reply;;;","28/Nov/17 6:58 AM;krw910;[~ozheregelya] take a look at this ticket. If it is not fixed and needs to be reopened push it to the bottom of the backlog with comments. We don't want to add more development work to this sprint.;;;","28/Nov/17 5:25 PM;ashcherbakov;[~krw910] I don't think there is something to be checked or fixes here. The behaviour in the ticket is expected. 
There is no timestamp check on the client (and on the tests used in this task).;;;","29/Nov/17 2:05 AM;ozheregelya;As I can see in previous Alex's comment and in Daniel's comment in INDY-716 (https://jira.hyperledger.org/browse/INDY-761?focusedCommentId=31257&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-31257 ), this is expected behavior. By the way, test script from description still doesn't work. I think I should close this ticket as won't fix.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node with malformed ldb files has inconsistent behavior,INDY-356,18814,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,29/Jun/17 10:47 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,6Months,KellyRetest,should,,,"Build Info:
sovrin-node 0.3.161
sovrin-client 0.3.150

Overview:
Node with malformed ldb files has inconsistent behavior.

Steps to Reproduce - Case 1:
1. Delete any symbols from last changed ~/attr_db/ .ldb file.
2. Start the node with malformed ldb file.

Steps to Reproduce - Case 2:
1. Delete any symbols from last changed ~/config_state/ .ldb file.
2. Start the node with malformed ldb file.

Actual Results:
1. Node starts successful if files in ~/attr_db/, ~/idr_cache_db/, ~/seq_no_db/ are malformed.
2. Node fails if files in ~/config_state/, ~/domain_state/, ~/pool_state/ are malformed.

Expected Results:
Clarification is needed due to +node starts successful when ALL this ldb files are absent+ (and they are partially recreated during the work with node).",,,,,,,,,,,,,,,,,,,,,,,INDY-308,,,,INDY-286,,,,,,,,"29/Jun/17 10:47 PM;VladimirWork;node_fails.txt;https://jira.hyperledger.org/secure/attachment/11494/node_fails.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzwyqf:",,,,,,,,,,,,,,,,,,,,,,,,,,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 10:49 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","23/Jan/18 12:11 AM;VladimirWork;Cases will be retested in scope of INDY-286.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] [Enhancement] Improvements for tips in 'help' command ,INDY-357,18815,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Lowest,Won't Do,stevetolman,aleksey-roldugin,aleksey-roldugin,29/Jun/17 11:29 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,CloseCandidate,,,,,"h6. BUILD

sovrin-node 0.3.161
sovrin-client 0.3.150

h6. SUMMARY
* In current implementation after typing _help_ tips mentioned below appear. _node_ tip is unnecessary because there is no command starting from _node_ word.
** status
** new
** node
** client
* Probably list with tips can contain more commands. On the other hand it can be empty by default but when user starts typing first letters of command all commands that are started from these letters will appear in the list.
* When user types anything after _help_ word (ex. ""help a"") list with 2 tips (_help_, _status_) appears. It's redundant. Probably real possible for entering word can appear (ex. list with words _proofreq_, _proof_ appears after typing _send_)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy0zr:",,,,,,,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 11:29 PM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","05/Dec/17 9:29 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Agent and Node code is constantly running ""stat"" system call in a tight loop",INDY-358,18819,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,krw910,krw910,29/Jun/17 11:41 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"When the agent is running, I am getting the following continuously in the log:

{code}
2017-04-03 21:47:51,794 | INFO     | looper.py            (205) | runOnceNicely | it took 0.575 seconds to run once nicely
2017-04-03 21:47:51,959 | WARNING  | base_events.py       (1308) | _run_once | Executing <Task pending coro=<Looper.runForever() running at /usr/local/lib/python3.5/dist-packages/plenum/common/looper.py:215> wait_for=<Future pending cb=[Task._wakeup()] created at /usr/lib/python3.5/asyncio/base_events.py:252> cb=[_run_until_complete_cb() at /usr/lib/python3.5/asyncio/base_events.py:164]> took 0.165 seconds
2017-04-03 21:47:52,948 | WARNING  | base_events.py       (1308) | _run_once | Executing <Task pending coro=<Looper.runForever() running at /usr/local/lib/python3.5/dist-packages/plenum/common/looper.py:215> wait_for=<Future pending cb=[Task._wakeup()] created at /usr/lib/python3.5/asyncio/base_events.py:252> cb=[_run_until_complete_cb() at /usr/lib/python3.5/asyncio/base_events.py:164]> took 0.249 seconds
2017-04-03 21:47:53,279 | WARNING  | base_events.py       (1308) | _run_once | Executing <Task pending coro=<Looper.runForever() running at /usr/local/lib/python3.5/dist-packages/plenum/common/looper.py:215> wait_for=<Future pending cb=[Task._wakeup()] created at /usr/lib/python3.5/asyncio/base_events.py:252> cb=[_run_until_complete_cb() at /usr/lib/python3.5/asyncio/base_events.py:164]> took 0.330 seconds
2017-04-03 21:47:53,609 | INFO     | looper.py            (205) | runOnceNicely | it took 0.660 seconds to run once nicely
2017-04-03 21:47:54,105 | WARNING  | base_events.py       (1308) | _run_once | Executing <Task pending coro=<Looper.runForever() running at /usr/local/lib/python3.5/dist-packages/plenum/common/looper.py:215> wait_for=<Future pending cb=[Task._wakeup()] created at /usr/lib/python3.5/asyncio/base_events.py:252> cb=[_run_until_complete_cb() at /usr/lib/python3.5/asyncio/base_events.py:164]> took 0.496 seconds
2017-04-03 21:47:54,598 | WARNING  | base_events.py       (1308) | _run_once | Executing <Task pending coro=<Looper.runForever() running at /usr/local/lib/python3.5/dist-packages/plenum/common/looper.py:215> wait_for=<Future pending cb=[Task._wakeup()] created at /usr/lib/python3.5/asyncio/base_events.py:252> cb=[_run_until_complete_cb() at /usr/lib/python3.5/asyncio/base_events.py:164]> took 0.330 seconds
{code}

The process is not serving any requests, yet it is almost constantly using anywhere from 10-60% of the CPU (though it occasionally drops to 3.7%). Running the process under {{strace}} reveals it is constantly running the {{stat}} system call in what appears to be a tight loop:

{code}
stat(""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", {st_mode=S_IFREG|0644, st_size=12309, ...}) = 0
stat(""/usr/lib/python3.5/asyncio/events.py"", {st_mode=S_IFREG|0644, st_size=21505, ...}) = 0
stat(""/usr/lib/python3.5/asyncio/tasks.py"", {st_mode=S_IFREG|0644, st_size=25567, ...}) = 0
stat(""/usr/local/lib/python3.5/dist-packages/plenum/common/looper.py"", {st_mode=S_IFREG|0644, st_size=10089, ...}) = 0
stat(""/usr/lib/python3.5/runpy.py"", {st_mode=S_IFREG|0644, st_size=11394, ...}) = 0
stat(""/usr/lib/python3.5/asyncio/base_events.py"", {st_mode=S_IFREG|0644, st_size=51862, ...}) = 0
stat(""/home/agent/unicorn/unicorn/agent/unicornA.py"", {st_mode=S_IFREG|0664, st_size=4135, ...}) = 0
stat(""/usr/lib/python3.5/asyncio/coroutines.py"", {st_mode=S_IFREG|0644, st_size=9593, ...}) = 0
stat(""/usr/local/lib/python3.5/dist-packages/sovrin_client/agent/agent.py"", {st_mode=S_IFREG|0644, st_size=8387, ...}) = 0
stat(""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", {st_mode=S_IFREG|0644, st_size=12309, ...}) = 0
stat(""/usr/lib/python3.5/asyncio/events.py"", {st_mode=S_IFREG|0644, st_size=21505, ...}) = 0
stat(""/usr/lib/python3.5/asyncio/tasks.py"", {st_mode=S_IFREG|0644, st_size=25567, ...}) = 0
stat(""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", {st_mode=S_IFREG|0644, st_size=26088, ...}) = 0
stat(""/usr/local/lib/python3.5/dist-packages/plenum/common/looper.py"", {st_mode=S_IFREG|0644, st_size=10089, ...}) = 0
stat(""/usr/lib/python3.5/runpy.py"", {st_mode=S_IFREG|0644, st_size=11394, ...}) = 0
clock_gettime(CLOCK_MONOTONIC, {2196, 580780534}) = 0
clock_gettime(CLOCK_REALTIME, {1491257540, 434410645}) = 0
recvfrom(7, 0x30499c0, 2048, 0, 0x7ffdd0d3bbc0, 0x7ffdd0d3bb8c) = -1 EAGAIN (Resource temporarily unavailable)
stat(""/usr/lib/python3.5/asyncio/base_events.py"", {st_mode=S_IFREG|0644, st_size=51862, ...}) = 0
stat(""/home/agent/unicorn/unicorn/agent/unicornA.py"", {st_mode=S_IFREG|0664, st_size=4135, ...}) = 0
stat(""/usr/lib/python3.5/asyncio/coroutines.py"", {st_mode=S_IFREG|0644, st_size=9593, ...}) = 0
stat(""/usr/local/lib/python3.5/dist-packages/sovrin_client/agent/agent.py"", {st_mode=S_IFREG|0644, st_size=8387, ...}) = 0
{code}

In my opinion, this is really bad behavior. There shouldn't be any reason to be constantly checking to see if these files that have already been loaded into memory still exist on disk.",,,32400,32400,,0%,32400,32400,,,INDY-414,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy21r:",,,,,,H4,,,,,,,,,,,,,,,,,,,,andkononykhin,davidlehn,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 11:42 PM;krw910;SOV-887;;;","29/Jun/17 11:42 PM;krw910;From Trev Harmon

On a ""clean"" system, the process appears to be taking between 10-11% CPU usage at idle:
{code}
top - 23:14:26 up  1:39,  6 users,  load average: 0.77, 0.39, 0.15
Tasks: 116 total,   3 running, 113 sleeping,   0 stopped,   0 zombie
%Cpu(s): 37.2 us,  1.8 sy,  0.0 ni, 61.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :   498296 total,     6104 free,   243028 used,   249164 buff/cache
KiB Swap:        0 total,        0 free,        0 used.   222408 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
 1997 agent     20   0  129348  52692   7520 R 11.3 10.6   0:14.90 python3
 1980 agent     20   0  130368  52564   6484 R 10.6 10.5   0:17.82 python3
 2013 agent     20   0  129428  53676   8248 S 10.6 10.8   0:11.55 python3
 1949 agent     20   0  130016  52804   6608 S 10.3 10.6   0:31.59 python3
 1813 agent     20   0   40524   2964   2324 R  0.3  0.6   0:00.46 top
{code}

The above is the top output on a system running four copies of the agent that have reached steady state.;;;","29/Jun/17 11:43 PM;krw910;We are also seeing this with the sovrin-node. We are using 10% CPU at idle just like sovrin-client. My guess is that what will fix one will fix the other. If this is not the case then please log a separate ticket for the node or let me know and I can do it.;;;","13/Jul/17 10:51 PM;andkononykhin;Testing the problem 
------------------- 
 
Env: 
    - sovrin-client=0.4.19, sovrin-node=0.4.10 (master) 
    - nodes pool and client started locally inside docker 
 
Testing results: 
    - didn't reproduce logs issue mentioed in description 
    - did reproduce issue with high CPU usage 
        about 25% for node 
        about 8% for client 
 
Why that happens: 
    it is caused by current logic of asyncio couroutine processing. In particular, it grows up 
    from logic of Prodables utilization in stp_core/loop/looper.py: 
 
      - runForever() calls runOnceNicely() in infinite loop 
      - runOnceNicely() calls all Prodables to do their stuff with conditional async sleep for 0.01 secs in case all Prodable haven't done anything in last round
 
What does it mean: 
    - we don't wait any events, we constantly check if they have happend 
    - we process all Prodables coroutines constantly even nothing to process -> CPU usage waste 
 
I tried to tune sleep timeout and checked CPU usage by sovrin client process in idle state inside my test docker container: 
    0.1s     1% CPU
    0.01s    8%  CPU
    0.001 s  41%  CPU
 
On real machine numbers could differ but I think the behaviour will be the same.

I don't think that current task could be resolved with some easy fix but instead the whole architecture should be reviewed and adjusted for real event driven behavior.

I've created a task INDY-414 for that and attached a document with more details and proposals:
https://docs.google.com/document/d/1m0pLAMKWRVdAxZN4ardDKGh_xV0J-0SBP-LCDOeN0M8/edit#heading=h.qapj7lclfhub;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Re-factor] Do not load and process ALL transactions from a Ledger,INDY-359,18820,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,stevetolman,krw910,krw910,29/Jun/17 11:46 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"We have multiple places where we call `ledger.getAllTxn()` and iterate through them.
It's very inefficient for a huge production ledger (especially domain one).

We need to make sure that we don't call getAllTxn() for Domain ledger.
It's also not good to call it for pool and config ledgers, but not as critical as for domain one.

[PoA|https://docs.google.com/document/d/1NYzrfhLmnvf9_sE2RMnyFI_WrEqHMMRW_vn1aIEl1dY/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy73z:",,,,,,H4,,,,,,,,,,,,,,,,,,,,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/17 11:47 PM;krw910;SOV-991;;;","29/Jun/17 11:47 PM;krw910;From [~ashcherbakov]
We need to make sure that we don't call getAllTxn() for Domain ledger.
It's also not good to call it for pool and config ledgers, but not as critical as for getAllTxn().;;;","29/Jun/17 11:47 PM;krw910;Possibly the same as INDY-265;;;","05/Jul/17 9:22 PM;lovesh;The only call to Domain ledger's `getAllTxn` is made when State database has been deleted which is correct. I don't think we need this ticket anymoree ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"need ""big red button"" to put network in read-only mode",INDY-360,18825,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,30/Jun/17 2:02 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"As a failsafe, we need a way to quickly put the network in read-only node. Perhaps we submit a transaction similar to pool upgrade, that's a ""pool pause"" transaction?

The use case for this is to quickly limit damage in the face of some kind of ongoing attack.",,,540,540,,0%,540,540,,,,,,,,,,,,,,,,,,,INDY-452,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8dr:",,,,,,H5,M1 Prelude,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,dsurnin,krw910,peacekeeper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/17 3:51 AM;peacekeeper;I think this is can be very useful in a number of attack types.

For certain attacks this may not help, e.g. imagine someone somehow managed to manipulate ledger contents, and ""stopping"" it is not enough, it would actually have to be reverted to an earlier state in order to stop the damage.;;;","30/Jun/17 4:34 AM;danielhardman;Comment from Sam Smith: 

 
The first priority is to make it dead simple for any admin to switch  their node into/outof  read only mode. So that at most its seconds from getting a notice to flipping the ""circuit breaker"".
 
This can then be augmented in the future with automated reasoning that will trip the circuit breaker without human intervention. The risk of doing so is minimized if its truly a do no harm mode (or at least minimizes the harm).
 
The next priority is to minimize the disruption. Since read only mode means that nodes will not accept write transactions there might be deleterious side effects based on assumptions clients and other nodes are making about the apparent refusal or inability to accept/process/respond to write transactions. 
 
We can be smarter about this by having an explicit recognized announced response for read only mode of operation. So for example when a client makes a request for a write transaction instead of just dropping the request (which could cause a burst of retries and other things a client might do  as a result of transactions being dropped) the Node responds with  ""I am in readonly mode  try again in 60 seconds"". This allows clients and other nodes to more gracefully adapt to the change.  That is read only mode is explicitly announced by the Node to anyone that attempts to write to it and can be queried. 
 
Another deleterious side effect could be metrics for selecting leader nodes. A node that goes into read only mode would look like its a bad node from a performance or reputation point of view so any algorithms that are monitoring performance to determine future leader elections or fitness in the pool will be biased or inaccurate if a node goes into read only mode unless it is specifically included as an exception case for metric calculation.
 
The rule should be that If a client or node sees >= f+1 nodes in read only mode then there should be no lasting deleterious side effects with respect to how that client or node treats those nodes that are in read only mode such as metrics or reputation. And clients should gracefully throttle retries so as not to cause a packet storm.
 ;;;","15/Jul/17 9:11 PM;dsurnin;[~danielhardman]

Should it be config transaction and should it be written to ledger?

Do we want ""read only""-ness in protocol level (node will have new state) or do we want actual ledger files be written protected (for example _chmod a-w ""_ledger_files_""_)?

Do we need a schedule for a read only, i.e. ""do not write anything from 13:00 to 17:00 or 3 hours from now, in other time it is ok to write"" ?

What about read only state near update time, i.e. scenario: node were scheduled to update in 10 sec, set read only, node updated. What node state do we expect?

The same question with restart, what node state do we expect to have after read only node restarted?;;;","17/Jul/17 6:10 PM;dsurnin;email from [~danielhardman]

We need to invent a mechanism that's as simple as possible, that's reversible, and that doesn't undermine the principle of diverse trust. i think it might be modeled on the POOL_UPGRADE, maybe, except that it wouldn't need a schedule. Maybe we just say POOL_CONFIG writes=False, and then later, POOL_CONFIG writes=True, or something like that.
 
The purpose of this mechanism is to have a way to stop ongoing damage from a spammer.;;;","17/Jul/17 6:12 PM;dsurnin;I created small gdoc to proceed with discussion

[https://docs.google.com/document/d/1wQpJXPhLOMxOp7XgV_3DGdzR_nInGvERhcH9O17M3U4]

 ;;;","21/Jul/17 10:39 PM;dsurnin;for the moment the changes are in indy-node

[https://github.com/hyperledger/indy-node/pull/250]

 ;;;","22/Jul/17 1:06 AM;ashcherbakov;[~dsurnin] It was decided that we don't need PrePrepare filter for now, just discrd client Requests if in read-only mode.
Please create a separate ticket for handling PrePrepare.;;;","22/Jul/17 7:50 PM;dsurnin;the last fixes are ready to be merged

indy-node 1699644c9da2fb8cf737c3aea67aa5ed19ee7eb7

tests

sovrin-node/sovrin_client/test/cli/test_pool_config.py

sovrin-node/sovrin_node/test/pool_config/*

 

new command format

send POOL_CONFIG writes=True force=False

writes and force are bool parameters; writes is required and force is not. default for force is False

command is allowed for Trustee only

 

Please note - the changes requires testing clients commands in both writable and readonly modes

also different startup scenarios should be tested - restart in readonly mode, with/without catchup, with/without upgrade etc.

also validation of command's messages is required;;;","24/Jul/17 12:26 PM;dsurnin;merged ;;;","24/Jul/17 1:56 PM;krw910;Notes from Dmitry on what to cover with the limited changes:

There were no any changes to read transaction except GET_TXN, so basically checking one or two command in both modes should sufficient.
all write txns should be working almost the same way, so I think send NYM should be enough to test
I think it is a minim to check in both modes
after restart and after upgrade use cases I'm aware the most since I checked it not too much
and catch up scenarios
there wasn't any significant changes in restart, upgrade, catch up, just to make sure it still the same;;;","27/Jul/17 1:30 AM;krw910;This works just fine. A new ticket has been logged to remove the rights from a TGB role so only a Trustee can perform this operation.

 

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
sovrin_sign and sovrin_verify_signature should support arbitrary byte array,INDY-361,18841,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,peacekeeper,peacekeeper,30/Jun/17 6:36 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,libsovrin,,0,,,,,,"Right now, {{sovrin_sign}} and {{sovrin_verify_signature}} can create/verify signatures for the JSON messages that are sent to the ledger. In these methods, a JSON message is serialized to a byte array using a custom algorithm that is not used outside of Indy/Sovrin ledger communication. Also, the signature is automatically inserted into the JSON message.

I think it would be very useful if those methods could be used more generically, to create/verify signatures on any arbitrary byte array supplied by the library user.

[ Creating this JIRA issue and closing the Github issue: [https://github.com/hyperledger/indy-sdk/issues/32] ]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy6hb:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,peacekeeper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/17 6:50 AM;danielhardman;I have moved this again–this time to https://jira.hyperledger.org/browse/IS-158;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Input validation] - Pool Ledger refers to different pool transaction file when original transaction file is a symlink to /dev/random,INDY-362,18847,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,jkumar,jkumar,30/Jun/17 1:48 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,6Months,KellyRetest,Security,,,"Steps to reproduce:
1. vagrant@validator01:/home/sovrin/.sovrin/data/nodes/Node1/pool_transactions_sandbox$ sudo cp 1 11
2. vagrant@validator01:/home/sovrin/.sovrin/data/nodes/Node1/pool_transactions_sandbox$ sudo chown sovrin:sovrin 11
3. vagrant@validator01:/home/sovrin/.sovrin/data/nodes/Node1/pool_transactions_sandbox$ sudo rm 1
4. vagrant@validator01:/home/sovrin/.sovrin/data/nodes/Node1/pool_transactions_sandbox$ sudo ln -s /dev/random 1
5. vagrant@validator01:/home/sovrin/.sovrin/data/nodes/Node1/pool_transactions_sandbox$ ll
total 12
drwxr-xr-x  2 sovrin sovrin 4096 Jun 30 09:44 ./
drwxr-xr-x 13 sovrin sovrin 4096 Jun 10 16:17 ../
lrwxrwxrwx  1 root   root     11 Jun 30 09:44 1 -> /dev/random
-rw-r--r--  1 sovrin sovrin 1366 Jun 30 09:42 11
6. vagrant@validator01:/home/sovrin/.sovrin$ sudo systemctl stop sovrin-node
7. vagrant@validator01:/home/sovrin/.sovrin$ sudo systemctl start sovrin-node","vagrant@validator01:/home/sovrin/.sovrin$ dpkg -s sovrin-node
Package: sovrin-node
Status: install ok installed
Priority: extra
Section: default
Installed-Size: 968
Maintainer: Sovrin Foundation <dev@sovrin.org>
Architecture: amd64
Version: 0.3.19
Depends: python3-sovrin-common (= 0.2.11), python3-dateutil
Description: Sovrin node
License: Apache 2.0
Vendor: none
Homepage: https://github.com/sovrin-foundation/sovrin-node.git",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/17 1:44 PM;jkumar;Node1.log;https://jira.hyperledger.org/secure/attachment/11513/Node1.log","30/Jun/17 1:59 PM;jkumar;Node1_Transaction.log;https://jira.hyperledger.org/secure/attachment/11516/Node1_Transaction.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy0sv:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,jkumar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/17 1:59 PM;jkumar;If sym link is removed, it still refers to file ""/home/sovrin/.sovrin/data/nodes/Node1/pool_transactions_sandbox/11"" and CLI can perform transactions. Log ""Node1_Transaction.log"" attached.;;;","07/Nov/18 10:13 PM;Derashe;We don't use vagrant anymore;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ubuntu AppArmor enforce mode doesn't let sovrin node service up.,INDY-363,18855,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,,jkumar,jkumar,30/Jun/17 9:13 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,6Months,KellyRetest,,,,"*Setup:*
4 validator nodes on vagrant with virtual box

*Configuration steps of AppArmor on Node1*
1. sudo apt-get install apparmor-utils
2. cd /etc/apparmor.d/
3. sudo aa-autodep /usr/local/bin/start_sovrin_node (Writing updated profile for /usr/local/bin/start_sovrin_node.)
4. sudo aa-complain /usr/local/bin/start_sovrin_node (Setting /usr/local/bin/start_sovrin_node to complain mode.)
5. sudo service sovrin-node stop ; sudo service sovrin-node start
6. Perform transactions through CLI (AppArmor silently listens to this)
7. sudo aa-logprof (Reading log entries from /var/log/syslog. Updating AppArmor profiles in /etc/apparmor.d.)
8. Allow different paths and modes and save changes
9. Restart sovrin node service

*Actual outcome:*
sovrin-node service failed to start on Node1.

*Expected outcome:*
If AppArmor profile file all constraints mentioned, sovrin node service shall be started.
","*Environment details:*

dpkg -s sovrin-node
Package: sovrin-node
Status: install ok installed
Priority: extra
Section: default
Installed-Size: 968
Maintainer: Sovrin Foundation <dev@sovrin.org>
Architecture: amd64
Version: 0.3.19
Depends: python3-sovrin-common (= 0.2.11), python3-dateutil
Description: Sovrin node
License: Apache 2.0
Vendor: none
Homepage: https://github.com/sovrin-foundation/sovrin-node.git",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/17 9:11 PM;jkumar;usr.local.bin.start_sovrin_node;https://jira.hyperledger.org/secure/attachment/11527/usr.local.bin.start_sovrin_node",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-987,,,,,,,,,,"1|hzy0t3:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,jkumar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 10:14 PM;Derashe;We don't use AppArmor for current moment of time.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
plenum/testConnectWithoutKeySharingFails is disabled,INDY-364,18857,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,andrey.goncharov,andrey.goncharov,30/Jun/17 10:15 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy23z:",,,,,,H3,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,andrey.goncharov,danielhardman,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jul/17 12:17 AM;danielhardman;Apparently this is failing in the master branch.;;;","03/Jul/17 5:03 AM;lovesh;https://github.com/hyperledger/indy-plenum/pull/247;;;","04/Jul/17 9:13 PM;aleksey-roldugin;h6. BUILD
python3-plenum 0.4.13

h6. VERIFICATION
plenum/testConnectWithoutKeySharingFails is enabled.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
plenum/test_view_change_complex is disabled,INDY-365,18858,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,andrey.goncharov,andrey.goncharov,30/Jun/17 10:17 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy247:",,,,,,H3,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,andrey.goncharov,danielhardman,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jul/17 12:17 AM;danielhardman;Apparently this is failing in the master branch.;;;","03/Jul/17 5:03 AM;lovesh;https://github.com/hyperledger/indy-plenum/pull/247;;;","04/Jul/17 9:12 PM;aleksey-roldugin;h6. BUILD
python3-plenum 0.4.13

h6. VERIFICATION
plenum/test_view_change_complex is enabled.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The socket used by the node to talk to other nodes becomes blocked,INDY-366,18864,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,01/Jul/17 1:08 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"We are seeing cases where nodes are not able to communicate with each other. It appears that the socket has become blocked.
When this occurs restarting all the nodes in the pool gets things working again, but that is not really an option with a global setup.

*Consider:* Currently reaching the high water mark on zeromq socket drops any new messages (this happens for Router and Dealer socket types which we use), so the socket maintains a FIFO queue till reaching high water mark. Explore how to drop the messages of the FIFO queue from the beginning once high water mark is reached. The objective is to preserve and send recent messages and ignore old messages if needed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1vb:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,danielhardman,krw910,lovesh,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jul/17 10:46 PM;mzk-vct;*Problem reason:*
ZMQ has internal queues for messages, which size is limited by 1000 by default. 
On high load this queues can can become overflown and new messages can be dropped.

*Changes:*
Queue size can be configured now using _ZMQ_INTERNAL_QUEUE_SIZE_ parameter. Default value is 0 what means 'unlimited'.

*Committed into:*
https://github.com/hyperledger/indy-stp/pull/45

*Risk factors:*
Nothing is expected.

*Risk:*
Low

*Covered with tests:*
stp_zmq/test/test_zstack.py/test_high_load

*Recommendations for QA (optional):*
1. Test it with different number of nodes
2. Try load testing with big  amount of requests
3. Try to switch off 3pc batching (and simple batching) to increase number of messages 
;;;","08/Jul/17 12:43 AM;mzk-vct;Builds:

- node 0.4.14
- client 0.4.24;;;","11/Jul/17 2:16 AM;lovesh;The default value of 0 would fill up all the memory of the node and crash it if one of the other node is not receiving. There is a reason why high water mark exists, don't undermine that. The ticket mentions that one possible option is dropping older messages, was it considered. I oppose the setting of default to 0, we need to be able to drop old messages.;;;","12/Jul/17 8:18 PM;mzk-vct;[~lovesh]

Yes. There is no default support of such functionality in zeromq. There is ZMQ_CONFLATE option, which can be used to simulate this, but documentation says that it does not support multipart messages.

Default values is set to 0 just in order to check how it works without such limitation. This value can be configured in any moment we see that it does not work. 
That's why I added such recommendations for QA.

I suggested to move logic for dropping messages from zmq to plenum internals. 
Also as far as I know [~andkononykhin] researching possibility of reimplementing message handling in reactive way. If we can do it then it will be easier to process queue and apply our logic instead of the one zmq provides.

;;;","13/Jul/17 5:26 AM;krw910;Blocked by INDY-406;;;","19/Jul/17 4:42 AM;krw910;The product is good enough to go Stable. I cannot reproduce this issue and we will need to wait until the alpha pool reports back.;;;","19/Jul/17 5:12 AM;danielhardman;I agree with [~lovesh]'s comment that ignoring the high water mark (allowing the FIFO queue to grow until memory is exhausted) is unwise. However, I also agree with [~krw910] that this is good enough for the short term. Therefore, I logged a new ticket, INDY-437, to capture the additional work of improving this fix.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Windows build instructions need review,INDY-367,18879,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,,srottem,srottem,02/Jul/17 1:21 AM,11/Oct/19 7:16 PM,28/Oct/23 2:46 AM,11/Oct/19 7:16 PM,,,libsovrin,,0,5Months,devops,,,,"The instructions for building under Windows is insufficient for a beginner to get started quickly, especially with regard to building source dependencies.  For example these are a few of the issues I ran into:
 * The link for downloading pre-built dependencies is broken
 * That cmake must be installed before attempting to build milagro-crypto-c. I attempted to use the MinGW cmake and ran unto trouble not realizing that there was another one for use in Windows.
 * Figuring out how to disable post-build events in milagro-crypto-c and that it should be done in all projects in the solution
 * That the libzmq-pw projects SDK target is 8.1 and this may be an issue on other versions of windows.   I had to change it for Windows 10 - how to change it might be useful.
 * Understanding whether the draft API and libsodium settings in libzmq-pw need to be changed in all projects of the solution or not and where to change these settings.
 * Finding where to change the output file name in libzmq-pw should be performed - simply changing it in General > Target Name of the libzmq project causes compiler warning MSB8012 and all other projects in the solution fail to build.
 * The paths specified in ~\builds\msvc\vs2017\libzmq.import.props specify a directory that may be invalid as it incorrectly assumes that the source root will be named libzmq.  Maybe this needs to be in a different ticket since its a different repo?
 * That rust needs to be installed (and what cargo is) and maybe a link to how to do so
 * What cargo command needs to be run to get the appropriate build (the specific command)
 * Finding the correct build artifact was problematic as I didn't know what output to expect or where specifically it would be written.  This appears to be ~/target/de
 * I didn't get an openssl related build failure complaining about gdi32.lib - perhaps the workaround instructions should say ""if"" rather than ""when"" the build fails?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-66,,,,,,,,,,"1|hzy10v:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,srottem,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 7:16 PM;ashcherbakov;This is done in SDK;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Incorrect message for POOL_UPGRADE with not unique name.,INDY-368,18886,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,spivachuk,ozheregelya,ozheregelya,03/Jul/17 4:12 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,should,,,," 

*Overview:*
Incorrect message for POOL_UPGRADE with not unique name.

*Case 1:*
*Steps to Reproduce:*
1. Open the CLI.
2. send POOL_UPGRADE command with valid parameters
{code:java}
send POOL_UPGRADE name=upgrade-oz1 version=0.3.163 sha256=aad1242 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-07-03T10:50:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-07-03T10:55:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-07-03T11:00:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-07-03T11:05:00.000000+00:00'} timeout=10{code}
3. send the same POOL_UPGRADE again.

*Actual Results:*
Error message: ""Pool upgrade failed: client request invalid: UnauthorizedClientRequest('TRUSTEE cannot do POOL_UPGRADE',)""
'TRUSTEE cannot do POOL_UPGRADE' is incorrect message, because TRUSTEE can do that.

*Expected Results:*
Error message should contain information about not unique name.","Build Info:
sovrin-client version: 0.3.150
sovrin-node version: 0.3.163

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx0o7:",,,,,,14,INDY 17.21,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 7:15 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] Incorrect message for send NODE (update node) with not existing dest.,INDY-369,18887,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,ozheregelya,ozheregelya,03/Jul/17 4:23 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,5Months,,,,,"*Overview:*
Incorrect message for send NODE (update node) with not existing dest.

*Case 1:*
*Steps to Reproduce:*
1. Open the CLI.
2. send NODE with 'alias' and 'services' parameters (demote/promote node) and not existing dest.
{code:java}
send NODE dest=8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWP1111 data={'alias': 'Node5', 'services': []}{code}
*Actual Results:*
Error message is unclear: ""Node request failed with error: client request invalid: UnauthorizedClientRequest(""Missing some of \{'client_ip', 'client_port', 'node_port', 'alias', 'node_ip'}"",)""

*Expected Results:*
The message should be more user friendly, it should contain information that need to use existing dest to update node or should specify 'client_ip', 'client_port', 'node_port', 'alias', 'node_ip' to add new node to the pool.","Build Info:
sovrin-client version: 0.3.150
sovrin-node version: 0.3.163

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzy0zz:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 12:03 AM;sergey-shilov;This CLI is deprecated, no longer supported and going to be removed, this ticket is not relevant any more and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] Incorrect message for send NODE (update node) with not existing dest,INDY-370,18888,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,ozheregelya,ozheregelya,03/Jul/17 4:57 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,5Months,,,,,"*Overview:*
Incorrect message for send NODE (update node) with not existing dest.

*Case 1:*
*Steps to Reproduce:*
1. Open the CLI.
2. Try to demote node as Steward.
sovrin@test> new key with seed 000000000000000000000000Steward1
sovrin@test> send NODE dest=8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb data=\{'alias': 'Node2', 'services': []}

*Actual Results:*
Error message contains incorrect information: ""Node request failed with error: client request invalid: UnauthorizedClientRequest('FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4 is not a steward of node 8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb',)"" but stewards can't demote/promote nodes.

*Expected Results:*
Message should contain information that only TRUSTEE can demote/promote nodes.

 

*Case 2:*
*Steps to Reproduce:*
1. Open the CLI.
2. Try to demote node as Steward.
sovrin@test> new key with seed 000000000000000000000000Steward1
sovrin@test> send NODE dest=8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb data=\{'alias': 'Node2', 'services': ['VALIDATOR']}

*Actual Results:*
Error message contains incorrect information: ""Node request failed with error: client request invalid: UnauthorizedClientRequest('FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4 is not a steward of node 8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb',)"" but stewards can't demote/promote nodes.

*Expected Results:*
Message should contain information that only TRUSTEE can demote/promote nodes.","Build Info:
sovrin-client version: 0.3.150
sovrin-node version: 0.3.163

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzy107:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 4:41 PM;Derashe;According to INDY-410 stewards must have ability to promote/demote their node;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] Incorrect error message when the user tries to blacklist himself,INDY-371,18890,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,Derashe,ozheregelya,ozheregelya,03/Jul/17 5:03 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,,,,,"Overview:
Incorrect error message when the user tries to blacklist himself.

Case 1:
Steps to Reproduce:
1. Open the CLI.
2. Try to blacklist yourself as Steward.
sovrin@test> new key with seed 000000000000000000000000Steward1
sovrin@test> send NYM dest=FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4 role=

Actual Results:
Error message contains incorrect information: ""Error: client request invalid: InvalidClientRequest('FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4 is neither Trustee nor owner of FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4',)"" but owner can't blacklist himself.

Expected Results:
Message should contain information that only TRUSTEE can blacklist the user.","Build Info:
sovrin-client version: 0.3.150
sovrin-node version: 0.3.163

OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-46,,,,,,,,,,"1|hzy10f:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 5:13 PM;Derashe;In actual version of code, if steward will try to blacklist himself, he will get an error like: ""STEWARD cannot update role"";;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Change help message,INDY-372,18896,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,spivachuk,VladimirWork,VladimirWork,03/Jul/17 8:55 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,should,,,,"Build Info:
sovrin-client 0.4.17
sovrin-node 0.4.7

Overview:
Change help message for send POOL_UPGRADE command.

Steps to Reproduce:
1. Perform send POOL_UPGRADE command with any incorrect parameter or without parameters.

Actual Results:
 example(s):
        send POOL_UPGRADE name=upgrade-01 version=0.0.1 *+sha256=aad1242+* action=start schedule={'AtDfpKFe1RPgcr5nnYBw1Wxkgyn8Zjyh5MzFoEUTeoV3': '2017-01-25T12:49:05.258870+00:00', '4yC546FFzorLPgTNTc6V43DnpFrR8uHvtunBxb2Suaa2': '2017-01-25T12:33:53.258870+00:00', 'JpYerf4CssDrH76z7jyQPJLnZ1vwYgvKbvcp16AB5RQ': '2017-01-25T12:44:01.258870+00:00', 'DG5M4zFm33Shrhjj6JB7nmx9BoNJUq219UXDfvwBDPe2': '2017-01-25T12:38:57.258870+00:00'} timeout=10 force=False

Expected Results:
There should be something like that value for sha256 due to INDY-119 changes: sha256=e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.
Current example is not valid.",,,,,,,,,,,,,,,,,,,,,,,INDY-119,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx0of:",,,,,,14,INDY 17.21,,,,,,,,,,,,,,,,,,,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/17 8:57 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","05/Dec/17 7:15 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement new Ledger serialization,INDY-373,18898,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,ashcherbakov,ashcherbakov,03/Jul/17 9:00 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,NewFeature,sprint11-goal-release,,,,"Depending on INDY-164 result, implement a new way to serialize Ledger.
Think about backward-compatiblity with the old (existing) one: a migration script?

Implementation requirement: When we get transaction from ledger it contains not only field that it supposed to, but all set of possible fields from other transaction types (set to None).",,,28800,28800,,0%,28800,28800,,,INDY-164,,,IS-220,,,,,,,,,,,,,,,,,,,,,"22/Aug/17 10:10 PM;VladimirWork;!reinstall113.txt;https://jira.hyperledger.org/secure/attachment/11919/%21reinstall113.txt","22/Aug/17 10:09 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11918/Screenshot.PNG","15/Aug/17 11:44 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11887/Screenshot.PNG","15/Aug/17 11:45 PM;VladimirWork;_node1.log;https://jira.hyperledger.org/secure/attachment/11888/_node1.log","15/Aug/17 11:45 PM;VladimirWork;_node2.log;https://jira.hyperledger.org/secure/attachment/11889/_node2.log","15/Aug/17 11:45 PM;VladimirWork;_node3.log;https://jira.hyperledger.org/secure/attachment/11890/_node3.log","15/Aug/17 11:45 PM;VladimirWork;_node4.log;https://jira.hyperledger.org/secure/attachment/11891/_node4.log","12/Aug/17 1:10 AM;VladimirWork;dotsovrin (1).tar.gz;https://jira.hyperledger.org/secure/attachment/11883/dotsovrin+%281%29.tar.gz","12/Aug/17 1:00 AM;VladimirWork;node1.txt;https://jira.hyperledger.org/secure/attachment/11879/node1.txt","12/Aug/17 1:00 AM;VladimirWork;node2.txt;https://jira.hyperledger.org/secure/attachment/11880/node2.txt","12/Aug/17 1:00 AM;VladimirWork;node3.txt;https://jira.hyperledger.org/secure/attachment/11881/node3.txt","12/Aug/17 1:00 AM;VladimirWork;node4.txt;https://jira.hyperledger.org/secure/attachment/11882/node4.txt","14/Aug/17 6:16 PM;VladimirWork;reinstall_journalctl.txt;https://jira.hyperledger.org/secure/attachment/11884/reinstall_journalctl.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzye7b:",,,,,,10,11,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jul/17 5:17 AM;danielhardman;Now that this has been deferred beyond the Go-Live milestone, we need to implement Rocks DB at the same time, so that we don't have to rewrite old ledger entries more than once.;;;","25/Jul/17 5:06 PM;ashcherbakov;[~danielhardman] [~stevetolman] The ticket is still in M1, is it correct? 
Options:
* Finish it with leveldb in M1
* Get the ticket out of M1 until we support Rocksdb
* Include Rocksdb support ticket into M1 (BTW Rocksdb task was almost done by Dmitry some time ago).;;;","11/Aug/17 11:00 PM;ashcherbakov;Changes:
- use msgpack as a serializer for ledger (all ledgers: domain, pool, config)
- use leveldb as a storage for all ledgers
- use leveldb as a storage for all ledgers's tree hash stores
- use '_genesis' suffix for genesis txn files
- use 'domain_' prefix for domain ledger files
- migration script (for upgrade)
- script for reading the ledger
- use real json instead of string for CLAIM_DEF and SCHEMA
- code cleanup:
- use json serialization for genesis txns
-- re-factor all serializations to have one place for settings
-- re-factor ledger and key-value storage hierarchy a bit (still not perfect)

PRs:
- https://github.com/hyperledger/indy-plenum/pull/331
- https://github.com/hyperledger/indy-node/pull/300
- https://github.com/sovrin-foundation/sovrin/pull/16

Build:
- indy-node 1.0.99
- sovrin 1.0.23

Recommendations for QA:
1. Check that a fresh pool with a new code is working (all genesis txn files are applied)
2. Check that Upgrade works and migration works (all previous data is present and accessible and the pool is still working after update)
3. Check that CLAIM_DEF/SCHEMA works (old one are still present and new one can be added)
4. Check that a new command `read_ledger` works. It can be used to read the ledger txns.
Use `read_ledger -h` for help. 
Examples:
-  `read_ledger --type=pool`: first 100 pool txns as jsons
-  `read_ledger --type=domain`: first 100 domain txns as jsons
-  `read_ledger --type=domain frm=10 to=20`: domain txns from 10 till 20 
-  `read_ledger --type=domain --seq_no=5`: 5th domain txn 
-  `read_ledger --type=pool --count`
-  `read_ledger --type=domain --count`
-  `read_ledger --type=config --count`
;;;","12/Aug/17 1:10 AM;VladimirWork; [^node1.txt]  [^node2.txt]  [^node3.txt]  [^node4.txt]  [^dotsovrin (1).tar.gz] ;;;","12/Aug/17 3:00 AM;ashcherbakov;Some fixes added:
indy-node 1.0.102;;;","14/Aug/17 6:16 PM;VladimirWork;Build Info:
indy-node 1.0.102

Steps to Reproduce - Case 1:
1. Try ""read_ledger"" from root user.
2. Try ""read_ledger"" from sovrin user.

Actual Results:
Step 1: No initiated nodes/client found: /root/.sovrin/data/nodes.
Step 2:
Traceback (most recent call last):
  File ""/usr/local/bin/read_ledger"", line 144, in <module>
    ledger = get_ledger(args)
  File ""/usr/local/bin/read_ledger"", line 101, in get_ledger
    fileNamePrefix=hash_store_name)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/persistence/leveldb_hash_store.py"", line 15, in __init__
    self.open()
  File ""/usr/local/lib/python3.5/dist-packages/plenum/persistence/leveldb_hash_store.py"", line 78, in open
    self.nodesDb = KeyValueStorageLeveldb(self.dataDir, self.nodes_db_name)
  File ""/usr/local/lib/python3.5/dist-packages/storage/kv_store_leveldb.py"", line 21, in __init__
    self.open()
  File ""/usr/local/lib/python3.5/dist-packages/storage/kv_store_leveldb.py"", line 73, in open
    self._db = leveldb.LevelDB(self.db_path)
leveldb.LevelDBError: IO error: lock /home/sovrin/.sovrin/data/nodes/Node1/pool_merkleNodes/LOCK: Resource temporarily unavailable.

Expected Results:
Command should work from any user well.

Steps to Reproduce - Case 2:
1. Send pool upgrade command to reinstall the current version (e.g. from 1.0.102 to 1.0.102).

Actual Results:
Upgrade is successful, but applied migrations seems to be wrong (Applying migration 1_0_96_to_1_0_97), see upgrade_journalctl log for more info.

Expected Results:
Need to discuss.;;;","15/Aug/17 11:46 PM;VladimirWork;Build Info:
indy-node 1.0.84

Steps to Reproduce:
1. Send pool upgrade command from 84 to 105 version.

Actual Results:
There are 2 files in .sovrin:
pool_transactions_sandbox with correct info about nodes.
pool_transactions_sandbox_genesis with incorrect info about nodes.

After the upgrade it looks like all nodes take incorrect info from pool_transactions_sandbox_genesis and this breaks the pool. [^_node1.log]  [^_node2.log]  [^_node3.log]  [^_node4.log] !Screenshot.PNG|thumbnail! 

FYI [~ashcherbakov];;;","16/Aug/17 9:07 PM;ashcherbakov;The latest build with fixes for migration: 1.0.108;;;","16/Aug/17 9:11 PM;ashcherbakov;There is a possible problem with the migration:
- since we changed the serialization for merkle tree, the roots are changed, and hence the newly updated nodes can not participate in consensus together with old nodes.
- re-start of all nodes after migration helps
- another workaround is to use force=True with the same time for update.;;;","17/Aug/17 1:02 AM;ashcherbakov;Another feature is added to read_ledger: show the number of txns in the ledger:
`read_ledger --type=pool --count`
`read_ledger --type=domain --count`
`read_ledger --type=config --count`;;;","17/Aug/17 7:24 PM;VladimirWork;Build Info:
sovrin (client) 1.0.67
indy-node 1.0.110

Steps to Reproduce:
1. Send SCHEMA command with valid parameters.
2. Send CLAIM_DEF command with valid parameters.

Actual Results:
sovrin@test> send SCHEMA name=Degree version=1.0 keys=undergrad,last_name,first_name,birth_date,postgrad,expiry_date
sovrin74c17e is already started, so start has no effect
_ensureReqCompleted failed; not trying any more because 20 seconds have passed; args were (('V4SGRU86Z58d6TV7PBUe6f', 1502965385233086), 7qmFGzvDFx5fW65qbQZS2G9SSrX8BXQf4avkdjSWmSpv, <function _submitData at 0x7f0245be1158>)
Task exception was never retrieved
future: <Task finished coro=<SovrinCli._sendSchemaActionAsync() done, defined at /usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py:863> exception=OperationError('error occurred during operation: client request invalid: InvalidClientRequest(""validation error [SchemaField]: invalid type <class \'str\'>, dict expected"",)',)>

sovrin@test> send CLAIM_DEF ref=16 signature_type=CL
Task exception was never retrieved
future: <Task finished coro=<SovrinCli._sendClaimDefActionAsync() done, defined at /usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py:888> exception=KeyError('data',)>

Expected Results:
Commands should work the same as in 1.0.110 version client.;;;","17/Aug/17 7:26 PM;VladimirWork;Build Info:
indy-node 1.0.110

Steps to Reproduce:
1. Perform some commands to add transactions to ledger (send NYM, send SCHEMA, etc).
2. Perform upgrade from 1.0.67 (old serialization) to 1.0.110 (new serialization) version.
3. Check the domain ledger consistency.

Actual Results:
There are default entries (15 units) or there is nothing at all in the ledger in all nodes (so in both cases we lose data from the ledger).

Expected Results:
Ledger should be the same as it was before the pool upgrade in all nodes.;;;","17/Aug/17 9:04 PM;ozheregelya;*Build Info:*
indy-node (used as client) 1.0.67
indy-node 1.0.110

Need to add migration script for client.

*Steps to Reproduce:*
1. Set up pool of 4 nodes, 1 clear node for adding and 1 client (using indy-node 1.0.67)
2. Add 1 clear node to pool.
3. Send POOL_UPGRADE command (for all nodes including newly added one).
4. Restart client, try to connect to test.

*Actual Results:*
Following message appear. Client does not work.
{code:java}
8BkoWKWvUvxs6g4rpugxzCHWwvHN4C3G2y265zGZ7N1u could not verify catchup reply CATCHUP_REP{'txns': {'5': {'type': '0', 'dest': '4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc', 'signature': '2MARwfygpjAEAfQhA9uG8dwPJcUA7R4WisqNk1bnTQU5eYKtwBCHeRcdBPFVJFQHphcpbdQiqKrqEYQsw6m1FvH2', 'txnTime': 1502961800, 'data': {'node_port': 9701, 'alias': 'Node5', 'services': ['VALIDATOR'], 'client_ip': '10.0.0.6', 'client_port': 9702, 'node_ip': '10.0.0.6'}, 'reqId': 1502961800712640, 'identifier': 'XhYtvJqezMUKfF6KVNaGmT'}}, 'consProof': [], 'ledgerId': 0} since Inconsistency: different root hashes for the same tree size{code}
*Expected Results:*
Need to add migration for client to have ability to work with the pool.

 ;;;","19/Aug/17 1:43 AM;ashcherbakov;There was a problem with migration tool that addresses the first issue.
https://github.com/hyperledger/indy-node/pull/316

As for the second issue, for now let's assume that we test the latest client only (>1.0.110).
;;;","21/Aug/17 6:36 PM;ashcherbakov;New build (master): 1.0.113 
For now we assume that the latest client (1.0.113) can work with the latest pool only.;;;","22/Aug/17 10:10 PM;VladimirWork;Build Info:
indy-node 1.0.113

Steps to Reproduce:
1. Perform ""send POOL_UPGRADE name=upgrade_reinstall version=1.0.113 sha256=ed0a366b4ef36d40c055672a8b83679e99246fec71a706b4ae4cb7958feace3f action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-18T15:20:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-08-18T15:25:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-08-18T15:30:00.258870+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-08-18T15:35:00.258870+00:00'} timeout=10 force=True reinstall=True""

Actual Results:
Upgrade is not performed. Nodes are disconnected and are not connected themselves. !Screenshot.PNG|thumbnail! 
See attached journalctl for more info. [^!reinstall113.txt] ;;;","23/Aug/17 5:33 PM;VladimirWork;The last case is not connected to new serialization so INDY-755 is reported.;;;","23/Aug/17 9:40 PM;VladimirWork;Build Info:
indy-node 1.0.113

Steps to Validate:
1. Check that a fresh pool with a new code is working (all genesis txn files are applied).
2. Check that pool upgrade works and migration works (all previous data is present and accessible and the pool is still working after update).
3. Check that CLAIM_DEF/SCHEMA works (old one are still present and new one can be added).
4. Check that a new command `read_ledger` works.

Actual Results:
New serialization pool works normally.

Additional Info:
All node-side issues found due to confirmation/regression testing of this ticket are fixed (client-side issues will be fixed in INDY-733).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement support of client backward compatibility,INDY-374,18905,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,mzk-vct,mzk-vct,03/Jul/17 9:57 PM,13/Nov/19 12:41 AM,28/Oct/23 2:46 AM,13/Nov/19 12:41 AM,,,,,0,5Months,,,,,"Implement backward compatibility mechanisms in 
 - client to node
 - client to client 

communications designed in https://jira.hyperledger.org/browse/INDY-242",,,,,,,,,,,INDY-242,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzy127:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Nov/19 12:41 AM;esplinr;We now include a protocol version in requests.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"In Identity Ledger file if a record (some byte in a line) is corrupted, node is unable to rectify that record even after sovrin node service restart.",INDY-375,18912,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,gudkov,jkumar,jkumar,03/Jul/17 11:05 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Security,,,,,"*Setup:*
4 nodes on vagrant with virtual box.

*Steps:*
1. Corrupt ledger file ""1"" present in /home/sovrin/.sovrin/data/nodes/Node3/transactions_sandbox (This can be done with hex mode of vi editor - To switch into hex mode hit escape and type :%!xxd and to exit :%!xxd -r)
2. Stop sovrin node service
3. Start sovrin node service

*Actual outcome:*
Ledger file is not repaired. Further transactions from CLI can appear in another nodes ledger but not in the ledger which is corrupted.","vagrant@validator03:/home/sovrin/.sovrin/data/nodes/Node3/transactions_sandbox$ dpkg -s sovrin-node
Package: sovrin-node
Status: install ok installed
Priority: extra
Section: default
Installed-Size: 968
Maintainer: Sovrin Foundation <dev@sovrin.org>
Architecture: amd64
Version: 0.3.19
Depends: python3-sovrin-common (= 0.2.11), python3-dateutil
Description: Sovrin node
License: Apache 2.0
Vendor: none
Homepage: https://github.com/sovrin-foundation/sovrin-node.git",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/17 11:04 PM;jkumar;1_Corrupted_Ledger;https://jira.hyperledger.org/secure/attachment/11535/1_Corrupted_Ledger","03/Jul/17 11:04 PM;jkumar;1_Good Ledger;https://jira.hyperledger.org/secure/attachment/11536/1_Good+Ledger","03/Jul/17 11:04 PM;jkumar;Node3.log;https://jira.hyperledger.org/secure/attachment/11534/Node3.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx233:",,,,,,,,,,,,,,,,,,,,,,,,,,jkumar,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Aug/17 5:51 AM;krw910;No longer valid now that we serialized the ledger.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Identity Ledger file size changes after catch-up,INDY-376,18927,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,jkumar,jkumar,04/Jul/17 2:58 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*setup:*
4 nodes on vagrant with virtual box

*steps:*
1. Check file size of ledger file /home/sovrin/.sovrin/data/nodes/Node4/transactions_sandbox/1
2. Perform transaction through CLI which will add a record in ledger file
2. Delete that record (one complete line either by vi dd cmd or truncate cmd) of ledger file 
3. Check ledger file size
4. Setup ledger catch-up by stop/start sovrin-node
5. Check ledger file size again

*Actual outcome:*
Ledger file size changes after catch-up from 4275 to 4277 bytes. snapshot attached.","vagrant@validator04:/home/sovrin/.sovrin/data/nodes/Node4/transactions_sandbox$ dpkg -s sovrin-node
Package: sovrin-node
Status: install ok installed
Priority: extra
Section: default
Installed-Size: 968
Maintainer: Sovrin Foundation <dev@sovrin.org>
Architecture: amd64
Version: 0.3.19
Depends: python3-sovrin-common (= 0.2.11), python3-dateutil
Description: Sovrin node
License: Apache 2.0
Vendor: none
Homepage: https://github.com/sovrin-foundation/sovrin-node.git",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jul/17 2:57 PM;jkumar;Ledger file size changes after catch-up.png;https://jira.hyperledger.org/secure/attachment/11538/Ledger+file+size+changes+after+catch-up.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx22v:",,,,,,,,,,,,,,,,,,,,,,,,,,jkumar,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Aug/17 5:51 AM;krw910;Ledger changed to binary so this is no longer valid.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node didn't make catch up after promotion,INDY-377,18937,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,danielhardman,aleksey-roldugin,aleksey-roldugin,04/Jul/17 5:57 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Stability,,,,,"h6. BUILD

sovrin-node 0.4.9
 sovrin-client 0.4.19
h6. STEPS TO REPRODUCE
 # Add 2 nodes to existing pool from 4 machines.
 # Demote one node (Node5) with default Trustee (000000000000000000000000Trustee1).
 # Add NYM and check that transaction was not written to the ledger on demoted node.
 # Demote another node (Node6).
 # Make another trustee (000000000000000000000000Trustee9) and check that corresponding transaction was not written to the ledger on Node5 and Node6.
 # As another trustee promote Node5.
 # Check that it did make catch up.
 # Switch to default trustee.
 # Promote Node6.

h6. ACTUAL RESULT

Node6 did note make catch up. After _sudo systemctl restart sovrin-node_ it did make catch up. See logs of all nodes in attachment.
h6. ADDITIONAL INFORMATION

I tried to reproduce that issue demoting and promoting Node5 with default trustee and repeating steps for Node6 but it wasn't reproduced.",,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,INDY-313,,,,,,,,,,,,"04/Jul/17 5:56 PM;aleksey-roldugin;Node1.log;https://jira.hyperledger.org/secure/attachment/11547/Node1.log","04/Jul/17 5:57 PM;aleksey-roldugin;Node2.log;https://jira.hyperledger.org/secure/attachment/11546/Node2.log","04/Jul/17 5:57 PM;aleksey-roldugin;Node3.log;https://jira.hyperledger.org/secure/attachment/11545/Node3.log","04/Jul/17 5:57 PM;aleksey-roldugin;Node4.log;https://jira.hyperledger.org/secure/attachment/11544/Node4.log","04/Jul/17 5:57 PM;aleksey-roldugin;Node5.log;https://jira.hyperledger.org/secure/attachment/11543/Node5.log","04/Jul/17 5:57 PM;aleksey-roldugin;Node6.log;https://jira.hyperledger.org/secure/attachment/11542/Node6.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzye8n:",,,,,,10,11,,,,,,,,,,,,,,,,,,,aleksey-roldugin,andkononykhin,ashcherbakov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jul/17 5:59 PM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","04/Aug/17 5:08 PM;ashcherbakov;Please spend 1-2 hours to investigate the log. If nothing special in the logs - then assign to QA to re-check.;;;","12/Aug/17 3:05 AM;andkononykhin;I've checked the case with the exact sequence of steps from description and haven't found any issues: both promoted back nodes successfully catched up.;;;","17/Aug/17 9:40 PM;ozheregelya;The problem doesn't reproduce on following version:

indy-node 1.0.110
 indy-anoncreds 1.0.25
 indy-plenum 1.0.97
 sovrin 1.0.23
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4-6 nodes, 1 client;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[send CLAIM_DEF] Claim DEF was published when it should not have been,INDY-378,18943,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,VladimirWork,VladimirWork,04/Jul/17 9:16 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Stability,,,,,"Build Info:
sovrin-client 0.4.19
sovrin-node 0.4.9

Overview:
Exceptions are raised due to command execution.

Steps to Reproduce - Case 1:
1. Send CLAIM_DEF with nonexistent seqNo as REF parameter.

Actual Results:
Task exception was never retrieved
future: <Task finished coro=<SovrinCli._sendClaimDefActionAsync() done, defined at /usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py:737> exception=AttributeError(""'NoneType' object has no attribute 'issuerId'"",)>

Expected Results:
User-friendly error message about incorrect REF parameter.


Steps to Reproduce - Case 2:
1. Send CLAIM_DEF with existing seqNo as REF parameter.

Actual Results:
The following claim definition is published to the Sovrin distributed ledger
...
Task exception was never retrieved
future: <Task finished coro=<SovrinCli._sendClaimDefActionAsync() done, defined at /usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py:737> exception=AttributeError(""'tuple' object has no attribute 'seqId'"",)>

Expected Results:
There should be no error or exception messages because the claim definition is successfully published.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jul/17 9:16 PM;VladimirWork;1.PNG;https://jira.hyperledger.org/secure/attachment/11552/1.PNG","04/Jul/17 9:16 PM;VladimirWork;2.PNG;https://jira.hyperledger.org/secure/attachment/11551/2.PNG","07/Aug/17 10:27 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11838/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyayn:",,,,,,10,,,,,,,,,,,,,,,,,,,,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jul/17 9:17 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","07/Aug/17 7:13 PM;spivachuk;*Problem reason:*
* In Sovrin CLI there was an exception handler for the case when a schema with the seq no passed in {{ref}} parameter of {{send CLAIM_DEF}} command is not found but an exception of the corresponding type was nowhere raised in the code. Also in wallets and public repos both exceptions and None values were used in different places in the code to indicate that the requested value is not found.

*Changes:*
* Corrected getting of values from wallets and public repos. SchemaNotFoundError and ValueError are now raised in case the requested value is not found (for schemas and other values correspondingly).
* Corrected existing tests correspondingly to the made changes.
* Added tests for send CLAIM_DEF command which verify the fix.
* Updated indy-anoncreds dependency.

*Committed into:*
* Pull requests:
** https://github.com/hyperledger/indy-anoncreds/pull/86
** https://github.com/hyperledger/indy-node/pull/281
* Version:
** indy-node-dev 1.0.78

*Risk factors:*
* Operations which get values from wallets and public repos.

*Risk:*
* Low

*Covered with tests:*
* New tests:
** testSendClaimDefSucceedsIfRefIsSeqNoOfSchemaTxn
** testSendClaimDefFailsIfRefIsSeqNoOfNonSchemaTxn
** testSendClaimDefFailsIfRefIsNotExistingSeqNo
* Existing tests:
** testGetSchemaByInvalidSeqNo
** testGetSchemaNonExistent
** testSubmitPublicKey
** testGetPrimaryPublicKeyNonExistent
** testGetRevocationPublicKeyNonExistent

*Recommendations for QA:*
* Please verify that the message {{Schema with seqNo <SEQ_NO> not found}} is printed in both cases: when the transaction with the seq no passed in {{ref}} parameter of {{send CLAIM_DEF}} command is not SCHEMA and when there is no transaction with the seq no passed in {{ref}} parameter of {{send CLAIM_DEF}} command.;;;","07/Aug/17 10:27 PM;VladimirWork;Build Info:
sovrin 1.0.78
indy-node 1.0.78

Steps to Validate:
1. Send CLAIM_DEF with nonexistent seqNo as REF parameter.
2. Send CLAIM_DEF with existing seqNo (not SCHEMA) as REF parameter.
3. Send CLAIM_DEF with existing seqNo (SCHEMA) as REF parameter.

Actual Results:
Step 1 and 2: Schema with seqNo ... not found.
Step 3: The claim definition was published to the Sovrin distributed ledger:
Sequence number is ... !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Build badges in several github repos have stopped working,INDY-379,18964,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,avkrishnan,avkrishnan,05/Jul/17 6:43 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,,,,,"!image-2017-07-05-15-08-46-263.png!

See the attached image. This is after the migration to ci.evernym.com. The readme.md files on several repos need to be updated to the new CI URL.

As an aside, currently build badges for master have been implemented. Those for stable also need to be added.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jul/17 6:38 PM;avkrishnan;image-2017-07-05-15-08-46-263.png;https://jira.hyperledger.org/secure/attachment/11557/image-2017-07-05-15-08-46-263.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-48,,,,,,,,,,"1|hzy12f:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Sep/18 12:02 AM;esplinr;The CI badges have been removed from the repos. If it is necessary to create new ones, we will raise a separate issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make the tests working using pure pytest,INDY-380,18968,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,,alexander.shekhovcov,alexander.shekhovcov,05/Jul/17 9:52 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,,,,,"There is the runner.py script which is common for 4 repos. The script is used for testing on CI and local testing. So we have two options:
 * store 4 copies of the script in each repo
 * store the script in a common repo so each developer has to somehow obtain the script from the repo

Both options have disadvantages.

The only solution can be do not use runner.py by making the tests working using just the `pytest` commands. 

A solution should be check on the CI and the developer environment (pycharm and terminal).",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-318,INDY-1750,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzy11z:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,sergey.khoroshavin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 9:26 PM;sergey.khoroshavin;*Triage*
Tests do work with pure pytest, the reason why we have _runner.py_ is to split test workload between different machines to parallelize testing. Still using standard tools like pytest-xdist looks like better solution, but this should be separate feature task.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Command doesn't work with justification parameter,INDY-381,18978,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,VladimirWork,VladimirWork,05/Jul/17 11:55 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,should,,,,"Build Info:
sovrin-client 0.4.19

Overview:
Send POOL_UPGRADE command doesn't work with justification parameter.

Steps to Reproduce:
1. Send POOL_UPGRADE command with empty/text/numeric justification parameter.

Actual Results:
Invalid syntax error in all cases.
Help message does not contain justification parameter.

Expected Results:
Command should handle justification parameter the same way as other parameters.
Help message should contain justification parameter in ""usage"" and ""example(s)"" sections.",,,,,,,,,,,,,,INDY-121,,,,,,,,,,,,,,,,,,,,,"05/Jul/17 11:52 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11564/Screenshot.PNG","05/Jul/17 11:55 PM;VladimirWork;cli.log;https://jira.hyperledger.org/secure/attachment/11563/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx0tj:",,,,,,,,,,,,,,,,,,,,,,,,,,Toktar,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jul/17 11:56 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","10/Oct/18 10:36 PM;Toktar;This client is deprecated now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Node is upgraded not on schedule when the upgrade is scheduled twice,INDY-382,18983,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,ozheregelya,ozheregelya,06/Jul/17 12:50 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,should,,,,,"*Overview:*
Node is upgraded not on schedule when the upgrade is scheduled twice.

*Case 1:*
*Steps to Reproduce:*
1. Send POOL_UPGRADE to one or several nodes.
Node1 upgrade is scheduled to 2017-07-25 14:00:
{code:java}
send POOL_UPGRADE name=upgrade-1 version=0.4.9 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-07-25T14:00:00.000000+00:00'} timeout=10 force=True{code}
Node2 upgrade is scheduled to 2017-07-10 14:10:
{code:java}
send POOL_UPGRADE name=upgrade-2 version=0.4.9 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-07-10T14:10:00.000000+00:00'} timeout=10 force=True{code}
2. Send POOL_UPGRADE to all nodes.
All nodes upgrade is scheduled to 2017-07-15:
{code:java}
send POOL_UPGRADE name=upgrade-3 version=0.4.9 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-07-15T12:20:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-7-15T10:25:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-07-15T10:30:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-07-15T10:35:00.000000+00:00'} timeout=10 force=False{code}
*Actual Results:*
Node 1 and Node 2 were upgraded 2017-07-05 (in date of sending the last POOL_UPGRADE) at 14:00 and 14:10 accordingly.

*Expected Results:*
Nodes should be upgraded in accordance with the schedule.","Build Info:
  sovrin-client version: 0.4.9
  sovrin-node version: 0.4.9
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,INDY-280,INDY-231,,,INDY-701,,,,,,,,"06/Jul/17 10:29 PM;ozheregelya;2017-07-06 16_29_23-.png;https://jira.hyperledger.org/secure/attachment/11600/2017-07-06+16_29_23-.png","06/Jul/17 1:20 AM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11575/Node1.log","06/Jul/17 1:20 AM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11576/Node2.log","06/Jul/17 1:20 AM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11577/Node3.log","06/Jul/17 1:20 AM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11578/Node4.log","06/Jul/17 1:20 AM;ozheregelya;cli.log;https://jira.hyperledger.org/secure/attachment/11574/cli.log","06/Jul/17 10:54 PM;ozheregelya;new_logs.tar.gz;https://jira.hyperledger.org/secure/attachment/11601/new_logs.tar.gz","06/Jul/17 1:20 AM;ozheregelya;upgrade_log_node1;https://jira.hyperledger.org/secure/attachment/11579/upgrade_log_node1","06/Jul/17 1:20 AM;ozheregelya;upgrade_log_node2;https://jira.hyperledger.org/secure/attachment/11580/upgrade_log_node2","06/Jul/17 1:20 AM;ozheregelya;upgrade_log_node3;https://jira.hyperledger.org/secure/attachment/11581/upgrade_log_node3","06/Jul/17 1:20 AM;ozheregelya;upgrade_log_node4;https://jira.hyperledger.org/secure/attachment/11582/upgrade_log_node4",,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyk5z:",,,,,,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,,ozheregelya,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jul/17 10:54 PM;ozheregelya;On the next day this pool looks like this: 
!2017-07-06 16_29_23-.png|thumbnail!
Node 1 and Node 2 were upgraded yesterday (as described in description of this ticket). But really strange thing happened with Node 3 and Node 4. They either tried to upgrade out of schedule (but upgrade was failed because of problems with dependencies). So, it looks like upgrade scheduling to future date does not work at all. New logs are attached: [^new_logs.tar.gz];;;","24/Oct/17 12:45 AM;spivachuk;*Problem status:*
- The issue described in the ticket description is not reproduced on the current {{master}} version. The issue might be earlier caused by INDY-231 which has already been fixed.
- Found another issue: node upgrade is scheduled twice in case pool upgrade is made in force mode. This can be seen in the upgrade log: 3 messages are added for the same upgrade: {{scheduled}}, {{cancelled}} and {{scheduled}}.

*Changes:*
- Fixed the issue with repeated scheduling of node upgrade in case pool upgrade is made in force mode.

*Committed into:*
- https://github.com/hyperledger/indy-plenum/pull/424
- https://github.com/hyperledger/indy-node/pull/408
- indy-plenum 1.1.147 master
- indy-node 1.1.174 master

*Risk factors:*
- Handling of {{POOL_UPGRADE}} and {{POOL_CONFIG}} transactions with {{force=True}}, with {{force=False}} and without {{force}} flag.

*Risk:*
- Low

*Covered with tests:*
- The absence of the issue described in the ticket is verified by {{test_node_reschedules_upgrade_for_proper_datetime}}.
- The absence of the issue with repeated scheduling of node upgrade in case pool upgrade is made in force mode is verified by {{test_pool_upgrade_force_scheduled_only_once}}.

*Recommendations for QA:*
* It should be tested that:
- the issue described in the ticket description is not reproduced on the current {{master}} version;
- the issue with repeated scheduling of node upgrade in case pool upgrade is made in force mode has been fixed.;;;","26/Oct/17 9:24 PM;VladimirWork;Build Info:
indy-node 1.2.185

Steps to Reproduce - Case 1:
1. Send POOL_UPGRADE to one or several nodes.
Node1 upgrade is scheduled to 2017-10-29 10:00:
{code:java}
send POOL_UPGRADE name=upgrade-1 version=1.2.186 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-10-29T10:00:00.000000+00:00'} timeout=10 force=True{code}
Node2 upgrade is scheduled to 2017-10-27 10:10:
{code:java}
send POOL_UPGRADE name=upgrade-2 version=1.2.186 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-10-27T10:10:00.000000+00:00'} timeout=10 force=True{code}
2. Send POOL_UPGRADE to all nodes.
All nodes upgrade is scheduled to 2017-10-28:
{code:java}
send POOL_UPGRADE name=upgrade-3 version=1.2.186 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-10-28T10:20:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-10-28T10:25:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-10-28T10:30:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-10-28T10:35:00.000000+00:00'} timeout=10 force=False{code}

Actual Results:
The last upgrade txn on each node cancels previous upgrade txn for this node. Upgrades scheduled on future date are not performed at current date.

Steps to Reproduce - Case 2:
1. Send POOL_UPGRADE to one or several nodes.
Node1 upgrade is scheduled to 2017-10-26 11:00:
{code:java}
send POOL_UPGRADE name=upgrade--1 version=1.2.186 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-10-26T11:00:00.000000+00:00'} timeout=10 force=True{code}
Node2 upgrade is scheduled to 2017-10-26 11:10:
{code:java}
send POOL_UPGRADE name=upgrade--2 version=1.2.186 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-10-26T11:10:00.000000+00:00'} timeout=10 force=True{code}
2. Send POOL_UPGRADE to all nodes.
All nodes upgrade is scheduled to 2017-10-26:
{code:java}
send POOL_UPGRADE name=upgrade--3 version=1.2.186 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-10-26T11:20:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-10-26T11:25:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-10-26T11:30:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-11-26T10:35:00.000000+00:00'} timeout=10 force=False{code}

Actual Results:
The last upgrade txn on each node cancels previous upgrade txn for this node. All nodes are upgraded in accordance with the schedule.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
After simultaneous restart of several nodes NYM sending stop working,INDY-383,18985,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,aleksey-roldugin,aleksey-roldugin,06/Jul/17 2:04 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"h6. BUILD

sovrin-node 0.4.9
 sovrin-client 0.4.19
h6. PRECONDITIONS

6 machines in pool: 4 original, 2 added.
h6. STEPS TO REPRODUCE
 # Run _sudo systemctl restart sovrin-node_ command at the same time on several nodes (Node 4, 5, 2, 3). It was at 2017-07-05 14:14:43,004 in logs.
 # Restart another node (Node 1).
 # Try to add NYM.

h6. ACTUAL RESULT

NYM is not added. Simultaneous restart of all 6 nodes and sequential restart of every node did not help.
h6. Predictions about problem cause
 * After first simultaneous restart of 4 nodes new primary node was not elected but I did not found information about it in logs.
 * View change was happen and broke something",,,,,,,,,,,INDY-389,,,,,,,,,,,,INDY-334,,,,,,,,,,,,"06/Jul/17 2:04 AM;aleksey-roldugin;Node1.log;https://jira.hyperledger.org/secure/attachment/11588/Node1.log","06/Jul/17 2:04 AM;aleksey-roldugin;Node2.log;https://jira.hyperledger.org/secure/attachment/11587/Node2.log","06/Jul/17 2:04 AM;aleksey-roldugin;Node3.log;https://jira.hyperledger.org/secure/attachment/11586/Node3.log","06/Jul/17 2:04 AM;aleksey-roldugin;Node4.log;https://jira.hyperledger.org/secure/attachment/11585/Node4.log","06/Jul/17 2:04 AM;aleksey-roldugin;Node5.log;https://jira.hyperledger.org/secure/attachment/11584/Node5.log","06/Jul/17 2:04 AM;aleksey-roldugin;Node6.log;https://jira.hyperledger.org/secure/attachment/11583/Node6.log","06/Jul/17 2:04 AM;aleksey-roldugin;cli.log;https://jira.hyperledger.org/secure/attachment/11589/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxqdr:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,aleksey-roldugin,lovesh,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jul/17 2:05 AM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","07/Jul/17 8:22 PM;lovesh;The problem, Node4 and Node6 were turned off when they had ordered only 82 txns, while the others had ordered 83 txns, now when Node4 and Nod6 came back they could get not get n-f consistent ViewChangeDone message since n-f equals 5 in this case and we have only 4 Nodes giving consistent ViewChangeDone messages. An alternative approach can be that on startup, if n-f nodes are not able to satisfy a node(s), they trust the highest f+1 consistent ViewChangeDone messages
This bug does not satisfy the protocol requirements since it increases the number of faults beyond `f` at a particular instant of time.
A new task has been created to address this general problem, INDY-389;;;","15/Jul/17 12:54 AM;mzk-vct;Changes were done in https://jira.hyperledger.org/browse/INDY-389
Check whether they helped 

Build numbers: 
node==0.4.35
plenum==0.4.47;;;","18/Jul/17 7:12 AM;slafranca;Tested with: 
indy-plenum 0.4.50
indy-anoncreds 0.4.15 
indy-node 0.4.39
I repeatedly sent the command to restart the nodes (all 6 simultaneously).  The nodes came online and I was able to add a nym.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New Stable Build Request from H4 Sprint,INDY-384,18995,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,06/Jul/17 1:51 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"We need an RC build of:
indy-plenum=0.4.50
indy-anoncreds= 0.4.15
indy-node= 0.4.39


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1vj:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,andrey.goncharov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/17 5:26 AM;krw910;Blocked by INDY-406;;;","18/Jul/17 9:51 PM;andrey.goncharov;Released.
plenum 0.4.20
anoncreds 0.4.7
node 0.4.27
sovrin 0.2.1;;;","18/Jul/17 9:54 PM;andrey.goncharov;[~krw910] there was a problem with testPrePrepareProcessedInOrder test in plenum. It also can be reproduced on master 0.4.50. I disabled it for this particular build to do the merge. The problem seems to be gone with the latest plenum. If you want I can build a new stable with the latest plenum for you.;;;","19/Jul/17 5:32 AM;krw910;QA has approved the build.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Public key file is not created when SERVICES field of NODE request is empty,INDY-385,18997,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,,mzk-vct,mzk-vct,06/Jul/17 7:11 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,,,,,"If NODE transaction contains empty SERVICES field then file for public key file is not created.

 https://github.com/hyperledger/indy-plenum/blob/master/plenum/server/pool_manager.py#L228",,,,,,,,,,,,,,INDY-133,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzwyp3:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/18 12:47 PM;krw910;[~VladimirWork] Can you take a look into this issue and see what we need to do with this ticket. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Blocking Issue: Unable to add NYM using DID because genesis files are setup with cryptonyms,INDY-386,19006,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,slafranca,slafranca,07/Jul/17 7:42 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"# I created a new ID and entered 'new key with seed Faber000000000000000000000000000'. Result was:
{code:java}
Key created in keyring Default (Faber)
Identifier for key is ULtgFQJe6bjiFbs7ke3NJD
Verification key is ~5kh3FB4H3NKq7tUDqeqHc1
Current identifier set to ULtgFQJe6bjiFbs7ke3NJD
{code}

# Adding a new NYM, I set a steward as a signer (new key with seed 000000000000000000000000Steward1).  
# I ran 'send NYM dest=ULtgFQJe6bjiFbs7ke3NJD verkey=~5kh3FB4H3NKq7tUDqeqHc1'

Result:
The output was:
{code:java}
Adding nym ULtgFQJe6bjiFbs7ke3NJD
Error: client request invalid: CouldNotAuthenticate() [caused by verkey must be provided]
{code}




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/17 11:49 PM;krw910;.sovrin-cli-history;https://jira.hyperledger.org/secure/attachment/11605/.sovrin-cli-history","07/Jul/17 11:49 PM;krw910;cli.log;https://jira.hyperledger.org/secure/attachment/11606/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxqdz:",,,,,,H3,H4,H5,,,,,,,,,,,,,,,,,,dsurnin,krw910,ozheregelya,slafranca,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/17 7:43 AM;slafranca;[~krw910] had me log this as a high priority and assign it directly to Devin.;;;","07/Jul/17 11:16 PM;ozheregelya;Here is workaround which Kelly told about in the checkpoint meeting:


I see one workaround of INDY-386 using old client. Need to add NYM with new Trustee1 DID using old Trustee1 CID on old client version.
From new client (0.4.22 version):
{code:java}
sovrin@test> new key with seed 000000000000000000000000Trustee1
Key created in keyring testf
Identifier for key is V4SGRU86Z58d6TV7PBUe6f
Verification key is ~CoRER63DVYnWZtK8uAzNbx
Current identifier set to V4SGRU86Z58d6TV7PBUe6f{code}

From old client (e.g. 0.4.19 version):
{code:java}
sovrin@test> new key with seed 000000000000000000000000Trustee1
Key created in keyring Default
Identifier for key is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
Current identifier set to GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBUe6f role=TRUSTEE verkey=~CoRER63DVYnWZtK8uAzNbx
Adding nym V4SGRU86Z58d6TV7PBUe6f
Nym V4SGRU86Z58d6TV7PBUe6f added{code}

After that we can use Trustee in new client (0.4.22 version):
{code:java}
sovrin@test> new key with seed 000000000000000000000000Trustee1
Key created in keyring testNoTrustee
Identifier for key is V4SGRU86Z58d6TV7PBUe6f
Verification key is ~CoRER63DVYnWZtK8uAzNbx
Current identifier set to V4SGRU86Z58d6TV7PBUe6f
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBUe66
Adding nym V4SGRU86Z58d6TV7PBUe66
Nym V4SGRU86Z58d6TV7PBUe66 added{code};;;","10/Jul/17 1:36 PM;krw910;The issue is that the genesis files are using Cryptonyms. If you manually change them before starting the nodes to use the correct DIDs then things work. [~devin-fisher] was going to check in a change to the genesis file creation. I believe he has a test failing which is in INDY-392;;;","13/Jul/17 5:26 AM;krw910;Blocked by INDY-406;;;","18/Jul/17 6:15 AM;slafranca;Tested with: 
indy-plenum                      0.4.50
indy-anoncreds                   0.4.15 
indy-node                        0.4.39
The NYM was added successfully.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add maintainers.txt file with names and email addresses of project maintainers to each github repo,INDY-387,19008,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,nage,nage,07/Jul/17 11:07 AM,08/Oct/19 9:16 PM,28/Oct/23 2:46 AM,08/Oct/19 9:16 PM,,,,,0,5Months,,,,,"Hyperledger projects typically have a maintainers file with a list of project maintainers and their email addresses.  Here is an example file from fabric [https://github.com/hyperledger/fabric/blob/3af753eb6afb9db890f9a1c5207fe39a2b46a14e/docs/source/MAINTAINERS.rst|https://github.com/hyperledger/fabric/blob/3af753eb6afb9db890f9a1c5207fe39a2b46a14e/docs/source/MAINTAINERS.rst.]

These files are not necessarily at the root of each project, but reflect who maintains portions of the project.

 

[~danielhardman], we should consider how we want to handle this information for Indy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzy11r:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,nage,tkuhrt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jul/17 6:14 AM;danielhardman;I agree that we should do this. Please do it, Nathan.;;;","08/Oct/19 9:16 PM;ashcherbakov;This is already done. We have CODEOWNERS file and [MAINTAINERS.md|https://github.com/hyperledger/indy-node/blob/master/MAINTAINERS.md];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to locate sovrin-client when apt install is done in vagrant ,INDY-388,19015,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,faisal00813,faisal00813,07/Jul/17 9:32 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,5Months,,,,,"I was trying to setup agent and validators.

Validators started fine, but when I started agents with command
{quote}{{vagrant up agent01 agent02 agent03 agent04 }}
{quote}
it threw error 
{quote}{{agent03: Unable to locate package sovrin-client }}
{quote}
got the same error when I ssh-ed in vagrant and tried sudo apt-get install sovrin-client

 

Environment:

Mac Os Sierra 10.12.5

vagrant 1.9.6","Include OS, Indy platform version, and specific configuration settings that may prove useful.",,,,,,,,,,,,,,,,,,,INDY-2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzy11b:",,,,,,,,,,,,,,,,,,,,,,,,,,faisal00813,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 10:25 PM;sergey-shilov;This package and client itself do not exist any more, this ticket is outdated and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Recover from greater than f failures,INDY-389,19019,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,lovesh,lovesh,07/Jul/17 10:02 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,blocked,,,,,"An example of >f failures is more than f nodes simultaneously crashing or crashing such that they have different ledger from other nodes.

[Researching solutions|https://docs.google.com/document/d/1o8cqulI_DyS8ccaaXJVdwLEIfs4iGtLEcvJGvWMxQvE/edit#]",,,,,,,,,,,INDY-401,,,INDY-334,INDY-236,INDY-383,,,,,,,,,,,INDY-420,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx1tz:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,ashcherbakov,lovesh,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jul/17 12:54 AM;mzk-vct;Ticket is blocked by discussion of solutions;;;","10/Jul/17 2:46 PM;lovesh;Here is a proposal:
We have been using *>2f* for CONSISTENCY_PROOF and LEDGER_STATUS quorum sizes. I now realise that they are incorrect. You need *>2f* for agreement before ordering since some replicas may vote one way or the other. But after requests have been ordered only a quorum of *f+1* is required, eg. Clients require *f+1* replies not *2f+1* replies. Since LEDGER_STATUS and CONSISTENCY_PROOF are communicating information derived from ordered requests, *f+1* is sufficient since we know that at least once correct node saw ordered the request which means *>=2f+1* nodes participated in consensus. This solves the problem where *<= 2f* nodes can crash simultaneously with their ledger being different from the non crashed ones or all nodes crash where the last orderable (*>2f* COMMITs) requests are ordered at *>=f+1* and *<2f+1* nodes. If more than *2f* nodes crash, leaving less than *f+1* nodes alive or less than *f+1* nodes with last ordered requests, then the nodes alive will revert remove entries from the ledger. The idea is to choose the *>f* nodes with the highest ledger and consider them to be the last ordered state.  
This is fine as *<f+1* nodes had ordered the requests so a client could not have got sufficient replies for those requests and thus would not have considered them ordered. 
Also one more change that needs to be made to processing LEDGER_STATUS is that a node should not start requesting/processing consistency proof as soon as it gets *>f* LEDGER_STATUS, it should either get from *>2f* or wait till a timeout. 
;;;","15/Jul/17 12:52 AM;mzk-vct;Build numbers: 
node==0.4.35
plenum==0.4.47;;;","22/Jul/17 12:55 AM;mzk-vct;PR https://github.com/hyperledger/indy-plenum/pull/295;;;","24/Jul/17 4:57 PM;ashcherbakov;A new PR: https://github.com/hyperledger/indy-plenum/pull/301;;;","24/Jul/17 5:53 PM;mzk-vct;PR 295 closed in favour of PR 301which has more simple implementation. 
Some developmens from 295 can be useed then in refactoring.;;;","24/Jul/17 9:52 PM;mzk-vct;h3. Pull requests merged, builds:
node==0.4.60
plenum==0.4.73;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Combine repos,INDY-390,19025,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,andrey.goncharov,andrey.goncharov,07/Jul/17 11:03 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Combine repos to get two of them as a result:
 * indy-plenum
 * indy-node",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy21z:",,,,,,H4,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jul/17 9:10 PM;andrey.goncharov;Repo consolidation is done.

indy-node/0.4.17

indy-plenum/0.4.31

As a result we have two repos: plenum and indy-node. Each one of them produces a single deb package: python3-plenum and sovrin-node correspondingly.

BE AWARE, I stumbled upon intermittent issues with Jenkins several times (missing workspace). Eventually it disappeared, yet I feel obligated to inform you about it.

I tested final deliverable (DEB package) myself on a brand new VM. It installs and works just fine: cli starts, node starts.

[~danielhardman] at you request I packed our code in two DEB files: sovrin-node (includes indy-node, indy-client, indy-common) and python3-plenum (includes indy-plenum, indy-state, indy-ledger, indy-stp). Yet it feels odd to me that we bundle node and client together. Shouldn't we let our users work with the client alone? Shouldn't we still produce separate sovrin-node and sovrin-client DEB packages? If we decide to keep it bundled shouldn't we rename the package from sovrin-node to just sovrin (to avoid any confusion)? Anyway it can be done quick enough after the merge (I believe it's no more than a one day job). It's just something for you to think about.

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Blocking Issue: sovrin-node service throws multiple errors on startup,INDY-391,19067,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,08/Jul/17 4:43 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,1,,,,,,"I am getting multiple types of errors from the sovrin-node service.

*Build Information*
*{color:#205081}Node {color}*
python3-stp=0.2.44
python3-ledger=0.3.51
python3-state-trie=0.2.19
python3-plenum=0.4.29
python3-sovrin-common=0.3.24
sovrin-node=0.4.15


*{color:#205081}Client {color}*
python3-stp=0.2.42
python3-ledger=0.3.48
python3-state-trie=0.2.3
python3-plenum=0.4.26
python3-sovrin-common=0.3.22
python3-anoncreds=0.4.7
sovrin-client=0.4.25

*Node 3*
Showed no errors

*Node 1*
{code}
Node1.evernym.lab start_sovrin_node[9499]: CURVE I: cannot open client HELLO -- wrong server key?
{code}

*Node 2 and 4*
{code}
     return self._process_requested_ledger_status(msg, frm)
   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 2257, in _process_requested_ledger_status
     ledger_status=ledger_status)
   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 2197, in valid_requested_msg
     return self._validate_requested_ledger_status(**kwargs)
   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 2213, in _validate_requested_ledger_status
     return LedgerStatus(*kwargs['ledger_status'])
   File ""/usr/local/lib/python3.5/dist-packages/plenum/common/messages/message_base.py"", line 89, in __init__
     .format(argsLen)
 AssertionError: number of parameters should be the same as a number of fields in schema, but it was 8
{code}
",,,,,,,,,,,,,,IS-199,,,,,,,,,,,,,INDY-405,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy227:",,,,,,H4,,,,,,,,,,,,,,,,,,,,gudkov,krw910,mzk-vct,sergey.minaev,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jul/17 1:05 AM;mzk-vct;The reason is that ujson dependency which is used for serialization (marshaling) of messages does serialization in different ways depending on its version: ujson==1.35 - does what we need, ujson==1.33 - does it wrong.

 

[~krw910] [~ozheregelya] [~aleksey-roldugin] [~ozheregelya] [~VladimirWork]

Researching solutions, but there is workaround to make pool work - manually install ujson==1.35 for user sovrin;;;","11/Jul/17 2:30 AM;mzk-vct;Found simple solution, pull request https://github.com/hyperledger/indy-plenum/pull/266;;;","11/Jul/17 8:55 PM;mzk-vct;PR for Sovrin https://github.com/hyperledger/indy-node/pull/218;;;","11/Jul/17 10:00 PM;mzk-vct; *Problem reason:*
 # In the scope of message validation task messages were reimplemented as classes, but in a way to keep them compatible with a code that is written for named tuples. That's why they mimic for being named tuples. 
 # version of ujson that is used for serialization differs depending on the version of OS. 
 # ujson of version 1.33 uses different methods for getting fields of objects then ujson of version 1.35.
 # MessageRequest recently introduced includes other messages as field values. In this case ujson 1.33 and 1.35 give different results.

*Changes:*
Overrided __dir__ method for MessageBase to make it return only keys that we need

*Builds:*
 sovrin-node==0.4.19
 plenum==0.4.35

*Tests:*
https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/input_validation/test_message_serialization.py

*Risk factors:*
New message implementation pretends being named tuple quite well, but it is not right solution and this ticket shows that it can cause problems.
It was done this way because of time and some other limitations, but it should be re-factored.

*Risk:*
 Low

*Recommendations for QA (optional):*
Try running pool with different versions of ujson;;;","12/Jul/17 7:35 PM;VladimirWork;Build Info:
sovrin-node 0.4.19

Steps to Validate:
1. Start nodes with ujson 1.33/1.34/1.35.

Actual Results:
Nodes start successfully. There are no errors in systemctl status sovrin-node.service and journalctl.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test_network_setup.py uses cryptonyms,INDY-392,19097,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,devin-fisher,devin-fisher,10/Jul/17 12:13 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,test_network_setup.py which sets up the genesis txns for our tests networks is using cryptonyms which make it hard to use with recent CLI changes. We are deprecating cryptonyms so we should change these testing genesis txns to use DID style identifiers. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy22f:",,,,,,H4,,,,,,,,,,,,,,,,,,,,ashcherbakov,devin-fisher,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jul/17 12:16 PM;devin-fisher;I've done most of the work at:

[https://github.com/devin-fisher/plenum/tree/test_network_did]

[https://github.com/hyperledger/indy-plenum/pull/261]

but it is causing issues with the tests that I don't really understand.

[https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-261/1/console]

 

I think it would be quicker to have someone with more experience with plenum get the test working again.;;;","10/Jul/17 8:12 PM;ashcherbakov;[~devin-fisher]
This looks very weird. The errors seem to be not related to your changes.
Let's wait for the results of next test run.
Probably there was some error that makes all other tests fail.;;;","10/Jul/17 8:45 PM;ashcherbakov;[https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-264/] - looks like the PR is green now.;;;","12/Jul/17 2:23 PM;krw910;[~ashcherbakov] the PR auto merge shows a failure.
https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-264/;;;","12/Jul/17 4:48 PM;ashcherbakov;[~krw910]
Sorry, the correct PR for this issue is [https://github.com/hyperledger/indy-plenum/pull/261]. not 264.

261 PR was successfully merged.;;;","12/Jul/17 10:14 PM;krw910;I have verified that PR 261 has the changes and did pass.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[send NYM] Exception is raised due to multiple commands sending,INDY-393,19105,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,VladimirWork,VladimirWork,10/Jul/17 8:07 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,5Months,,,,,"Build Info:
sovrin-client 0.4.19
sovrin-node 0.4.12

Overview:
Exception is raised due to multiple send NYM commands sending in sequence.

Preconditions:
Install pool with following machine settings:
400 MB RAM
1 processor with load limit at 95%

Steps to Reproduce:
1. Send new key command.
2. Login as default Trustee.
3. Send NYM command to new key several times (5-10) in sequence.

Actual Results:
Exception in callback PosixAsyncioEventLoop.run_as_coroutine.<locals>.stdin_ready() at /usr/lib/python3/dist-packages/prompt_toolkit/eventloop/asyncio_posix.py:65
handle: <Handle PosixAsyncioEventLoop.run_as_coroutine.<locals>.stdin_ready() at /usr/lib/python3/dist-packages/prompt_toolkit/eventloop/asyncio_posix.py:65>

Expected Results:
There should be human-readable error (if it is necessary) or nothing (because NYM actually is added successfully).",,,,,,,,,,,,,,,,,,,,,,,INDY-271,,,,,,,,,,,,"10/Jul/17 8:04 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11616/Screenshot.PNG","10/Jul/17 8:04 PM;VladimirWork;cli.log;https://jira.hyperledger.org/secure/attachment/11615/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-785,,,,,,,,,,"1|hzy113:",,,,,,,,,,,,,,,,,,,,,,,,,,n-horiguchi,RyanWest,sergey-shilov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jul/17 8:08 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","10/Nov/17 12:22 AM;VladimirWork;Another case for similar issue:

Build Info:
indy-node 1.2.202

Steps to Reproduce:
1. Place .sovrin directory (1.1.43) to /home/indy/.
2. Run CLI as indy user.
3. Type Y to migrate client data.
4. Try to connect sandbox network.

Actual Results:
Exception in callback PosixAsyncioEventLoop.run_as_coroutine.<locals>.stdin_ready() at /usr/lib/python3/dist-packages/prompt_toolkit/eventloop/asyncio_posix.py:65
handle: <Handle PosixAsyncioEventLoop.run_as_coroutine.<locals>.stdin_ready() at /usr/lib/python3/dist-packages/prompt_toolkit/eventloop/asyncio_posix.py:65>

Expected Results:
CLI should work normally.

Additional Info:
*Issue reproduces in docker only.*;;;","10/Oct/18 12:23 AM;sergey-shilov;This CLI is deprecated, no longer supported and going to be removed, this ticket is not relevant any more and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incorrect client behavior due to no free disk space is available,INDY-394,19106,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,VladimirWork,VladimirWork,10/Jul/17 8:43 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,5Months,,,,,"Build Info:
sovrin-client 0.4.19
sovrin-node 0.4.12

Overview:


Preconditions:
Install pool with following machine settings:
400 MB RAM
1 processor with load limit at 95%
*No free disk space is available*

Steps to Reproduce:
1. Run sovrin client.

Actual Results:
1. ""OSError: [Errno 28] No space left on device"" with stack trace is displayed (see in attachment).
2. Client try to restart itself several times throwing ""FileNotFoundError: [Errno 2] No usable temporary directory found in ['/tmp', '/var/tmp', '/usr/tmp', '/home/sovrin']"" with stack trace (see in attachment).

Expected Results:
There should be no spontaneous client's restarts.
All errors should be human-readable (""There are no free disk space is available, free some disk space and try again"" or something like that) and have no stack trace.",,,,,,,,,,,,,,,,,,,,,,,INDY-271,,,,,,,,,,,,"10/Jul/17 8:41 PM;VladimirWork;another_cli.log;https://jira.hyperledger.org/secure/attachment/11618/another_cli.log","10/Jul/17 8:41 PM;VladimirWork;another_cli_errors.txt;https://jira.hyperledger.org/secure/attachment/11617/another_cli_errors.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzx1nj:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jul/17 8:43 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","12/Oct/18 6:55 PM;ashcherbakov;The CLI is deprecated.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Transfer LATEST pipelines from jenkins.evernym.com to ci.evernym.com,INDY-395,19110,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,stevetolman,andrey.goncharov,andrey.goncharov,10/Jul/17 9:36 PM,08/Oct/19 9:14 PM,28/Oct/23 2:46 AM,08/Oct/19 9:14 PM,,,,,0,5Months,,,,,"On old jenkins we had LATEST pipelines for master and stable to run all tests for all repos ignoring dependency pins to test compatibility of latest packages periodically.

We should reinstate them. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzy11j:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Oct/19 9:14 PM;ashcherbakov;We have system tests instead now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Blocking Issue: Unable to launch agents for Faber, Acme, and Thrift due to recent DID changes",INDY-396,19123,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,krw910,krw910,krw910,11/Jul/17 1:45 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"The agents for Faber, Acme, and Thrift throw an error when launching them. I believe this will be the same case for the Unicorn agents which will also need updating with the new DID changes.

 

To setup the agents needed in the Getting Started Tutorial you need to do the following listed below. Once those agents are setup you start the demo scripts and will get the error listed below.

*Setup*
 In the sovrin cli register the demo agents by doing the following
 ------------------------------------------------------------------------------------------------------------------------
 *Register the Faber Agent* 
 *{color:#205081}Create a Trust Anchor for the agent{color}*
 send NYM dest=ULtgFQJe6bjiFbs7ke3NJD role=TRUST_ANCHOR

*{color:#205081}Send the endpoint attribute for the agent{color}*
 send ATTRIB dest=ULtgFQJe6bjiFbs7ke3NJD raw=\{""endpoint"": \{""ha"": ""10.0.0.202:5555"", ""pubkey"": ""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z""}}

------------------------------------------------------------------------------------------------------------------------
 *Register the Acme Agent*

*{color:#205081}Create a Trust Anchor for the agent{color}*
 send NYM dest=CzkavE58zgX7rUMrzSinLr role=TRUST_ANCHOR

*{color:#205081}Send the endpoint attribute for the agent{color}*
 send ATTRIB dest=CzkavE58zgX7rUMrzSinLr raw=\{""endpoint"": \{""ha"": ""10.0.0.203:6666"", ""pubkey"": ""C5eqjU7NMVMGGfGfx2ubvX5H9X346bQt5qeziVAo3naQ""}}

------------------------------------------------------------------------------------------------------------------------
 *Register the ThriftBank Agent*

*{color:#205081}Create a Trust Anchor for the agent{color}*
 send NYM dest=H2aKRiDeq8aLZSydQMDbtf role=TRUST_ANCHOR

*{color:#205081}Send the endpoint attribute for the agent{color}*
 send ATTRIB dest=H2aKRiDeq8aLZSydQMDbtf raw=\{""endpoint"": \{""ha"": ""10.0.0.204:7777"", ""pubkey"": ""AGBjYvyM3SFnoiDGAEzkSLHvqyzVkXeMZfKDvdpEsC2x""}}

------------------------------------------------------------------------------------------------------------------------

*Starting the Agents*
 *{color:#205081}Agent 2 (Faber){color}*
 python3 /usr/local/lib/python3.5/dist-packages/sovrin_client/test/agent/faber.py --port 5555

*{color:#205081}Agent 3 (Acme){color}*
 python3 /usr/local/lib/python3.5/dist-packages/sovrin_client/test/agent/acme.py --port 6666

*{color:#205081}Agent 4 (Thrift){color}*
 python3 /usr/local/lib/python3.5/dist-packages/sovrin_client/test/agent/thrift.py --port 7777

 
 *{color:#d04437}Error{color}*
  
{code:java}
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/test/agent/faber.py"", line 119, in <module>
    agent = create_faber(name=name, wallet=buildAgentWallet(name, FABER_SEED), base_dir_path=None, port=port)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/test/agent/faber.py"", line 26, in create_faber
    client = create_client(base_dir_path=None, client_class=TestClient)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/agent/agent.py"", line 215, in create_client
    basedirpath=base_dir_path)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/test/testable.py"", line 65, in init_only
    return func(self, *args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/test/client/TestClient.py"", line 25, in __init__
    super().__init__(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", line 51, in __init__
    sighex)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 111, in __init__
    HasPoolManager.__init__(self)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/pool_manager.py"", line 27, in __init__
    _, cliNodeReg, nodeKeys = self.parseLedgerForHaAndKeys(self.ledger)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stack_manager.py"", line 79, in parseLedgerForHaAndKeys
    for _, txn in ledger.getAllTxn():
  File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 223, in getAllTxn
    for seq_no, txn in self._transactionLog.get_range(frm, to))
  File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 223, in <genexpr>
    for seq_no, txn in self._transactionLog.get_range(frm, to))
  File ""/usr/local/lib/python3.5/dist-packages/ledger/serializers/json_serializer.py"", line 75, in deserialize
    return self.loads(data)
  File ""/usr/local/lib/python3.5/dist-packages/ledger/serializers/json_serializer.py"", line 65, in loads
    return json.loads(data)
  File ""/usr/lib/python3.5/json/__init__.py"", line 319, in loads
    return _default_decoder.decode(s)
  File ""/usr/lib/python3.5/json/decoder.py"", line 339, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File ""/usr/lib/python3.5/json/decoder.py"", line 357, in raw_decode
    raise JSONDecodeError(""Expecting value"", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
{code}
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy747:",,,,,,H4,,,,,,,,,,,,,,,,,,,,devin-fisher,krw910,n-horiguchi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/17 1:17 AM;krw910;Looks like this is tied to or the same as INDY-378;;;","12/Jul/17 2:12 AM;devin-fisher;*Not* tied to INDY-378

Caused by a typo in a hand edited genesis file. Changes INDY-392 should prevent needing to hand-edit these files.;;;","12/Jul/17 7:25 AM;krw910;My pool_transactions_sandbox file was incorrect.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LevelDB Error when node runs on low RAM ,INDY-397,19133,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,stevetolman,jkumar,jkumar,11/Jul/17 3:39 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,5Months,,,,,"*Setup:*
4 nodes on vagrant with Virtual box.

*Steps:*
Configure Node1 to run on 200MB RAM.

*Result:*
Node1 logs show LevelDB Error. Logs attached.","vagrant@validator01:~$ sudo dpkg -s sovrin-node
Package: sovrin-node
Status: install ok installed
Priority: extra
Section: default
Installed-Size: 968
Maintainer: Sovrin Foundation <dev@sovrin.org>
Architecture: amd64
Version: 0.3.19
Depends: python3-sovrin-common (= 0.2.11), python3-dateutil
Description: Sovrin node
License: Apache 2.0
Vendor: none
Homepage: https://github.com/sovrin-foundation/sovrin-node.git",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jul/17 3:38 PM;jkumar;Node1.log;https://jira.hyperledger.org/secure/attachment/11629/Node1.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzy0tz:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,jkumar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/18 7:41 PM;ashcherbakov;RocksDB is now used instead of LevelDB;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add new executors on demand,INDY-398,19145,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,andrey.goncharov,andrey.goncharov,11/Jul/17 5:49 PM,09/Oct/19 6:14 PM,28/Oct/23 2:46 AM,09/Oct/19 6:14 PM,,,,,0,5Months,,,,,"We need to fire up new jenkins' slaves on high load and shut them down after 5 minutes of being idle.

POA:
 * Research existing approaches to adding executors dynamically
 * Implement on of them
 * If none found create a python script to fire up a new executor on demand and create a daemon which polls Jenkins periodically for number of active executors and kicks off that script",,,97200,97200,,0%,97200,97200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzy0tb:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:14 PM;esplinr;We aren't going to do this issue as we are moving from Jenkins to GitLab. GitLab makes dynamic pools much easier.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Repo consolidation followup,INDY-399,19146,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,andrey.goncharov,andrey.goncharov,11/Jul/17 5:52 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"1. Rename python3-plenum to indy-plenum
2. Rename sovrin-node to indy-node
3. Create a new .deb file: sovrin.deb that includes genesis transaction files for both the live network and the test network. This depends on indy-node. Please store it the indy repo for now.",,,32400,32400,,0%,32400,32400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1vr:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,andrey.goncharov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/17 9:14 PM;andrey.goncharov;The work is done in feature/indy-399 branches in indy-node, indy-anoncreds, indy-plenum, sovrin-packaging, jenkins-shared repos. Merge is blocked by pending patches to client to make it compatible with the latest anoncreds. They will be provided by gabriel team shortly.;;;","14/Jul/17 6:08 PM;andrey.goncharov;[~krw910]

Packages were renamed:

sovrin-node -> indy-node

python3-plenum -> indy-plenum

python3-anoncreds -> indy-anoncreds

A new package was added: sovrin;;;","17/Jul/17 5:05 AM;krw910;Packages seem to be working with the new naming.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Intermittently failing tests in Plenum/Sovrin,INDY-400,19148,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mzk-vct,mzk-vct,11/Jul/17 6:33 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Following tests in Plenum fail intermittently on Jenkins. Not checked on other machines.
 - test_view_change_in_between_3pc_all_nodes_random_delays - *fixes: [PR-287|https://github.com/hyperledger/indy-plenum/pull/287] (merged) and* *[PR-298|https://github.com/hyperledger/indy-plenum/pull/298] (merged)*
 - test_view_change_complex.py -*fixes: [PR-287|https://github.com/hyperledger/indy-plenum/pull/287] (merged) and* *[PR-298|https://github.com/hyperledger/indy-plenum/pull/298]*  *(**merged**)*
 *{color:#cccccc}- -test_message_outside_watermark1.py-{color} - not reproduced*
 *{color:#cccccc}- -test_state_regenerated_from_ledger-{color} - not reproduced*
 - testSendGetNymFailsIfDestIsPassedInHexFormat in sovrin_client – *fix: [PR-253|https://github.com/hyperledger/indy-node/pull/253] (merged)*
 - test_successive_batch_do_no_change_state in sovrin_node - *fix: [PR-256|https://github.com/hyperledger/indy-node/pull/256] (merged)*
 - -testNodeControlCreatesBackups in sovrin_node- *- can't reproduce in 223 runs*",,,97200,97200,,0%,97200,97200,,,,,,,,,,,,,,,,,,,INDY-823,,,,,,,,"15/Jul/17 5:17 AM;lovesh;testSendGetNymFailsIfDestIsPassedInHexFormat.log;https://jira.hyperledger.org/secure/attachment/11681/testSendGetNymFailsIfDestIsPassedInHexFormat.log","17/Jul/17 10:03 PM;mzk-vct;test_view_change_in_between_3pc_all_nodes_random_delays.log;https://jira.hyperledger.org/secure/attachment/11685/test_view_change_in_between_3pc_all_nodes_random_delays.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx22f:",,,,,,H5,,,,,,,,,,,,,,,,,,,,andkononykhin,andrey.goncharov,ashcherbakov,krw910,lovesh,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jul/17 6:47 PM;mzk-vct;If you faced failing test that is not on the list - please add it.;;;","17/Jul/17 11:51 PM;mzk-vct;Some items marked as *not reproduced*. If you faced it anyway - add comment ;;;","18/Jul/17 12:31 AM;ashcherbakov;A hint for debugging view_change_with_random_delay tests:
* We try to catch-up limited number of times, so, if delays is very huge, it's possible that one of the nodes doesn't catch-up to the correct state
* In the tests we require to receive replies from ALL nodes, not f+1 only. So, if a node with a huge delay (see Item 1) is broken, then we will not be able to receive replies from all nodes (which is probably OK)
* Because of previous items, a possible solution is to require replies from sufficient (f+1) number of nodes only (this is how the real protocol works). 
* Also in order to investigate the issue, I suggest to print the delays (they are ransom) for each node and each 3PC message, to get a picture what delays lead to failing the tests. Probably it will help us to realize either the fix, or expected behaviour (as in Item 1);;;","19/Jul/17 11:05 PM;lovesh;[~andkononykhin] the error shown for log of `test_view_change_in_between_3pc_all_nodes_random_delays` is resolved;;;","20/Jul/17 12:09 AM;andkononykhin;[~lovesh] could you point me to the PR which fixed that?

Thank you;;;","20/Jul/17 6:39 PM;lovesh;[~andkononykhin] Pr for `test_view_change_in_between_3pc_all_nodes_random_delays` https://github.com/hyperledger/indy-plenum/pull/287;;;","21/Jul/17 6:53 PM;andrey.goncharov;Can't reproduce testNodeControlCreatesBackups. 223 runs were successful.;;;","21/Jul/17 10:56 PM;andrey.goncharov;Fixed sovrin_client / testSendGetNymFailsIfDestIsPassedInHexFormat in https://github.com/hyperledger/indy-node/commit/4f631e90f6eee15ed77d4a709bacbc63b6048a88;;;","22/Jul/17 4:01 AM;andkononykhin;*test_view_change_in_between_3pc_all_nodes_random_delays* and *test_view_change_complex.py* have similar failure cases.
 As [~lovesh] mentioned one of them should be fixed in scope of [PR-287|https://github.com/hyperledger/indy-plenum/pull/287].

I 've investigated and prepared fix for another case related to garbage collection logic in node's replicas: *[PR-298|https://github.com/hyperledger/indy-plenum/pull/298].* Waiting for reviews and tests passed on Jenkins;;;","24/Jul/17 9:39 PM;andrey.goncharov;Fixed test_successive_batch_do_no_change_state in sovrin_node in https://github.com/hyperledger/indy-node/pull/256;;;","25/Jul/17 5:32 AM;krw910;Tests are running green.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Introduce message for notifying lagged nodes about previously selected primary ,INDY-401,19149,19019,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mzk-vct,mzk-vct,11/Jul/17 7:33 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"For now ViewChangeDone is used for this purpose, but it is semantically incorrect, so new message should be created for this purpose.

It can be either absolutely new message or a kind of a wrapper (let's call it CurrentState) for ViewChangeDone message and some other information.

Make them be configurable via Quorums class.",,,,,,,,,,,,,,INDY-334,INDY-389,INDY-402,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy7t3:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,mzk-vct,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 12:54 AM;mzk-vct;Implemented new message CurrentState
Pull request https://github.com/hyperledger/indy-plenum/pull/277
;;;","18/Jul/17 12:13 AM;ozheregelya;Problem with coming back nodes count after being below consensus still reproduces.
indy-node version 0.4.37
indy-plenum version 0.4.50;;;","26/Jul/17 1:18 AM;VladimirWork;Build Info:
indy-node 0.4.63

Steps to Validate:
1. Stop and start any nodes.
2. Check logs on each node for ""CURRENT_STATE"" message after node connecting.

Actual Results:
All nodes send current state messages to connected node.
Connected node successfully received current state messages.

Additional Info:
Nodes catchup and reach consensus normally at f+1.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update consensus quorums for catchup,INDY-402,19150,19019,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mzk-vct,mzk-vct,11/Jul/17 7:37 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,Update consensus quorums for catchup. Make it be configurable via Quorums class if it is not.,,,,,,,,,,,INDY-401,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy7tb:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,dsurnin,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 2:47 PM;dsurnin;made catchup consensus f+1

plenum 1a8739715a6e4f4204207e7aa919d7e036e8bda7

test

plenum/test/node_catchup/test_catchup_f_plus_one.py;;;","25/Jul/17 10:12 PM;VladimirWork;Build Info:
indy-node 0.4.63

Steps to Validate:
1. Disconnect node 1.
2. Send NYM transactions.
3. Disconnect nodes 2 and 3.
4. Connect node 1 (now there are two nodes connected).
5. Connect node 2 (now there are three nodes connected).

Actual Results:
There is no catchup in Step 4.
There is successfull catchup in Step 5.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support the config settings related to log rotation,INDY-403,19151,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,spivachuk,spivachuk,11/Jul/17 8:01 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Support the config settings related to log rotation. These settings are as follows:
* logRotationWhen
* logRotationInterval
* logRotationBackupCount
* logRotationMaxBytes",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy7tj:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jul/17 10:58 PM;spivachuk;stp and plenum/sovrin parameters were combined together (see the commit https://docs.google.com/document/d/1NSq0ecO_zg02Pq4E1ej4_8wg0aQqn54I61M6EMVx3oQ for details). The parameters `logRotationWhen`, `logRotationInterval`, `logRotationBackupCount`, `logRotationMaxBytes` from the combined set are properly used.

Closed this ticket as invalid.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RAETLogFilePathCli config setting is used as node RAET log file name instead of RAETLogFilePath,INDY-404,19152,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,spivachuk,spivachuk,11/Jul/17 8:11 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,5Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy0tj:",,,,,,,,,,,,,,,,,,,,,,,,,,sergey-shilov,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/18 6:34 PM;sergey-shilov;All Raet related stuff is deprecated and removed, this ticket is not relevant any more and can be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor message classes and their handlers,INDY-405,19154,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,mzk-vct,mzk-vct,11/Jul/17 10:04 PM,09/Oct/19 6:45 PM,28/Oct/23 2:46 AM,09/Oct/19 6:45 PM,,,,,0,5Months,,,,,"In the scope of message validation task messages were reimplemented as classes, but in a way to keep them compatible with a code that is written for named tuples. 
That's why they mimic for being named tuples.

This works, but it is ugly and can cause problems like https://jira.hyperledger.org/browse/INDY-391",,,,,,,,,,,,,,,,,,,,,,,INDY-391,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzy0tr:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:45 PM;ashcherbakov;Let's continue as part of incremental refactoring policy in the scope of all the tasks we do.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[BLOCKER] Send NYM command does not work on node version 0.4.19,INDY-406,19164,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,,ozheregelya,ozheregelya,12/Jul/17 12:37 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,1,,,,,,"*Case 1:*
 *Steps to Reproduce*:
 1. Open the CLI of version 0.4.24 (version with changes in CID/DID).
 2. Set yourself as Trustee
{code:java}
sovrin@live> new key with seed 000000000000000000000000Trustee1
 Key created in keyring Default
 Identifier for key is V4SGRU86Z58d6TV7PBUe6f
 Verification key is ~CoRER63DVYnWZtK8uAzNbx
 Current identifier set to V4SGRU86Z58d6TV7PBUe6f{code}
3. Try to send NYM.

*Actual Results:*
 Nothing happened, no error messages appear.

*Expected Results:*
 Send NYM command should work.

*Case 2:*
 *Steps to Reproduce:*
 1. Open the CLI of version 0.4.20 (version without changes in CID/DID).
 2. Set yourself as Trustee
{code:java}
sovrin@live> new key with seed 000000000000000000000000Trustee1
 Key created in keyring Default
 Identifier for key is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
 Current identifier set to GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL{code}
3. Try to send NYM.

*Actual Results:*
 Nothing happened, no error messages appear.

*Expected Results:*
 Send NYM command should work.","Build Info:
  sovrin-client version: 0.4.24 (case 1)
  sovrin-client version: 0.4.20 (case 2)
  sovrin-node version: 0.4.19
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client",,,,,,,,,,,,,INDY-35,IS-199,,INDY-411,INDY-412,INDY-413,,,,,,,,,,,,,,,,"12/Jul/17 12:54 AM;ozheregelya;Node1.7z;https://jira.hyperledger.org/secure/attachment/11640/Node1.7z","12/Jul/17 12:54 AM;ozheregelya;Node2.7z;https://jira.hyperledger.org/secure/attachment/11641/Node2.7z","12/Jul/17 12:53 AM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11638/Node3.log","12/Jul/17 12:53 AM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11639/Node4.log","12/Jul/17 12:53 AM;ozheregelya;cli.log;https://jira.hyperledger.org/secure/attachment/11637/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy22n:",,,,,,H4,,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,krw910,ozheregelya,sergey.minaev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/17 5:07 AM;danielhardman;this is a test comment;;;","13/Jul/17 10:11 PM;ashcherbakov;Problem reason:
- primary selection didn't start because catch-up didn't complete.
- the cause is recently added MsgReq and MsgRep requests
- They introduced 'composite' messages (when another message (unserialized) is a part of the message as-is)
- It turned out that ujson serializes composite messages differently depending on the version: ujson=1.33 serializes to dict, and ujson=1.35 serializes to list.
- Our code didn't fix ujson version, so 1.35 were used for developers and in Jenkins (the latest version in pypi).
- The code assumes serialization according to 1.35, that's why all the tests passed.
- However, we used canonical deb package for ujson, which is 1.33. So, the issue was reproduced with deb packages only.
 


Changes: 
- Fixed ujson==1.33
- Fixed code to expect dict-based serialization
- Fixed build to use canonical ujson, not 1.33 one.

Committed into:
- https://github.com/hyperledger/indy-plenum/pull/272
- sovrin-node 0.4.23

Risk factors:
- build
- catch-up
- NYM

Risk:
- Medium

Covered with tests:
- plenum/test/input_validation/test_message_serialization.py

;;;","14/Jul/17 3:32 AM;krw910;This is now working and we have a functional build.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Enhancement][POOL_UPGRADE] Validation on the client should be added for upgrate that won't be scheduled,INDY-407,19165,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,aleksey-roldugin,aleksey-roldugin,12/Jul/17 12:42 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,,,,,"h6. BUILD

sovrin-node 1.8.2 (but problem also occurs in usual master builds)
 sovrin-client 0.4.20
h6. STEPS TO REPRODUCE
 # Send POOL_UPGRADE command specifying time xx.yy, xx.yy+5, xx.yy+10, ... in _schedule_ section. => Message about successful upgrade in CLI.
 # Send POOL_UPGRADE command specifying time xx-1.yy, xx-1.yy+5, ... in _schedule_ section (but it still should be valid time, so xx-1.yy > current time).

h6. ACTUAL RESULT
 * Message about successful upgrade in CLI but in fact this upgrade will be ignored.
 * When xx-1.yy time comes upgrade won't be applied.
 * _upgrade_log_ doesn't contain any information about this upgrade.
 * I couldn't found information about upgrade in _Node<number>.log_ and _journalctl.log_

h6. EXPECTED RESULT
Appropriate error message in CLI which helps to understand that upgrade will be ignored.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy0u7:",,,,,,,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,Toktar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/17 12:42 AM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","10/Oct/18 9:05 PM;Toktar;Testing in follow tests:
 * [testRescheduleUpgradeToLowerVersionThanPreviouslyScheduled|https://github.com/hyperledger/indy-node/blob/5d4088f70f69113e6f1ae31373e3d201b8273fe9/indy_node/test/upgrade/test_reschedule_upgrade_lower_version.py#L12]
 * [test_node_reschedules_upgrade_for_proper_datetime|https://github.com/hyperledger/indy-node/blob/5d4088f70f69113e6f1ae31373e3d201b8273fe9/indy_node/test/upgrade/test_node_reschedules_upgrade_for_proper_datetime.py#L15]

CLI is deprecated now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"[Migration tool] ""Proof .sovrin restores from a backup"" test is failed",INDY-408,19166,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,aleksey-roldugin,aleksey-roldugin,12/Jul/17 1:25 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"h6. BUILD

sovrin-node 1.8.2 (repo migrations-test)
 sovrin-client 0.4.20
h6. STEPS TO REPRODUCE
 # Set up pool with 4 nodes and 1 client using with _sovrin-node_ version 1.8.2.
 # Send POOL_UPGRADE command to version 1.8.7
{code:java}
sovrin@test> send POOL_UPGRADE name=update_to_node_187 version=1.8.7 sha256=6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b action=start schedule={'
Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv':'2017-07-11T15:35:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb':'2017-07-11T15:40:00.258870+00:00', 
'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-07-11T15:45:00.258870+00:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-07-11T15:50:00.258870+00:00'} 
timeout=10
Sending pool upgrade update_to_node_187 for version 1.8.7
Pool upgrade successful
{code}

 # Compare _.sovrin_ and _.sovrin_test_ directories
{code:java}
root@d0852504926d:/home/sovrin# diff -r .sovrin_test .sovrin | grep .sovrin_test | awk
root@d0852504926d:/home/sovrin#
{code}

h6. ACTUAL RESULT

Directories are completely the same.
h6. EXPECTED RESULT

Only _.sovrin_test_ directory contains _migration_proof_ file.",,,10800,10800,,0%,10800,10800,,,,,,INDY-200,,,,,,,,,,,,,,,,,,,,,"12/Jul/17 1:25 AM;aleksey-roldugin;journalctl.log;https://jira.hyperledger.org/secure/attachment/11642/journalctl.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1vz:",,,,,,H5,,,,,,,,,,,,,,,,,,,,aleksey-roldugin,andrey.goncharov,danielhardman,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/17 1:26 AM;aleksey-roldugin;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","12/Jul/17 1:39 AM;andrey.goncharov;Short overview:

If an exception is thrown in one of applied migrations .sovrin is not recovered from a backup ZIP file, though it should.;;;","13/Jul/17 6:30 AM;krw910;[~andrey.goncharov] could we get into an infinite loop where restoring the .sovrin folder makes us believe we need to try the upgrade again? ;;;","13/Jul/17 6:39 PM;andrey.goncharov;[~krw910] it could indeed.;;;","16/Jul/17 6:41 AM;danielhardman;If we could get into an infinite loop, then perhaps it's best to never do anything automated with a backup of .sovrin; instead, if the migration script fails, we need to write a message to the screen and to syslog announcing the failure of the migration, and reporting that the backup of .sovrin is available for manual recovery if needed. (We'd need to specify the path to it.)

It feels like we could timebox this to an hour or so and be done.;;;","17/Jul/17 4:37 PM;andrey.goncharov;[~danielhardman] we could restore everything except upgrade log. This way we will avoid going into infinite loop. Leaving instructions for manual recovery opens us up to a human error.A steward could replace upgrade log and there will be the same loop.

I proceed with this option unless you tell me otherwise.;;;","19/Jul/17 4:30 AM;danielhardman;Okay, proceed.;;;","19/Jul/17 11:30 PM;andrey.goncharov;Problem reason: 
- incorrect dependency resolving

Changes: 
- dependency resolving fixed

Committed into:
https://github.com/hyperledger/indy-node/commit/994a3301df7e87ae503cc88405fc4c9a1a3d89cd
indy-node 0.4.49

Risk factors:
Upgrade functionality could be affected.

Risk:
 Low

Covered with tests:
https://github.com/hyperledger/indy-node/blob/master/sovrin_node/test/upgrade/test_node_control_tool.py#L35

Recommendations for QA (optional):
How to test:
 # Set up a pool from indy-node=1.9.18 (sovrin repo: migrations-test, evernym repo: master)
 # Submit a pool upgrade
 # The migration should raise an exception with text '1.5.6test'.
 # The upgrade should fail and it should rollback.
 # Check journalctl logs to find out if the exception was thrown and rollback happened.
 # Check: - there's '.sovrin_test' directory in /home/sovrin
 # Check there's 'migration_proof' file in the directory with content '1.5.6'
 # Check there's no 'migration_proof' file in your /home/sovrin/.sovrin
 # Check there's no 'sovrin_backup_1.8.2.zip' file in you /home/sovrin folder ;;;","20/Jul/17 11:28 PM;VladimirWork;The case above is passed.
Issue with upgrade loop that appears due to this case execution will be fixed in INDY-316.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Blocking Issue: Unable to add NYMs pool does not appear to be electing a primary node,INDY-409,19201,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,ashcherbakov,krw910,krw910,12/Jul/17 7:16 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Install the latest build 0.4.19

*Components list as:*
python3-rlp  0.5.1
python3-sha3  0.2.1
python3-plenum  0.4.35
python3-anoncreds  0.4.7
sovrin-node  0.4.19

Once a 4 node pool is setup try to add a NYM doing the following:
*Start CLI*
sovrin

sovrin>new key with seed 000000000000000000000000Steward1
sovrin>send NYM dest=FeYAYEx2aat2T5pVeix1Fz

*{color:#d04437}Result{color}*
The CLI shows ""Adding nym FeYAYEx2aat2T5pVeix1Fz"", but you do not get the confirmation of ""NYM Added"" and nothing gets put on the ledger.

It appears that a primary node was never elected so the nodes are not working together.
I have attached the log files for the 4 nodes.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/17 7:16 AM;krw910;Node1.log;https://jira.hyperledger.org/secure/attachment/11646/Node1.log","12/Jul/17 7:16 AM;krw910;Node2.log;https://jira.hyperledger.org/secure/attachment/11645/Node2.log","12/Jul/17 7:16 AM;krw910;Node3.log;https://jira.hyperledger.org/secure/attachment/11648/Node3.log","12/Jul/17 7:16 AM;krw910;Node4.log;https://jira.hyperledger.org/secure/attachment/11647/Node4.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy82v:",,,,,,H4,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/17 7:38 AM;krw910;Duplicate of INDY-406;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stewards should be able to demote and promote their own node,INDY-410,19218,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,krw910,krw910,13/Jul/17 4:16 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"A Steward needs to have the ability to demote and promote their own node. The use case is if a Steward knows they will be down for maintenance and they want to remove their node from the pool so it does not count as a failed node during down time.

The current process of removing a node from the pool is to send the following command
{code}
send NODE dest=<NODE ID> data={'alias': '<node name>', 'services': []}
{code}

Currently only a Trustee has the permissions to perform this action. 
To add promote the node back into the pool the Steward would need to be able to send the following command
{code}
send NODE dest=<NODE ID> data={'alias': '<node name>', 'services': ['VALIDATOR']}
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-46,,,,,,,,,,"1|hzye7j:",,,,,,10,11,,,,,,,,,,,,,,,,,,,ashcherbakov,DouglasWightman,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jul/17 12:50 AM;DouglasWightman;I've been thinking about this ticket in relation to a conversation that was had about recovering from > f failures.  Reducing the size of the pool is the same as an attack and is thus a potential exploit.  It was discussed that allowing a node to remove itself just introduces a new vulnerability.  Is allowing this and widening the attack vector a good idea?

If this has already been discussed and my understanding is limited then that's fine.  I just want to make sure.

(mentioning [~danielhardman] in case he has additional insights as he was present during that conversation);;;","29/Jul/17 4:24 AM;DouglasWightman;I'm assuming that silence means to go forward with the ticket.  I've submitted a patch.;;;","01/Aug/17 12:35 PM;krw910;SOV-983;;;","03/Aug/17 11:59 PM;ashcherbakov;indy-node 1.0.77;;;","10/Aug/17 12:17 AM;ozheregelya;*Build Info:*
   indy-node 1.0.83
   indy-anoncreds 1.0.25
   indy-plenum 1.0.82
   sovrin 1.0.19
   python3-rlp 0.5.1
   python3-sha3 0.2.1
   python3-pyzmq 16.0.2
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 6 nodes, 1 client

*Reason for Reopen:*
 Steward is not able to add his node back after demotion.

*Steps to Reproduce:*
 Case 1:
 1. Set yourself as Steward.
 2. Add node to the pool.
 3. Demote it.
 4. Try to promote it back.

*Actual Results:*
{code:java}
sovrin@test> send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'alias': 'Node5', 'services': ['VALIDATOR']}
Sending node request for node DID 4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc by XhYtvJqezMUKfF6KVNaGmT (request id: 1502288922028848)
Node request failed with error: client request invalid: UnauthorizedClientRequest(""2 not in allowed roles {'0': []}"",){code}
*Expected Results:*
 Steward should be able to promote his node back.

*Additional Information:*
Small regression testing was performed: adding/demotion/promotion of nodes work correctly for all roles except Case 1.;;;","10/Aug/17 12:31 AM;ozheregelya;[~krw910], as far as I can see, changes in scenario 8 are needed after this fix. Should I create ticket for these changes, or update scenario 8 myself?;;;","11/Aug/17 7:08 AM;DouglasWightman;I've checked in new changes and tests to verify that promotion can happen after demotion.;;;","17/Aug/17 9:27 PM;ozheregelya;*Build Info:*
  indy-node 1.0.110
  indy-anoncreds 1.0.25
  indy-plenum 1.0.97
  sovrin 1.0.23
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4-6 nodes, 1 client

*Steps to Validate:*
1. Setup the pool.
2. Promote/demote node as Steward who owns this node.
3. Make sure that promotion/demotion of node as Steward who doesn't own this node is impossible.
4. Promote/demote node as Trustee.

*Actual Results:*
Promotion/demotion of nodes is possible for Trustee and for Steward who owns this node.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - [BLOCKER] Send NYM command does not work on node version 0.4.19,INDY-411,19219,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,ashcherbakov,ozheregelya,danielhardman,13/Jul/17 5:06 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*Case 1:*
 *Steps to Reproduce*:
 1. Open the CLI of version 0.4.24 (version with changes in CID/DID).
 2. Set yourself as Trustee
{code:java}
sovrin@live> new key with seed 000000000000000000000000Trustee1
 Key created in keyring Default
 Identifier for key is V4SGRU86Z58d6TV7PBUe6f
 Verification key is ~CoRER63DVYnWZtK8uAzNbx
 Current identifier set to V4SGRU86Z58d6TV7PBUe6f{code}
3. Try to send NYM.

*Actual Results:*
 Nothing happened, no error messages appear.

*Expected Results:*
 Send NYM command should work.

*Case 2:*
 *Steps to Reproduce:*
 1. Open the CLI of version 0.4.20 (version without changes in CID/DID).
 2. Set yourself as Trustee
{code:java}
sovrin@live> new key with seed 000000000000000000000000Trustee1
 Key created in keyring Default
 Identifier for key is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
 Current identifier set to GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL{code}
3. Try to send NYM.

*Actual Results:*
 Nothing happened, no error messages appear.

*Expected Results:*
 Send NYM command should work.","Build Info:
  sovrin-client version: 0.4.24 (case 1)
  sovrin-client version: 0.4.20 (case 2)
  sovrin-node version: 0.4.19
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,INDY-406,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy86f:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - [BLOCKER] Send NYM command does not work on node version 0.4.19,INDY-412,19221,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,ashcherbakov,ozheregelya,danielhardman,13/Jul/17 5:07 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*Case 1:*
 *Steps to Reproduce*:
 1. Open the CLI of version 0.4.24 (version with changes in CID/DID).
 2. Set yourself as Trustee
{code:java}
sovrin@live> new key with seed 000000000000000000000000Trustee1
 Key created in keyring Default
 Identifier for key is V4SGRU86Z58d6TV7PBUe6f
 Verification key is ~CoRER63DVYnWZtK8uAzNbx
 Current identifier set to V4SGRU86Z58d6TV7PBUe6f{code}
3. Try to send NYM.

*Actual Results:*
 Nothing happened, no error messages appear.

*Expected Results:*
 Send NYM command should work.

*Case 2:*
 *Steps to Reproduce:*
 1. Open the CLI of version 0.4.20 (version without changes in CID/DID).
 2. Set yourself as Trustee
{code:java}
sovrin@live> new key with seed 000000000000000000000000Trustee1
 Key created in keyring Default
 Identifier for key is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
 Current identifier set to GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL{code}
3. Try to send NYM.

*Actual Results:*
 Nothing happened, no error messages appear.

*Expected Results:*
 Send NYM command should work.","Build Info:
  sovrin-client version: 0.4.24 (case 1)
  sovrin-client version: 0.4.20 (case 2)
  sovrin-node version: 0.4.19
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,INDY-406,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy86v:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - [BLOCKER] Send NYM command does not work on node version 0.4.19,INDY-413,19222,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,ashcherbakov,ozheregelya,danielhardman,13/Jul/17 5:08 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*Case 1:*
 *Steps to Reproduce*:
 1. Open the CLI of version 0.4.24 (version with changes in CID/DID).
 2. Set yourself as Trustee
{code:java}
sovrin@live> new key with seed 000000000000000000000000Trustee1
 Key created in keyring Default
 Identifier for key is V4SGRU86Z58d6TV7PBUe6f
 Verification key is ~CoRER63DVYnWZtK8uAzNbx
 Current identifier set to V4SGRU86Z58d6TV7PBUe6f{code}
3. Try to send NYM.

*Actual Results:*
 Nothing happened, no error messages appear.

*Expected Results:*
 Send NYM command should work.

*Case 2:*
 *Steps to Reproduce:*
 1. Open the CLI of version 0.4.20 (version without changes in CID/DID).
 2. Set yourself as Trustee
{code:java}
sovrin@live> new key with seed 000000000000000000000000Trustee1
 Key created in keyring Default
 Identifier for key is GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL
 Current identifier set to GJ1SzoWzavQYfNL9XkaJdrQejfztN4XqdsiV4ct3LXKL{code}
3. Try to send NYM.

*Actual Results:*
 Nothing happened, no error messages appear.

*Expected Results:*
 Send NYM command should work.","Build Info:
  sovrin-client version: 0.4.24 (case 1)
  sovrin-client version: 0.4.20 (case 2)
  sovrin-node version: 0.4.19
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client",,,,,,,,,,,,,INDY-35,IS-199,,,,,INDY-406,,,,,,,,,,,,,,,"13/Jul/17 5:08 AM;danielhardman;Node1.7z;https://jira.hyperledger.org/secure/attachment/11650/Node1.7z","13/Jul/17 5:08 AM;danielhardman;Node2.7z;https://jira.hyperledger.org/secure/attachment/11651/Node2.7z","13/Jul/17 5:08 AM;danielhardman;Node3.log;https://jira.hyperledger.org/secure/attachment/11652/Node3.log","13/Jul/17 5:08 AM;danielhardman;Node4.log;https://jira.hyperledger.org/secure/attachment/11653/Node4.log","13/Jul/17 5:08 AM;danielhardman;cli.log;https://jira.hyperledger.org/secure/attachment/11654/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy873:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Event oriented architecture using asyncio,INDY-414,19231,,Story,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,stevetolman,andkononykhin,andkononykhin,13/Jul/17 10:50 PM,13/Feb/19 10:02 PM,28/Oct/23 2:46 AM,,,2.0,,,0,5Months,,,,,"During work on INDY-358 it was found that actually we use asyncio without any event oriented patterns and it leads to some valuable problems and unnecessary  CPU usage.

 

I have created the doc that describes that in more details and proposes a set of changes to fix that:

https://docs.google.com/document/d/1m0pLAMKWRVdAxZN4ardDKGh_xV0J-0SBP-LCDOeN0M8/edit#heading=h.qapj7lclfhub",,,,,,,,,,,,,,INDY-358,,,,,,,,,,,,,INDY-1442,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1380,,,,,,,,,,"1|hzwx4f:2rzi",,,,,,,,,,,,,,8.0,,,,,,,,,,,,andkononykhin,davidlehn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/17 10:59 PM;andkononykhin;[~danielhardman] [~jlaw 1] [~stevetolman] [~lovesh] [~ashcherbakov]

I created that task after reviewing the code in stp/plenum  in scope of INDY-358.

I think I found quite serious problem in current architecture related to non proper usage of asyncio.

I would be happy if you check and leave your comments in the doc that I published:

[https://docs.google.com/document/d/1m0pLAMKWRVdAxZN4ardDKGh_xV0J-0SBP-LCDOeN0M8/edit#heading=h.qapj7lclfhub]

Thank you;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Pool fails to send NYMs after upgrade command,INDY-415,19233,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,14/Jul/17 12:11 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Build Info:
sovrin-node 0.4.20

Overview:
Pool fails to send NYMs after POOL_UPGRADE command.

Steps to Reproduce:
1. Login as Trustee.
2. Send NYM to prove that it works.
3. Send POOL_UPGRADE command with force=True and 3 nodes in schedule (it should work due to changes in INDY-201), e.g.:
send POOL_UPGRADE name=upgrade2 version=0.4.20 sha256=e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 action=start schedule={'8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-07-13T13:35:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-07-13T13:20:00.258870+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-07-13T13:25:00.258870+00:00'} timeout=10 force=True
4. Send NYM.

Actual Results:
Step 4 NYM sending is failed (there is no result message).

Expected Results:
Send NYM should work normally.

Workaround:
Restart all nodes of the pool.

Aditional Info:
According to INDY-201 comments no validation for uniqueness of upgrade name is ok, but actually this validation is present (see screenshot).

Logs of all nodes are in attachment.",,,,,,,,,,,,,,,,,,,,,,,INDY-201,,,,,,,,,,,,"14/Jul/17 12:07 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11659/Screenshot.PNG","14/Jul/17 12:07 AM;VladimirWork;log1;https://jira.hyperledger.org/secure/attachment/11658/log1","14/Jul/17 12:07 AM;VladimirWork;log2;https://jira.hyperledger.org/secure/attachment/11657/log2","14/Jul/17 12:07 AM;VladimirWork;log3;https://jira.hyperledger.org/secure/attachment/11656/log3","14/Jul/17 12:07 AM;VladimirWork;log4;https://jira.hyperledger.org/secure/attachment/11655/log4",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1w7:",,,,,,H5,,,,,,,,,,,,,,,,,,,,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 12:11 AM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","14/Jul/17 6:46 PM;VladimirWork;Cannot reproduce on sovrin 0.2.9. Now there is an issue with performing pool upgrade command, it will be reported in another bug.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Display Trustee key usage on the Sovrin Status page,INDY-416,19236,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,nage,lsc,lsc,14/Jul/17 1:37 AM,13/Nov/19 12:44 AM,28/Oct/23 2:46 AM,13/Nov/19 12:44 AM,,,,,0,,,,,,"Develop a method to capture and display on the ""Sovrin Status Page"" each and every time a trustee key is being exercised on the Sovrin ledger. This should be mainly aimed to achieve a proactive manner to detect potential trustee key compromise

 

Design

https://docs.google.com/document/d/1u5TKZg6DcyLQS6fcNpHMqIQ2byIg7OhrXOwr8NFRt44",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx11b:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,danielhardman,esplinr,lsc,nage,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 4:58 PM;ashcherbakov;[~nage] [~danielhardman]
What is `Sovrin Status Page`?;;;","11/Aug/17 10:26 PM;nage;My reading of this ticket is that there could be some sort of ledger status webpage where certain statistics are displayed that would allow people monitoring the network to draw conclusions about the health and status of the system relative to the trust framework.

In this case it is a proposal for a monitoring tool for detecting key compromise.  We should address this as a statistics logging/gathering mechanism first, and log new issues for some type of status page.;;;","14/Aug/17 6:06 PM;andrey.goncharov;[~danielhardman]

I created a short design [doc|https://docs.google.com/document/d/1u5TKZg6DcyLQS6fcNpHMqIQ2byIg7OhrXOwr8NFRt44]. Please review. After the approval I can start implementation

[~nage] if you can do the review instead of Daniel please do so.;;;","15/Aug/17 10:52 PM;andrey.goncharov;I updated the design doc with ledger SSH access requirement;;;","16/Aug/17 5:02 PM;danielhardman;I think this design is fine. I vote for you to proceed. However, I think [~nage] has veto power over my recommendation...;;;","28/Sep/17 5:36 PM;ashcherbakov;This looks like a big task, and I don't think we will be able to do it in Sprint 14;;;","13/Nov/19 12:44 AM;esplinr;Monitoring of the Sovrin network will be done by users of Sovrin. It would be great to have a Sovrin Status Page that reports when trustee keys are used, but it is not a priority for those working on Indy.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Faber and Acme demo agents are unable startup because they cannot authenticate ,INDY-417,19241,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,krw910,krw910,krw910,14/Jul/17 4:15 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*{color:#14892c}Scroll to the bottom for what I believe the fix is. I tried the fix out manually and it did not seem to work, but I know that section of code will be an issue with DIDs{color}*

 

When starting the Faber and Acme agents they are not able to authenticate and therefore cannot finish the startup process.
 I believe this is because we changed from Cryptonyms to DIDs and it does not have the verkey in the wallet where the agent is running from.

*Setup*
 4 nodes
 4 clients (3 client will act separately as the Faber, Acme, and Thrift agents)

*Steps*
 *Start the CLI*
 sovrin

*Register the Faber agent*
{code:java}
send NYM dest=ULtgFQJe6bjiFbs7ke3NJD role=TRUST_ANCHOR

send ATTRIB dest=ULtgFQJe6bjiFbs7ke3NJD raw={""endpoint"": {""ha"": ""10.0.0.202:5555"", ""pubkey"": ""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z""}}
{code}
*Register the Acme agent*
{code:java}
send NYM dest=CzkavE58zgX7rUMrzSinLr role=TRUST_ANCHOR

send ATTRIB dest=CzkavE58zgX7rUMrzSinLr raw={""endpoint"": {""ha"": ""10.0.0.203:6666"", ""pubkey"": ""C5eqjU7NMVMGGfGfx2ubvX5H9X346bQt5qeziVAo3naQ""}}
{code}
*Register the ThriftBank agent*
{code:java}
send NYM dest=H2aKRiDeq8aLZSydQMDbtf role=TRUST_ANCHOR

send ATTRIB dest=H2aKRiDeq8aLZSydQMDbtf raw={""endpoint"": {""ha"": ""10.0.0.204:7777"", ""pubkey"": ""AGBjYvyM3SFnoiDGAEzkSLHvqyzVkXeMZfKDvdpEsC2x""}}
{code}
*On Client 2 run*
{code:java}
python3 /usr/local/lib/python3.5/dist-packages/sovrin_client/test/agent/faber.py  --port 5555
{code}
*On Client 3 run*
{code:java}
python3 /usr/local/lib/python3.5/dist-packages/sovrin_client/test/agent/acme.py  --port 6666
{code}
*On Client 4 run*
{code:java}
python3 /usr/local/lib/python3.5/dist-packages/sovrin_client/test/agent/thrift.py  --port 7777
{code}
*{color:#d04437}Error{color}*
 After starting the agents and doing nothing else you will see the Faber and Acme agent exit with an error about not being able to authenticate.

See Attachment


*{color:#14892c}Fix{color}*
The issue is when we used cryptonyms the verkey was the same as the cryptonym. In the agent code you will see the verkey just equals the cryptonym for the seed that was passed.
I will provide you with the correct verkey and you should just have to replace it in the code.

You will find the agent code here
https://github.com/hyperledger/indy-node/tree/master/sovrin_client/test/agent

*{color:#205081}faber.py{color}*
{code}
FABER_SEED = b'Faber000000000000000000000000000'
FABER_SIGNER = DidSigner(seed=FABER_SEED)
FABER_ID = FABER_SIGNER.identifier
FABER_VERKEY = FABER_SIGNER.verkey
{code}
The DID that is produced from the faber seed is
*Faber Agent*
new key with seed Faber000000000000000000000000000
Identifier for key is ULtgFQJe6bjiFbs7ke3NJD
Verification key is ~5kh3FB4H3NKq7tUDqeqHc1

You should be able to just replace 
FABER_VERKEY = FABER_SIGNER.verkey
with
FABER_VERKEY = '~5kh3FB4H3NKq7tUDqeqHc1'

-------------------------------------------------------------------------------------------------------

*{color:#205081}acme.py{color}*
{code}
ACME_SEED = b'Acme0000000000000000000000000000'
ACME_ID = DidSigner(seed=ACME_SEED).identifier
ACME_VERKEY = DidSigner(seed=ACME_SEED).verkey
ACME_SIGNER = DidSigner(seed=ACME_SEED)
{code}
The DID that is produced from the faber seed is
*Acme Agent*
new key with seed Acme0000000000000000000000000000
Identifier for key is CzkavE58zgX7rUMrzSinLr
Verification key is ~WjXEvZ9xj4Tz9sLtzf7HVP

You should be able to just replace 
ACME_VERKEY = DidSigner(seed=ACME_SEED).verkey
with
ACME_VERKEY = '~WjXEvZ9xj4Tz9sLtzf7HVP'

-------------------------------------------------------------------------------------------------------

*{color:#205081}thrift.py{color}*
{code}
THRIFT_SEED = b'Thrift00000000000000000000000000'
THRIFT_SIGNER = DidSigner(seed=THRIFT_SEED)
THRIFT_ID = THRIFT_SIGNER.identifier
THRIFT_VERKEY = THRIFT_SIGNER.verkey
{code}
The DID that is produced from the faber seed is
*Thrift Agent*
new key with seed Thrift00000000000000000000000000
Identifier for key is H2aKRiDeq8aLZSydQMDbtf
Verification key is ~3sphzTb2itL2mwSeJ1Ji28

You should be able to just replace 
THRIFT_VERKEY = THRIFT_SIGNER.verkey
with
THRIFT_VERKEY = '~3sphzTb2itL2mwSeJ1Ji28'




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 3:57 AM;krw910;Faber Agent Crash.txt;https://jira.hyperledger.org/secure/attachment/11671/Faber+Agent+Crash.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1y7:",,,,,,H4,H5,,,,,,,,,,,,,,,,,,,krw910,mark.hadley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jul/17 1:28 AM;mark.hadley;Kelly and I spoke, the behavior may be in the steps of the user, not in the code.;;;","15/Jul/17 2:40 AM;krw910;I had to update the steps on setting up the agents. Once I got the correct steps the agents started up just fine.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
POOL_UPGRADE Command is Usability Nightmare,INDY-418,19245,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,farooq_m_khan,farooq_m_khan,14/Jul/17 5:04 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,Usability,,,," To be able to issue a pool upgrade a person first needs to create a schedule which requires python skills**

You need to download the contents of this page: [Pool Upgrade Schedule Generator|[https://gist.github.com/lovesh/56b947b051f55619f2885feb09354b47],] then fix some typos in the script becuase is its coded for display so has some unnecessary characters.

Then you need to figure out the ID's for all your Nodes and that takes some effort.

Change the script to code these IDS into it

Run the script take the output and and within a short time fire it on the Sovrin CLI or the schedule becomes stale and does not work.

This is a Usability nightmare. Needs fixing for sure. 

 
 ",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx0tb:",,,,,,,,,,,,,,,,,,,,,,,,,,farooq_m_khan,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Dec/17 11:59 PM;VladimirWork;This steps for pool upgrade aren't up-to-date, we don't need to use any external scripts' output to schedule POOL_UPGRADE command in the CLI.

CLI POOL_UPGRADE command template (run it as Trustee):
{noformat}
send POOL_UPGRADE name=upgrade210 version=1.2.210 sha256=ed0a366b4ef36d40c055672a8b83679e99246fec71a706b4ae4cb7958feace3f action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-11-16T14:15:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-11-16T14:20:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-11-16T14:25:00.258870+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-11-16T14:30:00.258870+00:00'} timeout=10 force=False reinstall=False
{noformat};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hookup Sovrin-Notifier-AWSSNS to Jenkins,INDY-419,19246,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,andkononykhin,farooq_m_khan,farooq_m_khan,14/Jul/17 5:16 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,build-system,CI/CD/Update,,,,"A new repo was recently added for a new type (AWS SNS) of notifier.

This repo needs to be hooked up to Jenkins and the builds need to be auto published to pypi.
 ",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyayv:",,,,,,10,,,,,,,,,,,,,,,,,,,,andkononykhin,farooq_m_khan,mgbailey,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 5:17 AM;farooq_m_khan;[~stevetolman] [~danielhardman] I am adding this task so that we can account for Andrey G's time that will be required on this task (I have marked it for Spring: M1) but this should be actually done sooner. Please update the priority appropriately.;;;","15/Jul/17 6:35 AM;mgbailey;[~stevetolman], delivery wants to use this and perhaps distribute it to stewards.;;;","08/Aug/17 9:50 PM;andkononykhin;Resolved:

Git changes: [https://github.com/evernym/sovrin-notifier-awssns/pull/4]

Pypi: [https://pypi.python.org/pypi/sovrinnotifierawssns]

Git tags are published as well: [https://github.com/evernym/sovrin-notifier-awssns/releases];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Disconnection of the primary node and secondary node can lead to pool failure (service stop or port disconnect),INDY-420,19249,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,14/Jul/17 10:05 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,ViewChange,,,,,"This may seem like an edge case, but I think there is a bigger issue with this ticket.

*Setup*
4 nodes
4 clients

*Steps*
# Once everything is setup go to the .sovrin directory on one of the nodes and search for  “new primary is” to see which node is the primary node.
# Go to the primary node and stop the sovrin-node service ""sudo systemctl stop sovrin-node""
# Now open the logs on one of the remaining nodes and run the search again to see which nodes is now the primary node.
# Start the service again on the machine that you just shut the service down on ""sudo systemctl start sovrin-node""
# Check the logs on the node where you just started the sovrin-node service to see if a new primary was selected.

*{color:#d04437}At this point no primary election or view change occurred{color}*

Send a NYM transaction to make sure the pool is still accepting transactions. 
*{color:#14892c}You will see that the pool is still functioning {color}*

# Check the transactions file on the node where you started the service and you should see the NYM transaction you just sent.
# Now shutdown the sovrin-node service on the current primary node
# Check to see if a new primary was selected

*{color:#d04437}Issue{color}*
At this point not only was a new primary node not selected, but you also could not send any more transactions to the pool. It acted as if only 2 nodes were in the pool instead of 3 and so it could not reach consensus.
We are still testing around the scenario to see if there is a problem when nodes restart their services and cannot participate in the new primary election process.
",,,0,0,,0%,0,0,,,,,,,,,,,,,,,INDY-389,,,,,,,,,,,,"16/Jul/17 12:33 PM;krw910;LogsSet_Debug_ServiceIssue.7z;https://jira.hyperledger.org/secure/attachment/11683/LogsSet_Debug_ServiceIssue.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzxqdj:",,,,,,H5,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,lovesh,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 6:50 PM;ashcherbakov;There is a possible problem with re-starting nodes if we have just 4 nodes. It will be fixed soon in the scope of INDY-389.

We don't 'elect' primary now, we 'select' it in round-robin style.
So, initially the Primary for master (instance 0) is Node1, for instance 1 is Node2, for instance 2 is Node3, etc.
When a new Node comes online, all other nodes propagate the existing Primary to it (so, no new election, the new node will just get know the primary).
Currently a consensus of n-f is required for a newly added node to get the existing Primary. So, if you had 4 nodes, send some txns, then one node is down, and then it is back up, then there is chance that it will not get the consensus and will not get the Primary.
;;;","15/Jul/17 1:34 AM;mzk-vct;Cannot reproduce. Seems that it is fixed by https://jira.hyperledger.org/browse/INDY-389
Builds:
node==0.4.35
plenum==0.4.47;;;","15/Jul/17 6:44 AM;slafranca;I had 7 nodes.  Node 1 was the primary node.  I stopped the service on node 1, node 2 became the primary node.  I ran ""grep ""selected primary"" *.log"" on node 2 and I see: 
{code:java}
Node2.log:2017-07-14 17:20:04,534 | DISPLAY  | primary_selector.py  ( 276) | _startSelection | Node2:0 selected primary Node1:0 for instance 0 (view 0)
Node2.log:2017-07-14 17:20:04,535 | DISPLAY  | primary_selector.py  ( 276) | _startSelection | Node2:1 selected primary Node2:1 for instance 1 (view 0)
Node2.log:2017-07-14 17:20:04,536 | DISPLAY  | primary_selector.py  ( 276) | _startSelection | Node2:2 selected primary Node3:2 for instance 2 (view 0)
Node2.log:2017-07-14 20:28:20,206 | DISPLAY  | primary_selector.py  ( 276) | _startSelection | Node2:0 selected primary Node2:0 for instance 0 (view 1)
Node2.log:2017-07-14 20:28:20,208 | DISPLAY  | primary_selector.py  ( 276) | _startSelection | Node2:1 selected primary Node3:1 for instance 1 (view 1)
Node2.log:2017-07-14 20:28:20,209 | DISPLAY  | primary_selector.py  ( 276) | _startSelection | Node2:2 selected primary Node4:2 for instance 2 (view 1)
{code}
I brought node 1 back online and ran the same grep command (I also searched for 'primary is') on node 1 and there are no new entries.  The output was the same before and after the service was stopped.  I see:
{code:java}
Node1.log:2017-07-14 17:19:39,906 | DISPLAY  | primary_selector.py  ( 276) | _startSelection | Node1:0 selected primary Node1:0 for instance 0 (view 0)
Node1.log:2017-07-14 17:19:39,907 | DISPLAY  | primary_selector.py  ( 276) | _startSelection | Node1:1 selected primary Node2:1 for instance 1 (view 0)
Node1.log:2017-07-14 17:19:39,908 | DISPLAY  | primary_selector.py  ( 276) | _startSelection | Node1:2 selected primary Node3:2 for instance 2 (view 0)
{code}
After node 1 was back online, I shut node 2 down and sent a transaction to the pool.  The transaction did not get processed.  I started the service on node 2.  When node 2 came online, the transaction I sent before I restarted the service on node 2 was processed and node 2 was still the primary.

+Expected results:+
* I expected the other nodes to propagate the the log entries for the existing primary node back to node 1 when it came online, I saw nothing in the logs that would indicate this happened
* After stopping and starting node 1, then stopping node 2.  I expected the pool to process transactions and node 3 would be the primary node.  Instead, the cli shows the following message:
{code:java}
Remote Node2C is not connected - message will not be sent immediately.If this problem does not resolve itself - check your firewall settings
{code}

* While node 2 was down, I expected the transaction I sent to get processed.   I also expected the status message shown above to keep scrolling in the client view until node 2 came back online.

Until node 2 came back online, I could not process transactions.  It appears like the pool will only trigger one view change.  It didn't matter which node I dropped, node 2 remained as the primary node.
;;;","16/Jul/17 12:33 PM;krw910;Debug logs from each of the 10 nodes are attached. I had been deleting logs between test runs and on this last one Node5 has a much larger log file. The time stamps seem to line up so I am not sure why it is so much larger. [^LogsSet_Debug_ServiceIssue.7z] 

We are seeing some strange behvior with view change where the pool can stop working when node become disconnected in some fashion. I have reproduced the pool failing by both stopping the node service and both just shutting off the ports.
My concern here being that we already know of 3 Steward nodes that have been experiencing random disconnects and reconnects.
What I am going to describe below is a consistent way to see the pool stop working, but it probably is not the only way.

I have done this 3 times and every time I get the pool to stop working unless every nodes service is restarted in the pool.

*Version*
indy-plenum=0.4.50
indy-anoncreds= 0.4.15
indy-node= 0.4.36

*Legend*
:0 = Primary Instance
:1 = Secondary Instance
:2 = Next Instance
:3 = Next Instance

The larger the pool the more instances.

It appears that when the pool starts up* it sets the instance order based off the order of nodes in the pool_transactions_sandbox(or live) ledger*. So when the pool starts or if the entire pool is restarted Node1 is always the primary node (Node1:0) and node 2 is always the secondary instance (Node2:1) and so on depending on the size of the pool.

With that background here is what we have seen in testing.

*7 Node Pool*
With a 7 node pool we should be able to tolerate two nodes in a failed state.
We found the following issue
Pool starts with
Node1:0 (view 0)
Node2:1 (view 0)
Node3:2 (view 0)

We stopped the service on Node1 which was the primary node.
A view change happened showing:
Node2:0 (view 1)
Node3:1 (view 1)
Node4:2 (view 1)

You could still send transactions. Since with 7 nodes you should be able to lose 2 nodes we shut down the service on Node2.
A new view change did not occur. We expected to see:
Node3:0 (view 2)
Node4:1 (view 2)
Node5:2 (view 2)

*{color:#d04437}Issues{color}*
With Node1 and Node2 down the pool stopped accepting transactions.
Until Node2 came back on line the pool will not accept any transactions even with 6 of the 7 nodes running once we started Node1 again and left Node2 off.


--------------------------------------------

*10 Node Pool*
With a 10 node pool chasing the primary like in the 7 node scenario seem to work just fine. The view changes kept happening as long as you still had 7 out of the 10 nodes running which is what is expected.
We would shut down Node1, then primary Node2, then primary Node3, then bring back up Node1, then shut down primary Node4, then bring back up Node2, and so on always keeping 7 nodes active.

*10 nodes show 4 instances*
Node1:0 (view 0)
Node2:1 (view 0)
Node3:2 (view 0)
Node4:3 (view 0)

*{color:#d04437}Failures{color}*
If you restart the entire pool for some reason you will not be able to perform any transactions until the primary node comes online.
After I had been running a few transactions I stopped the entire pool.
I started with Node10 and brought the nodes online one node at a time in reverse order. Once I had 7 out of 10 nodes running (Node10 - Node4) I expected to be able to start sending transactions. I was unable to send any transactions. I then started Node3 and sent transactions with nothing going through so I had 8 out of 10 nodes running. I then started Node2 and sent transactions with nothing going through so I now had 9 out of 10 nodes. It was not until I started Node1 that transactions went through and once Node1 started you could see in the CLI all the transactions I had sent all the sudden went through like they were waiting in a queue.

If you stop the secondary node then the primary node the pool will sometimes stop accepting transactions and other times if you wait about 30 seconds a view change would happen and transactions would go through.
*{color:#d04437}
Here is how I got the entire pool to go down{color}*
Started with the following in a 10 node setup
Node1:0 (view 0)
Node2:1 (view 0)
Node3:2 (view 0)
Node4:3 (view 0)

Remember the nodes change in a round robin fasion.
In the following steps you can *+{color:#d04437}either stop the sovrin-node service or block the node ports 9701-9799{color}+*
*Either way as long as there is a disconnect*

*Step 1* - Node2:1 (view 0) -- Stop this node and transactions still go through
*Step 2* - Node1:0 (view 0) -- Stop this node and transactions still go through as well as a view change

View Change
Node3:0 (view 1)
Node4:1 (view 1)
Node5:2 (view 1)
Node6:3 (view 1)

*Step 3* - Node3:0 (view 1) -- Stop this node and transactions still go through as well as a view change

View Change
Node4:0 (view 2)
Node5:1 (view 2)
Node6:2 (view 2)
Node7:3 (view 2)

*Step 4* - Node1 -- Start and searched for ""primary is"", but it still showed that Node1:0 was the primary from (view 0)
*Step 5* - Node2 -- Start and searched for ""primary is"", but it still showed that Node1:0 was the primary from (view 0)
*Step 6* - Node5:1 (view 2) -- Stop this node and the entire pool stopped working.

After step 6 *{color:#d04437}the only recover was to restart the entire pool{color}* which set the view back to the following and *{color:#d04437}transactions would not occur until Node1 was up and running{color}*
Node1:0 (view 0)
Node2:1 (view 0)
Node3:2 (view 0)
Node4:3 (view 0)

;;;","17/Jul/17 5:55 PM;lovesh;Same cause as INDY-430;;;","17/Jul/17 7:55 PM;lovesh;PR, https://github.com/hyperledger/indy-plenum/pull/283;;;","19/Jul/17 6:37 AM;krw910;Blocked by INDY438. I am unable to throw a sufficant load at the pool until this ticket has been addressed. Lovesh is looking at the pool.;;;","25/Jul/17 6:08 AM;slafranca;I tested this with node version 0.4.61.  The nodes processed the transaction while node 1 went down.  When node 1 came back online, the logs were updated and the transaction was processed on node 1.  Each time I stopped the service on the primary node, a different node was promoted.  The logs appear to contain the data about the new primary and backup nodes.  The transaction logs show the NYM transaction was processed as well.  As far as I can tell, the expectation listed in my comments above are met and the bug has been fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to run load tests. The load_test.py script uses cryptonyms instead of DIDs,INDY-421,19251,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,14/Jul/17 11:28 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"i am unable to run the load tests using the add_keys.py and load_test.py scripts.
The add_keys.py script shows in the output that is is using cryptonyms and we have switched to DIDs

*See attachment*

In order to perform operations the NYM that is added must have an associated verkey.

In addition to run the ""send ATTRIB"" command you have to add a NYM without a verkey to also send ATTRIBs for that NYM. If you add a NYM with a verkey then only the owner of that NYM can add an ATTRIB to it. So the option for send ATTRIB in the load_test.py script needs to account for that.
",,,,,,,,,,,,,,INDY-292,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 11:24 AM;krw910;addkeys_Output.log;https://jira.hyperledger.org/secure/attachment/11673/addkeys_Output.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1wf:",,,,,,H5,,,,,,,,,,,,,,,,,,,,krw910,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 10:16 PM;mzk-vct;PR https://github.com/hyperledger/indy-node/pull/232;;;","14/Jul/17 10:32 PM;mzk-vct;*Problem reason:*
SimpleSigner instead of DidSigner was used in both scripts

*Changes:*
SimpleSigner replaced by DidSigner

*Committed into:*
 https://github.com/hyperledger/indy-node/pull/232

*Risk factors:*
Nothing is expected.

*Risk:*
Low;;;","17/Jul/17 5:05 AM;krw910;The load_test.py and add_keys.py scripts are both working.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update maintainer field for DEB packages,INDY-422,19255,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,andrey.goncharov,andrey.goncharov,14/Jul/17 5:53 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Currently indy-plenum and all its dependencies are maintained by Evernym organization. Sovrin and indy-node are maintained by Sovrin Foundation.

Anything indy-related should be maintained by Hyperledger, and anything sovrin-related should be maintained by Sovrin.

Discuss with Daniel if we need to packages that we build from pypi should be maintained by Sovrin as well (currently they are maintained by Evernym)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyaz3:",,,,,,10,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,andrey.goncharov,danielhardman,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 5:55 PM;andrey.goncharov;[~danielhardman] who should be referenced as a maintainer of DEB packages that we build from pypi (like ioflo, base58 ant etc). Currently it's Evernym. Should we change that to Sovrin?;;;","19/Jul/17 4:31 AM;danielhardman;I think we clarified the answer by email. Right now, Sovrin Foundation is the origin, and Hyperledger is the maintainer for all .deb packages that begin with ""indy"".;;;","19/Jul/17 8:44 PM;alexander.shekhovcov;In the scope INDY-346 I've set ""Hyperledger <hyperledger-indy@lists.hyperledger.org>"" as a maintainer field for all packages except `sovrin`. The `sovrin` package has ""Sovrin Foundation <repo@sovrin.org>"".

The following packages have ""Hyperledger <hyperledger-indy@lists.hyperledger.org>"" in a maintainer field:

packages:
indy-node
indy-plenum
indy-anoncreds

3rd party dependencies:
python3-ioflo
python3-orderedset
python3-base58
python3-prompt-toolkit
python3-rlp
python3-sha3
python3-raet
python3-pyzmq
python3-intervaltree
python3-ujson
python3-portalocker
python3-sortedcontainers
python3-charm-crypto
python3-timeout-decorator


;;;","04/Aug/17 11:09 PM;ozheregelya;*Build Info:*
  indy-node 1.0.77
  indy-anoncreds 1.0.22
  indy-plenum 1.0.79
  sovrin 1.0.15
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes (shakedown pool 3), 1 client

*Steps to Validate:*
1. Check maintainers of packages described in previous comment.

*Actual Results:*
sovrin - Sovrin Foundation <repo@sovrin.org>
indy-node - Hyperledger <hyperledger-indy@lists.hyperledger.org>
indy-plenum - Hyperledger <hyperledger-indy@lists.hyperledger.org>
indy-anoncreds - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-timeout-decorator - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-rlp - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-sha3 - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-ioflo - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-base58 - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-sortedcontainers - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-portalocker - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-pyzmq - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-raet - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-intervaltree - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-orderedset - Hyperledger <hyperledger-indy@lists.hyperledger.org>
python3-charm-crypto - Hyperledger <hyperledger-indy@lists.hyperledger.org>

python3-pygments - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
python3-leveldb - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
python3-semver - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
python3-orderedsetp - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
python3-psutil - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
python3-pip - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
python3-psutil - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
python3-jsonpickle - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
python3-dateutil - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
python3-ujson - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
python3-prompt-toolkit - Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>

Packages maintained by Ubuntu Developers are ok, see INDY-709.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance validation to make it work with internal messages ,INDY-423,19257,,Story,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,mzk-vct,mzk-vct,14/Jul/17 8:52 PM,13/Nov/19 11:41 PM,28/Oct/23 2:46 AM,,,,,,0,5Months,,,,,"Some messages can have other messages as fields and these messages should be validated. For example MessageRep has 'params' field which contains messages of specific type. As of now they are validated using external logic, take a look at MessageReq nad CurrentState message handlers at node.  This approach is not consistent.


Steps:

*1. Make message validator be able to validate internal messages*
(it is partially implemented, take a look at MessageField class)

*2. Make message validator set parsed values as its fields instead of raw values*

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy13r:",,,,,,,,,,,,,,,,,,,,,,,,,,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 8:55 PM;mzk-vct;[~stevetolman] this is not very urgent task, but it would be great to do it soon;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Command doesn't perform after it is scheduled,INDY-424,19258,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,VladimirWork,VladimirWork,14/Jul/17 9:22 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Build Info:
sovrin 0.2.8

Overview:
Command doesn't perform after it is scheduled.

Steps to Reproduce:
1. Send valid POOL_UPGRADE command, e.g.:
send POOL_UPGRADE name=upgrade0 version=0.2.9 sha256=e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2
017-07-14T12:00:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-07-14T12:05:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-07-14T12:10:00.258870+00:00', '4P
S3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-07-14T12:15:00.258870+00:00'} timeout=10 force=False
2. Get success message ""Pool upgrade successful"".

Actual Results:
Upgrade doesn't perform at scheduled time.
There is no entries about attempts of upgrade neither in NodeX.log nor in Node journalctl.

Expected Results:
Upgrade should perform at scheduled time.

Additional Info:
Pool has a normal state (I can send and get NYMs due to this case execution).
Value of force parameter doesn't matters (it is unsuccessful both with True or False).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 9:20 PM;VladimirWork;Node1.txt;https://jira.hyperledger.org/secure/attachment/11678/Node1.txt","14/Jul/17 9:20 PM;VladimirWork;Node2.txt;https://jira.hyperledger.org/secure/attachment/11677/Node2.txt","14/Jul/17 9:20 PM;VladimirWork;Node3.txt;https://jira.hyperledger.org/secure/attachment/11676/Node3.txt","14/Jul/17 9:20 PM;VladimirWork;Node4.txt;https://jira.hyperledger.org/secure/attachment/11675/Node4.txt","14/Jul/17 9:21 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11674/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1wn:",,,,,,H5,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/17 9:22 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","15/Jul/17 5:48 AM;krw910;[~moidinis] is appears that there is a space in the dest ID of the 4th node ('4P S3E) If this is the cause then this is a validation issue.;;;","15/Jul/17 8:40 PM;dsurnin;[~VladimirWork]

in my tests node package returns version 0.4 and if version is higher the upgrade is made as expected.

also check the timezone of a schedule;;;","17/Jul/17 7:06 PM;VladimirWork;Upgrade 0.4.36 -> 0.4.37 works correctly (version parameter is the indy-node version, not sovrin like it was discussed earlier). Upgrade to current or nonexistent version now has no effect.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make sure indy and sovrin packages are never automatically updated,INDY-425,19261,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,andrey.goncharov,andrey.goncharov,14/Jul/17 10:34 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,CI/CD/Update,,,,,"During an install (postinst script in deb?) we need to use ""apt hold"" to make sure that indy-* and sovrin packages are never automatically installed by a general apt upgrade command; they should only be updated by a POOL_UPGRADE or by a manual apt upgrade that specifically names them.",,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyazb:",,,,,,10,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Aug/17 12:21 PM;danielhardman;What pull request is associated with this work?;;;","09/Aug/17 10:23 PM;andrey.goncharov;[~danielhardman]
 [https://github.com/hyperledger/indy-node/pull/290]
https://github.com/sovrin-foundation/sovrin/pull/14;;;","10/Aug/17 12:17 AM;andrey.goncharov;Implemented:

Node control tool puts indy and sovrin packages on hold.

indy-node/master 1.0.86

sovrin/master 1.0.19

How to test:
 * Install a node on a brand new VM and start it.
 * Make sure the node has started with _sudo systemctl status sovrin-node_
 * Make sure the control tool has started with _sudo systemctl status sovrin-node-control_
 * Run _sudo apt-mark showhold_ and check it shows indy-anoncreds, indy-plenum, indy-node and sovrin as held packages.
 * Perform an upgrade on a newer version
 * After restart check the packages are still held yet the upgrade was a success;;;","10/Aug/17 1:16 AM;ozheregelya;[~andrey.goncharov], are you sure in sovrin version? As far as I can see, 1.0.19 was built on Aug 03 but your commit has been done today.;;;","10/Aug/17 4:49 PM;andrey.goncharov;[~ozheregelya] my bad. It's 1.0.20;;;","12/Aug/17 12:30 AM;ozheregelya;Build Info:
 indy-node 1.0.100
 indy-anoncreds 1.0.25
 indy-plenum 1.0.91
 sovrin 1.0.22
 python3-rlp 0.5.1
 python3-sha3 0.2.1
 python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client

Case 1:
Steps to Validate:
1. Perform clean installation of sovrin.
2. Check hold packages.
=>
root@4ed3883ce1ce:/home/sovrin# apt-mark showhold
indy-anoncreds
indy-node
indy-plenum
sovrin
3. Perform full upgrade of system.

Actual Results:
indy-* and sovrin were not upgraded.

Case 2:
1. Install any version of sovrin.
2. Check that packages are not hold (perform command 'apt-mark unhold indy-anoncreds indy-node indy-plenum sovrin')
3. Upgrade the pool using POOL_UPGRADE transaction.
4. Check hold packages.
=>
root@4ed3883ce1ce:/home/sovrin# apt-mark showhold
indy-anoncreds
indy-node
indy-plenum
sovrin
5. Perform full upgrade of system.

Actual Results:
indy-* and sovrin were not upgraded.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool does not work after demotion and promotion node,INDY-426,19266,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,stevetolman,ozheregelya,ozheregelya,15/Jul/17 12:26 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Steps to Reproduce:

1. Set up pool.
2. Open the CLI, connect to the pool, set up yourself as Trustee.
3. Demote any node (e.g. Node 3).
send NODE dest=DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya data=\{'alias': 'Node3', 'services': []}
4. Promote it back.
send NODE dest=DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya data=\{'alias': 'Node3', 'services': ['VALIDATOR']}
=> Pool works.
5. Exit the CLI and open it again.
6. Connect to test environment.

Actual Results:
Strange error appears during connecting to test. NYMs are not send.

 
{code:java}
sovrin@sovrin-VirtualBox:~/.sovrin$ sovrin
Loading module /usr/local/lib/python3.5/dist-packages/config/config-crypto-example1.py
Module loaded.
Sovrin-CLI (c) 2017 Evernym, Inc.
Node registry loaded.
 Node1: 10.0.0.2:9701
 Node2: 10.0.0.3:9703
 Node3: 10.0.0.4:9705
 Node4: 10.0.0.5:9707
 Node5: 10.0.0.6:9709
 Node6: 10.0.0.7:9711
 Node7: 10.0.0.8:9713
Type 'help' for more information.
Running Sovrin 0.4.28
sovrin> connect test
Saved keyring ""Default_1f168"" restored (/home/sovrin/.sovrin/keyrings/test/default_1f168.wallet)
Active keyring set to ""Default_1f168""
Client sovrin7bc183 initialized with the following node registry:
 Node1C listens at 10.0.0.2 on port 9702
 Node2C listens at 10.0.0.3 on port 9704
 Node3C listens at 10.0.0.4 on port 9706
 Node4C listens at 10.0.0.5 on port 9708
 Node5C listens at 10.0.0.6 on port 9710
 Node6C listens at 10.0.0.7 on port 9712
 Node7C listens at 10.0.0.8 on port 9714
Active client set to sovrin7bc183
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 listening for other nodes at 0.0.0.0:6005
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 looking for Node1C at 10.0.0.2:9702
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 looking for Node6C at 10.0.0.7:9712
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 looking for Node3C at 10.0.0.4:9706
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 looking for Node5C at 10.0.0.6:9710
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 looking for Node4C at 10.0.0.5:9708
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 looking for Node2C at 10.0.0.3:9704
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 looking for Node7C at 10.0.0.8:9714
Connecting to test...
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 now connected to Node2C
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 now connected to Node4C
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 now connected to Node6C
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 now connected to Node3C
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 now connected to Node5C
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 now connected to Node7C
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 now connected to Node1C
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 could not verify catchup reply CATCHUP_REP{'ledgerId': 0, 'txns': {'8': {'reqId': 1500034359003949, 'dest': 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya', 'data': {'services': [], 'alias': 'Node3'}, 'signature': 'okhKtLWKmBiam4EsohrgMA57uXTqwVPUh2w7FSdvyXXVUT77Rp9yA79E8NehaYsreBwfQNuTwJy35BJgdTGaBSc', 'identifier': 'V4SGRU86Z58d6TV7PBUe6f', 'type': '0'}}, 'consProof': ['Gf5K1TEoNegZsS2C5vzfNPbJ3cKMZGS4NaHZ8VY19Esp']} since Bad Merkle proof: second root hash does not match. Expected hash: b'bd8142fe77cece59f67e2f3c51083607845a8119ac14be20969b72b36f05719f' , computed hash: b'524121f7b02d124d6aa43800d50240acbed868fc1ff2aef9ca11aa13f0f94587'
Db57e2gEAJPSMwUoQ48axT1iW4M9RXLztAMrp7xv3Xa4 could not verify catchup reply CATCHUP_REP{'ledgerId': 0, 'txns': {'8': {'reqId': 1500034359003949, 'dest': 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya', 'data': {'services': [], 'alias': 'Node3'}, 'signature': 'okhKtLWKmBiam4EsohrgMA57uXTqwVPUh2w7FSdvyXXVUT77Rp9yA79E8NehaYsreBwfQNuTwJy35BJgdTGaBSc', 'identifier': 'V4SGRU86Z58d6TV7PBUe6f', 'type': '0'}}, 'consProof': ['Gf5K1TEoNegZsS2C5vzfNPbJ3cKMZGS4NaHZ8VY19Esp']} since Bad Merkle proof: second root hash does not match. Expected hash: b'bd8142fe77cece59f67e2f3c51083607845a8119ac14be20969b72b36f05719f' , computed hash: b'524121f7b02d124d6aa43800d50240acbed868fc1ff2aef9ca11aa13f0f94587'
Connected to test.
sovrin@test> new key with seed 000000000000000000000000Steward1
Key created in keyring Default_1f168
Identifier for key is Th7MpTaRZVRYnPiabds81Y
Verification key is ~7TYfekw4GUagBnBVCqPjiC
Current identifier set to Th7MpTaRZVRYnPiabds81Y
sovrin@test> send NYM dest=ULtgFQJe6bjiFbs7ke3NJD role=TRUST_ANCHOR
Adding nym ULtgFQJe6bjiFbs7ke3NJD
sovrin@test>
{code}
 

Expected Results:

Error should not be shown, NYMs should be send.","Build Info:
indy-node version: 0.4.28
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 7 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8j3:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jul/17 5:50 AM;krw910;Duplicate of INDY-158;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need script to upgrade ChunkedFileStore,INDY-427,19267,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,DouglasWightman,DouglasWightman,15/Jul/17 1:35 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Changes from INDY-104 require a script to update the contents of ChunkedFileStore.  This script should read in the old files and upgrade them to the new.

Here's the POA:

resides in indy-node/scripts/upgrade_ledger.py
will use the old code to read in the transactions
will use the new code to write out the transactions
will store the old files in a backup location",,,,,,,,,,,,,,,,,,,,,,,INDY-104,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1z3:",,,,,,H5,,,,,,,,,,,,,,,,,,,,DouglasWightman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Error starting a node - mode is 300,INDY-428,19273,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,slafranca,slafranca,slafranca,15/Jul/17 5:12 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"I was given a new pool of machines to use.  I started all the nodes and everything seemed to run fine.  I was trying to find the primary node and when I ran ""grep ""selected primary"" *.log"" on each of the nodes.  I noticed the query on Node 3 did not return anything (Node 3 is in the eu-west-1-ireland region).  When I looked in the log, I see this error 3 times.
{code:java}
2017-07-14 17:19:39,906 | INFO     | primary_selector.py  ( 255) | _startSelection | Node3 cannot start primary selection since mode is 300
{code}

The log for Node 3 is attached.  I also attached the log from Node 2 for comparison.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jul/17 5:07 AM;slafranca;Node2.log;https://jira.hyperledger.org/secure/attachment/11679/Node2.log","15/Jul/17 5:02 AM;slafranca;Node3.log;https://jira.hyperledger.org/secure/attachment/11680/Node3.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1wv:",,,,,,H5,,,,,,,,,,,,,,,,,,,,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jul/17 5:54 AM;krw910;Time box this to an hour to see what this message is referring to and communicate it to Kelly. ;;;","17/Jul/17 10:41 PM;lovesh;[~krw910] ""mode is 300"" means that node has caught up pool ledger but still to catchup other ledger. This alone should not be considered an error unless the node can never (say >2-3 minutes) catchup and participate
;;;","20/Jul/17 7:02 AM;slafranca;Added comment to https://docs.google.com/document/d/1WsBoX414FDt3FI-dEvbanWof5jYUr1A-lnGot13CYC8/edit#heading=h.o4sfgbz5i7yk
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Any time  a new config value shows up, prove that it's documented.",INDY-429,19275,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,stevetolman,stevetolman,15/Jul/17 7:09 AM,11/Oct/19 6:52 PM,28/Oct/23 2:46 AM,11/Oct/19 6:52 PM,,,,,0,5Months,,,,,This should be an automated test. This could be done by parsing our config class in python and reconciling it against a markdown file somewhere.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx17z:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 6:52 PM;ashcherbakov;We have tasks to cleanup configs;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Nodes not receiving new transaction if its ""View"" list is different from other nodes in the pool",INDY-430,19287,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,17/Jul/17 4:48 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,ViewChange,,,,,"It looks like if a node has a different list of who is primary than other nodes in the pool is does not receive new transactions.

I got setup to do load testing today. I ran add_key.py to get 200 trust anchors added. I was watching the ledger count on just Node1 and it didn't seem like it worked so I ran it again. After trying to find out what happened. I checked the other ledgers and found they all had a count of 436 which would be correct. Only Node1 was at 76 in the ledger.

I restarted Node1 and it did a catch up so now all nodes had a ledger count of 436.

*{color:#d04437}Mismatch{color}*
I then ran load_test.py and sent just 10 new transactions. I checked the ledger counts and Node1 still had 436 and Nodes 2-10 all had 446. So only nodes 2-10 processed the new transactions.

I did a search for ""primary is"" and ""selected primary"" in the log files and found the following
*Node1 showed*
{color:#d04437}Node1:0 - Master{color}
Node2:1
Node3:2
Node4:3

*Node2 through Node10 showed*
{color:#14892c}Node2:0 - Master{color}
Node3:1
Node4:2
Node5:3",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1x3:",,,,,,H5,,,,,,,,,,,,,,,,,,,,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jul/17 5:55 PM;lovesh;Same cause as INDY-420;;;","17/Jul/17 7:55 PM;lovesh;PR, https://github.com/hyperledger/indy-plenum/pull/283;;;","19/Jul/17 6:37 AM;krw910;Blocked by INDY438. I am unable to throw a sufficant load at the pool until this ticket has been addressed. Lovesh is looking at the pool.;;;","21/Jul/17 5:47 AM;krw910;This appears to be working. The nodes are getting updated with who the current primary node is.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Change the update mechanism so it is driven by the version of sovrin.deb, not the version of indy-node.deb",INDY-431,19296,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,stevetolman,andrey.goncharov,andrey.goncharov,17/Jul/17 11:13 PM,11/Oct/19 7:01 PM,28/Oct/23 2:46 AM,11/Oct/19 7:01 PM,,,,,0,5Months,,,,,"We change the update mechanism so it is driven by the version of sovrin.deb, not the version of indy-node.deb. This means that any time we want to update the sovrin network, we build a new sovrin.deb that changes the dependency that it declares, on indy-node. (We almost certainly will have to update indy-node as well, of course.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx187:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 7:01 PM;esplinr;This is complete. We only update the sovrin.deb on the Sovrin network.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
 repo.sovrin.org should be a higher priority repo,INDY-432,19297,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,mzk-vct,andrey.goncharov,andrey.goncharov,17/Jul/17 11:13 PM,13/Nov/19 11:46 PM,28/Oct/23 2:46 AM,13/Nov/19 11:46 PM,,,,,0,5Months,,,,,"Besides telling stewards to add [repo.sovrin.org|http://repo.sovrin.org/] to their /etc/apt/sources.lst, we also tell them to configure [repo.sovrin.org|http://repo.sovrin.org/] to be a higher priority repo (from apt's perspective) than the default ubuntu repos, [using instructions from askubuntu|https://askubuntu.com/questions/135339/assign-highest-priority-to-my-local-repository]. (We should automate this by putting it in sovrin.deb's postinst script). (I've [logged a ticket|https://evernym.atlassian.net/browse/TE-40] to develop an equivalent solution for RHEL.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzy15r:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,esplinr,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jul/17 12:51 AM;mzk-vct;[~danielhardman]
Am I right that the purpose of this is to make all dependencies to be installed from sovrin repos even if they are also available from other repos?
I have some concerns:
# I suspect that changing priority of repos in hooks can confuse node admin or cause some problems.
# Post install script starts after installation is complete and dependencies installed.
But even if we use preinstall script instead I cannot guarantee that it will be executed before installation of dependencies since package can be installed in a multiple ways. 
I made a short research, but found no clear answer.
# What should we do if some dependencies are already installed from base ubuntu repos?

What if we explicitly guide node admin to change repo priority instead? We can provide shell script to simplify this process.


;;;","31/Jul/17 8:51 PM;danielhardman;No, we don't want all dependencies to install from sovrin repos. For example, i want ujson and similar modules that we have nothing to do with, to install latest stable from the distro. However, we *do* want indy-node and indy-plenum to install from sovrin repos, even if at some future date they are also available in the main distro repos. If we don't do this, hyperledger indy could release an update to indy that sovrin is unprepared to accept, and sovrin's network would be destabilized.

Note that I am requesting this change to priority of repos to be made by *Sovrin*'s deb file, not indy-node's. If people are going to run Sovrin, then they need to use the version of indy-node that the Sovrin pool is pegged to. If they want to run raw indy-node, they can run whatever version they like.;;;","01/Aug/17 8:19 PM;mzk-vct;[~danielhardman] 
My main concern is whether it should be done automatically in process of installation.
In an [installation guide (page 6)|https://drive.google.com/drive/u/0/folders/0B4efUY1IocYwUERNNW5sekNTMUU] we ask node admin to manually put sovrin repos on the apt repo list. Can we just tell him to put them with specific repo priority?;;;","01/Aug/17 11:00 PM;danielhardman;I don't understand why it's hard or difficult to automate this. Can you provide some additional details?

I am under the impression that placing the sovrin repo at the top of /etc/apt/sources.lst will not work; that will cause apt to find sovrin's repo version first, but it will still find other versions as well, and pick the latest. The only way we can do this is to update /etc/apt/preferences and placing a high priority on sovrin's repo. Thus, we would be asking an admin to make two edits instead of one. It can be done, but it seems more cumbersome than just automating that.

Perhaps there are good reasons why automating it is a bad idea?;;;","01/Aug/17 11:47 PM;mzk-vct;*>Can you provide some additional details?*
 # As you said we want indy-node and indy-plenum to install from sovrin repos, even if at some future date they are also available in the main distro repos. But if we are going to change priority in deb pre/post install hooks we cannot guarantee that at the moment when admin installs them *first time* they will be installed from sovrin repos.
 # I found no clear explanation when exactly preinstall script runs - before or after downloading of dependencies. Looks like the only way to know it for sure is to make an experiment.

*>Perhaps there are good reasons why automating it is a bad idea?*
 *>Thus, we would be asking an admin to make two edits instead of one.*
 Automating is not a bad idea, but I'd not recommend to manipulate repos priority in deb pre/post install hook.
Admin should be aware that such change is going to be done and should be able to do it manually, considering all specific fetures of his system.
Instead I propose automating installation preparations.


Yes, it requires one more edit, but we can automate this.
Moreover, we can automate some other steps, like adding keys, repos and calling apt install.

 

 

 ;;;","03/Aug/17 3:59 AM;danielhardman;I defer to [~nage]'s judgment.;;;","13/Nov/19 11:46 PM;esplinr;We are in the process of updating Indy Node from Ubuntu 16.04 to Ubuntu 18.04, and regret having dependencies on so many packages that conflict with the new repos. We want to minimize that practice going forward, so we don't expect many overlaps between Sovrin repos and the standard repos. For now, situations where we are concerned about pulling a package from a specific repository are addressed by careful explicit pinning.

If we decide that changing repo prioritization is required to meet a specific objective, we will reconsider this decision. It might be preferable to add it to the steward instructions instead of automating it in an install script so that system administrators are not surprised.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
improve view change at moment of blacklisting,INDY-433,19304,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,danielhardman,danielhardman,18/Jul/17 1:22 AM,09/Oct/19 5:17 PM,28/Oct/23 2:46 AM,09/Oct/19 5:17 PM,,,,,0,5Months,,,,,"This ticket is a follow-up to INDY-193.

In that ticket's comment stream, [~spivachuk] identified some follow-up work that could be done to make us more robust. Here is what he said:

""To trigger view change at the moment when the master's primary is blacklisted the first time we need to introduce notifying other nodes about some node is blacklisted and a mechanism of requesting known transactions from other node for verification only. Such the fix seems to be rather time-consuming while the issue seems not to be critical because blacklisting of some node by other nodes one by one during their catch-ups will eventually cause a view change. So I propose to schedule this work for the time after Minimal Go-Live.""

This ticket is to track that work.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-46,,,,,,,,,,"1|hzx13z:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 5:17 PM;ashcherbakov;The only situation when a node can be blacklisted is during a catchup (when we see that a Ledger of this node differs).

If the Primary is blacklisted, then, due to the implemented Freshness checks, other nodes will notice that there is no ordering happening, and do a view change;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy-node test should show debug and trace logs,INDY-434,19308,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,lovesh,lovesh,18/Jul/17 5:26 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,Currently tests show only INFO level logs which makes troubleshooting failing tests difficult,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1xb:",,,,,,H5,,,,,,,,,,,,,,,,,,,,andrey.goncharov,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jul/17 12:48 AM;andrey.goncharov;Added an autouse fixture to patch debug level for tests. [https://github.com/hyperledger/indy-node/commit/7216ed252f6cd49a88bd5a47dd4fdb73f164ab42]
Try to run tests for sovrin_node locally and see DEBUG logs for node.py are shown.

indy-node/master 0.4.53 ;;;","21/Jul/17 5:46 AM;krw910;This looks like it will work, but I don't run the unit tests.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Logs do not roll over,INDY-435,19314,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,lovesh,lovesh,18/Jul/17 6:23 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"A simple experiment to reproduce this bug is to reduce log size to 2MB per file and then write logs over 20MB, see if the rollover happens. This bug can be seen in the AWS performance pool on Node1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jul/17 11:35 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11743/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1xj:",,,,,,H5,,,,,,,,,,,,,,,,,,,,danielhardman,lovesh,mgbailey,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jul/17 7:50 PM;mzk-vct;Logs do have rotation.

Conditions:
1. Every 24h
2. Every 100MB

Number of log files limited, by default it is 10 (check option logRotationBackupCount in config file).
It means that if there are 10 log files and 11 is being written then when it is completed it replaces first one.;;;","18/Jul/17 11:35 PM;lovesh;But ""replaces first one"" does not happen, you can check at Node1;;;","18/Jul/17 11:38 PM;danielhardman;[~mgbailey], what have you observed about log rotation?;;;","19/Jul/17 8:25 AM;mgbailey;ubuntu@ip-172-31-46-122:/home/sovrin/.sovrin$ ll -t ev1.log*
-rw-r--r-- 1 sovrin sovrin 261124 Jul 18 23:05 ev1.log
-rw-r--r-- 1 sovrin sovrin 2444341 Jul 18 20:31 ev1.log.2017-07-17
-rw-r--r-- 1 sovrin sovrin 104399808 Jul 17 20:31 ev1.log.2017-07-16
-rw-r--r-- 1 sovrin sovrin 2446719 Jul 16 20:30 ev1.log.2017-07-15
-rw-r--r-- 1 sovrin sovrin 3156702 Jul 15 20:30 ev1.log.2017-07-14
-rw-r--r-- 1 sovrin sovrin 2437713 Jul 14 20:30 ev1.log.2017-07-13
-rw-r--r-- 1 sovrin sovrin 4523738 Jul 13 20:30 ev1.log.2017-07-12
-rw-r--r-- 1 sovrin sovrin 2417796 Jul 12 02:16 ev1.log.2017-07-11
-rw-r--r-- 1 sovrin sovrin 49706413 Jul 11 02:16 ev1.log.2017-07-10
-rw-r--r-- 1 sovrin sovrin 104857563 Jul 10 02:16 ev1.log.2017-07-09
-rw-r--r-- 1 sovrin sovrin 104857325 Jul 9 07:18 ev1.log.2017-07-08;;;","19/Jul/17 8:38 AM;mgbailey;Here is another example (from the log consolidation server), of one which is rolling faster:

ubuntu@ip-172-31-33-106:~/logs$ ll -t OASFCU.log*

-rw-r--r-- 1 ubuntu ubuntu 14345259 Jul 18 23:30 OASFCU.log
-rw-r--r-- 1 ubuntu ubuntu 104857470 Jul 18 23:04 OASFCU.log.2017-07-18.6
-rw-r--r-- 1 ubuntu ubuntu 104857548 Jul 18 19:56 OASFCU.log.2017-07-18.5
-rw-r--r-- 1 ubuntu ubuntu 104857501 Jul 18 16:50 OASFCU.log.2017-07-18.4
-rw-r--r-- 1 ubuntu ubuntu 104857502 Jul 18 13:45 OASFCU.log.2017-07-18.3
-rw-r--r-- 1 ubuntu ubuntu 104857534 Jul 18 10:36 OASFCU.log.2017-07-18.2
-rw-r--r-- 1 ubuntu ubuntu 104857581 Jul 18 07:27 OASFCU.log.2017-07-18.1
-rw-r--r-- 1 ubuntu ubuntu 104857598 Jul 18 04:17 OASFCU.log.2017-07-18
-rw-r--r-- 1 ubuntu ubuntu 104857480 Jul 18 01:09 OASFCU.log.2017-07-17.8
-rw-r--r-- 1 ubuntu ubuntu 104857575 Jul 17 22:00 OASFCU.log.2017-07-17.7;;;","19/Jul/17 6:33 PM;lovesh;PR https://github.com/hyperledger/indy-plenum/pull/288;;;","21/Jul/17 11:36 PM;VladimirWork;Log files grow to logRotationMaxBytes size and to logRotationBackupCount quantity (does not include ""active"" log file).
Log rotation with various logRotationMaxBytes/logRotationBackupCount parameters and log files numeration works correctly. !Screenshot.PNG|thumbnail! 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[send NODE] Unable to perform command with 'services': ['VALIDATOR'],INDY-436,19315,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,dsurnin,VladimirWork,VladimirWork,18/Jul/17 6:39 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
indy-node 0.4.39
sovrin 0.4.39

Overview:
Unable to perform send NODE command with 'services': ['VALIDATOR'].

Preconditions:
Pool of 4 nodes and one more single node.

Steps to Reproduce:
1. Login as Steward of new node, e.g.:
new key with seed StewardNode500000000000000000000.
2. Send NODE with valid parameters and 'services': [], e.g.:
send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.0.2.15', 'alias':'Node5', 'node_ip': '10.0.2.15', 'node_port': 9701, 'services': []}.
3. Send NODE with valid parameters and 'services': ['VALIDATOR'], e.g.:
send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.0.2.15', 'alias':'Node5', 'node_ip': '10.0.2.15', 'node_port': 9701, 'services': ['VALIDATOR']}.

Actual Results:
Node request failed with error: client request invalid: UnauthorizedClientRequest(""2 not in allowed roles {'0': []}"",).

Expected Results:
The node successfully becomes connected and the pool can handle requests (see INDY-233).

Additional Info:
Step 2 command performs successfully, but Step 3 command fails with UnauthorizedClientRequest, so it seems like it is a validation problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jul/17 6:38 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11696/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1yn:",,,,,,H5,,,,,,,,,,,,,,,,,,,,krw910,stevetolman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jul/17 6:40 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","19/Jul/17 8:47 AM;stevetolman;We are hoping if this is a validation problem it will be straight forward and that it has something to do with DID and not cryptonym validation.

Please make sure the command we are using is still legitimate given our switch to DIDs. We think nodes are still identified by cryptonyms, we are just double checking.;;;","19/Jul/17 10:57 PM;krw910;Duplicate of INDY-326;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
roll back default where zmq high water mark = 0,INDY-437,19336,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,mzk-vct,danielhardman,danielhardman,19/Jul/17 5:11 AM,11/Oct/19 7:14 PM,28/Oct/23 2:46 AM,11/Oct/19 7:14 PM,,,,,0,5Months,Stability,,,,"This is a follow-up to INDY-366. In that ticket, we changed the default FIFO queue in ZMQ to be unlimited. This makes certain problems less likely, but it also masks problems for a lot longer. I would be more comfortable that we were truly robust if:
 # The high water mark were finite (e.g., 100,000).
 # We had a way to detect that we are nearing the high water mark, and that we would report a graceful error that makes this condition easy to diagnose.
 # We implemented logic in STP to discard old messages rather than new ones. (Desirable but not necessarily required.)
 # If we exceed the high water mark, we exit the daemon process gracefully rather than crashing due to an out-of-memory condition.

This ticket is to track the work in items 1-4. Possibly 3 could be omitted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-41,,,,,,,,,,"1|hzx19j:",,,,,,12,,,,,,,,5.0,,,,,,,,,,,,ashcherbakov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 7:14 PM;ashcherbakov;This is done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool fails to accept new transactions. Roots and requests are different between nodes,INDY-438,19340,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,19/Jul/17 6:32 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"""Some nodes have ordered different requests and hence roots are different, logs and ledger confirm this""

Lovesh and Kelly are working through this issue. All we know so far is what Lovesh has stated above. 
This ticket is to track our findings and the fix.

Setup
10 Physical Nodes
10 Physical Clients

I setup the load_test.py script to run from each of the 10 clients. 
I then ran the load_test.py script from each of the 10 clients all sending 500 requests each at the same time. 
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once

I should have seen 5.000 transactions, but after 2,000 the pool stopped accepting new transactions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1xr:",,,,,,H5,,,,,,,,,,,,,,,,,,,,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jul/17 3:48 PM;lovesh;PR https://github.com/hyperledger/indy-plenum/pull/300
;;;","23/Jul/17 5:29 AM;krw910;I cannot reproduce with the latest build.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"improve timestamp mechanism to use fuzzy, state proof style consensus",INDY-439,19342,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,danielhardman,danielhardman,19/Jul/17 8:06 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,,,,,"The same way we come to consensus on which set of validators are the signers in the BLS signature, we could come to consensus about which timestamp to use. The timestamp could be computed at exactly the same time as the rest of the state proof.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-63,,,,,,,,,,"1|hzx17j:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Aug/17 5:18 PM;ashcherbakov;[~danielhardman] I'm not sure that I understand the ticket. BLS signatures are calculates independently by each node, and then aggregated to multi-sig by a Primary. And it's done only during the next batch of txns (so, we have to have a lag in order to get a multi-sig which is the same for all nodes). Do we need something similar for timestamps?;;;","28/Sep/18 7:12 AM;ashcherbakov;The timestamp is suggested by the Primary, verified by others (10 mins deviation is accepted), and signed by BLS multi-sig. So, we the timestamp is always the same on all nodes, as this is part of consensus.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update Getting Started Guide: DID/verkey changes & Sovrin prompt changes,INDY-440,19364,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,TechWritingWhiz,TechWritingWhiz,20/Jul/17 2:06 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,02/Aug/17 12:00 AM,0,Documentation,,,,,"Update the Getting Started Guide to include all of the necessary DID/verkey changes and sovrin> changes where applicable. 

 

Currently waiting on identification in other documents.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyazj:",,,,,,M1 Prelude,10,,,,,,,,,,,,,,,,,,,krw910,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/17 11:11 PM;TechWritingWhiz;I've done the work on this and need someone to review the changes I've made to make sure they are correct. Working with Kelly to get that done prior to check in. ;;;","28/Jul/17 5:12 AM;TechWritingWhiz;I have checked in those changes here: [https://github.com/TechWritingWhiz/indy-node] The checkin with these changes can be seen here: [https://github.com/TechWritingWhiz/indy-node/commit/e7c33d3717aa428a3b5ab2ca57353bbd1b6eac7a]

Please review this for accuracy. 

Thank you.;;;","29/Jul/17 1:38 AM;krw910;I placed comments on git for the file.;;;","29/Jul/17 4:21 AM;TechWritingWhiz;These changes are completed. Pull Request: 

[https://github.com/hyperledger/indy-node/pull/269]

 

 ;;;","31/Jul/17 8:25 PM;TechWritingWhiz;This has been merged. Closing this ticket.;;;","03/Aug/17 4:24 AM;krw910;[~TechWritingWhiz] based off a recent ticket from development you can change the faber-invitation back to faber-request. Here is the link to INDY-457 changes:
https://github.com/hyperledger/indy-node/pull/268/commits/de4dc9a46735ed5e73b4506412564522d8772416
;;;","03/Aug/17 6:07 AM;TechWritingWhiz;Changing ""invitation"" to ""request"" for the Faber file name in the Getting Started. This is done. Pull request is here: 

[https://github.com/hyperledger/indy-node/pull/278]

 ;;;","10/Aug/17 11:27 PM;krw910;This is completed

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The pool is broken after adding new nodes,INDY-441,19368,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,lovesh,ozheregelya,ozheregelya,20/Jul/17 3:52 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,Seems-invalid,,,,,"Steps to Reproduce: https://docs.google.com/document/d/1Nl6d0Vd5riuCenAY-Qon9sp1vCjRO5KJncUF6nA7PAU/edit#
 # Set up pool of 4 nodes.
 # Configure two additional nodes to connection (as described in scenario 7)
 # Connect the first additional node as one Steward.
 => message about connection of new node appeared in CLI.
 # Connect the second additional node as other Steward.
 => message about connection of new node appeared in CLI.
 # Try to send NYM.

Actual Results:
 Nothing happened.

Expected Results:
 NYM should be added.","Build Info:
  indy-anoncreds 0.4.7
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
  indy-plenum 0.4.20
  indy-node 0.4.27
  sovrin 0.2.1
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4+2 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jul/17 4:31 AM;krw910;Node1.log;https://jira.hyperledger.org/secure/attachment/11726/Node1.log","20/Jul/17 4:31 AM;krw910;Node2.log;https://jira.hyperledger.org/secure/attachment/11720/Node2.log","20/Jul/17 4:31 AM;krw910;Node3.log;https://jira.hyperledger.org/secure/attachment/11721/Node3.log","20/Jul/17 4:31 AM;krw910;Node4.log;https://jira.hyperledger.org/secure/attachment/11722/Node4.log","20/Jul/17 4:31 AM;krw910;Node5.log;https://jira.hyperledger.org/secure/attachment/11723/Node5.log","20/Jul/17 4:31 AM;krw910;Node6.log;https://jira.hyperledger.org/secure/attachment/11724/Node6.log","20/Jul/17 4:31 AM;krw910;cli.log;https://jira.hyperledger.org/secure/attachment/11725/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1yf:",,,,,,H5,,,,,,,,,,,,,,,,,,,,krw910,lovesh,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jul/17 4:28 AM;krw910;I have tried with with another installation and could not reproduce the issue. ;;;","20/Jul/17 10:47 PM;lovesh;[~ozheregelya] I am abandoning this ticket, i do see on the 2 new nodes that the new nodes raised a suspicion on for the PRE-PREPARE having incorrect state trie root but i could not reproduce this, i am going to commit an automated test for this behaviour. Also the log files contain only info and above log levels. But the biggest reason for abandoning this ticket is this kind of line in the logs of both new nodes.
{code}
Node5:0 reverting 1 txns and state root from b""\xdf\xee\x92{dz\xea\xb9\xcd\x86n~\x04T\xa4B\xd2\xe0\xa3}2$\xdd\x02\xb25.\xae\t\x1e'\xb8"" to b'\xac\xfd_\xe0\x05\xf3WB\xfa\xc5\xce`U>\xe7\xa8\xb9\x15F\x11\x8d\xff\xa0\x18^\xf7g\xa3\x01M\xe6\x98' for ledger 1
{code}
Above is from Node5. This means that before this PRE-PREPARE the state root of node was `b'\xac\xfd_\xe0\x05\xf3WB\xfa\xc5\xce`U>\xe7\xa8\xb9\x15F\x11\x8d\xff\xa0\x18^\xf7g\xa3\x01M\xe6\x98` which is `CeHDAVUNU3vdv9KPuYJcMyLapAdQfeRcVWWgWMZq1ukB` in base58. But if you check in the logs, no previous PRE-PREPARE had state root as `CeHDAVUNU3vdv9KPuYJcMyLapAdQfeRcVWWgWMZq1ukB`. In the fact the revert should have happened to `2tDdU58Ra4WLTznbmsTmJxedzqMDXw67xFL7qWx6yh7M` which is the previous PRE-PREPARE for ledger 1 and i don't see any indication of something being written to ledger or state before the transaction since catchup had already completed. So i am assuming the node was not started from a correct state (some wrong genesis file copied). I think we should start including state roots in catchup messages (LEDGER_STATUS, CONS_PROOF) so these problems can be caught earlier.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CouldNotAuthenticate error message appear for default Trustee when the pool is broken,INDY-442,19369,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,,ozheregelya,ozheregelya,20/Jul/17 4:07 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Steps to Reproduce: 
 [https://docs.google.com/document/d/1Nl6d0Vd5riuCenAY-Qon9sp1vCjRO5KJncUF6nA7PAU/edit#|https://docs.google.com/document/d/1Nl6d0Vd5riuCenAY-Qon9sp1vCjRO5KJncUF6nA7PAU/edit]

[https://docs.google.com/document/d/1dVUkcmwRYGMSC6FZfSEWwip8TsCc_QVsZOvXZg0NWF8/edit]
 # Set up pool of 4 nodes.
 # Configure two additional nodes to connection (as described in scenario 7)
 # Connect the first additional node as one Steward.
 => message about connection of new node appeared in CLI.
 # Connect the second additional node as other Steward.
 => message about connection of new node appeared in CLI.
 After these steps pool is broken, see INDY-441 for details.
 # Set yourself as default Trustee:
 new key with seed 000000000000000000000000Trustee1
 # Try to dend NYM:
 send NYM dest=CDBcM7hSAmQuenmEnE8dXG role=TRUSTEE verkey=~JsqrSipV963hwbojxwR2fg

Actual Results:
 Error: client request invalid: CouldNotAuthenticate()

Expected Result:
 Behavior should be the same as usual (usually nothing happened when the pool is broken, no errors appear).","Build Info:
  indy-anoncreds 0.4.7
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
  indy-plenum 0.4.20
  indy-node 0.4.27
  sovrin 0.2.1
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4+2 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jul/17 4:20 AM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11714/Node1.log","20/Jul/17 4:20 AM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11715/Node2.log","20/Jul/17 4:20 AM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11716/Node3.log","20/Jul/17 4:20 AM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11717/Node4.log","20/Jul/17 4:21 AM;ozheregelya;Node5.7z;https://jira.hyperledger.org/secure/attachment/11718/Node5.7z","20/Jul/17 4:21 AM;ozheregelya;Node6.7z;https://jira.hyperledger.org/secure/attachment/11719/Node6.7z","20/Jul/17 4:20 AM;ozheregelya;cli.log_couldnotauthenticate;https://jira.hyperledger.org/secure/attachment/11713/cli.log_couldnotauthenticate",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy1zb:",,,,,,H5,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jul/17 1:17 AM;alexander.shekhovcov;I went through Test Scenario 07 and Test Scenario 09 as described in the description and cli.log_couldnotauthenticate a couple times and didn't get any errors. 

Also cannot reproduce in tests.

If the issue is reproduced again attaching /home/sovrin/.sovrin folder may help.

For now moving in ""to test"" stage.

;;;","22/Jul/17 2:32 AM;ozheregelya;I can't reproduce this problem again on clear machine, so I will close this ticket as invalid.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Bad validation error for /u2018 and /u2019 quotation marks,INDY-443,19375,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,VladimirWork,VladimirWork,20/Jul/17 5:57 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,5Months,,,,,"Build Info:
sovrin 0.4.45
indy-node 0.4.48

Overview:
Bad validation error for /u2018 and /u2019 quotation marks.

Steps to Reproduce:
1. Login as Trustee.
2. Send pool upgrade command with /u2018 and /u2019 quotation marks, e.g.:
send POOL_UPGRADE name=upgradeJuly192017 version=0.4.50 sha256=57ceed6fcd1682af44ebdbf3cecb15ede8e28de1 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv':'2017-07-19T11:15:00.258870-07:00','8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb':'2017-07-19T11:35:00.258870-07:00','DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-07-19T11:55:00.258870-07:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-07-19T12:15:00.258870-07:00','4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe':'2017-07-19T12:35:00.258870-07:00','Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8':'2017-07-19T12:55:00.258870-07:00','BM8dTooz5uykCbYSAAFwKNkYfT4koomBHsSWHTDtkjhW':'2017-07-19T13:15:00.258870-07:00'} timeout=10

Actual Results:
Not user-friendly """"schedule"" must be in proper format"" error with huge trace log.

Expected Results:
/u2018 and /u2019 quotation marks should be handled the same way as other invalid special chars (highlight this chars by color and throw invalid syntax error with hint).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jul/17 5:56 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11727/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy12v:",,,,,,,,,,,,,,,,,,,,,,,,,,Toktar,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 10:22 PM;Toktar;It happen in the old CLI that deprecated. This problem links with the json format error and should be checked in the indy-sdk level. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unclear error appears in CLI and pool is crashed after changing node data,INDY-444,19378,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andkononykhin,ozheregelya,ozheregelya,20/Jul/17 9:21 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,should,,,,"*Steps to Reproduce:*
 # Set up pool of 4 nodes.
 # Init additional node #1 (ip 10.0.0.6 in this example)

{code:java}
init_sovrin_node Node5 9701 9702 000000000000000000000000000node5
generate_sovrin_pool_transactions --nodes 4 --clients 4 --ips  '10.0.0.2,10.0.0.3,10.0.0.4,10.0.0.5'{code}
 # Add additional node #1 to pool, try to send NYM to test communication.

{code:java}
send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.0.0.6', 'alias':'Node5', 'node_ip': '10.0.0.6', 'node_port': 9701, 'services': ['VALIDATOR']}{code}
=> Node is added, consensus reached, NYM is successfully added.
 # Stop services on additional node #1, try to send NYM to test communication.
 => Count of nodes is n-f, consensus is reached, NYM is successfully added.
 # Init additional node #2 (ip 10.0.0.7 in this example)

{code:java}
init_sovrin_node Node5 9701 9702 000000000000000000000000000node5
generate_sovrin_pool_transactions --nodes 4 --clients 4 --ips  '10.0.0.2,10.0.0.3,10.0.0.4,10.0.0.5'{code}
 # Add additional node #2 to pool, try to send NYM to test communication.

{code:java}
send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.0.0.6', 'alias':'Node5', 'node_ip': '10.0.0.6', 'node_port': 9701, 'services': ['VALIDATOR']}{code}
=> Node is added, consensus reached, NYM is successfully added.
 # Stop services on additional node #2, try to send NYM to test communication.
 => Count of nodes is n-f, consensus is reached, NYM is successfully added.
 # Exit the CLI.
 # Open the CLI again, try to connect to test environment.

*Actual Results:*
{code:java}
sovrin> connect test
Saved keyring ""Default-dd49d5"" restored (/home/sovrin/.sovrin/keyrings/test/default-dd49d5.wallet)
Active keyring set to ""Default-dd49d5""
Client sovrin3c4a29 initialized with the following node registry:
 Node1C listens at 10.0.0.2 on port 9702
 Node2C listens at 10.0.0.3 on port 9704
 Node3C listens at 10.0.0.4 on port 9706
 Node4C listens at 10.0.0.5 on port 9708
Active client set to sovrin3c4a29
G8MVTMHZdsPTmxbaUX78Z5xkWnUg14cDtxFMUiKzyGtX listening for other nodes at 0.0.0.0:6029
G8MVTMHZdsPTmxbaUX78Z5xkWnUg14cDtxFMUiKzyGtX looking for Node2C at 10.0.0.3:9704
G8MVTMHZdsPTmxbaUX78Z5xkWnUg14cDtxFMUiKzyGtX looking for Node1C at 10.0.0.2:9702
G8MVTMHZdsPTmxbaUX78Z5xkWnUg14cDtxFMUiKzyGtX looking for Node3C at 10.0.0.4:9706
G8MVTMHZdsPTmxbaUX78Z5xkWnUg14cDtxFMUiKzyGtX looking for Node4C at 10.0.0.5:9708
Connecting to test...
G8MVTMHZdsPTmxbaUX78Z5xkWnUg14cDtxFMUiKzyGtX now connected to Node2C
G8MVTMHZdsPTmxbaUX78Z5xkWnUg14cDtxFMUiKzyGtX now connected to Node3C
G8MVTMHZdsPTmxbaUX78Z5xkWnUg14cDtxFMUiKzyGtX now connected to Node1C
G8MVTMHZdsPTmxbaUX78Z5xkWnUg14cDtxFMUiKzyGtX now connected to Node4C
Connected to test.
G8MVTMHZdsPTmxbaUX78Z5xkWnUg14cDtxFMUiKzyGtX could not verify catchup reply CATCHUP_REP{'txns': {'5': {'identifier': 'XhYtvJqezMUKfF6KVNaGmT', 'type': '0', 'txnTime': 1500466694, 'signature': '3F6YEvZRGWY8DeYKJGykJjL4LhsidxWPCWjqQYd7mLTQQCfB9NkYycxf6cfEe46buA3773htHSSFCHd8BuGoVg9Q', 'reqId': 1500466694263116, 'dest': '4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc', 'data': {'client_ip': '10.0.0.6', 'alias': 'Node5', 'services': ['VALIDATOR'], 'node_port': 9701, 'client_port': 9702, 'node_ip': '10.0.0.6'}}}, 'consProof': ['BALn3uTnmGbyLpwspvZq99qB8aTtzvrz1gPpHCvb8N3r', '8ayqSLxRaqzM7LAv7yMvfcUPXVpgrabwbjCtiZXd7753', 'BZYapF9k1VgPp6Qv7A5Lm7tJy97ty7mTYGFFt1r8LTUR', '6mQmSGzvyAeSpp5E7rBcYyAwgim9pTdggDXwL4quw8HA'], 'ledgerId': 0} since Inconsistency: first root hash does not match. Expected hash: b'e5d008ade2ffe0debf65d1d018bad655a8758d00223ee1299f15041bd6355fd2', computed hash: b'a0bd5c80d48d2069a27489bcdf2ac6b2bfb89ed4cb4348361875c6336c5a65e9'
{code}
 

*Expected Results:*
 Error should not appear, pool should work.

*Additional Information:*
 * pool_ledger file:

{code:java}
{""data"":{""alias"":""Node1"",""client_ip"":""10.0.0.2"",""client_port"":9702,""node_ip"":""10.0.0.2"",""node_port"":9701,""services"":[""VALIDATOR""]},""dest"":""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"",""identifier"":""Th7MpTaRZVRYnPiabds81Y"",""txnId"":""fea82e10e894419fe2bea7d96296a6d46f50f93f9eeda954ec461b2ed2950b62"",""type"":""0""}
{""data"":{""alias"":""Node2"",""client_ip"":""10.0.0.3"",""client_port"":9704,""node_ip"":""10.0.0.3"",""node_port"":9703,""services"":[""VALIDATOR""]},""dest"":""8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb"",""identifier"":""EbP4aYNeTHL6q385GuVpRV"",""txnId"":""1ac8aece2a18ced660fef8694b61aac3af08ba875ce3026a160acbc3a3af35fc"",""type"":""0""}
{""data"":{""alias"":""Node3"",""client_ip"":""10.0.0.4"",""client_port"":9706,""node_ip"":""10.0.0.4"",""node_port"":9705,""services"":[""VALIDATOR""]},""dest"":""DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya"",""identifier"":""4cU41vWW82ArfxJxHkzXPG"",""txnId"":""7e9f355dffa78ed24668f0e0e369fd8c224076571c51e2ea8be5f26479edebe4"",""type"":""0""}
{""data"":{""alias"":""Node4"",""client_ip"":""10.0.0.5"",""client_port"":9708,""node_ip"":""10.0.0.5"",""node_port"":9707,""services"":[""VALIDATOR""]},""dest"":""4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA"",""identifier"":""TWwCRQRZ2ZHMJFn9TzLp7W"",""txnId"":""aa5e817d7cc626170eca175822029339a444eb0ee8f0bd20d3b0b76e566fb008"",""type"":""0""}
{""data"":{""alias"":""Node5"",""client_ip"":""10.0.0.6"",""client_port"":9702,""node_ip"":""10.0.0.6"",""node_port"":9701,""services"":[""VALIDATOR""]},""dest"":""4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc"",""identifier"":""XhYtvJqezMUKfF6KVNaGmT"",""reqId"":1500466694263116,""signature"":""3F6YEvZRGWY8DeYKJGykJjL4LhsidxWPCWjqQYd7mLTQQCfB9NkYycxf6cfEe46buA3773htHSSFCHd8BuGoVg9Q"",""txnTime"":1500466694,""type"":""0""}
{""data"":{""alias"":""Node5"",""services"":[]},""dest"":""4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc"",""identifier"":""V4SGRU86Z58d6TV7PBUe6f"",""reqId"":1500467102695168,""signature"":""4vcbkSwr2ppBY1jn5QEzNmADQ6KJX7eYnyTw9hcjUkDqK4LfUvFcHzKfioZRuiT5h4DLqNJ6LihY23Grc3Ut7CGM"",""txnTime"":1500467102,""type"":""0""}
{""data"":{""alias"":""Node5"",""client_ip"":""10.0.0.6"",""client_port"":9702,""node_ip"":""10.0.0.6"",""node_port"":9701,""services"":[""VALIDATOR""]},""dest"":""4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc"",""identifier"":""V4SGRU86Z58d6TV7PBUe6f"",""reqId"":1500467708380544,""signature"":""58bcdLHdmq66Hd4NWWhUNjVNq6WuTWzUseKMhtSa3p9xR5rS6UGFoF3YGfqMHRwhUuRzTUJ8dbrXpVhfaCGsxNjy"",""txnTime"":1500467708,""type"":""0""}
{""data"":{""alias"":""Node5"",""client_ip"":""10.0.0.7"",""client_port"":9702,""node_ip"":""10.0.0.7"",""node_port"":9701,""services"":[""VALIDATOR""]},""dest"":""4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc"",""identifier"":""XhYtvJqezMUKfF6KVNaGmT"",""reqId"":1500467756471212,""signature"":""259eWdbRVzLUqmFMZ5xvjxJs6eGKwF5TYBJTADpXzg3aTy5SwAgsnQCnugrYTLN9GDzMjgRzqc78ZzZuVVdgA1WY"",""txnTime"":1500467756,""type"":""0""}{code}
 *  Logs of 7 nodes are attached, but Node 7 was used only for invalid case and it was not connected to the pool.","Build Info:
  indy-anoncreds 0.4.18
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
  indy-plenum 0.4.61
  indy-node 0.4.46
  sovrin 0.2.10
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4+2 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jul/17 9:51 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11731/Node1.log","20/Jul/17 9:51 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11732/Node2.log","20/Jul/17 9:51 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11733/Node3.log","20/Jul/17 9:51 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11734/Node4.log","20/Jul/17 9:51 PM;ozheregelya;Node5.log;https://jira.hyperledger.org/secure/attachment/11735/Node5.log","20/Jul/17 9:51 PM;ozheregelya;Node6.log;https://jira.hyperledger.org/secure/attachment/11736/Node6.log","20/Jul/17 9:51 PM;ozheregelya;Node7.log;https://jira.hyperledger.org/secure/attachment/11737/Node7.log","20/Jul/17 9:51 PM;ozheregelya;cli.log;https://jira.hyperledger.org/secure/attachment/11730/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx0t3:",,,,,,14,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 7:56 PM;ozheregelya;Similar problem was explored before. Problem is in wrong genesis files on client. See more details in INDY-797 and INDY-802.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""abbr"" parameter in ""new identifier"" command is recognized as identifier",INDY-445,19379,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ozheregelya,ozheregelya,20/Jul/17 9:29 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,6Months,KEEP,,,,"*Steps to Reproduce:*
 # Open the CLI.
 # Run the command ""new identifier abbr""

*Actual Results:*
{code:java}
sovrin@test> help new identifier
new identifier
--------------
 title: Creates new Identifier
usage: new identifier [<identifier>|abbr|crypto] [with seed <seed>] [as <alias>]
note: crypto = cryptographic identifier, abbr = abbreviated verkey
example(s):
 new identifier
 new identifier abbr
 new identifier 4QxzWk3ajdnEA37NdNU5Kt
 new identifier with seed aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa
 new identifier abbr with seed aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa
 new identifier 4QxzWk3ajdnEA37NdNU5Kt with seed aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa
sovrin@test> new identifier abbr
Identifier created in keyring Default-dd49d5
New identifier is abbr
New verification key is EQBJ8w79aQbiC3LtGoNWB5NoZ9dDUVceiCGp5BTYMDJo
Current identifier set to abbr
{code}
*Expected Results:*
 abbr parameter should work or it should be removed from help. ","Build Info:
   indy-anoncreds 0.4.18
   python3-rlp 0.5.1
   python3-sha3 0.2.1
   python3-pyzmq 16.0.2
   indy-plenum 0.4.61
   indy-node 0.4.46
   sovrin 0.2.10
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-785,,,,,,,,,,"1|hzy133:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,Toktar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 10:04 PM;Toktar;This CLI is deprecated now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node promotion failed if pool is restarted and the primary node does not start.,INDY-446,19397,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,slafranca,slafranca,21/Jul/17 7:26 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,sprint11-goal-release,,,,,"I have 7 nodes, the primary node is node 1, backup nodes are node 2 and 3.  I simultaneously turned the sovrin service off on all 7 nodes.

I started the sovrin service for the nodes in reverse order.  The service started for nodes 7,6,5,4,3.  {color:#205081}The sovrin service is running on nodes 3-7{color} 

When I look at the log to see which node is the primary node, it still says {color:#14892c}node 1 is the primary{color} with node 2 and 3 as the backup.  I waited a few minutes to see if the nodes would promote a new primary node since nodes 1 and 2 are offline.  They did not.  I sent a NYM transaction to the pool, waited a few minutes and checked the log again to see if a new primary node was promoted.  The primary node was still set to 1, with a backup of 2 and 3 and the NYM transaction did not get processed.  At this point, {color:#205081}the sovrin service is running on nodes 3-7{color}.

I started the service on node 2 and sent another transaction after waiting for a few minutes for the node to come back online.  The primary node is still set to 1.  {color:#205081}The sovrin service is running on nodes 2-7{color}.

I started the sovrin service on node 1.  As soon as the sovrin service came online for node 1, the NYM transactions were processed and the primary node was node 1.  {color:#205081}The sovrin service is running on all 7 nodes{color}.

*Expected results:*
When I started the last five nodes, I expected the nodes to start the process of promoting a new primary node with 2 backup nodes.  ",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Aug/17 11:52 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11937/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyddj:",,,,,,11,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Aug/17 10:24 PM;ashcherbakov;PR: https://github.com/hyperledger/indy-plenum/pull/345;;;","23/Aug/17 9:22 PM;alexander.shekhovcov;(/) *Resolved:*
https://github.com/hyperledger/indy-plenum/pull/353
Had to create a new PR because I did not have a write permissions for PR 345

*How to test:*
See description.;;;","24/Aug/17 11:43 PM;VladimirWork;Build Info:
indy-node 1.0.115

Steps to Validate:
1. Create and run a new pool (with 1st node as primary).
2. Stop all nodes simultaneously.
3. Start nodes from 7th to 3rd successively.

Actual Results:
Pool reaches consensus normally. New primary is promoted normally. Following view changes works normally.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
During view change former primary node stopped taking any transactions,INDY-447,19398,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,,krw910,krw910,21/Jul/17 7:34 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,ViewChange,,,,,"While running a load test of 2,000 transactions a view change happened. The former primary node stopped receiving transactions from that point forward and did not perform a catch up.

*Setup*
4 Nodes (separate physical machines)
4 Clients (separate physical machines)

*Run the load scripts*
python3 add_keys.py Steward1 000000000000000000000000Steward1

At this point I had 210 transactions

*Run from each client 500 at once*
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once

I should have ended up with 2,210 transactions after it was done. Some how Nodes 1, 3, 4 ended up with 2408 and Node 2 had 2110

Node1: 2408
Node2: 2110
Node3: 2408
Node4: 2408

*{color:#d04437}Issue{color}*
Node2 did not catch up. 
After checking the logs I see that at UTC 22:12:45 a view change happened where the master switched from Node2 to Node3. Now that we have time stamps in the ledger for transactions I was able to run it through the converter and see the last transaction on Node2 occurred at 22:12:48

After the test was over I started the CLI and sent a single transaction. Nodes 1,3,4 all received the transaction. Node2 will not take any new transactions.
",,,,,,,,,,,INDY-734,,,,,,,,,,,,,,,,,,,,,,,,"21/Aug/17 4:52 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11906/Node1.log","21/Aug/17 4:52 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11907/Node2.log","21/Aug/17 4:52 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11908/Node3.log","21/Aug/17 4:52 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11909/Node4.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzye8v:",,,,,,11,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Aug/17 8:18 PM;alexander.shekhovcov;[~krw910] Do we still have the logs?;;;","18/Aug/17 2:00 AM;ashcherbakov;[~krw910] any logs? I will assign this task to QA for a time being, let's try to reproduce it.;;;","21/Aug/17 4:52 PM;ozheregelya;*Build Info:*
   indy-node 1.0.67
   indy-anoncreds 1.0.22
   indy-plenum 1.0.77
   sovrin 1.0.23
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 4 nodes, 4 clients

Load test was ran on 4 clients with following command on each of clients:
{code:java}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once{code}
View change was happened at 13:33:54,076:
{code:java}
root@999bea1e428c:/home/sovrin# grep ""selected primary"" .sovrin/Node1.log*
.sovrin/Node1.log.2017-08-18:2017-08-18 11:40:59,831 | DISPLAY | primary_selector.py ( 284) | _startSelection | Node1:0 selected primary Node1:0 for instance 0 (view 0)
.sovrin/Node1.log.2017-08-18:2017-08-18 11:40:59,832 | DISPLAY | primary_selector.py ( 284) | _startSelection | Node1:1 selected primary Node2:1 for instance 1 (view 0)
.sovrin/Node1.log.2017-08-18:2017-08-18 13:33:54,076 | DISPLAY | primary_selector.py ( 284) | _startSelection | Node1:0 selected primary Node2:0 for instance 0 (view 1)
.sovrin/Node1.log.2017-08-18:2017-08-18 13:33:54,097 | DISPLAY | primary_selector.py ( 284) | _startSelection | Node1:1 selected primary Node3:1 for instance 1 (view 1){code}
But taking transactions was stopped on all nodes:
{code:java}
root@999bea1e428c:/home/sovrin# wc -l .sovrin/data/nodes/Node1/transactions_sandbox/1
1000 .sovrin/data/nodes/Node1/transactions_sandbox/1
---------------------------------------------------------------------------
root@c9e086cb2bc2:/home/sovrin# wc -l .sovrin/data/nodes/Node2/transactions_sandbox/1
1000 .sovrin/data/nodes/Node2/transactions_sandbox/1
---------------------------------------------------------------------------
root@4bfa5d8ff9eb:/home/sovrin# wc -l .sovrin/data/nodes/Node3/transactions_sandbox/1
1000 .sovrin/data/nodes/Node3/transactions_sandbox/1
---------------------------------------------------------------------------
root@1dd896e0e77b:/home/sovrin# wc -l .sovrin/data/nodes/Node4/transactions_sandbox/1
1000 .sovrin/data/nodes/Node4/transactions_sandbox/1{code}
Last update of transactions file was happened about the same time as view change:
{code:java}
root@999bea1e428c:/home/sovrin# ll .sovrin/data/nodes/Node1/transactions_sandbox/ 
total 268
drwxr-xr-x 2 sovrin sovrin 4096 Aug 18 13:34 ./
drwxr-xr-x 13 sovrin sovrin 4096 Aug 18 11:40 ../
-rw-r--r-- 1 sovrin sovrin 197648 Aug 18 13:34 1
-rw-r--r-- 1 sovrin sovrin 54378 Aug 18 13:34 1001{code}
So, it looks like the issue is still reproduces. Here are logs:
 [^Node1.log] [^Node2.log] [^Node3.log] [^Node4.log];;;","21/Aug/17 8:45 PM;alexander.shekhovcov;We've discussed with [~ozheregelya] that additional testing is required because there is no any issues in the logs.;;;","21/Aug/17 11:53 PM;ozheregelya;After second reproducing: 
- transactions count is the same on all nodes (so initial problem is not reproduces as is)
- one of ran load_test.py was stopped to process transactions (so, it will be better to wait for fix of INDY-734 and verify on the latest build).;;;","23/Aug/17 9:33 PM;ozheregelya;*Build Info:*
  indy-node 1.0.113
  indy-anoncreds 1.0.25
  indy-plenum 1.0.97
  sovrin 1.0.24
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 4 clients

Load test was ran on 4 clients with following command on each of clients:
{code:java}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once{code}
View change was happened:
{code:java}
root@1e452dd36ee0:/home/sovrin# tail -f .sovrin/Node2.log | grep ""selected primary""
2017-08-23 11:46:00,733 | DISPLAY | primary_selector.py ( 283) | _startSelection | PRIMARY ELECTION: Node2:0 selected primary Node3:0 for instance 0 (view 2)
2017-08-23 11:46:00,736 | DISPLAY | primary_selector.py ( 283) | _startSelection | PRIMARY ELECTION: Node2:1 selected primary Node4:1 for instance 1 (view 2)
{code}
 

Count of transactions is the same on all nodes:

Node 1
{code:java}
sovrin@759ef71009df:~$ read_ledger --type=pool --count
4
sovrin@759ef71009df:~$ read_ledger --type=domain --count
2887
sovrin@759ef71009df:~$ read_ledger --type=config --count
0{code}
Node 2
{code:java}
sovrin@1e452dd36ee0:~$ read_ledger --type=pool --count
4
sovrin@1e452dd36ee0:~$ read_ledger --type=domain --count
2887
sovrin@1e452dd36ee0:~$ read_ledger --type=config --count
0{code}
Node 3
{code:java}
sovrin@24d46a3d82f8:~$ read_ledger --type=pool --count
4
sovrin@24d46a3d82f8:~$ read_ledger --type=domain --count
2887
sovrin@24d46a3d82f8:~$ read_ledger --type=config --count
0{code}
Node 4
{code:java}
sovrin@b555996955b7:~$ read_ledger --type=pool --count
4
sovrin@b555996955b7:~$ read_ledger --type=domain --count
2887
sovrin@b555996955b7:~$ read_ledger --type=config --count
0{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GET_NYM returns incorrect result for 32-byte identifiers,INDY-448,19407,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid: Works as Expected,,ozheregelya,ozheregelya,21/Jul/17 7:46 PM,13/Nov/19 11:50 PM,28/Oct/23 2:46 AM,13/Nov/19 11:50 PM,,,,,0,5Months,,,,,"*Steps to Reproduce:*
 # Open the CLI.
 # As Trustee or any other role with necessary permissions send command:
 send NYM dest=W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv999
 # Send command 
 send GET_NYM dest=W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv999

*Actual Results:*
 Following result returned:
{code:java}
Current verkey is same as identifier W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv999{code}
*Expected Results:*
 Following result should be returned:
{code:java}
No verkey ever assigned to the identifier W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv999{code}
*Additional Information:*

Here is transactions file:
{code:java}
||||1|V4SGRU86Z58d6TV7PBUe6f|~CoRER63DVYnWZtK8uAzNbx||||||0||
V4SGRU86Z58d6TV7PBUe6f||||1|Th7MpTaRZVRYnPiabds81Y|~7TYfekw4GUagBnBVCqPjiC||||||2||
V4SGRU86Z58d6TV7PBUe6f||||1|EbP4aYNeTHL6q385GuVpRV|~RHGNtfvkgPEUQzQNtNxLNu||||||2||
V4SGRU86Z58d6TV7PBUe6f||||1|4cU41vWW82ArfxJxHkzXPG|~EMoPA6HrpiExVihsVfxD3H||||||2||
V4SGRU86Z58d6TV7PBUe6f||||1|TWwCRQRZ2ZHMJFn9TzLp7W|~UhP7K35SAXbix1kCQV4Upx||||||2||
V4SGRU86Z58d6TV7PBUe6f||||1|7JhapNNMLnwkbiC2ZmPZSE|~LgpYPrzkB6awcHMTPZ9TVn||||||||
Th7MpTaRZVRYnPiabds81Y|1500558332385065|2qsX8mt6cgLJNdhHZ93HU4P9nC95TdA7ZPKHCissHXAURDhdzZhtw6rTWh18D62efyoNg542McyUwN7gMAgMhYRZ|1500558332|1|RrTkY1dPvpxJShvtHoPe8Y|~MKpejEBYGxdQzHRZ1CZk1Z||||||||
RrTkY1dPvpxJShvtHoPe8Y|1500559298686229|59a8PsivEnAc6KZ7yyq2ftN3sTYBUnYaqGhm1gZRvDxX6vSvSqpZDjhkmCSoemdToPzSdECNSFbyCe9A7gXZehPc|1500559298|1|RrTkY1dPvpxJShvtHoPe8Y|8141LM6L6Lm3XXB76sGVDuBE5q8w94WLZBkRBkTZ2NTP||||||||
RrTkY1dPvpxJShvtHoPe8Y|1500559769713363|4pMLbHGEuUSZQoeiN7BiT9w41WjQ25Lym3dDS5ktWf9qAVPicrNXZ6Vwdc1U2Qp9Dou1iXrLqfPMVgsycHbYB56H|1500559769|1|RrTkY1dPvpxJShvtHoPe8Y|7DraUMinVb67g6uMxio955u7MSBSKKSMzfUoUxZCQYRK||||||||
Th7MpTaRZVRYnPiabds81Y|1500561721619998|4gwd5rTAPvWa8xLuVV7WCn91iCvbztzMgyBpZTVRSeR5iE3Yw1S856HV2ehbuPRhHX3kv2SYfxz77cmL5QqEhBNB|1500561721|1|VWWqQERPa2LHGY86UNJKWY|||||||||
Th7MpTaRZVRYnPiabds81Y|1500561976072049|3BX2N8WiYzneYguE3f9zPVJJkpPG9bAu7pyWYoJWLy1Kn9pQZLrkbJzJXe9do2ZNwhLyMG3Tmd62adyuoVtPbv9u|1500561976|1|VWWqQERPa2LHGY86UNJKWY|4qvUoW4yGSpqxjjGLWtZETngiHT5JoGA5pSq8uwFqcA7||||||||
VWWqQERPa2LHGY86UNJKWY|1500561988523410|5EHM7wSqZWCij9QYXQqrFeAs9RmyPHAoMRP899t5cNpk4HMB9cM4MNMQooP8L5YyCASfrPEfyuH7bNpsPte8hmUd|1500561988|1|VWWqQERPa2LHGY86UNJKWY|||||||||
Th7MpTaRZVRYnPiabds81Y|1500568279362189|3JfjA5Dz66qLTo7ozxokAEnsAjcCCWZyWkBaCe11kRCnpKPqomE5Pwzc4jtb8YD3wdBTZVh84A4fTrZ6QjPGbRH4|1500568279|1|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A|||||||||
V4SGRU86Z58d6TV7PBUe6f|1500568361305289|2zW4ouSgvcwcwfKTyWnBwVY2cWCSvtnt5ggGD9653GjBaraQaq8r2Hbd3wva4zzsFCf9zdtsd1jVofnwPHhbd1rs|1500568361|1|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A|||||||0||
Th7MpTaRZVRYnPiabds81Y|1500568442641013|wGUoFSdZ3AJTn9abTJB3vaW5R5g2sqoAiEyR38eoPA9aNXwRtqcuRzBCUDks4E5MEK8JCFkC4o5B4gjn1mj4VP8|1500568442|1|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A||||||||
W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A|1500568452134573|3aJr54MFsCvAu3b78uzS3xsKNHdHxyAXmXtgqEyqThGqR64J28nNicSTPufFyN9c5JoYgkR4RQ9TSGu1E6sy661E|1500568452|1|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv851|||||||||
Th7MpTaRZVRYnPiabds81Y|1500633526998862|3qe1Uay5nthHe2jFTrAr7GiyMZUiZeko5mLtfRewnuAbjRXv4BGDyDF4LxhLgnkYc69599iJGYydZtEBcqpVste7|1500633527|1|W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv999|||||||||
Th7MpTaRZVRYnPiabds81Y|1500633919216149|3FADUPQd4iQTuht1uzuYLkDCPQJBUVfyiMdS9Geot1Vz6AibNPMSV8FCppmwDDZ6PaFPG3uytpx771bK3vfoFFzF|1500633919|1|Hh6q3aMwJ7xtk7CHusCk9R|||||||||{code}
There is no verkey for W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv999.

 ","Build Info:
  indy-node 0.4.52
  indy-anoncreds 0.4.18
  indy-plenum 0.4.64
  sovrin 0.2.10
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,INDY-213,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx14n:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jul/17 8:17 PM;ozheregelya;[~stevetolman], [~devin-fisher], [~danielhardman], [~krw910]
As far as I understand, logic with cryptonyms was deprecated, but user is still able to create 32-byte identifier (e.g. using command ""new identifier W6CUN1QHTpYa2HxxJ7aRP4aLfi8cx8AJ6cFvY9pv85A"" or something like this), send NYM still support sending 32-byte identifiers and 32-byte identifier are still present in help (e.g. ""help send NYM""). Is it ok?

[~ashcherbakov], FYI.;;;","15/Jan/18 12:40 PM;krw910;[~ozheregelya] Is this still an issue since the one it is linked to is done?;;;","13/Nov/19 11:50 PM;esplinr;Even though we prefer using DIDs in Nyms, there are no negative consequences to being able to use a cryptonym in a transaction. We don't think it is worth removing this feature, so we will focus on other things.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"There is no validation for identifier in ""new identifier"" command",INDY-449,19408,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,ozheregelya,ozheregelya,21/Jul/17 9:02 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,5Months,,,,,"*Steps to Reproduce:*
 # Open the CLI.
 # Type command ""new ideinfier abcde"" (or ""new ideinfier 000000"").
=> no errors, identifier successfully created.
 # Try to send NYM with this identifier as Trustee:
send NYM dest=abcde (or send NYM dest=000000)

*Actual Results:*
Identifier created without any errors, but sending NYM with this identifier is impossible:
{code:java}
Error: client request invalid: InvalidClientRequest('validation error [ClientNYMOperation]: b58 decoded value length 4 should be one of [16, 32] (dest=abcde)',){code}
{code:java}
Error: client request invalid: InvalidClientRequest(""validation error [ClientNYMOperation]: should not contain the following chars ['0'] (dest=000000)"",){code}
*Expected Results:*
Identifier in ""send identifier"" command should be validated same as in ""send NYM"" command.","Build Info:
  indy-node 0.4.52
  indy-anoncreds 0.4.18
  indy-plenum 0.4.64
  sovrin 0.2.10
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzwzbb:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/18 6:05 AM;spivachuk;This bug relates to the old CLI (not libindy-based one). So it is not relevant anymore.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
make send NYM during pool upgrade more robust,INDY-450,19414,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,danielhardman,danielhardman,22/Jul/17 1:07 AM,11/Oct/19 7:03 PM,28/Oct/23 2:46 AM,11/Oct/19 7:03 PM,,,,,0,5Months,,,,,This ticket captures some work to make the send NYM command more robust during pool upgrade. It is a follow-up to INDY-289. Please see [~ashcherbakov]'s final comment in that ticket for an explanation of what additional work should be done.,,,,,,,,,,,,,,,,,,,,,,,INDY-289,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx17r:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 7:03 PM;esplinr;Pool upgrades in the current releases of Indy node appear to be sufficiently robust.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
upgrade_log is uninformative in some cases,INDY-451,19416,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,stevetolman,ozheregelya,ozheregelya,22/Jul/17 1:43 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,,,,," 

*Case 1:*

*Steps to Reproduce:*
 # Send POOL_UPGRADE command:

{code:java}
send POOL_UPGRADE name=upgrade-oz1 version=0.4.55 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-07-21T15:30:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-07-21T15:35:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-07-21T15:40:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-07-21T15:45:00.000000+00:00'} timeout=10{code}
 

 # Check the upgrade_log files on all nodes after completion of all upgrades.

*Actual Results:*
{code:java}
root@6c959b21839a:/home/sovrin# cat .sovrin/data/nodes/Node2/upgrade_log 
2017-07-21 15:02:33.693157	scheduled	2017-07-21 15:35:00+00:00 0.4.55
2017-07-21 15:30:27.027529	scheduled	2017-07-21 15:35:00+00:00 0.4.55
2017-07-21 15:34:59.030581	scheduled	2017-07-21 15:35:00+00:00 0.4.55
2017-07-21 15:34:59.696508	scheduled	2017-07-21 15:35:00+00:00 0.4.55
2017-07-21 15:35:30.848809	succeeded	2017-07-21 15:35:00+00:00 0.4.55
{code}
{code:java}
root@c0ecf5b26ddb:/home/sovrin# cat .sovrin/data/nodes/Node3/upgrade_log 
2017-07-21 15:02:33.750770	scheduled	2017-07-21 15:40:00+00:00 0.4.55
2017-07-21 15:30:27.031118	scheduled	2017-07-21 15:40:00+00:00 0.4.55
2017-07-21 15:35:26.711642	scheduled	2017-07-21 15:40:00+00:00 0.4.55
2017-07-21 15:39:59.042298	scheduled	2017-07-21 15:40:00+00:00 0.4.55
2017-07-21 15:39:59.716344	scheduled	2017-07-21 15:40:00+00:00 0.4.55
2017-07-21 15:39:59.801772	scheduled	2017-07-21 15:40:00+00:00 0.4.55
2017-07-21 15:40:45.088748	succeeded	2017-07-21 15:40:00+00:00 0.4.55{code}
""scheduled"" record appears in each upgrade_log. 

*Expected Results:*
""scheduled"" record should appear only once in each upgrade_log.

*Case 2:*
Also situation with adding new upgrades to upgrade_log is unclear. Looks like new upgrades are not written in upgrade_log tool long. But this case needs additional testing.

 ","Build Info:
  indy-node 0.4.46
  indy-anoncreds 0.4.18
  indy-plenum 0.4.61
  sovrin 0.2.10
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx14v:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 6:53 PM;VladimirWork;Both cases are fixed:
- each pool upgrade command writes in upgrade log two entries: `scheduled` and `succeeded` or `failed` or `cancelled`
- new pool upgrade command cancels the previous;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Discard PrePrepare in readonly mode,INDY-452,19428,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,dsurnin,dsurnin,22/Jul/17 6:30 PM,19/Nov/19 4:13 AM,28/Oct/23 2:46 AM,18/Nov/19 9:04 PM,,,,,0,5Months,,,,,"In readonly mode all PrePrepare  should be discarded

except PrePrepares for the config ledger",,,,,,,,,,,,,,,,,,,,,,,INDY-360,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzx19z:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,dsurnin,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Nov/19 9:04 PM;ashcherbakov;[~esplinr]
Currently all in a read-only mode Nodes reject all requests from clients.
However, if a (malicious) Primary sends a Batch with requests to be ordered, it will be ordered. Freshness batches will be ordered as well.

Since the main purpose of a ""big red button"" (INDY-360) as a protection against external attacks (from the clients mostly) has been implemented, and the chances of malicious Primary doing this kind of attacks mentioned above are pretty low, we are going to Won't Do the ticket.
If there is a malicious Primary doing DDoS attack, we can detect and prevent it by other means as well (whitelisting, firewall protection, etc.) even more efficiently then pushing a big red button. With a firewall rule we can exclude (block) just the malicious primary, so that view change happens and the pool will be able to continue ordering, while the Big Red button will prevent the whole pool from ordering regardless of who is the Primary. Also the read only state will not prevent DDoS by just PrePrepares (even though they will be discarded, they still be sent). ;;;","19/Nov/19 4:13 AM;esplinr;I agree with this analysis.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Intermittently failing testPrimaryRecvs3PhaseMessageOutsideWatermarks,INDY-453,19442,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,mzk-vct,mzk-vct,24/Jul/17 9:03 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Test testPrimaryRecvs3PhaseMessageOutsideWatermarks in Plenum fails intermittently.

 Log file attached.",,,,,,,,,,,,,,,,,,,,,,INDY-462,,,,,,,,,,,,,"24/Jul/17 9:04 PM;mzk-vct;fail.7z;https://jira.hyperledger.org/secure/attachment/11758/fail.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzycgf:",,,,,,10,,,,,,,,,,,,,,,,,,,,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node stops the catchup procedure if gets f+1 old LedgerStatus,INDY-454,19443,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,24/Jul/17 9:46 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"During testing INDY-246 we found what a node stops the catchup procedure  if gets f+1 old LedgerStatus.

{quote}
My findings:
the pool is broken because not only Node2 and Node9 crashed with KeyError but at least Node6 and Node7 crashed too
Node6, Node7 (and maybe some others) finished catchup successfully
Node2, Node9 did not finished catchup because they got enough ledger status messages from others crashed nodes and they stopped their catchup
I am working on solution which increases the quorum for LedgerStatus messages.
https://github.com/hyperledger/indy-plenum/pull/299{quote}

We had to create this ticket because the issue does not related with INDY-246.
",,,,,,,,,,,,,,,,,,,,,,,INDY-246,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8dz:",,,,,,H5,M1 Prelude,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jul/17 10:09 PM;alexander.shekhovcov;(/)
*Problem reason:*
- a node may get f+1 old LedgerStatus before new ones and stop the catchup procedure

*Changes:*
- set LedgerStatus quorum N-f-1

Committed into: 
indy-node 0.4.60+
https://github.com/hyperledger/indy-plenum/commit/659d503252136e3a516ad4c85ac3373e5d261742

*Risk factors:*
 Nothing is expected.

*Risk:*
 Low

*Covered with tests:*
test_ledger_status_quorum

*Recommendations for QA:*
Testing the ticket is rather complicated. A pool should be in state when f+2 node have an old state whereas n-f-2 have a new state. But n-f-2 is below required consensus so n-f-2 nodes cannot process requests. 
In INDY-246 we got such a state in the result of crashes f+2 nodes between some txns had quorum and were persistent in to a local ledger. 
After we get pool in required state some node should get f+1 old LedgerStatus messages from another crashed f+1 before new ones.

Looks like we have to alter f+2 nodes code in a pool in order to crash nodes and then alter node's code which will skip new LedgerStatus and receive only old LedgerStatus and check  if the node does not synced. 

Let's think how we can test it simpler.;;;","25/Jul/17 12:44 AM;krw910;I have a pool that I think is in that state now. I will upgrade the pool and see what happens.;;;","27/Jul/17 12:32 AM;krw910;This appears to be working. I ran from the same pool I had before. I had two nodes already working on catch up. During the test I had another two get out of sync. One got back in sync so the pool could keep going and the other started catching up. The first two nodes are far enough behind that they were not able to catch up by the end of the test. We still have issues in this area, but this ticket is fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A primary may not be able to send checkpoints after re-start,INDY-455,19451,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,ashcherbakov,ashcherbakov,25/Jul/17 4:08 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,Stability,,,,,"If a Primary is re-started,  and the view is not changed, then the Primary may not be able to send checkpoints correctly.

How to reproduce:
- Have 3 nodes
- Stop the Primary
- Re-start the Primary. Since we had only 2 active nodes, view is not changed (not enough InstanceChange for consensus)
- Start sending txns

The re-started Primary is able to send txns due to the fix in INDY-334, but checkpoint logic may be broken since it would have lost checkpoints. Also h and H should be set accordingly.
",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,INDY-334,,,,,,,,,,,,"21/Aug/17 4:53 PM;VladimirWork;1.PNG;https://jira.hyperledger.org/secure/attachment/11911/1.PNG","21/Aug/17 4:53 PM;VladimirWork;2.PNG;https://jira.hyperledger.org/secure/attachment/11910/2.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzye7r:",,,,,,10,11,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Aug/17 7:46 PM;alexander.shekhovcov;(/) *Case:*
The primary replica crashes and completely looses its checkpoint context (array of `checkpoints` and watermark). After the replica is connected back the view is not changed (not enough InstanceChange for consensus or some other reason) so the replica stays the primary. In this case the replica stashes requests because the watermark is reseted. 
*The solution:*
Set `h` (watermark) on propagate primary done.
Unfortunately, it won't recover a backup replica but pool works well with this solution. Backup replica will stash 3pc messages until the next view change.
https://github.com/hyperledger/indy-plenum/pull/337

(i) *How to test:*
* Have 3 nodes
* Stop the Primary
* Re-start the Primary. Since we had only 2 active nodes, view is not changed (not enough InstanceChange for consensus)
* Start sending txns


;;;","21/Aug/17 4:54 PM;VladimirWork;Build Info:
indy-node 1.0.112

Steps to Validate:
1. Have 3 nodes.
2. Stop the Primary.
3. Start the Primary.
4. Start sending txns.

Actual Results:
View is not changed after Step 3. !2.PNG|thumbnail! 
Txn sending works normally after Step 4. !1.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
write release notes,INDY-456,19456,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,danielhardman,danielhardman,25/Jul/17 6:18 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Please identify the features that are supported and  known issues that should be shared with the community. Once these are identified, let's review them and then send the ticket to Misty for word smithing, etc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8e7:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,danielhardman,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jul/17 9:35 AM;TechWritingWhiz;This file is complete and submitted. The Pull Request is here: 

[https://github.com/sovrin-foundation/sovrin/pull/8]

 ;;;","31/Jul/17 8:26 PM;TechWritingWhiz;This has been merged.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Modify/Update remaining terminology changes,INDY-457,19459,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,mark.hadley,mark.hadley,25/Jul/17 9:02 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"indy-node still has some changes that need to be implemented to update the terminology.

These include, Link.py, (including the link attribute).  Wallet.py has many reference to a link, as well.

Many tests need their file names changed.

Rename invitation files (_faber-invitation.sovrin, etc.)_ 

_Also see INDY-440 for 'getting started guide' changes._

 ",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybmf:",,,,,,M1 Prelude,10,,,,,,,,,,,,,,,,,,,krw910,mark.hadley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jul/17 3:49 AM;mark.hadley;[https://github.com/hyperledger/indy-plenum/pull/315]

This plenum PR will break the indy-node/sovrin_client tests until the assocaited PR for indy-node is merged. 

https://github.com/hyperledger/indy-node/pull/268;;;","03/Aug/17 4:25 AM;krw910;I double checked the code changes and reopened INDY-440 to update the Getting Started Guide with the final changes from this ticket.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nodeRequestSpike triggers far too often,INDY-458,19470,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Duplicate,spivachuk,danielhardman,danielhardman,25/Jul/17 11:00 PM,18/Nov/19 10:45 PM,28/Oct/23 2:46 AM,18/Nov/19 10:45 PM,,,,,0,5Months,,,,,"We have a simple anomaly detector in Sovrin. It fires on several events, one of which is nodeRequestSpike. This event doesn't handle the transition from idle well enough; it is constantly firing. I suggest that we make it less sensitive as throughput nears zero, and more sensitive when throughput is significant enough that we can reason about changes being ""large"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzx0rr:",,,,,,14,,,,,,,,2.0,,,,,,,,,,,,ashcherbakov,danielhardman,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/17 12:39 AM;krw910;Moving this into sprint 14 at the request of Daniel. This is based off a discussion on a upgrade issue that occurred.;;;","18/Nov/19 10:45 PM;ashcherbakov;Has been done in the scope of https://jira.hyperledger.org/browse/INDY-1251;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TGB Role should not be able to put pool in read only mode,INDY-459,19502,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,stevetolman,krw910,krw910,27/Jul/17 1:29 AM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,5Months,,,,,"The new CLI command to put the pool in ready only mode should only be available to a Trustee. Currently someone with the TGB role can also put the pool into ready only mode. No other roles are able to perform this function.

*Steps*
As a Trustee create a TGB role
new key with seed 000000000000000000000000Trustee1
send NYM dest=REWXKnFCpiLBn3iQwaBs6g role=TGB verkey=~4KnG5Q3iKCUSyg6F5hRze1

*Set yourself as the TGB signer*
new key with seed TestTGB1000000000000000000000000

*Send commands to set pool to read only mode and back again*
send POOL_CONFIG writes=False
or
send POOL_CONFIG writes=True


*{color:#d04437}Issue{color}*
Only a Trustee should be able to perform this command
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1fr:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Sep/17 6:13 AM;krw910;This goes away when INDY-798 is fixed.;;;","04/Jan/18 4:29 AM;ozheregelya;Moved to won't fix because of INDY-798.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CLI command to ""list wallets"" does not autofill",INDY-460,19503,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,krw910,krw910,27/Jul/17 2:39 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,,,,,"*Start the CLI*
sovrin
connect test
new wallet mywallet
list wallets

*{color:#d04437}Issue{color}*
The list command only shows ""ids, claims, and connections"" as possible commands. The ""list wallets"" command is not listed, but does work.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-783,,,,,,,,,,"1|hzy147:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 9:29 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Intermittently failing test: testPrimaryRecvs3PhaseMessageOutsideWatermarks,INDY-462,19526,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,ashcherbakov,ashcherbakov,27/Jul/17 9:28 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-309/1/,,,,,,,,,,,,,,,,,,,,,INDY-453,,,,,,INDY-1021,,,,,,,,"03/Aug/17 12:58 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11812/Screenshot.PNG","31/Jul/17 10:15 PM;ashcherbakov;test-result-plenum.ubuntu-06.txt;https://jira.hyperledger.org/secure/attachment/11800/test-result-plenum.ubuntu-06.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8ef:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jul/17 10:15 PM;ashcherbakov;PR: https://github.com/hyperledger/indy-plenum/pull/312

Problem cause: do not do any view changes in the test since we're dealing with non-master instance and may have not order all requests if view is changed;;;","31/Jul/17 10:16 PM;ashcherbakov;The issue is reproduced again: https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-315/4/
Please see the attached logs.;;;","01/Aug/17 5:00 PM;ashcherbakov;Fixed in https://github.com/hyperledger/indy-plenum/pull/316;;;","03/Aug/17 12:59 AM;VladimirWork;test_message_outside_watermark1.py passes during multiple pytest runs (20 passes from 20 runs). !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Demotion of node 1 in a pool and restarting the pool causes a pool failure,INDY-463,19532,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,krw910,krw910,27/Jul/17 11:43 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,sprint11-goal-release,Stability,,,,"With the way view change works when the entire pool is restarted it resets the selection of the master and backup nodes in the order of the pool_transactions_sandbox (or live) file. So Node1 always is set as the master when the entire pool is restarted.

The test is to demote Node1 as a Trustee and then restart the entire pool to see if a different Node defaults to be the primary.

Start the CLI 
sovrin
connect test
new key with seed 000000000000000000000000Trustee1
send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services': []}

Restart the entire pool
",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/17 9:25 PM;VladimirWork;_node1_case1.txt;https://jira.hyperledger.org/secure/attachment/11818/_node1_case1.txt","03/Aug/17 9:25 PM;VladimirWork;_node1_case2.txt;https://jira.hyperledger.org/secure/attachment/11819/_node1_case2.txt","03/Aug/17 9:25 PM;VladimirWork;_node2_case1.txt;https://jira.hyperledger.org/secure/attachment/11820/_node2_case1.txt","03/Aug/17 9:25 PM;VladimirWork;_node2_case2.txt;https://jira.hyperledger.org/secure/attachment/11821/_node2_case2.txt","03/Aug/17 9:25 PM;VladimirWork;_node3_case1.txt;https://jira.hyperledger.org/secure/attachment/11822/_node3_case1.txt","03/Aug/17 9:25 PM;VladimirWork;_node3_case2.txt;https://jira.hyperledger.org/secure/attachment/11823/_node3_case2.txt","03/Aug/17 9:25 PM;VladimirWork;_node4_case1.txt;https://jira.hyperledger.org/secure/attachment/11824/_node4_case1.txt","03/Aug/17 9:25 PM;VladimirWork;_node4_case2.txt;https://jira.hyperledger.org/secure/attachment/11825/_node4_case2.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydc7:",,,,,,10,11,,,,,,,,,,,,,,,,,,,andkononykhin,ashcherbakov,krw910,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jul/17 4:17 AM;slafranca;After following the steps listed in the description, my pool does not process any transactions.  Nodes 2-6 are running.  Restarting the services does not make a difference.  The node log for 2-6 have the same information, they show:
{code}
.sovrin/Node6.log:2017-07-27 17:20:56,105 | DISPLAY  | primary_selector.py  ( 284) | _startSelection | Node6:0 selected primary Node3:0 for instance 0 (view 2)
{code}

The log on node 1 shows:
{code}
.sovrin/Node1.log:2017-07-27 17:19:20,005 | DISPLAY  | primary_selector.py  ( 284) | _startSelection | Node1:0 selected primary Node1:0 for instance 0 (view 0)
{code};;;","03/Aug/17 6:48 PM;ashcherbakov;Even if Node 1 is set as a primary initially, the view change will not finish as it required to have an ACK from the selected Primary as well, In this case Node 1 will not send ACK, we will select the next node after some timeout.
 ;;;","03/Aug/17 9:26 PM;VladimirWork;Steps to Reproduce - Case 1:

1. Send ""new key with seed 000000000000000000000000Trustee1"".
2. Send ""send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services': []}"".
3. Restart the entire pool.

Actual Results:
NYMs are not adding (but primary seems to be elected in log). [^_node1_case1.txt]  [^_node1_case2.txt]  [^_node2_case1.txt]  [^_node2_case2.txt]  [^_node3_case1.txt]  [^_node3_case2.txt]  [^_node4_case1.txt]  [^_node4_case2.txt] 

Steps to Reproduce - Case 2:

1. Send ""new key with seed 000000000000000000000000Trustee1"".
2. Send ""send NODE dest=4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA data={'alias': 'Node4', 'services': []}"".
3. Restart the entire pool.

Actual Results:
NYMs are not adding. There is a stack trace in systemctl status sovrin-node.service on Node 1:

Aug 03 12:06:10 8990aa3fcd5b env[110]:     if self.monitor.isMasterDegraded():
Aug 03 12:06:10 8990aa3fcd5b env[110]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/monitor.py"", line 266, in isMasterDegraded
Aug 03 12:06:10 8990aa3fcd5b env[110]:     (self.isMasterThroughputTooLow() or
Aug 03 12:06:10 8990aa3fcd5b env[110]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/monitor.py"", line 287, in isMasterThroughputTooLow
Aug 03 12:06:10 8990aa3fcd5b env[110]:     r = self.masterThroughputRatio()
Aug 03 12:06:10 8990aa3fcd5b env[110]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/monitor.py"", line 275, in masterThroughputRatio
Aug 03 12:06:10 8990aa3fcd5b env[110]:     masterThrp, backupThrp = self.getThroughputs(self.instances.masterId)
Aug 03 12:06:10 8990aa3fcd5b env[110]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/monitor.py"", line 361, in getThroughputs
Aug 03 12:06:10 8990aa3fcd5b env[110]:     avgReqsPerInst = totalReqs / self.instances.count
Aug 03 12:06:10 8990aa3fcd5b env[110]: TypeError: unsupported operand type(s) for /: 'NoneType' and 'int'

Expected Results:
Pool should work normally in both cases.;;;","12/Aug/17 12:20 AM;mzk-vct;The reason is that node uses *TxnPoolManager.get_name_by_rank* which reads NODE transactions directly from pool ledger.
 It traverses ledger searching first occurrence of NODE transaction with required id, ignoring other occurrence and without checking node for demotion - so, demoted node can be nominated to be next primary.

Stack trace in a comment of [~VladimirWork] is not caused by this problem. It happens when `totalReqs` is None, what happens when there were no requests.;;;","29/Aug/17 10:58 PM;andkononykhin;Fixed by [PR-354|https://github.com/hyperledger/indy-plenum/pull/354]: for now demoted node is not taken into account during primary selection, so after restart it won't be selected as primary

How it could be tested: repeat steps from the description;;;","30/Aug/17 8:09 PM;VladimirWork;Build Info:
indy-node 1.1.125

Steps to Reproduce - Case 1:
1. Send ""new key with seed 000000000000000000000000Trustee1"".
2. Send ""send NODE dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv data={'alias': 'Node1', 'services': []}"".
3. Restart the entire pool.

Steps to Reproduce - Case 2:
1. Send ""new key with seed 000000000000000000000000Trustee1"".
2. Send ""send NODE dest=4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA data={'alias': 'Node4', 'services': []}"".
3. Restart the entire pool.

Actual Results:
Pool works normally in both cases - NYMs are added and are got.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade: Does a client need to talk to the node for the upgrade transaction to be received.,INDY-464,19533,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,27/Jul/17 11:50 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"We ran into an issue where the only machine in the pool that did not upgrade was also the only machine in the pool where the port to the client is blocked. The node only talks to the other validator nodes and does not allow traffic from a client.

Two questions to research
1. Does a client have to actually talked to a node when sending the upgrade transaction or is it propagated to all nodes?

2. Does the config_transactions ledger sync with all nodes in the pool?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jul/17 10:01 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11785/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8en:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jul/17 10:01 PM;VladimirWork;> 1. Does a client have to actually talked to a node when sending the upgrade transaction or is it propagated to all nodes?

	It is propagated to all nodes (in one of the test cases config_transactions ledger wrote upgrade tnx that was sent with all nodes stopped when consensus was reached).

> 2. Does the config_transactions ledger sync with all nodes in the pool?

	Yes, if pool has consensus (e.g. if 3 nodes of 4 have the same upgrade txn in this ledger then 4th node get them as well after start). !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Log failure to post transaction,INDY-465,19540,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,sergey.khoroshavin,mgbailey,mgbailey,28/Jul/17 5:13 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,GA-0,Stability,,,,"In the case that a transaction is sent to the validator pool via CLI or otherwise, and is unable to be posted to the ledger, all nodes in the pool should log the failure to post as an ERROR, including an explanation of why the ledger was unable to post the transaction.  For example, if consensus was not achieved, list the nodes that were able to participate, and which were not.

This posting may occur after a short timeout period, if necessary.",,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,INDY-1300,,,,INDY-484,INDY-1274,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzwwgv:",,,,,,10,11,18.07 Stability & Monitoring,,,,,,3.0,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,esplinr,mgbailey,ozheregelya,sergey.khoroshavin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 5:44 PM;ashcherbakov;Do not spend much time on this, add a basis reasonable logging.;;;","21/Aug/17 9:42 PM;alexander.shekhovcov;[~mgbailey] [~ashcherbakov] 
Should I add logging on the client side (CLI, ...) or the ticket is about logging on the pool side?

After INDY-484 is closed we will have fairly well logging on the pool side with right log levels and ability to filter logs (see INDY-484).

Anyway let's consider possible cases:
 # a client sends invalid request
 ** for now this case has fairly well logging on the client side
 # pool does not reach consensus
** in this case the pool does not answer anything to the client so we have to add an additional client request like ""get request status"" which will return some verbose information about request status but it requires significant amount of work  
# the pool gets consensus but fails somehow between ""ordered"" and ""replay"" phases
** the pool does not answer anything, a new ""get request status"" will help here as well

So in case of a pool failure a client is not able to get any request status we can solve it adding a new type of request like ""get request status"" but it assumes some changes in code which are not a simple logging.;;;","21/Aug/17 9:55 PM;alexander.shekhovcov;[~mgbailey] Btw, Nikita has created a document [""Important Node Log Messages""|https://docs.google.com/document/d/1xEHNXn9-PiPP61BccWD0SOSDsw7LYxyOgY2dHXn0X8I/edit#] maybe the document will be helpful for you. The document reflects the latest changes in master branch so it will be actual in the next stable release.;;;","23/Aug/17 4:29 AM;mgbailey;[~alexander.shekhovcov], the ticket is intended for server-side logging.  Currently, we see many cases where attempts to post a transaction fail silently.  The transaction just does not appear in the ledger.  It is possible that a cause could be found if logging is turned on to a very high level, or with a lot of detective work, but this is not how it should be.  This type of event should be made obvious to the average admin, not just to the dedicated developer.  ERROR, or at least WARN, is the appropriate log level for failure to post a transaction, and an explanation of why the failure occurred should be given.;;;","23/Aug/17 10:04 PM;alexander.shekhovcov;Agree. I am going to view code to add more verbosity for failures.

Types of failures:

* cannot get consensus
* rejecting / reqnacking
* suspicions
* not enougth connection
* node is not participating
* missing requests
* cachup fails
* node crashes
* permission errors
* election fails

PoA:
* check if each of the cases has logging and logging level is >= than INFO

;;;","24/Aug/17 7:46 PM;alexander.shekhovcov;(/) *Resolved*

https://github.com/hyperledger/indy-plenum/pull/355
https://github.com/hyperledger/indy-node/pull/319

I've increased log level for some messages and added messages like:
{code}
2017-08-24 13:22:02,801 | WARNING  | monitor.py           ( 302) | warn_has_lot_unordered_requests | It looks like Beta does not participate in processing messages because it has 3 unordered requests in the last 0.25 minutes (assumed that minimum difference between unordered requests is at least 1 seconds)
{code}

{code}
2017-08-24 13:22:02,801 | WARNING  | Alpha is getting requests but still does not have a primary so the replica will not process the request until a primary is chosen
{code}

It should help to find out that a node is not participating in consensus so exact cause may be found by log messages which are placed above in a log. There is no certain place in the code there we can say ""the node cannot process 3pc messages"" or ""the node cannot choose a primary"" and define the cause of that. For example a node may miss a 3pc message because of network problem so a prepare comes before pre-prepare it is not a problem itself but in some cases it may be a sign that the node get out sync. 
Let's try to work with the current logging setup and collect cases when the average admin feels uncomfortable with the logs so we will be able to define exact problems and add reasonable logging.

Nothing to test here.;;;","25/Aug/17 8:32 PM;ashcherbakov;Node build: 1.1.116;;;","26/Aug/17 12:11 AM;VladimirWork;Build Info:
indy-node 1.1.118

Steps to Validate:
1. Change the log level ""echo ""logLevel=0"" >> /home/sovrin/.sovrin/sovrin_config.py""
2. Restart the node.
3. Check new messages in the log.

Actual Results:
New log messages are implemented.;;;","14/Feb/18 11:57 PM;mgbailey;The request was for an ERROR, not a DEBUG message when a failure occurs, along with a cause of the failure.  Should be just a couple of lines of logging.  This is not what was provided.

 ;;;","15/Feb/18 12:35 AM;ashcherbakov;I believe the requirement was got incorrectly.

All issues are logged with ERROR/WARNING level.

What is not logged, is when a request is received, but not enough 3PC. As the system is not deterministic, we can not say that transaction failed in this case, and there is no real ERROR to be shown.

What we can do, is to introduce some kind of a timeout, and check, that if txn is not ordered in, for example, 60 secs, we show a WARNING.;;;","15/Feb/18 3:33 AM;mgbailey;Yes.  It would be good to have at the INFO level that a transaction has been received for processing, and then if it is posted to the ledger have a message at the INFO level stating that, and after 60 seconds if it is not posted, have a WARNING and a reason.  This would be a great help, and would require less assistance from engineering for analyzing logs in the future.

 ;;;","29/Mar/18 7:48 PM;sergey.khoroshavin;Is it still needed to log this information by node? Now there is a tool which bulk processes logs from nodes (https://github.com/hyperledger/indy-plenum/tree/master/scripts/process_logs), and among other things it can track requests and report how much of them were not ordered at all. It's not hard to add to this tool reporting which individual requests were not ordered if really needed. Also, while working on https://jira.hyperledger.org/browse/INDY-1177 I plan to implement proof-of-concept integration with Elastic/LogStash/Kibana stack by middle/end of next week, which in the end could turn out to be even better solution.;;;","29/Mar/18 10:23 PM;ashcherbakov;[~mgbailey] ^;;;","30/Mar/18 11:55 PM;mgbailey;[~sergey.khoroshavin]This requirement remains in force.  Failure to post a transaction must be treated as a failure mode, and must be logged in a way that can be understood by operators, not devs.;;;","10/Apr/18 2:13 AM;sergey.khoroshavin;PR: https://github.com/hyperledger/indy-plenum/pull/619;;;","23/Apr/18 7:48 PM;ozheregelya;*Environment:*
indy-node 1.3.382;
Docker pool of 6 nodes.

*Case 1:*
Steps to Validate:
1. Setup the pool.
2. Check that the pool works by sending any transaction.
3. Stop 2 of 6 nodes.
=> Consensus is lost.
4. Send transaction and check logs after 1 min.

Actual Results:
Warning message appears if the transaction was not ordered in 1 min.
{code:java}
2018-04-22 21:30:44,186 | WARNING  | monitor.py           ( 348) | check_unordered | Following requests were not ordered for more than 60 seconds: [('V4SGRU86Z58d6TV7PBUe6f', 1524432616029524)] 
{code}
*Case 2:*
Steps to Validate:
1. Change UnorderedCheckFreq in indy_config.py to 1 sec (default value is 60).
2. Restart the pool after changes in the config.
3. Write several transactions, check logs.

Actual Results:
Warning message appears if transaction was not ordered during specified time:
{code:java}
2018-04-22 21:40:58,683 | WARNING | monitor.py ( 348) | check_unordered | Following requests were not ordered for more than 1 seconds: [('V4SGRU86Z58d6TV7PBUe6f', 1524433258386167)]{code};;;","24/Apr/18 2:52 AM;mgbailey;Is there information stating +why+ transaction failed to post (i.e. only 4 of 6 nodes, with the following nodes not participating: ...)?  This information is required.;;;","24/Apr/18 4:54 PM;ashcherbakov;[~sergey.khoroshavin] [~ozheregelya] [~mgbailey]
Let's create a new ticket if needed to enhance the message of why txn failed to post.;;;","25/Apr/18 6:57 AM;mgbailey;[~ashcherbakov], this ticket is not complete, since the stated requirements have not been completed. The ticket needs to be rejected.;;;","26/Apr/18 7:25 AM;esplinr;I reviewed this issue with [~mgbailey] to understand what specifically is missing. As a result, we clarified INDY-1274 and logged INDY-1300.

We will close this issue, and prioritize those other two into the backlog.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
If system timezone of the primary does not match that of the other nodes the pool cannot function,INDY-466,19541,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,28/Jul/17 7:06 AM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"We found a case where if the nodes timezone is not set to UTC then the pool cannot accept transactions and you will see in the logs entries like the following:

PREPARE time not acceptable
PRE-PREPARE time not acceptable

If you change the system timezone to UTC time this fixes the issue. We should not be reliant on this workaround.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8ev:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,krw910,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jul/17 10:00 PM;lovesh;PR https://github.com/hyperledger/indy-plenum/pull/314
;;;","03/Aug/17 2:31 AM;krw910;In the following build I changed the region and timezone for all my nodes and was still able to send transactions to the ledger.

indy-plenum=1.0.79
indy-anoncreds=1.0.22
indy-node=1.0.72
sovrin=1.0.15
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Intermittently failing tests: test_view_change_all_nodes_random_delay.py,INDY-467,19547,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ashcherbakov,ashcherbakov,28/Jul/17 5:30 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-472,,,,,,,,"03/Aug/17 1:16 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11813/Screenshot.PNG","28/Jul/17 5:30 PM;ashcherbakov;test-result-plenum.ubuntu-06.txt;https://jira.hyperledger.org/secure/attachment/11784/test-result-plenum.ubuntu-06.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8f3:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/17 6:27 PM;ashcherbakov;*The problem reproduced in the test*
Pre-Conditions:
* We have 4 Nodes, Alpha is a primary.
* All nodes (on master replica) have a random delay for some 3PC messages.
* Alpha has no (or short) delays for neither 3PC.
* Gamma has very long delays for both PREPARE and COMMIT 
* Beta and Delta have long delays for COMMIT, but no (or short) delays for PREPARE
* All delays are only for receiving a 3PC message. Sending is done without any delays. That's how our tests make artificial delays.
Steps:
* All replica's last oredered pp seqno is (0,1)
* Alpha, Beta and Delta receive n-f-1=2 PREPAREs => they send n-f=3 COMMITs
* Alpha has no delays for received COMMITs, so it Orders the Request => Alpha's last ordered pp SeqNo is (0,2)
* Beta and Delta have long delay for received COMMITs, so, although they have a quorum of COMMITs, they don't Order it => Beta's and Delta's last ordered pp SeqNo is still (0,1)
* View change is started.
* We try to perform N=5 rounds of catchup without any transaction caught up for Beta and Delta. It took 2 seconds to complete these 2 rounds of catch-up, although delay for COMMITs is much longer.
* We have a quorum for View Change Done (Beta, Delta, Gamma) for last ordered = (0,1) => view is changed.
Result:
* Alpha's ledger becomes invalid (it ordered one additional txn (0,1) which wasn't ordered by anyone else).
* The ledger is append-only, so Alpha's Ledger becomes broken forever.

*Problem in general*
* We have a write consensus of n-f, and consensus for catch-up of f+1.
* So, if more than n-f-(f+1)=n-2f-1 nodes agreed to order a txn but failed/crashed before writing it to the Ledger, then we have a stalled/broken Ledger.

*Severity of the issue*
Not major/critical, because
* For n=4, f=1, we may still have 2 nodes agreed to write a txn fail before ordering, and will be able to recover the Ledger during catch-up.
* The test reproduced the issue is quote artificial because
** It has very long delays 
** The delays are for *some* messages only (usually if this is a network issue, then the delay will be for all messages)
** The delay is only for receiving the messages (not for sending). IN a real network the delay will be usually for both.

*Short-term solution (to fix possible problems in the test)*
* Print delays in tests (for easier debug in future and notice correlation between delays and failures)
* Make catch-up longer (5 rounds were completed for just 2 seconds; it looks too fast). Have a minimum timeout for catchup during view change.
* Do not have random delays in the test more than this timeout.

*Long-term solution for the General Problem*
* Persist COMMITs, so that we can recover after start-up all txns that were agreed to be ordered, but not ordered yet for some reasons.
* Have a separate story this.
* I think the priority is Minor;;;","01/Aug/17 12:06 AM;ashcherbakov;A short-term solution is implemented in the scope of this ticket: https://github.com/hyperledger/indy-plenum/pull/317

https://jira.hyperledger.org/browse/INDY-472 is created for a long-term solution.;;;","02/Aug/17 5:59 PM;ashcherbakov;build: indy-node 1.0.69;;;","03/Aug/17 1:16 AM;VladimirWork;test_view_change_all_nodes_random_delay.py passes during multiple pytest runs (20 passes from 20 runs). !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor publishing to pypi helper function,INDY-468,19548,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,andrey.goncharov,andrey.goncharov,28/Jul/17 5:42 PM,09/Oct/19 6:50 PM,28/Oct/23 2:46 AM,09/Oct/19 6:50 PM,,,,,0,5Months,devops,,,,"We should migrate to twine (recommended tool for publishing) and refactor[ publishToPypiCore function in jenkins-shared|https://github.com/evernym/jenkins-shared/blob/master/vars/publishToPypiCore.groovy] to be usable py [python-wrapper in indy-sdk|https://github.com/hyperledger/indy-sdk/blob/master/wrappers/python/Jenkinsfile]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzy13z:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:50 PM;ashcherbakov;We are moving to GitLab CI;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Throughput degrades over time,INDY-469,19551,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,mzk-vct,mzk-vct,28/Jul/17 8:35 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,,,,,"[From comment in INDY-223|https://jira.hyperledger.org/browse/INDY-223?focusedCommentId=29135&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-29135]:

I run load test with *-c 20 -r 50000* parameters, 1.000.000 requests total. My script checks largest objects every 5 minutes, sysstat checks memory every 10 seconds.

I checked it after ~18 hours - only ~220.000 transactions were processed, whereas first 10.000 were processed in a first 10 minutes.

Same thing I saw when run *test_node_load* test from *plenum/test/test_performance.py*.",,,,,,,,,,,,,,,,,,,,,,,INDY-223,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzx1lr:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 10:37 PM;Derashe;For actual moment of time, throughtput measurement evolved much and don't contain this bug.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin CLI requires a pool_transactions_sandbox file even it just connecting to live,INDY-470,19564,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,krw910,krw910,krw910,29/Jul/17 5:12 AM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,5Months,,,,,"Where you are running the sovrin CLI from is a .sovrin directory. In this directory is the pool_transactions file for the sandbox and live pools.

If a user is only using the live environment and only has the pool_transactions_live file then the CLI will not attempt to connect to the live pool. It acts as if there is no pool_transactions file.

Steps:
In the .sovrin directory only have the pool_transactions_live file.
Start >sovrin
Run >connect live

You will get a message showing no file was found and a URL on where to find the files.
If you create a pool_transactions_sandbox file in the .sovrin directory and run the steps above you can now connect to the live pool.",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-702,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzy14f:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 12:33 PM;danielhardman;I am more concerned about the opposite scenario, where the CLI requires Live even if you're only trying to use Test. I hope most CLI users are talking to the test pool instead of the live one.

In any case, we should fix this. One pool is enough.;;;","04/Jan/18 4:28 AM;ozheregelya;The issue is not actual for indy-cli.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy-SDK tests crash node pool,INDY-471,19571,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,srottem,srottem,srottem,29/Jul/17 10:29 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Executing the TestGetTxnRequestWorksForInvalidSeqNo in GetTxnRequestTest after TestClaimDefRequestWorks in ClaimDefRequestTest from the .NET test suite causes the node pool to crash.  

I'm not clear on what specifically is triggering the crash but have narrowed it down to the code in these two tests: the first test sets up the condition that causes the failure while the second fails when calling indy_submit_request with the following value:

\{""reqId"":1501340745244981900,""identifier"":""V4SGRU86Z58d6TV7PBUe6f"",""operation"":\{""type"":""3"",""data"":27}}

If the first test is not run the second will not cause the failure in the pool.

Although this may be caused by an issue in the .NET tests themselves (I'm not seeing the same problem in the Java tests) it seemed prudent to raise the issue as it appears to demonstrate a problem that can be triggered in the node pool via the indy-sdk.

Please see the attached console output from the nodes.

Note that the indy-pool.dockerfile is being used to run the indy pool, although the IP address has been changed to 127.0.0.1.",Windows 10 Home running indy-pool docker container from indy-sdk.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jul/17 10:27 PM;srottem;node_console_output.txt;https://jira.hyperledger.org/secure/attachment/11788/node_console_output.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydbr:",,,,,,11,12,,,,,,,,,,,,,,,,,,,danielhardman,krw910,ozheregelya,srottem,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 12:34 PM;danielhardman;For now, i think we should investigate this as a bug in indy-node; we don't want any misbehaving client to be able to trigger a crash. However, it is possible that research will prove that this is an SDK issue instead of an indy-node issue.;;;","25/Aug/17 6:15 AM;krw910;[~ashcherbakov] please assign this ticket;;;","13/Sep/17 9:04 PM;srottem;Running the .NET test suite on the master branch at commit 8837b640273548c8ef7633f0f2de49856041651e all active tests pass. I haven't seen the issue in a while, so I expect it's fixed.;;;","15/Sep/17 5:41 PM;ozheregelya;[~srottem], could you please close this ticket as invalid if it doesn't reproduce now?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"We should be able to recover if from more than n-2f-1 agreed about ordering, but failed to order",INDY-472,19620,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Duplicate,anikitinDSR,ashcherbakov,ashcherbakov,01/Aug/17 12:06 AM,09/Oct/19 6:35 PM,28/Oct/23 2:46 AM,09/Oct/19 6:35 PM,,,,,0,5Months,Stability,,,,"*Problem in general*
* We have a write consensus of n-f, and consensus for catch-up of f+1.
* So, if more than n-f-(f+1)=n-2f-1 nodes agreed to order a txn but failed/crashed before writing it to the Ledger, then we have a stalled/broken Ledger.

A possible solution is to persist COMMITs, so that we can recover after start-up all txns that were agreed to be ordered, but not ordered yet for some reasons.

Please see INDY-467 for more details.",,,,,,,,,,,,,,,,,,,,,,INDY-2238,INDY-467,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzwyhb:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 12:07 AM;ashcherbakov;[~danielhardman] [~nage]
Do we really need it for M1 release? For me it looks quite low priority.;;;","17/Jan/18 6:32 PM;ashcherbakov;I don't think we have faced any problems with this.

This is rather a theoretical problem, and probably not of high priority.

 ;;;","26/Jan/18 6:32 PM;ashcherbakov;[~VladimirWork] [~ozheregelya]
Can you please prove that this issue was not a cause of our stabulity problems we've faced recently?;;;","26/Jan/18 10:33 PM;ozheregelya;[~ashcherbakov],
The latest stability problems (INDY-1033) consist in lagging of only one node. In all cases (7 nodes and 25 nodes in the pool) there are enough nodes for catch up, so I believe that this is not the same problem as this one.;;;","26/Jan/18 10:54 PM;VladimirWork;[~ashcherbakov] I also agree that this is not a high priority issue (unlike view change for example) and cases in which we can face this issue are pretty uncommon.;;;","29/Jan/18 5:41 PM;ashcherbakov;Moving to the backlog then;;;","09/Oct/19 6:35 PM;ashcherbakov;Duplicates https://jira.hyperledger.org/browse/INDY-2238;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add genesis transaction files to sovrin repo,INDY-473,19634,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,stevetolman,stevetolman,01/Aug/17 9:28 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,The genesis transaction files used in the go-live event should be checked in to the sovrin repo.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy8fb:",,,,,,M1 Prelude,,,,,,,,,,,,,,,,,,,,krw910,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Aug/17 9:29 AM;stevetolman;Added to sovrin repo.

PR: https://github.com/sovrin-foundation/sovrin/pull/9;;;","03/Aug/17 2:35 AM;krw910;I have verified the files against what was used in the launch event.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool loses consensus and catchup under load,INDY-475,19648,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,01/Aug/17 7:33 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,Stability,,,,,"Build Info:
indy-node 1.0.68

Overview:
Pool loses consensus and catchup under load.

Preconditions:
Setup pool of 4 nodes.

Steps to Reproduce:
0. Run ""python3 add_keys.py Steward1 000000000000000000000000Steward1"" on node 1.
1. Run ""python3 load_test.py -c 10 -r 1000"" on node 1.
2. Run ""python3 load_test.py -c 10 -r 1000"" on node 2.
3. Disconnect node 3 for some time and connect it back.

Actual Results:
Pool loses consensus and catchup after node 3 disconnecting (07/31 15:24 in attached logs) and doesn't recover from abnormal state after node 3 connecting and load stopping.

Expected Results:
Pool should work normally.

Additional Info:
The last entry in ledger is:
RRbkXVEr8UZ1Z9RidHmu25|1501514662987154|5LNtsUB5sBkBvVSsfDjcyzokhmwFZgiBDxYqLYYLo3ZPC9FHxbKsMMswXSAuCDWtxMyv7ii4q26UAkjwZD7BDyz5|1501514663|1|X5rmihBTebovJM5tQCue15|~GBm1PFQdEioeRkPfHB71NL||||||||",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-806,,,,,,,,"01/Aug/17 7:33 PM;VladimirWork;node1failsconsensusandcatchhup.7z;https://jira.hyperledger.org/secure/attachment/11801/node1failsconsensusandcatchhup.7z","01/Aug/17 7:33 PM;VladimirWork;node2failsconsensusandcatchhup.7z;https://jira.hyperledger.org/secure/attachment/11802/node2failsconsensusandcatchhup.7z","01/Aug/17 7:33 PM;VladimirWork;node3failsconsensusandcatchhup.7z;https://jira.hyperledger.org/secure/attachment/11803/node3failsconsensusandcatchhup.7z","01/Aug/17 7:33 PM;VladimirWork;node4failsconsensusandcatchhup.7z;https://jira.hyperledger.org/secure/attachment/11804/node4failsconsensusandcatchhup.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyfqv:",,,,,,12,,,,,,,,,,,,,,,,,,,,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Aug/17 7:39 PM;VladimirWork;FYI [~krw910], [~stevetolman], [~danielhardman], [~ashcherbakov];;;","05/Sep/17 9:08 PM;spivachuk;Cannot reproduce this bug on indy-node master 1.0.113.

While trying to reproduce, found another bug - INDY-806.;;;","06/Sep/17 7:22 PM;VladimirWork;Build Info:
indy-node 1.1.131

Steps to Validate:
0. Run ""python3 add_keys.py Steward1 000000000000000000000000Steward1"" on node 1.
1. Run ""python3 load_test.py -c 10 -r 1000"" on node 1.
2. Run ""python3 load_test.py -c 10 -r 1000"" on node 2.
3. Disconnect node 3 for some time and connect it back.

Actual Results:
Pool works normally. Node3 catch up successfully.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validator: Quick System Status,INDY-476,19650,,Task,To Develop,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,,,farooq_m_khan,farooq_m_khan,01/Aug/17 8:16 PM,09/Oct/19 11:15 PM,28/Oct/23 2:46 AM,,,,,,0,4Months,Could,Supportability,Usability,,"We probably need to show the Sovrin Version on OS Banner(one that is shown when you ssh into validator) just like Ubuntu shows, to quickly make it clear what version of Sovrin is installed and running at the moment. The only way to know this at the moment is by running this command:
{{apt-get -s install sovrin}}

We also need some command (bash / python script) that gives a quick status of the validator
Like: Validator running time for this many hours, All Ledgers and there synced up Status, Upcoming Upgrade schedule etc.

This will make the life of stewards easy, they do not need to know the internals of using sovrin cli or even having one for knowing such trivial status.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0sf:",,,,,,10,11,12,13,14,,,,3.0,,,,,,,,,,,,farooq_m_khan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Input validation should be used for all types and without using 'Any',INDY-477,19652,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:19 PM,30/Nov/17 1:31 PM,28/Oct/23 2:46 AM,,,,,,0,4Months,REFACTORING,,,,"Message types to be improved:
* CurrentState
* MessageReq
* MessageRep",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzy153:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Simplify catch-up code,INDY-478,19653,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:20 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,4Months,REFACTORING,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1384,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzx1gv:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 12:44 PM;danielhardman;What is the priority of this relative to simplifying view change and introducing state machines?

I would do this in conjunction with implementing a state machine for catchup.;;;","28/Sep/18 6:32 AM;esplinr;Closing as duplicate of INDY-1384;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Have an explicit state machine in the code,INDY-479,19654,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andkononykhin,andrey.goncharov,andrey.goncharov,01/Aug/17 9:20 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,REFACTORING,,,,,"We have states (in particular, node's states). But it's not obvious/explicit how the system goes from one state to another.
Think about State machine and State Design Pattern.
Think about existing state or state machine frameworks that can help.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzx0yv:",,,,,,,,,,,,,,13.0,,,,,,,,,,,,andrey.goncharov,ashcherbakov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 12:30 PM;danielhardman;I think we have multiple state machines–there is one for catchup state, another for view change state, and another for 3pc state.

Although I like state machines as a design pattern–*particularly* when states and transitions are complex and loaded with semantics–I am not sure about using a framework. State machine frameworks tend to be heavy without adding significant value over what we could write ourselves. Perhaps research will prove me wrong.

One important consequence of state machine logic is that we could write good unit tests for certain things without actually doing complex setup, by manipulating the state machines cleverly.

If we do this ticket, I want the state machines to be written in such a way that we can generate documentation from them, and possibly so we can trace how their state evolves in a debugger in a useful way. This will make it much easier to test and to learn how state evolves, as a developer.;;;","29/Nov/17 12:45 AM;ashcherbakov;We would like to do this vertically step by step according to the thoughts in https://docs.google.com/document/d/1qDfyb6ALqvf7Cwrnmk0RUmyVbM2Znd7urey-8B21j6o/edit#heading=h.myn1swcdi79r;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Simplify view change code,INDY-480,19655,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,andrey.goncharov,andrey.goncharov,01/Aug/17 9:20 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,REFACTORING,should,,,,"* Use proper abstractions for view change
* Split catch-up and view change (they should not be related)
* Separate all view change logic in a special class",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1376,,,,,,,,,,"1|hzypxb:",,,,,,INDY 17.24: Node Perf,INDY 17.25,,,,,,,5.0,,,,,,,,,,,,andkononykhin,andrey.goncharov,ashcherbakov,danielhardman,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 12:43 PM;danielhardman;I would do this in conjunction with implementing a state machine for view change.;;;","23/Nov/17 9:34 PM;ashcherbakov;I suggest just do separation of view change logic into a separate class, without full state machine support.
I suggest to re-factor it for states support in a separate ticket (it would be much easier to do it when view change code is already separated).
The reason is not to have a big re-factoring lasting multiple Sprints again.;;;","24/Nov/17 10:36 PM;andkononykhin;h2. PoA
 # analyze current logic of view change: who (object), when (events + conditionals) and what (action) performs
 # design class that implements existence behavior and provides API for the events processing
 # refactor code to use object of that class for all view change related routine
 # testing on current set of tests: check that no logic has been broken;;;","09/Dec/17 12:24 AM;ashcherbakov;PR: https://github.com/hyperledger/indy-plenum/pull/470
Build: 1.2.230
Changes: Just code refactoring

For QA:
Check that view change works as before
;;;","15/Dec/17 12:14 AM;ozheregelya;Version Info:
indy-node 1.2.236

Following cases were verified:
- view change because of low performance of primary node
- view change because of primary node stopping
- view change because of primary node demotion
- view change when the pool is loaded;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Separate catch-up and view-changev,INDY-481,19656,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:21 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyagf:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clean and reorganize utils,INDY-482,19657,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:21 PM,09/Oct/19 6:41 PM,28/Oct/23 2:46 AM,09/Oct/19 6:41 PM,,,,,0,4Months,REFACTORING,,,,"* Clean and reorganize utils - there are a number of util.py-like files
* Re-factor common/utils logic (move it from stp)",,,,,,,,,,,,,,,,,,,,,,,INDY-496,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzwyev:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:41 PM;ashcherbakov;We simplified this. Let's continue as part of incremental refactoring policy in the scope of all the tasks we do.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance logging framework we use,INDY-483,19658,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,mzk-vct,andrey.goncharov,andrey.goncharov,01/Aug/17 9:22 PM,09/Oct/19 6:43 PM,28/Oct/23 2:46 AM,09/Oct/19 6:43 PM,,,,,0,4Months,REFACTORING,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzx13b:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:43 PM;ashcherbakov;Let's continue as part of incremental refactoring policy in the scope of all the tasks we do.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clean up log messages and levels in the code,INDY-484,19659,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,spivachuk,andrey.goncharov,andrey.goncharov,01/Aug/17 9:22 PM,09/Oct/19 6:56 PM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,4Months,REFACTORING,Supportability,,,"* Check whether each log message has a proper log level
* The INFO log level must be compact though informative
* The log needs should be easy parseable
* Provide a guide on how to read the log (markers for some important events, such as view change, catch-up, etc.)
* Add helper scripts to grep the log for some important markers",,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,INDY-724,,INDY-465,,,,INDY-1267,INDY-1177,INDY-1186,INDY-1416,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-779,,,,,,,,,,"1|hzwy8f:",,,,,,10,11,12,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,danielhardman,esplinr,mgbailey,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 1:17 PM;danielhardman;We need to confer with [~mgbailey] and [~tharmon] and [~krw910] on this. All of them have important experience trying to troubleshoot and diagnose based on current logs.

The simplest thing we could do that would vastly improve the value of our logs is to stop issuing ""suspicious spike"" messages that flood the logs. It may be the case that a brief investment (say, a day) could yield important improvements.

We should not spend a long time on this ticket–just a modest amount.;;;","04/Aug/17 5:57 PM;ashcherbakov;What will be helpful to know from the logs easily from my point of view:
- current viewNo
- current primary for each replica
- catchup statuses
- view change statuses
- PRE-PREPARE, PREPARE, COMMIT times (probably not in INFO?)
- Order (commit to the Ledger) time;;;","17/Aug/17 8:05 PM;spivachuk;Added a google doc listing important node log messages to Development -> Testing -> How To:
https://docs.google.com/document/d/1xEHNXn9-PiPP61BccWD0SOSDsw7LYxyOgY2dHXn0X8I;;;","17/Aug/17 8:19 PM;spivachuk;Added a script extracting messages with a specific prefix from a log:
https://github.com/hyperledger/indy-plenum/blob/master/scripts/filter_log

Using this script, messages can be selected from a log by the category which prefix them.;;;","22/Aug/17 2:10 AM;spivachuk;Added a script gathering statistics on different log messages occurrences in a log:
https://github.com/hyperledger/indy-plenum/blob/master/scripts/log_stats

The statistics contains each executed line containing a logger call with the count of times this line was executed and an example of a log message produced by a logger call from this line.;;;","26/Apr/18 10:43 PM;esplinr;We believe this work was completed as part of INDY-1186 and INDY-1177;;;","26/Apr/18 11:02 PM;mgbailey;Richard, at the INFO level the logs are completely useless, as any of the devs will tell you. We still have yet to strike the correct balance of usefulness and verbosity at what should be the default log level. [~tharmon] has strong feelings on this as well.;;;","26/Apr/18 11:12 PM;ashcherbakov;[~mgbailey]
We did some changes in log levels recently (in the scope of INDY-1187). So we are hoping this is better now even on INFO level.
We will most probably continue the work on adapting the logs in the background during analysis of logs and running load tests.;;;","27/Apr/18 9:08 AM;esplinr;[~mgbailey] The problem with this story is that it is too vague. The team feels like they have been through the effort multiple times, and if they are not addressing the underlying need then more guidance is necessary. I can help gather requirements, but we should do that in the context of new issues with clear requirements based on research with a range of customers.

We created INDY-1274, which reflects your biggest pain point. This is prioritized to be completed as soon as possible.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove redundant config file options,INDY-485,19660,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:22 PM,09/Oct/19 6:54 PM,28/Oct/23 2:46 AM,,,,,,0,4Months,REFACTORING,,,,There are lots of config parameters which should be private and not public.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx1mf:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use async zmq,INDY-486,19661,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:23 PM,31/May/18 11:18 PM,28/Oct/23 2:46 AM,,,,,,0,4Months,REFACTORING,,,,"Use async version of zmq:
http://pyzmq.readthedocs.io/en/latest/api/zmq.asyncio.html",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1380,,,,,,,,,,"1|hzx173:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Asyncio usage,INDY-487,19662,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:23 PM,31/May/18 11:14 PM,28/Oct/23 2:46 AM,,,,,,0,4Months,REFACTORING,,,,"* Replace 'message boxes' of 'actors' by blocking async queueus to avoid active waiting* 
* think about event-driven approach to get rid of load when there is no messages in the system",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1380,,,,,,,,,,"1|hzx1i7:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clean up interfaces and abstract classes,INDY-488,19663,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:23 PM,10/Oct/19 11:59 PM,28/Oct/23 2:46 AM,10/Oct/19 11:59 PM,,,,,0,4Months,REFACTORING,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-496,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzx18n:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/19 11:59 PM;ashcherbakov;We've done a lot of refactorings and improvements in the scope of PBFT View Chnage protocol.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Simplify monitor class,INDY-489,19664,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:24 PM,09/Oct/19 6:43 PM,28/Oct/23 2:46 AM,09/Oct/19 6:43 PM,,,,,0,4Months,REFACTORING,,,,"* Simplify monitor class
* merge monitor TCP messages ",,,,,,,,,,,,,,,,,,,,,,,INDY-496,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzx18f:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:43 PM;ashcherbakov;We simplified this. Let's continue as part of incremental refactoring policy in the scope of all the tasks we do.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
make mostCommonElement return number of occurrences,INDY-490,19665,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:24 PM,09/Oct/19 6:53 PM,28/Oct/23 2:46 AM,09/Oct/19 6:53 PM,,,,,0,4Months,REFACTORING,,,,"This method counts number of occurrences of elements in some collection and returns the one which number is greater.
 There are some places where not only element itself, but also that number. 
 As of now it is done using count method of collections over element returned by mostCommonElement.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzy14v:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:53 PM;ashcherbakov;We've already fixed this;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add static code validation in CI,INDY-491,19666,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:24 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,CI/CD/Update,REFACTORING,,,,,,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Aug/17 7:10 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11870/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybmn:",,,,,,10,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 12:41 PM;danielhardman;If this can be done in 1 day, then I will vote for it. If it takes longer, it should be deferred for a while.;;;","10/Aug/17 6:14 PM;andrey.goncharov;Added static code validation step to ci.

[https://github.com/evernym/jenkins-shared/commit/f182890a2031dcb5ce073902340bb7589419f429]

For now it never fails, only produces warnings. It will start failing pipelines when pep8 refactoring is done.;;;","11/Aug/17 7:11 PM;VladimirWork;Static code validation is added to pipeline. !Screenshot.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make creation of routes more explicit,INDY-492,19667,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:25 PM,11/Oct/19 12:00 AM,28/Oct/23 2:46 AM,11/Oct/19 12:00 AM,,,,,0,4Months,REFACTORING,,,,"Message routers are configured in __init__ method of Node. But routers can be changed when replicas and primary selector added since they have own messages. It is done implicitly and the one who changes routes in __init__ can be confused.

We should consider more explicit way for this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzx1on:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Aug/17 6:17 AM;krw910;[~andrey.goncharov] Can you give more information on this ticket. Are you talking about the node code or somewhere else? Is this just a training issue or can something be done?;;;","11/Oct/19 12:00 AM;ashcherbakov;We've done a lot of refactorings and improvements in the scope of PBFT View Change protocol.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Adhere PEP8,INDY-493,19668,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:25 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,REFACTORING,,,,,"*PoA:*
# Fix all *E** and *W** except E501
# Setup flake8 on CI
# Fix E501
# Fix all *F**
# Fix all *N** (most difficult part)
# Fix C901",,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,,,,,,INDY-739,INDY-740,INDY-741,INDY-742,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzye7z:",,,,,,11,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,andrey.goncharov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Aug/17 10:59 PM;alexander.shekhovcov;flake8 statistic for indy-plenum:
{code}
12    E111 indentation is not a multiple of four
22    E122 continuation line missing indentation or outdented
3     E124 closing bracket does not match visual indentation
4     E125 continuation line with same indent as next logical line
179   E127 continuation line over-indented for visual indent
95    E128 continuation line under-indented for visual indent
1     E129 visually indented line with same indent as next logical line
10    E131 continuation line unaligned for hanging indent
1     E201 whitespace after '('
3     E202 whitespace before ']'
6     E203 whitespace before ','
6     E222 multiple spaces after operator
12    E225 missing whitespace around operator
1     E228 missing whitespace around modulo operator
45    E231 missing whitespace after ','
33    E251 unexpected spaces around keyword / parameter equals
16    E261 at least two spaces before inline comment
86    E265 block comment should start with '# '
7     E271 multiple spaces after keyword
97    E302 expected 2 blank lines, found 1
26    E303 too many blank lines (2)
13    E305 expected 2 blank lines after class or function definition, found 1
3     E306 expected 1 blank line before a nested definition, found 0
46    E402 module level import not at top of file
1470  E501 line too long (80 > 79 characters)
12    E711 comparison to None should be 'if cond is None:'
2     E712 comparison to True should be 'if cond is True:' or 'if cond:'
1     E713 test for membership should be 'not in'
9     E731 do not assign a lambda expression, use a def
531   F401 'ledger.stores.hash_store.HashStore' imported but unused
5     F402 import 'replica' from line 50 shadowed by loop variable
21    F403 'from .__metadata__ import *' used; unable to detect undefined names
715   F405 'NODE_IP' may be undefined, or defined from star imports: plenum.common.constants, plenum.common.messages.fields
207   F811 redefinition of unused 'Vt100_Output' from line 50
5     F821 undefined name 'delayD'
31    F841 local variable 'v' is assigned to but never used
3     N801 class names should use CapWords convention
2087  N802 function name should be lowercase
1196  N803 argument name should be lowercase
1     N805 first argument of a method should be named 'self'
1435  N806 variable in function should be lowercase
2     N813 camelcase imported as lowercase
43    W291 trailing whitespace
47    W292 no newline at end of file
13    W293 blank line contains whitespace
56    W391 blank line at end of file
13    W601 .has_key() is deprecated, use 'in'
{code}
;;;","08/Aug/17 11:01 PM;alexander.shekhovcov;flake8 statistic for indy-node:
{code}
2     E111 indentation is not a multiple of four
1     E115 expected an indented block (comment)
1     E116 unexpected indentation (comment)
17    E122 continuation line missing indentation or outdented
5     E124 closing bracket does not match visual indentation
71    E127 continuation line over-indented for visual indent
98    E128 continuation line under-indented for visual indent
8     E131 continuation line unaligned for hanging indent
6     E201 whitespace after '{'
2     E202 whitespace before ']'
5     E203 whitespace before ':'
9     E225 missing whitespace around operator
19    E231 missing whitespace after ','
30    E251 unexpected spaces around keyword / parameter equals
2     E261 at least two spaces before inline comment
1     E262 inline comment should start with '# '
11    E265 block comment should start with '# '
1     E271 multiple spaces after keyword
1     E301 expected 1 blank line, found 0
52    E302 expected 2 blank lines, found 1
14    E303 too many blank lines (2)
6     E305 expected 2 blank lines after class or function definition, found 1
1     E306 expected 1 blank line before a nested definition, found 0
42    E402 module level import not at top of file
978   E501 line too long (97 > 79 characters)
1     E502 the backslash is redundant between brackets
1     E703 statement ends with a semicolon
2     E713 test for membership should be 'not in'
2     E731 do not assign a lambda expression, use a def
319   F401 'plenum.common.constants.RAW' imported but unused
9     F403 'from time import *' used; unable to detect undefined names
168   F405 'perf_counter' may be undefined, or defined from star imports: time
138   F811 redefinition of unused 'NAME' from line 17
17    F821 undefined name 'EOT'
7     F841 local variable 'signature' is assigned to but never used
2     N801 class names should use CapWords convention
1466  N802 function name should be lowercase
1016  N803 argument name should be lowercase
1     N805 first argument of a method should be named 'self'
713   N806 variable in function should be lowercase
16    N812 lowercase imported as non lowercase
1     N814 camelcase imported as constant
1     W291 trailing whitespace
28    W292 no newline at end of file
8     W293 blank line contains whitespace
36    W391 blank line at end of file
{code};;;","18/Aug/17 11:16 PM;alexander.shekhovcov;(/)
Some check were disabled (see .flake8 files) 
so only:
* Fix all E* and W* except E501
* Setup flake8 on CI
are done

I am going to create separate tickets for each check which is going to be enabled later.

(i) *How to test:*
* install into a virtual environment *pip install pep8 pep8-naming flake8*
* get the latest master (indy-anoncreds, indy-plenum, indy-node, sovrin)
* cd into the repo and run *flake8 .*

The expected result:
{code}
⚡ flake8 .
(indy) 
sheh@sheh-Z68P-DS3 /home/sheh/prj/evernym/sovrin
{code}

there are no errors.

* add a few blank lines to any *.py file

The expected result:
{code}
⚡ flake8 .                              
./plenum/common/messages/client_request.py:40:1: E303 too many blank lines (5)
{code}




;;;","18/Aug/17 11:53 PM;alexander.shekhovcov;The new tickets:
* https://jira.hyperledger.org/browse/INDY-739
* https://jira.hyperledger.org/browse/INDY-740
* https://jira.hyperledger.org/browse/INDY-741
* https://jira.hyperledger.org/browse/INDY-742;;;","21/Aug/17 10:40 PM;VladimirWork;Build Info:
indy-node 1.0.112

Steps to Validate:
1. Check by ""flake8 ."" consistency of latest master sources.
2. Check by ""flake8 ."" that invalid changes in sources (except special files like setup.py) causes error messages.

Actual Result:
There are no errors in original files.
There are error messages due to invalid changes in source files.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Refactor] Apply State machine to Node Initialization Code,INDY-494,19669,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,andrey.goncharov,andrey.goncharov,01/Aug/17 9:25 PM,10/Oct/19 10:53 PM,28/Oct/23 2:46 AM,10/Oct/19 10:53 PM,,,,,0,4Months,REFACTORING,should,,,"node.py is a huge class dealing with lots of aspects. Re-factor it.

In particular, separate out Node Initialization:
https://docs.google.com/document/d/1qDfyb6ALqvf7Cwrnmk0RUmyVbM2Znd7urey-8B21j6o/edit#heading=h.myn1swcdi79r",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-496,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzx0nb:",,,,,,14,INDY 17.21,,,,,,,8.0,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/19 10:53 PM;ashcherbakov;We did a lot of improvements while working on PBFT View Change;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Refactor] Apply state machine to RequestManager Actor,INDY-495,19670,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,andrey.goncharov,andrey.goncharov,01/Aug/17 9:26 PM,10/Oct/19 11:58 PM,28/Oct/23 2:46 AM,10/Oct/19 11:58 PM,,,,,0,4Months,REFACTORING,should,,,"replica.py contains lots of different logic for processing of all 3PC messages, Checkpoints, parts of view change, etc.
Break the monolith.

In particular, create Request Manager Actor and apply state machine to it
See https://docs.google.com/document/d/1qDfyb6ALqvf7Cwrnmk0RUmyVbM2Znd7urey-8B21j6o/edit#heading=h.myn1swcdi79r

The code may live separately. Full integration and replacement of Replica can be done in another task.",,,,,,,,,,,,,,,,,,,,,,,INDY-496,,,,INDY-981,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzx0n3:",,,,,,14,INDY 17.21,,,,,,,8.0,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/19 11:58 PM;ashcherbakov;We've done a lot of refactorings and improvements in the scope of PBFT View Chnage protocol.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Simplify class hierarchy - remove redundant classes,INDY-496,19671,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:26 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,REFACTORING,,,,,,,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,INDY-494,,,,INDY-495,INDY-489,INDY-488,INDY-482,INDY-728,INDY-729,INDY-730,,"09/Aug/17 10:47 PM;mzk-vct;PoolManagers.png;https://jira.hyperledger.org/secure/attachment/11848/PoolManagers.png","09/Aug/17 10:47 PM;mzk-vct;PoolManagers.puml;https://jira.hyperledger.org/secure/attachment/11850/PoolManagers.puml","09/Aug/17 10:47 PM;mzk-vct;Stores.png;https://jira.hyperledger.org/secure/attachment/11849/Stores.png","09/Aug/17 10:47 PM;mzk-vct;Stores.puml;https://jira.hyperledger.org/secure/attachment/11851/Stores.puml",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybmv:",,,,,,10,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,krw910,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 5:44 PM;ashcherbakov;Do not spend too much time on this, do something reasonable.;;;","09/Aug/17 10:50 PM;mzk-vct;*Stores* and *PoolManagers* hierarchies should be simplified. It may take a lot of time, especially for *PoolManager*.;;;","09/Aug/17 10:51 PM;mzk-vct;Moved management of replicas to Replicas
https://github.com/hyperledger/indy-plenum/pull/326
;;;","16/Aug/17 3:35 AM;krw910;I have looked at the PR. It does not look like there is much for QA to do with this ticket so I am moving it on.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clean and reorganize utils - there are a number of util.py-like files,INDY-497,19672,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzywn3:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 12:43 PM;danielhardman;Is this a dup of INDY-482?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check which public methods and fields can be private,INDY-498,19673,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:27 PM,09/Oct/19 6:54 PM,28/Oct/23 2:46 AM,09/Oct/19 6:54 PM,,,,,0,4Months,REFACTORING,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzy15j:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:54 PM;ashcherbakov;We simplified this. Let's continue as part of incremental refactoring policy in the scope of all the tasks we do.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace 'message boxes' of 'actors' by blocking async queueus to avoid active waiting,INDY-499,19674,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:28 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyagn:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Drop messages from request queue when their amount is too high,INDY-500,19675,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,andrey.goncharov,andrey.goncharov,01/Aug/17 9:29 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,1.5,,,0,4Months,REFACTORING,Stability,,,"On high message rate node may be incapable to process them all quickly, so some of them should be en-queued. 
 Earlier we used internal queue of zmq for this, but it does not allow us to:
 # Understand which number of messages received
 # Drop some of them selectively (for example the oldest) when load is too high (zmq allows dropping of new messages only)

That's why we need to create own queue, put all incoming messages to it and drop some of them on high load.

 

In INDY-366 we changed the default FIFO queue in ZMQ to be unlimited. This makes certain problems less likely, but it also masks problems for a lot longer. 
It led to Memory Leaks, so we reverted  this  back to 10,000 limit.
We were truly robust if:
 # The high water mark were finite (e.g., 100,000).
 # We had a way to detect that we are nearing the high water mark, and that we would report a graceful error that makes this condition easy to diagnose.
 # We implemented logic in STP to discard old messages rather than new ones. (Desirable but not necessarily required.)
 # If we exceed the high water mark, we exit the daemon process gracefully rather than crashing due to an out-of-memory condition.

Possibly 3 could be omitted.",,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1241,,,,,,,,,,"1|hzwy0f:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,danielhardman,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 12:37 PM;danielhardman;I'm not sure that creating our own queue is a good idea, but the goal of this ticket makes a lot of sense. Can we submit a patch to zmq instead? Please confer with [~nage] and [~farooq_m_khan].;;;","04/Aug/17 5:48 PM;ashcherbakov;[~nage] [~danielhardman]
Is it a high priority task?;;;","15/May/18 6:54 PM;esplinr;If 10,000 items accumulate in the queue, then ZMQ will drop all new messages until the queue drops back below 10K.

This fulfills this requirement.

There are some additional questions about how dropping messages will impact network stability if a node spends an extended time on the 10K threshold. If it becomes important to investigate, we will raise another issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Get rid of implicit using of fixtures (optimize import should work),INDY-501,19676,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:29 PM,09/Oct/19 6:44 PM,28/Oct/23 2:46 AM,09/Oct/19 6:44 PM,,,,,0,4Months,REFACTORING,,,,"If one presses Ctrl+Alt+O in Pycharm in the tests, then the fixtures needed for the test startup may be removed. 
Use annotation to ignore this kind of imports when optimizing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzx1ov:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:44 PM;ashcherbakov;We simplified this. Let's continue as part of incremental refactoring policy in the scope of all the tasks we do.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Separate unit and integration tests,INDY-502,19677,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,spivachuk,andrey.goncharov,andrey.goncharov,01/Aug/17 9:31 PM,09/Oct/19 6:44 PM,28/Oct/23 2:46 AM,09/Oct/19 6:44 PM,,,,,0,4Months,REFACTORING,,,,,,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzx18v:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 12:38 PM;danielhardman;I'd be willing to work on this soon, if we timebox it. I'd like to see if we could get 80% of the benefit of this task by spending only 3 days on it. Can we?;;;","03/Aug/17 11:05 PM;danielhardman;Timebox this to 2 days or 3 days.;;;","04/Aug/17 7:44 PM;ashcherbakov;I think we have not so many unit tests as of now.
What can be done easily:
- just split test folder into `unit` and `integration` tests

What can be done afterwards: try to convert some integration tests into unit ones if possible and saves execution time.;;;","09/Oct/19 6:44 PM;ashcherbakov;We simplified this. Let's continue as part of incremental refactoring policy in the scope of all the tasks we do.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Each integration test must be a piece of requirement ,INDY-503,19678,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:32 PM,11/Oct/19 6:35 PM,28/Oct/23 2:46 AM,11/Oct/19 6:35 PM,,,,,0,4Months,REFACTORING,,,,"Make the tests more readable.
A test must be a piece of requirement.
It must be easy and 'human-readable' for everyone (including QA)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzy15b:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 6:35 PM;ashcherbakov;We have system tests that address this requirement;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Each integration test must be a piece of requirement ,INDY-504,19679,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:33 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyagv:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add system tests (with docker pool),INDY-505,19680,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,andkononykhin,andrey.goncharov,andrey.goncharov,01/Aug/17 9:33 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,REFACTORING,,,"Our current tests use in memory pool of test nodes (running in one process). They are integration, but not system.
Create real system tests, that will run against a pool of real nodes (probably in a docker).
Integrate them into CI.",,,,,,,,,,,INDY-1766,,,,,,,,,,,,INDY-1359,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzwx0f:",,,,,,EV 18.24,,,,,,,,3.0,,,,,,,,,,,,andkononykhin,andrey.goncharov,danielhardman,Sergey.Kupryushin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 12:39 PM;danielhardman;Please confer with [~krw910] about test design. If he will use this infrastructure, I am a huge fan of doing it. I think Docker will be excellent. But he may have other ideas.;;;","18/Oct/18 8:56 PM;Sergey.Kupryushin;Blocked by
https://ci.evernym.com/job/Indy-Node/job/indy-node-verify-x86_64/1461/execution/node/17/log/

[~VladimirWork] Please let me know when all checks are passed;;;","24/Oct/18 11:07 PM;VladimirWork;Test are here: https://github.com/hyperledger/indy-test-automation/tree/master/system FYI [~Sergey.Kupryushin];;;","05/Dec/18 8:31 PM;andkononykhin;The most valuable  part of the work is done and presented in the PR: [https://github.com/hyperledger/indy-node/pull/998]

The following PoA is for specifying things that are needed to finalize the task.

*PoA*:
 * update jenkins library to call system tests handlers for both master and stable;;;","06/Dec/18 11:16 PM;andkononykhin;*Problem reason:*

Systems tests haven't been automated. Thus all of them have been performed manually by QA. The task should start process to automate that routine.

*Changes*:
 * updated jenkins library to support system tests handlers
 * added such a handler for indy-node which perform one of tests from the [https://github.com/hyperledger/indy-test-automation] repo
 * system tests are run for both master and stable branches before GitHub tags releasing


*Committed into*:

https://github.com/hyperledger/indy-node/pull/1076

*Risk factors*:

Might brake the CD pipeline

*Risk*:

Low



*Covered with tests*:

no. Was tested manually with prepared test pipeline.


*Recommendations for QA*:

Nothing. According to pipeline runs after merge happened it works.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor module scoped fixtures to be function scoped,INDY-506,19681,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:33 PM,09/Oct/19 6:51 PM,28/Oct/23 2:46 AM,09/Oct/19 6:51 PM,,,,,0,4Months,REFACTORING,,,,Try to have tests more isolated.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzy14n:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:51 PM;ashcherbakov;We simplified this. Let's continue as part of incremental refactoring policy in the scope of all the tasks we do. Also we try to use more unit tests now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tests running in parallel report status incorrectly,INDY-507,19682,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Lowest,Cannot Reproduce,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:34 PM,11/Oct/19 6:37 PM,28/Oct/23 2:46 AM,11/Oct/19 6:37 PM,,,,,0,4Months,REFACTORING,,,,"We use Jenkin's `parallel` feature to run tests in parallel in different Agents.
However, looks like the test result and status is not reported properly: only part of the test result is reported.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1nr:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 6:37 PM;ashcherbakov;We don't have this issue anymore;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
It should be easy to build from branch,INDY-508,19683,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:34 PM,09/Oct/19 6:44 PM,28/Oct/23 2:46 AM,09/Oct/19 6:44 PM,,,,,0,4Months,REFACTORING,,,,"We need to be able to have a full workflow of CI/CD when developing in a branch (both plenum and node).
It includes:
* Raising and testing PRs against a branch
* Publishing to pypi
* Having builds for a branch (a repo per branch?) which we can present to QA.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzx1a7:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:44 PM;ashcherbakov;We don't use branches anymore;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Simplify RC creation,INDY-509,19684,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,andrey.goncharov,andrey.goncharov,andrey.goncharov,01/Aug/17 9:35 PM,09/Oct/19 6:41 PM,28/Oct/23 2:46 AM,09/Oct/19 6:41 PM,,,,,0,4Months,blocked,REFACTORING,,,"The process of RC creation requires some manual interaction as of now.
We can have a way to do it automatically (in case when we just want to merge the current master into stable).",,,10800,10800,,0%,10800,10800,,,INDY-727,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzx17b:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 4:38 PM;ashcherbakov;Timebox this to 1 day: try to do a reasonable improvement.;;;","11/Aug/17 7:54 PM;andrey.goncharov;It's blocked by INDY-727. We should resolve squash issue in stable before we can simplify RC creation. We can not trust any automatic tool to resolve conflicts when merging to stable.

Thoughts for future:
 * Automatically drop -dev postfix in setup py
 * Pull Jenkins API periodically to automatically create the next cascading PR when a one in the upstream is merged in (create a PR to indy-node when indy-plenum is merged and built)
 * Analyze diff to automatically rename any new migration scripts in it;;;","09/Oct/19 6:41 PM;esplinr;This was done by [~andkononykhin] in scope of other tasks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add code coverage metrics in CI,INDY-510,19685,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,stevetolman,andrey.goncharov,andrey.goncharov,01/Aug/17 9:35 PM,09/Oct/19 5:28 PM,28/Oct/23 2:46 AM,,,,,,0,4Months,REFACTORING,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzx1lb:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Refactor] Create decorator for 'lazy' fields,INDY-511,19689,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,mzk-vct,mzk-vct,02/Aug/17 12:25 AM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,REFACTORING,should,,,,"There are number of properties which do some initialization on first call and then return that cached value. To do it they use protected fields which are always in scope, but do nothing useful except of storing cached value.

We need decorator for this.
There is *functools.lru_cache* decorator which does memorization. If it is created with *maxsize=1* it does exactly what we need. But it is too resource consuming.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzyk53:",,,,,,14,INDY 17.21,INDY 17.22,,,,,,2.0,,,,,,,,,,,,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/17 9:13 PM;mzk-vct;*lazy_field* decorator is created in plenum/common/tools.py

Example of usage:
Without:
{code}
    # in __init__
        self._bls_register = None

    @property
    def bls_register(self):
        if self._bls_register is None:
            self._bls_register = BlsKeyRegisterPoolLedger(self._ledger)
        return self._bls_register
{code}

With:
{code}
    @lazy_field
    def bls_register(self):
        return BlsKeyRegisterPoolLedger(self._ledger)
{code};;;","17/Oct/17 12:27 AM;mzk-vct;PR for node https://github.com/hyperledger/indy-plenum/pull/417;;;","26/Oct/17 11:59 PM;mzk-vct;Node version: 1.2.187;;;","28/Oct/17 12:38 AM;VladimirWork;Build Info:
indy-node 1.2.188

Actual Results:
Basic actions with the pool (installation\upgrade, NYMs' sending\geting) works normally after the code's changes.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThreatModel: Securing the memory allocations,INDY-512,19700,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,stevetolman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"libSodium has functions like sodium_memzero(), sodium_mlock() having these functions and using them will help us further secure the memory allocations, it will also further mitigate the risk introduced by coredumps.On certain unix systems it will also use madvise() that advises the kernel not to include the locked memory in core dumps[See LibSodium Doc|https://download.libsodium.org/doc/helpers/memory_management.html]However NACL (python bindings over libSodium) the python library we use does not expose these libSodium functions.We need to first get these functions into NACL by some means or maybe have a small python bind of ourselves over libSodium and then use it in our code.This work requires someone who understands writing python bindings for ""c"" libraries. And also then python knowledge to be able to code it into STP",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzyaiv:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
POOL_UPGRADE needs to support different hashes and signatures for different platforms,INDY-513,19701,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Upgrade,,,,"Since source code can be different on different platforms the hash of the code and signature will differ too. The POOL_UPGRADE txns should indicate to which platforms the upgrade is targeted. This also helps in a scenario where we did not support platform *X* till version 9 but started supporting *X* in version 10, now when a node joins the pool which is on *X* does not need to do upgrades till version 9 but only for version 10",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyajb:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] The post genesis pool txns will have a multisig by the nodes of the pool,INDY-514,19702,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"When the client starts, it loads the genesis pool txns and then loads the post genesis pool transactions. The client should be able to verify multi-sig over txns in post genesis file",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-785,,,,,,,,,,"1|hzyaj3:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Break up the current pool_transaction_* file into genesis and post genesis txns,INDY-515,19703,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,The genesis txns will never change and any subsequent transactions will be added to the post-genesis txns file. The post genesis txn file will also be included with the source code.,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-785,,,,,,,,,,"1|hzx12n:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/17 5:46 PM;ashcherbakov;[~avkrishnan] [~danielhardman] [~nage]
I was assuming that all subsequent transactions will be added into the ledger directly (with NODE txn).
So, the current genesis txn files (in sovrin repo) will never change. The only thing that it needed is to rename genesis txn files to distinguish from other txn files and folders.And this is already done in the scope of INDY-373;;;","19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
No information given if you do not have a pool_transactions_live file and try to connect to live,INDY-516,19704,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,1.0,,,,0,4Months,MGLteam,minimal-go-live,,,"If I have a pool_transactions_sandbox file and it is empty I get a message with a url on where to go get the file. The difference here is the sandbox file is empty and the live file does not exist. *{color:#14892c}Message for sandbox file{color}*{code}sovrin> connect testThe information required to connect this client to the nodes cannot be found.This is an error. To correct the error, get the file containing genesis transactions(the file name is `pool_transactions_sandbox`) from the github repository and placeit in directory `/home/ubuntu/.sovrin`.The github url is https://github.com/sovrin-foundation/sovrin-client/tree/stable/data.{code}*{color:#d04437}If I do not have a pool_transactions_live file the message does not tell me how to correct it by giving me a URL like with the sandbox file{color}*{code}sovrin> connect liveDo not have information to connect to liveUsage:    connect <test|live>{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzyajj:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 12:49 AM;sergey-shilov;This CLI is deprecated, no longer supported and going to be removed, this ticket is not relevant any more and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
certain TXNS signed by certain DID types should be throttled,INDY-517,19705,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Must-Have,,,,"Given the Sovrin Validator nodes can recognize different types (roles) of transactions and which DIDs are signing transactions: # There should be a set of rules in the network (which the human Trustees & TGB would agree upon)# The rules should look for 3 variables: ## Who did the transaction? (DID)## What txn type is it?## How many of these txns do we allow per [time window]? e.g., how many nyms per hour?# Throttling txns based on their parameters can happen later in another story# If a txn violates the limits set in the config file: ## Reject the txn## We'll want to be able to warn the DID that they're getting close to their limit before shutting them down, but that will come in a later story.Whoever does the PoA should consult Nathan for getting it passed off.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-51,,,,,,,,,,"1|hzwvif:00001xzc",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need a ledger explorer tool,INDY-518,19706,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"I need a tool that allows me to walk through records in the ledger, inspecting them in much the same way that MySQL Workbench would allow me to open a RDBMS, enumerate all the tables, write arbitrary queries, export data, and maybe repair something.This tool addresses multiple important use cases:# As a sysadmin or other technical community member, I need to be able to diagnose problems with corrupt data.# As an Evernym developer or tester, I need to be able to create corrupt ledgers and interact with them to test various failure scenarios. I also need to accept corrupt ledgers and diagnose what went wrong.#  As a Sovrin advocate, I want to be able to demo Sovrin's behavior with respect to the ledger, without having a UI that necessarily manifests a given feature.# As a developer in the Sovrin ecosystem, I want to be able to study the effects of my code on test ledgers.# As a sysadmin in an ultimate ""nuclear failure"" scenario where the world ledger is offline and no automated remediation seems possible, I might need to patch a corrupt ledger by following instructions issued by the TGB.I can imagine two different modes of operation for this explorer: one where it talks to a remote ledger via libsovrin, and one where it talks to a local data file.The tool should support all the ledgers used by sovrin (identity, voting, performance, pool, etc).The UI should run on any common desktop OS. It can be relatively primitive and inefficient, as long as it's easy to understand. We could do a SPA with react/node.js, like the one that [~andrey.goncharov] wrote for the node admin UI, or we could use java or QT creator, maybe.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzx12v:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"The Indy Network should have size limits for Schemas, Issuer Keys and Revocation registries",INDY-519,19707,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"See rows 11,12 and 13 of https://docs.google.com/a/evernym.com/spreadsheets/d/1pf7XgCaKiiVMUJfsuwQ8TBrOvgSW0QNKhIDz9XfylBg/edit?usp=sharing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-59,,,,,,,,,,"1|hzwy87:",,,,,,,,,,,,,,3.0,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:53 AM;ashcherbakov;This is already done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Design & Implementation: Updates to my DDO should be throttled, and DDOs not be hack-able",INDY-520,19708,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,1.13.0,,,0,4Months,,,,,"Given I am an Identity Owner, I should # be limited to updating my DDO files 3 times per day per DDO. # my DDO should not be hack-able. # All DDOs should be limited to a reasonable size (I'm not sure what that is, but when architects come to a decision, please update this requirement in the description).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-51,,,,,,,,,,"1|hzwx4f:2o",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Set monitoring thresholds after calibration,INDY-521,19709,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,mzk-vct,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"The monitoring thresholds like Delta, Lambda, Omega need to be set after calibration. Currently we have set them arbitrarily after a little bit of observation[PoA | https://docs.google.com/document/d/12hLghQQVMk2s8H2ympKfVa234aYFrnQXNAjPWg4dM44/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzyajr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to be able to check for duplicate NYMs on ledger,INDY-522,19710,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,M1,,,,"Currently it is possible to have a Trust Anchor add the same NYM as many times as they want without any message telling them that NYM already exists.This means that it will be possible for two individuals , if they are naming the seed to use to generate the key, to have the same NYM on the ledger.The creates a situation where you do not have a unique NYM.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-777,,,,,,,,,,"1|hzyajz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Refactor closing of hashStore, primaryStorage and secondaryStorage of plenum.server.node.Node",INDY-523,19711,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,spivachuk,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,SovrinCOREteam,,,,"Refactor closing of {{domainLedger}}, {{poolLedger}}, {{hashStore}} and {{poolManager.hashStore}} of {{plenum.server.node.Node}} that is made in its {{onStopping}} method.Now these properties may be instances of various classes. Some of these classes provide {{close}} method for closing, others provide {{stop}} method for this, thirds do not support closing at all (since have nothing to free). The current code closing these properties is confused due to this inconsistency.In scope of this ticket provide a general way to close objects being used as {{domainLedger}}, {{poolLedger}}, {{hashStore}} and {{poolManager.hashStore}} in {{plenum.server.node.Node}} and use this way in {{onStopping}} method of {{plenum.server.node.Node}}.*PoA*:# Add {{close}} method to all the classes that are used as {{domainLedger}}, {{poolLedger}}, {{hashStore}} and {{poolManager.hashStore}} in {{plenum.server.node.Node}} and do not have this method yet. It must free all the resources allocated by the object if any were allocated or must do nothing otherwise. If a class already has {{stop}} method for this aim then {{close}} method must just call it.# Correct closing of {{domainLedger}}, {{poolLedger}}, {{hashStore}} and {{poolManager.hashStore}} in {{onStopping}} method of {{plenum.server.node.Node}} class: use only {{close}} method for uniform closing of {{domainLedger}}, {{poolLedger}}, {{hashStore}} and {{poolManager.hashStore}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzyak7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verify the signature of the deb files while doing POOL_UPGRADE,INDY-524,19712,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,blocked,Upgrade,,,"As of now we dont verify the signatures on packages while doing the source code upgrade, we need to do it as per the demand of https://evernym.atlassian.net/browse/SOV-948",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx16v:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The validator configuration file should reside in a more reasonable location,INDY-525,19713,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"Currently, the configuration file for validator nodes is stored in {{/usr/local/lib/python3.5/dist-packages/plenum/config.py}}. While this is technically Python, it really shouldn't be residing in this location. It is not obvious to anyone, nor does it follow any of the standard configuration file locations.On a Linux system, I would expect to find the configuration file in an {{etc/}} directory. I do know there is the possibility of creating another configuration file in {{.sovrin}}, but it's not clear which takes precedence.This does bring up the question of whether or not code-as-configuration is a good idea, but that's probably best served as a separate topic.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-50,,,,,,,,,,"1|hzyakf:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:39 AM;ashcherbakov;This is already done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
list keyrings showing results twice,INDY-526,19714,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,4Months,MGLteam,,,,"When you send the command 'list keyrings' it returns duplicate results.*From the CLI*sovrinconnect testnew keyring testsave keyringlist keyrings{code}sovrin@test> list keyringsContext Name: test (path:/home/kelly/.sovrin/keyrings/test)    Persisted wallets:       default (last modified at: Tue Apr 18 15:04:23 2017)    *  test [Active keyring, may have some unsaved changes] (last modified at: Tue Apr 18 15:04:30 2017)Context Name: test (path:/home/kelly/.sovrin/keyrings/test)    Persisted wallets:       default (last modified at: Tue Apr 18 15:04:23 2017)    *  test [Active keyring, may have some unsaved changes] (last modified at: Tue Apr 18 15:04:30 2017){code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-783,,,,,,,,,,"1|hzyakn:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:47 AM;ashcherbakov;The Plenum's CLI is deprecated;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Re-factoring] Process TODO in stp,INDY-527,19715,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,Process all TODOs in stp project,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-41,,,,,,,,,,"1|hzyakv:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[State trie] Add signature_type as querying parameter for ISSUER_KEY (CLAIM_DEF),INDY-528,19716,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,4Months,SovrinCOREteam,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzyal3:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 10:11 PM;ashcherbakov;It's already done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
decide what we'll do to get CII badge,INDY-529,19717,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,stevetolman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"Hyperledger security folks are recommending that we implement a number of best practices in our github management and our build process that lead to people having greater trust in the binary artifacts that we ultimately release. The formal spec for this body of best practices is located here:https://github.com/linuxfoundation/cii-best-practices-badgeI recommend that we analyze these best practices and create individual tickets for many or all of the items that we are not yet doing. This is not stuff required for minimal go live, but may have a bearing on whether we graduate from ""incubator"" to ""full project"" status in Hyperledger.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-48,,,,,,,,,,"1|hzyalb:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update test deps specifications,INDY-530,19718,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,," 

For now test deps declared in setup.py in 'tests_require' section but it's a setuptools's thing and pip doesn't support it. Thus we have to 'manually' add these packages during test env configuring instead of just 'pip install ...'

As a better approach we can use setuptools's [extras_require|https://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-extras-optional-features-with-their-own-dependencies] field which is [supported by pip|https://pip.pypa.io/en/latest/reference/pip_install/#examples].

In such case we will get the following advantages:
 - we can use e.g. 'pip install .[test]' or 'pip install plenum[test]'.
 - don't need to waste time for exploring test_require manually when building new pipeline in Jenkins (cause we need these packages for testing but 'pip install .' won't install it)

POA:
 * update and clean up (where it necessary) setup.py files in all repos:
{code}
tests_require = ['pack1', 'pack2' ...]
setup(
...
tests_require=tests_require,
extras_require={
    'test': tests_require
}
...
)
{code}

 * update Jenkins scripts to use 'pip install .[test]' and remove unnecessary installation routine",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx0x3:",,,,,,INDY 17.24: Node Perf,,,,,,,,1.0,,,,,,,,,,,,andkononykhin,avkrishnan,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/17 10:04 PM;andkononykhin;PRs to indy core repos:

https://github.com/hyperledger/indy-node/pull/464
https://github.com/hyperledger/indy-anoncreds/pull/113
https://github.com/hyperledger/indy-plenum/pull/460;;;","24/Nov/17 7:01 PM;andkononykhin;Problem reason:
 - tests dependencies (like _pytest_) are installed ""manually"" without any automation that pip provided

Changes:
 - added *extras_require* parameter for setup.py routine where list of packages needed for testing only is defined. So, it could be installed using *pip install .[tests]* command
 - updated jenkinsfile to use that new ability

Committed into:
 - [https://github.com/hyperledger/indy-node/pull/464]
 - [https://github.com/hyperledger/indy-anoncreds/pull/113]
 - [https://github.com/hyperledger/indy-plenum/pull/460]

Risk factors:
 - Nothing is expected.

Risk:
 - Low

Covered with tests:
 - tested manually

Recommendations for QA: do the following sequence of steps
 * check that python wrapper is installed for tests
 ** clone indy-plenum / indy-node / indy-anoncreds
 ** create and activate virtual environment:
 *** *virtualenv -p python3 venv && source venv/bin/activate*
 ** run *pip install .[tests]*
 ** check that packages listed in setup.py as necessary for testing are installed: e.g. *pip list | grep pytest*;;;","30/Nov/17 3:28 AM;ozheregelya;*Version Info:*
indy-node 1.2.223

*Steps to Validate:*

check that python wrapper is installed for tests
 * clone indy-plenum / indy-node / indy-anoncreds
 * create and activate virtual environment:
 ** *virtualenv -p python3 venv && source venv/bin/activate*
 * run *pip install .[tests]*
 * check that packages listed in setup.py as necessary for testing are installed: e.g. *pip list | grep pytest*

*Actual Results:*
{code:java}
(venv) me@me-VM:~/git/indy-plenum$ pip list | grep pytest
pytest (3.3.0)
pytest-asyncio (0.8.0)
pytest-forked (0.2){code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement creating MSIs,INDY-531,19719,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"As a Win64 user I need to have an MSI based installer for the sovrin node and all dependencies like 3d party python modules and orientdb.PoA:* Write a script to create MSI for ledger, plenum, sovrin-common, stp, anoncreds, sovrin-node, sovrin-client* Integrate the script with Jenkins",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-66,,,,,,,,,,"1|hzyalj:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Design how we create MSIs,INDY-532,19720,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,,,,"As a Win64 user I need to have an MSI based installer for the sovrin node and all dependencies like 3d party python modules and orientdb.Research and choose right approach.PoA:* We can create a msi file of the sovrin node package pretty simple: https://docs.python.org/3/distutils/apiref.html#module-distutils.command.bdist_msiIn this case we have to create msi for each dependency because bundling is not supported.* As alternative, we can use tool like this https://www.firegiant.com/wix/tutorial/. The tool is not simple as python setup.py bdist_msi it may take time to learn how to work with it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-66,,,,,,,,,,"1|hzyalr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cli does not reconnect to nodes that have rebooted while still in a Cli session,INDY-533,19721,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,1.0,,,,0,4Months,SovrinCOREteam,,,,If a node goes down and comes back up while you are in a Cli session the Cli does not reconnect to the node.# I had 4 nodes in the pool. # Started the Cli and performed operations# I shutdown one node to see if the Cli would still perform operations and it did.# I shutdown another node and the Cli stopped performing operations because the pool dropped below 3f+1.# I then brought the two nodes back up and their services were running.*{color:#d04437}Issue:{color}*The Cli still would not perform operations because it did not reconnect to the nodes that had restarted. While in the Cli I send the command to 'disconnect' and then 'connect test'. The Cli still would not connect to the nodes.I exited the Cli and restarted it. Only then did it reconnect to the nodes that had been offline.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzyalz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/18 4:24 AM;ozheregelya;The issue is not actual for sovrin-cli (case with stopping/demotion more than f nodes was verified in last acceptance testing).
Indy-cli is also works correctly in this case.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Was able to create a non-standard NYM by not having a space between ID and role=,INDY-534,19722,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,1.0,,,,0,,,,,,"I thought I had create a new Steward, but when taking a closer look I had not because there was no space between the ID and role=STEWARDI entered{code}sovrin@test> send NYM dest=EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarrrole=STEWARDAdding nym EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarrrole=STEWARDNym EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarrrole=STEWARD added{code}Since it said ""added"" I thought the Steward had been created.We should have a check for role=STEWARD or another role and throw and error if the format is incorrect.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/17 10:24 PM;VladimirWork;INDY-534.PNG;https://jira.hyperledger.org/secure/attachment/11897/INDY-534.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-776,,,,,,,,,,"1|hzy15z:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/17 10:25 PM;VladimirWork;The issue is not reproducing on the latest master (1.0.110) - there is a validation constraint. !INDY-534.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
No error messages when TCP connection is not available for ZMQ,INDY-535,19723,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,sergey-shilov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,1.0,,,,0,4Months,SovrinCOREteam,,,,"I spent many hours trying to figure this one out.The issue was I had setup a network before our ZMQ builds allowing UDP ports 9701-9799, but not TCP ports. This was working with RAET. When we had switched to ZMQ the system no longer worked because the TCP port range 9701-9799 was not allowed through my firewall.No error messages were thrown telling me there was an issue with TCP or to check my firewall.We found the issue by looking up the messages we were getting in debug mode within the Zstack.py file. After walking through the code it occured that we did not have TCP ports open.*We need an error message thrown if the TCP port range 9701-9799 is not open.**Here is the section of code we traced the issue to, but again this only returned DEBUG messages and an ERROR needs to be thrown.*{code}    def transmit(self, msg, uid, timeout=None):        # Timeout is unused as of now        assert uid in self.remotes        socket = self.remotes[uid].socket        if socket:            msg = self.prepMsg(msg)            try:                # noinspection PyUnresolvedReferences                socket.send(self.signedMsg(msg), flags=zmq.NOBLOCK)                logger.debug(                    '{} transmitting message {} to {}'.format(self, msg, uid))                return True            except zmq.Again as ex:                logger.debug('{} could not transmit message to {}'.format(self, uid))                return False        else:            logger.warning('{} has uninitialised socket for remote {}'.                        format(self, self.remotes[uid]))            return False{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-41,,,,,,,,,,"1|hzyam7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 10:06 PM;sergey-shilov;We can not figure out problems with firewall settings on application level. From the node's point of view it is ""a problem with the networking"", and diagnostic of such issues is up to system administrator (steward in our case), so this ticket may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLI shows looking for node xxx for all entries that have been added for that node,INDY-536,19724,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,1.0,,,,0,4Months,MGLteam,minimal-go-live,,,"My understanding is that the last entry should be what is used. In this case I had added a node with the wrong IP address (see SOV-906). Since the send ATTRIB was not working I sent the add node command again with the correct IP. Just for fun I send the command again with another IP.Now the node will not connect to any of the IPs and the CLI shows it is looking for each of them. When adding a node if you need to change the IP address you cannot update the entry using the ""send ATTRIB "" command.*Setup:*5 machines with nodes and only 4 in the genesis file. The 5th node is to be added.1 Client machineSteps:*1. Get the IDs of Steward you will be adding*new key with seed 0000000000000000000KellySteward1EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr*2. Create a keypair with a Trustee seed (default)*new key with seed 000000000000000000000000Trustee1*3. Send a nym transaction to add a new Steward*send NYM dest=EHHnpHErJkPqhtJWuKekA4Cn8jLhvnfTsvVVdy53Qarr role=STEWARD*4. Switch to the new steward for Node 5*new key with seed 0000000000000000000KellySteward1*5. Send a transaction to add new node*{code}send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.20.10.213', 'alias': 'Node5', 'node_ip': '10.20.10.213', 'node_port': 9701, 'services': ['VALIDATOR']}{code}*6. Now send that same transaction again with different IPs*{code}send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.20.10.240', 'alias': 'Node5', 'node_ip': '10.20.10.240', 'node_port': 9701, 'services': ['VALIDATOR']}{code}{code}send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.20.10.220', 'alias': 'Node5', 'node_ip': '10.20.10.220', 'node_port': 9701, 'services': ['VALIDATOR']}{code}*Now disconnect the CLI and reconnect.*disconnectconnect test*{color:#d04437}You will see the following entries:{color}*{code}Connecting to test...FBqy4GTvHoV7N6E8s3WV7FGyCx88WFpgkZByRCxPCsZF now connected to Node2CFBqy4GTvHoV7N6E8s3WV7FGyCx88WFpgkZByRCxPCsZF now connected to Node1CFBqy4GTvHoV7N6E8s3WV7FGyCx88WFpgkZByRCxPCsZF now connected to Node3CFBqy4GTvHoV7N6E8s3WV7FGyCx88WFpgkZByRCxPCsZF now connected to Node4CFBqy4GTvHoV7N6E8s3WV7FGyCx88WFpgkZByRCxPCsZF looking for Node5C at 10.20.10.213:9702FBqy4GTvHoV7N6E8s3WV7FGyCx88WFpgkZByRCxPCsZF looking for Node5C at 10.20.10.240:9702FBqy4GTvHoV7N6E8s3WV7FGyCx88WFpgkZByRCxPCsZF looking for Node5C at 10.20.10.220:9702Connected to test.{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/17 5:53 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11898/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzyamf:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/17 5:53 PM;VladimirWork;The issue is reproducing on the latest master. !Screenshot.PNG|thumbnail! ;;;","04/Jan/18 4:21 AM;ozheregelya;Impossible to retest in indy-cli because of IS-502.;;;","12/Oct/18 6:44 PM;ashcherbakov;The CLI is deprecated.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Timing report for all tests,INDY-537,19725,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,,,,"Run test for:* ledger* stp* plenum* sovrin-comon* sovrin-node* sovrin-client* anoncredsCreate a report with time taken by each single test.[Krishnan] Need to find out where to run the tests - on dev's local machine, or on Jenkins.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzyamn:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
logLevel in plenum/config.py changes doesn't take effect,INDY-538,19726,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,Toktar,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,4Months,,,,,logLevel in plenum/config.py changes doesn't take effect,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-779,,,,,,,,,,"1|hzyamv:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,Toktar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 6:21 PM;Toktar;I think, it was changed in plenum that was builded with indy-node. In this case value of field logLevel in indy-node/indy_common/config.py will overlap the value from plenum.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Signing in stp_zmq should be configurable,INDY-539,19727,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,It should be possible to control whether all messages are signed or not at the transport level by a configuration parameter,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-41,,,,,,,,,,"1|hzyan3:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
When removing the role from a NYM the transaction says NYM added when it should be NYM updated since the NYM already exists,INDY-540,19728,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,4Months,,,,,When removing a role from a NYM it displays NYM added when it really is NYM updated since that NYM already exsits.*Steps:*Set yourself as a Trustee (Default keys are one of the following):new key with seed 000000000000000000000000Trustee1*Add new TestTrustee1*send NYM dest=CqH1opg44oVnX9QZA1PEL9VwnPnukviPNYtxwEYZkmEB role=TRUSTEE*Remove that Role*TestTrustee1send NYM dest=CqH1opg44oVnX9QZA1PEL9VwnPnukviPNYtxwEYZkmEB role=*In both cases the CLI returns*Nym AQAgTLqWk4Wse7SvUN7X2L44xoKXgV3tky7Zj8D3xsc5 {color:#d04437}*added*{color}*If a NYM already exists the message should be *Nym AQAgTLqWk4Wse7SvUN7X2L44xoKXgV3tky7Zj8D3xsc5 *{color:#14892c}updated{color}*,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzyanb:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,Toktar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 7:05 PM;Toktar;It is problem in the deprecated client. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Node logs repeat message ""NodeRequestSuspiciousSpike suspicious spike has been noticed""",INDY-541,19729,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,krw910,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,1.0,,,,0,should,SovrinCOREteam,,,,"I have a terminal up just tailing the Node1.log file and saw the following repeated lines.Setup:8 Machines (4 Nodes) (4 Clients)Steps:I did a few small operations like saving the keyring, connecting, disconnecting, and then ran through half of the getting started guide. I have each of the 3 agents (Faber, Acme, Thrift) running from different agents (Agent 2, Agent 3, Agent 4){code}2017-03-31 19:42:07,821 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989327.8211238. Usual: 0.05855855855855854. New: 0.2017-03-31 19:42:08,842 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989328.842461. Usual: 0.05829596412556052. New: 0.2017-03-31 19:42:18,848 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989338.8484602. Usual: 0.05803571428571427. New: 0.2017-03-31 19:42:28,853 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989348.8536355. Usual: 0.057777777777777754. New: 0.2017-03-31 19:42:38,865 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989358.8658032. Usual: 0.05752212389380529. New: 0.2017-03-31 19:42:48,870 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989368.870112. Usual: 0.057268722466960326. New: 0.2017-03-31 19:42:58,882 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989378.882012. Usual: 0.0570175438596491. New: 0.2017-03-31 19:43:07,829 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989387.8292363. Usual: 0.05676855895196504. New: 0.2017-03-31 19:43:08,885 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989388.8854935. Usual: 0.056521739130434755. New: 0.2017-03-31 19:43:18,886 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989398.8866634. Usual: 0.05627705627705625. New: 0.2017-03-31 19:43:28,896 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989408.8962073. Usual: 0.05603448275862066. New: 0.2017-03-31 19:43:38,900 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989418.900946. Usual: 0.05579399141630899. New: 0.2017-03-31 19:43:48,903 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989428.903134. Usual: 0.05555555555555553. New: 0.2017-03-31 19:43:58,912 | WARNING  | notifier_plugin_manager.py (75) | sendMessageUponSuspiciousSpike | NodeRequestSuspiciousSpike suspicious spike has been noticed on node Node1 at 1490989438.9126465. Usual: 0.05531914893617019. New: 0.{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-779,,,,,,,,,,"1|hzx0kv:",,,,,,INDY 17.22,INDY 17.23,,,,,,,,,,,,,,,,,,,avkrishnan,davidlehn,dsurnin,krw910,mgbailey,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Aug/17 12:36 AM;mgbailey;This bug makes the [sovrin-notifier-awssns|https://github.com/evernym/sovrin-notifier-awssns] package nearly useless, since the constant stream of false warnings drowns out any real issues that arise.;;;","09/Aug/17 1:58 AM;davidlehn;Here are some numbers.  For ~8 days this results in an extra ~80k lines and ~20MB of log data.  It logs every 10s and an additional one every 60s.  (Are there two checking timers?)  

From 2017-07-31 17:07:19,745 to 2017-08-08 16:40:15,005:

$ cat digitalbazaar.log* | wc -lc
 81329 20366865

$ cat digitalbazaar.log* | grep -v NodeRequestSuspiciousSpike | wc -lc
 1037 293341;;;","03/Oct/17 8:30 AM;davidlehn;The constant NodeRequestSuspiciousSpike logging appears to be gone in newer releases.;;;","04/Oct/17 8:01 AM;mgbailey;This continues to be a problem.  It may not be manifesting in the logs at the default log level, but I am still getting SMS messages for this from the notification system, like clockwork.;;;","13/Oct/17 6:17 AM;krw910;Additional request for this ticket.
-Be able to disable it by default.
-Fix it so between 0 and 1 does not create a spike. Create a threshold.;;;","30/Oct/17 11:42 PM;dsurnin;added threshold for currents request count - 2. so now is request count less less then 2 the spike check will not be run.

add configuration to config to be able to enable/disable spike check.

Disabled by default!

SpikeEventsEnabled = False - global parameter to enable/disable spike check

Specific spike checks

clusterThroughputSpike': \{
 'enabled': True
 }
 'nodeRequestSpike': \{
 'enabled': True
 } 

 

plenum fab7533e3a2d0d70b36e9147a34e69b938bd14f4

tests

plenum/test/plugin/test_notifier_plugin_manager.py;;;","23/Nov/17 12:16 AM;krw910;The logs have been cleaned up from this message.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Optimize jenkins ubuntu.dockerfiles for all affected repos,INDY-542,19730,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,invalid,,,,,"There is a common pitfall in all ubuntu.dockerfile: separated RUN statements for apt-get update and install like:RUN apt-get update -yRUN apt-get update && apt-get install -y \     package1 \     package2 \     ....It could affect some unnecessary side-effects like installing not-updated packages without running RUN layer with update command.Please, check https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#run for detailsSo, for all affected repos (ledger, plenum, anoncreds, sovrin-common, sovrin-client, sovrin-node, sovringui-ui,  sovrin-notifier-email, stp) we need to do a simple fix like:RUN apt-get update && apt-get install -y \     package1 \     package2 \     ....",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyanj:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
refactor Ci docker images,INDY-543,19731,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,Currently existing ubuntu CI docker images can't be used on a Windows 10 machine because of UID arg. Find a workaround (maybe left it empty by default),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyanr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Wait for WIndows 2016 docker complete support and update pipelines,INDY-544,19732,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,,,,As of now we user virtualenv to run test on Windows 2016 (like on Windows 2012). It's because unlike Windows 10 Windows 2016 does not support linux docker images. Wait for the proper docker support on WIndows 2016 and update test pipelines to use docker for testing.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-66,,,,,,,,,,"1|hzyanz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove checkDeps,INDY-545,19733,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"After migration to Jenkins we no longer do a programmatic validation of dependent packages' versions with [check_deps function|https://github.com/evernym/plenum/blob/master/plenum/common/pkg_util.py#L20] (we rely on pypi to install right version in the first place). We should check if use the function anywhere else, remove the function or maybe the whole file.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyao7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor custom test runner,INDY-546,19734,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"As of now we run test for plenum with [a custom test runner|https://github.com/evernym/plenum/blob/master/runner.py]. We should refactor this runner so that in produces an xml in junit format, move it from plenum to jenkins-shared to be accesible for any repo and update our pipelines accordingly",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyaof:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"When a validator node falls behind by more than 1 version (2 or more), it should be kicked out until it upgrades",INDY-547,19735,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,SovrinCOREteam,,,,"Given there's a Sovrin Validator node that falls behind more than 1 version from the rest of the network, the network should collectively: # Kick out the node (automatically) that's behind until it upgrades# A Trustee (or the Steward of that node??) should be able to re-add the node back to the pool once it upgradesPoA:- Find a way to check that version of a node is below others for more than 1 (use NODE_UPGRADE txn?)- Find who checks that a particular node should be kicked out (the node itself, or the pool by some consensus)  Consider the following example: 4 nodes with versions 1.2.3, 1.2.2, 1.2.3, 1.2.1. Should we make sure that all nodes (even a node with 1.2.2) kicks out the node with version 1.2.1?- Find a time/place when we kick out a node (that is when we check that a version is too below): when we get NODE_UPGRADE txn, or at the startup, or check from time to time.- FInd how we kick out a node: just blacklist it?- Implement the proposed solution*Update:*On completion of each POOL_UPGRADE, each node checks whether other nodes are on an acceptable version by querying the ledger for NODE_UPGRADE txns, if they find they are not, they check if this POOL_UPGRADE can bring make node 1+ version, if yes they wait else not. Once they realise that some node is behind and they make an `OBSOLETE/OUTDATED` txn and once another node agrees that node has fallen behind on the upgrade, it also sends `OBSOLETE` txn.There needs to be configuration parameter specifying how long can a node stay outdated?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-64,,,,,,,,,,"1|hzyaon:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
I should be able to look at the transactions in the ledger,INDY-548,19736,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,unicorn,,,,As per unicorn's SOW requirement number 1.4.1.e: As a presenter presenting unicorn's phase0 demo script I should be able to:# Look at the transaction files in the ledger# Read and understand the transaction files in the ledger[Krishnan] The functionality is already in place. The estimate provided is to do the documentation to explain the contents of the ledger.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-777,,,,,,,,,,"1|hzyaov:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Design how we keep track of connected nodes,INDY-549,19737,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,SovrinCOREteam,,,,As of now plenum monitor can indicate that master is slow and we need a view change only if master is live but it performs poorly. We need to be able to tell that master degraded if it got disconnected.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzyapj:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a prover I should be able to accept claim which I have received,INDY-550,19738,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,unicorn,,,,"Prover should be able to issue a command {{alice> accept claim <claim-name>}} to accept a claim. Accepted claims should be available to generate a proof. Output for {{alice> show claim}}, {{alice> show link}} should clearly specify the state of claim. In output of {{alice> show claim}} command Status should specify it as Accepted. Show link command should show accepted claim in Accepted claims line.h2. [Plan of Attack|https://docs.google.com/document/d/1wWGodhK7tT6eQKwwCpMNPnU15zq_wG4qSk4AuJcg2J0/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-770,,,,,,,,,,"1|hzyap3:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
separate requesting and accepting claims in the CLI commands,INDY-551,19739,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,unicorn,,,,"Following are the changes that needs to be done* Change {{request claim}} command to {{send claim request}}* Response of existing command gets the claim from Issuer and there is no step to accepts it. We need to modify this behaviour, to only get the claim and not accept it. By accept means we means that unaccepted claims cannot be used to generate proof. Only when a user accepts a claim, then it can be used to generate a claim.Things to be taken care of:* Until claim is accepted, it cannot be used in {{> show proof request}} or {{> fulfil proof request}}* Output of {{> show link}} command should output {{Available Claim(s):}} and {{Unaccepted Claim(s)}}. As of now we just show {{Available Claim(s)}}h2. [Plan of Attack|https://docs.google.com/document/d/1iFJ2DdfGcVwwm1kVF7Ke6INbGPFHqI7k7qHviHYeYkk/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-770,,,,,,,,,,"1|hzyapb:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Repeated removal of verkey leads to unexpected errors,INDY-552,19740,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,avkrishnan,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,MGLteam,,,,,"I faced this problem when was following [Ledger team demo for Minimal-go-live|https://docs.google.com/document/d/1NCkFlkWPfJkXh6lGHzk1qbpgcflnd7BV6FyQOPuZnE4/edit]  (but it is not caused by the flow of this tutorial and does not require it's update)If you want to remove verkey you can send NYM transaction with empty verkey parameter. And it works well. But if you want to do it again you get an error which type varies: CouldNotAuthenticate, InvalidSignature*How to reproduce:*Become Steward{code}new key with seed 000000000000000000000000Steward1{code}Create records for DID (1) and CID (2):{code}send NYM dest=4QxzWk3ajdnEA37NdNU5Ktsend NYM dest=2ru5PcgeQzxF7QZYwQgDkG2K13PRqyigVw99zMYg8eML{code}Change their verkeys{code}send NYM dest=4QxzWk3ajdnEA37NdNU5Kt verkey=~8RBNqGxt6TsUL4uHQmpy4rsend NYM dest=2ru5PcgeQzxF7QZYwQgDkG2K13PRqyigVw99zMYg8eML verkey=3xu6EcTXFNi6FjE2KdQ16kogK8qsFA7RNbz1dzaNgQsp{code}Create keys for owners of that records{code}new identifier abbr with seed 00000000000000000000000000000000new identifier 2ru5PcgeQzxF7QZYwQgDkG2K13PRqyigVw99zMYg8eML with seed cidcidcidcidcidcidcidcidcidcidci{code}Become first user and remove verkey{code}use identifier 4QxzWk3ajdnEA37NdNU5Ktsend NYM dest=4QxzWk3ajdnEA37NdNU5Kt verkey={code}On this step there should be no errors. Then send executecommand again:{code}send NYM dest=4QxzWk3ajdnEA37NdNU5Kt verkey={code}{color:#d04437}There should be an error: {color}{code}Error: client request invalid: CouldNotAuthenticate() [caused by string index out of range]{code}Then do the same for seconds user:Become second user and remove verkey{code}use identifier 2ru5PcgeQzxF7QZYwQgDkG2K13PRqyigVw99zMYg8eMLsend NYM dest=2ru5PcgeQzxF7QZYwQgDkG2K13PRqyigVw99zMYg8eML verkey={code}No errors should appear. Send last command again:{code}send NYM dest=2ru5PcgeQzxF7QZYwQgDkG2K13PRqyigVw99zMYg8eML verkey={code}{color:#d04437}I'll get an error:{color}{code}Error: client request invalid: InvalidSignature(){code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyapr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/17 7:43 PM;ozheregelya;[~avkrishnan], 
This is correct behavior. When you send first transaction
send NYM dest=4QxzWk3ajdnEA37NdNU5Kt verkey=
empty verkey will written to the ledger. But your verkey in the wallet (on your machine) was not changed. 
After that, each transaction send by this identifier will be signed with signing key (which accords your old verkey) from your wallet. But transaction will be validated using your new verkey stored in ledger (empty value in your case). 
So, the message ""Error: client request invalid: InvalidSignature()"" just mean that verkey stored in the ledger does not accord to signing key which you are using for signing of transaction. In your case it is expected behavior.

Please, pay attention that now 'verkey=' is invalid in CLI:

 
{code:java}
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBUe6f verkey=
Invalid syntax: 'send NYM dest=V4SGRU86Z58d6TV7PBUe6f verkey='
send NYM
--------
 title: Adds given DID to sovrin
usage: send NYM dest=<target DID> role=<role> [verkey=<ver-key>]
example(s):
 send NYM dest=BiCMHDqC5EjheFHumZX9nuAoVEp8xyuBgiRi5JcY5whi role=TRUST_ANCHOR
 send NYM dest=33A18XMqWqTzDpLHXLR5nT verkey=~Fem61Q5SnYhGVVHByQNxHj
{code}
It was done few months ago because 'verkey=' resulted breaking of the pool.
Here is ticket for empty values in transactions: INDY-22

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ResourceWarning unclosed socket,INDY-553,19741,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,blocked,MGLteam,,,"To reproduce, comment out the corresponding line in warncheck fixture, and run the tests.This may cause unpredictable resource contention.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzyapz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DeprecationWarning in prompt_toolkit,INDY-554,19742,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,MGLteam,,,,"To reproduce, comment out the corresponding lines in warncheck fixture, and run the tests.This may cause issues down the road as support for the function may be removed in a future release of the package",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzyaq7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DeprecationWarning in jsonpickle,INDY-555,19743,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,MGLteam,,,,"To reproduce, comment out the corresponding lines in warncheck fixture, and run the tests.This may cause issues down the road as support for the function may be removed in a future release of the package",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzyaqf:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ResourceWarning unclosed file,INDY-556,19744,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,MGLteam,,,,"To reproduce, comment out the corresponding line in warncheck fixture, and run the tests.This may cause unpredictable resource contention.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzyaqn:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Research how to recover from a massive Trust Anchor mistake,INDY-557,19745,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"This story requires researching how the Board of Trustees, and/or the TGB would recover  if a million identifiers were created on Sovrin by mistake. Possible solutions: Checkpoint solution so we don't ahve to carry a bunch of old retired identifiers",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-62,,,,,,,,,,"1|hzyaqv:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a CLI Issuer I should be able to receive, examine, fulfill and send a Claim Request",INDY-558,19746,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,4Months,unicorn,,,,"This story includes implementing all parts of the [Unicorn Phase 0 script|https://github.com/evernym/unicorn/blob/master/Unicorn_Phase_0_script] in between the sov-694 START and sov-694 END markers. As a CLI Issuer having received a Claim Request, I should be able to:# Open and look at the claim request# Fulfill the claim request (which generates a Claim)# Send the Claim back to the requester (requester == Prover)# Use the above linked script for guidance on the exact CLI commands I should be able to type# Don't feel like the output has to be 100% exact matching the script. You may deviate on the actual format of the Claim Request and Claim itself, etc. Just keep the sentences the same like ""Claim generated successfully"". # The <-- within 2.0"" means that output and the output after it should show up within 2 seconds of executing the previous command.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-770,,,,,,,,,,"1|hzyar3:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/18 7:38 PM;ashcherbakov;IndyNode's CLI is deprecated;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a CLI Prover I should be able to generate and send a Proof to my existing connections,INDY-559,19747,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,4Months,unicorn,,,,"See section marked # [sov-693] START - # [sov-693] END in the [Unicorn Phase 0 script|https://github.com/evernym/unicorn/blob/master/Unicorn_Phase_0_script].Given I am a CLI user acting as a Prover and I have at least one connection, I should be able to: # Generate a proof# That proof should automatically be generated from a simple file which looks similar to this:        Name: ""new address""                Owner Name: Alice                1295 Billow lane road                Eagle Mountain, TX 58985       Issuer signature: [issuer sig goes here]       Issuer DID: [Issuer DID goes here]       Nonce: [nonce goes here]# I should be able to send that generated proof to my connections one at a time like the script shows.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-771,,,,,,,,,,"1|hzyarb:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/18 7:38 PM;ashcherbakov;IndyNode's CLI is deprecated;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node Monitor should not do a view change when a test barely starts.,INDY-560,19748,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:46 AM,30/Mar/19 5:35 AM,,,,,0,4Months,tests,,,,Some time should have elapsed.https://gist.github.com/jasonalaw/1b5d9a1de8208d596d26e0d019eab4a0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzyarj:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/18 7:38 PM;ashcherbakov;Monitor logic was improved to have initial window to gather statistics.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a developer of Indy, I should be able to customize log storing, rolling, etc.",INDY-561,19749,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"As an Evernym or Sovrin Admin: 1. For every piece of software we have: Need to be able to specify the name and location for where the log files are stored 1a. Should be done in a config file. 2. Log rolling-  configuring by sizewhen they get to a certain size (should be configurable), save it off and create a new log file2a. By date - save logs from the past 30 days, etc3. Log rolling - configuring by time -risk of filling up partition -relies on #24. Log depth - configuring how many rolled logs I keep (in same config file) - relies on #25. specifiy the verbosity of the logs (log level)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-779,,,,,,,,,,"1|hzyarr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to prevent a single Trustee or TGB member from acting alone to blacklist a node,INDY-562,19750,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,Currently the way blacklisting has been implemented we have created a single point of failure for a pool. To blacklist a node from the pool you need to be a Trustee or TGB member and it is a single transaction sent to the ledger. The intent is that the Trustees or TGB would come to a verbal consensus to blacklist a node in the pool. Then a single member can send a transaction to the pool to blacklist the node.*Issue:*The issue with this approach is that any one member has the ability to blacklist the pool down to 3 nodes. With only 3 nodes consensus cannot be reached on any transaction including adding back a node to the pool. *Possible Solution:*Instead of a single transaction maybe have two thirds of the Trustees or TGB members or a combination of both each send a transaction to blacklist a node. Once enough transaction requests for the same event occur that node can be blacklisted. This may not be the right approach it is just an example of how to possibly spread out the power.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-46,,,,,,,,,,"1|hzx15z:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make live and sandbox transaction files re-writable,INDY-563,19751,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:32 AM,28/Oct/23 2:46 AM,30/Mar/19 5:32 AM,,,,,0,4Months,,,,,"*Description:*For current moment installation and upgrading the packages (pypi and deb) do not rewrite the files: {code}.sovrin/pool_transactions_live.sovrin/pool_transactions_sandbox.sovrin/transactions_live.sovrin/transactions_sandbox{code}Perhaps, the files should be replaced by newest ones during installation or update in cases when {code}1. the sovrin node was installed on a node but the node was not joined2. the pool genesis was updated3. the node is trying to join to the pool{code}here we have to manually clean up {{.sovrin}}. If the files are re-writable the steward can run just {{apt upgrade sovrin-node}} or {{pip install -U sovrin-node}}.The files{code}.sovrin/pool_transactions_local.sovrin/transactions_local{code}should be not re-writable",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-780,,,,,,,,,,"1|hzyarz:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:56 AM;ashcherbakov;This is already done in the scope of supporting any package to be upgraded;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As someone viewing log messages, every log message should have a time stamp at the beginning",INDY-564,19752,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,MGLteam,,,,"Given I'm any type of User looking at the logs I should see: 1. A timestamp prefixed to every log message following ISO 86012. A time zone -3. Log in UTC-4. Replace the ""T"" with a space in the ISO standard5. Use a comma to separate the seconds and millisecondsExample: [2017-03-08 18:10:22,452+00:00] <log message here>*So that I can debug easier, know what time each log message was sent and so that Evernym has clearer log messages.*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-779,,,,,,,,,,"1|hzyas7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Steward, I should be able to detect a 'new DID transaction' coming from an unauthorized DID",INDY-565,19753,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"As a Steward, I should be able to: # Determine if a 'create new sovrin DID' transaction does NOT come from a DID authorized by a Trust Anchor# If #3 is true, I should be able to reject the transaction.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-773,,,,,,,,,,"1|hzyasf:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RAET replacement with ZMQ - remote socket cannot be disconnected if addr is not known,INDY-566,19754,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,SovrinCOREteam,ZeroMQ,,,"After replacing RAET with ZMQ:For multipart messages where the addr of the remote socket is not known (listener in ClientZStack), the remote cannot be disconnected, the consequence is that the node cannot forcefully disconnect the client, need to find some way to either send a FIN flag or something else. This mailing list thread and its replies might help, https://lists.zeromq.org/pipermail/zeromq-dev/2016-August/030774.html. Some links from zyre codebase https://github.com/zeromq/zyre/blob/055219523325cef4e87941e07abc39718d7350e4/src/zyre_node.c#L555 and https://github.com/zeromq/zyre/blob/055219523325cef4e87941e07abc39718d7350e4/src/zyre_node.c#L948.",,,600,600,,0%,600,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-41,,,,,,,,,,"1|hzyasn:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
include a provision in ZStack to not have a listener socket,INDY-567,19755,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,SovrinCOREteam,ZeroMQ,,,"-There should be a provision in ZStack to not have a listener socket, Client’s NodeZStack does not need a listener socket.",,,600,600,,0%,600,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-41,,,,,,,,,,"1|hzyasv:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"There should be a provision in ZStack to not have a listener socket, Client’s NodeZStack does not need a listener socket.",INDY-568,19756,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,ZeroMQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-41,,,,,,,,,,"1|hzyat3:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/18 5:50 PM;sergey-shilov;For now NodeZStack is used on the server side only, CLI based on the Client class is deprecated and is going to be removed, this ticket is not relevant and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nominate messages being sent twice,INDY-569,19757,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,SovrinCOREteam,ZeroMQ,,,"grepped for ""nominate"": https://gist.github.com/jasonalaw/ca17c40e4968626e03c1bf1402fdb7fc {code}Seeing what looks like double sending of messages (one line is sending to one node, and the next line the same message sent to all other nodes, including the first one):2017-02-26 12:58:14,798 | DEBUG    | node.py              (1950) | send | Beta sending message NOMINATE(name='Beta:1', instId=1, viewNo=0) to 1 recipients: ['Delta']2017-02-26 12:58:14,800 | DEBUG    | node.py              (1950) | send | Beta sending message NOMINATE(name='Beta:1', instId=1, viewNo=0) to all recipients: ['Delta', 'Gamma', 'Alpha']{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-41,,,,,,,,,,"1|hzyatb:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/18 7:36 PM;ashcherbakov;This ViewChange procedure is deprecated;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ClientZStack should have a provision to disconnect a client,INDY-570,19758,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,SovrinCOREteam,ZeroMQ,,,"For multipart messages where the addr of the remote socket is not known (listener in ClientZStack), the remote cannot be disconnected, the consequence is that the node cannot forcefully disconnect the client, need to find some way to either send a FIN flag or something else. This mailing list thread and its replies might help, https://lists.zeromq.org/pipermail/zeromq-dev/2016-August/030774.html. Some links from zyre codebase https://github.com/zeromq/zyre/blob/055219523325cef4e87941e07abc39718d7350e4/src/zyre_node.c#L555 and https://github.com/zeromq/zyre/blob/055219523325cef4e87941e07abc39718d7350e4/src/zyre_node.c#L948. Once this is done, unskip testClientRetryRequestWhenAckNotReceived and ensure it works",,,,,,,,,,,,,,,,,,,,,,,INDY-986,INDY-1037,,,INDY-1087,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-41,,,,,,,,,,"1|hzypsn:",,,,,,INDY 18.01: Stability+,,,,,,,,5.0,,,,,,,,,,,,ashcherbakov,avkrishnan,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 12:04 AM;sergey-shilov;[~avkrishnan] [~ashcherbakov] [~danielhardman] [~andkononykhin]

Hi all,

sending of FIN segment (i.e. ""graceful shutdown"") is not a proper way of initiation of termination of TCP connection from the server side. The FIN segment is sent when close() is called without any additional flags set for socket, but in this case the kernel holds this socket about 2 minutes in TIME_WAIT state. This is not acceptable for the server side.
 Proper way of termination of TCP connection from the server side is to send RST segment instead of FIN segment. Such segment is sent when close() is called for socket for which SO_LINGER socket option is set with timeout 0. In this case:
 - the kernel drops corresponding socket structure immediately;
 - the client is informed that the server side does not longer expect any TCP segments from this client.

So now I'm looking for any mechanisms that ZMQ provides to achieve such behaviour, further steps depend on it.;;;","22/Dec/17 2:11 AM;sergey-shilov;[~lovesh] [~avkrishnan] [~ashcherbakov] [~andkononykhin]

Hi all,

today we discussed ZMQ issue and summarised our current knowledge, so we propose the following roadmap to solve it:
 # try to find ZMQ API that allows to terminate client connections from the server side, if not then
 # take a look at ZMQ code whether there is some undocumented features to do that, if there is not then
 # propose own patch to ZMQ developers to do that if these changes are not so big, if not then
 # prepare our vision of dividing of node process into 3 processes where node-to-node communication and node-to-client communication are separated processes (mid term solution proposed by [~lovesh]), but in this case we still need possibility to control client connections from the server side.;;;","27/Dec/17 1:56 AM;sergey-shilov;Seems like there is no any ZMQ API to track and close clients connections from the server side using ZMQ_ROUTER socket, so I've created an issue for libzmq:

https://github.com/zeromq/libzmq/issues/2877;;;","10/Jan/18 1:45 AM;sergey-shilov;[~lovesh] [~avkrishnan] [~danielhardman] [~ashcherbakov] [~andkononykhin] [~nage] [~tharmon] [~mgbailey] [~gudkov]

Hi all,

my investigation showed that there is no any ZMQ API to track and close clients connections from the server side. Also there is no way to tell ZMQ to accept no more than N incoming connections per port.
 I've created an issue for libzmq:
 [https://github.com/zeromq/libzmq/issues/2877]
 and the answer from ZMQ guys was ""use firewall and authentication"".

For now we have authentication, it allows to:
 - terminate client connection in case of failed authentication;
 - terminate client connection after handshake timeout (ZMQ_HANDSHAKE_IVL) if some client initiates TCP connection and then becomes silent.

But we have not firewall. As a firewall we can use iptables to limit number of sumultaneous connections per port. Corresponding iptables rule may be added manually by steward or automatically by install script. The questions here is what max number of sumultaneous connections should be specified? Just to remind: the main problem of non-limited number of clients connections is situation when we can not open some file as the limit of opened file descriptors is reached. The main point here is that we always should have ability to open files that are necessary for node functionality. So I propose the following solution:
  1. calculate approximate number of file descriptors needed to open local files, DBs etc. (F)
  2. calculate approximate number of file descriptors needed for communication with other nodes (N)
  3. define some window, i.e. some number of spare file descriptors as two steps above calculate file descriptors approximately (W)
  4. now we can calculate max number of clients connections (X): X = LimitNOFILE - (F + N + W)

Described solution is short term solution.

Mid term solution is to divide the single process node into 3 processes (as proposed by Lovesh):
  1. node-to-node communication
  2. node-to-client communication
  3. all other node logic
 but it looks like we need iptables here too.;;;","11/Jan/18 5:16 PM;ashcherbakov;Although ZMQ works good for Node-to-Node communication, it looks like it's not the best choice for Node-to-Client communication because of ZMQ limitations.
So, we propose the following:
1) use firewall (iptables) as a short-term hotfix;
2) get rid of ZMQ as Node-to-Client solution and use something else. As an option, we can consider a similar approach as for Agent-to-Agemt communication in libindy (use `authcrypt` and any transport, for instance pure http). ;;;","11/Jan/18 9:41 PM;ashcherbakov;Created INDY-1087 and INDY-1085 to address the items above;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a developer interacting with Indy, I need all error messages to have a crisp identifier",INDY-571,19759,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"When developers code against the ledger (going through sovclient.py or its Rust equivalent), they need to know whether their calls succeed or not. If they fail, the error conditions need to be communicated. Today, that communication is textual (an error message). That's a good start, but it is problematic in three ways:1. It can't be localized.2. If the text changes, consuming code that analyzes the error will break.3. There are important challenges to reliably build a knowledge base or refer to an error condition in a forum or stack overflow posts.I believe the solution to this is to associate every error with a number or code that is held invariant across changes to text. (I actually recommend numbers, possibly with a textual prefix, because that is the easiest to pass across a C-callable interface cheaply.)This is not necessarily vital for warnings or less severe logged events -- only for errors.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzyatj:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Alias conflict is not handled gracefully,INDY-572,19760,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,sovrin-node,stats,,,"With {{sovrin-node}}, if it _detects_ a name collision between node aliases, it does not handle things gracefully. Instead it throws a stack trace, as can be seen in this snippet from {{/var/log/syslog}}:{code}Feb 22 04:41:26 play systemd[1]: Starting Sovrin Node...Feb 22 04:41:31 play systemd[1]: Started Sovrin Node.Feb 22 04:41:33 play start_sovrin_node[1962]: Traceback (most recent call last):Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/bin/start_sovrin_node"", line 46, in <module>Feb 22 04:41:33 play start_sovrin_node[1962]:     cliha=cliha)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 73, in __init__Feb 22 04:41:33 play start_sovrin_node[1962]:     config=self.config)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 157, in __init__Feb 22 04:41:33 play start_sovrin_node[1962]:     self.nodeReg)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stacked.py"", line 860, in __init__Feb 22 04:41:33 play start_sovrin_node[1962]:     KITStack.__init__(self, stackParams, msgHandler, registry, sighex)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stacked.py"", line 399, in __init__Feb 22 04:41:33 play start_sovrin_node[1962]:     super().__init__(stackParams, msgHandler, sighex)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stacked.py"", line 275, in __init__Feb 22 04:41:33 play start_sovrin_node[1962]:     super().__init__(**stackParams, msgHandler=self.msgHandler, sighex=sighex)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stacked.py"", line 60, in __init__Feb 22 04:41:33 play start_sovrin_node[1962]:     super().__init__(*args, **kwargs)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/raet/road/stacking.py"", line 156, in __init__Feb 22 04:41:33 play start_sovrin_node[1962]:     **kwa)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/raet/stacking.py"", line 565, in __init__Feb 22 04:41:33 play start_sovrin_node[1962]:     self.restoreRemotes() # load remotes from saved dataFeb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/raet/road/stacking.py"", line 373, in restoreRemotesFeb 22 04:41:33 play start_sovrin_node[1962]:     self.addRemote(remote)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/raet/road/stacking.py"", line 198, in addRemoteFeb 22 04:41:33 play start_sovrin_node[1962]:     super(RoadStack, self).addRemote(remote=remote, dump=dump)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/raet/stacking.py"", line 577, in addRemoteFeb 22 04:41:33 play start_sovrin_node[1962]:     super(KeepStack, self).addRemote(remote=remote)Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/raet/stacking.py"", line 159, in addRemoteFeb 22 04:41:33 play start_sovrin_node[1962]:     raise raeting.StackError(emsg)Feb 22 04:41:33 play start_sovrin_node[1962]: raet.raeting.StackError: StackError: Cannot add remote at name 'play', alreadys exists.Feb 22 04:41:33 play start_sovrin_node[1962]: --- Logging error ---Feb 22 04:41:33 play start_sovrin_node[1962]: Traceback (most recent call last):Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/lib/python3.5/logging/handlers.py"", line 71, in emitFeb 22 04:41:33 play start_sovrin_node[1962]:     if self.shouldRollover(record):Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/common/logging/TimeAndSizeRotatingFileHandler.py"", line 20, in shouldRolloverFeb 22 04:41:33 play start_sovrin_node[1962]:     bool(RotatingFileHandler.shouldRollover(self, record))Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/lib/python3.5/logging/handlers.py"", line 185, in shouldRolloverFeb 22 04:41:33 play start_sovrin_node[1962]:     self.stream = self._open()Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/lib/python3.5/logging/__init__.py"", line 1037, in _openFeb 22 04:41:33 play start_sovrin_node[1962]:     return open(self.baseFilename, self.mode, encoding=self.encoding)Feb 22 04:41:33 play start_sovrin_node[1962]: NameError: name 'open' is not definedFeb 22 04:41:33 play start_sovrin_node[1962]: Call stack:Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/lib/python3.5/asyncio/base_events.py"", line 431, in __del__Feb 22 04:41:33 play start_sovrin_node[1962]:     self.close()Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/lib/python3.5/asyncio/unix_events.py"", line 56, in closeFeb 22 04:41:33 play start_sovrin_node[1962]:     super().close()Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/lib/python3.5/asyncio/selector_events.py"", line 98, in closeFeb 22 04:41:33 play start_sovrin_node[1962]:     super().close()Feb 22 04:41:33 play start_sovrin_node[1962]:   File ""/usr/lib/python3.5/asyncio/base_events.py"", line 410, in closeFeb 22 04:41:33 play start_sovrin_node[1962]:     logger.debug(""Close %r"", self)Feb 22 04:41:33 play start_sovrin_node[1962]: Message: 'Close %r'Feb 22 04:41:33 play start_sovrin_node[1962]: Arguments: (<_UnixSelectorEventLoop running=False closed=False debug=True>,)Feb 22 04:41:33 play systemd[1]: sovrin-node.service: Main process exited, code=exited, status=1/FAILUREFeb 22 04:41:33 play systemd[1]: sovrin-node.service: Unit entered failed state.Feb 22 04:41:33 play systemd[1]: sovrin-node.service: Failed with result 'exit-code'.{code}We should never have a case of uncaught exceptions. They should always be caught and handled gracefullyl",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzyatr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,Toktar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 9:31 PM;Toktar;Gracefully solve of problem was done in the scope of the task INDY-1148 .

Now there are not possible to create several nodes with the same alias.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SendMonitorStats should be disabled by default,INDY-573,19761,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,4Months,sovrin-node,stats,,,"The `sovrin-node` process right now generates the following warning in the log files:{code}2017-02-22 06:36:48,495 | DEBUG    | stats_publisher.py   (72) | _connectionRefused | Connection refused for 127.0.0.1:30000 while sending message: [Errno 111] Connect call failed ('127.0.0.1', 30000){code}This is because it is attempting to communicate with a stats monitoring package, which is not installed/configured by default. So, this functionality should be disabled by default, as well.Currently, to change this behavior, one creates a `.sovrin/sovrin_config.py` file and adds the following line:{code}SendMonitorStats = False{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzyatz:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Mar/18 6:09 PM;ashcherbakov;This is already done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Daemonized process for `start_sovrin_node` should generate a PID,INDY-574,19762,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,daemon,validator,,,"When the ""daemon"" (i.e., `start_sovrin_node`) starts up, it should store its process ID into a `.pid` file.We should also properly clean up after the daemon as it exits.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzyau7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:40 AM;esplinr;Indy Node currently runs as a SystemD service, so this no longer applies.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Get requests on Indy return empty data if the data was not found, it must return an error",INDY-575,19763,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,**NeedsMoreInfo**,4Months,,,,The dev after fixing this should write a test that queries sovrin for # an unadded NYM and the response should contain an error code.# an unadded attribute and the response should contain an error code.# an added SCHEMA and the response should contain an error code.# an added ISSUER_KEY and the response should contain an error code.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzyauf:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Store REVOC_REG in state tree,INDY-576,19764,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzx113:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 6:31 PM;ashcherbakov;We don't have REVOC_REG yet. Once we have it, this task will be the essential part of REVOC_REG story.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Store DDO in state tree,INDY-577,19765,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzx15r:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 6:31 PM;ashcherbakov;We don't have DDO yet. Once we have it, this task will be the essential part of DDO story.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Schema data type validation,INDY-578,19766,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,24/May/19 5:27 AM,28/Oct/23 2:46 AM,24/May/19 5:26 AM,,,,,0,4Months,,,,,Schema data type validationWe need to do proper data type validation when schema based value is exchanged between different parties.,,,,,,,,,,,,,,,,,,,,,,,INDY-2101,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzyaun:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/May/19 5:26 AM;esplinr;Will be addressed as part of our effort to support rich schemas that comply with the emerging W3C standards.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need RPMs for CentOS and similar distros,INDY-580,19768,,Story,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,19/Jul/19 11:53 PM,28/Oct/23 2:46 AM,,,,,,0,4Months,devops,,,,"POA:
- Use _python setup.py bdist_rpm_ to create RPMs out of python packages
- Create RPM packages for system dependencies like libsodium, etc.
- Create a repo for RPMs (for stable, release candidates and dev, similar to how it's done for deb packages)
- A script to publish to the repositories (stable, rc, dev)
- Extend CI pipelines to include build and publishing step.

Notes: I think we could [re-useSahs's work on DEBs|https://github.com/evernym/sovrin-packaging] with some alterations. Have a look at [Releases and CD pipelines architecture and Guides|https://docs.google.com/document/d/1gKf3F_r7WamoIYS_-ts2nruB2VIuiIpjmzPIVNf2VK0/edit]",,,,,,,,,,,INDY-997,,,,,,,,,,,,,,,,INDY-835,INDY-964,IS-1318,,,,,,"07/Mar/18 5:09 PM;bdonneaux;IndyAnonCred-LazyPL.png;https://jira.hyperledger.org/secure/attachment/14734/IndyAnonCred-LazyPL.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-47,,,,,,,,,,"1|hzwx4f:2rzmi",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,avkrishnan,bdonneaux,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Aug/17 10:39 PM;bdonneaux;The above mentioned sovrin-packaging repo can not be found on Github.

Does anyone know what happened to its content?

Maybe [here|https://github.com/hyperledger/indy-node/tree/master/build-scripts/ubuntu-1604]?;;;","05/Sep/17 7:15 PM;bdonneaux;I've spent quite some time trying to ""mirror"" the deb packages I've found in the [sovrin xenial repo|https://repo.sovrin.org/lib/apt/xenial/stable/].

Because CentOS/EPEL does not provide Python 3.5 (only 3.4), I thought it makes sense to look in alternative repositories:
 - [SCLo|https://wiki.centos.org/SpecialInterestGroup/SCLo] - Software Collection ([el7|http://mirror.centos.org/centos/7/sclo/x86_64/rh/rh-python35/])
 - [IUS|https://ius.io/] Community Project ([el7|https://dl.iuscommunity.org/pub/ius/stable/CentOS/7/x86_64/])

Since we've previously tested Sovrin using IUS packages, I've decided to give it a try.
 Using [mock|https://github.com/rpm-software-management/mock] and [fpm|https://github.com/jordansissel/fpm], I've been able to package indy-node and all its declared dependencies.

Here is how a ""yum install"" looks like:

==============================

Package Arch Version Repository Size
 ==============================

Installing:
 python35u-indy-node noarch 1.1.33-1 local 236 k
 Installing for dependencies:
 pbc x86_64 0.5.14-1.el7 local 203 k
 python35u x86_64 3.5.4-1.ius.centos7 local 50 k
 python35u-base58 noarch 0.2.4-1 local 4.6 k
 python35u-charm-crypto x86_64 0.44-0.el7.giteec00df local 460 k
 python35u-dateutil noarch 2.6.1-1 local 188 k
 python35u-indy-anoncreds noarch 1.0.10-1 local 43 k
 python35u-indy-plenum noarch 1.1.24-1 local 561 k
 python35u-intervaltree noarch 2.1.0-1 local 22 k
 python35u-ioflo noarch 1.5.4-1 local 238 k
 python35u-jsonpickle noarch 0.9.5-1 local 25 k
 python35u-lazy-object-proxy x86_64 1.3.1-1 local 13 k
 python35u-leveldb x86_64 0.194-1 local 1.2 M
 python35u-libnacl noarch 1.5.2-1 local 12 k
 python35u-libs x86_64 3.5.4-1.ius.centos7 local 9.1 M
 python35u-msgpack-python x86_64 0.4.6-1 local 12 k
 python35u-orderedset x86_64 2.0-1 local 208 k
 python35u-pip noarch 9.0.1-1.ius.centos7 local 1.8 M
 python35u-portalocker noarch 0.5.7-1 local 7.1 k
 python35u-prompt-toolkit noarch 0.57-1 local 153 k
 python35u-psutil x86_64 5.3.0-1 local 213 k
 python35u-pygments noarch 2.2.0-1 local 727 k
 python35u-pyzmq x86_64 16.0.2-1 local 2.8 M
 python35u-raet noarch 0.6.8-1 local 150 k
 python35u-rlp noarch 0.6.0-1 local 15 k
 python35u-semver noarch 2.7.8-1 local 6.5 k
 python35u-setuptools noarch 33.1.1-1.ius.centos7 local 652 k
 python35u-sha3 x86_64 0.2.1-1 local 72 k
 python35u-six noarch 1.10.0-1 local 10 k
 python35u-sortedcontainers noarch 1.5.7-1 local 28 k
 python35u-timeout-decorator noarch 0.4.0-1 local 6.1 k
 python35u-ujson x86_64 1.33-1 local 57 k
 python35u-wcwidth noarch 0.1.7-1 local 18 k

Transaction Summary
 ====================================

Install 1 Package (+32 Dependent packages)

Total download size: 19 M
 Installed size: 81 M

 

Now busy trying to test node/client to see if it works and what's missing.

But I've to say I'm lost going back and forth between indy and sovrin documentation and trying to understand the differences.

Next step will be to implement script(s) to automate the packaging and try to expose them on a public repo.;;;","06/Sep/17 6:32 AM;danielhardman;Hi, [~bdonneaux]. Exciting progress! I know [~nage] will be excited as well, and may chime in with additional help.

I apologize for the confusion. Here's a quick summary of the state of packages and .deb files, to explain the relationship for RPM work.

The topmost package that all sovrin validators should run is ""sovrin"" (not ""sovrin-node"", ""sovrin-client"", etc–those are old and deprecated names). This package is built from [https://github.com/sovrin-foundation/sovrin.] The sovrin.deb lays down genesis transaction files and not much else right now–but in the future it might include some handy utilities such as the one sovrin validator nodes use to assess their security posture. But I expect that package to always be lightweight and simple. It depends on indy-node (https://github.com/hyperledger/indy-node), which in turn depends on indy-plenum. These two packages are the heart of the software itself.

The client code/CLI in indy-node also has a dependency on indy-anoncreds. We expect this dependency to eventually disappear, as client/CLI code in indy-node migrates into indy-sdk instead.

RPMs should follow this same division. Sovrin != indy-node, because it specifies a governance model and a set of genesis transactions that is a layer on top of indy-node (the raw software). Likewise indy-node (validator logic) must remain separate from indy-plenum (consensus protocol), because indy may use a different consensus protocol (e.g., Hyperledger Fabric) at some point in the future.

Hope this helps.;;;","07/Sep/17 5:06 PM;bdonneaux;Now I got it :P

It is explained on both README pages though. But many documents are still referring to sovrin-node, client and common packages. And since those are still present in the xenial repo, I though they were still used.

Anyway, I've managed to package sovrin as well and its installation by yum trigger the installation of indy-node and the 32 others dependencies.

While I'm waiting to get access to SovrinHelpers Jenkins library to start playing with the pipeline and automate the packaging, I'm testing the packages I've got so far.

Remarks regarding underlying dependencies:
 # [libsodium|https://github.com/jedisct1/libsodium/releases]: Requirements for indy-plenum-1.1.24>reat-0.6.8->libnacl-1.5.2 on Ubuntu refer to libsodium18 v1.0.8-5 which provides libsodium.so.18. CentOS/Redhat/EPEL 7 provides ""only"" libsodium v1.0.5-1 which provides libsodium.so.13. However, the maintainer of the [Fedora package|https://src.fedoraproject.org/rpms/libsodium] - [Remi Collet|https://src.fedoraproject.org/user/remi] - has also published a [libsodium-last v1.0.13-1|http://rpms.famillecollet.com/enterprise/7/remi/x86_64/libsodium-last-1.0.13-1.el7.remi.x86_64.rpm] (but I can't find the the SRPM!). In any case, from what I'm reading in the [code|https://github.com/saltstack/libnacl/blob/v1.5.2/libnacl/__init__.py] of libnacl, the library version should not be an issue, as it looks for so lib in sequence (18, 17, 13, 10, 5, 4) and will pickup the highest one. This being said, the [change logs|https://github.com/jedisct1/libsodium/releases] of latest stable version are stating a few improvement that may impact the performance.
# [pyzmq|https://github.com/zeromq/pyzmq]: Requirements for indy-plenum-1.1.24>pyzmq-16.0.2 can be met with zeromq-devel-4.1.4-5.el7 from EPEL but generating a warnings: ""Detected ZMQ version: 4.1.4, but pyzmq targets ZMQ 4.1.6. libzmq features and fixes introduced after 4.1.4 will be unavailable"". Alternatively, the package can be compiled against the embedded lib (which is 4.1.6) if zeromq-devel is not installed. I've chosen the test this second option. 
# [pbc|https://crypto.stanford.edu/pbc/]: Requirements for indy-anoncreds-1.0.10>Charm-Crypto are met with pbc-devel-0.5.14-1.el7 that we've already packaged a while ago for sovrin-node. I still need to publish the spec somewhere and deal with the lack of stable [release|https://github.com/JHUISI/charm/releases] tag for Charm-Crypto. But I've decided to use a specific [git commit|https://github.com/JHUISI/charm/commit/eec00dfacee4cb879a6bd0ce80f44e390936e2c3] in the mean time in order to package a pre-release version (python35u-charm-crypto-0.44-0.el7.giteec00df).;;;","07/Sep/17 6:30 PM;bdonneaux;If anyone wants to try those ""one shot test packages"" for CentOS7, I've temporarily published them in yum repo [here|https://store.digital-me.nl/public/sovrin-el7-x86_64/].

Disclaimer: most of them are not signed (yet)! Try at your own risk. But any feedback will be appreciated.

Meanwhile, the IUS and Remi keys can be found [here|https://github.com/iuscommunity-pkg/ius-release/blob/master/SOURCES/IUS-COMMUNITY-GPG-KEY] and [there|http://rpms.famillecollet.com/RPM-GPG-KEY-remi].;;;","07/Sep/17 6:46 PM;andkononykhin;Hello, [~bdonneaux]

For now SovrinHelpers (and one more library that is used form it indirectly) actually support external build package process.

All three repos (sovrin, indy-node and indy-plenum) implements deb packages build routine. Please check the following urls:
 * [indy-plenum builder|https://github.com/hyperledger/indy-plenum/blob/c37e8358f02cf438ec12ec1a2e5fa15d28a4501a/Jenkinsfile#L203]
 * [indy-node builder|https://github.com/andkononykhin/indy-node/blob/5fa2f762d479e68a8e02e2b59b94b4c2829284d8/Jenkinsfile#L75]
 * [sovrin builder|https://github.com/sovrin-foundation/sovrin/blob/d88cea91d93b6988bcd1bed7b8aa1c5dfefef7f4/Jenkinsfile#L7]

They are quite the same and expected to support API:

Args:
 * name: name of the package (for now it's always the same as name from the top of the accordant Jenkinsfiles)
 * releaseVersion: triple of numbers, like semver
 * sourcePath: location (absolute path) of cloned github repo in Jenkins workspace

Returns:
 * docker volume name or local path to directory with prepared packages

Returned path/volume then used by uploader logic.

Described scheme was tested and used only with deb packaging and uses prepared infrastructure (apt repository) on repo.sovrin.org.

I guess it could be refactored and adjusted to support multiple packaging but I think we can start with integration of rpm building logic into github repos.

Best regards;;;","07/Sep/17 9:05 PM;bdonneaux;Regarding Charm-Crypto, I've already opened an [issue|https://github.com/JHUISI/charm/issues/143] asking for a better/fresher tag.
According to [jakinyele|https://github.com/jakinyele], we shall see soon a pre-release tag for v0.50.;;;","12/Sep/17 6:16 PM;bdonneaux;Thanks to Sovrin support, I've managed to replay the whole getting-started guide about Alice. 
So I'm now pretty much confident the code is complete, well compiled and correctly packaged for CentOS 7.
Now full steam on the scripting part to build those packages.;;;","19/Sep/17 5:21 PM;bdonneaux;Status:
- our own CI infra has been upgraded to support Docker
- publish on PyPI has been disable in centos branch, so PL can work until package step
- now trying to implement function buildRpmCentos in Jenkins file (based on existing buildDebUbuntu)

REM:
I think an underlying requirement for this issue would be to publish SovrinHelpers Jenkins library in Github. Because it will likely need some tuning to support centos. Starting with some extra options to make it more flexible. For instance, allowing to build packages without publishing them (sort of dryrun). For now I'm reworking it a local Git repo. I wonder how hard it will be to merge later...;;;","20/Sep/17 3:06 AM;bdonneaux;I believe this issue to be pending on and/or impacted by INDY-835.;;;","06/Oct/17 7:27 PM;bdonneaux;Today, I've managed to PR some improvements for indy-node which were required to test the current CD pipeline on CentOS: still building only deb packages, but using Docker 1.12 on a CentOS 7 Jenkins slave.

Once this PR will be merged, I'll create additional PRs for similar changes in the other repos, then only start sending PRs to support CentOS packaging.;;;","08/Dec/17 8:45 PM;bdonneaux;I've been able to package indy-node as rpm in a forked branch using the existing buildscripts as suggested:

[https://github.com/digital-me/indy-node/tree/centos/build-scripts/centos-7.3.1611]

In order to achieve this, I needed to altered a copy of the Jenkins shared lib (SovrinHelpers) which is not publicly available.

But there is now a couple of issues that should help us stitching things together, starting with INDY-997.

As for me, it does not make sense to PR any centos build scripts as long as we can not interact with the shared lib for the packaging steps (without publishing).;;;","07/Mar/18 5:11 PM;bdonneaux;Waiting for the Indy shared lib to be published (INDY-997), I've managed to validate, test and package IndyAnonCreds + PBC and Charm using our own original idea ([https://github.com/digital-me/jenkins-lib-lazy|https://github.com/digital-me/jenkins-lib-lazy]):

 

!IndyAnonCred-LazyPL.png!

TODO: 
 1. Explore ways to tune the lib to support extra steps (before and after docker inside tasks) to act on the produced result (test reports and packages for instances).

2. See how to merge our ""lazy scripts"" in the new shared lib published since by Indy:
 [https://github.com/hyperledger/indy-jenkins-pipeline-lib];;;","08/Mar/18 7:59 AM;bdonneaux;On the way, I have [PR|https://github.com/blynn/pbc/pull/13] some changes in PBC and have the scripts of AnonCreds pointing at a specific [branch|https://github.com/digital-me/pbc/tree/indy-0.5.14] supporting rpm spec in the meantime.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a developer or QA, I need pipelines to check that client works on Mac OS",INDY-581,19769,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,,,,POA:- Setup MacOS machine- Configure MAcOS agent- Integrate MacOS agent into existing test pipelines,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzyawf:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a User, I should revoke a connection by rotating my new key to nothing",INDY-582,19770,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Must-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-55,,,,,,,,,,"1|hzyrc7:",,,,,,"Sprint 18.03 Stability, DKMS",,,,,,,,1.0,,,,,,,,,,,,ashcherbakov,avkrishnan,sergey-shilov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jan/18 11:01 PM;ashcherbakov;I believe it's already supported.

[~anikitinDSR] please make sure.;;;","05/Feb/18 11:40 PM;sergey-shilov;[~SeanBohan_Sovrin], [~ashcherbakov]

Hi all,

does it mean that our CLIs should support command to flush verkey from ledger? For now empty verkey is not allowed by both python-based and IndySDK-based CLIs, and NYM transaction without verkey for existing DID does not flush its' verkey.;;;","07/Feb/18 9:51 PM;sergey-shilov;*Problem state / reason:*

Setting verkey to nothing has not been supported by both server and client side. Flushing verkey logic is needed by user to have ability to go back under guardianship.

*Changes:*

 - Server-side/client-side: now empty verkey (None) is allowed by request/operation validation;
 - Added several tests;
 - Docs are updated.

*Committed into:*

    https://github.com/hyperledger/indy-plenum/pull/521
    https://github.com/hyperledger/indy-node/pull/555
    indy-node 1.2.298-master

*Risk factors:*

    Some non-expected logical errors related to permissions.

*Risk:*

    Medium

*Recommendations for QA:*

The main test-case:

 - Take the python-based client
 - Become a someone who can create NYMs
 - Create new DID and send NYM with verkey
 - Become newly created DID
 - Send NYM for himself with empty verkey (go back under guardianship, operation should succeed)
 - Send NYM for himself with some verkey, operation should fail due to absent verkey in ledger
 - Become origin creator of NYM
 - Update verkey by sending NYM transaction, operation should succeed;;;","08/Feb/18 11:59 PM;VladimirWork;Build Info:
indy-node 1.2.298

Steps to Validate:
1. Take the python-based client.
2. Become a someone who can create NYMs.
3. Create new DID and send NYM with verkey.
4. Become newly created DID.
5. Send NYM for himself with empty verkey (go back under guardianship).
6. Send NYM for himself with some verkey.
7. Become *origin creator* of NYM.
8. Update verkey by sending NYM transaction.

Actual Results:
DID can rotate its verkey to nothing and becomes unable to control it. *Origin creator* can set verkey to this DID if it has empty verkey only.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy User, I should have documentation and a demo around what Consent Receipts are and how they work, how they are used",INDY-583,19771,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Nice-To-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-49,,,,,,,,,,"1|hzyaw7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a User, I should have a dashboard to view, sort, examine and append my consent receipts",INDY-584,19772,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Nice-To-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-49,,,,,,,,,,"1|hzyawn:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a User, I should generate a consent receipt for any data I exchange with my agent",INDY-585,19773,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Nice-To-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-49,,,,,,,,,,"1|hzyawv:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy User, I should generate a consent receipt for any data I exchange with Indy",INDY-586,19774,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Nice-To-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-49,,,,,,,,,,"1|hzyax3:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy User, I should generate a consent receipt for any exchange of data (claim, proof)  between my SSI and a third party",INDY-587,19775,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Nice-To-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-49,,,,,,,,,,"1|hzyaxb:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy User, I should be able to anchor from one Indy node to another Indy node via paired DID",INDY-588,19776,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-43,,,,,,,,,,"1|hzyaxj:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a BitCoin/Ethereum user, I should be able to anchor a bitcoin or ethereum (or other ledger) claim or proof IN to Indy",INDY-589,19777,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,09/Oct/19 5:18 PM,28/Oct/23 2:46 AM,09/Oct/19 5:18 PM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-43,,,,,,,,,,"1|hzyaxr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 5:18 PM;esplinr;Interoperability with other ledgers is a common request, but it is not something we see as a priority in the near term. Therefore we will close this issue as ""deferred"". If someone wants to work on this, they can reopen this issue or raise new ones with more detailed plans.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy User, I should be able to anchor a claim or proof OUT to a bitcoin or enthereum (or other) ledger",INDY-590,19778,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,09/Oct/19 5:19 PM,28/Oct/23 2:46 AM,09/Oct/19 5:19 PM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-43,,,,,,,,,,"1|hzyaxz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 5:19 PM;esplinr;Interoperability with other ledgers is a common request, but it is not something we see as a priority in the near term. Therefore we will close this issue as ""deferred"". If someone wants to work on this, they can reopen this issue or raise new ones with more detailed plans.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy Network should have a method to view the reputation of any Node/Nodes on the ledger,INDY-591,19779,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,09/Oct/19 6:33 PM,28/Oct/23 2:46 AM,09/Oct/19 6:33 PM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-626,,,,,,,,,,"1|hzyay7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:33 PM;esplinr;Every Indy network will do this differently. If we need some common capabilities exposed in Indy, then we will create new issues to define that work and track the effort.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a Indy Stakeholder I should have a method to view the reputation of the Node/Nodes I control on the Ledger,INDY-592,19780,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-777,,,,,,,,,,"1|hzyayf:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy network should have a process for notification of upgrade error and resolution,INDY-593,19781,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx1af:",,,,,,11,12,,,,,,,5.0,,,,,,,,,,,,avkrishnan,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:13 PM;ozheregelya;Named functionality is implemented in monitoring tool and it will work after fix of INDY-995.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Indy network should be notified when a node has not upgraded within 1 day, 2 days, 3 days",INDY-594,19782,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyazr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy network should be notified when a node has upgraded,INDY-595,19783,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyazz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy network should have error handling for Pool Upgrades,INDY-596,19784,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyb07:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As someone who relies on Indy, I need to know the ordering of events on the ledger",INDY-597,19785,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:34 AM,28/Oct/23 2:46 AM,30/Mar/19 5:34 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-63,,,,,,,,,,"1|hzyb0f:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 7:10 AM;ashcherbakov;This is already supported because of timestamp and seqNo;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy network should have a dashboard that represents the performance of a specific Steward (validator or observer or both),INDY-598,19786,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzyb0n:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy network should have a dashboard that represents the overall performance of the system,INDY-599,19787,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,*,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzyb0v:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy Stakeholder, I should have a baseline security training and documentation based on role (developers, end users, IT sysadmins, and board members, Validators, etc.)",INDY-600,19788,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Must-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-60,,,,,,,,,,"1|hzyb13:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy Stakeholder, I should have a bug bounty program to reward community members for finding security issues",INDY-601,19789,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Must-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-60,,,,,,,,,,"1|hzyb1b:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy Stakeholder, I should have a set of requirements and recommendations for security of User endpoints (wallets, vaults)",INDY-602,19790,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Must-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-60,,,,,,,,,,"1|hzyb1j:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Store REVOC_REG in state trie,INDY-603,19791,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzx10f:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Dec/17 5:10 PM;ashcherbakov;SCHEMA and ISSUER_KEY are already stored in state trie.
We don't have REVOC_REG txn yet.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Store DDO and attributes in state trie,INDY-604,19792,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzx0qn:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 6:31 PM;ashcherbakov;We don't have DDO now. So, this task will be an essential part of DDO story.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy employee, I should have access to a resource/service for up-to-date information on the security status of commonly used components in the general tech stack of Indy",INDY-605,19793,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Must-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-60,,,,,,,,,,"1|hzyb1r:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy stakeholder, I should have a defined and documented process for vetting Stewards, Agents, Developers, etc. prior to access to the Indy ledger",INDY-606,19794,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Must-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-60,,,,,,,,,,"1|hzyb1z:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy Steward I should be informed if and when nodes I control have been promoted, demoted or their reputation changed",INDY-607,19795,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:46 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Must-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-60,,,,,,,,,,"1|hzyb27:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy Steward, I should see the status of the nodes I control and their reputation",INDY-608,19796,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Must-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzyb2f:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy stakeholder, I should see some form of visible notification that the ledger and administrative processes (non code) are being routinely tested",INDY-609,19797,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Must-Have,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-60,,,,,,,,,,"1|hzyb2n:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Tech. Gov. Board member, I need to know the general health of the network",INDY-610,19798,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"See #5.b of the [Sovrin Platform Requirements MASTER|https://docs.google.com/document/d/1cglrYjY5UKWF7e5F1FhwOMoJLNGrShDHeoGw7PUama0/edit#] docAs a Technical Governance Board Member, I need to know: # Ongoing thru-put of the network# What/who are all the nodes in the system# How many nodes in the system# How many nodes are being slower than the network average# Average network speed (?)# Unusual spikes in traffic (relates to SOV-352 and SOV -351)# These above items are considered ""general monitoring"" and should be turned ON by default for my viewing.For POA person: *Look at Andrey G's GUI for guidance on completing this story*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzwyxr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Tech. Gov. Board member, I need to know when there are unusual spikes or weird behaviors in the network",INDY-611,19799,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"See #5.e.i of the [Sovrin Platform Requirements MASTER|https://docs.google.com/document/d/1cglrYjY5UKWF7e5F1FhwOMoJLNGrShDHeoGw7PUama0/edit#] docAs a Technical Governance Board Member, I need to know when: # There's unusual spikes in the network# There's unusual/weird behavior# If someone is trying to abuse the system by creating 1 million new ID requests per minute (for example)# If someone is doing way too many verkey lookups in a given amount of time (need to decide what ""too many"" means)# The usage ratio on the network changes in a significant way (we are suddenly doing way more of a given transaction type in proportion to the general mix). For example, we suddenly see a barrage of key revocations or key rotations.# The load on individual validators is skewed significantly (one validator is receiving almost all incoming requests, whereas other validators are never contacted). Note that this doesn't mean one validator is working hard while others are idle, because any request causes all the validators to work for consensus--it just means that we see weird shifts where all the initial requests of the network arrive on a subset of the validators.lower-level: a change in the retry ratio or the timeout ratio between validator nodes# There's a change in how often the network rejects requests because they are malformed (e.g., not signed properly, or lacking required parameters)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzwyxz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Tech. Gov. Board member, I need to know when there's outages in the network",INDY-612,19800,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"See #5f of the [Sovrin Platform Requirements MASTER|https://docs.google.com/document/d/1cglrYjY5UKWF7e5F1FhwOMoJLNGrShDHeoGw7PUama0/edit#] docAs a Technical Governance Board Member, I need to know when: # There are minor outages and which nodes in the network it is affecting# There are major outages and which nodes in the network they are affecting# When there are major outages, I should get an email to [email group name for all tech. gov. board members]. # I should see that the system is degrading gracefully from the outages. # I should see that the system is recovering gracefully from the outages.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzwyy7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a user I need to know that when I get an answer back from Indy it could not have been faked or tampered with,INDY-613,19801,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzyb2v:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 10:12 PM;ashcherbakov;It's already done with state proofs support;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Indy user I want to know that when I get an answer back from the ledger, it is no more than 60 seconds old",INDY-614,19802,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,INDY-933,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzyb33:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 10:14 PM;ashcherbakov;it's done for the case when we have a stable load to the pool, but we don't write signatures every N seconds yet (there is INDY-933 for this);;;","25/Jan/19 9:34 PM;ashcherbakov;Duplicates INDY-933;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As global community we need to be able to lookup 100,000 current verkey’s for specific DID’s PER SECOND",INDY-615,19803,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,explore,performance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzy0gn:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,avkrishnan,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/17 12:57 AM;krw910;[~ozheregelya] [~VladimirWork] We need to test how our performance is today so we know what to improve. Please record your findings in the ticket and assign it back to me.;;;","20/Sep/17 6:03 PM;VladimirWork;[~krw910] Now we spend ~26 seconds on the average to read 1000 NYMs to ledger with --at-once option, ~30000 seconds on the average to read 100k NYMs from ledger without --at-once option (10 clients / 10000 reads for each) and ~4000 seconds on the average to read 100k NYMs from ledger with overmind.sh script (100 clients / 1000 reads for each) (1.1.37 RC version / AWS Performance Pool).
There are an errors during sending more than ~2500 GET_NYMs at once: ""retryForExpected not found in repeating actions"" and at the end of the test run script doesn't disconnect from nodes normally due to exceptions from /usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a community using Indy we need to be able to do 1k identity-creation transactions in 5 seconds,INDY-616,19804,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,explore,performance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-45,,,,,,,,,,"1|hzy0gf:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,avkrishnan,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/17 12:57 AM;krw910;[~ozheregelya] [~VladimirWork] We need to test how our performance is today so we know what to improve. Please record your findings in the ticket and assign it back to me.;;;","19/Sep/17 11:16 PM;VladimirWork;[~krw910] Now we spend ~120 seconds on the average to write 1000 NYMs to ledger with --at-once option (1.1.37 RC version / AWS Performance Pool).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a Win64 user I need the Indy Upgradge mechanism to work with Win64,INDY-617,19805,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,11/Oct/19 7:20 PM,28/Oct/23 2:47 AM,11/Oct/19 7:18 PM,,,,,0,4Months,Upgrade,,,,From Alex: We need to support Upgrading and wait until SOV-337 is complete.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-66,,,,,,,,,,"1|hzyb3b:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 7:18 PM;esplinr;We don't plan to test Indy Node on Windows at this time.

See this comment:

https://jira.hyperledger.org/browse/INDY-66?focusedCommentId=64611&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-64611;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a User I need the Indy Upgrade mechanism to work with CentOS,INDY-618,19806,,Story,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,andrey.goncharov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Nov/17 1:02 PM,28/Oct/23 2:47 AM,,,,,,0,4Months,,,,,Need to be able to upgrade the RPM-based world. POA:- Add CentOS update scripts to sovrin-node repo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-47,,,,,,,,,,"1|hzyb3j:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a Win64 user (Win Server 2012) I need a package-based installer (chocolatey package) for the Sovrin node package,INDY-619,19807,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,alexander.shekhovcov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,nice-have,,,"This builds on top of the [story|https://evernym.atlassian.net/browse/SOV-336] about having an MSI-based install. What we need is a way to issue a command that says, ""install the latest version of sovrin"" -- and then have the package manager go scan its repo(s) to decide what the latest version is, download the .msi-based package, and install it -- then keep track of what's installed so it can do future upgrades.h4. PoAPack the sovrin node and the dependencies in to chocolatey packages ([tutorial|https://github.com/chocolatey/choco/wiki/CreatePackages])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-66,,,,,,,,,,"1|hzyb3r:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tail propagation (Implementation),INDY-620,19808,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,,,,,Implement a way to store and get tails for anoncreds revocation in Sovrin according to design completed in SOV-68.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-44,,,,,,,,,,"1|hzyb3z:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Aug/18 4:28 PM;ashcherbakov;Done on SDK side;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multi-core support (Implementation),INDY-621,19809,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,29/Oct/19 11:10 PM,28/Oct/23 2:47 AM,29/Oct/19 11:10 PM,,,,,0,4Months,,,,,"Today, our python code uses only one core. Because we use deques between processes, it lends itself fairly easily to a multi-process architecture. This story has us improving performance of nodes by leveraging more available cores on the server.h4. [Plan of Attack|https://docs.google.com/document/d/1KSJUkRbmYdUB0bx5_BULF5T8oRqKkuCNRY679JL9g7E/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-2251,,,,,,,,,,"1|i0125u:z",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/19 11:10 PM;esplinr;Our analysis is that it is too expensive to move to a multi-process architecture at this time. We will re-evaluate if we are unable to hit our performance goals with the current architecture.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Dashboard of Public Indy Network (Implementation),INDY-622,19810,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,Placeholder for implementation of Full Design. This will need to be broken up into epics.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzyb47:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verifiable Claims native support (Full Design),INDY-623,19811,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,,,,,"Our claims and proofs don't look like the Verifiable Claims spec. They should follow the VC spec with a special CL (Camenisch-Lysyanskaya) type signature.h4. [Plan of Attack|https://docs.google.com/document/d/1GrA_ah-rRtwjeEYipDtF4sV30JdapbQq6CdUqEtYYl0/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-65,,,,,,,,,,"1|hzyb4f:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:49 AM;ashcherbakov;This is done in [https://github.com/hyperledger/indy-sdk] now;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Trust Anchor or an Organizational Guardian, I should be able to establish a connection with a Partner Agency",INDY-624,19812,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,09/Oct/19 6:25 PM,28/Oct/23 2:47 AM,09/Oct/19 6:25 PM,,,,,0,4Months,James-to-review,stag,,,"Given I am an Organizational Guardian (OG) (defined in the [Sovrin Trust Framework|https://docs.google.com/document/d/1n6if3-JZw8BaRmxm3B9X5mKj_IZPHLqi_khHFOrY-XA/edit#]), I should be able to establish a connection with a Partner Agency (PA).Assumptions: # OG and PA already have a legal services agreement signed.# PA already has a running agency.# PA has an agent for itself.# OG has already installed an agent on its premises.Steps:# PA generates a Connection Invitation (Offer?) and sends to OG out of band in the form of a .sovrin file.# The OG admin then loads the .sovrin invitation file into the OG agent and then accepts the invitation. This results in a Connection Request being sent to the PA through the agent connections. At this point, the OG's pairwise DID and key is written to Sovrin.# PA's agent receives and accepts the incoming Connection Request. It also writes its pairwise DID and key to Sovrin. It then sends a Connection Confirmation to OG’s agent.# OG’s agent records the connection.*[Plan of Attack|https://docs.google.com/document/d/17S5Qo78MpGBUN0UTh6dGzDyGNCTwZUW7LvZ-5vcQxJ0/edit]*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-53,,,,,,,,,,"1|hzyb4n:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:25 PM;esplinr;Our thinking on Guardianship has evolved a lot. It is expected to primarily be supported through DID Doc support and most work will be done in Aries Agents. Therefore we will close these old Indy issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a Trust Anchor I should be able to send a Trust Anchor Invitation,INDY-625,19813,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"Given I am a Trust Anchor acting as an Issuer I should be able to:
# send a special kind of Claim Offer: a Trust Anchor Invitation
# I should only be able to send this type of claim offer to an Independent Identity Owner (both Organizational and Individual)
# Given the Invitee accepts the invitation by sending in return a Claim Request  (covered in SOV-267), requesting I write a Public Claim of MY Trust Anchor Connection with the invitee. I should then be able to:
# Write a Public Claim of MY Trust Anchor Connection with the invitee to the Sovrin ledger.
# Send a message to the invitee pointing them to the Public Claim I wrote.
# When I receive the Claim Request, which is the invitee's Trust Anchor Invitation acceptance (after step 2), all remaining steps in this story should be automated and I should NOT be able to back out or cancel the invitation.
All terms are defined in the [Sovrin Trust Framework|https://docs.google.com/document/d/1n6if3-JZw8BaRmxm3B9X5mKj_IZPHLqi_khHFOrY-XA/edit#]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-62,,,,,,,,,,"1|hzyb4v:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Feb/19 11:56 PM;esplinr;Closing  because this issue is outdated.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node Reputation,INDY-626,19814,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,09/Oct/19 6:35 PM,28/Oct/23 2:47 AM,09/Oct/19 6:34 PM,,,,,0,4Months,,,,,"1. Nodes gossip periodically about latency and availability of other nodes.2. Some summary is written to a separate performance ledger3. This information is published in the public dashboardh2. [Plan of attack|https://docs.google.com/document/d/1upn0RK97fUyBdnZEi5tZKouQZeyPSTcK-W1EtWOddu0]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Node Reputation,Done,,,,,,,,"1|hzyb53:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:34 PM;esplinr;Each Indy network will do this differently. If we need some common capabilities in Indy, we will create new issues to define and track the effort.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Observer publishes state proofs on demand of client,INDY-627,19815,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzyb5b:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 10:18 PM;ashcherbakov;State proof is returned with each Reply, so we can say that this is already supported.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Abstract Observers Support,INDY-628,19816,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,4Months,,,,,https://docs.google.com/document/d/1HcVp0V1RvgHanW_et84ttiga-eWkOaNyzhBzFwsWBIg/edit#,,,,,,,,,,,,,,INDY-1010,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-58,,,,,,,,,,"1|hzypwf:",,,,,,INDY 17.25,,,,,,,,8.0,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/17 12:22 AM;ashcherbakov;PoA:
1) Support Observer and Observable Interface
2) Make Node implement or have an implementation of this Interface
3) Be able to register Observers 
3) Define enum with Observer Policy (have just one item for now: EACH_BATCH)
4) Support Strategy pattern for Observers and propagation of state
5) Propagate state according to the Observer Policy type (for now just support EACH_BATCH)
6) Make Observers process Sata based on the Policy (EACH_BATCH only for now);;;","20/Dec/17 6:55 PM;ashcherbakov;PR: https://github.com/hyperledger/indy-plenum/pull/487;;;","20/Dec/17 7:01 PM;ashcherbakov;*Changes*

- Abstract Observer Support (based on strategies/policies)
- Abstract Observable Support (based on strategies/policies)
- Implemented Observable strategy to propagate each committed Batch to all Observers
- Implemented Observer strategy to apply each committed Batch
- Each Node has Observer and Observable instances
- Communication between Observer/Observable and Nodes is done via messages (BatchCommitted, ObservedData). This is done to simplify future re-factoring for State Machine and Actors Model.
- added required tests

*PR*
- https://github.com/hyperledger/indy-plenum/pull/487

*Covered by Test*
- test/plenum/observers (both unit and integration tests for all entities and communications)

*Risk factor*
- Low, as this will not be really used until we register real observers

*Recommendation for QA*
- As it doesn't affect existing workflow (and tests prove that base functionality works), I think the story can be closed after PR is reviewed and merged.;;;","20/Dec/17 10:47 PM;ashcherbakov;Plenum build 1.2.203;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Full Design for Observers,INDY-629,19817,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"This design should be a ""Full Design"" complete with vertical slices, such that we'll start with simple static validator pool, but then move to a dynamic validator pool that has dynamic promotion and demotion based on downed nodes and poor performance and reputation.We don't have to fully design all aspects of future concerns like node reputation, but we include a good idea of how those concerns will work together.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-58,,,,,,,,,,"1|hzx0vr:",,,,,,INDY 17.24: Node Perf,,,,,,,,5.0,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 12:26 AM;ashcherbakov;Please find the design doc: https://docs.google.com/document/d/1HcVp0V1RvgHanW_et84ttiga-eWkOaNyzhBzFwsWBIg/edit#heading=h.gzcglndoi3x9;;;","06/Dec/17 4:50 PM;ashcherbakov;Discussed with Nathan, proposed to Architects.
I'm going to close the ticket technically, expecting more discussion in Architects channel;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As the Indy Network I should be able to recover from a massive mistake made by a Trust Anchor,INDY-630,19818,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,OnHOLD,,,,"Given I am a Trustee and a Trust Anchor makes a giant mistake, such as it creates millions of identifiers on accident, I along with other Trustees should be able to:# Recover by coming to agreement on modification of the ledger.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-62,,,,,,,,,,"1|hzyb5j:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy Network should be able to handle 1 million + Identities using the ledger,INDY-631,19819,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,VladimirWork,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,explore,performance,,,,A LOCALIZED (not geographically dispersed) Sovrin Network should be able to:1. Handle a total of at least 1 million Identities using the Ledger for a verkey lookup transaction within 1 hour2. I should have local latency less than 10 milliseconds for each transaction.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzwypb:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/17 12:58 AM;krw910;[~ozheregelya] [~VladimirWork] We need to test how our performance is today so we know what to improve. Please record your findings in the ticket and assign it back to me.;;;","03/Jan/18 3:40 AM;krw910;Unable to complete this test due to INDY-1054. I cannot get up to 100k NYMs without the pool stopping due to an issue with view change.;;;","15/Jan/18 12:48 PM;krw910;[~VladimirWork] Once stability issues have been addressed can you try out this scenario to see what the limitations are.;;;","19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a Trust Anchor I should be able to create 1 million plus Identities on Indy in three hours,INDY-632,19820,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,VladimirWork,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,explore,performance,,,,"Given I am a Trust Anchor, I should be able to:# create 1 million new identifiers on Sovrin in 3 hours. # I should have latency lower than 1 second for each transaction",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzwylr:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/17 12:58 AM;krw910;[~ozheregelya] [~VladimirWork] We need to test how our performance is today so we know what to improve. Please record your findings in the ticket and assign it back to me.;;;","03/Jan/18 3:38 AM;krw910;At 8 transactions per second it would take about 35 hours straight to add 1 million NYMs to the ledger.

To meet this requirement we need to sustain at a minimum 93 transactions per second for 3 hours.;;;","04/Jan/18 6:27 AM;krw910;Retest after 18.01;;;","28/Sep/18 6:25 AM;esplinr;We currently achieve 30 NYM writes a second, which is only 1/3 of the goal requested in this story.

However, our current analysis is that this is sufficient for current adoption. We will continue finding performance improvements in other stories. I'm closing this story as ""deferred"".;;;","19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As an Independent Identity Owner I should be able to receive and accept the Indy Identity Owner Agreement,INDY-633,19821,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,NeedDrummond,OnHOLD,,,"Given I am an Independent Identity Owner and I'm writing my first DID to the ledger, I should be required to: # Receive the Identity Owner Agreement (linked below)# Accept the Identity Owner Agreement by checking the boxes in the form# Send the accepted Identity Owner Agreement to 1. Receive the Independent Identity Owner Agreement here (https://docs.google.com/document/d/108RzMIUttXDooJR2CWrXDR-roF3wsk2eHvN-Iwxqq8k/edit#heading=h.s9fy0y2f2m3m) from my Trust Anchor2. I should be able to agree to it in a way that my Trust Anchor can see and verify.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-62,,,,,,,,,,"1|hzyb5r:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a Trust Anchor I need to obtain the Indy Identity Owner Agreement for every Independent Identity I create,INDY-634,19822,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,NeedDrummond,OnHOLD,,,Given I am I Trust Anchor and I am creating Indenpendent Identities on Sovrin:1. I need to be able to obtain the Sovrin Identity Owner Agreement form from EVERY Sovrin Identity I createSovrin Identity Owner Agreement: https://docs.google.com/document/d/108RzMIUttXDooJR2CWrXDR-roF3wsk2eHvN-Iwxqq8k/edit#heading=h.s9fy0y2f2m3m,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1942,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-62,,,,,,,,,,"1|hzyb5z:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a Dependent I should be able to change Guardians,INDY-635,19823,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,09/Oct/19 6:25 PM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,NeedDrummond,,,,Given I am a Dependent Identity Owner (meaning I have a Guardian who controls my Sovrin Identifiers) I should be able to: 1. Instruct my Guardian to transfer Guardianship to another Guardian.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-53,,,,,,,,,,"1|hzyb67:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;","09/Oct/19 6:25 PM;esplinr;Our thinking on Guardianship has evolved a lot. It is expected to primarily be supported through DID Doc support and most work will be done in Aries Agents. Therefore we will close these old Indy issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a Dependent I should be able to get control of my Identifiers from my Guardian,INDY-636,19824,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,INCOMPLETE-STORY,NeedDrummond,,,"Give I am a Dependent Identity Owner, I should be able to:1. Instruct my Guardian to grant me control of my Identifiers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-62,,,,,,,,,,"1|hzyb6f:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a Indy Tech. Gov. Board or group of Stewards we need to be able to invite a new Steward,INDY-637,19825,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,NeedDrummond,,,,As a group of Stewards and/or Sovrin tech. gov. member I need to be able to: # Invite a new Steward to the network,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-62,,,,,,,,,,"1|hzyb6n:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
I need to be able to create a proof which associates my Trust Anchor DID with my Legal Identity,INDY-638,19826,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,INCOMPLETE-STORY,NeedDrummond,,,Given I am a Trust Anchor Invitee I need to: 1. Create a proof associating my Trust Anchor DID with my legal Identity,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-62,,,,,,,,,,"1|hzyb6v:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As an Identity Owner I need to accept an invitation to become a Trust Anchor,INDY-639,19827,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"Given I am an Identity Owner (organization or individual) and not already a Trust Anchor, and I've received a Trust Anchor Invitation, I should be able to: # Create ONE Trust Anchor Identity# I should NEVER be able to create more than ONE Trust Anchor Identity# It is required that I agree to the Identity Owner Agreement AND the Trust Anchor Obligations before I can accept the invitation.# Upon completing Step 3, I should be able to send a Claim Request back to the inviter which requests the Inviter issues a Public Claim of a Trust Anchor Connection to the Sovrin Ledger. NOTE: This Claim Request will be interpreted by the Inviter as my acceptance of the invitation. (denial will be covered in a later story)(Inviter then sees my acceptance and writes a Public Claim of our Trust Anchor Connection to the Ledger, covered in SOV-301)(Then the Inviter sends me a message pointing me to the Public Claim of the Inviter's Trust Anchor Connection with me, newly written to the ledger, also covered in SOV-301)After that is done in SOV-301 I need to be able to: # Write a Public Claim to the ledger of my new Trust Anchor Connection with the Inviter.# Send a message to the Inviter pointing them to the Public Claim I wrote of my new Trust Anchor Connection with the Inviter.# If I complete Step 4, all the rest of the steps should happen automatically.All terms are defined in the [Sovrin Trust Framework|https://docs.google.com/document/d/1n6if3-JZw8BaRmxm3B9X5mKj_IZPHLqi_khHFOrY-XA/edit#]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-62,,,,,,,,,,"1|hzyb73:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multi-core support (Full Design),INDY-640,19828,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Deferred,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,29/Oct/19 11:12 PM,28/Oct/23 2:47 AM,29/Oct/19 11:12 PM,,,,,0,4Months,,,,,"Today, our python code uses only one core. Because we use deques between processes, it lends itself fairly easily to a multi-process architecture. This story has us improving performance of nodes by leveraging more available cores on the server.The following plan of attack assumes usage of ZeroMQ, another option can be RPCh4. [Plan of Attack|https://docs.google.com/document/d/1KSJUkRbmYdUB0bx5_BULF5T8oRqKkuCNRY679JL9g7E/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-2251,,,,,,,,,,"1|i0125u:r",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/19 11:12 PM;esplinr;Our analysis is that it is too expensive to move to a multi-process architecture at this time. We will re-evaluate if we are unable to hit our performance goals with the current architecture.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As the person who pays for a validator node, I want to know it's doing useful things",INDY-641,19829,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"See #5d of the [Sovrin Platform Requirements MASTER|https://docs.google.com/document/d/1cglrYjY5UKWF7e5F1FhwOMoJLNGrShDHeoGw7PUama0/edit#] doc

As the 'budget owner' who pays for the validator node to stay running, I need to see:

# How many transactions my node is participating in?
# The logs on my machine# My node is participating in consensus
# Ongoing thru-put of the Network
#  (optional) if my node is slower/faster than the average node on the network

* Can use or re-purpose the GUI that Andrey G built to help you complete this story

*From Jason:*
Add to dashboard metrics by Steward and Trust Anchor. (This creates visibility into behaviors on which, in the future, other Stewards and Trust Anchors can take action against offenders.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzyb7b:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Dashboard of Public Indy Network (Full Design),INDY-642,19830,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"Includes rate numbers like avg. throughput, avg. latency., identifiers added over time, view changes over timeTotal numbers like total txns, view changes, network uptimeInclude graphsTo the Engineer who is doing the PoA: look at what's already been done by Khagesh and Andrey G. Recommend the metrics we should show. Also, suggest efficient vertical slices. This is not specified in great detail, because this first pass doesn't need to look amazing. Just get it functional. Use the PoA as an opportunity to specify the requirements you think we need, and we can review together.h4. [Plan of Attack|https://docs.google.com/document/d/1p0z0kMTXIiq9LKKjMAIEeef3sy87ShYfQHx7vMTgTnw/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzyb7j:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verifiable Claims native support (Implementation),INDY-643,19831,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,,,,,Our claims and proofs don't look like the Verifiable Claims spec. They should follow the VC spec with a special CL (Camenisch-Lysyanskaya) type signature.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-65,,,,,,,,,,"1|hzyb7r:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:49 AM;ashcherbakov;This is done in [https://github.com/hyperledger/indy-sdk] now;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Native limited support for DDOs,INDY-644,19832,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,1.13.0,,,0,4Months,,,,,"See #4 of [Sovrin Platform Requirements MASTER|https://docs.google.com/document/d/1cglrYjY5UKWF7e5F1FhwOMoJLNGrShDHeoGw7PUama0/edit#] docSupport owner/control sectionsNote to person writing PoA: include in the PoA which DDO sections you recommend to include, and which to omit, and give justification for your recommendation.Include mechanism for ultra-fast transaction signature verification. We need to make sure that we're not having to deserialize a json DDO structure and navigate it to find the key. That would be too slow. We may have to have a simple key-value store for verkeys. Or it could be some kind of LRU cache. Please recommend an approach and justify.This does depend on the Patricia-Merkle Trie. Here is the repository. https://github.com/evernym/stateOld DID/DDO Design document link: https://docs.google.com/document/d/1UGyoLlmv9OMBi-EStDrLFvY6URwlN4hSCfXghRbSgLo/edit#",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-51,,,,,,,,,,"1|hzwx4f:26",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a Crime Boss I should not be able to create millions of fake identites,INDY-645,19833,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,,,,,"See #3 of [Sovrin Platform Requirements MASTER|https://docs.google.com/document/d/1cglrYjY5UKWF7e5F1FhwOMoJLNGrShDHeoGw7PUama0/edit#] doc",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-774,,,,,,,,,,"1|hzyb7z:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:43 AM;ashcherbakov;We allow pluggable payments/fees to address the issue;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy Public Trust Graph and ZKP,INDY-646,19834,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,Research-and-Architecture,,,,"Please take a look here: https://docs.google.com/document/d/1OSlXZ8PX7PfIQzDAInYzOjQg-l4ElqH-AWg8L03Ji8Y/edit# Under section entitled: ""How does a trust anchor’s public identity relate to his/her/its other Sovrin identities?"", the second bullet reads: “For other private identities, the identity owner will need to use a revocable anonymous credential to prove a specific level of trust anchor connections were associated with the identity owner’s public identity.”Task is to research ways to accomplish this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-67,,,,,,,,,,"1|hzyb87:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Proof of Non-Revocation protocol,INDY-647,19835,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,Design and document the protocol for Proof of Non-Revocation that fits with the existing Proving protocol. Share your progress as you go with Dmitry and Jason.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-44,,,,,,,,,,"1|hzx10v:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Dec/17 11:23 PM;ashcherbakov;We already have a Non-revocation protocol;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Steward, I can no longer do anything; my authorized rep can",INDY-648,19836,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"Stewards should not be allowed to have keys, only authorized identifiers. A Steward’s Authorized Rep should be able to do anything the Steward can do today.[PoA|https://drive.google.com/open?id=1EEnplkhhqbxfcmFdYADtJy1cjN4aRxAhxOeVQt2xlNM]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-773,,,,,,,,,,"1|hzyb8v:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Steward Authorized Rep, I should be able to remove another authorized rep.",INDY-649,19837,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"[PoA|https://drive.google.com/open?id=1EEnplkhhqbxfcmFdYADtJy1cjN4aRxAhxOeVQt2xlNM]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-773,,,,,,,,,,"1|hzyb8f:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Steward Authorized Rep, I should be able to add another authorized rep.",INDY-650,19838,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"[PoA|https://drive.google.com/open?id=1EEnplkhhqbxfcmFdYADtJy1cjN4aRxAhxOeVQt2xlNM]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-773,,,,,,,,,,"1|hzyb8n:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Guardian, I should be able to create new Dependent Identities on Sovrin",INDY-651,19839,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,09/Oct/19 6:25 PM,28/Oct/23 2:47 AM,09/Oct/19 6:25 PM,,,,,0,4Months,stag,,,,"As a Guardian, I should be able to: 1. Create new Dependent Sovrin Identities2. Specify the Agent endpoint for the identities I createExample: -Refugee camp creates Sovrin Identities for each refugee, and becomes the Guardian for them, managing the identifiers until the refugees can assert control over their identities. An Organizational Guardian is a type of Trust Anchor which can create a new Dependents. A Dependent is an Individual who must depend on a Guardian to administer the Individual’s identities. Under the [Sovrin Trust Framework|https://docs.google.com/document/d/1n6if3-JZw8BaRmxm3B9X5mKj_IZPHLqi_khHFOrY-XA/edit#], all Dependents have the right to become Independents. Mutually exclusive with Independent.h2. [Plan of Attack|https://docs.google.com/document/d/1oRtl9_p9mkXJlvzL5mghMnvStj5pYNkzUPu2DXtdmYw/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-53,,,,,,,,,,"1|hzyb93:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:25 PM;esplinr;Our thinking on Guardianship has evolved a lot. It is expected to primarily be supported through DID Doc support and most work will be done in Aries Agents. Therefore we will close these old Indy issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
I should be able to load a .sovrin file from a URL directly into the CLI,INDY-652,19840,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,,,,,From James: Downloading .sovrin files before they can be opened by the CLI is awkward -- we should support loading files from a URL directly in the CLI.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-50,,,,,,,,,,"1|hzyb9b:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:39 AM;ashcherbakov;The indy-node-based CLI is deprecated;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a CLI user I need to look up identifiers on Indy and get back an Agent endpoint,INDY-653,19841,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,unicorn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-772,,,,,,,,,,"1|hzyb9j:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:36 AM;ashcherbakov;We are doing this in [https://github.com/hyperledger/indy-sdk] project;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a CLI user I should be able to publish my current local Agent endpoint to Indy so I can receive communication from other Agents (and CLI users),INDY-654,19842,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,unicorn,,,,"To support CLI to CLI communication, the embedded CLI Agent endpoint should be made accessible to those who know the Owner's chosen identifier.We will need to consider the security implications of this, and how we might traverse NAT and firewalls without requiring Evernym to operate a cloud-based port forwarding service...[POA|https://docs.google.com/document/d/1cWB6izREVuNG0Cv3wwcaDejqeiUEyrdGAcTWZQugIkY/edit#]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-772,,,,,,,,,,"1|hzyb9r:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:37 AM;ashcherbakov;We are doing this in [https://github.com/hyperledger/indy-sdk] project;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a CLI user or Agent, I should send and verify nonces to prevent against replay of important messages",INDY-655,19843,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,bulldog,Nice-To-Have,POCteam,unicorn,"There is uncertainty as to whether the nonce generation and verification as represented in the Getting Started guide (and the Bulldog demo) is fully implemented and tested. This is going to be very important when Unicorn begin their testing.1. The nonces should be used and visible where claims and proofs are shown here: https://github.com/evernym/unicorn/blob/master/unicorn/demo/unicorn_phase_0_test.scripth2. [Plan of Attack|https://docs.google.com/document/d/165r9nLCTfzMMRnbdeK0xuiN0KoNjPrZqhICAcdnqt1c/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzyb9z:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Guardian, I should be the only one who can write to the agents I've provisioned",INDY-656,19844,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,09/Oct/19 6:25 PM,28/Oct/23 2:47 AM,09/Oct/19 6:25 PM,,,,,0,4Months,stag,,,,"Given I am a Guardian, I should: 1. Be the only Identity which can write to the Agents of the Sovrin Identities which I've created and am Guardian over. Note: When I am no longer Guardian, and some people assert control over (take control of their private keys) their Sovrin Identity, they will be able to decide who can write to their agent.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-53,,,,,,,,,,"1|hzyba7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:25 PM;esplinr;Our thinking on Guardianship has evolved a lot. It is expected to primarily be supported through DID Doc support and most work will be done in Aries Agents. Therefore we will close these old Indy issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Trust Anchor or an Organizational Guardian, I should be able to request a Partner Agency creates agents",INDY-657,19845,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,09/Oct/19 6:25 PM,28/Oct/23 2:47 AM,09/Oct/19 6:25 PM,,,,,0,4Months,INCOMPLETE-STORY,James-to-review,stag,,"Given I am an Organizational Guardian (defined in the [Sovrin Trust Framework|https://docs.google.com/document/d/1n6if3-JZw8BaRmxm3B9X5mKj_IZPHLqi_khHFOrY-XA/edit#]) and I've created at least one Dependent, I should be able to: # Request a Partner Agency to create an Agent for each Dependent Sovrin Identity I create. # Give me an endpoint for each Dependent's Agent which the Partner Agency creates for me.*[Plan of Attack|https://docs.google.com/document/d/1wOpwDQXOH5F1GPCfhDpvR_I3G-Zu2DkOJDbZd49VMOg/edit]*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-53,,,,,,,,,,"1|hzybaf:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:25 PM;esplinr;Our thinking on Guardianship has evolved a lot. It is expected to primarily be supported through DID Doc support and most work will be done in Aries Agents. Therefore we will close these old Indy issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a CLI user (acting as an Issuer) I should be able to issue a claim,INDY-658,19846,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,unicorn,,,,"Given: # I am a CLI user (Issuer)# I have at least one connection that has sent me a claim request:I should be able to:# Issue a claim to the requester of the claimSo that I can: [Plan of Attack|https://docs.google.com/document/d/1S4ZPZcO2cMj7-FQKC2b3ZKZSf4wJACJ2m5f8-1gXr9g/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-770,,,,,,,,,,"1|hzyban:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a CLI Prover I need to offer an unsolicited proof to one of my connections (Proof Offer),INDY-659,19847,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Won't Do,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,unicorn,,,,"Using claims in my vault, I should be able to:1. Offer a proof to one of my connections. 2. The proof I offer does not contain the proof, it is simply an invitation for a relying party to send a proof request. This story does not cover actually sending any proofs, only offering to send them. Examples: - A restaurant offers proof to Alice of having 25 convenient locations in Utah.- Alice offers proof of her school teaching license to perspective employers and schools.- A business offers proof of its patents to investors.- Alice moves home and offers a proof of her new address to her bank and cellphone provider.PoA- After successful connection a Prover will offer available proofs to end-user(Alice)- Create a CLI command which will send message to Alice about proof details- Command can be something like - -- {{offer proofs <proof_name>}} - Create message having proof details - then send message to Alice’s endpoint using command -- {{offer proofs <proof_name>}} command- Above command will execute {{sendMessage(msg, endpoint_for_alice}} of CLI- {{sendMessage(msg, endpoint_for_alice}} method with will send a message to Alice with all details (proof details and how to get them)- At Alice’s CLI there will be a handler to print incoming message on Alice’s CLI.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-771,,,,,,,,,,"1|hzybav:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 7:17 AM;ashcherbakov;Verifiable claims are implemented in indy-sdk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a CLI Issuer I need to send a claim offer to one of my connections,INDY-660,19848,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,avkrishnan,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,unicorn,,,,"Given I am a CLI user and I have at least one connection, I should be able to: 1. Offer a claim to one of my connections. (This is the equivalent of sending an invitation to send me a claim request)Examples:-A business invites Alice to request a claim containing its valid business license-Joe offers a claim to Alice saying she has blonde hair.-Alice's doctor offers her a claim saying she is in good health.-Alice's insurance company offers her a claim saying Alice is defensive driver.-Ebay issues Alice a claim saying she has 99.98% positive seller feedback.-Patrons offer claims to a restaurant saying it has great service.-Movie critics offer claims to their connections saying a certain movie was worth watching.*POA*_Assumptions_* sender knows endpoint and verkey of receiver* standard claim definitions are already established and mutually agreed upon by all parties involved_POA steps_* Create a CLI command `offer claim <claim-name-version>`. Add a command in sovrin cli. In file sovrin/cli/cli.py, add regex to interpret cli command, add it to lexers and completers. Add command action handler.* offer command handler will get the claim from available claims and will send to receiver* On receiver agent create a handler that accepts incoming claims, cli will need to register to this event, and call already created method which receives claim after `accept invitation`. Once we have available claims added via same method call after `accept invitation`, it will be printed on cli and user can request claim, if he wants.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-770,,,,,,,,,,"1|hzybb3:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a CLI user (Relying Party) I want manage MULTIPLE claim and proof definitions,INDY-663,19851,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,admin,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,bulldog,unicorn,,,Given I am a CLI user and I can create and name JSON proof and claim definitions I should be able to: 1. I should be able to type some command in the CLI to see a list of all my claim and proof defs I've created and named. 3. I should be able to delete a claim definition in the CLI,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-767,,,,,,,,,,"1|hzybfj:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As an Organizational Guardian, I should be able to give permissions to the Dependent Agents over which I am a Guardian",INDY-664,19852,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,09/Oct/19 6:25 PM,28/Oct/23 2:47 AM,09/Oct/19 6:25 PM,,,,,0,4Months,INCOMPLETE-STORY,stag,,,"Given I am an Organizational Guardian over some Dependents (defined in the [Sovrin Trust Framework|https://docs.google.com/document/d/1n6if3-JZw8BaRmxm3B9X5mKj_IZPHLqi_khHFOrY-XA/edit#]), and I already have access to the Dependent's Agents through a Partner Agency, I should be able to: 1. Give permission for those Dependent's Agents to allow their Organizational Guardian's Agent (me) to read/write data to their vaults2. Give permission for those Dependent's Agents to communicate with their Guardian Agent (me)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-53,,,,,,,,,,"1|hzybfr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:25 PM;esplinr;Our thinking on Guardianship has evolved a lot. It is expected to primarily be supported through DID Doc support and most work will be done in Aries Agents. Therefore we will close these old Indy issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Show build badge on public repositories related to indy,INDY-665,19853,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,,,,"We need to show build status of all projects related to sovrin on public repositories.Refer this screenshot  !Badge-github.png|thumbnail! Refer below link for documentation on how to do it.https://github.com/dwyl/repo-badges",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzybfz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verification of any state variable referring the signed state proof,INDY-666,19854,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,4Months,Must-Have,,,,"eg, check if verkey is correct given last state proof",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzybg7:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 10:16 PM;ashcherbakov;It's already possible since we have state proofs;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verification of multisig over state-proof by clients.,INDY-667,19855,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"POA:Sovrin client fetches the last anchored record of the pool ledger before the state proof. It takes the anchor record, and then gets (each client has the same pool ledger as nodes) the node verification keys corresponding to the root hash in the anchored record. Once it has the correct verification keys, it verifies the state proof",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzybgf:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 10:14 PM;ashcherbakov;It's already done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ledger Anchoring,INDY-668,19856,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"POA:We need to distinguish between requests during 3 phase process that go in different ledgers. So there would be different multisigs for each ledger. Only the pool ledger needs to be anchored to the different ledgers, so the identity ledger and config ledger would have periodic entries specifying the sequence number from the pool ledger . Each ledger has a unique id. Pool ledger has id 0, identity ledger has id 1, config ledger has id 1. Identity ledger and config ledger will have entries like this:	{type: “anchor”, ledger_id: 0, root_hash: af190be3341ac, seq_no: 32}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-43,,,,,,,,,,"1|hzybgn:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Storing the multisig in the ledger (the multisig is a request made by the primary),INDY-669,19857,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,lovesh,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"POA:The multisig contains the signed root hash of the state trie, transaction tree and sequence number of the transactions. Multisigs for different ledgers go into their respective ledgers, so a multisig over pool ledger goes into the pool ledger, multisig over identity ledger goes into the identity ledger and so on.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzybgv:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/17 10:17 PM;ashcherbakov;We already have it (it's stored in a separate key-value storages). We have it for Domain ledger only. We have INDY-1068 for pool state support.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Signed State,INDY-670,19858,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Must,Must-Have,sprint11-goal-state-proof,,,"Multisig mechanism in consensus protocol.
 This is on hold as we might do a different signature scheme called BLS as shown here [https://github.com/evernym/anoncreds-priv/blob/bls-sig/anoncreds/bls_experiment.py]. Please find the paper attached. [^BLS-BFT.pdf]. Here is a supporting doc [https://docs.google.com/document/d/1WRkqNqXXi1LoVxZu0C353uR0KRatoQuvrV_UZNDuNcc/edi|https://docs.google.com/document/d/1WRkqNqXXi1LoVxZu0C353uR0KRatoQuvrV_UZNDuNcc/edit]
h3.  ",,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,,,,,,IS-314,INDY-858,INDY-859,INDY-927,,,,,"24/Oct/17 3:42 AM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/12721/Node1.log","24/Oct/17 3:42 AM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/12722/Node2.log","24/Oct/17 3:42 AM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/12723/Node3.log","24/Oct/17 3:42 AM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/12724/Node4.log","18/Oct/17 9:40 PM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/12514/_node1.txt","18/Oct/17 9:40 PM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/12515/_node2.txt","18/Oct/17 9:40 PM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/12516/_node3.txt","25/Oct/17 12:26 AM;VladimirWork;bls_negative.PNG;https://jira.hyperledger.org/secure/attachment/12812/bls_negative.PNG","25/Oct/17 12:26 AM;VladimirWork;bls_positive.PNG;https://jira.hyperledger.org/secure/attachment/12811/bls_positive.PNG","18/Oct/17 9:40 PM;VladimirWork;change_bls_3_nodes_pool.PNG;https://jira.hyperledger.org/secure/attachment/12513/change_bls_3_nodes_pool.PNG","24/Oct/17 3:45 AM;ozheregelya;cli.log;https://jira.hyperledger.org/secure/attachment/12725/cli.log","24/Oct/17 6:08 PM;ozheregelya;indy.7z;https://jira.hyperledger.org/secure/attachment/12800/indy.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzyk6v:",,,,,,11,12,13,14,INDY 17.21,INDY 17.22,,,13.0,,,,,,,,,,,,ashcherbakov,avkrishnan,krw910,lovesh,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Aug/17 3:35 PM;lovesh;This POA attached in the ticket was obsolete; we are proceeding with BLS rather than CoSi. Have a look at the attached google doc now;;;","23/Aug/17 10:00 PM;ashcherbakov;A link to PoA: [PoA|https://docs.google.com/document/d/1WRkqNqXXi1LoVxZu0C353uR0KRatoQuvrV_UZNDuNcc/edit#heading=h.myk709jx20js]

The current problems/questions:
1. Crypto lib.
Charm has inappropriate license, while there is no python implementation in milagro.
2. Who calculates the multi-sig (see discussion and proposed Options in PoA): Primary or each node individually.
Each Option has cons and pro. Although calculation of multi-sig of each nodes individually looks more simple and stable, some future features may require to have the same value for multi-sig. So, probably we should follow with Option 2 (Primary calculates and propagates it).
;;;","18/Sep/17 9:55 PM;ashcherbakov;* We created a separate Rust-based indy-crypto lib (with Python wrapper).
* The final multi-sig is created by Primary and propagated to nodes with Pre-Prepares for next batches.
At the same time, each node calculates its own multi-sig to be able to reply immediately for the latest state. The multi-sig for the latest state may be different, but verification will work fine. Once a multi-sig calculkated by a Primary is received for a state, it will replace the multi-sig calculated by the Node, so that eventually we will have equal multi-sigs for all nodes.
* We do not support historical multi-sigs as of now (there is INDY-859 for this)
* Multi-sig config parameters (elliptic curve, generator, etc.) are hard-coded as of now; there is a separate task to store them in config ledger (INDY-858);;;","26/Sep/17 12:08 AM;ashcherbakov;What is done:
    - Supported indy-crypto for working with BLS signatures;
    - Created separate classed (with unit and integration tests) for BLS-related logic;
    - Supported BLS sigs in consensus protocol;

PR:
- https://github.com/hyperledger/indy-node/pull/358

Build:
indy-node 1.1.149

Comments for QA:
- state proofs will be supported in python CLI in the scope of INDY-790 (not this one).
- we need to test the following:
-- test that consensus works when no BLS keys are generated
-- test that consensus works when we have BLS created for some nodes ( < n-f and >= n-f; n-f is BLS consensus)
-- test that consensus works when we have BLS created for all or >= n-f nodes and we have multi-sigs calculated and saved.

How to init BLS for a node:
- run `init_bls_keys --name <NodeName> --seed <seed>`
- note the generated key
- send NODE txn with 'bls_key' in DATA for this node.;;;","27/Sep/17 10:39 PM;krw910;Changed back to test because the subtasks were completed, but the testing is coming from this ticket.;;;","18/Oct/17 9:40 PM;VladimirWork;Build Info:
indy-node 1.1.167

Preconditions:
Install pool of 3 nodes.

Steps to Reproduce:
1. Change blskey for the Node1.
2. Try to add some NYMs.

Actual Results:
NYMs write in Node1 ledger only. See attachments for more info. !change_bls_3_nodes_pool.PNG|thumbnail!  [^_node1.txt]  [^_node2.txt]  [^_node3.txt] 

Expected Results:
The pool should work normally.

Additional Info:
- It's unable to write NYMs at all if we restart Node2 and Node3 after Step 2.
- Is it expected behaviour - node restarts during the send NODE command execution?;;;","21/Oct/17 3:09 AM;ashcherbakov;Problem cause:
* It was not possible to rotate BLS keys without re-starting Nodes;
* Also the Nodes without BLS keys didn't participate in calculation of BKS signatures (although BLS keys are not required to verify signatures) 

Changes:
* Re-factored bls classes to separate signing and verification:
-* split bls crypto to signer and verifier
-* split bls_bft and bls_bft_replica
-* each node always can verify BL sigs and calculate multi-sigs even if it can not create BLS sigs (if BLS keys are not initialized on the node)
* Support correct rotation of BLS keys:
-* Node can work with newly initialized BLS keys without re-start
-* Node works correctly if BLS keys saved in NODE txn and on disk differ
-* added tests

PRs:
* https://github.com/hyperledger/indy-plenum/pull/425
* https://github.com/hyperledger/indy-node/pull/409

Addes tests:
* https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/bls/test_add_bls_key.py
* https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/bls/test_update_bls_key.py
* https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/bls/test_add_incorrect_bls_key.py
* https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/bls/test_update_incorrect_bls_key.py

Build:
master 1.1.172

Recommendation to QA:
* Have a pool without BLS keys; add BLS keys one by one; check that BLS started working after all nodes get keys (no restart required)
* Have a pool without BLS keys; add incorrect BLS keys one by one (send NODE txn with keys different from init_bls_keys result); check that pool still works, but BLS is not enabled
* Have a pool with BLS keys; update BLS keys one by one; check that BLS still works (no restart required)
* Have a pool with BLS keys; update BLS key to incorrect one by one; check that BLS is disabled (since we don't have enough BLS keys for BLS consensus)
Note: Although it's not required to restart the pool, CLI needs to be restarted each changing of keys.;;;","24/Oct/17 12:36 AM;VladimirWork;All bls scripts should be run by ""indy"" user.;;;","24/Oct/17 3:45 AM;ozheregelya;It looks like init_bls_keys still does not work on upgraded pool. See attached logs:
 [^Node1.log] [^Node2.log] [^Node3.log] [^Node4.log] [^cli.log]

UDP: .indy folder of Node1: [^indy.7z];;;","24/Oct/17 6:18 PM;ashcherbakov;The cause of the issye is that `init_bls_key` was called with incorrect alias (node1 instead of Node1), and alias is case sensitive.;;;","25/Oct/17 12:26 AM;VladimirWork;Build Info:
indy-node 1.1.177

Steps to Validate - Case 1:
1. Have a pool with BLS keys.
2. Update BLS keys one by one.
3. Check that BLS still works (no restart required).

Actual Results:
BLS calculates and works normally. !bls_positive.PNG|thumbnail! 

Steps to Validate - Case 2:
1. Have a pool with BLS keys.
2. Update BLS key to incorrect one by one.
3. Check that BLS is disabled (since we don't have enough BLS keys for BLS consensus).

Actual Results:
BLS doesn't work because keys in bls_pk of each node don't match keys in pool ledger. !bls_negative.PNG|thumbnail! ;;;","25/Oct/17 10:46 PM;ozheregelya;Build Info:
indy-node 1.1.178, 1.1.180

Case 2:
1. Set up the pool with old version (without state proofs support).
2. Upgrade it to the latest master.
3. Initialize bls keys on nodes one by one.
4. Send NODE transactions with valid blskey values.
5. Restart the CLI.
6. Stop services on n-1 node, check that GET transactions work.

Actual Results:
Signatures are correct, reading with one node work.

Case 3:
1. Set up the pool with old version (without state proofs support).
2. Upgrade it to the latest master.
3. Initialize bls keys on nodes one by one.
4. Send NODE transactions with invalid blskey values.
5. Restart the CLI.
6. Stop services on n-1 node, check that GET transactions don't work.

Actual Results:
Transactions are not signed when blskeys are invalid.



Full list of verified cases: https://docs.google.com/spreadsheets/d/1XzJ6yK1z4em_N-ZY6IMeGxs54x-ar4uYKOYR_x5_CCo/edit#gid=0;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a CLI user I should be able to create and name a JSON claim definition,INDY-671,19859,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,unicorn,,,,"h2. [Plan of Attack|https://docs.google.com/document/d/1yhPDi9viKErEsvP4kBznJZlZm3dPJid4pOBIkkvGimw/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-767,,,,,,,,,,"1|hzybh3:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a CLI user or Agent I should have access to a well defined schema for claims/proofs,INDY-672,19860,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,danielhardman,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,bulldog,POCteam,unicorn,,"1. Implement and publish a way for claims and proofs to be shared. 1.1 The CLI should use a well defined schema for claims and proofs.2. Publishing the selected way3. Nathan must pass off on this POA4. Should have a serialization example for: claim offerclaim requestproof offerproof requesth2. [Plan of Attack|https://docs.google.com/document/d/1Mer6szvBotAw-u_bC_fcQmXgmoperTl2xqQ2rnJEElQ/edit#]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-768,,,,,,,,,,"1|hzybhb:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:58 AM;ashcherbakov;This is already done in indy-sdk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
As a CLI user (Relying Party) I should be able to create and name a JSON proof definition (locally),INDY-673,19861,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,bulldog,Nice-To-Have,unicorn,,"I should be able to: # Create, name and save a JSON proof definition so I (as a Prover and Owner) can request and offer proofs from the CLI.# The definition can be stored locally (no need to write it to the ledger)h2. [PoA|https://docs.google.com/document/d/10Td0kMl6wOv53OcqcLqhaK_sp_q7k21lJVex7T1l8NQ/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-767,,,,,,,,,,"1|hzybhj:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CI should upload created and tested Docker images to Dockerhub,INDY-674,19862,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andkononykhin,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,Docker,,,"* Create Evernym user on dockerhub* Create a script that uploads image to dockerhub using just created Evernym account* Integrate the script into the pipelines (sovrin-client-dev-deploy and sovrin-client-master-deploy)* Note that we deploy dev and releases separately (releases are deployed only after manual approval from QA)Please refer to the following design doc: [Sovrin Pipeline Design|https://docs.google.com/document/d/1hKwXzX3vsKN97R9F3XVzpCZ7WBOYkyCLuOyrvhCH048/edit#]",,,240,180,,0%,240,180,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzybhr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CI should check that a Docker image is working before publishing it,INDY-675,19863,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andkononykhin,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,Docker,,,"* Run a simple test to check that docker image can be launched and CLI can be started (for sovrin-client-dev-deploy and sovrin-client-master-deploy)Please refer to the following design doc: [Sovrin Pipeline Design|https://docs.google.com/document/d/1hKwXzX3vsKN97R9F3XVzpCZ7WBOYkyCLuOyrvhCH048/edit#]",,,720,720,,0%,720,720,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzybhz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CI should be able to build Docker images for indy-client,INDY-676,19864,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andkononykhin,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,Docker,,,CI build pipelines should be able to create Docker images (for both master and stable branches)PoA:# add task of building docker images for the sovrin-client into deploy pipelines# test,,,480,480,,0%,480,480,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzybi7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance test pipelines to run tests on Windows 10,INDY-677,19865,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andkononykhin,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,,,,"We need to run sovrin-client tests in GoCD for Windows 10* Prepare a VM for Windows 10* Install GoCD agent to the Windows machines* Connect Windows GoCD agents to the GoCD server* Enhance test pipelines for ledger(-dev), anoncreds(-dev), plenum(-dev), sovrin-client(-dev), sovrin-common(-dev) to run tests on Windows 10 (in parallel with ubuntu)* Check that it starts all integration tests and reports results.Please refer to the following design doc: [Sovrin Pipeline Design|https://docs.google.com/document/d/1hKwXzX3vsKN97R9F3XVzpCZ7WBOYkyCLuOyrvhCH048/edit#]",,,,,,,1560,1560,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-66,,,,,,,,,,"1|hzybif:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Publish deb packages to Ubuntu's master repo,INDY-678,19866,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,,,,"In SPLAT-11 we created a procedure of building deb packages. Now we need a way to publish these packages.Ubuntu's master repo looks a good alternative (ppa, or custom repo, or FTP are other alternatives): http://askubuntu.com/questions/16446/how-to-get-my-software-into-ubuntu* Think whether we should publish only release packages to the Ubuntu's master repo, or all packages including dev packages (created by CI on a daily-base).* Define the process of publishing to the master repo, what pre-requisites do we need.* Extend CI pipelines to include publishing step.See Pipelines Design for details: [Sovrin Pipelines Design|https://docs.google.com/document/d/1hKwXzX3vsKN97R9F3XVzpCZ7WBOYkyCLuOyrvhCH048/edit#]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzybin:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tail propagation (Full Design),INDY-679,19867,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,,,,,"Design a way to store and get tails for anoncreds revocation in SovrinSee anoncreds design for details: [Anoncreds design|https://docs.google.com/document/d/1pqyvXCcGAWFm0mHWIh9PsJp0lIdIraUsntf_3HcD294/edit#]- We have an entity we call 'tails'. It's an ordered sequence of elements used for non-revocation proof.- The tails may require quite huge amount of data (~200MB).- The tails are created and uploaded by Issuers.- The tails are required (so must be available for download) for both Provers and Verifiers.- We can cache tails, so we can download them only once.- We need to find a way how to store and transfer tails (one of the options is bit-torrent style).- We probably can not just store tails on Issuer side, as Issuer may be offline.- We had a research on Torrents (https://docs.google.com/document/d/10QUo4xRFaEM9nYCcmpZrOfmWbe44L8zELvOYERS2Eh0/edit)PoA: [link|https://docs.google.com/document/d/15DD6HTZu8ZCyyaBu1jfGyvqEPHDSVHX2ft7Q9AjaQlc/edit]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-44,,,,,,,,,,"1|hzx15j:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:51 AM;ashcherbakov;This is indy-sdk/indy-agent task;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Design] Support anoncreds revocation in Indy,INDY-680,19868,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Support all transaction types related to revocation - [Anoncreds Design|https://docs.google.com/document/d/1pqyvXCcGAWFm0mHWIh9PsJp0lIdIraUsntf_3HcD294/edit]
",,,1920,1920,,0%,1920,1920,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-59,,,,,,,,,,"1|hzyrbj:",,,,,,"Sprint 18.03 Stability, DKMS",,,,,,,,5.0,,,,,,,,,,,,ashcherbakov,avkrishnan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Feb/18 10:47 PM;ashcherbakov;PR with the Design: https://github.com/hyperledger/indy-node/pull/547;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explore: Test 1 million DIDs on ledger,INDY-681,19869,19819,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ozheregelya,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybiv:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explore: Create 1 million DIDs in 3 hours,INDY-682,19870,19820,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ozheregelya,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybj3:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide a description of the error message,INDY-683,19871,19759,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybjb:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gather all the existing error messages,INDY-684,19872,19759,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybjj:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Merge old ddo branch code from old plenum-priv and sovrin-priv repos to new corresponding public repos,INDY-685,19873,19832,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,Merge old ddo branch code from old plenum-priv and sovrin-priv repos to new corresponding public repos,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybjr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
This information is published in the public dashboard,INDY-686,19874,19814,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybjz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Some summary is written to a separate performance ledger,INDY-687,19875,19814,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybk7:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nodes gossip periodically about latency and availability of other nodes,INDY-688,19876,19814,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybkf:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Document the claim/proof definition format,INDY-689,19877,19859,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,This subtask involves creating a document to capture the current claim and proof definition formats in a way that external users/developers on Sovrin can understand and replicate.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybkn:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update getting started guide to cover this functionality,INDY-690,19878,19848,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybkv:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Install and configure Go-Agent on newly configured Win10 VM on AWS,INDY-691,19879,19865,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,andkononykhin,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,480,480,,0%,480,480,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybl3:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a fork to run tests on Windows 10,INDY-692,19880,19865,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Configure sovrin-client(-dev), ledger(-priv), sovrin-common(-dev), plenum(-priv), anoncreds(-priv) pipeline to fork, connect to Windows 10 agent (Jobs in parallel), and wait for the results (do not go further until all tests pass on all platforms)",,,360,360,,0%,360,360,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyblb:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create and configure Windows 10 VM,INDY-693,19881,19865,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,avkrishnan,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,* Create and configure Windows 10 VM to be able to run tests* Install and configure GoCD agent on Windows 10,,,720,720,,0%,720,720,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyblj:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create claim/proof serialization official documentation,INDY-694,19882,19860,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Bulldog,Unicorn,,,,We need Sovrin (open source) documentation explaining claim/proof serialization and it's protocol(s).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyblr:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create claim/proof serialization protocol,INDY-695,19883,19860,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,avkrishnan,avkrishnan,02/Aug/17 6:27 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Bulldog,Unicorn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyblz:",,,,,,,,,,,,,,,,,,,,,,,,,,avkrishnan,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/19 12:11 AM;esplinr;These issues are outdated. The represent early thinking about the project. We have since implemented many of these issues, and are thinking differently about the remaining ones. We will create new issues for the additional work that represent our current thinking.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CI] The test run fails if there is a test exceeding test run limit,INDY-696,19885,,Bug,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,ashcherbakov,ashcherbakov,02/Aug/17 6:43 PM,09/Oct/19 5:28 PM,28/Oct/23 2:47 AM,,,,,,0,4Months,,,,,"Example: https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-320/3/console

Problem cause:
* The test was running more than 100 seconds (default limit for tests) - this is the issue by itself, we have a separate ticket for this.
* `pytest.fail` was called: `indy-plenum/plenum/test/conftest.py`, line 109.
* The tests on CI are executed by https://github.com/evernym/jenkins-shared/blob/master/resources/runner.py
* If `runner.py` sees that a test existed with non-zero code, but there were no error/failures (like in the situation above), it logs the output and exists (doesn't call other tests):
https://github.com/evernym/jenkins-shared/blob/master/resources/runner.py#L60
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzx1hj:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test_batching_scenarios.py fails with timeout intermittently,INDY-697,19886,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,ashcherbakov,ashcherbakov,ashcherbakov,02/Aug/17 6:47 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Stability,,,,,"Example: https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-320/3/consoleFull

We need to investigate why the test fails with the timeout.
Does it succeed eventually (and fails only because of the timeout)?
Or the test gets the pool into a stalled state?

A first look at the log shows that there were some ViewChanges (unexpected though possible?).",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1d3:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 5:49 PM;ashcherbakov;Timebox it to 4-8 hours.;;;","09/Oct/18 5:18 PM;sergey-shilov;Several fixes were made for view change procedure. Also the test timeouts were reviewed and tuned, so this issue is not reproduced any more and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make max transaction size configurable via config ledger,INDY-698,19887,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,dsurnin,dsurnin,dsurnin,02/Aug/17 9:03 PM,01/Oct/20 8:21 AM,28/Oct/23 2:47 AM,29/Oct/19 11:24 PM,,,,,0,4Months,,,,,"At the moment max transaction size is a config parameter and is set on node start.

It should be moved to config ledger and made configurable via POOL_CONFIG transaction.

This setting also should be added to genesis transactions",,,,,,,,,,,,,,,,,,,,,,,INDY-25,,,,INDY-805,INDY-756,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-785,,,,,,,,,,"1|hzx1lz:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/17 6:10 AM;krw910;Also review INDY-805 when looking at this ticket.;;;","29/Oct/19 11:24 PM;esplinr;At some point, we should move the majority of the configuration options from the node specific config file to the config ledger. But this option has not been a problem for us over the past couple of years. As a result, we won't be prioritizing this work in the near future and will close this issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"[Refactor] Make all transactions, requests and replies consistent",INDY-699,19889,,Task,To Develop,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,mzk-vct,ashcherbakov,ashcherbakov,02/Aug/17 9:40 PM,30/May/18 7:59 PM,28/Oct/23 2:47 AM,,,,,,0,4Months,REFACTORING,should,,,"As of now, we may return either serialized json (in GET_ATTR) or json object in Replies (GET_SCHEMA).
Let's make it similar and consistent

Also it would be great to have one very explicit place with format of all requests and schemas (we already have schemas for validation, so maybe just make it more explicit).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1375,,,,,,,,,,"1|hzx0rb:",,,,,,14,INDY 17.21,,,,,,,5.0,,,,,,,,,,,,ashcherbakov,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Oct/17 5:41 PM;mzk-vct;There is a problem in SCHEMA:
In contradistinction to other requests GET_SCHEMA contains key parts (schema name and version) directly in a data field.
This complicates state proof for missing schema - key fields should be removed from data before saving it to State and added back when retrieved. 
It also makes client to check not just data field to be None, but also check whether it contains other fields except schema name and version.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Do not re-serialize data coming from Nodes and Clients,INDY-700,19890,,Story,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,nage,ashcherbakov,ashcherbakov,02/Aug/17 9:44 PM,31/May/18 11:18 PM,28/Oct/23 2:47 AM,,,,,,0,4Months,,,,,"Try to avoid re-serialization (de-serialization of serialized data and re-serialization again) in all places.
* Consider using the serialized data from client as-is. De-serialize it just for analysing, but use the initial (serialized by client) version to put it into the ledger (transactions log and hash store).
* Consider using serialized data from other nodes during catch-up as is. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1375,,,,,,,,,,"1|hzx1ev:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] More earlier pool_upgrade was not happened when there were scheduled upgrade to future date.,INDY-701,19902,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,VladimirWork,ozheregelya,ozheregelya,03/Aug/17 1:33 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,should,,,,,"*Steps to Reproduce:*
1. Send POOL_UPGRADE command for all nodes to 13:00.
{code:java}
send POOL_UPGRADE name=upgrade-oz1 version=1.0.69 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-02T13:00:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-08-02T13:05:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-08-02T13:10:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-08-02T13:15:00.000000+00:00'} timeout=10{code}
2. Send POOL_UPGRADE command for some nodes (with Force flag) to 12:00.
{code:java}
send POOL_UPGRADE name=upgrade-oz2 version=1.0.69 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-02T12:00:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-08-02T12:05:00.000000+00:00'} timeout=10 force=True{code}
 

*Actual Results:*
The first upgrade (13:00) is written to upgrade_log and it happen in accordance with the schedule. The second upgrade (12:00) was not written to upgrade log and was not happened.

*Expected Results:*
The second upgrade (12:00) should be written to upgrade_log and should happen before the first (13:00) upgrade.

*Additional information:*
Both of POOL_UPGRADE commands were send at about 2017-08-02T11:00:00.000000+00:00","*Build Info:*
  indy-node 1.0.69
  indy-anoncreds 1.0.22
  indy-plenum 1.0.78
  sovrin 1.0.15
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes (running locally), 1 client",,,,,,,,,,,,,,,,,,,,,,INDY-382,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzympj:",,,,,,14,INDY 17.21,INDY 17.22,INDY 17.23,,,,,,,,,,,,,,,,,ozheregelya,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Oct/17 12:57 AM;spivachuk;*Problem status:*
- The bug is not reproduced on the current {{master}} version. The issue might be earlier caused by INDY-231 which has already been fixed.

*Covered with tests:*
- {{test_node_reschedules_upgrade_for_proper_datetime}} (added in scope of INDY-382);;;","15/Nov/17 10:39 PM;VladimirWork;The issue is not reproduced on 1.2.210 master. Second pool upgrade cancels the first according to new pool upgrade scheduling logic.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Connect to named networks in CLI,INDY-702,19904,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,nage,mgbailey,mgbailey,03/Aug/17 2:10 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,,,,,"A single cli client should be able to connect to one of various sovrin networks, each with its own pool_transactions file.  For example, a user will want to connect to either the live (provisional) network, the STN, the ESN, or a local test pool.  Each will have its own genesis file, e.g. pool_transactions_live, pool_transactions_STN, pool_transactions_ESN, pool_transactions_localTest, etc., which are all in the .sovrin directory.

The user should be able to select which network to connect to, corresponding to which genesis file to use, by typing the suffix of the genesis file on the connection line, in this fashion:

sovrin> connect live

or

sovrin> connect STN

etc.",,,,,,,,,,,,,,,,,,,,,,,INDY-470,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1mv:",,,,,,,,,,,,,,,,,,,,,,,,,,mgbailey,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/18 4:18 AM;ozheregelya;In sovrin CLI similar functionality was implemented in scope of INDY-831 - INDY-833.
In indy-cli this functionality is implemented in pool create command:

 
{code:java}
pool(p1):wallet(wall):did(V4S...e6f):indy> pool create help 
Command:
 pool create - Create new pool ledger config with specified name
Usage:
 pool create [name=]<name-value> gen_txn_file=<gen_txn_file-value>
Parameters are:
 name - The name of new pool ledger config
 gen_txn_file - Path to file with genesis transactions
Examples:
 pool create pool1 gen_txn_file=/home/pool_genesis_transactions
{code}
 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client load time is 45 seconds to connect to a 19 node global pool,INDY-703,19906,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,03/Aug/17 3:41 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Stability,,,,,I have a 19 node globally dispersed pool. When starting the CLI is take 45 seconds to connect to all nodes in the pool.,,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzypyf:",,,,,,INDY 17.24: Node Perf,INDY 17.25,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,nage,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Aug/17 7:38 AM;nage;Lets get a strategy of how to deal with this and then triage whether it is worth pursuing the fix yet.;;;","27/Sep/17 5:50 AM;krw910;We should retest this after state proofs are completed.;;;","23/Nov/17 3:53 PM;ashcherbakov;[~krw910] will you be able to re-test this?

# I'm not sure that stat proof the behaviour (we still connect to all nodes, since we need it for write).
# I think loading may take a long time because of catch-up of pool ledger.
# Was the pool ledger huge when the problem reproduced?  
# Was it a first run of client?;;;","12/Dec/17 2:33 AM;krw910;I want to close this ticket and test load times again with Libindy CLI once that has been completed.

Current CLI load time is still 39 seconds for 19 nodes.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Release Notes - Sovrin Aries 1.0 - Updates,INDY-704,19907,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,TechWritingWhiz,TechWritingWhiz,03/Aug/17 3:43 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,07/Aug/17 12:00 AM,0,documentation,,,,,"Please add the requested information to the Release Notes, which includes some important information. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybn3:",,,,,,10,,,,,,,,,,,,,,,,,,,,TechWritingWhiz,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/17 5:37 AM;TechWritingWhiz;This has been done and the pull request is here: 

INDY-704 Release Notes - Adds Additional Info

Adding additional information to cover time stamps, terminology changes
in the CLI, a new emergency command for Trustees and keyring to wallet
directory information.

[https://github.com/sovrin-foundation/sovrin/pull/11]

 ;;;","04/Aug/17 9:58 PM;VladimirWork;The Release Notes are actualized.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unicorn agents fail on 'show proof request',INDY-705,19909,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,,mgbailey,mgbailey,03/Aug/17 6:28 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"If a connection-request is loaded, and then a modified version of it is loaded again, the modified one having proof-request data, 'show proof request' fails.  Here is the exact sequence (from the unicorn storyboard script):
{quote}
h4. 3.1.2.4  Establish Connection to unicornA

# replace path with absolute path to .sovrin file
$ load sample/alice/unicornA-invitation.sovrin

# to see invitation run
$ show connection ""UnicornA""

# to accept invitation run
$ accept request from ""UnicornA""
h4. 3.1.2.5  Respond to Proof Request

# to show proof request behaviour, we are loading proof-request from
# invitation file
# replace path with absolute path to .sovrin file
$ load sample/alice/unicornA-proof-request-banking.sovrin

# Check proof request in link
$ show connection ""UnicornA""

# Check how proof request will be fulfilled
$ show proof request ""Proof-Banking-Relationship""
{quote}
The result (from the cli.log):

2017-08-02 10:31:17,181 | ERROR    | base_events.py       (1148) | default_exception_handler | Task exception was never retrieved
future: <Task finished coro=<SovrinCli._fulfillAndShowConstructedProof() done, defined at /usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py:1558> exception=AttributeError(""'list' object has no attribute 'keys'"",)>
Traceback (most recent call last):
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
    result = coro.send(None)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 1559, in _fulfillAndShowConstructedProof
    fulfilled = await self.fulfillProofRequest(proof_request_name)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 1540, in fulfillProofRequest
    return await self._fulfillProofRequestByContext(self.curContext)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 1501, in _fulfillProofRequestByContext
    c.proofRequest.attributes)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/agent/agent_prover.py"", line 195, in getClaimsUsedForAttrs
    for key in attributes.keys():
AttributeError: 'list' object has no attribute 'keys'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybqn:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 1:18 AM;mgbailey;Moving this to [EN-20|https://evernym.atlassian.net/browse/EN-20];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Copy Paste of the commands from ""Working with Nodes and Clients.pdf"" document is not working all the time.",INDY-706,19911,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,SowjanyaPV7,SowjanyaPV7,03/Aug/17 3:58 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybr3:",,,,,,,,,,,,,,,,,,,,,,,,,,SowjanyaPV7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/17 4:02 PM;SowjanyaPV7;If we install ubuntu server on VM and try to copy paste and execute the commands: 

1. Copy Paste from local machine to ubuntu server on VM is not working in MAC. If we enable drag and drop option to bidirectional then copy paste will work on linux machines but it's not working on MAC.
2. So I have installed ubuntu desktop on VM and executing the commands.

-When I tried to copy paste the commands, some white spaces and new lines are getting created. It is causing the command to fail each time.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Command Failure: new key with seed 000000000000000000000000Trust-ee1,INDY-707,19912,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,SowjanyaPV7,SowjanyaPV7,03/Aug/17 4:13 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybrb:",,,,,,,,,,,,,,,,,,,,,,,,,,SowjanyaPV7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/17 4:18 PM;SowjanyaPV7;1.When I executed ""new key with seed 000000000000000000000NameOfSteward"" command it gave error saying ""new command not found"", installed it using ""sudo apt install nmh"" then it executed fine.

2.When I executed ""new key with seed 000000000000000000000000Trust-ee1"" command it is saying ""The program 'new' is currently not installed. You can install it by typing: sudo apt install nmh"" even though i installed ""nmh"" earlier. I tried again to install nmh but it was saying it's already installed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Command Failure: use DID V4SGRU86Z58d6TV7PBUe6f,INDY-708,19913,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,SowjanyaPV7,SowjanyaPV7,03/Aug/17 4:21 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybrj:",,,,,,,,,,,,,,,,,,,,,,,,,,SowjanyaPV7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/17 4:23 PM;SowjanyaPV7;When I executed ""use DID V4SGRU86Z58d6TV7PBUe6f"" command it is saying: 

""No command 'use' found, did you mean:
 Command 'nse' from package 'ns2' (universe)
 Command 'muse' from package 'muse' (universe)
 Command 'fuse' from package 'fuse-emulator-sdl' (universe)
 Command 'fuse' from package 'fuse-emulator-gtk' (universe)
use: command not found"";;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
publish only to repo.sovrin.org,INDY-709,19922,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,danielhardman,danielhardman,03/Aug/17 10:41 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,CI/CD/Update,,,,,"None of the packages we're currently releasing should end up being published on evernym's repo, since all of them are open source. Change destination so all of them end up on repo.sovrin.org. This will require some adjustment to CI pipelines.",,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzye87:",,,,,,10,11,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,danielhardman,TechWritingWhiz,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 10:09 PM;alexander.shekhovcov;TODO:
* clean up the deb packages in repo.evernym.com
* correct the install documentation 
* do not build ujson (there is the same package in the canonical archive);;;","10/Aug/17 7:22 PM;alexander.shekhovcov;How to clean up:
* login repo.evernym.com instance
* remove each version the following packages from each component:
{code}
indy-anoncreds
indy-plenum
libpbc0
libpbc-dev
python3-anoncreds
python3-base58
python3-charm-crypto
python3-intervaltree
python3-ioflo
python3-ledger
python3-orderedset
python3-plenum
python3-prompt-toolkit
python3-pyzmq
python3-raet
python3-rlp
python3-sha3
python3-state-trie
python3-stp
python3-timeout-decorator
{code}

as a result all component must be empty:
{code}
lab/                                               19-Jul-2017 13:02                   -
master/                                            19-Jul-2017 13:02                   -
master-latest/                                     19-Jul-2017 13:02                   -
migrations-test/                                   19-Jul-2017 13:02                   -
migrations-test-latest/                            19-Jul-2017 13:02                   -
new-names/                                         19-Jul-2017 13:02                   -
new-names-latest/                                  19-Jul-2017 13:02                   -
rc/                                                19-Jul-2017 13:02                   -
rc-latest/                                         19-Jul-2017 13:02                   -
repo-merge/                                        19-Jul-2017 13:02                   -
repo-merge-latest/                                 19-Jul-2017 13:02                   -
stable/                                            19-Jul-2017 13:02                   -
stable-latest/       
{code}
;;;","10/Aug/17 7:35 PM;alexander.shekhovcov;Remove building ujson package: https://github.com/hyperledger/indy-plenum/pull/330

[~andkononykhin] After the PR is merged please remove python3-ujson from repo.sovrin.org too, the package already exists in the Canonical archive.;;;","10/Aug/17 7:39 PM;alexander.shekhovcov;(i) *How to tests:*

Install sovrin according with the [instruction|https://docs.google.com/document/d/1fUrvt8rEekZmpfHjoeod7ZmWh3ISvSf-18vK5yTH6RY/edit#] (only from repo.sovrin.org is added)

Make sure what you are not able to install the packages (see above) if only repo.evernym.com is added on a machine. ;;;","16/Aug/17 10:46 PM;VladimirWork;Build Info:
indy-node 1.0.108

Steps to Validate:
1. Perform ""echo ""deb https://repo.evernym.com/deb xenial master"" >> /etc/apt/sources.list"" on clear machine.
2. Try to install sovrin or its components.
3. Perform ""echo ""deb https://repo.sovrin.org/deb xenial master"" >> /etc/apt/sources.list"" on clear machine.
4. Try to install sovrin or its components.

Actual Results:
Step 2: installation is failed.
Step 4: installation is successful.;;;","24/Aug/17 6:53 AM;danielhardman;[~tharmon] [~mgbailey] [~TechWritingWhiz]: Once this change is live, install instructions should no longer require anyone to add repo.evernym.com to /etc/apt/sources.list, or to add evernym's PGP key to its signers. I'm not sure what updates will be required; can you please log a ticket about it?;;;","24/Aug/17 7:45 AM;TechWritingWhiz;New ticket has been created per request. INDY-758. Tried to link the new ticket but it says that this ticket is ""blocked"" by the new ticket, which I did not know it would do and is not true. Removed the link. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a separate upgrade ledger,INDY-710,19923,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,nage,andrey.goncharov,andrey.goncharov,03/Aug/17 11:04 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,Enhancement,,,,,Currently we use config ledger to store upgrade txns. We should consider creating a separate upgrade ledger. This will allow us to drop upgrade log because it will basically duplicate upgrade ledger.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybsv:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Pool is broken after changing of system time on 1 - 3 nodes, but it works if time is changed only on node 4",INDY-711,19944,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ozheregelya,ozheregelya,04/Aug/17 5:58 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,should,,,,"h6. Preconditions:

Node 2 is primary.
h6. Steps to Reproduce:

1. Change date on the node.
{code:java}
sudo timedatectl set-ntp false
sudo timedatectl set-time ""2017-08-09 16:59:35""{code}
2. Try to send any transaction using CLI.
 => In case of Node 1 - Node 3 pool is broken, in case of Node 4 transaction was successfully send.

3. Turn back correct date.
{code:java}
sudo timedatectl set-ntp true{code}
4. Restart services on all nodes.

5. Repeat these actions on each node alternately.
h6. Actual Results:

Pool is broken in case of not primary nodes 1 and 3. In case on primary node (node 2) pool is either broken. In case of not primary node 4.
h6. Expected results:

Pool should work: node with incorrect date should be blacklisted, in case of primary node view change should happen.","Build Info:
  indy-node 1.0.77
  indy-anoncreds 1.0.22
  indy-plenum 1.0.79
  sovrin 1.0.15
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes (shakedown pool 3), 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,INDY-281,,,,,,,,"04/Aug/17 6:46 PM;ozheregelya;logs.7z;https://jira.hyperledger.org/secure/attachment/11827/logs.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzyrdb:",,,,,,14,"Sprint 18.03 Stability, DKMS",,,,,,,,,,,,,,,,,,,anikitinDSR,lovesh,ozheregelya,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Aug/17 8:05 PM;lovesh;[~ozheregelya] It is a known limitation, more than f nodes cannot have their time ""unsynced"".;;;","05/Feb/18 8:59 PM;anikitinDSR;This case was tested on lates master. Steps to reproduce:
 * Primary node is Node2.
 * On Node1 was set time 15 minutes less than for other nodes. 
 * Sent NYM from client on Node2
 * PREPREPARE messages was stashed with ""wrong time"" reason
 * When quorum for PREPARE messages was reached message was ordered  ;;;","06/Feb/18 10:52 PM;zhigunenko.dsr;*Environment:*
 indy-node 1.2.296

4-nodes AWS cluster. Node 2 is primary.

*Steps to reproduce:*
 1. Change date on the node 1 (first iteration ~ -1,5 hour, then ~ +24 hours)
 2. Try to send any transaction using CLI (client node with actual time)
 3. Turn back correct date.
 4. Restart services on all nodes.
 5. Repeat steps 1-4 for node 2, node3 and node 4

*Actual results:*
 * There are no issues with send NYMs
 * Output of _validator-info_ is the same on all nodes;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create CI pipeline for Ubuntu 17.04,INDY-712,19948,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,nage,dsurnin,dsurnin,04/Aug/17 9:49 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,Create CI pipeline for Ubuntu 17.04,,,,,,,,,,,,,,,,,,,,,,,INDY-8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyby7:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/17 6:16 AM;stevetolman;We don't feel the need to make a release for a non-LTS version.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accidental tests of indy-node intermittently fail on Jenkins,INDY-713,19952,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,spivachuk,spivachuk,04/Aug/17 11:24 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"Examples of builds with accidental test fails:
https://ci.evernym.com/blue/organizations/jenkins/Sovrin%20Node/detail/PR-277/2/pipeline/
https://ci.evernym.com/blue/organizations/jenkins/Sovrin%20Node/detail/PR-277/3/pipeline/
https://ci.evernym.com/blue/organizations/jenkins/Sovrin%20Node/detail/PR-277/6/pipeline/
https://ci.evernym.com/blue/organizations/jenkins/Sovrin%20Node/detail/PR-278/2/pipeline/
https://ci.evernym.com/blue/organizations/jenkins/Sovrin%20Node/detail/PR-281/1/pipeline/
https://ci.evernym.com/blue/organizations/jenkins/Sovrin%20Node/detail/PR-283/1/pipeline/
https://ci.evernym.com/blue/organizations/jenkins/Sovrin%20Node/detail/PR-283/2/pipeline/
https://ci.evernym.com/blue/organizations/jenkins/Sovrin%20Node/detail/PR-283/3/pipeline/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzybnb:",,,,,,10,,,,,,,,,,,,,,,,,,,,krw910,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Aug/17 11:58 PM;spivachuk;[~andkononykhin] found that a number of Jenkins agents were being short of AWS credits during the last week. These were the following agents:
* ubuntu-1,
* ubuntu-3,
* ubuntu-5,
* ubuntu-6,
* ubuntu-10,
* ubuntu-12.

All the failed steps (runs of tests in top-level packages) of builds from the ticket description were executed on the agents ubuntu-01, ubuntu-03, ubuntu-10, ubuntu-12, i.e. only on agents with lack of AWS credits. For all the pull requests, which these builds relate to, later there were builds with the same steps completed successfully. These successful steps were executed on ubuntu-02, ubuntu-07, ubuntu-08, ubuntu-09, i.e. only on agents without lack of AWS credits.

So most likely the accidental test fails on Jenkins were caused by lack of AWS credits on Jenkins agents.

[~andkononykhin] has fixed the issue with lack of AWS credits on agents. However, some time is needed for the agents to accumulate enough credits to provide acceptable performance. Then we will be watching builds on Jenkins for a few days to ensure that this issue was indeed the cause of accidental test fails.;;;","16/Aug/17 3:34 AM;krw910;I don't see anything QA can do with this ticket so I am passing it on.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testRestoreWalletFile fails locally,INDY-714,19953,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,spivachuk,spivachuk,04/Aug/17 11:35 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,AlexReview,,,,"testRestoreWalletFile from indy-node fails on a local machine on Ubuntu 16.04 VM
[See the log for details|https://gist.github.com/spivachuk/5f4e0ebfa52fd50952a974b4db778f7b]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1pz:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/18 10:47 PM;Derashe;Test passes locally on Ubuntu 16.04 VM.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Command line tool to provide validator status,INDY-715,19974,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,tharmon,tharmon,06/Aug/17 1:05 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,validator-info,,0,report,sprint11-goal-monitoring,tools,validator,,"h2. 1 Overview

As a system administrator responsible for running a validator node, I would like a command line tool that would provide me with the current status of the validator.

h2. 2 Tool Description

Tool name:
 {{validator-info}}

Command line switches:
||Switch||Description||
|{{-v}}|Verbose mode (command line)|
|{{--json}}|Format output as JSON (ignores {{-v}})|

This information should be gathered from the perspective of the queried node. Information should be gathered without querying the ledger pool, but instead from the files on the filesystem and other services. For example, the count of the number of transactions should be based on the local file-based copy of the ledger instead of querying the pool in general. This is also true for the configuration (e.g., port, IP, etc.) for the validator.

h2. 3 Field Descriptions

*{{alias}}*
 Name of the node as it's known in the ledger.

*{{bindings}}* > *{{client}}* > *{{ip}}*
 CIDR address for the client port. Is only shown in the command line output with the {{-v}} switch.

*{{bindings}}* > *{{client}}* > *{{port}}*
 Port number for the client port.

*{{bindings}}* > *{{client}}* > *{{protocol}}*
 Protocol for the client port. Is only shown in the command line output with the {{-v}} switch. Valid values: {{tcp}} or {{udp}}

*{{bindings}}* > *{{node}}* > *{{ip}}*
 CIDR address for the node port. Is only shown in the command line output with the {{-v}} switch.

*{{bindings}}* > *{{node}}* > *{{port}}*
 Port number for the node port.

*{{bindings}}* > *{{node}}* > *{{protocol}}*
 Protocol for the client port. Is only shown in the command line output with the {{-v}} switch. Valid values: {{tcp}} or {{udp}}

*{{did}}*
 Validator's DID.

*{{enabled}}*
 Whether or not the validator service is enabled to restart when the system restarts. Valid values are {{true}} or {{false}}

*{{response-version}}*
 Semantic version for the JSON output of the tool.

*{{state}}*
 Current state of the validator service. Valid values: {{running}}, {{stopped}}, or {{failed}}

*{{timestamp}}*
 The epoch timestamp for when the output was generated. Is only shown in the command line output with the {{-v}} switch.

*{{verkey""}}*
 The verification key for the validator.

*{{metrics}}* > *{{average-per-second}}* > *{{read-transactions}}*
 Average number of read requests per second currently serviced by the validator.

*{{metrics}}* > *{{average-per-second}}* > *{{write-transactions}}*
 Average number of write requests per second currently serviced by the validator.

*{{metrics}}* > *{{transaction-count}}* > *{{config}}*
 Total number of transactions that exist on the config ledger. Is only shown in the command line output with the {{-v}} switch.

*{{metrics}}* > *{{transaction-count}}* > *{{ledger}}*
 Total number of transactions that exist on the ledger.

*{{metrics}}* > *{{transaction-count}}* > *{{pool}}*
 Total number of transactions that exist in the pool ledger.

*{{metrics}}* > *{{uptime}}*
 Number of seconds since the last validator service restart.

*{{pool}}* > *{{reachable}}* > *{{count}}*
 The number of validators in the pool that can be reached (including the validator providing the report).

*{{pool}}* > *{{reachable}}* > *{{list}}*
 List of validators in the pool that can be reached (including the validator providing the report). Is only shown in the command line output with the {{-v}} switch.

*{{pool}}* > *{{total-count}}* "": 6,
 Total number of validators in the pool (including the validator providing the report).

*{{pool}}* > *{{unreachable}}* > *{{count}}*
 The number of validators in the pool that cannot be reached (including the validator providing the report).

*{{pool}}* > *{{unreachable}}* > *{{list}}*
 List of validators in the pool that cannot be reached (including the validator providing the report). Is only shown in the command line output with the {{-v}} switch.

*{{software}}* > *{{indy-node}}*
 Semantic version of the {{indy-node}} package that is install on the machine. Is only shown in the command line output with the {{-v}} switch.

*{{software}}* > *{{sovrin}}*
 Semantic version of the {{sovrin}} package that is install on the machine. If the {{sovrin}} package is not installed, related output is skipped. Is only shown in the command line output with the {{-v}} switch.
h2. 4 Sample Output

Not all attributes are output in the command line version. The command line output also converts second-based times into a more usable format.
h3. 4.1 Command Line (non-verbose)
{code:java}
Validator valPool01 is currently running
Validator DID:    9eij3is93yehd9eohawo3hw8dhs9e323
Verification Key: ~38hfsljasldjf983hw9wohjrojfsosi
Node Port:        9701
Client Port:      9702
Metrics:
  Uptime: 9 days, 16 hours, 33 minutes, 52 seconds
  Total Ledger Transactions:  34847593
  Total Pool Transactions:    103
  Read Transactions/Seconds:  1038
  Write Transactions/Seconds: 42
Reachable Hosts:   5/6
Unreachable Hosts: 1/6
{code}
h3. 4.2 Command Line (verbose)
{code:java}
Validator valPool01 is currently running
Current time:     Sunday, August 6, 2017 3:11:50 AM
Validator DID:    9eij3is93yehd9eohawo3hw8dhs9e323
Verification Key: ~38hfsljasldjf983hw9wohjrojfsosi
Node Port:        9701/tcp on 10.0.0.3/32
Client Port:      9702/tcp on 10.0.7.4/32
Metrics:
  Uptime: 9 days, 16 hours, 33 minutes, 52 seconds
  Total Config Transactions:  5
  Total Ledger Transactions:  34847593
  Total Pool Transactions:    103
  Read Transactions/Seconds:  1038
  Write Transactions/Seconds: 42
Reachable Hosts:   5/6
  valPool01
  valPool02
  valPool04
  valPool05
  valPool06
Unreachable Hosts: 1/6
  valPool03
Software Versions:
  indy-node: 1.0.28
  sovrin:    1.0.3
{code}
h3. 4.3 JSON
{code:java}
{
  ""response-version"": ""1.0.0"",
  ""timestamp"": 1501989110,
  ""alias"": ""valPool01"",
  ""state"": ""running"",
  ""enabled"": ""true"",
  ""did"": ""9eij3is93yehd9eohawo3hw8dhs9e323"",
  ""verkey"": ""~38hfsljasldjf983hw9wohjrojfsosi"",
  ""bindings"": {
    ""node"": {
      ""ip"": ""10.0.0.3/32"",
      ""port"": 9701,
      ""protocol"": ""tcp""
    },
    ""client"": {
      ""ip"": ""10.0.7.4/32"",
      ""port"": 9702,
      ""protocol"": ""tcp""
    }
  },
  ""metrics"": {
    ""uptime"": 837232,
    ""transaction-count"": {
      ""config"": 5,
      ""ledger"": 34847593,
      ""pool"": 103
    },
   ""average-per-second"": {
     ""read-transactions"": 1038,
     ""write-transactions"": 42,
   }
  },
  ""pool"": {
    ""total-count"": 6,
    ""reachable"": {
      ""count"": 5,
      ""list"": [
        ""valPool01"",
        ""valPool02"",
        ""valPool04"",
        ""valPool05"",
        ""valPool06""
      ]
    },
    ""unreachable"": {
      ""count"": 1,
      ""list"": [
        ""valPool03""
      ]
    }
  },
  ""software"": {
    ""indy-node"": ""1.0.28"",
    ""sovrin"": ""1.0.3""
  }
}
{code}",,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,,,,,,INDY-1819,,,,,,,,"29/Aug/17 7:56 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11974/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzwyzr:",,,,,,11,12,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,andkononykhin,tharmon,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Aug/17 12:53 AM;alexander.shekhovcov;For current moment `validator-info` reads json file which the Node prints each 60 sec. Let's see how it works. As the next step communication validator-info with node may be implemented using client-server model. 

*How to test:*
Install 1.0.122+ and make sure that `validator-info` command is available in shell and prints actual information (see description)
;;;","29/Aug/17 7:28 PM;alexander.shekhovcov;[~VladimirWork] `validator-info` returns {{""There are no info files in /home/sovrin/.sovrin""}} first 60 sec after first start. For now that is expected behavior.;;;","29/Aug/17 7:55 PM;VladimirWork;Build Info:
indy-node 1.1.125

Actual Results:
1. Only ""sovrin"" user can run ""validator-info"" cause files are in /home/sovrin/.sovrin.
2. There is no node status in ""validator-info"": ""Validator Node1 is Failed to connect to bus: No such file or directory"" cause ""sovrin"" user can't check ""systemctl status sovrin-node.service"".
3. There are incorrect IPs in ""validator-info -v"" and ""validator-info --json"": 0.0.0.0 for all nodes.
4. There are incorrect versions in ""validator-info -v"": ""indy-node:1.0.28 sovrin:1.0.3"" and there are nulls in ""validator-info --json"": ""software"": {""indy-node"": null,""sovrin"": null}.
5. How ""average-per-second"" parameters are calculated? How can we check low amounts of txns (less than 60 txns during 60 seconds for example - will we see ""0"" if node printed json in the moment when no txns are reading/writing?)?

Expected Results:
2. Need to get node status normally by ""sovrin"" user.
3. Need to get correct IPs.
4. Need to get correct versions with -v. Need to get correct versions with --json or remove version block from it.

Other points need to be clarified.;;;","29/Aug/17 8:25 PM;alexander.shekhovcov;{quote}1. Only ""sovrin"" user can run ""validator-info"" cause files are in /home/sovrin/.sovrin.{quote}
Try to use --basedir option if execute ""validator-info"" from non sovrin user.
{code} 
validator-info --basedir /home/sovrin/.sovrin
{code}

{quote}2. There is no node status in ""validator-info"": ""Validator Node1 is Failed to connect to bus: No such file or directory"" cause ""sovrin"" user can't check ""systemctl status sovrin-node.service"".
{quote}
This is a know problem for docker. For workaround use #1.

{quote}3. There are incorrect IPs in ""validator-info -v"" and ""validator-info --json"": 0.0.0.0 for all nodes.{quote}
Will be fixed.

{quote}
4. There are incorrect versions in ""validator-info -v"": ""indy-node:1.0.28 sovrin:1.0.3"" and there are nulls in ""validator-info --json"" ...
{quote}
Will be fixed.

{quote}
5. How ""average-per-second"" parameters are calculated? How can we check low amounts of txns (less than 60 txns during 60 seconds for example - will we see ""0"" if node printed json in the moment when no txns are reading/writing?)?
{quote}

 ""average-per-second"" parameters are calculated like:
{code}
avg_reads = node.total_read_request_number / (time.time() - self._node.created)
avg_writes = node.monitor.totalRequests / (time.time() - self._node.created)
{code}
So you may start a pool then send some amount of txns and check the result after 60 sec. If there is not issues in implementation you will see some values > 0.

;;;","30/Aug/17 12:02 AM;alexander.shekhovcov;[~tharmon] I am going to set parameters *bindings > client > ip*, *bindings > node > ip* from node's pool ledger. Is it correct? If a node is not a part of pool (there are no any records in the pool ledger about the node) validator-info output looks like:
{code}
Node Port:        None/tcp on None
Client Port:      None/tcp on None
{code}

Is this okay?
Why we use CIDR address? Should I hard code '/32' for the addresses?

;;;","30/Aug/17 12:21 AM;tharmon;[~alexander.shekhovcov], I actually want to know where the bindings are happening, not where the ledger says they should be happening. In other words, the only things that should be gotten from the ledger are the port numbers. These should then be checked with the operating system to see which interfaces they are bound to.

I'm expecting to see {{0.0.0.0/0}} as the output for this. I don't want that output, but my guess is that right now the validators are not binding to specific interfaces, but are instead binding to all interfaces. That wouldn't be a good thing, and I want a tool that will surface that if it's happening.

That's the reason for the CIDR address, and no, it shouldn't be hard-coded to {{/32}}.;;;","30/Aug/17 12:22 AM;tharmon;[~VladimirWork] See my comment above regarding {{0.0.0.0}}. That is the IP they are binding to, which is a problem (in my opinion).;;;","30/Aug/17 12:57 AM;alexander.shekhovcov;[~tharmon] Is {{/32}} in the example a network mask of the interface to which node (or client) is bound to?

So if I have a node bound to the interface:
{code}
enp0s3    Link encap:Ethernet  HWaddr 08:00:27:ef:97:7c  
          inet addr:10.0.2.15  Bcast:10.0.2.255  Mask:255.255.255.0
          inet6 addr: fe80::3ab2:52a7:c4bb:ab79/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:44872 errors:0 dropped:0 overruns:0 frame:0
          TX packets:31590 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:60528613 (60.5 MB)  TX bytes:2098874 (2.0 MB)

{code}

the output for validator-info should be:
{code}
...
Node Port:        9701/tcp on 10.0.2.15/24
...
{code}

Am I correct?
;;;","30/Aug/17 1:37 AM;andkononykhin;[~tharmon]
{quote}[~alexander.shekhovcov], I actually want to know where the bindings are happening, not where the ledger says they should be happening. In other words, the only things that should be gotten from the ledger are the port numbers. These should then be checked with the operating system to see which interfaces they are bound to.
{quote}
For now its harcoded in plenum/stp_zmq/zstack.py as 
{code:java}
self.listener.bind('tcp://*:{}'.format(self.ha[1])){code}
 

so we bind to all ifaces and only port number is configurable. ([http://api.zeromq.org/2-1:zmq-tcp#toc3)]

Could you explain a bit more:
 * What is the reason to see subnet mask?
 * What is the sense of 0.0.0.0/mask form in the scope of node as listening server?
 * Shouldn't we enumerate all ifaces with accordant masks instead?

Thank you;;;","31/Aug/17 2:06 AM;tharmon;I think there are some basic differences in how we are seeing this. So, let me explain where I'm coming from:

* While we don't have the ability to only bind to a specific interface at this point, this is something we should allow in the future. Up until this point, I assumed that is what was happening, but didn't know for sure.
* There are a number of security reasons why I would want certain ports not binding to all interfaces.
* If I see a binding of {{0.0.0.0/0}}, that indicates to me that the service has bound to all interfaces, a fact of which I need to be aware of as an administrator.
* The subnet mask becomes more interesting when the ability exists to bind to a specific interface. CIDR conveys more information to me in a compact form about the interface that is allowing in traffic.

{quote}
* Shouldn't we enumerate all ifaces with accordant masks instead?
{quote}

That would be a possible alternative, though {{0.0.0.0/0}} implies that to me, as that is how the OS reports that type of binding to all interfaces.

Regarding the proposed example above:

{quote}
the output for validator-info should be:
{code}
...
Node Port:        9701/tcp on 10.0.2.15/24
...
{code}
Am I correct?
{quote}

Yes, that is what I would expect.;;;","31/Aug/17 5:29 PM;VladimirWork;Build Info:
indy-node 1.1.126

Steps to Reproduce - Case 1:
1. Perform ""python3 load_test.py -t GET_NYM -c 10 -r 100"".
2. Check read transactions per second count.

Actual Results:
Read Transactions/Seconds:  0.00

Expected Results:
There should be not 0 value.;;;","01/Sep/17 12:37 AM;andkononykhin;[~tharmon] Thank you for clarification. We have implemented that in the same way with some additional things.
 * Port is the only parameter which is taken into account by validator-info tool
 * we use 'ss' tool to determine all bindings expecting more than one (e.g. in case of multiple protocols on the same ip:port)
 * if * is detected IP is set to 0.0.0.0/0, otherwise we explore ip/mask from matched net interface using 'ip' tool
 * protocol value is also got from 'ss' tool output

So, I changed a bit a json schema you required in description: node/client bindings is array of triples (ip/mask, port, protocol).;;;","01/Sep/17 10:54 PM;VladimirWork;Build Info:
indy-node 1.1.128

Actual Results:
""validation-info"" works with the following parameters:
--basedir /home/sovrin/.sovrin (for non-sovrin users)
-v (for verbose mode)
--json (for JSON output)

All parameters are actual (including statistics data about ledger reads/writes per second).;;;","01/Sep/17 11:35 PM;VladimirWork;[~tharmon] ""validator-info"" looks good. You can check that the tool is good enough from your side before it will be merged in RC using >=1.1.128 master version.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The Node starts with asyncio debug=True,INDY-716,19990,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,alexander.shekhovcov,alexander.shekhovcov,07/Aug/17 9:31 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,1,Stability,,,,,"In the {{run_node}} method there is the following code:

{code}
    with Looper(debug=True) as looper:
        node = Node(name, nodeRegistry=None, basedirpath=config.baseDir,
                    ha=node_ha, cliha=client_ha)
        looper.add(node)
        looper.run()
{code}

So when the node is started using {{start_sovrin_node}} it runs asyncio debug mode enabled.
https://docs.python.org/3/library/asyncio-dev.html#asyncio-debug-mode

It may affect on performance and memory usage.

For example, the test test_catchup_f_plus_one.py works two times faster with debug disabled (change mode of some loopers in conftest.py). 21.12 seconds against 48.29 seconds. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzwzan:",,,,,,12,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,lovesh,mzk-vct,sergey-shilov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Aug/17 8:03 PM;lovesh;[~alexander.shekhovcov] Thanks, great catch. Please make `debug`'s value configurable.;;;","06/Sep/17 1:11 AM;sergey-shilov;Hi [~lovesh],

do we need to make it configurable for tests? Or I can leave it as is?;;;","06/Sep/17 1:28 AM;mzk-vct;[~sergey-shilov] [~lovesh]
I think debug should be disabled in tests by default, right in place (*Looper(debug=False)* or just *Looper()*), instead of using config. 
If someone will need to set it to True in every test he can use *PYTHONASYNCIODEBUG* env var for this, or just set *debug=True* manually for required test.;;;","13/Sep/17 1:39 AM;sergey-shilov;Task is done, changes are in master (plenum 1.1.126):
 [https://github.com/hyperledger/indy-plenum/pull/374]
 [https://github.com/hyperledger/indy-node/pull/343]

Now debug flag for Looper class is got from config, code example:
 [https://github.com/hyperledger/indy-node/blob/d77f9b62007382059022c05cf5ae2195b3ff99c1/sovrin_node/utils/node_runner.py#L25]
 For test functionality debug flag for Looper class is left as default (_False_) or set to _False_ explicitly.
 New configuration parameter that enables/disables debug mode for _Looper_ class is called *LOOPER_DEBUG* and located in _indy-plenum/stp_core/config.py_. *LOOPER_DEBUG* is set to _False_ by default:
 [https://github.com/hyperledger/indy-plenum/blob/24990f6af9bfc0eaab44111bb6266d82792c7911/stp_core/config.py#L25];;;","14/Sep/17 12:27 AM;VladimirWork;Build Info:
indy-node 1.1.136
indy-plenum 1.1.127

Actual Results:
All described changes are made. No additional QA testing is needed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[send CLAIM_DEF] Incorrect validation errors of REF parameter,INDY-717,19991,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,VladimirWork,VladimirWork,07/Aug/17 10:00 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,4Months,KellyRetest,,,,"Build Info:
sovrin 1.0.78

Overview:
Incorrect validation of REF parameter.

Steps to Reproduce:
1. send CLAIM_DEF ref=0 signature_type=CL (or send CLAIM_DEF ref=0000000000 signature_type=CL).
2. send CLAIM_DEF ref=999999999999999999999999999999999999999999999999999999999999999999999999999999999999 signature_type=CL.

Actual Results:
Step 1: ensureReqCompleted failed; not trying any more because 20 seconds have passed; args were (('V4SGRU86Z58d6TV7PBUe6f', 1502107649173889), DJsEqpVXodCshS7W3ZdDDH6mmePFAh6LrvReBKbUM6mU, <function _getData at 0x7effde9bd378>)
Task exception was never retrieved
future: <Task finished coro=<SovrinCli._sendClaimDefActionAsync() done, defined at /usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py:893> exception=OperationError(""error occurred during operation: client request invalid: InvalidClientRequest('validation error [ClientGetTxnOperation]: cannot be smaller than 1 (data=0)',)"",)>

Step 2: Task exception was never retrieved
future: <Task finished coro=<SovrinCli._sendClaimDefActionAsync() done, defined at /usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py:893> exception=OverflowError('int too big to convert',)>

Expected Results:
REF parameter should have common validation and throw user-friendly validation errors the same as other numeric parameters.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Aug/17 9:58 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11837/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx1mn:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/18 6:57 PM;ashcherbakov;REF field has correct validation in the current version:
{code:java}
class ClientClaimDefSubmitOperation(MessageValidator):
    schema = (
        (TXN_TYPE, ConstantField(CLAIM_DEF)),
        (CLAIM_DEF_SCHEMA_REF, TxnSeqNoField()),
        (CLAIM_DEF_PUBLIC_KEYS, ClaimDefField()),
        (CLAIM_DEF_SIGNATURE_TYPE, LimitedLengthStringField(max_length=SIGNATURE_TYPE_FIELD_LIMIT)),
        (CLAIM_DEF_TAG, LimitedLengthStringField(max_length=256, optional=True)),
    )
 {code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to overwrite changed genesis files during upgrade,INDY-718,20009,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,nage,VladimirWork,VladimirWork,08/Aug/17 1:00 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
sovrin 1.0.78

Overview:
Need to overwrite changed genesis files during upgrade.

Steps to Reproduce:
1. Install sovrin.
2. Make changes in genesis files (but don't delete them).
3. Upgrade sovrin.

Actual Results:
Changed genesis files are not overwritten.

Expected Results:
Changed genesis files should be overwritten during upgrade.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyc87:",,,,,,,,,,,,,,,,,,,,,,,,,,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hookup Sovrin-Notifier-Email to Jenkins,INDY-719,20011,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,nage,andrey.goncharov,andrey.goncharov,08/Aug/17 2:01 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"https://github.com/evernym/sovrin-notifier-email

This repo needs to be hooked up to Jenkins and the builds need to be auto published to pypi.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyc8n:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,nage,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/17 6:27 AM;nage;This is specific to Evernym's build system, and not an INDY issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Impossible to install Sovrin on Ubuntu 17.04,INDY-720,20034,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,ozheregelya,ozheregelya,09/Aug/17 12:39 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,devops,,,,"*Steps to Reproduce:*
1. Prepare clear VM with Ubuntu 17.04.
2. Try to install sovrin:
{code:java}
sudo apt-get install sovrin{code}
*Actual Results:*
Following error appears:

 
{code:java}
me@me-VirtualBox:~/.sovrin$ sudo apt-get install sovrin
[sudo] password for me: 
Reading package lists... Done
Building dependency tree 
Reading state information... Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:
The following packages have unmet dependencies:
 sovrin : Depends: indy-node but it is not going to be installed
E: Unable to correct problems, you have held broken packages.
{code}
 

*Expected Result:*
All necessary dependencies should be installed.

*Additional Information:*
Installation worked correctly on Ubuntu 17.04 for indy-node version 1.0.79.","Build Info:
  indy-node 1.0.81
  indy-anoncreds 1.0.25
  indy-plenum 1.0.82
  sovrin 1.0.19
OS/Platform: Ubuntu 17.04
Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-987,,,,,,,,,,"1|hzx13j:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,SeanBohan_Sovrin,sergey.khoroshavin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/18 4:35 AM;SeanBohan_Sovrin;[~ozheregelya] - still valid?;;;","04/Jan/18 5:04 AM;ozheregelya;[~SeanBohan_Sovrin] - yes.;;;","10/Oct/18 7:54 PM;sergey.khoroshavin;*Triage*
AFAIK Ubuntu 17.04 is not officially supported (and actually 17.04 is not supported by Canonical anymore), so marking this as invalid.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Minor visual problems with CLI on Ubuntu 17.04,INDY-721,20037,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Lowest,Won't Do,nage,ozheregelya,ozheregelya,09/Aug/17 1:06 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,,,,,"*Case 1:*
The last ran command sometimes appear again in CLI after successful execution.
*Steps to Reproduce:*
1. Open the CLI.
=> sovrin> is shown.
2. Type command 'connect test', press Enter key.

*Actual Results:*
Command successfully executed, but 'sovrin>connect test' is shown in CLI again.

*Expected Results:*
Only 'sovrin>' should be shown.

 

*Case 2:*
'sovrin>' is not bold on Ubuntu 17.04.
Steps to Reproduce:
1. Open the CLI on Ubuntu 16.04.02.
=> 'sovrin>' is bold.
2. Open the CLI on Ubuntu 17.04.
=> 'sovrin>' is not bold.

*Actual Results:*
Formatting is different on Ubuntu 16.04.02 and on Ubuntu 17.04.

*Expected Results:*
Formatting should be the same.","Build Info:
  indy-node 1.0.81
  indy-anoncreds 1.0.25
  indy-plenum 1.0.82
  sovrin 1.0.19
OS/Platform: Ubuntu 17.04
Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1pj:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:46 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test test_slow_nodes_catchup_before_selecting_primary_in_new_view fails,INDY-722,20060,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,,alexander.shekhovcov,alexander.shekhovcov,09/Aug/17 8:05 PM,11/Oct/19 6:39 PM,28/Oct/23 2:47 AM,11/Oct/19 6:39 PM,,,,,0,4Months,KellyRetest,,,,The test fails time to time (~50%) so for now it is skipped. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1gf:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 6:39 PM;ashcherbakov;We are going to take care about skipped tests in the scope of PBFT View Change epic;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Upgrade to the same version doesn't work,INDY-723,20061,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,VladimirWork,VladimirWork,09/Aug/17 8:32 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Build Info:
indy-node 1.0.83

Overview:
Upgrade to the same version doesn't work.

Preconditions:
There is a pool of 1.0.83 version installed.

Steps to Reproduce:
1. Send ""send POOL_UPGRADE name=upgrade83 version=1.0.83 sha256=ed0a366b4ef36d40c055672a8b83679e99246fec71a706b4ae4cb7958feace3f action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-09T09:20:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-08-09T09:25:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-08-09T09:30:00.258870+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-08-09T09:35:00.258870+00:00'} timeout=10 force=False reinstall=True""

Actual Results:
Version is not reinstalled, there is a traceback in journalctl:

Aug 09 09:19:59 9f42abbfd607 env[187]: Traceback (most recent call last):
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/bin/start_sovrin_node"", line 19, in <module>
Aug 09 09:19:59 9f42abbfd607 env[187]:     run_node(config, self_name, int(sys.argv[2]), int(sys.argv[3]))
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/utils/node_runner.py"", line 29, in run_node
Aug 09 09:19:59 9f42abbfd607 env[187]:     looper.run()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 284, in __exit__
Aug 09 09:19:59 9f42abbfd607 env[187]:     self.shutdownSync()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 280, in shutdownSync
Aug 09 09:19:59 9f42abbfd607 env[187]:     self.loop.run_until_complete(self.shutdown())
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
Aug 09 09:19:59 9f42abbfd607 env[187]:     return future.result()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
Aug 09 09:19:59 9f42abbfd607 env[187]:     raise self._exception
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
Aug 09 09:19:59 9f42abbfd607 env[187]:     result = coro.send(None)
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 270, in shutdown
Aug 09 09:19:59 9f42abbfd607 env[187]:     await self.runFut
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/futures.py"", line 363, in __iter__
Aug 09 09:19:59 9f42abbfd607 env[187]:     return self.result()  # May raise too.
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
Aug 09 09:19:59 9f42abbfd607 env[187]:     raise self._exception
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/utils/node_runner.py"", line 29, in run_node
Aug 09 09:19:59 9f42abbfd607 env[187]:     looper.run()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 254, in run
Aug 09 09:19:59 9f42abbfd607 env[187]:     return self.loop.run_until_complete(what)
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
Aug 09 09:19:59 9f42abbfd607 env[187]:     return future.result()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
Aug 09 09:19:59 9f42abbfd607 env[187]:     raise self._exception
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
Aug 09 09:19:59 9f42abbfd607 env[187]:     result = coro.send(None)
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 218, in runForever
Aug 09 09:19:59 9f42abbfd607 env[187]:     await self.runOnceNicely()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
Aug 09 09:19:59 9f42abbfd607 env[187]:     return self.gen.send(None)
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 202, in runOnceNicely
Aug 09 09:19:59 9f42abbfd607 env[187]:     msgsProcessed = await self.prodAllOnce()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
Aug 09 09:19:59 9f42abbfd607 env[187]:     return self.gen.send(None)
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 147, in prodAllOnce
Aug 09 09:19:59 9f42abbfd607 env[187]:     s += await n.prod(limit)
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/lib/python3.5/asyncio/coroutines.py"", line 105, in __next__
Aug 09 09:19:59 9f42abbfd607 env[187]:     return self.gen.send(None)
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 366, in prod
Aug 09 09:19:59 9f42abbfd607 env[187]:     c += self.upgrader.service()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/upgrader.py"", line 134, in service
Aug 09 09:19:59 9f42abbfd607 env[187]:     return self._serviceActions()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/server/has_action_queue.py"", line 65, in _serviceActions
Aug 09 09:19:59 9f42abbfd607 env[187]:     action()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/upgrader.py"", line 433, in _callUpgradeAgent
Aug 09 09:19:59 9f42abbfd607 env[187]:     self._upgrade_start_callback()
Aug 09 09:19:59 9f42abbfd607 env[187]:   File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 260, in notify_upgrade_start
Aug 09 09:19:59 9f42abbfd607 env[187]:     scheduled_upgrade_version = self.upgrader.scheduledUpgrade[0]
Aug 09 09:19:59 9f42abbfd607 env[187]: TypeError: 'NoneType' object is not subscriptable

Expected Results:
Upgrader should reinstall the current version.

Additional Info:
systemctl status sovrin-node.service displays the same traceback above after the upgrade.",,,,,,,,,,,,,,,,,,,,,,,INDY-316,,,,,,,,,,,,"09/Aug/17 8:28 PM;VladimirWork;node1.7z;https://jira.hyperledger.org/secure/attachment/11844/node1.7z","09/Aug/17 8:28 PM;VladimirWork;node2.7z;https://jira.hyperledger.org/secure/attachment/11845/node2.7z","09/Aug/17 8:28 PM;VladimirWork;node3.7z;https://jira.hyperledger.org/secure/attachment/11846/node3.7z","09/Aug/17 8:28 PM;VladimirWork;node4.7z;https://jira.hyperledger.org/secure/attachment/11847/node4.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzycfj:",,,,,,10,,,,,,,,,,,,,,,,,,,,andrey.goncharov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Aug/17 8:33 PM;VladimirWork;FYI [~ashcherbakov] [~andrey.goncharov];;;","09/Aug/17 11:19 PM;andrey.goncharov;Problem reason: 
-typo

Changes: 
- typo fixed

Committed into:
https://github.com/hyperledger/indy-node/commit/227a1e0fd049640c64b90ac00ee1fc56b1f12f84
indy-node/master 1.0.84 

Risk factors:
 Nothing is expected.

Risk:
 Low

 ;;;","10/Aug/17 1:06 AM;VladimirWork;Build Info:
indy-node 1.0.84

Steps to Validate:
1. Perform pool upgrade to current version (reinstall).
2. Perform pool upgrade to next/latest version.

Actual Results:
Upgrader upgrades/reinstalls packages successfully.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Reduce number of messages (client-to-node, node-to-node) logged",INDY-724,20062,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,dsurnin,dsurnin,09/Aug/17 9:31 PM,09/Oct/19 7:02 PM,28/Oct/23 2:47 AM,09/Oct/19 7:00 PM,,,,,0,4Months,KellyRetest,,,,"Two main issues:

*The same message is logged several times during the work
*Max message size is 128K - it is time consuming to log all the message

It would be nice to reduce the number of logging and, probably, it is better to limit logged message to some predefined size, i.e. 1024 chars",,,,,,,,,,,,,,,,,,,,,,INDY-484,INDY-1311,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-779,,,,,,,,,,"1|hzx1hr:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,esplinr,krw910,SeanBohan_Sovrin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/17 5:50 AM;krw910;Lets not remove the log, but move it to a lower logging level like Debug.;;;","04/Jan/18 4:33 AM;SeanBohan_Sovrin;If Mike is happy we are happy. The question is, is [~krw910] happy?;;;","09/Oct/19 7:00 PM;esplinr;Mike and Kelly say that the current logging is much better. Some problems still need to be addressed, but will be raised as separate issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve logs per request,INDY-725,20104,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ashcherbakov,ashcherbakov,11/Aug/17 12:09 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"When the client cli is run, it generates a world-readable cli.log file that echoes all commands typed into the cli.  Unfortunately, this includes seeds, which are sensitive information.  For example, if a trustee types in his seed in the CLI to perform his duties, what he types in is written to the cli.log as follows:

    2017-08-04 14:02:45,481 | INFO     | cli.py               (1921) | parse | CLI command entered: new key with seed secretTrusteeSeed000000000000000


This seed data should not be written to the log.  A better solution would be to mask the seed when writing to the log:

    2017-08-04 14:02:45,481 | INFO     | cli.py               (1921) | parse | CLI command entered: new key with seed [redacted]


The same information is written to .sovrin-cli-history, which is also a world-readable file.  Seeds should also be redacted there.",,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzycfr:",,,,,,10,,,,,,,,,,,,,,,,,,,,ashcherbakov,dsurnin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Aug/17 1:13 PM;dsurnin;remove seed from log and cli history

plenum 9f33ffe18bdc2637101406ae5edbd81dd1f00c97

 

no automated tests;;;","16/Aug/17 3:26 AM;krw910;This is working correctly. The log .sovrin-cli-history file now shows:
# 2017-08-15 15:42:52.067022
+new key with seed [redacted]
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Primary fails to send pre-prepare,INDY-726,20113,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,mgbailey,mgbailey,11/Aug/17 6:58 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"This error was observed in the ESN.  While running a low-volume load test, one of the nodes, 'metis' lost sync and did not recover.  'play was the primary node at this time.  It occurred at about 16:22:02 in the 'play' log, and the DID of this first NYM transaction was 3SMdqenHLPYz654FAUd5o5.  The issue continued for the next 40 or so transactions until the test script terminated. Later, while attempting to diagnose the issue, another NYM transaction was sent to the pool manually, using the CLI.  The node also failed to post this transaction.  Two other nodes were examined and unlike metis, they were in sync and were accepting new transactions.

In troubleshooting, the metis sovrin-node process was restarted.  metis quickly caught up, but would still not accept new transactions.  As the next troubleshooting step, we stopped the sovrin-node process on the primary, forcing a view change.  At this point, the problem cleared up, and new transactions were posted to all nodes, including metis.

Examining the primary's logs, during the time where the error was occurring we see the transaction propagating to all nodes, but we see PREPREPAREs going to only two of eight nodes.  We speculate that this lack of PREPREPAREs may be a clue.

There were no signs of connectivity issues anywhere.  We later restarted all nodes, and with play once again the primary, there were no further problems observed.

INFO-level logs are attached for play, which is the primary, and for metis.

 

 

 ",This network is running indy-node 1.0.28,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Aug/17 6:58 AM;mgbailey;metisLogs.tgz;https://jira.hyperledger.org/secure/attachment/11867/metisLogs.tgz","11/Aug/17 6:58 AM;mgbailey;playLog.tgz;https://jira.hyperledger.org/secure/attachment/11868/playLog.tgz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzycfz:",,,,,,10,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,krw910,lovesh,mgbailey,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Aug/17 2:51 AM;alexander.shekhovcov;[~mgbailey] First of all, thank you for a great description! 

Looks like a timezone issue. I've found in the *metis* log the following:
{code}
2017-08-09 17:11:35,561 | ERROR    | replica.py           (2004) | is_pre_prepare_time_acceptable | metis:0 found PREPREPARE{'viewNo': 0, 'reqIdr': [('RRbkXVEr8UZ1Z9RidHmu25', 1502316696034239)], 'ppTime': 15023
16696, 'instId': 0, 'txnRootHash': '5xHbjpEmnMxafwrPPNQgYXNYsyLkkN1puy9P2eeTNx31', 'ledgerId': 1, 'discarded': 1, 'ppSeqNo': 124, 'stateRootHash': '2G1KeraEJM7tfWrpV96JoPd8j8mWzFfYM2x1G4DoYU5x', 'digest': '4a022
af4196648b0cc326bbcb288b2e847823a85f57f8246749593b0f382b233'} to have incorrect time.
2017-08-09 17:11:35,562 | WARNING  | node.py              (2494) | reportSuspiciousNode | metis raised suspicion on node play for PRE-PREPARE time not acceptable; suspicion code is 18
{code}

We have some issue fixed which is not in stable branch yet
https://github.com/hyperledger/indy-plenum/commit/aec69eb25748be2e6e30a1ef5eb0ca0a7acbb0d3

[~lovesh] Could you add more details about this?


;;;","12/Aug/17 7:03 AM;mgbailey;Alex,

Great clue!  We got on with the customer today and discovered that indeed they were in a different timezone.  It is puzzling that many transactions were able to get through to metis before this problem manifested, and then nothing got through after that. 

Today we changed the timezone on metis to match the rest (UTC), and restarted the sovrin-node process on it.  We then posted a transaction to the ledger, which failed to be written to metis.  

Next we killed the primary (play), and metis immediately caught up.  We posted another transaction to the ledger, which was successfully written to metis.

It will be interesting to see if metis will once again get into a state where it does not accept transactions, now that its timezone is in sync with the others.  We will post a transaction to the ESN ledger when we get in on Monday and see.;;;","15/Aug/17 12:57 AM;mgbailey;I added a transaction to the ESN ledger this morning, and the ledger on metis updated fine with it.

[~krw910], please try this test to see if it replicates the issue.  On a test validator network, set the timezone on one node (not the primary) to be CDT, the others all UDT.  Put a few transactions on the ledger.  Wait 24 hours.  Add another transaction.  Did the node in the different timezone keep sync?;;;","15/Aug/17 4:23 AM;krw910;[~mgbailey] I have confirmed that if one node is not in UTC time it will get out of sync. I have 7 nodes and put one in CDT. I sent 500 transactions and after 400 the node in CDT fell out of sync. This issue should be addressed in INDY-466;;;","15/Aug/17 4:30 AM;lovesh;The timezone being wrong on one node should not matter, only if timezone is inconsistent on more than f nodes, it becomes a problem. So >=n-f nodes are correct, the f nodes should continue to function even if they have wrong timezone;;;","15/Aug/17 5:02 AM;krw910;[~lovesh] we are not sure why it is happening, but it should be the same issue that was fixed after we released. We are just waiting until the next stable to roll out that fix. For some reason if the nodes are in UTC, but one node is not then that node will eventually stop taking transactions and get out of sync. I have confirmed this in my test pool.;;;","15/Aug/17 8:14 PM;alexander.shekhovcov;*Summary:*
A pool build on the current stable build does not support nodes in different timezone.  Workaround is to set UTC timezone for each node in the pool. 
In case a non primary node has another timezone it adds to the blacklist other nodes whereas the pool works well.

The issue already fixed in [master|https://github.com/hyperledger/indy-plenum/commit/aec69eb25748be2e6e30a1ef5eb0ca0a7acbb0d3].
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Recreate stable from master without squashes,INDY-727,20126,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,,nage,andrey.goncharov,andrey.goncharov,11/Aug/17 7:47 PM,09/Jan/18 5:41 PM,28/Oct/23 2:47 AM,,,,,,0,4Months,,,,,Currently stable has much less commits because several times master was merged into stable with a squash. We should recreate stable from master without any squashes and prevent creating squashes from master to stable in the future.,,,,,,,,,,,,,,INDY-509,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzx1of:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,SeanBohan_Sovrin,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/17 5:54 AM;stevetolman;We set this to low since nothing is broken; however, we should also stop squashing commits.;;;","04/Jan/18 4:32 AM;SeanBohan_Sovrin;[~ashcherbakov] - Nathan says ""YES"". Still valid?;;;","09/Jan/18 5:41 PM;ashcherbakov;We don't use squashes now, but it's still an issue in general. So, yes, still valid, but not critical.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Simplify class hierarchy in Node,INDY-728,20133,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,mzk-vct,mzk-vct,12/Aug/17 12:42 AM,10/Oct/19 11:59 PM,28/Oct/23 2:47 AM,10/Oct/19 11:59 PM,,,,,0,4Months,REFACTORING,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-496,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzx1kf:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/19 11:59 PM;ashcherbakov;We've done a lot of refactorings and improvements in the scope of PBFT View Change protocol.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Simplify PoolManager class hierarchy ,INDY-729,20134,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,mzk-vct,mzk-vct,12/Aug/17 12:43 AM,10/Oct/19 11:59 PM,28/Oct/23 2:47 AM,10/Oct/19 11:59 PM,,,,,0,4Months,REFACTORING,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-496,,,,,,,,,,,,"12/Aug/17 12:44 AM;mzk-vct;PoolManagers.png;https://jira.hyperledger.org/secure/attachment/11876/PoolManagers.png","12/Aug/17 12:44 AM;mzk-vct;PoolManagers.puml;https://jira.hyperledger.org/secure/attachment/11877/PoolManagers.puml",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzx1kn:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Aug/17 12:46 AM;mzk-vct;Be careful, removal of RegistryPoolManager breaks tests;;;","10/Oct/19 11:59 PM;ashcherbakov;We've done a lot of refactorings and improvements in the scope of PBFT View Change protocol.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Simplify class hierarchy of stores,INDY-730,20135,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,mzk-vct,mzk-vct,12/Aug/17 12:43 AM,11/Oct/19 12:01 AM,28/Oct/23 2:47 AM,11/Oct/19 12:01 AM,,,,,0,4Months,REFACTORING,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-496,,,,,,,,,,,,"12/Aug/17 12:44 AM;mzk-vct;Stores.png;https://jira.hyperledger.org/secure/attachment/11874/Stores.png","12/Aug/17 12:44 AM;mzk-vct;Stores.puml;https://jira.hyperledger.org/secure/attachment/11875/Stores.puml",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzx1kv:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 12:01 AM;ashcherbakov;We've done a lot of refactorings and improvements already;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Help shows ""No such command found"" for three-word commands.",INDY-731,20136,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,sergey-shilov,ozheregelya,ozheregelya,12/Aug/17 1:22 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,,,,,"Steps to Reproduce:
1. Open the CLI.
2. Type 'help <any three-word command>' e.g.
change current key
3. Press Enter key.

Actual Results:
""No such command found"" message and full help are shown.

Expected Results:
detailed help for command should be shown.","Build Info:
  indy-node 1.0.100
  indy-anoncreds 1.0.25
  indy-plenum 1.0.91
  sovrin 1.0.22
  python3-rlp 0.5.1
  python3-sha3 0.2.1
  python3-pyzmq 16.0.2
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-792,,,,,,,,,,"1|hzx1hb:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 12:06 AM;sergey-shilov;This CLI is deprecated, no longer supported and going to be removed, this ticket is not relevant any more and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Wallet and pool synchronization ,INDY-732,20159,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,,dsurnin,dsurnin,14/Aug/17 5:29 PM,09/Oct/19 5:33 PM,28/Oct/23 2:47 AM,09/Oct/19 5:33 PM,,,,,0,4Months,,,,,"In case the operation requires changes both in pool and wallet there must be a mechanism to ensure that data across wallet and pool are valid

Example is change key operation
If verkey were updated in pool but the wallet update failed the user will not be able to send transactions since verkeys are different",,,,,,,,,,,,,,,,,,,,,,,INDY-290,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzwxgd:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,dsurnin,SeanBohan_Sovrin,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/17 6:04 AM;stevetolman;Let's state the obvious: code errors should not rob the user of their identity.;;;","04/Jan/18 4:30 AM;SeanBohan_Sovrin;[~gudkov] - is still a problem in the SDK? Should it still live in Indy??;;;","09/Oct/19 5:33 PM;ashcherbakov;We don't have CLI in Node anymore;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to restore wallet after the pool upgrade,INDY-733,20217,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,VladimirWork,VladimirWork,17/Aug/17 12:44 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,sprint11-goal-release,,,,,"Build Info:
indy-node 1.0.110 (master)

Overview:
Unable to restore wallet after the pool upgrade.

Preconditions:
Installed 1.0.67 (master) pool.

Steps to Reproduce:
1. Enter the wallet.
2. Do an actions using this wallet that are saved in it.
3. Save the wallet or exit the CLI.
4. Perform upgrade to 1.0.110 (master).
5. Run the CLI and connect test.

Actual Results:
Error occurred during restoring last active wallet (default.wallet), error: list index out of range
Error while running coroutine shell: IndexError('list index out of range',)
Traceback (most recent call last):
  File ""/usr/local/bin/sovrin"", line 78, in <module>
    run_cli()
  File ""/usr/local/bin/sovrin"", line 56, in run_cli
    looper.run(cli.shell(*commands))
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 259, in run
    return self.loop.run_until_complete(what)
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
    return future.result()
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
    raise self._exception
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
    result = coro.send(None)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 250, in wrapper
    raise ex
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 237, in wrapper
    results.append(await coro)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1150, in shell
    self.parse(c)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1946, in parse
    r = action(matchedVars)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 1790, in _connectTo
    self.restoreLastActiveWallet()
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1810, in restoreLastActiveWallet
    self.errorDuringRestoringLastActiveWallet(baseFileName, e)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1816, in errorDuringRestoringLastActiveWallet
    raise e
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1805, in restoreLastActiveWallet
    self._searchAndSetWallet(os.path.join(walletPath, baseFileName))
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1634, in _searchAndSetWallet
    self._loadFromPath(name, copyAs=copyAs, override=override)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1559, in _loadFromPath
    self.restoreWalletByPath(path, copyAs=copyAs, override=override)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1767, in restoreWalletByPath
    wallet = self.walletSaver.loadWallet(walletFilePath)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/wallet.py"", line 397, in loadWallet
    wallet = self.decode(wf.read())
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/wallet.py"", line 324, in decode
    return jsonpickle.decode(data, keys=True)
  File ""/usr/lib/python3/dist-packages/jsonpickle/__init__.py"", line 148, in decode
    return unpickler.decode(string, backend=backend, keys=keys)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 26, in decode
    return context.restore(backend.decode(string), reset=reset)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 119, in restore
    value = self._restore(obj)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 159, in _restore
    return restore(obj)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 243, in _restore_object
    return self._restore_object_instance(obj, cls)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 308, in _restore_object_instance
    return self._restore_object_instance_variables(obj, instance)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 337, in _restore_object_instance_variables
    self._restore_from_dict(obj, instance)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 321, in _restore_from_dict
    value = self._restore(v)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 159, in _restore
    return restore(obj)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 243, in _restore_object
    return self._restore_object_instance(obj, cls)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 308, in _restore_object_instance
    return self._restore_object_instance_variables(obj, instance)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 337, in _restore_object_instance_variables
    self._restore_from_dict(obj, instance)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 321, in _restore_from_dict
    value = self._restore(v)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 159, in _restore
    return restore(obj)
  File ""/usr/lib/python3/dist-packages/jsonpickle/unpickler.py"", line 210, in _restore_id
    return self._objs[obj[tags.ID]]
IndexError: list index out of range

Expected Results:
The last active wallet should restore normally.",,,18000,18000,,0%,18000,18000,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/17 12:43 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11894/Screenshot.PNG","17/Aug/17 12:40 AM;VladimirWork;cli.log;https://jira.hyperledger.org/secure/attachment/11895/cli.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzye8f:",,,,,,11,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/17 5:03 PM;ashcherbakov;I think it was caused by terminology renaming.;;;","18/Aug/17 1:57 AM;ashcherbakov;1) We need to provide a script for migration. Let's create just a script, not a migration procedure, so that the script can be run locally for the wallets that require migration. Delivery team can just run the script for the existing old wallets.
2) let's assume that the latest version of client is used (>1.0.110 on master), that is we don't have problems with using old client (with old ledger serialization) with new pool. We assume that it is possible because we have not so many activity with the live pool (just 2 txns).
[~nage] [~danielhardman] [~stevetolman] [~tharmon] Are you OK with this?;;;","18/Aug/17 3:20 AM;krw910;[~ashcherbakov] I have spoken with [~tharmon] about this solution. I didn't think having the user run a script was a good idea and Trev has confirmed this. He has indicated that now that we are live we don't know who is running the client (CLI) or how to contact all of them to tell them to run a script. The upgrade process must take care of upgrading. In the live environment this means that there should not be post upgrade user interaction. So the upgrade process needs to take care of this issue.;;;","18/Aug/17 5:14 PM;ashcherbakov;[~krw910] [~tharmon]
We can do it as a part of some client migration client. But important thing: are we ok to require all existing clients to be updated to the latest version (that is migration script is executed)? In other words, old client will not work with the newest pool (the easiest way to do it is just end something like 'you must upgrade' to old clients).;;;","19/Aug/17 3:36 AM;krw910;[~ashcherbakov] I spoke with [~tharmon] today and we have to account for a particular scenario with regards to the wallet fix. We have customers where there are several users on the machine each with their own wallet in their own home directory. So we cannot assume we know where all the wallets are on a system. [~nage] suggested we make the wallet fix be at CLI run time so it can detect if the wallet is in the correct format or needs to be changed.;;;","28/Aug/17 7:47 PM;VladimirWork;Build Info:
indy-node 1.1.119

Steps to Reproduce - Case 1:
1. Install 0.4.44 client.
2. Perform Getting Started Tutorial with default.wallet.
3. Exit CLI to save default.wallet in /keyrings/.
4. Upgrade client to 1.1.119.
5. Start CLI.

Steps to Reproduce - Case 2:
1. Install 1.0.67 client.
2. Perform Getting Started Tutorial with default.wallet.
3. Exit CLI to save default.wallet in /wallets/.
4. Upgrade client to 1.1.119.
5. Start CLI.

Actual Results:
Migrated default.wallet is restored successfully in both cases from /wallets/.
All DIDs in the wallet saved before the upgrade are available to use after the upgrade.;;;","01/Sep/17 11:51 PM;spivachuk;The changes related to the wallet migration mechanism are in the following merged pull requests:
* https://github.com/hyperledger/indy-plenum/pull/357
* https://github.com/hyperledger/indy-node/pull/320
* https://github.com/hyperledger/indy-node/pull/321
* https://github.com/hyperledger/indy-plenum/pull/360
* https://github.com/hyperledger/indy-node/pull/323
* https://github.com/hyperledger/indy-plenum/pull/363
* https://github.com/hyperledger/indy-node/pull/334;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nodes do not respond to transactions when ~400 transactions are send at once,INDY-734,20220,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,,ozheregelya,ozheregelya,17/Aug/17 5:45 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,sprint11-goal-release,,,,,"*Case 1:*
 *Steps to Reproduce:*
 1. Setup the pool.
 2. Run the load test with following parameters:
 python3 load_test.py --clients-list load_test_clients.list --timeout 15 -t NYM -c 1 -r 400 --at-once
 3. Look at results of load_test.py.

*Actual Results:*
 Following records are repeatedly written to output file:
{code:java}
sovrin@sovrin-VirtualBox:~/load$ tail -f perf_results_1_400_1502913493.csv
signerName,signerId,dest,reqId,transactionType,sentAt,quorumAt,latency,ackNodes,nackNodes,replyNodes
Sponsor1,NZWFmi43mW9WN91eWtWv7y,VNvHHoV7mLVCPXAsgkZXe,1502914554853548,1,1502914554.85375,,120.19551825523376,""Node3C,Node4C,Node2C,Node1C"",,
Sponsor1,NZWFmi43mW9WN91eWtWv7y,7kPAvDBWBNvegcBfX5vVbW,1502914675050327,1,1502914675.050499,,120.01642322540283,""Node3C,Node1C,Node2C,Node4C"",,
Sponsor1,NZWFmi43mW9WN91eWtWv7y,N796UiDZtxqhnwwDeaV6bU,1502914795071366,1,1502914795.0715904,,120.0725646018982,""Node3C,Node1C,Node2C,Node4C"",,
Sponsor1,NZWFmi43mW9WN91eWtWv7y,3k6L7vpeXsnobzVpTkaFyb,1502914915145072,1,1502914915.1452458,,120.16396474838257,""Node3C,Node1C,Node2C,Node4C"",,
Sponsor1,NZWFmi43mW9WN91eWtWv7y,NcPWCJooxyt2omGAUopAoR,1502915035310199,1,1502915035.3103657,,120.23259568214417,""Node3C,Node1C,Node2C,Node4C"",,
Sponsor1,NZWFmi43mW9WN91eWtWv7y,V34wuFkejWxekrtWGmR51f,1502915155559550,1,1502915155.5597646,,120.23397612571716,""Node3C,Node4C,Node2C,Node1C"",,
Sponsor1,NZWFmi43mW9WN91eWtWv7y,TPveRqFmYRJfXXMiXAsKWf,1502915275795061,1,1502915275.795235,,120.11274743080139,""Node3C,Node1C,Node2C,Node4C"",,
... etc ...{code}
 

*Expected Results:*
 Transactions should be written.

*Additional Information:*
 load_test.py with ~50 transactions and --at-once argument works correctly.
load_test.py with ~400 transactions and without --at-once argument works correctly.","Build Info:
  indy-node 1.0.110
  indy-anoncreds 1.0.25
  indy-plenum 1.0.97
  sovrin 1.0.23
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4-6 nodes, 1 client",,18000,18000,,0%,18000,18000,,,,,,INDY-292,INDY-447,,,,,,,,,,,,,,,,,,,,"18/Aug/17 5:54 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11899/Node1.log","18/Aug/17 5:54 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11900/Node2.log","18/Aug/17 5:54 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11901/Node3.log","18/Aug/17 5:54 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11902/Node4.log","18/Aug/17 5:54 PM;ozheregelya;perf_results_1_10_1502981845.csv;https://jira.hyperledger.org/secure/attachment/11903/perf_results_1_10_1502981845.csv","18/Aug/17 5:54 PM;ozheregelya;perf_results_1_400_1502981869.csv;https://jira.hyperledger.org/secure/attachment/11904/perf_results_1_400_1502981869.csv",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzye93:",,,,,,11,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/17 5:57 PM;ozheregelya;+Nodes logs+: [^Node1.log] [^Node2.log] [^Node3.log] [^Node4.log]

 

+Results for 10 transactions:+
{code:java}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 10 --at-once{code}
[^perf_results_1_10_1502981845.csv]

 

+Results for 400 transactions:+
{code:java}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 400 --at-once{code}
[^perf_results_1_400_1502981869.csv];;;","19/Aug/17 1:24 AM;alexander.shekhovcov;We limited length of an input message for a stack (zstack, rstack, ...) with:
{code}
MSG_LEN_LIMIT = 128 * 1024
{code}

the command 
{code}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 400 --at-once
{code}
sends 400 requests in one batch as a result:

{code}
2017-08-18 16:13:36,524 | DEBUG    | batched.py           (  99) | flushOutBoxes | Node1 batching 400 msgs to Node2 into one transmission
2017-08-18 16:13:36,526 | DEBUG    | batched.py           ( 148) | signAndSerialize | Message will be discarded due to InvalidMessageExceedingSizeException('Message len 154335 exceeded allowed limit of 131072',)
2017-08-18 16:13:36,526 | DEBUG    | batched.py           ( 112) | flushOutBoxes | Node1 error Message will be discarded due to InvalidMessageExceedingSizeException('Message len 154335 exceeded allowed limit of 131072',). tried to Node2: None
{code}

([~spivachuk] is going to replaced DEBUG level with ERROR level because actually it is an error)

If it is not a crucial thing to send all 400 request from one client  I'd suggest the following 
{code}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 4 -r 100 --at-once
{code}

The command sends 400 request in 4 batches from each client and each of them less than limit.

[~kelly.wilson] [~ozheregelya] Is it eligible for testing? 
;;;","23/Aug/17 1:36 AM;ozheregelya;The problem was discussed and there were decided that current behavior of the system is correct. But there is unclear situation with load test: test works correctly with 1 client and 200 transactions but it does not work for 4 clients and 200 transactions per client with InvalidMessageExceedingSizeException. But this is topic for other ticket (see INDY-753).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support downgrade migration scripts,INDY-735,20239,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,,ashcherbakov,ashcherbakov,17/Aug/17 4:47 PM,11/Oct/19 6:39 PM,28/Oct/23 2:47 AM,11/Oct/19 6:39 PM,,,,,0,4Months,,,,,"* We support migration scripts during update 
* We support downgrade on apt level (it's possible to install a lower version)
* However, migration scripts are always called AFTER code upgrade/downgrade. This is fine for upgrades, but doesn't work for downgrades, since we need to have the current code to call the downgrade migration script.
* So, for downgrade cases migration scrip must be called BEFORE code downgrade.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx1l3:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,esplinr,nage,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/17 6:26 AM;nage;Allowing for backward migration will increase the amount of work significantly and seems like a fixing a symptom for other problems rather than addressing those issues directly.  This ticket needs more architecture work before we accept it.;;;","11/Oct/19 6:39 PM;esplinr;This would be a nice capability to have, but we haven't needed it in the last two years. So we will defer the work until it becomes clear that it is necessary.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"[CLAIM_DEF] Signature type ""CL"" should be published only",INDY-736,20242,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,VladimirWork,VladimirWork,17/Aug/17 8:24 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,4Months,,,,,"Build Info:
indy-node 1.0.110

Overview:
Signature type ""CL"" should be published only.

Steps to Reproduce:
1. Send some SCHEMA.
2. Send CLAIM_DEF with ref of added SCHEMA and signature_type *is not* CL.

Actual Results:
The claim definition was published to the Sovrin distributed ledger.

Expected Results:
CLAIM_DEFs with signature_type CL should be published only (we can't GET_CLAIM_DEF with other than CL signature_type cause it is not supported).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/17 8:23 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11896/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-767,,,,,,,,,,"1|hzx1gn:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,SeanBohan_Sovrin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/18 4:28 AM;SeanBohan_Sovrin;[~gudkov] - is this still valid?;;;","07/Nov/18 6:41 PM;Derashe;Now InsufficientCorrectSignatures will be thrown if wrong signature type will be passed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"[GET_CLAIM_DEF] Implement ""origin"" parameter explicitly",INDY-737,20243,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,VladimirWork,VladimirWork,17/Aug/17 9:31 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,needs-more-info,,,,,"Build Info:
indy-node 1.0.110

Overview:
Implement ""origin"" parameter explicitly.

Actual Results:
GET_CLAIM_DEF command has an explicit ""ref"" and ""signature_type"" parameters and implicit ""origin"" parameter now.

Expected Results:
All GET_CLAIM_DEF parameters should be explicit (to get claim definitions of any keys without using of this keys).

Additional Info:
CLI help message for GET_CLAIM_DEF command also should be changed according to the new implementation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-767,,,,,,,,,,"1|hzx1db:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/17 6:35 AM;krw910;[~VladimirWork] We need to get more information on this ticket. We do not know what ""origin"" is in reference to. I looked at the help for GET_CLAIM_DEF and it does not show anything for ""origin"". Please explain what this parameter is.;;;","21/Aug/17 4:28 PM;VladimirWork;[~krw910] According to discussion with [~ashcherbakov], ""origin"" parameter is a DID of user that owns CLAIM_DEF (it exists in code and sets as DID of current key implicitly when we execute GET_CLAIM_DEF command). So if I add CLAIM_DEF as DID1 and try to get it as DID2 I get message that claim def is not found and vice versa so now we have an issue that each DID can see its own claim defs only (even if this DID is Trustee/Steward or another privileged user) and it's wrong because we should be able to see all published claim defs as any user (or as any priveleged user at least?).;;;","12/Oct/18 8:03 PM;ashcherbakov;This is already done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
All issues that deal with upgrades,INDY-738,20261,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,stevetolman,stevetolman,18/Aug/17 6:01 AM,11/Oct/19 7:13 PM,28/Oct/23 2:47 AM,11/Oct/19 7:13 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-5,,Upgrade,Done,,,,,,,,"1|hzyw5b:",,,,,,,,,,,,,,,,,,,,,,,,,,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix C* (too complex) flake8 errors,INDY-739,20280,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,alexander.shekhovcov,alexander.shekhovcov,18/Aug/17 11:29 PM,12/Oct/18 8:05 PM,28/Oct/23 2:47 AM,,,,,,0,4Months,,,,,"* enable all C* in .flake8 for indy-anoncreds indy-plenum indy-node sovrin (for current moment only C901)
* check errors *flake8 .*
* make flake8 passed
* as a last resort, ignore specific file in .flake8

The task is fairly simple I saw the error only for {{state/util/utils.py}}",,,,,,,,,,,,,,,,,,,,,,,INDY-493,INDY-742,INDY-741,INDY-740,INDY-740,INDY-741,INDY-742,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1758,,,,,,,,,,"1|hzx1jj:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix E501 (max line length) flake8 errors,INDY-740,20281,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,alexander.shekhovcov,alexander.shekhovcov,18/Aug/17 11:35 PM,12/Oct/18 8:06 PM,28/Oct/23 2:47 AM,,,,,,0,4Months,,,,,"* enable all E501 in .flake8 for indy-anoncreds indy-plenum indy-node sovrin
* check errors *flake8 .*
* make flake8 passed
* use *# noqa* as a last resort

We should define maximum length for lines. Maybe 79 is too short. Let's research common practices. 

The ticket supposes fairly big amount of manual work.
",,,,,,,,,,,,,,,,,,,,,,,INDY-493,INDY-739,INDY-741,INDY-742,INDY-739,INDY-741,INDY-742,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1758,,,,,,,,,,"1|hzx1jr:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix F401 (imported but unused) flake8 errors,INDY-741,20282,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,alexander.shekhovcov,alexander.shekhovcov,18/Aug/17 11:40 PM,12/Oct/18 8:06 PM,28/Oct/23 2:47 AM,,,,,,0,4Months,,,,,"* enable all F401 in .flake8 for indy-anoncreds indy-plenum indy-node sovrin
* make sure that there are no test folders in *exclude* variable of .flake8
* check errors *flake8 .*
* make flake8 passed
* use *# noqa* as a last resort

Be careful with removing imports of pytest fixtures.

The ticket supposes fairly big amount of manual work.
",,,,,,,,,,,,,,,,,,,,,,,INDY-493,INDY-739,INDY-740,INDY-742,INDY-739,INDY-740,INDY-742,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1758,,,,,,,,,,"1|hzx1jz:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix N* (naming) flake8 errors,INDY-742,20283,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,alexander.shekhovcov,alexander.shekhovcov,18/Aug/17 11:51 PM,12/Oct/18 8:07 PM,28/Oct/23 2:47 AM,,,,,,0,4Months,,,,,"* enable all N* (one-by-one will be simpler) in .flake8 for indy-anoncreds indy-plenum indy-node sovrin
* check errors *flake8 .*
* make flake8 passed

It is the most difficult part these group of tickets.

The following ways can be chosen:

* try to use *sed*, [some other tool|https://gist.github.com/jaytaylor/3660565] or write a tool by your own
* [use Daniel's experience|https://codecraft.co/2014/03/25/how-to-make-a-const-correct-codebase-in-4300-easy-steps/]
* use renaming feature of pycharm object-by-object

",,,,,,,,,,,,,,,,,,,,,,,INDY-493,INDY-739,INDY-740,INDY-741,INDY-739,INDY-740,INDY-741,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1758,,,,,,,,,,"1|hzx1k7:",,,,,,,,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Unable to schedule pool upgrade after pool upgrade cancel,INDY-743,20284,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,,VladimirWork,VladimirWork,19/Aug/17 12:05 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
sovrin 1.0.111
indy-node 1.0.111

Overview:
Unable to schedule pool upgrade after pool upgrade cancel.

Steps to Reproduce:
1. Login as Trustee.
2. Send POOL_UPGRADE command.
3. Send cancel for previous command.
4. Send anoher POOL_UPGRADE command.

Actual Results:
Pool upgrade failed: client request invalid: UnauthorizedClientRequest('TRUSTEE cannot do POOL_UPGRADE',).

Expected Results:
Upgrade should schedule normally.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/17 12:00 AM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11905/Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydlz:",,,,,,,,,,,,,,,,,,,,,,,,,,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[QA] Add load testing to acceptance tests,INDY-744,20330,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ozheregelya,ozheregelya,ozheregelya,22/Aug/17 10:15 PM,09/Oct/19 11:28 PM,28/Oct/23 2:47 AM,09/Oct/19 11:28 PM,,,,,0,4Months,KellyRetest,,,,"* Add load testing to acceptance tests (scenario in Acceptance Tests and Matrix folder).
 * Add according row to Test Matrix - RC - Sovrin - INDY spreadsheet.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx0pb:",,,,,,11,12,13,14,INDY 17.21,,,,8.0,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[QA] Add scenario for view change to acceptance tests,INDY-745,20331,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ozheregelya,ozheregelya,22/Aug/17 10:19 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"* Add scenario for view change to acceptance tests:
 ** caused by stopping services on primary;
 ** caused by demotion of primary;
 ** caused by decreasing of primary node performance.
 * Add according row to Test Matrix - RC - Sovrin - INDY spreadsheet.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydcv:",,,,,,11,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Aug/17 5:49 PM;VladimirWork;13 - DID - Test Scenario – (View Change) is added.
Test Matrix - RC - Sovrin - INDY is updated.;;;","25/Aug/17 6:08 AM;ozheregelya;Scenario was reviewed, small changes in formatting have been done.
New cases in Test matrix were reviewed, mistakes have been fixed.;;;","26/Aug/17 1:01 AM;krw910;The tests look good and have a new test document as well as tracking in the acceptance spreadsheet.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[QA] Add scenario for upgrade to acceptance tests,INDY-746,20332,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ozheregelya,ozheregelya,22/Aug/17 10:21 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"* Add scenario for upgrade to acceptance tests:
 ** usual upgrade;
 ** force upgrade;
 ** data for testing of migration;
 ** cancellation of upgrade;
 * Add according row to Test Matrix - RC - Sovrin - INDY spreadsheet.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydd3:",,,,,,11,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Aug/17 5:39 PM;VladimirWork;00 - DID - Test Scenario -- (Upgrade) is added.
Test Matrix - RC - Sovrin - INDY is updated.;;;","25/Aug/17 5:52 AM;ozheregelya;Scenario was reviewed, small formatting changes were performed.
Cases in test matrix also were reviewed, case for data consistency validation was added.;;;","26/Aug/17 1:02 AM;krw910;The tests look good and have a new test document as well as tracking in the acceptance spreadsheet.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[QA] Add explicit description for testing of catch-up and consensus count to scenario 08,INDY-747,20333,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ozheregelya,ozheregelya,22/Aug/17 10:36 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyddb:",,,,,,11,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Aug/17 12:20 AM;ozheregelya;New cases for catch up are added to scenario 7.
 New cases for consensus count and for catch up (after promotion and after restart of services) are added to scenario 8.

According cases are added to Test Matrix.

See documents history for details.

 ;;;","25/Aug/17 5:04 PM;ozheregelya;May be it will be better to move tests of consensus count to separate scenario, but I kept them in scenario 8 for now.;;;","25/Aug/17 5:12 PM;VladimirWork;Both scenario changes have been reviewed.;;;","26/Aug/17 1:03 AM;krw910;The tests look good and have a new test document as well as tracking in the acceptance spreadsheet.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support BLS crypto math,INDY-748,20339,19858,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dsurnin,ashcherbakov,ashcherbakov,23/Aug/17 1:22 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"- Provide general interface for BLS crypto
- Support indy-crypto lib created in the scope of IS-314
- May have a charm-based PoC until indy-crypto is ready",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydvb:",,,,,,11,12,13,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support MULTI_SIG_PARAMS txn,INDY-749,20340,19858,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,mzk-vct,ashcherbakov,ashcherbakov,23/Aug/17 1:23 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"- Support MULTI_SIG_PARAMS txn in config ledger
-- What groups (G1, G2, GT) should we use by default?
-- What functions should we choose as H and F?
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydvj:",,,,,,11,12,13,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Sep/17 8:16 PM;ashcherbakov;INDY-858 is created to address this;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support Public key generation for each Node,INDY-750,20341,19858,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,mzk-vct,ashcherbakov,ashcherbakov,23/Aug/17 1:23 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"- Store as part of Node txn, or a separate txn? I think NODE txn is fine for this.
- Think about how to set this for existing nodes
- Where to store secret keys? 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydvr:",,,,,,11,12,13,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extend BFT protocol with multi-sig,INDY-751,20342,19858,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,mzk-vct,ashcherbakov,ashcherbakov,23/Aug/17 1:24 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"- PRE-PREPARE: Primary sends sig for the current batch (and multi-sig for the previous one?)
- PREPARE: Non-primaries (verify multi-sig for the previous batch?) and send a sig for the current one
- COMMIT: send COMMIT only if we have n-f correct sigs from different nodes
- Support multi-sig verification on timeout (without a real batch)??
- Having the logic on master instance only we make the difference between master and backups even more dramatic, so it may lead to incorrect view changes
",,,,,,,,,,,,,,,,,,,,,,,INDY-824,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydvz:",,,,,,11,12,13,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,ashcherbakov,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Sep/17 4:47 PM;mzk-vct;What is done:
- PrePrepare, Prepare and Commit messages got fields for signatures
- Primary (can) add signature to PrePrepare
- Replicas (can) add signatures to Prepare and Commit messages
- Replicas verify signatures of Prepare and Commit messages but allow missing signatures 
- When request ordered all replicas create multi-signature
- Multi-signature created by primary propagates to other nodes with a new PrePrepare

Branch: bls;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Store multisig,INDY-752,20343,19858,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dsurnin,ashcherbakov,ashcherbakov,23/Aug/17 1:25 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"- Is it Primary who calculates multi-sig?
- Where do we store multisig? Is it a separate db? If we need historical proofs, then we need a protocol to have it always in sync and be able to restore/catch-up it.
- Store the nodes participated in the signature together with the multi-sig (since it’s possible that only n-f nodes participated)?
- Need to think how to represent the Nodes participated in multi-sig:
Node’s IDs?
- Option1: Each Nodes calculates and stores multi-sig independently
-- Each COMMIT contains sig_i. 
-- Once each Node orders a txn, it calculates the multiplication of sig_i (>= n-f), and stores the sig and nodes participated in multiplication in a separate DB.
-- It’s possible and fine that multi-sigs are different for the same state for different nodes (because they may receive different set of COMMITs). The only requirement that >=n-f nodes must sign.
-- It’s OK that a Node may miss a multi-sig in its own DB. In this case a client should ask another Node.
-- Also we may implement requesting of missing signed states.
-- Do we need to verify multi-sig of a previous batch sent with PRE_PREPARE? Isn’t the multi-sigs crypto and the requirement of having n-f participants already provides all necessary info for state proofs?
- Option2: Primary calculates the multi-sig and it’s persisted with the next batch
-- Primary calculates the multi-sig and stores it in its own DB.
-- During the next PRE-PREPARE, other nodes verify multi-sig, and if it’s fine, then they store it in they own DBs (so, we have a lag between ordering and signing).
-- We may have incorrect multi-sigs stored in primary’s DB if the primary is malicious. Probably that’s not a big problem.
-- If nodes find that primary’s multi-sig (for last batch) is invalid, then should the new primary re-calculate it?
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydw7:",,,,,,11,12,13,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,ashcherbakov,dsurnin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Sep/17 7:01 PM;dsurnin;bls store implemented and merged to bls development branch

plenum 34c3c08ad5a20a62af77d8ea9e0cdaea8d356e6d;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clients count (-c) argument works strange with batching in load_test.py script (InvalidMessageExceedingSizeException appears when script is running with several clients),INDY-753,20344,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ozheregelya,ozheregelya,ozheregelya,23/Aug/17 1:26 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*Steps to Reproduce:*

1. Run the load test with following parameters:
{code:java}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 4 -r 100 --at-once{code}
=> all works correctly, all transactions are written.
 2. Run the load test with following parameters:
{code:java}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 6 -r 100 --at-once{code}
=> only first 100 transactions are written, InvalidMessageExceedingSizeException appears in logs.

*Actual Result:*
 Message length limitation works when several clients are used.

*Expected Result:*
 Message length limitation should not work when several clients are used.

*Possible Workaround:*
 Run load_test.py using several different machines.
Turn off the limitation (it is acceptable for testing of some tickets like INDY-292).",,,,,,,,,,,,,,,,,,,,INDY-765,,,,,,,,,,,,,,,"23/Aug/17 1:35 AM;ozheregelya;logs.7z;https://jira.hyperledger.org/secure/attachment/11920/logs.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyihb:",,,,,,14,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Aug/17 6:01 AM;krw910;[~mzk-vct] can we do something with the load_test script to break up the transactions into multiple messages. The fix in INDY-25 limits the message size instead of the transaction size which is causing this issue. I will be logging another ticket to deal with the limits on the message size versus the transaction size.;;;","28/Sep/17 1:41 AM;ashcherbakov;We need to check whether this is still an issue after recent fixes of txn size limit.;;;","03/Oct/17 12:15 AM;ozheregelya;No, the problem does not reproduce now. The problem was not in load test script, it was in the node logic and it fixed in scope of INDY-765, so I'll close this ticket as invalid.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Doc] Have up-to-date HOWTO and list of Architecture docs available from GitHub,INDY-754,20353,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,ashcherbakov,ashcherbakov,23/Aug/17 5:27 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Documentation,Must,,,,"Indy's GitGub page must have all necessary information for ramp up and get familiar with the project.
It can either has
* necessary docs in .md format in source code
* docs in Github project's wiki
* docs in Hyperledger's wiki
* reference to other docs (google docs?)  

It includes:
* Instructions on how to work with the code (build, run tests, static code validation) - {color:red}needs to be created{color}
* CI/CD instructions - we have  [Releases and CD pipelines architecture and Guides|https://docs.google.com/document/d/1gKf3F_r7WamoIYS_-ts2nruB2VIuiIpjmzPIVNf2VK0/edit#heading=h.sgv0qe7trz1p], but it needs to be reviewed for sure, there were some changes from that time
* Architecture docs (or references to them) - please see the list below
* CLI help: [List of CLI commands|https://docs.google.com/spreadsheets/d/1wizYZUNXdDvvj6zu7XVVwW03bVTp2mOsZakbLyj7RLM/edit#gid=0]

Some architecture and design docs we may want to reference:
* [RBFT|https://pakupaku.me/plaublin/rbft/5000a297.pdf]
* [Batching transactions into blocks|https://docs.google.com/document/d/1qYKTttP40RF0pRKVQms6_3ll9j7Wfh2F8IzTBRfVqq4/edit#heading=h.raerzlqofz47]
* [DID/DDO Design|https://docs.google.com/document/d/1UGyoLlmv9OMBi-EStDrLFvY6URwlN4hSCfXghRbSgLo/edit#heading=h.4dabf3er5xg1]
* [ledger catchup|https://docs.google.com/document/d/1GaGoEa5pPPPajnnECGWVGy6VpSgbZgKFNZwRRx3uPNU/edit]
* [View Change Protocol|https://docs.google.com/document/d/1oftK70I00wPGXFvFqiA2tmpwU7-kIjgNNieYkZcFkic/edit#heading=h.426nyiht19nr]
* [HLD of python Sovrin client|https://docs.google.com/document/d/1OxwZdhA5SjKRJ03A4IondcRqi_DsPYgYIvFIMl09lWs/edit]
* [Important Node Log Messages|https://docs.google.com/document/d/1xEHNXn9-PiPP61BccWD0SOSDsw7LYxyOgY2dHXn0X8I/edit#heading=h.fyqxs8wc7yks]
* [Sovrin Ledger Transaction Types|https://docs.google.com/spreadsheets/d/1p7nt1e6iNRfdYG-SVQmhsB2-iZ1zhFgJ1ey-kIBguiE/edit#gid=657206024]
* [Sovrin State Proofs Technical Design|https://docs.google.com/document/d/1UTzvC6by1q_Ny5ob6JFz4-q3YU2gd9-qH5iAowhVbqE/edit#heading=h.4dabf3er5xg1]
* [Anoncreds in Sovrin|https://docs.google.com/document/d/1pqyvXCcGAWFm0mHWIh9PsJp0lIdIraUsntf_3HcD294/edit]
* [Releases and CD pipelines architecture and Guides|https://docs.google.com/document/d/1gKf3F_r7WamoIYS_-ts2nruB2VIuiIpjmzPIVNf2VK0/edit#heading=h.sgv0qe7trz1p]
* [Sovrin network roles and permissions|https://docs.google.com/document/d/1gKf3F_r7WamoIYS_-ts2nruB2VIuiIpjmzPIVNf2VK0/edit#heading=h.sgv0qe7trz1p]
* [FAQ (a bit outdated)|https://docs.google.com/document/d/1XPaLrnTi4gbTFqSeakpeC1O-6vhWaH0OWUJ--TUIEsQ/edit]
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzx0vz:",,,,,,12,14,INDY 17.21,INDY 17.22,INDY 17.23,INDY 17.24: Node Perf,,,5.0,,,,,,,,,,,,ashcherbakov,krw910,lovesh,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Oct/17 6:55 AM;TechWritingWhiz;[~ashcherbakov] - I'm reviewing this ticket again. 

Here are my questions: 
 *  Indy's GitHub page: which page is this? Is the Hyperledger Wiki-Indy page?
 * ""Necessary docs"".: what documents exactly should be included? Where are they located? Should the docs themselves be migrated or simply referenced via Link?
 * ""docs in Githubs project's wiki"" : What is the ""github project"" wiki? Is this the same as the Hyperledger Wiki-Indy page?
 docs in the Hyperleger wiki"": Which docs need to be here and where can I find each of them? I've added some recently to this page (the Hyperledger Wiki-Indy page) [https://wiki.hyperledger.org/projects/indy]
 * ""reference to other Google docs"": Which docs are these and where can each of them be found? 
 * Where are the current CI/CD instructions?

 

Also: 

In slack you mentioned that you wanted to create placeholder for some of these items in the current documentation. Which documents am I supposed to be creating placeholders in and where can they be found? ;;;","25/Oct/17 6:06 PM;ashcherbakov;[~TechWritingWhiz]
I've started working on this task, so I'm going to send PR with updated documentation, and you can review it.;;;","31/Oct/17 7:29 AM;TechWritingWhiz;[~ashcherbakov] In your last comment, you said you be doing a pull request so I could review it. When that is done, will that pull request be placed here in the comments? I'm only asking because I'm not sure where I would be watching for that to come through. If you haven't done it yet, that is fine. I'm just following up since it's on my radar. ;;;","31/Oct/17 5:20 PM;ashcherbakov;[~TechWritingWhiz]
I'm still working on it. I will let you know (both here and in Slack) when I'm done.
;;;","01/Nov/17 12:51 AM;ashcherbakov;[~TechWritingWhiz] This is not a final version of a PR, but close to it:
https://github.com/hyperledger/indy-node/pull/427
I think it will give an overview about the changes and structure I propose.;;;","01/Nov/17 5:31 AM;TechWritingWhiz;[~ashcherbakov] Thanks. I've reviewed the changes. I'm wondering how much of this information needs to referenced from the Hyperledger Wiki-Indy page. I'm still confused as I haven't had my questions answered. In other words, I can see how some of these changes you made fulfill some of the bullet items of the ticket. However, I'm not seeing how they fulfill the rest. I'm also still unsure as to what it is exactly I need to be doing at this point. I'm genuinely seeking clarification. ;;;","01/Nov/17 5:19 PM;ashcherbakov;[~TechWritingWhiz]
 Thanks for review.

{quote}
I'm wondering how much of this information needs to referenced from the Hyperledger Wiki-Indy page.
{quote}
I think we can discuss it with [~nage] [~SeanBohan_Sovrin] [~stevetolman]. 
Personally, I would prefer to have all information available on GitHub, so that we someone clones the project it has all required information embedded.
I think we can duplicate some information in two places (GitHub and Indy Wiki). It will mean that we should take care of making the information in sync.

{quote}
 I'm also still unsure as to what it is exactly I need to be doing at this point
{quote}
I think we can merge my changes (after review of the content from other engineers). Then our QA can test the doc and scripts.
And then you can take care of proper style, grammar, vocabulary, etc. if needed. Also you can extend/add more documentation if you think it's necessary.
Would you agree with that plan?

{quote}
 In other words, I can see how some of these changes you made fulfill some of the bullet items of the ticket.
{quote}
-  Indy's GitHub page: which page is this? Is the Hyperledger Wiki-Indy page?
I'm assuming this is https://github.com/hyperledger/indy-node
- ""Necessary docs"".: what documents exactly should be included? Where are they located? Should the docs themselves be migrated or simply referenced via Link?
I've asked a question in architecture channel about what docs can be shared and what docs can not. 
I think it should be fine to reference the docs by links.
Actually most of the design docs are rather some design/discussion docs, which are not very good for public. But probably we can still share them (better than nothing).
Let's discuss this item in Slack in more details. Probably we will need to create a separate ticket to find out what docs we have, and what can be shared.
Please find some links in the ticket description.

- ""docs in Githubs project's wiki"" : What is the ""github project"" wiki? Is this the same as the Hyperledger Wiki-Indy page?
docs in the Hyperleger wiki"": Which docs need to be here and where can I find each of them? I've added some recently to this page (the Hyperledger Wiki-Indy page) https://wiki.hyperledger.org/projects/indy
There is also a wiki page on GitHub (for example, https://github.com/hyperledger/indy-plenum/wiki).
So, as an option, we could put some documentation here as well.
I think it's better to put documentation to either Hyperledger's Indy or into code instead. 
As for the docs, the same answer as above. It's not clear and needs to be defined. Please find some links in the ticket description.

- ""reference to other Google docs"": Which docs are these and where can each of them be found? 
The same, it needs to be find out what docs we may share. Please find some links in the ticket description.

- Where are the current CI/CD instructions
There is (quite outdated) doc here: [Releases and CD pipelines architecture and Guides|https://docs.google.com/document/d/1gKf3F_r7WamoIYS_-ts2nruB2VIuiIpjmzPIVNf2VK0/edit#heading=h.sgv0qe7trz1p]
Also I added this information to https://github.com/hyperledger/indy-node/blob/improve-doc/docs/ci-cd.md
;;;","01/Nov/17 9:35 PM;ashcherbakov;PR: https://github.com/hyperledger/indy-node/pull/427
It doesn't contain yet all references to docs/designs, as we need to figure out what we can share.;;;","02/Nov/17 4:17 AM;TechWritingWhiz;[~ashcherbakov]. 

_Personally, I would prefer to have all information available on GitHub, so that we someone clones the project it has all required information embedded._

_-_ This is fine. It just is not clear from the Hyperledger Wiki Indy page, that this is where the bulk of the info can be found. To fix that, I will simply mention it on that page as a note so at least the reader has a better idea of where to look for it. This will satisfy that need. There won't be a need to synchronize data at that point.

 _Also you can extend/add more documentation if you think it's necessary._
_Would you agree with that plan?_

- Yes, that is fine. I agree with that.

_There is also a wiki page on GitHub (for example, [https://github.com/hyperledger/indy-plenum/wiki])._

_-_ This highlights why we are trying to streamline where documentation can be found, should be housed etc. I didn't know this existed until you mentioned it here. I know from discussions in the past the Hyperledger Wiki-Indy page should be the main ""Hub"" as a starting off jump point for all things Indy. There should only be one Wiki page. I propose that the information found in the wiki you mentioned above either be moved into a separate doc within the docs folder or be migrated to the main Wiki. If it has to do with the code, then it should stay in the ""docs"" folder for its repo.

_Probably we will need to create a separate ticket to find out what docs we have, and what can be shared._

_-_ I agree. 

The rest of what you did, has been answered now. (Had to go through it a few times). :D 

The Hyperledger Wiki-Indy page should be the main ""hub"" and all documentation related to the code, how the code works, etc... should be kept in the ""docs"" folder of the individual repos. 

 

I'll put this ticket on the ""back burner"" for now, until I hear from someone they need me again. 

 ;;;","20/Nov/17 7:25 PM;lovesh;[~TechWritingWhiz] The doc Anoncreds in Sovrin has been updated.;;;","01/Dec/17 1:00 AM;krw910;[~ashcherbakov] after discussing this with Misty we found the documents do not seem to be in the correct location.

Misty's instructions:
The Hyperledger Wiki-Indy page should be the main ""hub"" and all documentation related to the code, how the code works, etc... should be kept in the ""docs"" folder of the individual repos. 

We should not be adding information to the Hyperledger GitHub wiki, they should be in the correct docs folder for the repo they belong to. Please correct this and provide updated links when this is done.;;;","01/Dec/17 1:05 AM;ashcherbakov;[~krw910] There is no new documentation added to Hyperldeger GitHub Indy. All new docs are added as .md in the source code.
The only doc in GitHub wiki is a Plenum doc, but this is pretty old, not new, and not in the scope of this ticket. Moreover, this wiki in plenum will be deprecated soon.

I think we need to create a new ticket if we see some old documentation that needs to be moved.
This task was about adding new docs.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Unable to start nodes after pool reinstall,INDY-755,20354,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,zhigunenko.dsr,VladimirWork,VladimirWork,23/Aug/17 5:31 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,1.6.83,,,0,,,,,,"Build Info:
indy-node 1.0.113

Overview:
Unable to start nodes after pool reinstall due to nonexistent migration script is applying during reinstallation.

Steps to Reproduce:
1. Perform ""send POOL_UPGRADE name=upgrade_reinstall version=1.0.113 sha256=ed0a366b4ef36d40c055672a8b83679e99246fec71a706b4ae4cb7958feace3f action=start schedule=
{'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-08-18T15:20:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-08-18T15:25:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-08-18T15:30:00.258870+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-08-18T15:35:00.258870+00:00'}
timeout=10 force=True reinstall=True""

Actual Results:
Nodes are disconnected and are not connected themselves due to migration script applying errors. See attached journalctl for more info.

Expected Results:
Nodes should be started after the upgrade. Migration script should not be applied during reinstallation (according to discussion with Alexander S).

Workaround:
Start all nodes manually.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Aug/17 5:29 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/11922/Screenshot.PNG","23/Aug/17 5:29 PM;VladimirWork;journalctl_reinstall_113.txt;https://jira.hyperledger.org/secure/attachment/11921/journalctl_reinstall_113.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzwxdb:",,,,,,,,,,,,,,,,,,,,,,,,,,VladimirWork,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 10:39 PM;zhigunenko.dsr;*Environment:*
indy-node 1.6.78 (stable)

*Steps to Validate:*
1. Perform ""send POOL_UPGRADE name=upgrade_reinstall version=1.6.78 sha256=ed0a366b4ef36d40c055672a8b83679e99246fec71a706b4ae4cb7958feace3f action=start schedule={%schedule%} timeout=10 force=True reinstall=True""

*Actual Results:*
Nodes started after the upgrade. Migration script hasn't applied during reinstallation. Pool orders further transactions;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to limit transaction size independent of message size and by transaction type,INDY-756,20365,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,krw910,krw910,24/Aug/17 12:59 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"INDY-25 was meant to limit transaction size. The implementation limits the message size and not the individual transaction size to 128k.

*Problem*
We need to be able to limit the transaction size by type of transaction and not by the size of the message. One large message could contain several hundred transactions. In the case of the load_test.py script when sending 400 transactions at once a single message is sent and then rejected due to message size. 

*Use Case*
The best way for users to add large amounts of NYMs to the ledger will be in sending large batches of transactions within a single message. We should be able to break out the message and deal with each transaction individually.

Limiting the size by transaction type will keep transactions within a reasonable range without giving a blanket size to all transaction types. Adding a NYM transaction does not need to be large while adding a schema or CLAIM_DEF will require a large limit.

*Requirement*
Limit size of transactions by transaction type and not by message size.


",,,,,,,,,,,,,,,,,,,,,,,INDY-698,,,,INDY-852,,,,,,,,"13/Sep/17 9:01 PM;VladimirWork;__SIGNATURE_TYPE.PNG;https://jira.hyperledger.org/secure/attachment/12089/__SIGNATURE_TYPE.PNG","13/Sep/17 9:02 PM;VladimirWork;__VERSION.PNG;https://jira.hyperledger.org/secure/attachment/12090/__VERSION.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyl4f:",,,,,,11,12,13,14,INDY 17.21,,,,3.0,,,,,,,,,,,,ashcherbakov,danielhardman,dsurnin,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Aug/17 1:33 AM;krw910;Linked to INDY-765;;;","26/Aug/17 1:38 AM;krw910;[~ashcherbakov][~nage][~stevetolman][~danielhardman]
This relates to INDY-765 where both need to be addressed in the same build.;;;","02/Sep/17 12:53 AM;ashcherbakov;[~krw910] [~dsurnin]
I think we need to discuss whether the feature in this ticket is really needed if INDY-765 is fixed.;;;","05/Sep/17 10:31 PM;dsurnin;[~krw910] [~ashcherbakov] [~mzk-vct]

After short team discussion we suggest to use mixed approach - leave message limit as is and add individual txn length limit.

INDY-765 fix allows to split long batches into several batches each fitted to message limit, so there should not be any changes.

Most of the txns' fields have fixed size, so we need to limit only variable sizing fields, such as name, raw, etc.
We can do this on txn scheme level during the validation process for the needed fields only.

 

Question for discussion

Do we plan to set individual txn lengths via pool_config txn, see INDY-698 ?;;;","08/Sep/17 9:14 PM;dsurnin;individual fields length restrictions added

plenum 612b2c3ceeba38ac4087fd3aa9f45e0e1eff0de9

node 0b6e59abae8b923b580103beddc7a08182e9ef52

 

please note, following constraints were added

ALIAS_FIELD_LIMIT = 256
DIGEST_FIELD_LIMIT = 512
TIE_IDR_FIELD_LIMIT = 256
NAME_FIELD_LIMIT = 256
SENDER_CLIENT_FIELD_LIMIT = 256
HASH_FIELD_LIMIT = 256
SIGNATURE_FIELD_LIMIT = 512
JSON_FIELD_LIMIT = 5 * 1024
DATA_FIELD_LIMIT = 5 * 1024
NONCE_FIELD_LIMIT = 512
ORIGIN_FIELD_LIMIT = 128
ENC_FIELD_LIMIT = 16
RAW_FIELD_LIMIT = 5 * 1024
SIGNATURE_TYPE_FIELD_LIMIT = 16
BLS_KEY_LIMIT = 512
BLS_SIG_LIMIT = 512
BLS_MULTI_SIG_LIMIT = 512

 

these limits could be discussed and configured

 

no additional tests were added;;;","13/Sep/17 9:02 PM;VladimirWork;Build Info:
indy-node 1.1.134

Steps to Reproduce - Case 1:
0. Login as Trustee.
1. send CLAIM_DEF ref=16 signature_type=CLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCL

Actual Results:
In 617 iterations, found prime 16588191782994323122975708446126707113022746136322835518069910531704777222371121307846835296695807547324646674696357625698228391623149616099004338627192875431052230317381749
In 129 iterations, found prime 15081128388203406640905998096007010940543334738547626084248744619521111357048790683330677838329326480880906221441703868983372143472554712293142273519416027407733726260127209
The claim definition was published to the Sovrin distributed ledger:
Sequence number is 29. !__SIGNATURE_TYPE.PNG|thumbnail! 

Expected Results:
There should be an validation error (LIMIT=16). Claim definition should not be published.


Steps to Reproduce - Case 2:
0. Login as Trustee.
1. send SCHEMA name=Degree version=1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111.11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111.111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111 keys=undergrad,last_name,first_name,birth_date,postgrad,expiry_date

Actual Results:
The following schema is published to the Sovrin distributed ledger...Sequence number is 30. !__VERSION.PNG|thumbnail! 

Expected Results:
We should add some validation (about 16 or 128 as max?) for ""version"" attribute, because now we can send 1024+ chars in it.
;;;","15/Sep/17 10:13 PM;VladimirWork;General implementation is done. All bugs found are reported as separated ticket (INDY-852).;;;","29/Sep/17 6:23 AM;danielhardman;I am not sure I am understanding the fix fully. Are we waiting until a message arrives, and then running it through input validation, rejecting any message that has a field that exceeds the max size? If so, this helps, but it is not enough. A person could open a connection and begin streaming a message with a 10 TB field, and we would continue to try to buffer the incoming message until we ran out of memory, without ever getting to the point where the input validation is triggered.

Am I misunderstanding?;;;","29/Sep/17 6:18 PM;dsurnin;[~danielhardman]

First of all we check that incoming chunk of data is less than 128K. We do this on raw data without decoding.

After that we decode it and split on individual transactions.

Individual transactions are validated with field size, field types, values, etc validators. And the length field constants I talked about above are applied on this step.

This size 128K is hardcoded in config for now, but as far as I remember we have plans to make it configurable via special transaction.

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validator unable to catch up until load generator client is stopped,INDY-757,20372,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,mgbailey,mgbailey,24/Aug/17 7:33 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,validator-info,,0,4Months,KellyRetest,,,,"While running a low-volume load test on the ESN, one node, play, did not maintain sync with the rest of the network.  It's transaction count remained at 15072, while the rest of the network was posting new transactions at a rate of one per minute.  At 20:51:23 UTC, when the ledger transaction count on the rest of the pool reached 15175, the load generator was killed.  Immediately at this time, play began to resync with the rest of the pool.  This resync was successfully completed at 20:53:01.

The issue to investigate is why was play unable to obtain and maintain synchronization with the remainder of the pool while the load generator was running an a low rate?","ESN network, running indy-node 1.0.28",,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1033,INDY-1141,,,,,,,"24/Aug/17 7:32 AM;mgbailey;play.logs.tgz;https://jira.hyperledger.org/secure/attachment/11931/play.logs.tgz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzyrbz:",,,,,,"Sprint 18.03 Stability, DKMS",,,,,,,,,,,,,,,,,,,,anikitinDSR,dsurnin,mgbailey,SeanBohan_Sovrin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jan/18 7:07 AM;SeanBohan_Sovrin;[~ashcherbakov] - want you to look at this in context of state machine refactor and know if there is anything we can do in refactoring to make this kind of use scenario more possible as we refactor the code;;;","06/Feb/18 5:18 PM;anikitinDSR;This probelm is similar as INDY-1033 or INDY-1141. Need to recheck before fixing this tickets;;;","07/Feb/18 5:40 PM;dsurnin;Node stashes all the requests because watermarks were not updated. Similar issue was fixed in the latest master. Should be retested with latest master.;;;","09/Feb/18 9:52 PM;VladimirWork;Build Info:
indy-node 1.2.299

Steps to Validate:
1. Install pool.
2. Run low-volume load test.
3. Check domain txn count by validator-info or read_ledger.

Actual Results:
Issue with fallen behind node is not reproduced (but it is reproduced by high load test run and will be fixed in scope of INDY-1141).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"When ticket INDY-709 is Live, Update Instructions with New Changes",INDY-758,20373,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,TechWritingWhiz,TechWritingWhiz,24/Aug/17 7:42 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,documentation,,,,,"When ticket INDY-709 is Live, install instructions should no longer require anyone to add repo.evernym.com to /etc/apt/sources.list, or to add evernym's PGP key to its signers. Update all necessary instructions. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzydbz:",,,,,,11,12,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,krw910,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/17 5:56 AM;krw910;Depends on INDY-709;;;","29/Aug/17 7:07 PM;alexander.shekhovcov;[~krw910] [~TechWritingWhiz]
I updated [""Installation and Setup (Node, Client)""|https://docs.google.com/document/d/1fUrvt8rEekZmpfHjoeod7ZmWh3ISvSf-18vK5yTH6RY/edit]. Do we have others installation instructions somewhere?


;;;","31/Aug/17 5:47 AM;TechWritingWhiz;I've previously added these instructions to the main documentation – the PDF called ""Working with Nodes and Clients."" I will take the changes you made to the document you changed and update the main document. Other than that, I do not know of any other installation instructions somewhere else. I am not definitive answer on that one though. :) ;;;","31/Aug/17 6:18 AM;TechWritingWhiz;The PDF and HTML versions of this information has now been updated with the changes noted in the google doc referenced. The new version of the official PDF is located here: [https://drive.google.com/drive/u/0/folders/0B4efUY1IocYwUERNNW5sekNTMUU.] Please review this for accuracy. If it is accurate, we may close out this ticket.;;;","12/Sep/17 4:08 AM;krw910;I have checked the documents and it all looks good.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"validator maintains pace with network, exactly 12 transactions behind",INDY-759,20374,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,mgbailey,mgbailey,24/Aug/17 7:43 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"While running a low-load (1 transaction per minute) test on the ESN validator network, one node, metis, posted transactions to its copy of the ledger, but exactly 12 transactions behind the rest of the network.  That is, while the rest of the network had 15175, metis had 15163 transactions.  The transactions in the ledger up to 15163 are complete and match the first 15163 transactions of the rest of the network.  When the next transaction is posted, metis will have 15164 transactions, and this last transaction will match the 15164th transaction of the rest of the nodes.  The rest of the nodes will remain 12 transactions ahead of metis.

The load test has been terminated, and metis remains 12 transactions behind.  We are able to do more tests with this network, as debugging requires.

When logs are made available by the unicorn client, they will be posted here.","ESN test pool, running Indy-node 1.0.28",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/17 7:11 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/12124/Screenshot.PNG","26/Aug/17 12:53 AM;mgbailey;logs_jouer.tgz;https://jira.hyperledger.org/secure/attachment/11957/logs_jouer.tgz","25/Aug/17 1:41 AM;mgbailey;logs_metis.tgz;https://jira.hyperledger.org/secure/attachment/11940/logs_metis.tgz","30/Aug/17 5:01 AM;mgbailey;logs_metis_earlier.tgz;https://jira.hyperledger.org/secure/attachment/11989/logs_metis_earlier.tgz","26/Aug/17 12:53 AM;mgbailey;merkle_jouer.tgz;https://jira.hyperledger.org/secure/attachment/11956/merkle_jouer.tgz","25/Aug/17 1:41 AM;mgbailey;trans_jouer.tgz;https://jira.hyperledger.org/secure/attachment/11939/trans_jouer.tgz","25/Aug/17 1:41 AM;mgbailey;trans_metis.tgz;https://jira.hyperledger.org/secure/attachment/11941/trans_metis.tgz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyl4v:",,,,,,11,12,13,14,INDY 17.21,,,,,,,,,,,,,,,,ashcherbakov,krw910,mgbailey,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Aug/17 7:49 AM;krw910;[~ashcherbakov] We are dealing with a customer on this node that is having the trouble. More than anything [~mgbailey] needs to know what steps to take next to help troubleshoot the issue. I would have assigned this to Victor, but I show he is out this week. Please pass this ticket to an available developer that can point Mike in the direction of what to do next for this node.;;;","24/Aug/17 2:53 PM;ashcherbakov;[~mgbailey] Do I understand correctly that metis can post transactions to its ledger (it's not stalled), but it's always 12 txns behind? How do you get the total number of txns? Just counting the lines in txn files? I know that we had a bug previously where some empty lines were inserted there, so the real number of txns were equal, but number of lines was different.

Can you please provide the logs, and, if possible, ledger folders? ;;;","25/Aug/17 1:46 AM;mgbailey;[~ashcherbakov], attached are transactions and logs from metis.  I have also attached the transactions from jouer, one of the other nodes in the ESN.  

There are no blank lines in either set of transactions, and the files are in sync except for the last 12 transactions.

I have added an additional transaction to the ledger manually, using the CLI.  Once again, metis added one transaction to the ledger as well, and remains 12 behind.;;;","25/Aug/17 10:41 PM;ashcherbakov;[~mgbailey]
Thank you. Can you please also provide the following info:
- logs from 'jouer'
- `domain_state` folders for both 'jouer' and 'metis'
- `merkleLeaves` and `merkleNodes` folders for both 'jouer' and 'metis'
Sorry for big amount of data needed for debug.;;;","26/Aug/17 12:58 AM;mgbailey;[~ashcherbakov], I have added the requested files from jouer.  The domain_state is too large to upload to jira, so a google doc of it is [here|https://drive.google.com/file/d/0B8BSiLQLtlY8Y2pXQ2twWGtLZzg/view?usp=sharing].  The metis docs have been requested from the customer.;;;","28/Aug/17 3:04 AM;mgbailey;[~ashcherbakov], The metis data requested is now available on google docs h[ere.|https://drive.google.com/open?id=0B8BSiLQLtlY8TXFFNllqRGVHLUk];;;","30/Aug/17 12:54 AM;mzk-vct;[~mgbailey], unfortunately log level of jouer was to high, so its log does not contain 'debug' and 'trace' items. Could you please provide logs from other healthy node which had lower log level?;;;","30/Aug/17 1:10 AM;mzk-vct;[~mgbailey] also, if possible, please attach more logs for metis, especially earlier ones;;;","30/Aug/17 5:00 AM;mgbailey;[~mzk-vct] the only other node with low-level logs enabled was 'play', and it had other problems. Its logs are on INDY-759. Since these are the only two nodes with low-level logs enabled, and they were the two that had problems, it kind of makes me wonder if the logging itself might contribute to problems.  I have attached earlier metis logs.;;;","01/Sep/17 6:40 AM;mgbailey;[~mzk-vct], I was excited to hear that the issue has been isolated.  Since this is a persistent issue that remains even after restarting the sovrin-node service, how hard would it be to get a hotfix for Indy-node 1.0.28 that we could put onto metis to resolve this?;;;","04/Sep/17 6:08 PM;mzk-vct;*Scenario:*
 # Client sends request
 # Request is ordered and node send Ordered and Checkpoint messages
 # If some nodes are slower then others (for example because of extended logging) they can process Checkpoint before Ordered
 # When Checkpoint is processed replica removes all request ordered before it (even requests which were ordered, but not yet executed)
 # So the Ordered message cannot be processed, because related request is removed.

*This leads to the following problems:*
 # Falling behind in written transactions
 # Executing the same request twice

*Solution:*

Do not remove requests which were ordered, but not executed

PR: https://github.com/hyperledger/indy-plenum/pull/370;;;","15/Sep/17 4:48 AM;mgbailey;[~mzk-vct], what is the status of this?  It has been in review for over a week.;;;","15/Sep/17 9:55 PM;mzk-vct;[~mgbailey]

There are failing tests that should be fixed before merge. This will be done in the current sprint.

 ;;;","19/Sep/17 7:11 PM;VladimirWork;Build Info:
indy-node 1.1.138

Steps to Validate:
1. Install pool of 4 nodes.
2. Set logging to debug level at 1 node.
3. Perform low-load and high-load tests.
4. Check ""read_ledger --type=domain --count"" at all nodes.

Actual Results:
Domain txns count is the same at all nodes of the pool. !Screenshot.PNG|thumbnail! 

Additional Info:
This issue is covered by plenum/test/test_request_executed_once_and_without_failing_behind.py unit test.;;;","29/Sep/17 5:21 AM;mgbailey;[~danielhardman], USAA asked about this again.  Do we expect it in the upcoming build?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool is broken after several running of load_test.py,INDY-760,20381,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ozheregelya,ozheregelya,24/Aug/17 9:21 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Stability,,,,,"Steps to Reproduce:

1. Connect to pool.
2. Using two clients, run load script several times:
Client 1 (all tests are running one by one):
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 10 -r 100 --at-once
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 10 -r 300 --at-once
python3 load_test_inv.py --clients-list load_test_clients.list -t NYM -c 5 -r 100 --at-once

Client 2 in parallel with load_test_inv.py on client 1:
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 10 -r 100 --at-once
=>test was failed because of InvalidMessageExceedingSizeException)

Invalid test from client 1 and valid test from client 2 are stopped, new test on client 2:
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 10 -r 100 --at-once

Actual Results:
Pool is broken after these actions. Following messages repeatedly appear in the log:
{code:java}
2017-08-24 10:42:37,450 | DEBUG | replica.py ( 311) | last_ordered_3pc | Node1:1 set last ordered as (0, 0)
2017-08-24 10:42:37,450 | DEBUG | replica.py ( 953) | __is_next_pre_prepare | Node1:2 missing PRE-PREPAREs between 10 and 8
2017-08-24 10:42:37,450 | DEBUG | replica.py ( 495) | _setup_for_non_master | Node1:2 Setting last ordered for non-master as (0, 0)
2017-08-24 10:42:37,450 | DEBUG | replica.py ( 311) | last_ordered_3pc | Node1:2 set last ordered as (0, 0)
2017-08-24 10:42:37,463 | DEBUG | replica.py ( 953) | __is_next_pre_prepare | Node1:1 missing PRE-PREPAREs between 6 and 4
2017-08-24 10:42:37,464 | DEBUG | replica.py ( 495) | _setup_for_non_master | Node1:1 Setting last ordered for non-master as (0, 0){code}

Expected Result:
Pool should work.

Additional Information:
Count of transactions is equal for ledgers on all nodes:
{code:java}
ubuntu@californiaPerf1:/home/sovrin/.sovrin$ sudo read_ledger --type=domain --count
1406{code}","Build Info:
  indy-node 1.0.111
  indy-anoncreds 1.0.25
  indy-plenum 1.0.97
  sovrin 1.0.23
OS/Platform: Ubuntu 16.04.2 LTS
Setup: performance pool (7 nodes, 2 clients)",,,,,,,,,,,,,,,,,,,,,,,,,,INDY-804,,,,,,,,"29/Aug/17 7:08 PM;ozheregelya;Node1.7z;https://jira.hyperledger.org/secure/attachment/11967/Node1.7z","29/Aug/17 7:08 PM;ozheregelya;Node2.7z;https://jira.hyperledger.org/secure/attachment/11968/Node2.7z","29/Aug/17 7:08 PM;ozheregelya;Node3.7z;https://jira.hyperledger.org/secure/attachment/11969/Node3.7z","29/Aug/17 7:08 PM;ozheregelya;Node4.7z;https://jira.hyperledger.org/secure/attachment/11970/Node4.7z","29/Aug/17 7:08 PM;ozheregelya;Node5.7z;https://jira.hyperledger.org/secure/attachment/11971/Node5.7z","29/Aug/17 7:08 PM;ozheregelya;Node6.7z;https://jira.hyperledger.org/secure/attachment/11972/Node6.7z","29/Aug/17 7:08 PM;ozheregelya;Node7.7z;https://jira.hyperledger.org/secure/attachment/11973/Node7.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzwz0f:",,,,,,12,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ashcherbakov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Aug/17 5:19 PM;ashcherbakov;[~ozheregelya] do you have some logs from the nodes in the pool?;;;","29/Aug/17 7:09 PM;ozheregelya;[~ashcherbakov], I've attached logs.;;;","12/Sep/17 9:51 PM;andrey.goncharov;Problem reason:
the protocol does not originally support this functionality


Fix:
Added requesting missing preprepares and prepares


Merged Into:
indy-node / master 1.1.134 (https://github.com/hyperledger/indy-node/commit/58d6b4ed6fe3e67384f0cf4e9aee53b1ef75fec2)
indy-plenum / master 1.1.127 (https://github.com/hyperledger/indy-plenum/commit/24990f6af9bfc0eaab44111bb6266d82792c7911);;;","14/Sep/17 12:07 AM;ozheregelya;Build Info:
  indy-node 1.1.136
  indy-anoncreds 1.1.25
  indy-plenum 1.1.127
  sovrin 1.1.26
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 7 nodes, 2 clients

Steps to Validate:
1. Run load tests several times as described before.
2. Look at the logs.

Actual Results:
Requesting missing preprepares is happening, count of ""missing PRE-PREPAREs"" messages is not decreasing when tests are completed. Pool works correctly after all tests.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Response with outdated data,INDY-761,20386,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,danielhardman,Artemkaaas,Artemkaaas,24/Aug/17 10:31 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Indy-sdk integration test on Jenkins often fails because of node response with outdated data. (For pool from 4 Nodes)
For example:
1) Sends Attrib request.
2) Gets response from two nodes (Node1, Node2)
3) Sends GetAttrib request.
3) Gets response from other two nodes (Node3, Node4) with empty Attrib data.
See the attached file which demonstrates log of the failed test.",,,,,,,,,,,,,,IS-140,,,,,,,,,,,,,,,,,,,,,"25/Aug/17 11:49 PM;sergey.minaev;attrib_requests_AND_claim_def_requests_failed.zip;https://jira.hyperledger.org/secure/attachment/11947/attrib_requests_AND_claim_def_requests_failed.zip","25/Aug/17 9:55 PM;sergey.minaev;failed_schema_request.zip;https://jira.hyperledger.org/secure/attachment/11946/failed_schema_request.zip","24/Aug/17 10:30 PM;Artemkaaas;log.txt;https://jira.hyperledger.org/secure/attachment/11936/log.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyihz:",,,,,,11,12,13,14,,,,,,,,,,,,,,,,,Artemkaaas,ashcherbakov,danielhardman,gudkov,krw910,mzk-vct,sergey.minaev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/17 6:01 AM;krw910;[~ashcherbakov] can you assign this ticket out so we can unblock the SDK project.;;;","25/Aug/17 7:31 PM;ashcherbakov;[~Artemkaaas] Can you please provide pool logs with DEBUG level?;;;","25/Aug/17 9:55 PM;sergey.minaev; [^failed_schema_request.zip] another same fail for schema request and get schema. But only default logs level;;;","25/Aug/17 11:49 PM;sergey.minaev;one more logs with maximum log level and failed  [^attrib_requests_AND_claim_def_requests_failed.zip] ;;;","08/Sep/17 6:40 PM;mzk-vct;This problem cannot be fully solved since it is the fundamental problem of distributed systems.
But we can make decrease its frequency, here is a pull reuqest: https://github.com/hyperledger/indy-plenum/pull/362

To make it appear less often and avoid negative effects it may be required to:
1. Make checks on clients side for state freshness by checking seq.no, update time or some other property.
2. Increase read-reply quorum

;;;","13/Sep/17 12:48 AM;mzk-vct;[~danielhardman] [~nage]We need your thoughts about this problem.

*Brief explanation:*
 # Client sends WRITE request
 # He then gets *f+1* confirmations for it  - quorum achieved, client considers request to be written
 # He sends READ request and waits for *f + 1* replies
 # Client gets replies for READ and expect them to contain the same value it sent in WRITE transaction

Success of step 3 depends on whether client receives replies from nodes which really wrote WRITE transaction.
 Despite the fact that pool-internal quorum for ordering is *n-f* it does not mean that all of these n-f nodes already wrote the data, it just means that they *decided* to do it.

 

This is a generic problem of distributed systems and solutions look more like searching tradeoff between performance and consistency.

The most simple solution is to make client send READ to the same nodes he got replies for WRITE from. But this does not cover the case when READ is sent by other client.
 Another solution is to change read quorum - make client wait for an equal replies for READ from majority of nodes, not just f + 1.
 We also can introduce some freshness criteria for READs.

*This problem requires additional discussion*

We have three tickets caused by this problem:
 - this one
 - https://jira.hyperledger.org/browse/INDY-354
 - https://jira.hyperledger.org/browse/INDY-355

 ;;;","15/Sep/17 6:39 PM;gudkov;Looks like it will be nice to discuss this on ART;;;","18/Sep/17 7:08 PM;ashcherbakov;[~gudkov] We've already discussed it on one of the recent ARTs. The decision is that it's really not a problem, but rather a property of distributed systems. 
Once we have state proofs (should have it soon), each reply to the client will contain the result, state proof, seq_no and timestamp. So, if the client isn't satisfied with seqNo/timestamp, he should either send another request in some time (assuming the node doesn't yet have the latest result), or use another validatior/observer node.;;;","29/Sep/17 6:26 AM;danielhardman;Thank you for the excellent summary of the problem, Victor. I agree with Alex's summary of the ART decision, and I agree with the ART decision itself: we will gladly benefit from the ways that state proofs helps, but this is a fundamental problem of distributed systems and we will not do anything special to solve it right now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Code says ""claim"" when it should say ""Proof"" in Test Environment: Alice Demo",INDY-763,20405,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,ashcherbakov,TechWritingWhiz,TechWritingWhiz,25/Aug/17 5:06 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,,,,,"Running through the Getting Started Guide in the Test Environment, code says ""claim"" when Getting Started Guide says ""proof."" 

This appears in the ""send proof Loan-Application-Basic to Thrift Bank"" section. The bank is requiring further proof for her Loan-Application-KYC item, not a claim. The documentation is correct in this case, but the code is not.  See screen shot. 

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/17 5:07 AM;TechWritingWhiz;code.jpg;https://jira.hyperledger.org/secure/attachment/11942/code.jpg","25/Aug/17 5:07 AM;TechWritingWhiz;documentation.jpg;https://jira.hyperledger.org/secure/attachment/11943/documentation.jpg",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-771,,,,,,,,,,"1|hzx1an:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,SeanBohan_Sovrin,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/17 6:03 AM;krw910;[~ashcherbakov] Please make an assignment for this ticket.;;;","04/Jan/18 4:25 AM;SeanBohan_Sovrin;[~gudkov] - can we keep this ticket in mind with the new GSG;;;","28/Sep/18 7:17 AM;ashcherbakov;This GSG is deprecated;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Message length limitation affects parallel sending of transactions from different machines,INDY-765,20417,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,ozheregelya,ozheregelya,25/Aug/17 11:21 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"*Case 1:*

*Steps to Reproduce:*
1. Run load test with following parameters on one of the clients:
{code:java}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 10 -r 100 --at-once{code}
2. After completion of load test check InvalidMessageExceedingSizeException messages in logs.
{code:java}
ubuntu@californiaPerf1:/home/sovrin/.sovrin$ grep ""InvalidMessageExceedingSizeException"" /home/sovrin/.sovrin/Node1.log* | wc -l{code}
 

*Actual Results:*
All 1000 transactions are written successfully, but there are 12 InvalidMessageExceedingSizeException messages appear in logs (there were no such exceptions before the test).

*Expected Results:*
If the massage from one client (running on one physical machine) exceeded limitation, transactions should not be written.

*Case 2:*

*Steps to Reproduce:*

1. Run load test with following parameters on one of the clients:
{code:java}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 5 -r 100 --at-once{code}
=> All transactions are written, count of InvalidMessageExceedingSizeException messages was not increased.
2. After completion of previous script run load test with the same parameters at the same time on all clients.

*Actual Results:*
All transactions were written on 3 clients, but on the 4th client all of transactions were not written. Count of InvalidMessageExceedingSizeException in logs become equal to 60 (before test there were 48 messages).

*Expected Results:*
Transactions which were send by different clients should not affect each other.","Build Info:
  indy-node 1.0.111
  indy-anoncreds 1.0.25
  indy-plenum 1.0.97
  sovrin 1.0.23
OS/Platform: Ubuntu 16.04.2 LTS
Setup: performance pool (7 nodes, 2 clients)",,,,,,,,,,,,,,,,INDY-753,,,,,,,,,,INDY-25,INDY-805,,,,,,,"03/Sep/17 11:52 PM;ozheregelya;length1.txt;https://jira.hyperledger.org/secure/attachment/12018/length1.txt","26/Aug/17 12:34 AM;ozheregelya;logs1.7z;https://jira.hyperledger.org/secure/attachment/11949/logs1.7z","26/Aug/17 12:36 AM;ozheregelya;logs2.7z;https://jira.hyperledger.org/secure/attachment/11950/logs2.7z","26/Aug/17 12:36 AM;ozheregelya;logs3.7z;https://jira.hyperledger.org/secure/attachment/11951/logs3.7z","26/Aug/17 12:36 AM;ozheregelya;logs4.7z;https://jira.hyperledger.org/secure/attachment/11952/logs4.7z","26/Aug/17 12:36 AM;ozheregelya;logs5.7z;https://jira.hyperledger.org/secure/attachment/11953/logs5.7z","26/Aug/17 12:36 AM;ozheregelya;logs6.7z;https://jira.hyperledger.org/secure/attachment/11954/logs6.7z","26/Aug/17 12:36 AM;ozheregelya;logs7.7z;https://jira.hyperledger.org/secure/attachment/11955/logs7.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzwyzz:",,,,,,11,12,,,,,,,,,,,,,,,,,,,alexander.shekhovcov,andrey.goncharov,ashcherbakov,danielhardman,dsurnin,krw910,mzk-vct,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/17 11:31 PM;ashcherbakov;We increased limits for max message length. Now it's 128 MB: https://github.com/hyperledger/indy-plenum/commit/1ba2d758d3fd0be92325ea223633584bb69d2552
It should fix the issues with load tests.
However, we need to re-think whether this is a proper size, and re-think whether we implemented this limitation at a proper place.;;;","26/Aug/17 1:34 AM;krw910;Linked to INDY-756;;;","26/Aug/17 1:37 AM;krw910;[~ashcherbakov][~nage][~stevetolman][~danielhardman]
We need to limit incoming messages per source not as an overall total buffer size. 
This relates to INDY-756 where we want to limit transaction size independent of the message size. ;;;","28/Aug/17 7:45 PM;ozheregelya;MSG_LEN_LIMIT=128MB was verified on following version:
Build Info:
  indy-node 1.0.111
  indy-anoncreds 1.0.25
  indy-plenum 1.0.97
  sovrin 1.0.23
OS/Platform: Ubuntu 16.04.2 LTS
Setup: performance pool (7 nodes, 4 clients)

python3 load_test.py --clients-list load_test_clients.list -t NYM -c 5 -r 100 --at-once
was run on 4 clients at the same time. 2000 transactions were send without any problems.;;;","31/Aug/17 9:45 PM;alexander.shekhovcov;(/) *Resolved:*

Split a batch on pieces during {{flushOutBoxes}} in case if the batch excesses the maximum allowed length.
https://github.com/hyperledger/indy-plenum/pull/367

(i) *How to test:*

The command:
{code}
python3 load_test.py --clients-list load_test_clients.list -t NYM -c 10 -r 100 --at-once
{code}

should not cause ""InvalidMessageExceedingSizeException"".

;;;","03/Sep/17 11:56 PM;ozheregelya;*Build Info:*
   indy-node 1.1.130
   indy-anoncreds 1.1.25
   indy-plenum 1.1.121
   sovrin 1.1.26
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 7 nodes, 4 clients

*Reason for Rejection:*
 Problem from one of comments INDY-25 (https://jira.hyperledger.org/browse/INDY-25?focusedCommentId=29369&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-29369) reproduces after this fix.

*Case 1:*
Pre-conditions:
Turn back limits to 128K on each node to disable Alex's changes https://jira.hyperledger.org/browse/INDY-765?focusedCommentId=30203&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-30203
1. sudo -iu sovrin
2. echo ""MSG_LEN_LIMIT=128*1024"" >> /home/sovrin/.sovrin/sovrin_config.py
3. systemctl restart sovrin-node
4. exit
 Steps to Reproduce:
 1. Connect to the pool.
 2. Set yourself as default Trustee.
 3. Send ATTRIB transaction with long raw field (see attached file [^length1.txt]).
 4. Try to send NYM.
 => NYM was not send.
 5. Exit the CLI.

*Actual Results:*
 Exception appear:
{code:java}
sovrin@test> exit
Active wallet ""Default"" saved (/home/ubuntu/.sovrin/wallets/test/default.wallet)
Goodbye.
Traceback (most recent call last):
 File ""/usr/local/bin/sovrin"", line 78, in <module>
 run_cli()
 File ""/usr/local/bin/sovrin"", line 56, in run_cli
 looper.run(cli.shell(*commands))
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 289, in __exit__
 self.shutdownSync()
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 285, in shutdownSync
 self.loop.run_until_complete(self.shutdown())
 File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
 return future.result()
 File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
 raise self._exception
 File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
 result = coro.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 275, in shutdown
 await self.runFut
 File ""/usr/lib/python3.5/asyncio/futures.py"", line 363, in __iter__
 return self.result() # May raise too.
 File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
 raise self._exception
 File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
 result = coro.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 222, in runForever
 await self.runOnceNicely()
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 205, in runOnceNicely
 msgsProcessed = await self.prodAllOnce()
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 150, in prodAllOnce
 s += await n.prod(limit)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", line 179, in prod
 s = await super().prod(limit)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 244, in prod
 s = await self.nodestack.service(limit)
 File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/kit_zstack.py"", line 108, in service
 c = await super().service(limit)
 File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 441, in service
 return self.processReceived(pracLimit)
 File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 551, in processReceived
 self.msgHandler((msg, frm))
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/client/client.py"", line 102, in handleOneNodeMsg
 super().handleOneNodeMsg(wrappedMsg, excludeFromCli)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 314, in handleOneNodeMsg
 self.reqRepStore.addReject(msg, frm)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/persistence/client_req_rep_store_file.py"", line 72, in addReject
 self.delimiter, reason))
 File ""/usr/local/lib/python3.5/dist-packages/storage/directory_store.py"", line 44, in appendToValue
 with open(self.keyFilePath(key), mode=""a+"") as f:
IsADirectoryError: [Errno 21] Is a directory: '/home/ubuntu/.sovrin/data/clients/AXfp1PZK9KdSSj9GyJGwwnXUxmTystHLCgMydrMhRVN6/Requests/'{code}
 

*Expected Results:*
 CLI should not be broken.

Additional Information:
 Logs are not attached due to large size. You can see them on the performance pool machines (Nodes 1 - 7, Clients 3 and 4).

*Case 2:*
 Sending lots of NYMs using load_test was also verified. Running 
 python3 load_test.py --clients-list load_test_clients.list -t NYM -c 10 -r 100 --at-once
 on 3 client at the same time worked without any issues.;;;","04/Sep/17 9:32 PM;dsurnin;I tested this case locally and it works.

for the moment parameter MSG_LEN_LIMIT is stored in config.
 in case client and node are run on different machines the configs are different.
 if node's MSG_LEN_LIMIT is smaller than client's MSG_LEN_LIMIT it is possible that client can send big txn but node silently ignore it and client does not receive any response - just waits. also it leads to crash on exit since connection still opened.

 ;;;","04/Sep/17 9:42 PM;mzk-vct;Here is a new ticket created for the problem discussed in previous two comments https://jira.hyperledger.org/browse/INDY-805;;;","05/Sep/17 8:31 PM;ozheregelya;Need to revert Alex's changes: https://jira.hyperledger.org/browse/INDY-765?focusedCommentId=30203&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-30203;;;","05/Sep/17 9:08 PM;ozheregelya;Sending of large transactions using CLI and sending lots of transactions using load_test.py by different clients work correctly with changed limitation on client.;;;","08/Sep/17 7:12 PM;andrey.goncharov;Fixed in [https://github.com/hyperledger/indy-plenum/commit/c37e8358f02cf438ec12ec1a2e5fa15d28a4501a]

indy-plenum 1.1.123;;;","08/Sep/17 8:40 PM;ozheregelya;New limit was verified on following build (RC):
indy-plenum= 1.1.25
indy-anoncreds= 1.0.10
indy-node= 1.1.35
sovrin= 1.1.6;;;","13/Sep/17 11:28 PM;danielhardman;I need some clarification about what was implemented:
 # Did we make it so the max size of a message is a per-message limit? Or is it a per-batch limit? Or a per-zmq-queue limit?
 # Is there still a MSG_LEN_LIMIT config option?;;;","13/Sep/17 11:29 PM;danielhardman;[~andrey.goncharov] After answering the questions above, you can set the status back to Customer Validation and assign back to me...;;;","13/Sep/17 11:50 PM;mzk-vct;[~danielhardman]
 # It is both per-message and per-batch since batch is actually a message type. 
However batch has special logic for creation, if it's too large then it's split on smaller batches.
 # Yes, there is a MSG_LEN_LIMIT, its default value is 128kb.
 # In addition to this in ticket https://jira.hyperledger.org/browse/INDY-756 [~dsurnin] implemented size limitation by transaction type.
It discards requests which are too large for their type.

 

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Continuous Integration / Continuous Delivery Pipeline,INDY-766,20423,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,tylerq,tylerq,26/Aug/17 5:31 AM,11/Oct/19 8:50 PM,28/Oct/23 2:47 AM,,,,,,0,devops,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-9,,CI/CD,To Do,,,,,,,,"1|hzxwyv:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Work surrounding Claim & Proof Definitions,INDY-767,20424,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:33 AM,09/Oct/19 5:32 PM,28/Oct/23 2:47 AM,09/Oct/19 5:32 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-2,,Claim/Proof Defs,Done,,,,,,,,"1|hzxwzb:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
All schema related work,INDY-768,20425,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:34 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-4,,Schemas,Done,,,,,,,,"1|hzyvh3:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"All work related to sending Claim Offers, accepting them and requesting Claims.",INDY-770,20427,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:38 AM,09/Oct/19 5:32 PM,28/Oct/23 2:47 AM,09/Oct/19 5:32 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-8,,Claims,Done,,,,,,,,"1|hzxwz3:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"All work dealing with the requesting, offering & presenting of proofs.",INDY-771,20428,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,tylerq,tylerq,26/Aug/17 5:39 AM,28/Sep/18 7:17 AM,28/Oct/23 2:47 AM,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-1,,Proofs,Done,,,,,,,,"1|hzyvfz:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
All work dealing with Sovrin-enabled Agent communications,INDY-772,20429,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,tylerq,tylerq,26/Aug/17 5:41 AM,09/Oct/19 5:16 PM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-3,,Agent Communication,Done,,,,,,,,"1|hzxwwv:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:37 AM;ashcherbakov;We are doing this in [https://github.com/hyperledger/indy-sdk] project;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
All stories dealing with Steward functionality on the ledger,INDY-773,20430,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:42 AM,09/Oct/19 11:16 PM,28/Oct/23 2:47 AM,09/Oct/19 11:15 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-5,,Steward,Done,,,,,,,,"1|hzyvif:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
All work helping to fight spam,INDY-774,20431,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:43 AM,09/Oct/19 7:04 PM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-7,,SPAM,Done,,,,,,,,"1|hzyvhr:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
All issues helping increase performance of individual nodes or the Sovrin network as a whole,INDY-775,20432,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,tylerq,tylerq,26/Aug/17 5:44 AM,20/Dec/19 11:21 PM,28/Oct/23 2:47 AM,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-9,,Node Performance,To Do,,,,,,,,"1|hzyvev:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Work dealing with Trust Anchor functions & features,INDY-776,20433,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:45 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-2,,Trust Anchor,Done,,,,,,,,"1|hzyvjb:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Deals with work for having a dashboard Stewards, Trust Anchors & Trustees can use to see & interact with their node",INDY-777,20434,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:48 AM,09/Oct/19 11:14 PM,28/Oct/23 2:47 AM,09/Oct/19 11:14 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-4,,Node Dashboard,Done,,,,,,,,"1|hzyven:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
We should have better error messages and should show error messages when appropriate. Fail gracefully.,INDY-778,20435,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:52 AM,11/Oct/19 7:23 PM,28/Oct/23 2:47 AM,11/Oct/19 7:22 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-9,,Error Msgs,Done,,,,,,,,"1|hzxx13:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Logging strategy and work,INDY-779,20436,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:53 AM,09/Oct/19 7:02 PM,28/Oct/23 2:47 AM,09/Oct/19 7:02 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-8,,Logs,Done,,,,,,,,"1|hzyvdr:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
All Sandbox tasks & stories,INDY-780,20437,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:54 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-1,,Sandbox,Done,,,,,,,,"1|hzyvgv:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
All testing related work,INDY-781,20438,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 5:59 AM,11/Oct/19 7:01 PM,28/Oct/23 2:47 AM,11/Oct/19 7:00 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1505,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-3,,Tests,Done,,,,,,,,"1|hzyvin:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
All work surrounding the 'create nym' txn and creating additional identities on the ledger,INDY-782,20439,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,tylerq,tylerq,26/Aug/17 6:00 AM,26/Aug/17 6:01 AM,28/Oct/23 2:47 AM,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-5,,DID creation,Done,,,,,,,,"1|hzyeev:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Wallet work,INDY-783,20440,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 6:02 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-7,,Wallet,Done,,,,,,,,"1|hzyw5z:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactoring/housekeeping work,INDY-784,20441,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 6:05 AM,09/Oct/19 6:55 PM,28/Oct/23 2:47 AM,09/Oct/19 6:55 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-4,,Refactor,Done,,,,,,,,"1|hzyvg7:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Transaction-oriented stories,INDY-785,20442,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,tylerq,tylerq,26/Aug/17 6:07 AM,29/Oct/19 11:29 PM,28/Oct/23 2:47 AM,29/Oct/19 11:28 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-2,,TXNS,Done,,,,,,,,"1|hzyw53:",,,,,,,,,,,,,,,,,,,,,,,,,,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool is still writing transactions when more than F nodes are stopped,INDY-786,20467,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,ozheregelya,ozheregelya,29/Aug/17 1:33 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Stability,,,,,"Steps to Reproduce:
 1. Set up pool of 4 nodes. (f=1)
 2. Add 2 more nodes to the pool. (n=6, f=1)
 3. Send transactions to make sure that pool works.
 4. Stop services on Node 6, send transaction.
 => transaction is written, it is ok.
 5. Stop services on Node 5, send transaction.
 => transaction is written, but is should not (because there are less than n-f nodes are in pool).
 6. Stop services on Node 4, send transaction.
 => transaction is written, but is should not.
 7. Stop services on Node 3, send transaction.
 => transaction is not written.

Actual Results:
 Pool is still writing transactions when more than F nodes are stopped.

Expected Results:
 Pool should stop writing transactions after step 5.

Additional Information:
 After promotion of all nodes pool is working. The problem doesn't reproduce on the same pool after starting of stopped nodes.

Here is output of CLI:
{code:java}
sovrin@test> new key with seed 000000000000000000000000Trustee1
Key created in wallet Default
DID for key is V4SGRU86Z58d6TV7PBUe6f
Verification key is ~CoRER63DVYnWZtK8uAzNbx
Current DID set to V4SGRU86Z58d6TV7PBUe6f
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBUe11
Adding nym V4SGRU86Z58d6TV7PBUe11
Nym V4SGRU86Z58d6TV7PBUe11 added
CONNECTION: EkUTN5MQk7HKy6YNZfDAAD7iP3b5bb72XUd1YkJYmSUV disconnected from Node5C
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBUe12
Adding nym V4SGRU86Z58d6TV7PBUe12
Nym V4SGRU86Z58d6TV7PBUe12 added
CONNECTION: EkUTN5MQk7HKy6YNZfDAAD7iP3b5bb72XUd1YkJYmSUV disconnected from Node6C
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBUe13
Adding nym V4SGRU86Z58d6TV7PBUe13
Nym V4SGRU86Z58d6TV7PBUe13 added
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBUe13
Adding nym V4SGRU86Z58d6TV7PBUe13
Nym V4SGRU86Z58d6TV7PBUe13 added
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBUe14
Adding nym V4SGRU86Z58d6TV7PBUe14
Nym V4SGRU86Z58d6TV7PBUe14 added
CONNECTION: EkUTN5MQk7HKy6YNZfDAAD7iP3b5bb72XUd1YkJYmSUV disconnected from Node4C
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBUe15
Adding nym V4SGRU86Z58d6TV7PBUe15
Nym V4SGRU86Z58d6TV7PBUe15 added
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBUe25
Adding nym V4SGRU86Z58d6TV7PBUe25
Nym V4SGRU86Z58d6TV7PBUe25 added
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBU123
Adding nym V4SGRU86Z58d6TV7PBU123
Nym V4SGRU86Z58d6TV7PBU123 added
CONNECTION: EkUTN5MQk7HKy6YNZfDAAD7iP3b5bb72XUd1YkJYmSUV disconnected from Node3C
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBU124
Adding nym V4SGRU86Z58d6TV7PBU124
CONNECTION: EkUTN5MQk7HKy6YNZfDAAD7iP3b5bb72XUd1YkJYmSUV now connected to Node3C
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBU125
Adding nym V4SGRU86Z58d6TV7PBU125
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBU125
Adding nym V4SGRU86Z58d6TV7PBU125
CONNECTION: EkUTN5MQk7HKy6YNZfDAAD7iP3b5bb72XUd1YkJYmSUV now connected to Node4C
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBU125
Adding nym V4SGRU86Z58d6TV7PBU125
CONNECTION: EkUTN5MQk7HKy6YNZfDAAD7iP3b5bb72XUd1YkJYmSUV now connected to Node5C
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBU126
Adding nym V4SGRU86Z58d6TV7PBU126
sovrin@test> send NYM dest=V4SGRU86Z58d6TV7PBU127
Adding nym V4SGRU86Z58d6TV7PBU127
CONNECTION: EkUTN5MQk7HKy6YNZfDAAD7iP3b5bb72XUd1YkJYmSUV now connected to Node6C
Nym V4SGRU86Z58d6TV7PBU126 added
Nym V4SGRU86Z58d6TV7PBU124 added
Nym V4SGRU86Z58d6TV7PBU127 added
Nym V4SGRU86Z58d6TV7PBU125 added
Nym V4SGRU86Z58d6TV7PBU125 added
Nym V4SGRU86Z58d6TV7PBU125 added{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-804,,,,,,,,"29/Aug/17 1:34 AM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11960/Node1.log","29/Aug/17 1:34 AM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11961/Node2.log","29/Aug/17 1:34 AM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11962/Node3.log","29/Aug/17 1:34 AM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11963/Node4.log","29/Aug/17 1:34 AM;ozheregelya;Node5.log;https://jira.hyperledger.org/secure/attachment/11964/Node5.log","29/Aug/17 1:34 AM;ozheregelya;Node6.log;https://jira.hyperledger.org/secure/attachment/11965/Node6.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzwz07:",,,,,,12,,,,,,,,,,,,,,,,,,,,andrey.goncharov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Sep/17 9:52 PM;andrey.goncharov;Problem reason:
Protocol misimplementation


Fix:
Added requesting missing preprepares and prepares


Merged Into:
indy-node / master 1.1.134 (https://github.com/hyperledger/indy-node/commit/58d6b4ed6fe3e67384f0cf4e9aee53b1ef75fec2)
indy-plenum / master 1.1.127 (https://github.com/hyperledger/indy-plenum/commit/24990f6af9bfc0eaab44111bb6266d82792c7911);;;","13/Sep/17 12:57 AM;ozheregelya;*Build Info:*
  indy-node 1.1.134
  indy-anoncreds 1.1.25
  indy-plenum 1.1.127
  sovrin 1.1.26
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 6 nodes, 1 clients

*Steps to Validate:*
1. Set up the pool of 6 nodes.
2. Stop services on 2 nodes.
3. Send transaction. 

*Actual Results:*
Transaction was not written.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
----------MARKER--------------------------------------------------------------------------------------------------------,INDY-787,20479,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,ashcherbakov,ashcherbakov,29/Aug/17 4:43 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0uf:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As I Validator or Observer Node, I need to be able to present Signed State Proof for the client request",INDY-790,20482,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,ashcherbakov,ashcherbakov,29/Aug/17 5:00 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,Sprint-goal-state-proof,,,,"- Support generation of State Proofs creation for client requests
- https://github.com/hyperledger/indy-plenum/pull/364
- https://docs.google.com/document/d/1x94NtronycZUppYnO_847yJ06f33QT-L90xdL1ZbTiE/edit?ts=59a687f1#",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-927,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzyk9b:",,,,,,12,13,14,INDY 17.21,INDY 17.22,,,,8.0,,,,,,,,,,,,ashcherbakov,mzk-vct,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Sep/17 12:56 AM;ashcherbakov;[~mzk-vct] Feel free to re-assign the work to someone else in the Sprint.;;;","19/Sep/17 12:58 AM;ashcherbakov;What is left:
- add pool_root_state to multisig field;
- support proof of non-existence;
- add timestamp into Reply
- add/fix tests 
- migration of state
- [optional] support pool state in client
- [optional] support state proofs in client (instead of f+1 equal replies);;;","03/Oct/17 12:04 AM;ashcherbakov;What is left:
- more tests for state proof (send and get request from one node only)
- check proof of non-existence support;;;","09/Oct/17 6:11 PM;mzk-vct;Supported in node 1.1.158 and plenum 1.1.142;;;","26/Oct/17 1:31 AM;ozheregelya;Client was verified on indy-node versions 1.1.160 - 1.2.182. See details about state proofs testing here: https://docs.google.com/spreadsheets/d/1XzJ6yK1z4em_N-ZY6IMeGxs54x-ar4uYKOYR_x5_CCo/edit#gid=0;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support anchoring of the pool ledger state,INDY-791,20483,19858,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,ashcherbakov,ashcherbakov,29/Aug/17 5:05 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"- We need to know what keys were used for multi-sig;
- Support Anchoring (https://docs.google.com/document/d/1WRkqNqXXi1LoVxZu0C353uR0KRatoQuvrV_UZNDuNcc/edit#) ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyeo7:",,,,,,11,12,13,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/17 12:54 AM;ashcherbakov;PoA:
- Add pool_root_hash to multi-sig (so that MultiSig consists of three values: multi-sig; participants (node names); pool_root_hash)
- Sign not only domain_root_hash, but concatenation of domain_root_hash and pool_root_hash (so that verifier knows that the pool state is valid)
- Store pool_root_hash in multi-sig storage (that is store all three values).
- When verifying, get the pool state according to the provided pool_root_hash, and get the BLS keys corresponded to that state.
- Send both domain_root_hash and pool_root_hash in PrePrepare (multi-sig) and use correct values for verification of multi-sig

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Documentation,INDY-792,20498,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,ashcherbakov,ashcherbakov,29/Aug/17 8:21 PM,19/Dec/18 9:25 PM,28/Oct/23 2:47 AM,,,,documentation,,0,,,,,,"*Story*
Each persona that engages with Indy should have well organized documentation that helps them meet their needs.

Developers:
* Getting started guides somewhere easily searchable by Google
* Reference documentation outside of GitHub

Architects:
* Architecture documentation in GitHub

Open Source Collaborators:
* Project status and process documentation in the Hyperledger Wiki",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-8,,Documentation,To Do,,,,,,,,"1|hzxx0v:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Some nodes appear in both of ""nackNodes"" and ""replyNodes"" in load_test.py output",INDY-793,20511,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,ozheregelya,ozheregelya,29/Aug/17 11:00 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,KellyRetest,,,,"*Steps to Reproduce:*
 1. Set up the pool.
 2. Run load_test.py with any parameters. E.g. 
 python3 load_test.py --clients-list load_test_clients.list -t NYM -c 5 -r 10 --at-once
 3. Look at output file.

*Actual Results:*
 Following rows appear in output:
|signerName|signerId|dest|reqId|transactionType|sentAt|quorumAt|latency|ackNodes|nackNodes|replyNodes|
|Sponsor2|SJ9Akdc6vNkBsNiNhTPEhG|GQCQb3hBsvCaCApFD5Uv7e|1504009656285340|1|1504009656|1504009663|6.984776258|Node6C,Node5C,Node3C|Node4C,Node2C,Node1C|Node3C,Node6C,Node5C,Node4C,Node2C,Node1C|
|Sponsor2|SJ9Akdc6vNkBsNiNhTPEhG|J1DUfRV3HKtYoF9BpE3vkP|1504009656285550|1|1504009656|1504009663|6.985527754|Node6C,Node5C,Node3C|Node4C,Node2C,Node1C|Node3C,Node6C,Node5C,Node4C,Node2C,Node1C|
|Sponsor2|SJ9Akdc6vNkBsNiNhTPEhG|Jpc5AHdSE5kxGeuFW8nNWU|1504009656285720|1|1504009656|1504009663|6.986278534|Node6C,Node5C,Node3C|Node4C,Node2C,Node1C|Node3C,Node6C,Node5C,Node4C,Node2C,Node1C|
|Sponsor2|SJ9Akdc6vNkBsNiNhTPEhG|MrzjcZhCrNsv5XaEs4tbpU|1504009656285890|1|1504009656|1504009663|7.034237146|Node6C,Node5C,Node3C|Node4C,Node2C,Node1C|Node3C,Node6C,Node5C,Node4C,Node2C,Node1C|
|Sponsor2|SJ9Akdc6vNkBsNiNhTPEhG|brNQDNsKpcRcborQGGe1n|1504009656286050|1|1504009656|1504009663|7.0350492|Node6C,Node5C,Node3C|Node4C,Node2C,Node1C|Node3C,Node6C,Node5C,Node4C,Node2C,Node1C|
|Sponsor2|SJ9Akdc6vNkBsNiNhTPEhG|Ba5mxiX544a8ygWkjMxcCc|1504009656286220|1|1504009656|1504009663|7.035830975|Node6C,Node5C,Node3C|Node4C,Node2C,Node1C|Node3C,Node6C,Node5C,Node4C,Node2C,Node1C|
|Sponsor2|SJ9Akdc6vNkBsNiNhTPEhG|HjiriStXqbS7zAY6SaujpZ|1504009656286410|1|1504009656|1504009663|7.036584854|Node6C,Node5C,Node3C|Node4C,Node2C,Node1C|Node3C,Node6C,Node5C,Node4C,Node2C,Node1C|
|Sponsor2|SJ9Akdc6vNkBsNiNhTPEhG|8KUDRCSLbntDtVShGEpGUT|1504009656286590|1|1504009656|1504009663|7.037379503|Node6C,Node5C,Node3C|Node4C,Node2C,Node1C|Node3C,Node6C,Node5C,Node4C,Node2C,Node1C|
|Sponsor2|SJ9Akdc6vNkBsNiNhTPEhG|SSmPQEFfadW3eqprbtAhb6|1504009656286750|1|1504009656|1504009663|7.03812623|Node6C,Node5C,Node3C|Node4C,Node2C,Node1C|Node3C,Node6C,Node5C,Node4C,Node2C,Node1C|
|Sponsor2|SJ9Akdc6vNkBsNiNhTPEhG|PLSFFYsuvjPACsPETawXoN|1504009656286910|1|1504009656|1504009663|7.038893938|Node6C,Node5C,Node3C|Node4C,Node2C,Node1C|Node3C,Node6C,Node5C,Node4C,Node2C,Node1C|

*Expected Results:*
 One node should not reply with nack and reply for one request.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Aug/17 11:03 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11976/Node1.log","29/Aug/17 11:03 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11977/Node2.log","29/Aug/17 11:03 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11978/Node3.log","29/Aug/17 11:03 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11979/Node4.log","29/Aug/17 11:03 PM;ozheregelya;Node5.log;https://jira.hyperledger.org/secure/attachment/11980/Node5.log","29/Aug/17 11:03 PM;ozheregelya;Node6.log;https://jira.hyperledger.org/secure/attachment/11981/Node6.log","29/Aug/17 11:03 PM;ozheregelya;perf_results_5_10_1504009655.csv;https://jira.hyperledger.org/secure/attachment/11975/perf_results_5_10_1504009655.csv",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1b3:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Aug/17 5:52 AM;krw910;[~ozheregelya]
Is this a new issue or has it just not been seen before?
Do the consensus experts believe this is incorrect behavior?
Is it consistently reproducible?
Is it the test or the code being tested?;;;","30/Aug/17 6:32 PM;ozheregelya;[~krw910], I believe that this is not new issue. It was noticed first time in INDY-292:
{quote}On 103th transaction Node1C and Node2C appeared in both ackNodes and nackNodes columns of pref_results spreadsheet: [^perf_results_1_1000_1497994390.csv]
 The rest transactions were failed. After completion of the test cluster does not send NYMs.
{quote}
Then, I thought that this behavior results breaking of the pool. But now I see that I was mistaken. All transactions are written to the ledger independently on appearing of these rows in output file, so I think it is not a critical problem (probably it is problem in load_test.py output, or not a problem at all). I discussed it with our developers and we decided that it will be better to create a ticket and explore this behavior to make sure is this a problem or not.
 This behavior reproduces almost always during sending valid transactions using load_test.py with --at-once.;;;","07/Nov/18 6:44 PM;Derashe;load_test.py is deprecated;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Primary selection possibly failure cases,INDY-794,20512,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,andkononykhin,andkononykhin,30/Aug/17 12:13 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"During work on INDY-463 new more possible failure cases were found. They haven't been reproduced yet but at least they should be checked (seems some of them could be checked only in scope of integration auto-tests in indy-plenum) and then fixed if necessary.

Cases:
 # demote one node when primary is NodeX - make several view changes so the primary is NodeX again - promote demoted node - check that it accepts current primary
 (_expect failure cause currently nodes discards previous primary without checking difference between view numbers_)
 # the same as previous but restart instead of re-promotion
 # do view change(s) - demote one node - restart remaining pool - do some txns - promote previously demoted node - check how it does catch-up: _it has viewNo than restarted remaining pool but less txns in ledger_
 # the same as previous but restart instead of re-promotion
 # do 4 view changes for 4-nodes pool - add new validator - do one more view change #5: _expect primary of the view change #5 will be discarded and one more view change #6 happens cause according to formula primary(viewNo=4, totalNodes=4) = primary(viewNo=5, totalNode=5)_
 # disconnect node from 4-nodes pool - do several view changes until next primary for backup instance points to disconnected node - check what happens: _it seems we will get non-functional backup instance for long cause according to current code in plenum that nodes don't ensure VIEW_CHANGE_DONE from next backup instance primary and won't receive primary disconnected event as it will has already happened and it is monitored for master instance only_",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1199,,,,,,,,"20/Feb/18 10:40 PM;zhigunenko.dsr;case3.7z;https://jira.hyperledger.org/secure/attachment/14640/case3.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzy0m7:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,andkononykhin,krw910,zhigunenko.dsr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Aug/17 5:59 AM;krw910;[~ozheregelya] Please test these scenarios and log any issues you find.;;;","08/Feb/18 12:20 AM;zhigunenko.dsr;h6. Case #1
demote one node when primary is NodeX - make several view changes so the primary is NodeX again - promote demoted node - check that it accepts current primary
 (_expect failure cause currently nodes discards previous primary without checking difference between view numbers_)
*Steps to reproduce:*
1. Sequentially demote and promote NODE for each of 7 node in pool
2. After a full cycle of changing the primary node, send a few nyms
*Actual results:*
* Accident 1:
[If node's promotion requires to increase number of backup of primary node, new backup instance duplicate current primary node|https://jira.hyperledger.org/browse/INDY-1112] -
 reason was found

* Accident 2: 
if send demote command twice, demoted node looks like connected again
{code}
_indy@sandbox> send NODE dest=Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8 data={""alias"":""Node6"", ""services"":[]}_
Sending node request for node DID Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8 by V4SGRU86Z58d6TV7PBUe6f (request id: 1518010476342686)
indyd63811 updated its pool parameters: f 2, totalNodes 7,minNodesToConnect 3, quorums {'view_change': Quorum(5), 'timestamp': Quorum(3), 'election': Quorum(5), 'consistency_proof': Quorum(3), 'bls_signatures': Quorum(5), 'ledger_status': Quorum(4), 'view_change_done': Quorum(5), 'propagate_primary': Quorum(3), 'commit': Quorum(5), 'same_consistency_proof': Quorum(3), 'observer_data': Quorum(3), 'propagate': Quorum(3), 'f': 2, 'reply': Quorum(3), 'checkpoint': Quorum(4), 'prepare': Quorum(4)}
Node request completed Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8
{code}
{color:red}
CONNECTION: 7s7HxzCLzaoikXpJW8eMAmWtTA3XJmEbTaN3J44vaD2X looking for Node6C at 10.0.0.7:9712
CONNECTION: 7s7HxzCLzaoikXpJW8eMAmWtTA3XJmEbTaN3J44vaD2X now connected to Node6C
CATCH-UP: 7s7HxzCLzaoikXpJW8eMAmWtTA3XJmEbTaN3J44vaD2X completed catching up ledger 0, caught up 0 in total
{color}

h6. Case #2
the same as previous but restart instead of re-promotion
*Steps to reproduce:*
1. Sequentially stop and start indy-node service on each of 7 node in pool
2. After a full cycle of changing the primary node, send a few nyms
*Actual results:* {color:green}NYMs successfully sent{color}

h6. Case #3
do view change(s) - demote one node - restart remaining pool - do some txns - promote previously demoted node - check how it does catch-up: _it has viewNo than restarted remaining pool but less txns in ledger_
*Step to reproduce:*
1) Demote one node
2) make some NYM/GET_NYM
3) Simultaneously restart services on all nodes (exclude demoted node)
4) make some NYM/GET_NYM
5) Promote node
*Actual results:* {color:green}CATCH-UP is successful{color}
6) Demote one node
7) make some NYM/GET_NYM
8) Simultaneously restart services on all nodes (include demoted node)
9) make some NYM/GET_NYM
10) Promote node
*Actual results:* {color:green}CATCH-UP is successful{color}

h6. Case #4
the same as previous but restart instead of re-promotion
*Step to reproduce:*
1) Demote one node
2) make some NYM/GET_NYM
3) Simultaneously restart services on all nodes (exclude demoted node)
4) make some NYM/GET_NYM
5) Promote node
*Actual results:* {color:green}CATCH-UP is successful{color}

h6. Case #5
do 4 view changes for 4-nodes pool - add new validator - do one more view change #5: _expect primary of the view change #5 will be discarded and one more view change #6 happens cause according to formula primary(viewNo=4, totalNodes=4) = primary(viewNo=5, totalNode=5)_
*Step to reproduce:*
1. Stop and start indy-node service on node1 - node4 sequentially
2. Add node5 to pool
3. Stop service in current primary node1
*Actual results:* {color:green}viewNo=5 discarded, viewNo=6 is successful{color}

*Step to reproduce:*
4. Restart service on node1
5. demote node5
6. Stop and start indy-node service on node2 - node4 sequentially
*Actual results:* {color:green}Primary changed to node1 with correct viewNO{color}

h6. Case #6
disconnect node from 4-nodes pool - do several view changes until next primary for backup instance points to disconnected node - check what happens: _it seems we will get non-functional backup instance for long cause according to current code in plenum that nodes don't ensure VIEW_CHANGE_DONE from next backup instance primary and won't receive primary disconnected event as it will has already happened and it is monitored for master instance only_
{color:red}Trouble with ""view change"" has been{color} [found|https://jira.hyperledger.org/browse/INDY-1151]
TO TEST: ""view change"" through load script;;;","20/Feb/18 10:22 PM;zhigunenko.dsr;*Environment:*
indy-anoncreds 1.0.32
indy-node 1.3.311
indy-plenum 1.2.250
libindy 1.3.1~399
libindy-crypto 0.2.0
python3-indy-crypto 0.2.0
Docker, 7 nodes

h6.CASE #1
*Steps to reproduce:*
# Demote node1
# Sequentially stop and start _indy-node_ for each of 2..7 node in pool
# After a full cycle of changing the primary node, promote node1

*Actual results:*
{color:green}Promoted node have got actual viewChangeNo{color}

h6.CASE #2
*Steps to reproduce:*
# Stop _indy_node_ on node1
# Sequentially stop and start _indy-node_ for each of 2..7 node in pool
# After a full cycle of changing the primary node, start _indy_node_ on node1

*Actual results:*
{color:green}Node1 have got actual viewChangeNo{color}

h6.CASE #3
*Step to reproduce:*
# make some viewChanges
# demote node1 with current viewNo 7
# Simultaneously stop indy-node on all nodes (exclude demoted node)
# Simultaneously start indy-node on all nodes (exclude demoted node)
# Promote node1

*Actual results:*
{color:red}node1 cannot link with any viewChange from pool, until it reach #8 (more than current viewChange on node1). {color} Allocated into INDY-1199
{code}
2018-02-20 11:23:40,877 | DEBUG    | node.py              (1476) | sendToViewChanger | Node1 sending message to view changer: (INSTANCE_CHANGE{'viewNo': 2, 'reason': 28}, 'Node7')
{code}
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The first transaction is not processed by pool when more 500 tnx are send using load_test.py at once,INDY-795,20513,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,ozheregelya,ozheregelya,30/Aug/17 12:28 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,4Months,KellyRetest,,,,"Steps to Reproduce:
 1. Set up the pool.
 2. Run load_test.py with following parameters:
 python3 load_test.py --clients-list load_test_clients.list -t NYM -c 1 -r 500 --at-once
 3. Wait for completion of the test, look at output file.

Actual Results:
 One transaction is failed.
 The first row in the output file:
|signerName|signerId|dest|reqId|transactionType|sentAt|quorumAt|latency|ackNodes|nackNodes|replyNodes|
|Sponsor1|RRbkXVEr8UZ1Z9RidHmu25|S9yc53gUPZ2E5jZLWjYcWk|1.50401E+15|1|1504008552| |175.433995| | | |

Expected Results:
All transactions should be processed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Aug/17 12:29 AM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/11982/Node1.log","30/Aug/17 12:29 AM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/11983/Node2.log","30/Aug/17 12:29 AM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/11984/Node3.log","30/Aug/17 12:29 AM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/11985/Node4.log","30/Aug/17 12:29 AM;ozheregelya;Node5.log;https://jira.hyperledger.org/secure/attachment/11986/Node5.log","30/Aug/17 12:29 AM;ozheregelya;Node6.log;https://jira.hyperledger.org/secure/attachment/11987/Node6.log","30/Aug/17 12:29 AM;ozheregelya;perf_results_1_500_1504008551.csv;https://jira.hyperledger.org/secure/attachment/11988/perf_results_1_500_1504008551.csv","30/Aug/17 6:49 PM;ozheregelya;perf_results_5_500_1504019490.csv;https://jira.hyperledger.org/secure/attachment/11991/perf_results_5_500_1504019490.csv",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1av:",,,,,,12,,,,,,,,,,,,,,,,,,,,Derashe,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Aug/17 5:54 AM;krw910;[~ozheregelya] is this related to INDY-793 where the missing transaction only happens when the conditions of INDY-793 are seen?;;;","30/Aug/17 5:56 AM;krw910;[~ozheregelya] is this related to INDY-793 where the missing transaction only happens when the conditions of INDY-793 are seen?;;;","30/Aug/17 6:50 PM;ozheregelya;[~krw910], I think that INDY-793 and INDY-795 are different problems. INDY-793 doesn't result missing of transactions. These problems sometimes reproduce together (as you can see in [^perf_results_1_500_1504008551.csv]) because INDY-793 reproduces very often. But sometimes INDY-795 reproduces alone (for instance here: [^perf_results_5_500_1504019490.csv]).;;;","07/Nov/18 6:46 PM;Derashe;load_test.py deprecated. In actual version of load test no such a problem have been noticed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DOC: Request for release notes on Indy-node 1.1.31,INDY-796,20532,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,31/Aug/17 2:54 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,31/Aug/17 12:00 AM,0,Documentation,,,,,"
*Version Information*
indy-plenum= 1.1.24
indy-anoncreds= 1.0.9
indy-node= 1.1.31
sovrin= 1.0.4

*Major Fixes  *

INDY-410 - Stewards can now demote and promote their own nodes
INDY-466 - Fixed problem with timezones for timestamp in transaction
INDY-25 - Limited incoming message size from 128k to 128MB (Temporary solution)
INDY-378 - fixed `send CLAIM_DEF` command
INDY-725 - mask private info in CLI logs/output
INDY-8 - fixes crashes on ubuntu 17.04
INDY-211 - python interpreter is executed in optimized mode
INDY-223 - memory leak fixes
Some minor stability fixes



Changes and Additions


	* New ledger serialization is supported and Leveldb is used as as a storage for all ledgers : msgpack is used for the ledger serialization (both transaction log and merkle tree)
	* 
		*      The new serialization change created changes to the directory structure for the nodes. The directory name changes are located on a node under .sovrin/data/nodes/<node name>/<directories>. The change removes the ledger files as plain text files and creates them as binary files. A new tool was created to view the ledger entries called read_ledger and is described below.

	* Genesis transaction files are renamed adding a _genesis to the end of each file name.
	* 

	* Added the commands to the POOL_UPGRADE to support downgrade and re-installation. However both have issues and should not be used at this time (INDY-735 and INDY-755).
	* The tool read_ledger.py was created to allow access to reading the ledger or getting a count of the transactions. You can run read_ledger as the sovrin user with --h to get a list of commands.
	* Fixes to upgrade procedure (in particular and issue which caused an infinite loop INDY-316)
	* CLI Changes
	* 
		* New CLI command was added to ease the process of rotating a verification key (verkey). The command is `change current key` or 'change current key with seed xxxxx'. 
		* Modified terminology in code, CLI and documentation
		* 
			* Changed 'keyring' to 'wallet'
			* Changed 'link' to 'connection'
			* Changed 'invitation' to 'request'
			* Changed 'identifier' to 'DID'


	* Improvements to log messages
	* Publishing only to repo.sovrin.org
	* 
		* In your sources.list you only need the entry ""deb https://repo.evernym.com/deb xenial stable"".

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyfr3:",,,,,,11,12,,,,,,,,,,,,,,,,,,,krw910,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Aug/17 7:34 AM;TechWritingWhiz;The PDF and HTML version of this are complete and stored in MadCap Flare ready for distribution. The markdown version is also complete. Here is the pull request: [https://github.com/sovrin-foundation/sovrin/pull/19]

 ;;;","01/Sep/17 12:41 AM;TechWritingWhiz;These build numbers were corrected in the document and the pull request [https://github.com/sovrin-foundation/sovrin/pull/19] has been merged. Closing this ticket.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client does not work with the pool after promotion/demotion of nodes,INDY-797,20553,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,,ozheregelya,ozheregelya,31/Aug/17 10:24 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*Case 1:*
 Steps to Reproduce:
 1. Set up the pool of 4 nodes.
 2. Open the CLI.
 Only 1 - 4 nodes are in pool_transactions_sandbox_genesis file:
{code:java}
{""data"":{""alias"":""Node1"",""client_ip"":""10.0.0.2"",""client_port"":9702,""node_ip"":""10.0.0.2"",""node_port"":9701,""services"":[""VALIDATOR""]},""dest"":""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"",""identifier"":""FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4"",""txnId"":""fea82e10e894419fe2bea7d96296a6d46f50f93f9eeda954ec461b2ed2950b62"",""type"":""0""}
{""data"":{""alias"":""Node2"",""client_ip"":""10.0.0.3"",""client_port"":9704,""node_ip"":""10.0.0.3"",""node_port"":9703,""services"":[""VALIDATOR""]},""dest"":""8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb"",""identifier"":""8QhFxKxyaFsJy4CyxeYX34dFH8oWqyBv1P4HLQCsoeLy"",""txnId"":""1ac8aece2a18ced660fef8694b61aac3af08ba875ce3026a160acbc3a3af35fc"",""type"":""0""}
{""data"":{""alias"":""Node3"",""client_ip"":""10.0.0.4"",""client_port"":9706,""node_ip"":""10.0.0.4"",""node_port"":9705,""services"":[""VALIDATOR""]},""dest"":""DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya"",""identifier"":""2yAeV5ftuasWNgQwVYzeHeTuM7LwwNtPR3Zg9N4JiDgF"",""txnId"":""7e9f355dffa78ed24668f0e0e369fd8c224076571c51e2ea8be5f26479edebe4"",""type"":""0""}
{""data"":{""alias"":""Node4"",""client_ip"":""10.0.0.5"",""client_port"":9708,""node_ip"":""10.0.0.5"",""node_port"":9707,""services"":[""VALIDATOR""]},""dest"":""4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA"",""identifier"":""FTE95CVthRtrBnK2PYCBbC9LghTcGwi9Zfi1Gz2dnyNx"",""txnId"":""aa5e817d7cc626170eca175822029339a444eb0ee8f0bd20d3b0b76e566fb008"",""type"":""0""}{code}
3. Using CLI, add 1 more node to the pool.
 4. Exit the CLI.
 5. Open CLI again, connect to test environment.
 6. Try to send NYM.

Actual Results:
 Following message appear in CLI during connection to test:
{code:java}
FiZUBGTj5sXzKtRHbuYVoXr9ePMeUku8hUjwvecHaKTm could not verify catchup reply CATCHUP_REP{'ledgerId': 0, 'consProof': [], 'txns': {'5': {'signature': '514zkpnsiekKieL9FzJwK3vh4Qq3S9tVDmDr3QLeUS1GuoR231Rs2dM575KVosB8yYrqFR8eYUHJhLZ2YMHWq91S', 'reqId': 1504177080495373, 'txnTime': 1504177080, 'data': {'node_port': 9701, 'node_ip': '10.0.0.6', 'alias': 'Node5', 'client_ip': '10.0.0.6', 'services': ['VALIDATOR'], 'client_port': 9702}, 'identifier': 'XhYtvJqezMUKfF6KVNaGmT', 'dest': '4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc', 'type': '0'}}} since Inconsistency: different root hashes for the same tree size
{code}
NYM was not send.

Expected Results:
 NYM should be send, message should not be shown.

*Case 2:*
 Steps to Reproduce:
 0. After steps of Case 1 perform following actions:
 1. Add to Node5 to pool_transactions_sandbox_genesis file.
 2. Open the CLI, try to send NYM.
 => NYM is successfully added.
 3. Demote Node5 using CLI.
 4. Exit the CLI, open it again.
 5. Connect to test, try to send NYM.

Actual Results:
 Following message appear in CLI during connection to test:
{code:java}
3y9Q1EXsVcPS6AGd3Ujtf5kfvZVatjuHKidbhNc5aFyN could not verify catchup reply CATCHUP_REP{'txns': {'6': {'type': '0', 'reqId': 1504185580897602, 'dest': '4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc', 'txnTime': 1504185581, 'identifier': 'V4SGRU86Z58d6TV7PBUe6f', 'signature': '4KotWu6AWYdaQtr1Qani71tZzRPfkrWTaMBb81VC2yPhoNDwUqq7qMitKhBmNhrC4xuusszavhd6nsV7NLwe9v16', 'data': {'alias': 'Node5', 'services': []}}}, 'ledgerId': 0, 'consProof': []} since Inconsistency: different root hashes for the same tree size{code}
Nym was not send.

Expected Results:
 NYM should be send, message should not be shown.

*Additional Information:*
The issue is also reproduces on previous stable version (indy-node=1.0.28).

 Attached files contain nodes logs and .sovrin folder after Case 2.

Possible workaround:
 Change pool_transactions_sandbox_genesis file manually: add according row in case of adding node and remove according row in case of demotion. Or use generate_sovrin_pool_transactions with remaining nodes in -ips list.","Build Info:
stable repo:
  indy-node 1.1.33
  indy-anoncreds 1.0.10
  indy-plenum 1.1.24
  sovrin 1.1.6
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4-5 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,INDY-802,,,,,,,,"31/Aug/17 10:36 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/12001/Node1.log","31/Aug/17 10:36 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/12002/Node2.log","31/Aug/17 10:36 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/12003/Node3.log","31/Aug/17 10:36 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/12004/Node4.log","31/Aug/17 10:36 PM;ozheregelya;Node5.log;https://jira.hyperledger.org/secure/attachment/12005/Node5.log","31/Aug/17 10:36 PM;ozheregelya;sovrin.7z;https://jira.hyperledger.org/secure/attachment/12006/sovrin.7z",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyfrb:",,,,,,12,,,,,,,,,,,,,,,,,,,,ozheregelya,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Sep/17 10:31 PM;spivachuk;Cannot reproduce Case 1 on indy-node 1.1.33 stable (a local pool on Ubuntu 16.04 VM).;;;","02/Sep/17 2:24 AM;ozheregelya;Described behavior was happened because of two reasons:
1. Old pool_transactions_sandbox_genesis file was used. (32-bytes identifiers were specified in signer ID.) This situation can be caused by using client with version before CID/DID changing. These changes were made before MGL, so we assume that real users will not be able to use such genesis file.
2. The pool and client have been working with invalid genesis file because catch up was not happened while starting client. Client and pool ledgers were compared by size and they had the same count of transactions. Comparison of hashes was not happened after that, so, client was able to work with pool using invalid genesis file until first catch up caused by changing of nodes count (adding/demotion/promotion). This problem was discussed with Nikita and Alex and we decided to create new ticket for this with lower priority.;;;","03/Sep/17 8:04 PM;ozheregelya;New ticket for comparison of hashes is INDY-802.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TGB Role should be removed from the code. TGB is not a role.,INDY-798,20561,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,krw910,krw910,31/Aug/17 11:39 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,4Months,,,,,A TGB member is a board member with no specific roles within the Indy code. The TGB role within the code should be removed.,,,,,,,,,,,,,,,,,,,,,IS-504,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzzt93:",,,,,,Ev 18.20,,,,,,,,,,,,,,,,,,,,Derashe,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/18 4:07 AM;ozheregelya;The issue is actual for indy-cli:

 
{code:java}
pool(p1):wallet(wall):did(V4S...e6f):indy> ledger nym help 
Command:
 ledger nym - Send NYM transaction to the Ledger.
Usage:
 ledger nym did=<did-value> [verkey=<verkey-value>] [role=<role-value>]
Parameters are:
 did - DID of new identity
 verkey - (optional) Verification key of new identity
 role - (optional) Role of identity. One of: STEWARD, TRUSTEE, TRUST_ANCHOR, TGB or empty in case of blacklisting NYM
Examples:
 ledger nym did=VsKV7grR1BUE29mG2Fm2kX
 ledger nym did=VsKV7grR1BUE29mG2Fm2kX verkey=GjZWsBLgZCR18aL468JAT7w9CZRiBnpxUPPgyQxh4voa
 ledger nym did=VsKV7grR1BUE29mG2Fm2kX role=TRUSTEE
 ledger nym did=VsKV7grR1BUE29mG2Fm2kX role=
{code}
 

Ticket for indy-cli in IS-504.;;;","09/Oct/18 11:53 PM;Derashe;TGB removed in [https://github.com/hyperledger/indy-node/pull/967|https://github.com/hyperledger/indy-node/pull/967.], need review

[~ashcherbakov];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Transactions missing from config ledger after upgrade,INDY-799,20565,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,mgbailey,mgbailey,01/Sep/17 7:11 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"After upgrading the STN to 1.1.33, the expected transactions are not being posted in the config ledger.  In addition to failed upgrades, I would expect to see upgrade successes.  Successes are not being recorded in the ledger.

The upgrade transaction used is:

send POOL_UPGRADE name=STNUpgrade20170831 version=1.1.33 sha256=e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 action=start schedule=
\{'UZH61eLH3JokEwjMWQoCMwB3PMD6zRBvG6NCv5yVwXz':'2017-08-31T11:05:05.555000-06:00','2MHGDD2XpRJohQzsXu4FAANcmdypfNdpcqRbqnhkQsCq':'2017-08-31T11:05:05.555000-06:00',
'8NZ6tbcPN2NVvf2fVhZWqU11XModNudhbe15JSctCXab':'2017-08-31T11:05:05.555000-06:00','DNuLANU7f1QvW1esN3Sv9Eap9j14QuLiPeYzf28Nub4W':'2017-08-31T11:05:05.555000-06:00',
'HCNuqUoXuK9GXGd2EULPaiMso2pJnxR6fCZpmRYbc7vM':'2017-08-31T11:05:05.555000-06:00','Dh99uW8jSNRBiRQ4JEMpGmJYvzmF35E6ibnmAAf7tbk8':'2017-08-31T11:05:05.555000-06:00',
'EoGRm7eRADtHJRThMCrBXMUM2FpPRML19tNxDAG8YTP8':'2017-08-31T11:05:05.555000-06:00','2VMDBjJCqxEonfaTcwvyBy5J473H2u65ZqQhPHx47iDG':'2017-08-31T11:05:05.555000-06:00'}
 timeout=20 force=True

It appears that one node failed to upgrade properly.  The others upgraded fine.  After the upgrade, using ""sudo read_ledger --type config"" command, I get:

[1,\{""action"":""start"",""force"":false,""identifier"":""6feBTywcmJUriqqnGc1zSJ"",""justification"":null,""name"":""STNUpgrade2"",""reqId"":1501781257520465,""schedule"":\{""2MHGDD2XpRJohQzsXu4FAANcmdypfNdpcqRbqnhkQsCq"":""2017-08-03T17:30:33.555000+00:00"",""8NZ6tbcPN2NVvf2fVhZWqU11XModNudhbe15JSctCXab"":""2017-08-03T17:35:33.555000+00:00"",""DNuLANU7f1QvW1esN3Sv9Eap9j14QuLiPeYzf28Nub4W"":""2017-08-03T17:40:33.555000+00:00"",""Dh99uW8jSNRBiRQ4JEMpGmJYvzmF35E6ibnmAAf7tbk8"":""2017-08-03T17:50:33.555000+00:00"",""EoGRm7eRADtHJRThMCrBXMUM2FpPRML19tNxDAG8YTP8"":""2017-08-03T17:55:33.555000+00:00"",""HCNuqUoXuK9GXGd2EULPaiMso2pJnxR6fCZpmRYbc7vM"":""2017-08-03T17:45:33.555000+00:00"",""UZH61eLH3JokEwjMWQoCMwB3PMD6zRBvG6NCv5yVwXz"":""2017-08-03T18:00:33.555000+00:00""},""sha256"":""e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"",""signature"":""4h7mGrZE2JzjLY39ifnhNcyLpKbzXe1RgXrPmmqCJopEUPv6vsSmbk9p2XMkuZ4oij6kAWak6mpqpYCedv3gKJq9"",""timeout"":10,""txnTime"":1501781257,""type"":""109"",""version"":""1.0.3""}]
[2,\{""action"":""start"",""force"":true,""identifier"":""6feBTywcmJUriqqnGc1zSJ"",""justification"":null,""name"":""STNUpgrade20170831"",""reqId"":1504197853027234,""schedule"":\{""2MHGDD2XpRJohQzsXu4FAANcmdypfNdpcqRbqnhkQsCq"":""2017-08-31T11:05:05.555000-06:00"",""2VMDBjJCqxEonfaTcwvyBy5J473H2u65ZqQhPHx47iDG"":""2017-08-31T11:05:05.555000-06:00"",""8NZ6tbcPN2NVvf2fVhZWqU11XModNudhbe15JSctCXab"":""2017-08-31T11:05:05.555000-06:00"",""DNuLANU7f1QvW1esN3Sv9Eap9j14QuLiPeYzf28Nub4W"":""2017-08-31T11:05:05.555000-06:00"",""Dh99uW8jSNRBiRQ4JEMpGmJYvzmF35E6ibnmAAf7tbk8"":""2017-08-31T11:05:05.555000-06:00"",""EoGRm7eRADtHJRThMCrBXMUM2FpPRML19tNxDAG8YTP8"":""2017-08-31T11:05:05.555000-06:00"",""HCNuqUoXuK9GXGd2EULPaiMso2pJnxR6fCZpmRYbc7vM"":""2017-08-31T11:05:05.555000-06:00"",""UZH61eLH3JokEwjMWQoCMwB3PMD6zRBvG6NCv5yVwXz"":""2017-08-31T11:05:05.555000-06:00""},""sha256"":""e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"",""signature"":""rmQirALnJJw6ziQa8zchH4mCzB3xFZN129HxLQ13acsJwcuvZs5BJXR952zdtNcngiHe7bRdNhAp6cwsDnHUgrK"",""timeout"":20,""txnTime"":1504197853,""type"":""109"",""version"":""1.1.33""}]
[3,\{""data"":\{""action"":""fail"",""version"":""1.1.33""},""identifier"":""2VMDBjJCqxEonfaTcwvyBy5J473H2u65ZqQhPHx47iDG"",""reqId"":1504199153876348,""signature"":""27w2iRrT34AUQcmbAdPhhoPvJ7iMMN2S3VkDBCjDHdsrJUcwaC3bhX8fD3Rd9SHXWKdgcw2oYJNFEXzVNisxX4wz"",""txnTime"":1504199195,""type"":""110""}]

In previous versions of sovrin, both successes and failures to upgrade were recorded on the config ledger.  I would expect this to remain the case.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx0wf:",,,,,,12,13,14,INDY 17.21,INDY 17.22,INDY 17.23,INDY 17.24: Node Perf,,,,,,,,,,,,,,ashcherbakov,krw910,mgbailey,mzk-vct,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/17 5:46 AM;krw910;We want to see which nodes succeeded and which nodes failed.;;;","07/Nov/17 6:52 PM;mzk-vct;[~krw910] Is there corresponding logs? 
Also there are only three records, but eight nodes as I see. 
Was pool working well after upgrade despite this node failed upgrade?;;;","08/Nov/17 4:22 AM;mgbailey;[~mzk-vct] our nodes do not retain logs that far back.

I suspect that this is due to force=true, with all nodes set to upgrade simultaneously, which was required for this upgrade (and others).  It is probable that as the nodes came up, they did not have consensus, and the transaction was not written to the config ledger.;;;","15/Nov/17 5:07 PM;ashcherbakov;[~mgbailey]

 - If we send POOL_UPGRADE with force=true, then there is a chance that NODE_UPGRADE with IN_PROGRESS action will not be written to the ledger since all nodes in the pool are restarted at the same time, and the txn is getting lost and we have no consensus.
 - After Node is restarted, it checked whether we had 1) START action in Upgrade log and 2) NODE_UPGRADE with IN_PROGRESS action. If so, it sent Upgrade SUCCEESS or FAIL (depending on whether the current version equals to the expected one).
 - In the situation with forced POOL_UPGRADE we didn't have IN_PROGRESS txn, so SUCCESS/FAIL NODE_UPGRADE txns may be not sent and written to the ledger
 - It look like it's sufficient to check START action in Upgrade log only. If we have it, we send NODE_UPGRADE.
;;;","16/Nov/17 10:00 PM;ashcherbakov;PR: https://github.com/hyperledger/indy-node/pull/452;;;","17/Nov/17 11:49 PM;ashcherbakov;Build: 1.2.213;;;","04/Dec/17 8:35 PM;ozheregelya;Version Info:
indy-node 1.2.50 (RC)

Steps to Validate:
 # Perform successful force upgrade with the same date for all nodes.
 # Run read_ledger --type config command, check that all actions are written.
 # Perform force upgrade with some failed nodes.
 # Run read_ledger --type config command, check that all actions are written.
 # Perform not force upgrade.
 # Run read_ledger --type config command, check that all actions are written and that nothing were broken.

Actual Results:

All actions are written, upgrade work without any issues.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin doesn't log status of submitted transactions at INFO level,INDY-800,20566,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,mgbailey,mgbailey,01/Sep/17 7:50 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"This is a change in behavior in 1.1.33.

I submitted a transaction to the validator pool:
{code:none}
sovrin@test> send NYM dest=TKqYL5sMd7xNAuCxGg36Wk verkey=~MvD957ZepR26ZjPx1gYmTZ
Adding nym TKqYL5sMd7xNAuCxGg36Wk
Nym TKqYL5sMd7xNAuCxGg36Wk added
{code}
The transaction was successful and the NYM is on the ledger:
{code:none}
ubuntu@singapore:~$ sudo read_ledger --type domain | grep TKqYL5sMd7xNAuCxGg36Wk
[23,{""dest"":""TKqYL5sMd7xNAuCxGg36Wk"",""identifier"":""6feBTywcmJUriqqnGc1zSJ"",""reqId"":1504213515840157,""signature"":""3TpgWXjt9zsUSSrPm8mJZs1MCAtQc5iiRuJmtT7hbPFoSTLRXCWupQcNMrSAhdj8KEKXScNyLN5WD4CbS28NXjv3"",""txnTime"":1504213514,""type"":""1"",""verkey"":""~MvD957ZepR26ZjPx1gYmTZ""}]
{code}
However, when looking at the logs on the validators at the default INFO level, there is no indication that anything occurred.

All transactions should be have log messages at the INFO level in the validator logs with for at least the following:
 # Submission
 # Status, as the submission proceeds through major stages
 # Success (written to ledger) or failure (not written to ledger)
 ## When failure occurs, the message should be at the FAIL or WARNING level, and should contain the reason for the failure.

 ","STN, newly upgraded to 1.1.33.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Sep/17 11:51 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/12082/Screenshot.PNG","01/Sep/17 7:50 AM;mgbailey;singapore_log.tgz;https://jira.hyperledger.org/secure/attachment/12008/singapore_log.tgz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyf6f:",,,,,,12,,,,,,,,,,,,,,,,,,,,andkononykhin,krw910,mgbailey,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/17 5:53 AM;krw910;After talking with Mike he needs the PROPOGATE and COMMIT information listed as INFO in the logs. On the commits we need to know if the commit succeeded or failed. If it failed to write we need some error in the logs showing why. ;;;","11/Sep/17 10:48 PM;andkononykhin;Task is done, changes are in master (1.1.125):
 [https://github.com/hyperledger/indy-plenum/pull/376]

How to test:
 * install plenum master 1.1.125 (available from +master-latest+ component in apt repo)
 * make some interactions with pool performing some set requests  from cli (e.g. as in description)
 * check that  txn states are logged in nodes' logs for valid requests and ids of original client requests are presented
 ** PROPAGATE - INFO message _propagating.*request.*from client_
 ** ORDERED - INFO message _ordered batch request_
 ** COMMIT - INFO message _committed batch request_
 * for invalid request (e.g. non-authorized new steward NYM requests):
 ** DISCARDED - WARNING message _encountered exception.*while processing.*will reject_
 * for failed message writing (not sure how to emulate that, as an option - move ledger files before  txn sending):

 * 
 ** FAILED COMMIT - WARNING message _commit failed for batch request_;;;","12/Sep/17 9:12 PM;VladimirWork;Latest indy-node depends on 1.1.123 plenum, we should rebuild indy-node for 1.1.125 plenum to test this ticket.;;;","12/Sep/17 10:18 PM;andkononykhin;[~VladimirWork] Indy-node 1.1.134 is available in master, it is linked with plenum 1.1.127.;;;","13/Sep/17 6:27 PM;VladimirWork;Build Info:
indy-node 1.1.134

Actual Results:
- PROPAGATE -> ORDER -> COMMIT *info* messages for valid requests
- DISCARD *info* messages for invalid client-to-node requests
- DISCARD / FAILED *warning* messages for invalid node-to-node requests;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[POOL_UPGRADE] Sovrin logs are insufficient for failed upgrade,INDY-801,20577,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,mgbailey,mgbailey,02/Sep/17 12:46 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,should,,,,,"An upgrade of the STN was performed via ledger.  One of the nodes, owned by an external steward, failed to upgrade.  There is a single-line entry in the sovrin log on that node stating that the upgrade failed, with no other explanation:
{quote}2017-08-31 17:05:04,843 | INFO | upgrader.py ( 369) | _callUpgradeAgent | 2VMDBjJCqxEonfaTcwvyBy5J473H2u65ZqQhPHx47iDG's upgrader calling agent for upgrade
2017-08-31 17:05:49,672 | INFO | log.py ( 79) | setupRaet | Setting RAET log level 2
2017-08-31 17:05:52,101 | INFO | plugin_loader.py ( 116) | _load | plugin FirebaseStatsConsumer successfully loaded from module plugin_firebase_stats_consumer
2017-08-31 17:05:52,102 | INFO | replica.py ( 300) | h | icenode:0 set watermarks as 0 300
2017-08-31 17:05:52,102 | DISPLAY | node.py (1034) | addReplica | icenode added replica icenode:0 to instance 0 (master)
2017-08-31 17:05:52,102 | INFO | replica.py ( 300) | h | icenode:1 set watermarks as 0 300
2017-08-31 17:05:52,102 | DISPLAY | node.py (1034) | addReplica | icenode added replica icenode:1 to instance 1 (backup)
2017-08-31 17:05:52,103 | INFO | replica.py ( 300) | h | icenode:2 set watermarks as 0 300
2017-08-31 17:05:52,103 | DISPLAY | node.py (1034) | addReplica | icenode added replica icenode:2 to instance 2 (backup)
*2017-08-31 17:05:52,156 | ERROR | upgrader.py ( 109) | __init__ | Failed to upgrade node 'icenode' to version 1.1.33*
2017-08-31 17:05:52,156 | INFO | node.py (2408) | initStateFromLedger | icenode found state to be empty, recreating from ledger
2017-08-31 17:05:52,157 | INFO | zstack.py ( 312) | start | icenode starting with restricted as True and reSetupAuth as True
2017-08-31 17:05:52,158 | INFO | stacks.py ( 76) | start | icenode listening for other nodes at 0.0.0.0:9791
2017-08-31 17:05:52,159 | INFO | zstack.py ( 312) | start | icenodeC starting with restricted as False and reSetupAuth as True
2017-08-31 17:05:52,159 | INFO | node.py ( 594) | start | icenode first time running...
2017-08-31 17:05:52,163 | INFO | zstack.py ( 580) | connect | icenode looking for england at 52.56.191.9:9701
2017-08-31 17:05:52,165 | INFO | zstack.py ( 580) | connect | icenode looking for singapore at 13.228.62.7:9701
2017-08-31 17:05:52,166 | INFO | zstack.py ( 580) | connect | icenode looking for brazil at 54.233.203.241:9701
{quote}
A reason for the failure should be included as well.  A message instructing the admin to look in the syslog for more detail would also be appropriate. ","STN, running 1.0.28, being upgraded to 1.1.33",,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1078,,,,,,,,"15/Nov/17 12:04 AM;VladimirWork;upgrades_failed_and_cancelled.PNG;https://jira.hyperledger.org/secure/attachment/13336/upgrades_failed_and_cancelled.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzympb:",,,,,,14,INDY 17.21,INDY 17.22,INDY 17.23,,,,,,,,,,,,,,,,,krw910,mgbailey,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Sep/17 7:00 AM;krw910;I recently saw this error message as well which is not helpful.
Cancelling upgrade of node 'korea' to version 1.1.35 *due to some reason*;;;","03/Nov/17 5:41 PM;mzk-vct;[~krw910] ""some reason"" is default value which is used if no comment specified in node upgrade request which cancels upgrade.
The reason can be specified using optional 'justification' field.;;;","03/Nov/17 5:44 PM;mzk-vct;[~krw910] looks like 'justification' is not supported by client.
https://jira.hyperledger.org/browse/INDY-381

Also, do you think that it is better to make this parameter required rather than optional?;;;","03/Nov/17 8:10 PM;mzk-vct;[~krw910] I prepared pull request which makes messages more verbose and guides to check syslog if reason is external.
Also I replaced ""some reason"" by ""cancellation reason not specified"".
https://github.com/hyperledger/indy-node/pull/432
;;;","15/Nov/17 12:04 AM;VladimirWork;Build Info:
indy-node 1.2.209

Steps to Validate:
1. Perform pool upgrade to nonexistent version.
2. Schedule pool upgrade and cancel it.

Actual Results:
1:
{quote}ERROR    | upgrader.py          ( 512) | _upgrade_failed | Node Node1 failed upgrade 1510660724360331 to version 1.2.210 scheduled on 2017-11-13 16:00:00.258870+00:00 because of unknown reason
ERROR    | upgrader.py          ( 514) | _upgrade_failed | This problem may have external reasons, check syslog for more information{quote}

2:
{quote}INFO     | upgrader.py          ( 401) | _cancelScheduledUpgrade | Cancelling upgrade 151066950198533410 of node Node1 to version 1.2.211 scheduled on 2017-11-14 14:30:00.258870+00:00, cancellation reason not specified
INFO     | upgrader.py          ( 336) | handleUpgradeTxn | Node 'Node1' cancels upgrade to 1.2.211{quote}

Additional Info:
Justification parameter (for the 2nd case) will be implemented in scope of INDY-381.

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Client] Hashes are not compared during first connection to the pool if ledgers have the same size,INDY-802,20588,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,,ozheregelya,ozheregelya,03/Sep/17 8:01 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Steps to Reproduce:
1. Set up the pool of 4 nodes.
2. Put to the .sovrin on client machine following file: 
(identifiers contain old CIDs instead of currently used DIDs)
{code:java}
{""data"":{""alias"":""Node1"",""client_ip"":""10.0.0.2"",""client_port"":9702,""node_ip"":""10.0.0.2"",""node_port"":9701,""services"":[""VALIDATOR""]},""dest"":""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"",""identifier"":""FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4"",""txnId"":""fea82e10e894419fe2bea7d96296a6d46f50f93f9eeda954ec461b2ed2950b62"",""type"":""0""}
{""data"":{""alias"":""Node2"",""client_ip"":""10.0.0.3"",""client_port"":9704,""node_ip"":""10.0.0.3"",""node_port"":9703,""services"":[""VALIDATOR""]},""dest"":""8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb"",""identifier"":""8QhFxKxyaFsJy4CyxeYX34dFH8oWqyBv1P4HLQCsoeLy"",""txnId"":""1ac8aece2a18ced660fef8694b61aac3af08ba875ce3026a160acbc3a3af35fc"",""type"":""0""}
{""data"":{""alias"":""Node3"",""client_ip"":""10.0.0.4"",""client_port"":9706,""node_ip"":""10.0.0.4"",""node_port"":9705,""services"":[""VALIDATOR""]},""dest"":""DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya"",""identifier"":""2yAeV5ftuasWNgQwVYzeHeTuM7LwwNtPR3Zg9N4JiDgF"",""txnId"":""7e9f355dffa78ed24668f0e0e369fd8c224076571c51e2ea8be5f26479edebe4"",""type"":""0""}
{""data"":{""alias"":""Node4"",""client_ip"":""10.0.0.5"",""client_port"":9708,""node_ip"":""10.0.0.5"",""node_port"":9707,""services"":[""VALIDATOR""]},""dest"":""4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA"",""identifier"":""FTE95CVthRtrBnK2PYCBbC9LghTcGwi9Zfi1Gz2dnyNx"",""txnId"":""aa5e817d7cc626170eca175822029339a444eb0ee8f0bd20d3b0b76e566fb008"",""type"":""0""}{code}
3. Open the CLI, send NYM to check that client works with the pool.
=> NYM is successfully send.
4. Using CLI, add 1 more node to the pool, exit the CLI.
5. Open CLI again, connect to test environment.
=> Catch up was started, following message appear in CLI during connection to test:
{code:java}
FiZUBGTj5sXzKtRHbuYVoXr9ePMeUku8hUjwvecHaKTm could not verify catchup reply CATCHUP_REP{'ledgerId': 0, 'consProof': [], 'txns': {'5': {'signature': '514zkpnsiekKieL9FzJwK3vh4Qq3S9tVDmDr3QLeUS1GuoR231Rs2dM575KVosB8yYrqFR8eYUHJhLZ2YMHWq91S', 'reqId': 1504177080495373, 'txnTime': 1504177080, 'data': {'node_port': 9701, 'node_ip': '10.0.0.6', 'alias': 'Node5', 'client_ip': '10.0.0.6', 'services': ['VALIDATOR'], 'client_port': 9702}, 'identifier': 'XhYtvJqezMUKfF6KVNaGmT', 'dest': '4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc', 'type': '0'}}} since Inconsistency: different root hashes for the same tree size
{code}
 Actual Results:
Catch up is happened only when ledger sizes are different.

Expected Results:
Catch up should also happen when ledger sizes are the same, but hashes are different.","Build Info:
 (stable repo)
   indy-node 1.1.33
   indy-anoncreds 1.0.10
   indy-plenum 1.1.24
   sovrin 1.1.6
 OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4+1 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,INDY-797,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1n3:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:46 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
After demotion 2 of the 4 nodes pool is still sending transactions,INDY-803,20589,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ozheregelya,ozheregelya,03/Sep/17 10:02 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Steps to Reproduce:
1. Set up the pool of 4 nodes. (f=1)
2. Demote one node by sending
send NODE dest=4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA data=\{'alias': 'Node4', 'services': []}
3. Send NYM to check consensus.
=> NYM is successfully send.
4. Demote one more node by sending
send NODE dest=DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya data=\{'alias': 'Node3', 'services': []}
=> f becomes 0.
5. Send NYM to check consensus.
=> NYM is successfully send.
6. Demote one more node by sending
send NODE dest=8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb data=\{'alias': 'Node2', 'services': []}
7. Send NYM to check consensus.
=> Nym was not send.

Actual Results:
Pool still sends transactions when there were only 2 nodes.

Expected Results:
Minimal f value should not be less than 1, minimal count of active nodes for sending transactions should be 3.","Build Info:
  indy-node 1.1.130
  indy-anoncreds 1.1.25
  indy-plenum 1.1.121
  sovrin 1.1.26
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 4 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/17 10:18 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/12014/Node1.log","03/Sep/17 10:18 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/12015/Node2.log","03/Sep/17 10:18 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/12016/Node3.log","03/Sep/17 10:18 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/12017/Node4.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzx1cv:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 12:28 AM;Derashe;[~ashcherbakov] This case seems to be true, even two nodes can write txns and give a reply. But probably this is expected, because f = 0 and we don't guarantee that pool can sustain suspicious node;;;","10/Oct/18 5:41 PM;Derashe;This is expected;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool doesn't come back to consensus,INDY-804,20591,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,VladimirWork,VladimirWork,04/Sep/17 7:09 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Build Info:
indy-node 1.1.33 (stable)
indy-node 1.1.130 (master)

Overview:
Pool doesn't come back to consensus.

Preconditions:
Pool of 6 nodes is installed.

Steps to Reproduce:
{color:#d04437}0. Login as Trustee -> send NYM.{color}
1. Stop Node6 -> send NYM.
2. Stop Node5 -> send NYM.
3. Start Node6 -> send NYM.
4. Start Node5 -> send NYM.

Actual Results:
Pool doesn't come back to consensus after Step 3. NYMs in Steps 3,4 are not written to the ledger.

Expected Results:
Pool should come back to consensus after Step 3. NYMs in Steps 3,4 should be sent successfully.",,,,,,,,,,,,,,,,,,,,,,,INDY-334,INDY-786,INDY-760,,INDY-849,,,,,,,,"04/Sep/17 7:09 PM;VladimirWork;Node5_stable.txt;https://jira.hyperledger.org/secure/attachment/12022/Node5_stable.txt","04/Sep/17 7:09 PM;VladimirWork;Node6_stable.txt;https://jira.hyperledger.org/secure/attachment/12021/Node6_stable.txt","13/Sep/17 11:50 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/12103/Screenshot.PNG","04/Sep/17 10:10 PM;VladimirWork;case_without_step_0.PNG;https://jira.hyperledger.org/secure/attachment/12024/case_without_step_0.PNG","04/Sep/17 10:10 PM;VladimirWork;first_rc_4.PNG;https://jira.hyperledger.org/secure/attachment/12025/first_rc_4.PNG","04/Sep/17 10:10 PM;VladimirWork;first_rc_6.PNG;https://jira.hyperledger.org/secure/attachment/12026/first_rc_6.PNG","04/Sep/17 7:06 PM;VladimirWork;stable.PNG;https://jira.hyperledger.org/secure/attachment/12023/stable.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyf5z:",,,,,,12,,,,,,,,,,,,,,,,,,,,andrey.goncharov,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/17 7:13 PM;mzk-vct;This is probably the same problem as [INDY-334|https://jira.hyperledger.org/browse/INDY-334]
;;;","04/Sep/17 10:11 PM;VladimirWork;Actually, now we have the next:
Current stable pool (and master) with *4* or *6* nodes comes back to consensus *if we don't perform Step 0*. !case_without_step_0.PNG|thumbnail! 
RC 1.1.30 (08/28/2017) pool with *4* or *6* nodes comes back to consensus in the same cases.  !first_rc_4.PNG|thumbnail!  !first_rc_6.PNG|thumbnail! 

So the amount of transactions written before the pool loses consensus matters.

;;;","12/Sep/17 9:50 PM;andrey.goncharov;Problem reason:
 * the protocol does not originally support this functionality

Fix:
 * Added requesting missing preprepares and prepares

Merged Into:
 * indy-node / master 1.1.134 ([https://github.com/hyperledger/indy-node/commit/58d6b4ed6fe3e67384f0cf4e9aee53b1ef75fec2)]
 * indy-plenum / master 1.1.127 (https://github.com/hyperledger/indy-plenum/commit/24990f6af9bfc0eaab44111bb6266d82792c7911);;;","13/Sep/17 11:50 PM;VladimirWork;Build Info:
indy-node 1.1.136

Steps to Validate:
0. Login as Trustee -> send NYM.
1. Stop Node6 -> send NYM.
2. Stop Node5 -> send NYM.
3. Start Node6 -> send NYM.
4. Start Node5 -> send NYM.

Actual Results:
Pool comes back to consensus after Step 3. NYMs in Steps 3,4 are sent successfully. !Screenshot.PNG|thumbnail! 

Additional Info:
Also it checked for different pool sizes.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client and node config parameter MSG_LEN_LIMIT mismatch,INDY-805,20595,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,ozheregelya,dsurnin,dsurnin,04/Sep/17 9:29 PM,15/Jan/18 12:48 PM,28/Oct/23 2:47 AM,,,,,,0,,,,,,For the moment parameter MSG_LEN_LIMIT is stored in config. In case client and node are run on different machines the configs are different. If node's MSG_LEN_LIMIT is smaller than client's MSG_LEN_LIMIT it is possible that client can send big txn but node *silently ignore* it and client does not receive any response - just wait. It leads to crash on exit since connection still opened.,,,,,,,,,,,,,,,,,,,,,,,INDY-25,INDY-765,INDY-698,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx1m7:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/17 9:39 PM;mzk-vct;When [INDY-698|https://jira.hyperledger.org/browse/INDY-698] is done this one may become irrelevant;;;","15/Jan/18 12:48 PM;krw910;[~ozheregelya] Can you keep track of this issue and check it once INDY-698 has been addressed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Under load an earlier stopped node launch fails with KeyError in KeyValueStorageLeveldb,INDY-806,20599,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,spivachuk,spivachuk,05/Sep/17 8:26 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,GA-0,Stability,,,,"*Build Info:*
* indy-node master 1.0.113

*Overview:*
* Under load one node of a pool with 4 nodes was stopped and after some period started. This node successfully started up and performed catch-up. After some time this node raised suspicions on all other nodes in the pool about Pre-Prepare messages have incorrect state trie roots and sent Instance Change messages due to this. Later this node was again stopped and after some period started. This time its startup was failed with KeyError raised from KeyValueStorageLeveldb and its restart was scheduled. The next startup was again failed with the same error and the node restart was again scheduled and this process was repeated multiple times cyclically.

*Performed steps and results:*
# Deploy a pool with 4 nodes in Docker.
# Start a CLI in Docker and execute: {{connect test}}
[ CLI reports that it has been connected to all 4 nodes. ]
# Execute on Node4: {{read_ledger --type=domain --count}}
[ The script reports the following count of transactions in the domain ledger: {{15}} ]
# Copy the directory {{indy-node/scrips}} to Node1 and Node2.
# Run and wait for completion on Node1: {{python3 add_keys.py Steward1 000000000000000000000000Steward1}}
# Execute on Node4: {{read_ledger --type=domain --count}}
[ The script reports the following count of transactions in the domain ledger: {{215}} ]
# Run on Node1: {{python3 load_test.py -c 10 -r 1000}}
# Run on Node2: {{python3 load_test.py -c 10 -r 1000}}
# Check whether the count of transactions in the domain ledger is growing, using the following command on Node4: {{read_ledger --type=domain --count}}
[ The count of transactions in the domain ledger is growing. ]
# Stop the node service on Node3: {{systemctl stop sovrin-node}}
[ CLI reports that it has been disconnected from Node3. ]
# Check whether the count of transactions in the domain ledger is growing, using the following command on Node4: {{read_ledger --type=domain --count}}
[ The count of transactions in the domain ledger is growing. ]
# After some period start the node service on Node3: {{systemctl start sovrin-node}}
[ CLI reports that it has been connected to Node3. ]
# Wait for Node3 completes catch-up (check for corresponding messages in the log).
# Check whether the count of transactions in the domain ledger is growing, using the following command on Node4: {{read_ledger --type=domain --count}}
[ The count of transactions in the domain ledger is growing. ]
# Check Node3 log for unexpected messages.
{color:#d04437}*Actual results:*{color}
At some moment Node3 reports in its log for each other node in the pool:
{{Node3 raised suspicion on node Node<X> for Pre-Prepare message has incorrect state trie root; suspicion code is 21}}
{{VIEW CHANGE: Node3 sent instance change since suspicion code 21}}
{color:#14892c}*Expected results:*{color}
No messages about raised suspicions appear in Node3 log.
# Stop the node service on Node3: {{systemctl stop sovrin-node}}
[ CLI reports that it has been disconnected from Node3. ]
# Check whether the count of transactions in the domain ledger is growing, using the following command on Node4: {{read_ledger --type=domain --count}}
[ The count of transactions in the domain ledger is growing. ]
# After some period start the node service on Node3: {{systemctl start sovrin-node}}
{color:#d04437}*Actual results:*{color}
CLI does not report that it has been connected to Node3.
In systemd journal on Node3 (view using {{journalctl -ex}}) it can be viewed that the node service fails with KeyError in KeyValueStorageLeveldb on startup and is restarted in cycles.
{color:#14892c}*Expected results:*{color}
CLI reports that it has been connected to Node3.

See the attachments for details.",,,,,,,,,,,,,,,,,,,,,,,INDY-475,,,,,,,,,,,,"05/Sep/17 8:26 PM;spivachuk;Node1.log;https://jira.hyperledger.org/secure/attachment/12035/Node1.log","05/Sep/17 8:26 PM;spivachuk;Node1_load_test_results.txt;https://jira.hyperledger.org/secure/attachment/12034/Node1_load_test_results.txt","05/Sep/17 8:26 PM;spivachuk;Node1_perf_results_10_1000.csv;https://jira.hyperledger.org/secure/attachment/12033/Node1_perf_results_10_1000.csv","05/Sep/17 8:26 PM;spivachuk;Node2.log;https://jira.hyperledger.org/secure/attachment/12032/Node2.log","05/Sep/17 8:26 PM;spivachuk;Node2_load_test_results.txt;https://jira.hyperledger.org/secure/attachment/12031/Node2_load_test_results.txt","05/Sep/17 8:26 PM;spivachuk;Node2_perf_results_10_1000.csv;https://jira.hyperledger.org/secure/attachment/12030/Node2_perf_results_10_1000.csv","05/Sep/17 8:26 PM;spivachuk;Node3.log;https://jira.hyperledger.org/secure/attachment/12029/Node3.log","05/Sep/17 8:26 PM;spivachuk;Node3_msgs_from_systemd_journal.txt;https://jira.hyperledger.org/secure/attachment/12028/Node3_msgs_from_systemd_journal.txt","05/Sep/17 8:26 PM;spivachuk;Node4.log;https://jira.hyperledger.org/secure/attachment/12027/Node4.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzz3v3:",,,,,,18.07 Stability & Monitoring,,,,,,,,,,,,,,,,,,,,ashcherbakov,SeanBohan_Sovrin,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jan/18 7:27 AM;SeanBohan_Sovrin;[~ashcherbakov] - is this the same issue duplicate transaction issue MikeB had (1.1.43)?;;;","17/Jan/18 5:40 PM;ashcherbakov;I think this is a different issue.;;;","27/Mar/18 6:18 PM;ashcherbakov;I think it's already fixed, please re-test.;;;","11/Apr/18 9:16 PM;VladimirWork;The issue is not reproducing on 1.3.357 master.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
reset_client completely empties the .sovrin directory,INDY-807,20610,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,Derashe,mgbailey,mgbailey,06/Sep/17 1:42 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,1.6.79,,,0,TShirt_S,,,,,"After upgrading to indy-node 1.1.33, running the ""reset_client"" command results in a completely empty .sovrin directory.  All files, including the genesis files, are deleted.  This appears to be due to renaming of the standard files in this directory.  The file names need to be updated in the ""keepFilesInClientReset"" struct in the script_helper.py file.

*Acceptance Criteria*
* The script should either be fixed or removed.",indy-node 1.1.33,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzzx4v:",,,,,,Ev 18.22,,,,,,,,,,,,,,,,,,,,Derashe,esplinr,mgbailey,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/18 5:20 AM;esplinr;reset_client should no longer be used. We should remove the script and test cases.;;;","06/Nov/18 4:07 PM;Derashe;PR: https://github.com/hyperledger/indy-node/pull/1010;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UPGRADE: Unable to manually upgrade a node with a migration script,INDY-808,20612,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,krw910,krw910,06/Sep/17 2:25 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"I have a node that did not upgrade successfully with a POOL_UPGRADE. I am running through the steps of upgrading that node manually along with running the migration script.

Current build is Stable version
 indy-plenum=1.0.21
 indy-anoncreds=1.0.8
 indy-node=1.0.28
 sovrin=1.0.3

Upgrading to Stable version
 indy-plenum=1.1.24
 indy-anoncreds=1.0.10
 indy-node=1.1.33
 sovrin=1.1.6

*I receive the following error:*
 {color:#d04437}ImportError: No module named 'data/migrations'{color}

*Steps*
 I have 4 nodes in my pool and I am upgrading them manually to simulate an issue where not all the nodes upgraded with a pool_upgrade command.

{color:#205081}Run the following commands on the node:{color}
 sudo apt update
 sudo systemctl stop sovrin-node
 sudo systemctl stop sovrin-node-control
 sudo apt-get install sovrin -y
 sudo apt-get install indy-node -y

{color:#205081}After upgrade of node run the following:{color}
 sudo python3
 from sovrin_node.utils.migration_tool import migrate
 migrate(""1.0.28"",""1.1.33"",10)

*{color:#d04437}Error{color}*
{code:java}
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/utils/migration_tool.py"", line 52, in migrate
    migration_scripts = _get_migration_scripts(current_platform)
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/utils/migration_tool.py"", line 73, in _get_migration_scripts
    '.'.join([SCRIPT_PREFIX, PLATFORM_PREFIX[current_platform]]))
  File ""/usr/lib/python3.5/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 944, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 956, in _find_and_load_unlocked
ImportError: No module named 'data/migrations'
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/17 10:17 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/12040/Screenshot.PNG","06/Sep/17 10:18 PM;VladimirWork;Screenshot_.PNG;https://jira.hyperledger.org/secure/attachment/12041/Screenshot_.PNG","06/Sep/17 10:18 PM;VladimirWork;Screenshot__.PNG;https://jira.hyperledger.org/secure/attachment/12042/Screenshot__.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyf67:",,,,,,12,,,,,,,,,,,,,,,,,,,,andkononykhin,krw910,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/17 7:45 AM;krw910;[~gudkov] Can you please get this assigned out to someone today? We need to make this the highest priority.

The customer success team has now deployed the latest Stable to two of its test networks. In both cases one of the nodes did not upgrade. In both cases we do not control the nodes and they can no longer participate in the pool due to the significant changes between releases.

We must have the process of manually upgrading the node functional. Hopefully just my steps are incorrect, but if not we need some kind of fix to get these node upgraded and functional.

[~nage] FYI;;;","06/Sep/17 4:43 PM;ozheregelya;The problem is also reproduces on the latest master versions (upgrade from 1.1.130 to 1.1.131).;;;","06/Sep/17 6:00 PM;andkononykhin;Fixed and merged to stable:
https://github.com/hyperledger/indy-node/pull/337;;;","06/Sep/17 10:18 PM;VladimirWork;Build Info:
1.1.34 (rc)

Steps to Validate:

1. sudo apt update
2. sudo systemctl stop sovrin-node
3. sudo systemctl stop sovrin-node-control
4. sudo apt-get install sovrin -y
5. sudo apt-get install indy-node -y
6. sudo python3
7. from sovrin_node.utils.migration_tool import migrate
8. migrate(""1.0.28"",""1.1.34"",10)

Actual Results:
Migration is applied successfully after the upgrade from 1.0.28 to 1.1.34. !Screenshot.PNG|thumbnail! 

Additional Info:
Migration during pool upgrade to 1.1.34 works normally. !Screenshot_.PNG|thumbnail!  !Screenshot__.PNG|thumbnail! ;;;","08/Sep/17 8:52 PM;ozheregelya;The fix was also merged to master. 
Build Info:
  indy-node 1.1.130 -> 132
  indy-anoncreds 1.1.25 -> 25
  indy-plenum 1.1.121 -> 121
  sovrin 1.1.26
OS/Platform: Ubuntu 16.04.2 LTS

Migration works without any exceptions:
{code:java}
root@5805b95d70d0:/home/sovrin# sudo apt-get install indy-node
Reading package lists... Done
Building dependency tree 
Reading state information... Done
The following held packages will be changed:
 indy-node
The following packages will be upgraded:
 indy-node
1 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
Need to get 492 kB of archives.
After this operation, 0 B of additional disk space will be used.
Do you want to continue? [Y/n] y
Get:1 https://repo.sovrin.org/deb xenial/master amd64 indy-node amd64 1.1.132 [492 kB]
Fetched 492 kB in 5s (96.7 kB/s) 
debconf: delaying package configuration, since apt-utils is not installed
(Reading database ... 22844 files and directories currently installed.)
Preparing to unpack .../indy-node_1.1.132_amd64.deb ...
Unpacking indy-node (1.1.132) over (1.1.130) ...
Setting up indy-node (1.1.132) ...
root@5805b95d70d0:/home/sovrin# sudo python3
Python 3.5.2 (default, Nov 17 2016, 17:05:23) 
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from sovrin_node.utils.migration_tool import migrate
2017-09-08 11:48:26,016 | DEBUG | __init__.py (60) | register | Registered VCS backend: git
2017-09-08 11:48:26,037 | DEBUG | __init__.py (60) | register | Registered VCS backend: hg
2017-09-08 11:48:26,090 | DEBUG | __init__.py (60) | register | Registered VCS backend: svn
2017-09-08 11:48:26,092 | DEBUG | __init__.py (60) | register | Registered VCS backend: bzr
>>> migrate(""1.1.125"",""1.1.132"",10)
2017-09-08 11:48:33,371 | INFO | migration_tool.py (52) | migrate | Migrating from 1.1.125 to 1.1.132 on Ubuntu
2017-09-08 11:48:33,374 | DEBUG | migration_tool.py (54) | migrate | Found migration scripts: ['1_0_96_to_1_0_97', 'disabled_1_0_97_to_1_0_96', 'helper_1_0_96_to_1_0_97']
2017-09-08 11:48:33,375 | INFO | migration_tool.py (58) | migrate | No migrations can be applied to the current code.
0{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Release preparation,INDY-809,20641,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,gudkov,andkononykhin,andkononykhin,06/Sep/17 10:10 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,release,,,,,Ongoing task for new releases preparation work,,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyfgv:",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,krw910,nage,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Sep/17 3:31 AM;nage;Can you quantify this work so that we can prioritize this task relative to others?;;;","11/Sep/17 6:56 PM;andkononykhin;Done. Actually I created this task because I needed to link my reports with JIRA for reporting about such kind of work I did for the latest release. Usually it includes review of changes in master from, making git merge with possible exclusions of some commits and creating pull requests to stable for plenum and node. I see two options here: create such task in each sprint or use one for all sprints.;;;","13/Sep/17 6:10 AM;krw910;[~andkononykhin] You can make a recurring appointment in your calendar to track these tasks.;;;","13/Sep/17 4:08 PM;andkononykhin;[~krw910] I created it according to [~gudkov] request to have a task which we can link for reports about spent time. It's not a kind of reminder.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Review and replace 'assert' with exceptions in indy-plenum where needed,INDY-810,20688,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,andkononykhin,andkononykhin,08/Sep/17 5:50 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,1.5,,,0,,,,,,"Currently production builds use optimization for bytecode (INDY-211) when running [node|https://github.com/andkononykhin/indy-node/blob/master/build-scripts/ubuntu-1604/postinst_node#L54] and [node_control_tool|https://github.com/andkononykhin/indy-node/blob/master/build-scripts/ubuntu-1604/postinst_node#L78].

This silently [removes|https://docs.python.org/3.5/tutorial/modules.html#compiled-python-files] all assert statements from the code. I think all asserts (in both indy-plenum and indy-node) should be reviewed and fixed (e.g. replaced with custom/built-in exeptions) where needed.",,,,,,,,,,,,,,,,,INDY-1414,,,,,,INDY-211,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzzcp3:",,,,,,EV 18.12 Release RocksDB,,,,,,,,3.0,,,,,,,,,,,,andkononykhin,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jun/18 4:03 PM;andkononykhin;Problem reason:
 - asserts are silently removed in production, thus they shouldn't be used in cases where errors are expected and exceptions are better there

Changes:
 - reviewed asserts in indy-plenum, replaced with exceptions where needed, added tests

Committed into:
 - https://github.com/hyperledger/indy-plenum/pull/726
 - https://github.com/hyperledger/indy-plenum/pull/748

Risk factors:
 - broken CI testing

Risk:
 - Low

Covered with tests:
 - added unit or integration tests for any change

Recommendations for QA: do the following sequence of steps
 * nothing more than tests should pass;;;","18/Jun/18 4:06 PM;ashcherbakov;Done. Changes in node will be done in a separate task.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test_view_change_complex fails intermittently,INDY-811,20689,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,mzk-vct,mzk-vct,08/Sep/17 7:18 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,should,tests,,,,"Test test_view_change_complex in Plenum fails sometimes.
Logs attached.
[Jenkins build|https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-374/4/]",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-823,,,,,,,,"30/Nov/17 9:29 PM;VladimirWork;node_catchup.PNG;https://jira.hyperledger.org/secure/attachment/13433/node_catchup.PNG","08/Sep/17 7:19 PM;mzk-vct;test_view_change_complex.log;https://jira.hyperledger.org/secure/attachment/12044/test_view_change_complex.log","13/Sep/17 10:43 PM;andkononykhin;test_view_change_complex.log.txt;https://jira.hyperledger.org/secure/attachment/12102/test_view_change_complex.log.txt","23/Nov/17 12:23 AM;ashcherbakov;test_view_change_complex_latest.log;https://jira.hyperledger.org/secure/attachment/13410/test_view_change_complex_latest.log","30/Nov/17 9:29 PM;VladimirWork;view_change.PNG;https://jira.hyperledger.org/secure/attachment/13434/view_change.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx0wv:",,,,,,14,INDY 17.21,INDY 17.24: Node Perf,,,,,,,,,,,,,,,,,,anikitinDSR,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Nov/17 11:58 PM;anikitinDSR;excluded check_last_ordered_3pc;;;","30/Nov/17 9:29 PM;VladimirWork;Build Info:
indy-node 1.2.224

Steps to Validate:
1. Run ~/indy-plenum/plenum/test/node_catchup tests via pytest.
2. Run ~/indy-plenum/plenum/test/view_change tests via pytest.

Actual Results:
There are no errors during tests run. !node_catchup.PNG|thumbnail!  !view_change.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DOC: Request for release notes on Indy-node 1.1.35,INDY-812,20691,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ozheregelya,ozheregelya,08/Sep/17 8:36 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,documentation,,,,,"*Version Information*
 indy-plenum= 1.1.25
 indy-anoncreds= 1.0.10
 indy-node= 1.1.35
 sovrin= 1.1.6

*Major Fixes*
 INDY-808 - Fixed problem with migration during manual upgrade
 INDY-765 - Fixed problem with message length limitation (permanent solution of INDY-25)

*Changes and Additions*
 Implemented command line tool to provide validator status (INDY-715)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyihr:",,,,,,12,13,14,,,,,,,,,,,,,,,,,,mgbailey,ozheregelya,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Sep/17 4:11 AM;mgbailey;Is INDY-796 correct?  I don't see validator status tool information there.;;;","13/Sep/17 7:01 PM;ozheregelya;[~mgbailey], sorry for my mistake. It should be INDY-715. I'll correct description.;;;","16/Sep/17 6:09 AM;TechWritingWhiz;This work is completed and is included in the pull request: https://github.com/sovrin-foundation/sovrin/pull/24;;;","18/Sep/17 7:24 PM;ozheregelya;Changes were reviewed. Documentation looks good.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Automated system tests,INDY-813,20694,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,spivachuk,spivachuk,09/Sep/17 1:25 AM,11/Oct/19 6:42 PM,28/Oct/23 2:47 AM,11/Oct/19 6:42 PM,,,,,0,,,,,,Currently in sovrin there are automated tests of unit and integration levels only. In scope of this story automated tests of system level must be introduced into sovrin.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1cn:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 6:42 PM;ashcherbakov;Already done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create basic framework for system tests,INDY-814,20695,20694,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,spivachuk,spivachuk,09/Sep/17 1:28 AM,11/Oct/19 6:42 PM,28/Oct/23 2:47 AM,11/Oct/19 6:42 PM,,,,,0,,,,,,"System tests must be located in indy-node repository but must be isolated from the rest of sovrin code which must not be importable in system tests.
It is preferable to use pytest and pytest-asyncio as the test framework.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyfs7:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/17 9:23 PM;spivachuk;Created an initial version of an acceptance test framework. The changes are contained in the following pull request:
 [https://github.com/hyperledger/indy-node/pull/347];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create pool deployment tool for system tests,INDY-815,20696,20694,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,spivachuk,spivachuk,09/Sep/17 1:29 AM,11/Oct/19 6:42 PM,28/Oct/23 2:47 AM,11/Oct/19 6:42 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyfsf:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create reporting tool for system tests,INDY-816,20697,20694,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,spivachuk,spivachuk,09/Sep/17 1:29 AM,11/Oct/19 6:43 PM,28/Oct/23 2:47 AM,11/Oct/19 6:43 PM,,,,,0,,,,,,"The full procedure of run of all the system tests must include generating a report artifact. This report must contain the same information as ""Acceptance Matrix"" tab of ""Test Matrix - RC - Sovrin - INDY"" spreadsheet (https://docs.google.com/spreadsheets/d/12k8kdQ4gnHBZbg36RkACmj1lpzuWqyQRL8fKzE1OvXA) contains now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyfsn:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate run of system tests into CI,INDY-817,20698,20694,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,spivachuk,spivachuk,09/Sep/17 1:30 AM,11/Oct/19 6:43 PM,28/Oct/23 2:47 AM,11/Oct/19 6:43 PM,,,,,0,devops,,,,,"Note: acceptance matrix report (see INDY-816 for details) generated for each build must be saved, so that the history of these reports for performed builds will be available.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyfsv:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Write system test for Acceptance Scenario 2,INDY-818,20699,20694,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,spivachuk,spivachuk,09/Sep/17 1:32 AM,11/Oct/19 6:43 PM,28/Oct/23 2:47 AM,11/Oct/19 6:43 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyft3:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Write system test for Acceptance Scenario 4,INDY-819,20700,20694,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,spivachuk,spivachuk,09/Sep/17 1:32 AM,11/Oct/19 6:44 PM,28/Oct/23 2:47 AM,11/Oct/19 6:44 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyftb:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Write system test for Acceptance Scenario 9,INDY-820,20701,20694,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,spivachuk,spivachuk,09/Sep/17 1:32 AM,11/Oct/19 6:44 PM,28/Oct/23 2:47 AM,11/Oct/19 6:44 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyftj:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/17 9:25 PM;spivachuk;Implemented together with [~VladimirWork] a test for Acceptance Test Scenario 9 (Remove / Add Roles). The changes are contained in the following pull request:
https://github.com/hyperledger/indy-node/pull/347;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Write system test for Acceptance Scenario 10,INDY-821,20702,20694,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,spivachuk,spivachuk,09/Sep/17 1:33 AM,11/Oct/19 6:48 PM,28/Oct/23 2:47 AM,11/Oct/19 6:48 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyftr:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Write system test for Acceptance Scenario 11,INDY-822,20703,20694,Sub-task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,spivachuk,spivachuk,09/Sep/17 1:33 AM,11/Oct/19 6:49 PM,28/Oct/23 2:47 AM,11/Oct/19 6:49 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyftz:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Intermittently failed tests,INDY-823,20723,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,andkononykhin,andkononykhin,11/Sep/17 6:22 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,tests,,,,,"The task if for collecting cases of intermittently failed tests happens as a rule during Jenkins testing.

Lists of tests:
 * plenum/test/pool_transactions/test_nodes_with_pool_txns.py:*testStewardCannotAddNodeWithNonBase58VerKey* [^testStewardCannotAddNodeWithNonBase58VerKey.log.txt], [jenkins build|https://ci.evernym.com/job/Plenum/job/PR-376/1/] (temporarily available)
 * plenum/test/view_change/slow_nodes/*test_view_change_complex*:  [^test_view_change_complex.log.txt], [jenkins build|https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-374/4/]
 * plenum/test/view_change/slow_nodes/*test_view_change_all_nodes_random_delay.py*: [^test_view_change_all_nodes_random_delay.log.txt], [jenkins build|https://ci.evernym.com/job/Plenum/job/PR-374/1/]
 * plenum/test/instances/test_instance_cannot_become_active_with_less_than_four_servers.py:*testProtocolInstanceCannotBecomeActiveWithLessThanFourServers* [logs|^testProtocolInstanceCannotBecomeActiveWithLessThanFourServers.log.txt], [jenkins build|https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-378/2/]",,,,,,,,,,,,,,,,,,,,,,,INDY-400,INDY-811,,,,,,,,,,,"13/Sep/17 3:27 PM;andkononykhin;testProtocolInstanceCannotBecomeActiveWithLessThanFourServers.log.txt;https://jira.hyperledger.org/secure/attachment/12086/testProtocolInstanceCannotBecomeActiveWithLessThanFourServers.log.txt","11/Sep/17 6:25 PM;andkononykhin;testStewardCannotAddNodeWithNonBase58VerKey.log.txt;https://jira.hyperledger.org/secure/attachment/12054/testStewardCannotAddNodeWithNonBase58VerKey.log.txt","12/Sep/17 12:51 AM;sergey-shilov;test_view_change_all_nodes_random_delay.log.txt;https://jira.hyperledger.org/secure/attachment/12073/test_view_change_all_nodes_random_delay.log.txt","12/Sep/17 12:03 AM;andkononykhin;test_view_change_complex.log.txt;https://jira.hyperledger.org/secure/attachment/12057/test_view_change_complex.log.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyfyf:",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Sep/17 6:20 AM;krw910;There are tickets logged from this one that cover all the tests.;;;","13/Sep/17 4:14 PM;andkononykhin;[~krw910] I've checked among bugs and not found them except INDY-811 which is linked here. Did you mean we should create separate tasks?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Send multisignature on timeout,INDY-824,20726,20873,Sub-task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,ashcherbakov,mzk-vct,mzk-vct,11/Sep/17 10:20 PM,18/Sep/17 8:28 PM,28/Oct/23 2:47 AM,,,,,,0,,,,,,"As of now multisignature created by Primary propagates to other nodes with the next PrePrepare which depends on requests (no requests - no PrePrepares).
",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-751,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyfz3:",,,,,,,,,,,,,,,,,,,,,,,,,,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nodes have no ViewChangeDone message to send for view 0,INDY-825,20728,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,VladimirWork,VladimirWork,11/Sep/17 11:40 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Build Info:
indy-node 1.0.113

Overview:
View change is failed during nodes adding.

Steps to Reproduce:
0. Install pool with 4 nodes.
1. Add nodes from 5th to 7th.
2. Restart the whole pool.
3. Check the logs at each node for view change and current primary.

Actual Results:
View change is failed during nodes adding: ""| get_msgs_for_lagged_nodes | NodeX has no ViewChangeDone message to send for view 0"" at all nodes. Pool consensus is lost.

Expected Results:
Pool should work normally.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Sep/17 12:28 AM;VladimirWork;_node1.log;https://jira.hyperledger.org/secure/attachment/12058/_node1.log","12/Sep/17 12:28 AM;VladimirWork;_node2.log;https://jira.hyperledger.org/secure/attachment/12059/_node2.log","12/Sep/17 12:28 AM;VladimirWork;_node3.log;https://jira.hyperledger.org/secure/attachment/12060/_node3.log","12/Sep/17 12:28 AM;VladimirWork;_node4.log;https://jira.hyperledger.org/secure/attachment/12061/_node4.log","12/Sep/17 12:28 AM;VladimirWork;_node5.log;https://jira.hyperledger.org/secure/attachment/12062/_node5.log","12/Sep/17 12:28 AM;VladimirWork;_node6.log;https://jira.hyperledger.org/secure/attachment/12063/_node6.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyl53:",,,,,,12,13,14,INDY 17.21,,,,,,,,,,,,,,,,,ashcherbakov,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Sep/17 11:48 PM;krw910;The steps I did to get this pool into this state was the following:

Started with a pool that contained 4 nodes
Went to add three more nodes to the pool
Added Node 5
Added Node 6
Went to add Node 7 and the transaction did not go through.

I checked the ledger sizes and Nodes 1 - 6 all had matching ledgers (at least they appear to have matching ledgers).
I restarted the pool and still could not get consensus.
It appears that Nodes 4, 5 and 6 show Node 1 as the primary (in the logs).
Nodes 1, 2 and 3 do not show any primary nodes (in the logs).;;;","18/Sep/17 7:03 PM;ashcherbakov;[~VladimirWork] Is it really in ToTest?;;;","18/Sep/17 7:26 PM;VladimirWork;[~ashcherbakov] [~krw910] Exact this issue is not reproducing on current master or latest rc (the steps are similar to Test Scenario 07), although we have another issue with missed view changes in INDY-848.;;;","19/Sep/17 11:43 PM;krw910;[~VladimirWork] It was set ""To Test"" so that I could see if it was still happening and if so to walk backwards through the bulids to see when it was introduced. If it is not happening with the latest builds I will move this ticket. Thanks for the help.;;;","19/Sep/17 11:43 PM;krw910;[~danielhardman] We are not able to reproduce this issue. If it is seen again we will reopen the ticket.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Getting Started with Sovrin outdated ,INDY-826,20731,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Invalid,VladimirWork,mzk-vct,mzk-vct,12/Sep/17 12:28 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"https://github.com/hyperledger/indy-node/blob/master/getting-started.md

It was reported that it raises following exception when starting Faber agent:
{code:java}
*Agent startup failed: [cause : error occurred during operation: client request invalid: CouldNotAuthenticate('Can not find verkey for DID ULtgFQJe6bjiFbs7ke3NJD',)]*
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Sep/17 12:31 AM;mzk-vct;Node1.log;https://jira.hyperledger.org/secure/attachment/12066/Node1.log","12/Sep/17 12:31 AM;mzk-vct;Node2.log;https://jira.hyperledger.org/secure/attachment/12067/Node2.log","12/Sep/17 12:31 AM;mzk-vct;Node3.log;https://jira.hyperledger.org/secure/attachment/12068/Node3.log","12/Sep/17 12:31 AM;mzk-vct;Node4.log;https://jira.hyperledger.org/secure/attachment/12069/Node4.log","12/Sep/17 12:31 AM;mzk-vct;domain_transactions_sandbox_genesis;https://jira.hyperledger.org/secure/attachment/12064/domain_transactions_sandbox_genesis","12/Sep/17 12:31 AM;mzk-vct;faber-cmd.log;https://jira.hyperledger.org/secure/attachment/12065/faber-cmd.log","12/Sep/17 12:31 AM;mzk-vct;pool_transactions_sandbox_genesis;https://jira.hyperledger.org/secure/attachment/12070/pool_transactions_sandbox_genesis","12/Sep/17 12:31 AM;mzk-vct;steward-cli.log;https://jira.hyperledger.org/secure/attachment/12071/steward-cli.log","12/Sep/17 12:31 AM;mzk-vct;steward-cmd.log;https://jira.hyperledger.org/secure/attachment/12072/steward-cmd.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzygqf:",,,,,,13,,,,,,,,,,,,,,,,,,,,krw910,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Sep/17 12:39 AM;mzk-vct;Perhaps it is missing some steps, described in [https://github.com/evernym/sovrin-environments/blob/master/vagrant/training/vb-multi-vm/TestSovrinClusterSetup.md];;;","12/Sep/17 4:14 AM;krw910;The instructions look correct. The guide does say that you need to have setup the demo agents, but does not tell you where to do that if you have not followed the setup in the section using the vagrant scripts. Maybe we need to explain better where that setup is located.;;;","15/Sep/17 10:08 PM;VladimirWork;PR is sent in https://github.com/hyperledger/indy-node/blob/master/docs/Sovrin_Running_Locally.md with last update about 5 month ago.

Reporter should use actual guides:
https://github.com/hyperledger/indy-node/blob/master/getting-started.md
https://github.com/evernym/sovrin-environments/blob/master/vagrant/training/vb-multi-vm/TestSovrinClusterSetup.md;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow a steward to update his node entry in the ledger - including the verkey,INDY-827,20754,,Story,In Progress,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,brentzundel,mgbailey,mgbailey,12/Sep/17 5:04 AM,10/Jun/20 7:23 AM,28/Oct/23 2:47 AM,,,1.16.0,,,0,EV-CS,,,,,"Currently, a steward is allowed only a single node entry in the ledger, regardless of if it is designated a validator or not.  The correct way should be to allow a steward to put multiple node entries onto the ledger, but only one should be permitted to be a validator at a time.

We have had instances where a steward has had to replace a node in a validator network, and the public-private key pair for the node was changed as a part of the process. There needs to be a way that the steward can update the ledger to reflect the new verkey. There does not appear to be a way to do this, currently.

For example, the steward for icenode, who's node entry had been written to the ledger, updated the ledger to un-assign the validator as shown in line 9:
{code:java}
[1,{""data"":{""alias"":""australia"",""client_ip"":""52.64.96.160"",""client_port"":""9702"",""node_ip"":""52.64.96.160"",""node_port"":""9701"",""services"":[""VALIDATOR""]},""dest"":""UZH61eLH3JokEwjMWQoCMwB3PMD6zRBvG6NCv5yVwXz"",""identifier"":""3U8HUen8WcgpbnEz1etnai"",""txnId"":""c585f1decb986f7ff19b8d03deba346ab8a0494cc1e4d69ad9b8acb0dfbeab6f"",""type"":""0""}]
[2,{""data"":{""alias"":""brazil"",""client_ip"":""54.233.203.241"",""client_port"":""9702"",""node_ip"":""54.233.203.241"",""node_port"":""9701"",""services"":[""VALIDATOR""]},""dest"":""2MHGDD2XpRJohQzsXu4FAANcmdypfNdpcqRbqnhkQsCq"",""identifier"":""G3knUCmDrWd1FJrRryuKTw"",""txnId"":""5c8f52ca28966103ff0aad98160bc8e978c9ca0285a2043a521481d11ed17506"",""type"":""0""}]
[3,{""data"":{""alias"":""canada"",""client_ip"":""52.60.207.225"",""client_port"":""9702"",""node_ip"":""52.60.207.225"",""node_port"":""9701"",""services"":[""VALIDATOR""]},""dest"":""8NZ6tbcPN2NVvf2fVhZWqU11XModNudhbe15JSctCXab"",""identifier"":""22QmMyTEAbaF4VfL7LameE"",""txnId"":""408c7c5887a0f3905767754f424989b0089c14ac502d7f851d11b31ea2d1baa6"",""type"":""0""}]
[4,{""data"":{""alias"":""england"",""client_ip"":""52.56.191.9"",""client_port"":""9702"",""node_ip"":""52.56.191.9"",""node_port"":""9701"",""services"":[""VALIDATOR""]},""dest"":""DNuLANU7f1QvW1esN3Sv9Eap9j14QuLiPeYzf28Nub4W"",""identifier"":""NYh3bcUeSsJJcxBE6TTmEr"",""txnId"":""d56d0ff69b62792a00a361fbf6e02e2a634a7a8da1c3e49d59e71e0f19c27875"",""type"":""0""}]
[5,{""data"":{""alias"":""korea"",""client_ip"":""52.79.115.223"",""client_port"":""9702"",""node_ip"":""52.79.115.223"",""node_port"":""9701"",""services"":[""VALIDATOR""]},""dest"":""HCNuqUoXuK9GXGd2EULPaiMso2pJnxR6fCZpmRYbc7vM"",""identifier"":""U38UHML5A1BQ1mYh7tYXeu"",""txnId"":""76201e78aca720dbaf516d86d9342ad5b5d46f5badecf828eb9edfee8ab48a50"",""type"":""0""}]
[6,{""data"":{""alias"":""singapore"",""client_ip"":""13.228.62.7"",""client_port"":""9702"",""node_ip"":""13.228.62.7"",""node_port"":""9701"",""services"":[""VALIDATOR""]},""dest"":""Dh99uW8jSNRBiRQ4JEMpGmJYvzmF35E6ibnmAAf7tbk8"",""identifier"":""HfXThVwhJB4o1Q1Fjr4yrC"",""txnId"":""51e2a46721d104d9148d85b617833e7745fdbd6795cb0b502a5b6ea31d33378e"",""type"":""0""}]
[7,{""data"":{""alias"":""virginia"",""client_ip"":""34.225.215.131"",""client_port"":""9702"",""node_ip"":""34.225.215.131"",""node_port"":""9701"",""services"":[""VALIDATOR""]},""dest"":""EoGRm7eRADtHJRThMCrBXMUM2FpPRML19tNxDAG8YTP8"",""identifier"":""SPdfHq6rGcySFVjDX4iyCo"",""txnId"":""0a4992ea442b53e3dca861deac09a8d4987004a8483079b12861080ea4aa1b52"",""type"":""0""}]
[8,{""data"":{""alias"":""icenode"",""client_ip"":""185.102.43.35"",""client_port"":9792,""node_ip"":""185.102.43.35"",""node_port"":9791,""services"":[""VALIDATOR""]},""dest"":""2VMDBjJCqxEonfaTcwvyBy5J473H2u65ZqQhPHx47iDG"",""identifier"":""8KSy24k3x1YoviorD8n8Li"",""reqId"":1502122356574315,""signature"":""5DEBmucbHssW8MZKVTN6AF2eB9ibywb9n5wy7aNExy3zxfrWs7eumVbMbBsbsbAAHTN26vpgkD8APMx3dAt56Eqq"",""txnTime"":1502122359,""type"":""0""}]
[9,{""data"":{""alias"":""icenode"",""services"":[]},""dest"":""2VMDBjJCqxEonfaTcwvyBy5J473H2u65ZqQhPHx47iDG"",""identifier"":""8KSy24k3x1YoviorD8n8Li"",""reqId"":1505151569077969,""signature"":""4an4Ym52Je8VUpY1ZJGzuJNJducfXCXHAGf9gTFhh3Sf8D8vmCNj3oc2fh5x4ym7ETXcoqnqi1MxKA6fCgrZjUSb"",""txnTime"":1505151570,""type"":""0""}]
{code}
He did this because the dest had been changed, and 2VMDBjJCqxEonfaTcwvyBy5J473H2u65ZqQhPHx47iDG was no longer correct. He then attempted to add a node with the correct dest, but was denied because there was already a node associated with the steward.  Rather than checking on node creation for *1 node per steward*, the check should occur when _promoting or creating_ a node to allow only *1 validator per steward*.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzwvif:00001yw969w4c98r",,,,,,,,,,,,,,,,,,,,,,,,,,brentzundel,esplinr,mgbailey,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/18 12:10 AM;spivachuk;Verified in the source code that the story is still valid.;;;","02/Nov/18 10:45 PM;esplinr;We would like to better understand the use case driving this request. Why wouldn't the steward just create a new DID and maintain a one-to-one relationship?;;;","03/Nov/18 12:03 AM;mgbailey;Steward DIDs are a tightly controlled commodity, written by Sovrin Trustees only;;;","19/Apr/19 6:00 AM;esplinr;Stewards occasionally lose keys and need to re-provision their validator nodes. Currently they have to have a new steward DID in order to change their validator.

In the future, it is expected that stewards may have multiple nodes following the network, where one is a validator and the others are observers, and the steward can rotate between them.;;;","20/Apr/19 12:39 AM;esplinr;Having a one-to-one relationship between Steward DIDs and Nodes can improve security: multiple nodes are not compromised if a DID is compromised.;;;","20/Apr/19 1:15 AM;mgbailey;A steward MUST have only one validator node on a network. However, there is no reason that he cannot have more than one node on the ledger, only one of which has service=[validator] active.;;;","24/Apr/19 5:46 PM;esplinr;We see three different use cases here:
1. Stewards should be able to update the Node entry and change their verkey. This is possible today and is tested.
2. Stewards should be able to swap in a new machine for their existing validator node. Currently, the suggested approach is to edit the Node transaction when the new machine is added, and edit the Node transaction again when the old machine is brought back.
3. Stewards should be able to have multiple Node transactions associated with their DID in order to allow hot-swapping a machine. We see the value to an operations team in having multiple Node transactions assigned per steward, but only one recognized as the validator. We'll evaluate when it is best to implement this functionality.;;;","25/Apr/19 1:42 AM;mgbailey;[~esplinr] Has there been a change? This ticket is all about item #1, the ability of a steward to change his node DID (note that at some point engineering changed what they are calling it from node verkey to node DID). As far as I know, we are still unable to change this.

 ;;;","29/May/19 10:58 PM;esplinr;The team will retest use case 1 (stewards updating their Node entry to change their verkey).

Use case 2 and 3 should be raised in separate issues if they are considered important.;;;","10/Jun/20 7:23 AM;brentzundel;A PR has been raised which changes dynamic validation on indy plenum to check for existing validator nodes, not just existing nodes.
This allows a steward to have any number of nodes on a network, but only one of them may be promoted to Validator at any one time.



[https://github.com/hyperledger/indy-plenum/pull/1486];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Needed to graduate from Incubation,INDY-828,20765,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,gudkov,gudkov,12/Sep/17 9:31 PM,09/Oct/19 6:21 PM,28/Oct/23 2:47 AM,09/Oct/19 6:20 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-1,,Incubation,Done,,,,,,,,"1|hzyg6v:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,gudkov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 6:20 PM;esplinr;Indy graduated from Hyperledger Incubation!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Remove all non-Indy branding from indy-plenum repo,INDY-829,20766,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,gudkov,gudkov,12/Sep/17 9:41 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"We need to remove all non-Indy branding and names from indy-plenum repo:
* Package names
* Code primitive names
* Paths
* Documentation

Ideally, if full-text search for Sovrin and Evernym will return nothing.",,,,,,,,,,,,,,,,,,,,,,,INDY-885,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzyii7:",,,,,,13,14,,,,,,,5.0,,,,,,,,,,,,andkononykhin,gudkov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Sep/17 8:43 PM;andkononykhin;[https://github.com/hyperledger/indy-plenum/pull/381]

All copyrights and comments related to code origins have been left intact;;;","21/Sep/17 5:49 PM;VladimirWork;Сopyrights, comments related to code origins and references to CI/sovrin.org have been left intact only.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Remove all non-Indy branding from indy-node repo,INDY-830,20767,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,nage,gudkov,gudkov,12/Sep/17 10:16 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"We need to remove all non-Indy branding and names from indy-node repo:
* Package names
* Code primitive names
* Paths
* Documentation

Ideally, if full-text search for Sovrin and Evernym will return nothing.",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-885,INDY-925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzyk87:",,,,,,13,14,INDY 17.21,INDY 17.22,,,,,5.0,,,,,,,,,,,,ashcherbakov,danielhardman,gudkov,krw910,spivachuk,tharmon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/17 12:53 AM;spivachuk;The following changes have been done in scope of this ticket:
- Removed Evernym and Sovrin brands from code and documentation in indy-node repository.
- Implemented rebranding upgrade mechanism and rebranding migration script for node.
- Implemented rebranding migration for wallet.
- Extracted wallet raw updaters from Wallet class.
- Added a test verifying loading of a wallet with GST stuff saved before rebranding.

The changes are contained in the following pull requests:
- https://github.com/hyperledger/indy-plenum/pull/402
- https://github.com/hyperledger/indy-node/pull/351

Evernym and Sovrin mentions have been kept in the following places of indy-node repository:
- Copyright statements.
- CI/CD URLs.
- APT repositories URLs.
- sovrin-environments URL and related links.
- References to {{sovrin}} package built on top of {{indy-node}} in validator-info tool and its tests.
- Documentation on {{sovrin}} package built on top of {{indy-node}}.
- Scripts related to rebranding upgrade and references to these scripts.
- Wallet migration mechanism.
- User and data references in existing node migration scripts.
- Serialized wallets in formats of old versions which are used in tests of backward compatibility of WalletStorageHelper.
- SovrinHelpers library references in CI/CD scripts.
- Example URLs in tests in indy_client/test/cli/test_send_attrib_validation module.;;;","05/Oct/17 3:05 AM;spivachuk;[~danielhardman], [~nage], [~krw910], currently the application data is not migrated for client upgrade being performed by {{apt-get install indy-node}} command. The application data is migrated only for node upgrade being performed by the node control tool (which can be initiated by {{POOL_UPGRADE}} transaction).

However, the client is backward compatible with wallets serialized with previous client versions. So if a user manually copies wallet files from the old application directory to the new one then the rebranded client will be able to load them.

The only case when the application data is migrated for a client is the case when the user {{sovrin}} uses both a node and a client on the same machine (i.e. the application directory is shared between the node and the client) and the node is upgraded by the node control tool. In such the case the application data will be migrated including proper migration of client-related stuff (for example, the extension of the sample request files will be changed - {{faber-request.sovrin}} -> {{faber-request.indy}}, and so on).

Do we need the feature of the application data migration for client upgrade being performed by {{apt-get install indy-node}} command, taking into account that the application directories must be migrated for all the users in the system if the package is updated by {{root}} and that in future the current CLI will be replaced with a new one based on Indy SDK?;;;","05/Oct/17 6:24 AM;krw910;[~spivachuk] Let me check with [~tharmon] and [~mgbailey] on this question since they will be dealing with it.;;;","05/Oct/17 11:48 PM;tharmon;My opinion is that when someone starts up the {{indy}} executable, it should check to see if there is a {{.sovrin}} directory in the current users home directory. If there is, it should ask the user if they would like to migrate it to a {{.indy}} directory with the default answer being 'Yes'.

Part of the issue here is that you don't know which users have actually used the {{sovrin}} executable, and traversing through the home directories seems to be a bit invasive. The solution that we do here cannot only work for one user and then break for all of the others.;;;","11/Oct/17 1:14 AM;ashcherbakov;[~nage] [~tharmon]
Should we implement it in the way how Trev suggests, taken into account that we're going to start implementation of CLI in indy-sdk?
I suggest that we close this ticket, and create a new one for client migration support;;;","24/Oct/17 5:28 AM;danielhardman;Yes, I agree with Trev's suggestion.;;;","25/Oct/17 3:15 AM;spivachuk;Created the task INDY-925 for implementation of application data migration for client upgrade.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Support of multiple pool networks by Indy Node,INDY-831,20770,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,VladimirWork,gudkov,gudkov,12/Sep/17 10:36 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"It should be possible to choose which network to use from the same install of Indy Node.

This is important for test networks, private network shards for regulatory reasons, development could use this, and it helps prove Indy can be used independently of Sovrin -- reduces open source fork risk.

It is related to path refactoring in INDY-833",,,,,,,,,,,,,,INDY-838,INDY-912,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzymp3:",,,,,,13,14,INDY 17.21,INDY 17.22,INDY 17.23,,,,3.0,,,,,,,,,,,,andrey.goncharov,dsurnin,gudkov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Sep/17 8:26 PM;andrey.goncharov;[~nage] [~danielhardman] we have an issue with upgrades if we support multiple networks for a node. Say, our network A uses indy-node 1 and our network B uses the same indy-node A. Then an upgrade transaction is issued in network A to upgrade to indy-node 2. The upgrade was a success. We switch to network B, where all nodes use old indy-node 1. As result of the upgrade which could have brought incompatible changes out node can no longer participate in consensus. We should either prohibit using several netwroks for a node (it's still possible for a client though) or implement multiple netwroks via virtualization (like docker).

Of course, we still have an option of putting a constraint ""all networks should depend on the same version of indy-node"", but I do not really like it: we prohibit using a major feature of our system.;;;","13/Sep/17 9:07 PM;andrey.goncharov;Added a design doc. Please review https://docs.google.com/document/d/14qwjFbrbMyGLjrAH7Kyqcv9e62Fo83GGdDwMXbk4b2A;;;","19/Oct/17 9:16 PM;dsurnin;[~ozheregelya] [~VladimirWork]

Do not forget that now init_indy_node should be called once for each network:
 * in /etc/indy/indy_config.py change NETWORK_NAME to desired network
 * run init_indy_node ;;;","27/Oct/17 7:21 PM;dsurnin;also please note 

script generate_indy_pool_transaction now has a new argument --network (""sandbox"" by default)

this parameter generates genesis transactions for the specified network only and place all the file to network specific folder.

after the script run you need to set desired network in /ect/indy/indy_config.py;;;","27/Oct/17 9:49 PM;dsurnin;done according to this doc

https://docs.google.com/spreadsheets/d/1A84H8knCtn8rrTirzxta8XC1jpHBjvQiqrxquTv6bpc/edit#gid=0;;;","15/Nov/17 7:48 PM;VladimirWork;Verified according to https://docs.google.com/spreadsheets/d/15_9oh8apbzSfjyAdLydl8ToEM692Jce44I2CSfULYkw/edit#gid=0.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Support of multiple pool networks by Indy Client (CLI),INDY-832,20771,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,VladimirWork,gudkov,gudkov,12/Sep/17 10:37 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"It should be possible to choose which network to use from the same install of Indy CLI.

This is important for test networks, private network shards for regulatory reasons, development could use this, and it helps prove Indy can be used independently of Sovrin -- reduces open source fork risk.

It is related to path refactoring in INDY-833",,,,,,,,,,,,,,INDY-838,INDY-912,,,,,,,,INDY-925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzx0y7:",,,,,,13,14,INDY 17.21,INDY 17.22,INDY 17.23,INDY 17.24: Node Perf,,,8.0,,,,,,,,,,,,andrey.goncharov,gudkov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Sep/17 9:07 PM;andrey.goncharov;Added a design doc. Please review https://docs.google.com/document/d/14qwjFbrbMyGLjrAH7Kyqcv9e62Fo83GGdDwMXbk4b2A;;;","27/Nov/17 11:19 PM;VladimirWork;Build Info:
indy-node 1.2.221

Steps to Validate:
1. Check that all files are placed according to new folder structure changes after client installation.
2. Connect CLI to any existing network.
3. Connect CLI to newly added network.
4. Check that all wallets made are placed to correct network folders.

Actual Results:
CLI works with different networks normally. All files and folders are placed according to https://docs.google.com/spreadsheets/d/1A84H8knCtn8rrTirzxta8XC1jpHBjvQiqrxquTv6bpc/edit#gid=0.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Proper file folder paths for system service,INDY-833,20772,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,VladimirWork,gudkov,gudkov,12/Sep/17 10:54 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"We need to use proper file folder paths for system service: usr, var, etc, user-configuration vs system configuration, folders for network configuration so multiple networks can co-exist

The most urgent task here is likely the file and folder location refactor, we will want to reorganize how things are laid out as soon as we can, before we pick up more production use cases and grow the network.  I walked through this with Dan and Devin and have attached an outline of what we discussed (see attached image).  Notice the paths under /var, /etc and $HOME/.indy.  The variables at the top of the board could be used as potential substitutes.  We also talked about having some sort of environment variable(s) so that system users can overwrite the home folder location to something more suitable.  Notice that this was from a brainstorming session, there is nothing set in stone.  Please add your thoughts and suggestions.  Obviously some plan as to how we can migrate files from existing locations in the current network will be important.   I look forward to hearing what tickets you think will be needed.",,,,,,,,,,,,,,INDY-838,INDY-912,,,,,,,,INDY-925,,,,,,,,,,,,"09/Nov/17 7:48 PM;VladimirWork;1.1.43-1.2.203.PNG;https://jira.hyperledger.org/secure/attachment/13315/1.1.43-1.2.203.PNG","13/Sep/17 12:02 AM;gudkov;Image uploaded from iOS(1).jpg;https://jira.hyperledger.org/secure/attachment/12083/Image+uploaded+from+iOS%281%29.jpg","08/Nov/17 11:22 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/13306/Node1.log","08/Nov/17 11:22 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/13307/Node2.log","08/Nov/17 11:22 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/13308/Node3.log","08/Nov/17 11:22 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/13309/Node4.log","08/Nov/17 11:22 PM;ozheregelya;Screenshot_2017-11-08_12-17-51.png;https://jira.hyperledger.org/secure/attachment/13305/Screenshot_2017-11-08_12-17-51.png","02/Nov/17 5:42 PM;VladimirWork;journalctl.txt;https://jira.hyperledger.org/secure/attachment/13200/journalctl.txt","02/Nov/17 7:05 PM;VladimirWork;manual_node_upgrade.PNG;https://jira.hyperledger.org/secure/attachment/13202/manual_node_upgrade.PNG","08/Nov/17 8:00 PM;VladimirWork;screenshot-1.png;https://jira.hyperledger.org/secure/attachment/13303/screenshot-1.png","02/Nov/17 5:43 PM;VladimirWork;upgrade_to_192.PNG;https://jira.hyperledger.org/secure/attachment/13201/upgrade_to_192.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzymov:",,,,,,13,14,INDY 17.21,INDY 17.22,INDY 17.23,,,,8.0,,,,,,,,,,,,andrey.goncharov,ashcherbakov,danielhardman,gudkov,MichaelWang,nage,ozheregelya,sergey-shilov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Sep/17 9:08 PM;andrey.goncharov;Added a design doc. Please review https://docs.google.com/document/d/14qwjFbrbMyGLjrAH7Kyqcv9e62Fo83GGdDwMXbk4b2A;;;","13/Sep/17 9:10 PM;andrey.goncharov;What is ""daemon wallet""?
Why do you want to keep shred ""cli history""?

Why do you want to keep shared key cache?

 ;;;","19/Sep/17 10:26 PM;andrey.goncharov;Spreadsheet with file move https://docs.google.com/spreadsheets/d/1A84H8knCtn8rrTirzxta8XC1jpHBjvQiqrxquTv6bpc;;;","20/Sep/17 6:10 AM;nage;The Daemon wallet was the keys/wallet required to run a node as a service (when you are running as a system daemon where do those files go --> not in a home folder).

Someone said we have a cli history file on disk, we were just calling out that this needs a clear file name (if it exists) and should live in the users home folder.

Also, it seems unusual to write logs to the current working directory unless the user has asked for that behavior, if you are logging by default, isn't it more normal to log to a known location in their home folder (or use system logging of some kind)?

Finally, someone said that we have some type of CurveZMQ key cache, and that was shared between Sovrin-aware programs and processes, if that isn't the case, please clarify what keys are stored or persisted to disk and what distinctions are useful at a file system level.  The idea here was that there exist keys on disk that are used to verify incomming connections and establish communications (but are not stored configuration or user data in the same way wallets are).  They shouldn't be stored in the same places we store wallets, unless we want to manage and back them up like wallets.;;;","25/Sep/17 9:04 PM;andrey.goncharov;[~nage]

??The Daemon wallet was the keys/wallet required to run a node as a service (when you are running as a system daemon where do those files go --> not in a home folder).??

Node is run from sovrin user. Why shouldn't it write to home of that user?

??Also, it seems unusual to write logs to the current working directory unless the user has asked for that behavior, if you are logging by default, isn't it more normal to log to a known location in their home folder (or use system logging of some kind)???

Agreed. Changed to .indy/cli.log

??Finally, someone said that we have some type of CurveZMQ key cache, and that was shared between Sovrin-aware programs and processes, if that isn't the case, please clarify what keys are stored or persisted to disk and what distinctions are useful at a file system level.  The idea here was that there exist keys on disk that are used to verify incomming connections and establish communications (but are not stored configuration or user data in the same way wallets are).  They shouldn't be stored in the same places we store wallets, unless we want to manage and back them up like wallets.??

As I said before node is run from sovrin user. Why shouldn't we keep related keys in that user's home dir? Wallets are client related and they are stored in a home directory of a user who runs the cli. ;;;","27/Sep/17 1:39 AM;sergey-shilov;[~nage], [~andrey.goncharov], [~ashcherbakov]
Hi guys,
currently I'm working on migration script in scope of this ticket and my question is what strategy should we use during directories/files migration: move or copy? Should we remove old directories/files at the end of successful migration in case of copy strategy?
Thanks.;;;","27/Sep/17 5:44 PM;ashcherbakov;We perform backup before migration, don't we? So move should be safe from my point of view. I think we should not have any outdated files in the file system after migration (all previous data must be in backup).;;;","29/Sep/17 11:13 PM;danielhardman;I think [~sergey-shilov]'s question can only be answered by [~tharmon] or [~mgbailey]. However, my vote is that a backup is adequate protection–and in fact, is cleaner than leaving a bunch of clutter than has to be manually cleaned up. Is the backup done tarball-style, capturing all permissions? And could the backup be restored simply by unpacking the archive? Or will we remove enough things that there'd be manual directory creation required to restore the backup?;;;","29/Sep/17 11:14 PM;danielhardman;Regarding the earlier note from Andrey G about the daemon running as the sovrin user: First, it should be the indy user now–right? Second, isn't it a bit unusual for a daemon user to have a folder under /home? If the user *does* have a folder there, I agree that putting the artifacts owned by that user, there, makes total sense...;;;","29/Sep/17 11:52 PM;ashcherbakov;[~nage] [~danielhardman]
As of now indy-node daemon is running as sovrin (indy) user which has home folder.
But we think that it's not good, and eventually we would like to avoid it (not in this ticket).
In the scope of this ticket we're planning to fully avoid writing or having anything in /home directory if node is running as a daemon. All data is going to migrate to /var/lib/indy, /var/log and /etc/indy
The data for CLI (which is run from the user) will go to home folder (/home/user/.indy-cli).;;;","31/Oct/17 4:56 AM;ozheregelya;indy-node 1.2.189
 indy-anoncreds 1.0.32
 indy-plenum 1.2.158
 sovrin 1.1.31

Case 1:
 indy-cli and .indy-cli directories present in /home/indy:
{code:java}
me@me-VM:/home/indy$ ll
total 44
drwxr-xr-x 6 indy indy 4096 Out 30 10:16 ./
drwxr-xr-x 4 root root 4096 Out 30 10:15 ../
-rw-r--r-- 1 indy indy 220 Set 1 2015 .bash_logout
-rw-r--r-- 1 indy indy 3771 Set 1 2015 .bashrc
drwxr-xr-x 3 indy indy 4096 Abr 20 2016 .config/
drwxr-xr-x 2 indy indy 4096 Out 30 10:16 .indy/
drwxr-xr-x 3 indy indy 4096 Out 30 10:16 .indy-cli/
drwxr-xr-x 3 indy indy 4096 Out 30 10:16 indy-cli/
-rw-r--r-- 1 indy indy 655 Mai 16 13:49 .profile
-rw-r--r-- 1 indy indy 1600 Jan 9 2016 .Xdefaults
-rw-r--r-- 1 indy indy 14 Jan 9 2016 .xscreensaver
me@me-VM:/home/indy$ ll indy-cli/
total 12
drwxr-xr-x 3 indy indy 4096 Out 30 10:16 ./
drwxr-xr-x 6 indy indy 4096 Out 30 10:16 ../
drwxr-xr-x 2 indy indy 4096 Out 30 10:16 networks/
me@me-VM:/home/indy$ ll .indy-cli/
total 12
drwxr-xr-x 3 indy indy 4096 Out 30 10:16 ./
drwxr-xr-x 6 indy indy 4096 Out 30 10:16 ../
drwxr-xr-x 5 indy indy 4096 Out 30 10:16 networks/{code}
Expected Results: Only one directory should present.
Additional Information: Note that this is actual only for indy user. For others ones only .indy-cli directory presents. ;;;","02/Nov/17 5:43 PM;VladimirWork;Build Info:
indy-node 1.2.188

Steps to Reproduce:
1. Perform pool upgrade to 1.2.192 version (force flag doesn't matter).

Actual Results:
Nodes don't start after the upgrade. Manual start also doesn't work. See journalctl for additional info. [^journalctl.txt]  !upgrade_to_192.PNG|thumbnail! 

Expected Results:
Nodes should start normally after the upgrade.

Additional Info:
The same manual node upgrade also doesn't work due to unmet dependencies:

The following packages have unmet dependencies:
 indy-node : Depends: indy-plenum (= 1.2.161) but 1.2.156 is to be installed
E: Unable to correct problems, you have held broken packages.;;;","03/Nov/17 8:39 PM;ozheregelya;Case 3:
Following errors appear during clean installation of sovrin package:
{code:java}
grep: /etc/sovrin/node_control.conf: No such file or directory
sed: can't read /etc/sovrin/node_control.conf: No such file or directory{code}
Case 4:
There is only one indy.env file on each node. indy.env file should be created for each network.;;;","03/Nov/17 9:21 PM;VladimirWork;[~dsurnin] We need to change clear_node.py according to file folder path changes (with --full parameter it should clear ledgers for all node networks).;;;","06/Nov/17 9:01 PM;ozheregelya;*Version Info:*
indy-anoncreds 1.0.32
indy-node 1.2.198
indy-plenum 1.2.165
libindy-crypto 0.1.6-10
python3-indy-crypto 0.1.6
sovrin 1.1.37


*Case 5:*

Owner of genesis files in user home directory is root if package was installed by user _me_:
{code:java}
me@me-VM:~$ cd ~/.indy-cli/networks/sandbox
me@me-VM:~/.indy-cli/networks/sandbox$ ll
total 16
drwxr-xr-x 2 me me 4096 Nov 6 11:29 ./
drwxr-xr-x 5 me me 4096 Nov 6 11:22 ../
-rw-r--r-- 1 root root 2121 Nov 6 11:22 domain_transactions_genesis
-rw-r--r-- 1 root root 2276 Nov 6 11:22 pool_transactions_genesis{code}
Owner should be _me_.

*Case 6:*

Genesis files for node (in /var/lib/indy/NETWORK_NAME) are executable:

 
{code:java}
me@me-VM:~/.indy-cli/networks/sandbox$ ll /var/lib/indy/sandbox/
total 16
drwxrwxr-x 2 indy indy 4096 Nov 6 11:22 ./
drwxrwxr-x 5 indy indy 4096 Nov 6 11:22 ../
-rwxrwxr-- 1 indy indy 2121 Nov 6 11:22 domain_transactions_genesis*
-rwxrwxr-- 1 indy indy 2276 Nov 6 11:22 pool_transactions_genesis*
 
{code}
Geneses files should not be executable.

*Case 7:*
Need to update dockerfiles to initialize client for indy user on node machine.
(RUN generate_sovrin_pool_transactions --nodes $nodecnt --clients $clicnt --ips ""$ips"");;;","08/Nov/17 12:16 AM;ozheregelya;*Case 8:*

Client data (/home/indy/.indy, /home/indy/.indy/wallets, /home/indy/.indy/dCancelata/clients) should not be removed from .indy directory.;;;","08/Nov/17 8:01 PM;VladimirWork;*Case 9:*

Build Info:
indy-node 1.2.199

Steps to Reproduce:
1. Perform pool upgrade command to 1.2.201 version.

Actual Results:
Upgrade is failed due to duplicated logging parameter at the same line as another parameter in config file:

{quote}Nov 08 09:15:43 1bcb81aa9e29 env[1387]:   File ""/usr/local/bin/start_indy_node"", line 9, in <module>
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:     config = getConfig()
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:   File ""/usr/local/lib/python3.5/dist-packages/indy_common/config_util.py"", line 19, in getConfig
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:     extend_with_default_external_config(config, user_config_dir)
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/common/config_util.py"", line 41, in extend_with_default_external_config
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:     extend_with_external_config(extendee, (extendee.GENERAL_CONFIG_DIR, extendee.GENERAL_CONFIG_FILE))
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/common/config_util.py"", line 32, in extend_with_external_config
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:     config = getInstalledConfig(*extender)
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:   File ""/usr/local/lib/python3.5/dist-packages/plenum/common/config_util.py"", line 26, in getInstalledConfig
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:     spec.loader.exec_module(config)
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:   File ""<frozen importlib._bootstrap_external>"", line 661, in exec_module
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:   File ""<frozen importlib._bootstrap_external>"", line 767, in get_code
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:   File ""<frozen importlib._bootstrap_external>"", line 727, in source_to_code
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:   File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:   File ""/etc/indy/indy_config.py"", line 16
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:     NETWORK_NAME = 'sandbox'enableStdOutLogging=False
Nov 08 09:15:43 1bcb81aa9e29 env[1387]:                                               ^
Nov 08 09:15:43 1bcb81aa9e29 env[1387]: SyntaxError: invalid syntax{quote}

Expected Results:
There should be no duplicated parameters in config. Upgrade should be performed normally. !screenshot-1.png|thumbnail! ;;;","08/Nov/17 11:23 PM;ozheregelya;-Case 10:-  invalid for indy-node 1.2.203
 indy-node upgrare from 1.2.180 to 1.2.202

Steps to Reproduce:
 1. Setup the pool with 1.2.180 indy node (before file folder changes)
 2. Upgrade indy-node to 1.2.202 and all depending packages using apt-get install.
 3. Run migrations (see instruction [https://docs.google.com/document/d/1vUvbioL5OsmZMSkwRcu0p0jdttJO5VS8K3GhDLdNaoI/edit|https://docs.google.com/document/d/1vUvbioL5OsmZMSkwRcu0p0jdttJO5VS8K3GhDLdNaoI/edit)] )
 4. Send NYM transaction.
 => Message about successful writing of transaction appear in cli.
 5. Send GET_NYM for this NYM.
 => GET_NYM didn't return anything.
 6. Send one more NYM transaction.
 => Message about successful writing of transaction appear in cli.
 5. Send GET_NYM for this NYM.
 => GET_NYM didn't return anything.
 6. Run read_ledger for this transaction.
 => Olly first NYM was written.
 !Screenshot_2017-11-08_12-17-51.png|thumbnail!

UPD: For indy-node 1.2.203 writing works correctly. Problem with reading is caused by not upgraded CLI. Backward compatibility with old client will be additionally tested during verification analog of live pool upgrade. 

Actual Results:
 Writing and reading transactions work strange.

Expected Results:
 All transactions should be written. Reading should work.

Additional Information:
 Attached logs: [^Node1.log] [^Node2.log] [^Node3.log] [^Node4.log];;;","09/Nov/17 12:50 AM;VladimirWork;*Case 11:*

Build Info:
indy-node 1.2.203

Actual Results:
Agents store their wallets in /var/lib/indy/:
INFO     | walleted_agent.py    (130) | _saveWallet | Active wallet ""Faber College"" saved (/var/lib/indy/wallets/agents/faber-college/faber college.wallet)
INFO     | walleted_agent.py    (130) | _saveWallet | Active wallet ""issuer"" saved (/var/lib/indy/wallets/agents/faber-college/issuer/issuer.wallet)

Expected Results:
Agents should store their wallets in ~/.indi-cli/.;;;","09/Nov/17 4:54 AM;ozheregelya;Additional information for case 9:
 Here is content of /etc/indy/indy_config.py after manual migration:
{code:java}
enableStdOutLogging=False
baseDir = '/var/lib/indy'
NODE_BASE_DATA_DIR = baseDir
LOG_DIR = '/var/log/indy'
BACKUP_DIR = '/var/lib/indy/backup'
CLI_BASE_DIR = '~/.indy-cli/'
CLI_NETWORK_DIR = '~/.indy-cli/networks'
NODE_BASE_DATA_DIR = baseDir
NETWORK_NAME = 'sandbox'
enableStdOutLogging=False
LOG_SIZE=999
NETWORK_NAME = 'sandbox'
{code}
Only following parameters were duplicated: enableStdOutLogging and NETWORK_NAME.;;;","09/Nov/17 7:48 PM;VladimirWork;*Case 12:*

Build Info:
indy-node 1.1.43 (stable)

Steps to Reproduce:
1. Perform pool upgrade to 1.2.203 (master) version.

Actual Results:
Migration script 1_1_150_to_1_1_151.py applying is failed due to FindNotFound error (/home/indy/.indy). !1.1.43-1.2.203.PNG|thumbnail! 

Expected Results:
Pool upgrade from stable to master should work normally.;;;","10/Nov/17 2:36 AM;ozheregelya;UPD for Case 12:
Migration fails in the next step on 1.2.205 version:
{code:java}
Nov 09 17:20:17 53bbae2d4c60 env[84]: 2017-11-09 17:20:17,430 | DEBUG | node_control_tool.py (201) | _create_backup | Creating backup for 1.1.43
Nov 09 17:20:17 53bbae2d4c60 env[84]: 2017-11-09 17:20:17,740 | INFO | migration_tool.py (52) | migrate | Migrating from 1.1.43 to 1.2.205 on Ubuntu
Nov 09 17:20:17 53bbae2d4c60 env[84]: 2017-11-09 17:20:17,748 | DEBUG | migration_tool.py (54) | migrate | Found migration scripts: ['1_0_96_to_1_0_97', '1_1_150_to_1_
Nov 09 17:20:17 53bbae2d4c60 env[84]: 2017-11-09 17:20:17,748 | INFO | migration_tool.py (61) | migrate | Following migrations will be applied: ['1_1_150_to_1_1_151',
Nov 09 17:20:17 53bbae2d4c60 env[84]: 2017-11-09 17:20:17,749 | INFO | migration_tool.py (63) | migrate | Applying migration 1_1_150_to_1_1_151
Nov 09 17:20:17 53bbae2d4c60 env[84]: 2017-11-09 17:20:17,749 | INFO | migration_tool.py (35) | _call_migration_script | script path /usr/local/lib/python3.5/dist-pac
Nov 09 17:20:19 53bbae2d4c60 env[84]: 2017-11-09 17:20:19,080 | INFO | migration_tool.py (67) | migrate | Migration 1_1_150_to_1_1_151 applied in 1.33109450340271 sec
Nov 09 17:20:19 53bbae2d4c60 env[84]: 2017-11-09 17:20:19,080 | INFO | migration_tool.py (63) | migrate | Applying migration 1_1_152_to_1_1_153
Nov 09 17:20:19 53bbae2d4c60 env[84]: 2017-11-09 17:20:19,081 | INFO | migration_tool.py (35) | _call_migration_script | script path /usr/local/lib/python3.5/dist-pac
Nov 09 17:20:20 53bbae2d4c60 env[84]: 2017-11-09 17:20:20,309 | DEBUG | __init__.py (60) | register | Registered VCS backend: git
Nov 09 17:20:20 53bbae2d4c60 env[84]: 2017-11-09 17:20:20,410 | DEBUG | __init__.py (60) | register | Registered VCS backend: hg
Nov 09 17:20:20 53bbae2d4c60 env[84]: 2017-11-09 17:20:20,640 | DEBUG | __init__.py (60) | register | Registered VCS backend: svn
Nov 09 17:20:20 53bbae2d4c60 env[84]: 2017-11-09 17:20:20,676 | DEBUG | __init__.py (60) | register | Registered VCS backend: bzr
Nov 09 17:20:21 53bbae2d4c60 env[84]: 2017-11-09 17:20:21,046 | INFO | 1_1_152_to_1_1_153.py (18) | <module> | script path /usr/local/lib/python3.5/dist-packages/data/mi
Nov 09 17:20:21 53bbae2d4c60 su[3035]: Successful su for indy by root
Nov 09 17:20:21 53bbae2d4c60 su[3035]: + ??? root:indy
Nov 09 17:20:21 53bbae2d4c60 su[3035]: pam_env(su:session): Unable to open env file: /etc/default/locale: No such file or directory
Nov 09 17:20:21 53bbae2d4c60 su[3035]: pam_unix(su:session): session opened for user indy by (uid=0)
Nov 09 17:20:21 53bbae2d4c60 env[84]: Can not find the directory with the ledger: /var/lib/indy/data/nodes
Nov 09 17:20:21 53bbae2d4c60 env[84]: Traceback (most recent call last):
Nov 09 17:20:21 53bbae2d4c60 env[84]: File ""/usr/local/lib/python3.5/dist-packages/data/migrations/deb/helper_1_1_152_to_1_1_153.py"", line 40, in <module>
Nov 09 17:20:21 53bbae2d4c60 env[84]: migrate_all()
Nov 09 17:20:21 53bbae2d4c60 env[84]: File ""/usr/local/lib/python3.5/dist-packages/data/migrations/deb/helper_1_1_152_to_1_1_153.py"", line 33, in migrate_all
Nov 09 17:20:21 53bbae2d4c60 env[84]: nodes_data_dir = _get_nodes_data_dir()
Nov 09 17:20:21 53bbae2d4c60 env[84]: File ""/usr/local/lib/python3.5/dist-packages/data/migrations/deb/helper_1_1_152_to_1_1_153.py"", line 19, in _get_nodes_data_dir
Nov 09 17:20:21 53bbae2d4c60 env[84]: raise Exception(msg)
Nov 09 17:20:21 53bbae2d4c60 env[84]: Exception: Can not find the directory with the ledger: /var/lib/indy/data/nodes
Nov 09 17:20:21 53bbae2d4c60 su[3035]: pam_unix(su:session): session closed for user indy
Nov 09 17:20:21 53bbae2d4c60 env[84]: 2017-11-09 17:20:21,704 | ERROR | 1_1_152_to_1_1_153.py (28) | <module> | Migration failed: script returned 1
Nov 09 17:20:21 53bbae2d4c60 env[84]: Traceback (most recent call last):
Nov 09 17:20:21 53bbae2d4c60 env[84]: File ""/usr/local/lib/python3.5/dist-packages/data/migrations/deb/1_1_152_to_1_1_153.py"", line 29, in <module>
Nov 09 17:20:21 53bbae2d4c60 env[84]: raise Exception(msg)
Nov 09 17:20:21 53bbae2d4c60 env[84]: Exception: Migration failed: script returned 1
Nov 09 17:20:21 53bbae2d4c60 env[84]: 2017-11-09 17:20:21,964 | ERROR | migration_tool.py (44) | _call_migration_script | Migration failed: script returned 1
Nov 09 17:20:21 53bbae2d4c60 env[84]: 2017-11-09 17:20:21,964 | DEBUG | node_control_tool.py (206) | _restore_from_backup | Restoring from backup for 1.1.43
Nov 09 17:20:21 53bbae2d4c60 env[84]: 2017-11-09 17:20:21,967 | WARNING | node_control_tool.py (213) | _restore_from_backup | Copying last_version failed due to [Errno 2] N
Nov 09 17:20:21 53bbae2d4c60 env[84]: 2017-11-09 17:20:21,967 | WARNING | node_control_tool.py (213) | _restore_from_backup | Copying next_version failed due to [Errno 2] N
Nov 09 17:20:21 53bbae2d4c60 env[84]: 2017-11-09 17:20:21,967 | WARNING | node_control_tool.py (213) | _restore_from_backup | Copying upgrade_log failed due to [Errno 2] No
Nov 09 17:20:21 53bbae2d4c60 env[84]: 2017-11-09 17:20:21,967 | WARNING | node_control_tool.py (213) | _restore_from_backup | Copying last_version_file failed due to [Errno
Nov 09 17:20:22 53bbae2d4c60 env[84]: 2017-11-09 17:20:22,126 | WARNING | node_control_tool.py (222) | _restore_from_backup | Copying last_version failed due to [Errno 2] N
Nov 09 17:20:22 53bbae2d4c60 env[84]: 2017-11-09 17:20:22,152 | WARNING | node_control_tool.py (222) | _restore_from_backup | Copying next_version failed due to [Errno 2] N
Nov 09 17:20:22 53bbae2d4c60 env[84]: 2017-11-09 17:20:22,152 | WARNING | node_control_tool.py (222) | _restore_from_backup | Copying upgrade_log failed due to [Errno 2] No
Nov 09 17:20:22 53bbae2d4c60 env[84]: 2017-11-09 17:20:22,152 | WARNING | node_control_tool.py (222) | _restore_from_backup | Copying last_version_file failed due to [Errno
Nov 09 17:20:22 53bbae2d4c60 env[84]: 2017-11-09 17:20:22,153 | DEBUG | node_control_tool.py (233) | _remove_old_backups | Removing old backups
Nov 09 17:20:22 53bbae2d4c60 env[84]: 2017-11-09 17:20:22,153 | ERROR | node_control_tool.py (265) | _upgrade | Unexpected error in _upgrade Migration failed: script retu
Nov 09 17:20:22 53bbae2d4c60 env[84]: 2017-11-09 17:20:22,153 | INFO | node_control_tool.py (257) | _upgrade | Trying to upgrade from 1.1.43 to 1.1.43
Nov 09 17:20:22 53bbae2d4c60 env[84]: 2017-11-09 17:20:22,153 | INFO | node_control_tool.py (163) | _call_upgrade_script | Upgrading sovrin node to version 1.1.43, test_
Nov 09 17:20:22 53bbae2d4c60 env[84]: 2017-11-09 17:20:22,153 | INFO | node_control_tool.py (142) | _get_deps_list | Getting dependencies for indy-node=1.1.43
Nov 09 17:20:22 53bbae2d4c60 env[84]: WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
Nov 09 17:20:28 53bbae2d4c60 env[84]: E: Version '1.1.43' for 'indy-node' was not found
Nov 09 17:20:28 53bbae2d4c60 env[84]: E: No packages found
Nov 09 17:20:28 53bbae2d4c60 env[84]: 2017-11-09 17:20:28,096 | ERROR | node_control_tool.py (265) | _upgrade | Unexpected error in _upgrade Command 'apt-cache show indy-
Nov 09 17:20:28 53bbae2d4c60 env[84]: 2017-11-09 17:20:28,096 | DEBUG | node_control_tool.py (293) | start | Waiting for the next event
Nov 09 17:20:28 53bbae2d4c60 env[84]: 2017-11-09 17:20:28,096 | DEBUG | node_control_tool.py (315) | start | Closing socket with fd 5
Nov 09 17:20:28 53bbae2d4c60 env[84]: 2017-11-09 17:20:28,096 | DEBUG | node_control_tool.py (293) | start | Waiting for the next event{code};;;","10/Nov/17 10:16 PM;VladimirWork;*Case 13:*

Build Info:
indy-node 1.1.43 (stable)

Steps to Reproduce:
1. Perform manual client machine upgrade (via apt-get install indy-node) to 1.2.203 (master).
2. Check ~/.indy-cli/networks/NETWORK_NAME/ for genesis files.

Actual Results:
There is no domain genesis file in the folder (but there is pool genesis file).

Expected Results:
There should be both genesis files in this folder.

Additional Info:
Client works normally in despite of genesis file absence, so this is a minor issue.;;;","15/Nov/17 1:23 AM;VladimirWork;Verified according to https://docs.google.com/spreadsheets/d/15_9oh8apbzSfjyAdLydl8ToEM692Jce44I2CSfULYkw/edit#gid=0.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Split indy-plenum CD pipeline to CI and CD parts,INDY-834,20773,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,gudkov,gudkov,12/Sep/17 11:00 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,Must,,,,,"Current CD pipeline is complex and contains closed parts:
- SovrinHelpers library that is setup as jar on Jenkins
- Secrets: Keys and accounts

Community suggests the following:
- Split CD pipeline to CI and CD parts
- CI part must be as simple as possible. Ideally, doesn't require specific Jenkins setup to be executed
- CD part can keep all current CD logic and secrets.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzyiin:",,,,,,13,14,,,,,,,3.0,,,,,,,,,,,,andkononykhin,gudkov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Sep/17 9:29 PM;andkononykhin;Changes:
 * created Jenkinsfile.ci (static code validation + testing), doesn't depends from any Groovy shared library
 * created Jenkinsfile.cd as a copy of legacy Jenkinsfile
 * reconfigured pipelines:
 ** Current pipeline watches only for changes in master and stable repos. It uses Jenkinsfile.cd.
 ** Added CI pipeline which watches for PRs only. It uses Jenkinsfile.ci
 ** Created folder as container to hold two pipelines above

PRs:
 * [https://github.com/hyperledger/indy-plenum/pull/386]
 * [https://github.com/hyperledger/indy-plenum/pull/392]

How to test:
 * checked that all mentioned files are presented in indy-plenum repo
 * check configuration of plenum's  CI and CD pipelines:
 ** https://ci.evernym.com/job/Indy-Plenum/
 ** PRs are built in CI pipeline
 ** master/stable are held by CD pipeline

Note. Currently CD pipeline uses legacy Jenkinsfile. We can't switch it to Jenkinsfile.cd until changes are merged into stable branch. Will do that after new release happens.;;;","25/Sep/17 7:46 PM;ozheregelya;Version Info:
indy-plenum 1.1.133

Following things were verified:
 * Jenkinsfile.ci and Jenkinsfile.cd files present in indy-plenum repository
 * There are two pipelines for indy-plenum in jenkins: Core: Indy-Plenum CD and Core: Indy-Plenum CI
 * PRs are built in CI pipeline
 * master/stable are held by CD pipeline;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Split indy-node CD pipeline to CI and CD parts,INDY-835,20774,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,gudkov,gudkov,12/Sep/17 11:00 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"Current CD pipeline is complex and contains closed parts:
- SovrinHelpers library that is setup as jar on Jenkins
- Secrets: Keys and accounts

Community suggests the following:
- Split CD pipeline to CI and CD parts
- CI part must be as simple as possible. Ideally, doesn't require specific Jenkins setup to be executed
- CD part can keep all current CD logic and secrets.",,,,,,,,,,,,,,,,,,,,,,,INDY-580,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzyiiv:",,,,,,13,14,,,,,,,3.0,,,,,,,,,,,,andkononykhin,gudkov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Sep/17 9:31 PM;andkononykhin;Changes:
 * created Jenkinsfile.ci (static code validation + testing), doesn't depends from any Groovy shared library
 * created Jenkinsfile.cd as a copy of legacy Jenkinsfile
 * reconfigured pipelines:
 ** Current pipeline watches only for changes in master and stable repos. It uses Jenkinsfile.cd.
 ** Added CI pipeline which watches for PRs only. It uses Jenkinsfile.ci
 ** Created folder as container to hold two pipelines above

PR:
 * [https://github.com/hyperledger/indy-node/pull/357]

How to test:
 * checked that all mentioned files are presented in indy-node repo
 * check configuration of node's  CI and CD pipelines:
 ** [https://ci.evernym.com/job/Indy-Node|https://ci.evernym.com/job/Indy-Node/]
 ** PRs are built in CI pipeline
 ** master/stable are held by CD pipeline

Note. Currently CD pipeline uses legacy Jenkinsfile. We can't switch it to Jenkinsfile.cd until changes are merged into stable branch. Will do that after new release happens.;;;","25/Sep/17 7:44 PM;ozheregelya;Version Info:
indy-node 1.1.143

Following things were verified:
 * Jenkinsfile.ci and Jenkinsfile.cd files present in indy-node repository
 * There are two pipelines for indy-node in jenkins: Core: Indy-Node CI and Core: Indy-Node CD
 * PRs are built in CI pipeline
 * master/stable are held by CD pipeline;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Some test scripts are still using CIDs instead of DIDs,INDY-836,20775,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,ozheregelya,ozheregelya,12/Sep/17 11:05 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"*Steps to Reproduce:*
 1. Set up the pool and client.
 2. On client machine run one of following scripts:
{code:java}
test_some_write_keys_others_read_them --writers 4 --readers 20 --iterations 10
test_users_write_and_read_own_keys --users 20 --iterations 10{code}
*Actual Results:*
 Following exceptions appear:
{code:java}
Traceback (most recent call last):
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 60, in run
 self.do()
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 153, in do
 self.setNym(id, verkey)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 160, in setNym
 VERKEY: verkey
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 90, in performOperation
 assert not error, error
AssertionError: client request invalid: CouldNotAuthenticate('Can not find verkey for DID FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4',)
concurrent.futures.process._RemoteTraceback: 
""""""
Traceback (most recent call last):
 File ""/usr/lib/python3.5/concurrent/futures/process.py"", line 175, in _process_worker
 r = call_item.fn(*call_item.args, **call_item.kwargs)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 51, in runInstance
 cls(*args, **kwargs).run()
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 69, in run
 raise ex
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 60, in run
 self.do()
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 153, in do
 self.setNym(id, verkey)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 160, in setNym
 VERKEY: verkey
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 90, in performOperation
 assert not error, error
AssertionError: client request invalid: CouldNotAuthenticate('Can not find verkey for DID FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4',)
""""""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
 File ""/usr/local/bin/test_users_write_and_read_own_keys"", line 113, in <module>
 main(parseArgs())
 File ""/usr/local/bin/test_users_write_and_read_own_keys"", line 81, in main
 nymsCreationScenarioFuture.result(timeout=timeout)
 File ""/usr/lib/python3.5/concurrent/futures/_base.py"", line 405, in result
 return self.__get_result()
 File ""/usr/lib/python3.5/concurrent/futures/_base.py"", line 357, in __get_result
 raise self._exception
AssertionError: client request invalid: CouldNotAuthenticate('Can not find verkey for DID FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4',)
{code}
*Expected Results:*
 Scripts should work.

*Additional Information:*
 After manual adding of specified CID
{code:java}
send NYM dest=FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4 role=STEWARD verkey=FYmoFw55GeQH7SRFa37dkx1d2dZ3zUF8ckg7wmL7ofN4{code}
and second running of the script
{code:java}
me@me-VirtualBox:~/.sovrin$ test_users_write_and_read_own_keys --users 20 --iterations {code}
following exceptions appear:
{code:java}
2017-09-12 16:22:57,566 | ERROR | user_scenarios.py ( 68) | run | User scenario throws out exception: 'data'
Traceback (most recent call last):
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 60, in run
 self.do()
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 153, in do
 self.setNym(id, verkey)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 160, in setNym
 VERKEY: verkey
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 92, in performOperation
 if reply[DATA]:
KeyError: 'data'
concurrent.futures.process._RemoteTraceback: 
""""""
Traceback (most recent call last):
 File ""/usr/lib/python3.5/concurrent/futures/process.py"", line 175, in _process_worker
 r = call_item.fn(*call_item.args, **call_item.kwargs)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 51, in runInstance
 cls(*args, **kwargs).run()
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 69, in run
 raise ex
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 60, in run
 self.do()
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 153, in do
 self.setNym(id, verkey)
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 160, in setNym
 VERKEY: verkey
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/utils/user_scenarios.py"", line 92, in performOperation
 if reply[DATA]:
KeyError: 'data'
""""""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
 File ""/usr/local/bin/test_users_write_and_read_own_keys"", line 113, in <module>
 main(parseArgs())
 File ""/usr/local/bin/test_users_write_and_read_own_keys"", line 81, in main
 nymsCreationScenarioFuture.result(timeout=timeout)
 File ""/usr/lib/python3.5/concurrent/futures/_base.py"", line 405, in result
 return self.__get_result()
 File ""/usr/lib/python3.5/concurrent/futures/_base.py"", line 357, in __get_result
 raise self._exception
KeyError: 'data'
{code}",,,,,,,,,,,,,,INDY-355,INDY-354,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx11r:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/18 12:39 PM;krw910;[~ozheregelya] Is this a won't fix like the ones it is linked to?;;;","07/Nov/18 6:54 PM;Derashe;these scripts are outdated.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Move CI part of pipelines to Hyperledger infrastructure,INDY-837,20776,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,andkononykhin,gudkov,gudkov,12/Sep/17 11:05 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,CI parts of all pipelines must be moved to Hyperledger infrastructure.,,ryjones,,,,,,,,,,,,,,,,,,,,,,,,,INDY-945,INDY-963,INDY-1132,INDY-1133,INDY-1140,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzyvrz:",,,,,,13,14,INDY 17.21,INDY 17.22,Sprint 18.02 Stability,"Sprint 18.03 Stability, DKMS",,,5.0,,,,,,,,,,,,andkononykhin,gudkov,ryjones,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Sep/17 3:38 PM;andkononykhin;There is a blocker for now: no access to Hyperledger's Jenkins server, waiting for response from its administrators.;;;","23/Nov/17 10:14 PM;andkononykhin;Current state:
 * configuration for jobs were implemented and tested (actually they works on Evernym's Jenkins server)
 * change was pushed to Hypereldger's Gerrit [https://gerrit.hyperledger.org/r/#/c/15243/], was approved and merged but reverted soon because of some strange issue on Hyperledger's production server
 * [~ry] works on that and related issues. Once he finished with them we expect to be merged and start ci testing on Hyperledger server;;;","13/Dec/17 5:46 AM;ryjones;Still blocked on JJB 2.0;;;","13/Dec/17 10:10 PM;andkononykhin;[~ryjones] Configuration files for indy jobs that are proposed do not require JJB 2.0.0: raw xml feature of JJB is used to overcome that for pipeline type of jobs. Why do you think that it is blocked by it?;;;","18/Jan/18 7:55 AM;ryjones;I think this particular work item is done. The change was merged and the jobs are live.;;;","31/Jan/18 9:12 PM;andkononykhin;Current state:
 * indy-anoncreds pipeline is ready
 * indy-plenum and indy-node: need to complete set up of GitHub webhook (set correct secret token), can be done by hyperledger admins only;;;","02/Feb/18 6:03 PM;andkononykhin;Currently I see that push notifications from GitHub work well (thanks [~ryjones]). The task could be marked as done. But we need to optimize builds: add our base docker images into OpenStack minions, also seems one-time on-demand minions are not so good for our pipelines cause we have several stages each require node that could lead to instantiation of several one-time minions per build. I will create tasks for that.;;;","02/Feb/18 6:17 PM;andkononykhin;INDY-1132 and INDY-1133 were created for things described in upper comment;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Incubation: Check that Indy Node, CLI and SDK can be used on one PC",INDY-838,20777,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,gudkov,gudkov,12/Sep/17 11:10 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"It must be possible to easy setup and use Indy Node, Indy CLI and Indy SDK on one PC.",,,,,,,,,,,INDY-831,INDY-832,INDY-833,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzymon:",,,,,,13,14,INDY 17.21,INDY 17.22,INDY 17.23,,,,5.0,,,,,,,,,,,,gudkov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Nov/17 7:51 PM;VladimirWork;Build Info:
indy-node 1.2.210 (master)
libindy 1.1.0 (master)

Steps to Validate:
1. Install pool with docker.
2. Run CLI on any node and send some commands.
3. Install libindy to any node:
{quote}apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 68DB5E88
sudo add-apt-repository ""deb https://repo.sovrin.org/sdk/deb xenial master""
sudo apt update
sudo apt-get install -y libindy{quote}
4. Clone indy-sdk repository to this node.
5. Run python wrapper acceptance test on installed pool:
{quote}python3.5 -m pip install -e .
python3.5 src/main.py{quote}
6. Check results.

Actual Results:
Any node of the pool can be used as client (CLI) and libindy installed also works with this pool.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool_upgrade does not work on some versions due to usage of incorrect migration scripts,INDY-840,20799,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,,ozheregelya,ozheregelya,13/Sep/17 10:06 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Steps to Reproduce:
 1. Set up the pool with indy-node version from following range:
 master: 1.1.113 - 1.1.131
 rc (stable): 1.1.33, 1.1.34
 2. Using CLI send valid POOL_UPGRADE command.

Actual Results:
 Pool was not upgraded, following error appears in journalctl:
{code:java}
Sep 13 10:15:31 californiaPerf1.qatest.evernym.com env[27174]: 2017-09-13 10:15:31,176 | ERROR    | node_control_tool.py (265) | _upgrade | Unexpected error in _upgrade No module named 'data/migrations', trying to rollback to the previous version 1.1.130{code}
Expected Results:
 Pool should be upgraded.

Workaround:
 Use manual upgrade (using package manager and manual starting of migration scripts https://docs.google.com/document/d/1vUvbioL5OsmZMSkwRcu0p0jdttJO5VS8K3GhDLdNaoI/edit).",,,,,,,,,,,,,,,,,,,,,INDY-846,,,,,,,,,,,,,,"13/Sep/17 9:58 PM;ozheregelya;Node1.7z;https://jira.hyperledger.org/secure/attachment/12098/Node1.7z","13/Sep/17 9:57 PM;ozheregelya;Node2.7z;https://jira.hyperledger.org/secure/attachment/12097/Node2.7z","13/Sep/17 9:57 PM;ozheregelya;Node3.7z;https://jira.hyperledger.org/secure/attachment/12096/Node3.7z","13/Sep/17 9:58 PM;ozheregelya;Node4.7z;https://jira.hyperledger.org/secure/attachment/12095/Node4.7z","13/Sep/17 9:57 PM;ozheregelya;Node5.7z;https://jira.hyperledger.org/secure/attachment/12094/Node5.7z","13/Sep/17 9:57 PM;ozheregelya;Node6.7z;https://jira.hyperledger.org/secure/attachment/12093/Node6.7z","13/Sep/17 9:57 PM;ozheregelya;Node7.7z;https://jira.hyperledger.org/secure/attachment/12092/Node7.7z","13/Sep/17 9:58 PM;ozheregelya;out.txt;https://jira.hyperledger.org/secure/attachment/12091/out.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzygq7:",,,,,,12,13,,,,,,,,,,,,,,,,,,,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/17 10:46 PM;VladimirWork;Will not be fixed according to 09/14/2017 discussion (because 1.0.28->1.1.35->1.1.37 upgrades works normally). Acceptance upgrade scenario is changed according to current upgrade test strategy and also will be changed after implementation of INDY-857.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testStewardCannotAddNodeWithNonBase58VerKey  fails intermittently,INDY-841,20801,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,andkononykhin,andkononykhin,13/Sep/17 10:23 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,tests,,,,,"Test: testStewardCannotAddNodeWithNonBase58VerKey
 Path: plenum/test/pool_transactions/test_nodes_with_pool_txns.py
[Logs|^testStewardCannotAddNodeWithNonBase58VerKey.log.txt]
 [Jenkins build|https://ci.evernym.com/job/Plenum/job/PR-376/1/] (temporarily available)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Sep/17 10:24 PM;andkononykhin;testStewardCannotAddNodeWithNonBase58VerKey.log.txt;https://jira.hyperledger.org/secure/attachment/12099/testStewardCannotAddNodeWithNonBase58VerKey.log.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1ef:",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/18 5:36 PM;sergey-shilov;Validation procedure was reviewed and improved, also working with connections was changed, this issue is not reproduced any more and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test_view_change_in_between_3pc_all_nodes_random_delays fails intermittently,INDY-842,20802,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,andkononykhin,andkononykhin,13/Sep/17 10:29 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,should,tests,,,,"Test: test_view_change_in_between_3pc_all_nodes_random_delays
 Path: plenum/test/view_change/slow_nodes/test_view_change_all_nodes_random_delay.py
 [Logs|^test_view_change_in_between_3pc_all_nodes_random_delays.log.txt]
 [Jenkins build|https://ci.evernym.com/job/Plenum/job/PR-374/1/] (temporarily available)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Sep/17 10:31 PM;andkononykhin;test_view_change_in_between_3pc_all_nodes_random_delays.log.txt;https://jira.hyperledger.org/secure/attachment/12100/test_view_change_in_between_3pc_all_nodes_random_delays.log.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx0mn:",,,,,,14,INDY 17.21,,,,,,,,,,,,,,,,,,,andkononykhin,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/18 5:26 PM;sergey-shilov;Several fixes were made for view change procedure. Also the test timeouts were reviewed and tuned, so this issue is not reproduced any more and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testProtocolInstanceCannotBecomeActiveWithLessThanFourServers fails intermittently,INDY-843,20803,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,andkononykhin,andkononykhin,13/Sep/17 10:32 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,should,tests,,,,"Test: testProtocolInstanceCannotBecomeActiveWithLessThanFourServers
Path: plenum/test/instances/test_instance_cannot_become_active_with_less_than_four_servers.py
[Logs|^testProtocolInstanceCannotBecomeActiveWithLessThanFourServers.log.txt]
[Jenkins build|https://ci.evernym.com/job/Plenum/view/change-requests/job/PR-378/2/]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Sep/17 10:33 PM;andkononykhin;testProtocolInstanceCannotBecomeActiveWithLessThanFourServers.log.txt;https://jira.hyperledger.org/secure/attachment/12101/testProtocolInstanceCannotBecomeActiveWithLessThanFourServers.log.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx0mv:",,,,,,14,INDY 17.21,,,,,,,,,,,,,,,,,,,andkononykhin,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/18 5:32 PM;sergey-shilov;Working with remotes was reviewed and improved, issue is not reproduced any more and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need version check for nodes,INDY-844,20805,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,danielhardman,danielhardman,13/Sep/17 11:19 PM,11/Oct/19 6:51 PM,28/Oct/23 2:47 AM,,,,,,0,,,,,,"Whenever a node is activated (powered on, rebooted, etc), it should check with its network to find out what version of the software it should be running. If the node is not running the version that the network expects, we need to record a message in the logs, and also echo a message to stderr. This will help with a case where a sysadmin tries to join a node to the network without realizing that his/her node isn't running the correct version of the software.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-2249,,,,,,,,,,"1|hzx193:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
don't accept a duplicate genesis transaction,INDY-845,20809,,Bug,To Develop,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,danielhardman,danielhardman,14/Sep/17 12:47 AM,13/Nov/19 12:17 AM,28/Oct/23 2:47 AM,,,,,,0,,,,,,"Steps to Reproduce:
1. Install pool.
2. Duplicate any key in domain_transactions_sandbox_genesis at any node.
3. Start all nodes.

Actual Results:
Node with malformed this way genesis file cannot catch up with other nodes due to incorrect transaction tree root and marks all other nodes as suspicious so it doesn't participate in consensus (see log for more info).

Desired behavior:

Node should emit an error about duplicate transaction making genesis file invalid, then exit.",,,,,,,,,,,,,,,,,,,,,,,INDY-26,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzx1dj:",,,,,,,,,,,,,,,,,,,,,,,,,,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failed to upgrade from 1.1.33 to 1.1.35 in STN,INDY-846,20816,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,VladimirWork,mgbailey,mgbailey,14/Sep/17 5:15 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"When attempting to upgrade the STN using a ledger transaction, all nodes in the pool failed to upgrade. The sovrin-node processes remained in an inactive state., and the packages  It appears that some required files and directories were not found.

History: The nodes in this pool had been at version 1.0.28.  When upgrading previously to 1.1.33, one node failed to upgrade properly, and then had further issues joining the pool after a manual upgrade.  Eventually, we fell back to bringing all nodes in the pool down, restoring to a fresh ledger by deleting the .sovrin/data, .sovrin/plugins, and .sovrin/__pycache__ directories, and bringing the pool back up.  After doing this, consensus was achieved with all nodes.

The logs in all nodes look similar.  The sovrin and syslog logs for one node are attached. I will attempt to determine steps to reproduce this in an internal test pool.

The current package configuration is:

{{ubuntu@korea:~$ dpkg -l | grep sovrin}}
{{ii sovrin 1.0.3 amd64 Sovrin node}}
{{ubuntu@korea:~$ dpkg -l | grep indy}}
{{ii indy-anoncreds 1.0.10 amd64 Anonymous credentials}}
{{ii indy-node 1.1.33 amd64 Sovrin node}}
{{ii indy-plenum 1.1.24 amd64 Plenum Byzantine Fault Tolerant Protocol}}","STN, running 1.1.33",,,,,,,,,,,,,,,,,,,,,INDY-840,,,,,,,,,,,,,"14/Sep/17 5:12 AM;mgbailey;korea_sovrin_log.tgz;https://jira.hyperledger.org/secure/attachment/12105/korea_sovrin_log.tgz","14/Sep/17 5:12 AM;mgbailey;korea_syslog.tgz;https://jira.hyperledger.org/secure/attachment/12104/korea_syslog.tgz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzygqn:",,,,,,12,13,,,,,,,,,,,,,,,,,,,mgbailey,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Sep/17 5:42 AM;mgbailey;The pool was able to return to its pre-upgrade state by restarting the processes on each node manually;;;","14/Sep/17 4:19 PM;VladimirWork;INDY-840 is the same issue. There is ""Unexpected error in _upgrade No module named 'data/migrations', trying to rollback to the previous version 1.1.33"" in the logs.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Error message is not shown when steward tries to add one more node,INDY-847,20819,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,ozheregelya,ozheregelya,14/Sep/17 5:49 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"*Steps to Reproduce:*
1. Create new steward:
{code:java}
new key with seed 000000000000000000000000Trustee1
send NYM dest=XhYtvJqezMUKfF6KVNaGmT role=STEWARD verkey=~RmCt3RtDvKDfQBSKxo4qvy{code}
2. As newly created steward, add node.
{code:java}
new key with seed StewardNode500000000000000000000
send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.0.0.105', 'alias':'Node5', 'node_ip': '10.0.0.105', 'node_port': 9701, 'services': ['VALIDATOR']}{code}
3. As the same steward try to add one more node.

{code:java}
send NODE dest=6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G data={'client_port': 9702, 'client_ip': '10.0.0.106', 'alias': 'Node6', 'node_ip': '10.0.0.106', 'node_port': 9701, 'services': ['VALIDATOR']}{code}


*Actual Results:*
Nothing happened.

*Expected Results:*
Error message that this steward already has a node should be shown.","Build Info:
  indy-node 1.1.37
  indy-anoncreds 1.1.10
  indy-plenum 1.1.27
  sovrin 1.1.6
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 6 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-778,,,,,,,,,,"1|hzx19b:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 4:40 PM;Derashe;In actual code if steward trying to add one more node, error appears:
{code:java}
plenum.common.exceptions.RequestRejectedException: Reject of id 1539157281379106626. Reason: client request invalid: UnauthorizedClientRequest('RD8XH5v6qZMJPb8caWQQ24 already has a node',){code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Primary node is broken after view change,INDY-848,20823,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,ozheregelya,ozheregelya,14/Sep/17 9:34 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"The problem reproduces not stable. Steps to reproduce are unclear. Here is possible procedure:
 1. Set up the pool of 6 nodes.
 2. Run load test with following parameters on two clients:
 python3 load_test.py -t NYM -c 20 -r 100 --at-once
 3. Look at nodes logs.

Actual Results:
 Node1 (which was primary) missed several view changes, it also doesn't processing any transactions. Following information is shown in logs of Node1:
{code:java}
2017-09-14 11:19:08,826 | INFO | node.py (1967) | _start_view_change_if_possible | VIEW CHANGE: Node1 starting view change for 31 after 2 view change indications from other nodes
2017-09-14 11:19:08,827 | INFO | node.py (2159) | startViewChange | VIEW CHANGE: Node1 changed to view 31, will start catchup now
2017-09-14 11:19:08,830 | ERROR | primary_selector.py ( 167) | _verify_primary | PRIMARY SELECTION: Node1 expected next primary to be Node2, but majority declared Node3 instead for view 31
2017-09-14 11:19:08,831 | ERROR | primary_selector.py ( 167) | _verify_primary | PRIMARY SELECTION: Node1 expected next primary to be Node2, but majority declared Node3 instead for view 31
2017-09-14 11:19:08,831 | ERROR | primary_selector.py ( 167) | _verify_primary | PRIMARY SELECTION: Node1 expected next primary to be Node2, but majority declared Node3 instead for view 31
2017-09-14 11:19:08,849 | INFO | node.py (1489) | preLedgerCatchUp | Node1 reverted 0 batches before starting catch up for ledger 0
2017-09-14 11:19:08,857 | ERROR | primary_selector.py ( 167) | _verify_primary | PRIMARY SELECTION: Node1 expected next primary to be Node2, but majority declared Node3 instead for view 31
2017-09-14 11:19:08,875 | INFO | node.py (1489) | preLedgerCatchUp | Node1 reverted 0 batches before starting catch up for ledger 2
2017-09-14 11:19:08,877 | INFO | upgrader.py ( 150) | should_notify_about_upgrade_result | Node's 'Node1' last upgrade txn is None
2017-09-14 11:19:08,877 | INFO | ledger_manager.py ( 848) | catchupCompleted | CATCH-UP: Node1 completed catching up ledger 2, caught up 0 in total
2017-09-14 11:19:08,877 | INFO | ledger_manager.py ( 848) | catchupCompleted | CATCH-UP: Node1 completed catching up ledger 0, caught up 1 in total
2017-09-14 11:19:08,899 | INFO | node.py (1489) | preLedgerCatchUp | Node1 reverted 0 batches before starting catch up for ledger 1
2017-09-14 11:19:08,926 | INFO | ledger_manager.py ( 848) | catchupCompleted | CATCH-UP: Node1 completed catching up ledger 1, caught up 3 in total
2017-09-14 11:19:08,927 | INFO | node.py (1525) | allLedgersCaughtUp | CATCH-UP: Node1 caught up till (31, 4)
2017-09-14 11:19:08,927 | INFO | node.py (1537) | allLedgersCaughtUp | CATCH-UP: Node1 does not need any more catchups
2017-09-14 11:19:08,928 | ERROR | primary_selector.py ( 167) | _verify_primary | PRIMARY SELECTION: Node1 expected next primary to be Node2, but majority declared Node3 instead for view 31
2017-09-14 11:20:08,831 | INFO | node.py (1019) | _check_view_change_completed | view change to view 31 is not completed in time, starting view change for view 32
2017-09-14 11:20:08,831 | INFO | node.py (1021) | _check_view_change_completed | VIEW CHANGE: Node1 initiating a view change to 32 from 31
2017-09-14 11:20:08,831 | INFO | node.py (2048) | sendInstanceChange | VIEW CHANGE: Node1 sending an instance change with view_no 32 since View change could not complete in time
2017-09-14 11:23:46,913 | INFO | propagator.py ( 148) | propagate | Node1 propagating request ('Th7MpTaRZVRYnPiabds81Y', 1505388226898996) from client I}w?$na9^IYnNXu-w!$nejVFV@w*.KQ#*M%-LZh6
2017-09-14 11:23:47,916 | INFO | propagator.py ( 148) | propagate | Node1 propagating request ('Th7MpTaRZVRYnPiabds81Y', 1505388227905354) from client b'I}w?$na9^IYnNXu-w!$nejVFV@w*.KQ#*M%-LZh6'
2017-09-14 11:23:48,921 | INFO | propagator.py ( 148) | propagate | Node1 propagating request ('Th7MpTaRZVRYnPiabds81Y', 1505388228909014) from client I}w?$na9^IYnNXu-w!$nejVFV@w*.KQ#*M%-LZh6
2017-09-14 11:23:49,925 | INFO | propagator.py ( 148) | propagate | Node1 propagating request ('Th7MpTaRZVRYnPiabds81Y', 1505388229912259) from client I}w?$na9^IYnNXu-w!$nejVFV@w*.KQ#*M%-LZh6
2017-09-14 11:23:50,929 | INFO | propagator.py ( 148) | propagate | Node1 propagating request ('Th7MpTaRZVRYnPiabds81Y', 1505388230917988) from client b'I}w?$na9^IYnNXu-w!$nejVFV@w*.KQ#*M%-LZh6'
2017-09-14 11:23:51,940 | INFO | propagator.py ( 148) | propagate | Node1 propagating request ('Th7MpTaRZVRYnPiabds81Y', 1505388231921568) from client I}w?$na9^IYnNXu-w!$nejVFV@w*.KQ#*M%-LZh6
2017-09-14 11:23:52,939 | INFO | propagator.py ( 148) | propagate | Node1 propagating request ('Th7MpTaRZVRYnPiabds81Y', 1505388232925218) from client I}w?$na9^IYnNXu-w!$nejVFV@w*.KQ#*M%-LZh6
2017-09-14 11:23:53,931 | INFO | propagator.py ( 148) | propagate | Node1 propagating request ('Th7MpTaRZVRYnPiabds81Y', 1505388233929200) from client b'I}w?$na9^IYnNXu-w!$nejVFV@w*.KQ#*M%-LZh6'
2017-09-14 11:23:54,951 | INFO | propagator.py ( 148) | propagate | Node1 propagating request ('Th7MpTaRZVRYnPiabds81Y', 1505388234934584) from client I}w?$na9^IYnNXu-w!$nejVFV@w*.KQ#*M%-LZh6
2017-09-14 11:23:55,948 | INFO | propagator.py ( 148) | propagate | Node1 propagating request ('Th7MpTaRZVRYnPiabds81Y', 1505388235938861) from client b'I}w?$na9^IYnNXu-w!$nejVFV@w*.KQ#*M%-LZh6'
2017-09-14 11:23:55,954 | WARNING | replica.py ( 722) | readyFor3PC | Node1:0 is getting requests but still does not have a primary so the replica will not process the request until a primary is chosen
2017-09-14 11:23:55,954 | WARNING | replica.py ( 722) | readyFor3PC | Node1:1 is getting requests but still does not have a primary so the replica will not process the request until a primary is chosen{code}
Expected Results:
 Old primary should work without problems.

Additional Information:
Several nodes (including Node1) were restarted in the end of load tests.","Build Info:
  indy-node 1.1.37
  indy-anoncreds 1.1.10
  indy-plenum 1.1.27
  sovrin 1.1.6
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 6 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Sep/17 9:41 PM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/12106/Node1.log","14/Sep/17 9:41 PM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/12107/Node2.log","14/Sep/17 9:41 PM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/12108/Node3.log","14/Sep/17 9:41 PM;ozheregelya;Node4.log;https://jira.hyperledger.org/secure/attachment/12109/Node4.log","14/Sep/17 9:41 PM;ozheregelya;Node5.log;https://jira.hyperledger.org/secure/attachment/12110/Node5.log","14/Sep/17 9:41 PM;ozheregelya;Node6.log;https://jira.hyperledger.org/secure/attachment/12111/Node6.log","25/Oct/17 10:38 PM;VladimirWork;view_changes_node_1.PNG;https://jira.hyperledger.org/secure/attachment/12814/view_changes_node_1.PNG","25/Oct/17 10:38 PM;VladimirWork;view_changes_node_4.PNG;https://jira.hyperledger.org/secure/attachment/12815/view_changes_node_4.PNG","25/Oct/17 10:38 PM;VladimirWork;view_changes_under_load.PNG;https://jira.hyperledger.org/secure/attachment/12816/view_changes_under_load.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk6n:",,,,,,12,13,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,andkononykhin,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/17 1:55 AM;andkononykhin;Created a PR: https://github.com/hyperledger/indy-plenum/pull/422;;;","23/Oct/17 7:36 PM;andkononykhin;Problem reason:
 - when node is promoted after demotion other nodes haven't updated parameters in memory. Consequences: non-sync pool ledger and memory, (possible) non-sync pool parameters between different nodes (e.g. after one other node is restarted after demoted node promotion getting pool parameters directly from pool ledger)

Changes:
 - triggering pool parameters update not only for newly added/promoted node but also for the one which was previously demoted
 - logging improvements

Committed into:
 - [https://github.com/hyperledger/indy-plenum/pull/422]

Risk factors:
 - Nothing is expected.

Risk:
 - Low

Covered with tests:
 - {{plenum/test/primary_selection/test_primary_selection_after_demoted_node_promotion.py}}

Recommendations for QA: do the following sequence of steps
 * start pool of 4 nodes
 * promote new one
 * demote and promote it again
 * restart one of the nodes from the original pool (after restart it will get pool parameters from pool ledger file)
 * initiate force view change at least 3 times and ensure from logs that all nodes choose the same nodes as primaries for all protocol instances: after 3 times - 5th node should be primary for backup instance, after 4 times - 5th is primary for master one;;;","25/Oct/17 10:38 PM;VladimirWork;Build Info:
indy-node 1.2.181

Steps to Validate - Case 1:
1. Start pool of 4 nodes.
2. Promote new one.
3. Demote and promote it again.
4. Restart one of the nodes from the original pool (after restart it will get pool parameters from pool ledger file).
5. Initiate force view change at least 3 times and ensure from logs that all nodes choose the same nodes as primaries for all protocol instances.

Steps to Validate - Case 2:
1. Set up the pool of 6 nodes.
2. Run load test with following parameters on two clients: python3 load_test.py -t NYM -c 20 -r 100 --at-once
3. Look at nodes logs.

Actual Results:
Primaries at all nodes are the same after each view change. There are no missing view changes at the primaries. Primary node works normally after each view change. !view_changes_node_1.PNG|thumbnail!  !view_changes_node_4.PNG|thumbnail!  !view_changes_under_load.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool can't be restored after losing consensus if at least one view change was happened,INDY-849,20830,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,ozheregelya,ozheregelya,15/Sep/17 1:01 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,Must,,,,,"Case 1:
 Steps to Reproduce:
 1. Set up the pool of 3 nodes.
 2. Make view change (i.e. restart primary node).
 3. Send transaction to make sure that pool works.
 4. Stop services on any node.
 5. Send NYM transaction.
 6. Start services on stopped node.
 7. Send NYM transaction.

Actual Results:
 Transactions were not written, consensus was not reached.

Expected Results:
 Pool should back to consensus.

 

Case 2:
 Steps to Reproduce:
 1. Set up the pool of 3 nodes.
 2. Send NYM transaction.
 3. Stop services on not primary node.
 4. Send NYM transaction.
 5. Start services back on stopped node.
 6. Send NYM transaction.
 => 2 NTMs were written.
 7. Stop services on primary node.
 8. Send NYM transaction.
 9. Start stopped node.
 10. Send NYM transaction.
 => 2 transactions were written. View Change was happened, new primary node was chosen.
 11. Stop services on old primary node.
 12. Send NYM transaction.
 13. Start old primary back.

Actual Results:
 Transactions were not written, consensus was not reached.

Expected Results:
 Pool should back to consensus.

 

Additional Information:
The same problem is reproduces for pool of 6 nodes. Case with 3 nodes was described as the most simple.","Build Info:
  indy-node 1.1.37
  indy-anoncreds 1.1.10
  indy-plenum 1.1.27
  sovrin 1.1.6
OS/Platform: Ubuntu 16.04.2 LTS
Setup: 6 nodes, 1 client",,,,,,,,,,,,,,,,,,,,,INDY-152,INDY-804,,,,,,,,,,,,"15/Sep/17 1:02 AM;ozheregelya;Node1.log;https://jira.hyperledger.org/secure/attachment/12112/Node1.log","15/Sep/17 1:02 AM;ozheregelya;Node2.log;https://jira.hyperledger.org/secure/attachment/12113/Node2.log","15/Sep/17 1:02 AM;ozheregelya;Node3.log;https://jira.hyperledger.org/secure/attachment/12114/Node3.log","20/Sep/17 9:19 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/12128/Screenshot.PNG","20/Sep/17 9:19 PM;VladimirWork;Screenshot_.PNG;https://jira.hyperledger.org/secure/attachment/12129/Screenshot_.PNG","21/Sep/17 6:55 PM;VladimirWork;Screenshot__.PNG;https://jira.hyperledger.org/secure/attachment/12134/Screenshot__.PNG","21/Sep/17 6:55 PM;VladimirWork;_node1.log;https://jira.hyperledger.org/secure/attachment/12135/_node1.log","20/Oct/17 6:23 PM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/12702/_node1.txt","21/Sep/17 6:55 PM;VladimirWork;_node2.log;https://jira.hyperledger.org/secure/attachment/12136/_node2.log","20/Oct/17 6:23 PM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/12703/_node2.txt","21/Sep/17 6:55 PM;VladimirWork;_node3.log;https://jira.hyperledger.org/secure/attachment/12137/_node3.log","20/Oct/17 6:23 PM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/12704/_node3.txt","20/Oct/17 6:23 PM;VladimirWork;_node4.txt;https://jira.hyperledger.org/secure/attachment/12705/_node4.txt","20/Oct/17 6:23 PM;VladimirWork;consensus.PNG;https://jira.hyperledger.org/secure/attachment/12701/consensus.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk5j:",,,,,,12,13,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,andrey.goncharov,mzk-vct,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/17 9:31 PM;andrey.goncharov;PR opened https://github.com/hyperledger/indy-plenum/pull/382;;;","19/Sep/17 10:32 PM;andrey.goncharov;Problem reason: 
- request not all required messages

Changes: 
- added requesting missing messages

Committed into:
https://github.com/hyperledger/indy-plenum/commit/45c91ce7f794d1d85d33ba0d4c0be71172e6f20e
indy-plenum/master 1.1.130

Risk factors:
 Nothing is expected.

Risk:
 Low

Covered with tests:
https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/node_request/message_request/test_node_request_missing_three_phase_messages.py;;;","20/Sep/17 9:18 PM;VladimirWork;Build Info:
indy-node 1.1.141

Case 1:
Steps to Validate:
1. Set up the pool of 3 nodes.
2. Make view change (i.e. restart primary node).
3. Send transaction to make sure that pool works.
4. Stop services on any node.
5. Send NYM transaction.
6. Start services on stopped node.
7. Send NYM transaction.

Actual Results:
Pool comes back to consensus.

 
Case 2:
Steps to Validate:
1. Set up the pool of 3 nodes.
2. Send NYM transaction.
3. Stop services on not primary node.
4. Send NYM transaction.
5. Start services back on stopped node.
6. Send NYM transaction.
=> 2 NTMs were written.
7. Stop services on primary node.
8. Send NYM transaction.
9. Start stopped node.
10. Send NYM transaction.
=> 2 transactions were written. View Change was happened, new primary node was chosen.
11. Stop services on old primary node.
12. Send NYM transaction.
13. Start old primary back.

Actual Results:
Pool comes back to consensus.

Additional Info:
Consensus is also checked with 6 and 7 nodes pools.;;;","21/Sep/17 6:55 PM;VladimirWork;The issue is reproducing again during testing of INDY-868 with another variation of Case 1:

Build Info:
indy-node 1.1.142

Case 1:
Steps to Reproduce:
1. Set up the pool of 3 nodes.
2. Make view change (i.e. restart primary node).
3. Send transaction to make sure that pool works.
4. Stop services on any node.
5. Send NYM transaction.
*6. Wait 10+ minutes.*
7. Start services on stopped node.
8. Send NYM transaction.

Actual Results:
Pool doesn't come back to consensus. !Screenshot__.PNG|thumbnail! 

Expected Result:
Pool should come back to consensus.

Additional Info:
There are missing pre-prepares in Node1.log (see attachments). [^_node1.log]  [^_node2.log]  [^_node3.log] ;;;","06/Oct/17 11:55 PM;mzk-vct;The reason is that preprepares have a life time. When replica receives outdated preprepare it discards it and marks sender as suspicious.;;;","06/Oct/17 11:56 PM;mzk-vct;There is a special case - if there are enough prepares life time is ignored. Perhaps this mechanism has a bug.;;;","25/Oct/17 9:00 PM;mzk-vct;Pull request to plenum https://github.com/hyperledger/indy-plenum/pull/415;;;","27/Oct/17 12:50 AM;VladimirWork;Build Info:
indy-node 1.2.186

Steps to Validate:
1. Set up the pool of 3 nodes.
2. Make view change (i.e. restart primary node).
3. Send transaction to make sure that pool works.
4. Stop services on any node.
5. Send NYM transaction.
6. Wait 10+ minutes.
7. Start services on stopped node.
8. Send NYM transaction.

Actual Results:
Pool works normally.

Additional Info:
Also checked with another f count (7 nodes).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DOC: Request for release notes on Indy-node 1.1.37,INDY-850,20835,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ozheregelya,ozheregelya,15/Sep/17 4:04 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,documentation,,,,,"*Version Information*
 indy-node 1.1.37
 indy-anoncreds 1.0.10
 indy-plenum 1.1.27
 sovrin 1.1.6

*Major Fixes*
 INDY-786 - fixed problem when the pool was writing transactions when more than F nodes were stopped
 INDY-808 - Manual upgrade fixed
 INDY-760 - fixed problem when the pool was broken after processing lots of transactions at once
 INDY-804 - fixed problem when the pool doesn't come back to consensus (case when less than n-f nodes are alive)
 INDY-761 - partially fixed problem when the pool responded with outdated data

*Changes and Additions*
 INDY-716 - ""debug"" mode for tests was moved to parameter
 INDY-800 - Log levels were changed on some debug level message to an info level

*Known Issues*
 INDY-849 - If the pool loses enough nodes and cannot reach consensus when enough nodes become available the pool still will not reach consensus. 
 Workaround for INDY-849 - If you restart all nodes in the pool it will start reaching consensus again.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyihj:",,,,,,12,13,14,,,,,,,,,,,,,,,,,,ozheregelya,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Sep/17 6:08 AM;TechWritingWhiz;This work is completed and is in pull request: https://github.com/sovrin-foundation/sovrin/pull/24;;;","18/Sep/17 7:24 PM;ozheregelya;Changes were reviewed. Documentation looks good.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to use sovrin package version for pool upgrade instead of indy-node version,INDY-851,20841,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,,ozheregelya,ozheregelya,15/Sep/17 8:24 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"From conversation with [~krw910]:
{quote}
I am in a meeting talking about plugging in a sovrin piece on top of indy to deal with tokens. In order to do something like this we would need to be upgrading using the sovrin package not the indy package. I don't have details yet it is still being designed.
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzygif:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Sep/17 6:56 AM;krw910;I need to get more information about this plugin to find out if it installs as a part of indy-node or separately. In either case we need to be upgrading the sovrin package when performing an upgrade.;;;","04/Sep/18 10:51 PM;ashcherbakov;Done in INDY-1471;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incorrect transaction fields' constraints,INDY-852,20842,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,VladimirWork,VladimirWork,15/Sep/17 8:43 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,should,,,,,"Build Info:
indy-node 1.1.134

Steps to Reproduce - Case 1:
0. Login as Trustee.
1. send SCHEMA name=Degree version=1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111.11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111.111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111 keys=undergrad,last_name,first_name,birth_date,postgrad,expiry_date

Actual Results:
The following schema is published to the Sovrin distributed ledger...Sequence number is 30.
 
Expected Results:
We should add some validation (about 16 or 128 as max?) for ""version"" attribute, because now we can send 1024+ chars in it.


Steps to Reproduce - Case 2:
0. Login as Trustee.
1. send CLAIM_DEF ref=16 signature_type=CLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCLCL

Actual Results:
In 617 iterations, found prime 16588191782994323122975708446126707113022746136322835518069910531704777222371121307846835296695807547324646674696357625698228391623149616099004338627192875431052230317381749
In 129 iterations, found prime 15081128388203406640905998096007010940543334738547626084248744619521111357048790683330677838329326480880906221441703868983372143472554712293142273519416027407733726260127209
The claim definition was published to the Sovrin distributed ledger:
Sequence number is 29. 

Expected Results:
There should be an validation error (LIMIT=16). Claim definition should not be published.",,,,,,,,,,,,,,,,,,,,,,,INDY-756,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk5r:",,,,,,13,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,dsurnin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Oct/17 5:37 PM;dsurnin;case 1: is fixed

case 2: it looks like the CLAIM_DEF command is not fully parsed in client, only the ref parameter is checked and the other parameters are filled with default values. current cli is not important for now, so it was decided not to fix it.

plenum 0ef4b9b48d793684a87362c07a676f08d3a49cb5

node a9da89b3733b3f5c7bfe1f40b77e77b91cdf1903

new test test_max_length_limit

 ;;;","27/Oct/17 12:11 AM;VladimirWork;Build Info:
indy-node 1.2.186

Steps to Validate:
0. Login as Trustee.
1. send SCHEMA name=Degree version=1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111.11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111.111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111 keys=undergrad,last_name,first_name,birth_date,postgrad,expiry_date

Actual Results:
InvalidClientRequest('validation error [SchemaField]: 1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111... is longer than 128 symbols.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLI crashes with traceback containing MemoryError if too large transaction was send,INDY-853,20843,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,,ozheregelya,ozheregelya,15/Sep/17 8:56 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*Steps to Reproduce:*
1. Set up the pool with clients on nano amazon instances.
2. Open the CLI, send large transaction [^length.txt]

*Actual Result:*
CLI crashed with following traceback:
{code:java}
Error while running coroutine shell: MemoryError()
Traceback (most recent call last):
 File ""/usr/local/bin/sovrin"", line 78, in <module>
 run_cli()
 File ""/usr/local/bin/sovrin"", line 56, in run_cli
 looper.run(cli.shell(*commands))
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 259, in run
 return self.loop.run_until_complete(what)
 File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
 return future.result()
 File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
 raise self._exception
 File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
 result = coro.send(None)
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 250, in wrapper
 raise ex
 File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 237, in wrapper
 results.append(await coro)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1160, in shell
 self.parse(c)
 File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 1967, in parse
 m = self.grammar.match(cmdText)
 File ""/usr/lib/python3/dist-packages/prompt_toolkit/contrib/regular_languages/compiler.py"", line 238, in match
 m = self._re.match(string)
MemoryError{code}

*Expected Results:*
Traceback should not be shown.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/17 8:54 PM;ozheregelya;length.txt;https://jira.hyperledger.org/secure/attachment/12116/length.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1r3:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:47 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Traceback appears when CLI is interrupted during loading,INDY-854,20847,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,,ozheregelya,ozheregelya,15/Sep/17 9:04 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*Steps to Reproduce:*
1. Set up the client.
2. Run the CLI.
3. Interrupt CLI during loading.

*Actual Results:*
Traceback is shown:

 
{code:java}
agent@agent01:~/load$ sovrin
Loading module /usr/local/lib/python3.5/dist-packages/config/config-crypto-example1.py
Module loaded.
^CTraceback (most recent call last):
 File ""/usr/lib/python3/dist-packages/pip/_vendor/__init__.py"", line 33, in vendored
 __import__(vendored_name, globals(), locals(), level=0)
ImportError: No module named 'pip._vendor.cachecontrol'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
 File ""/usr/share/python-wheels/requests-2.9.1-py2.py3-none-any.whl/requests/packages/__init__.py"", line 27, in <module>
ImportError: cannot import name 'urllib3'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
 File ""/usr/local/bin/sovrin"", line 37, in <module>
 from sovrin_client.cli.cli import SovrinCli
 File ""/usr/local/lib/python3.5/dist-packages/sovrin_client/cli/cli.py"", line 21, in <module>
 from plenum.cli.cli import Cli as PlenumCli
 File ""/usr/local/lib/python3.5/dist-packages/plenum/cli/cli.py"", line 74, in <module>
 from plenum.server.node import Node
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 64, in <module>
 from plenum.server.monitor import Monitor
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/monitor.py"", line 22, in <module>
 from plenum.server.notifier_plugin_manager import notifierPluginTriggerEvents, \
 File ""/usr/local/lib/python3.5/dist-packages/plenum/server/notifier_plugin_manager.py"", line 1, in <module>
 import pip
 File ""/usr/lib/python3/dist-packages/pip/__init__.py"", line 13, in <module>
 from pip.exceptions import InstallationError, CommandError, PipError
 File ""/usr/lib/python3/dist-packages/pip/exceptions.py"", line 6, in <module>
 from pip._vendor.six import iteritems
 File ""/usr/lib/python3/dist-packages/pip/_vendor/__init__.py"", line 64, in <module>
 vendored(""cachecontrol"")
 File ""/usr/lib/python3/dist-packages/pip/_vendor/__init__.py"", line 36, in vendored
 __import__(modulename, globals(), locals(), level=0)
 File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
 File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
 File ""<frozen importlib._bootstrap>"", line 664, in _load_unlocked
 File ""<frozen importlib._bootstrap>"", line 634, in _load_backward_compatible
 File ""/usr/share/python-wheels/CacheControl-0.11.5-py2.py3-none-any.whl/cachecontrol/__init__.py"", line 9, in <module>
 File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
 File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
 File ""<frozen importlib._bootstrap>"", line 664, in _load_unlocked
 File ""<frozen importlib._bootstrap>"", line 634, in _load_backward_compatible
 File ""/usr/share/python-wheels/CacheControl-0.11.5-py2.py3-none-any.whl/cachecontrol/wrapper.py"", line 1, in <module>
 File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
 File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
 File ""<frozen importlib._bootstrap>"", line 664, in _load_unlocked
 File ""<frozen importlib._bootstrap>"", line 634, in _load_backward_compatible
 File ""/usr/share/python-wheels/CacheControl-0.11.5-py2.py3-none-any.whl/cachecontrol/adapter.py"", line 3, in <module>
 File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
 File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
 File ""<frozen importlib._bootstrap>"", line 664, in _load_unlocked
 File ""<frozen importlib._bootstrap>"", line 634, in _load_backward_compatible
 File ""/usr/share/python-wheels/requests-2.9.1-py2.py3-none-any.whl/requests/__init__.py"", line 53, in <module>
 File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
 File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
 File ""<frozen importlib._bootstrap>"", line 664, in _load_unlocked
 File ""<frozen importlib._bootstrap>"", line 634, in _load_backward_compatible
 File ""/usr/share/python-wheels/requests-2.9.1-py2.py3-none-any.whl/requests/packages/__init__.py"", line 29, in <module>
 File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
 File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
 File ""<frozen importlib._bootstrap>"", line 664, in _load_unlocked
 File ""<frozen importlib._bootstrap>"", line 634, in _load_backward_compatible
 File ""/usr/share/python-wheels/urllib3-1.13.1-py2.py3-none-any.whl/urllib3/__init__.py"", line 8, in <module>
 File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
 File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
 File ""<frozen importlib._bootstrap>"", line 664, in _load_unlocked
 File ""<frozen importlib._bootstrap>"", line 634, in _load_backward_compatible
 File ""/usr/share/python-wheels/urllib3-1.13.1-py2.py3-none-any.whl/urllib3/connectionpool.py"", line 35, in <module>
 File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
 File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
 File ""<frozen importlib._bootstrap>"", line 664, in _load_unlocked
 File ""<frozen importlib._bootstrap>"", line 634, in _load_backward_compatible
 File ""/usr/share/python-wheels/urllib3-1.13.1-py2.py3-none-any.whl/urllib3/connection.py"", line 11, in <module>
 File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
 File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
 File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked
 File ""<frozen importlib._bootstrap_external>"", line 661, in exec_module
 File ""<frozen importlib._bootstrap_external>"", line 765, in get_code
 File ""<frozen importlib._bootstrap_external>"", line 476, in _compile_bytecode
KeyboardInterrupt
{code}
*Expected Results:*
Traceback should not be shown.

 ","Build Info:
  indy-node 1.1.37
  indy-anoncreds 1.1.10
  indy-plenum 1.1.27
  sovrin 1.1.6
OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1rb:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:48 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Remove all non-Indy branding from indy-anoncreds repo,INDY-855,20848,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,danielhardman,spivachuk,spivachuk,15/Sep/17 9:43 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"We need to remove all non-Indy branding and names from indy-anoncreds repo:
* Package names
* Code primitive names
* Paths
* Documentation

Ideally, if full-text search for Sovrin and Evernym will return nothing.",,,,,,,,,,,,,,,,,,,,,,,INDY-885,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzyiif:",,,,,,13,14,,,,,,,3.0,,,,,,,,,,,,andkononykhin,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/17 1:51 AM;andkononykhin;[https://github.com/hyperledger/indy-anoncreds/pull/94]

https://github.com/hyperledger/indy-anoncreds/pull/95

All copyrights and comments related to code origins have been left intact;;;","21/Sep/17 5:49 PM;VladimirWork;Сopyrights, comments related to code origins and references to CI/sovrin.org have been left intact only.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Split indy-anoncreds CD pipeline to CI and CD parts,INDY-856,20849,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,danielhardman,spivachuk,spivachuk,15/Sep/17 9:53 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"Current CD pipeline is complex and contains closed parts:
- SovrinHelpers library that is setup as jar on Jenkins
- Secrets: Keys and accounts

Community suggests the following:
- Split CD pipeline to CI and CD parts
- CI part must be as simple as possible. Ideally, doesn't require specific Jenkins setup to be executed
- CD part can keep all current CD logic and secrets.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzyij3:",,,,,,13,14,,,,,,,3.0,,,,,,,,,,,,andkononykhin,ozheregelya,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Sep/17 9:33 PM;andkononykhin;Changes:
 * created Jenkinsfile.ci (static code validation + testing), doesn't depends from any Groovy shared library
 * created Jenkinsfile.cd as a copy of legacy Jenkinsfile
 * reconfigured pipelines:
 ** Current pipeline watches only for changes in master and stable repos. It uses Jenkinsfile.cd.
 ** Added CI pipeline which watches for PRs only. It uses Jenkinsfile.ci
 ** Created folder as container to hold two pipelines above

PR:
 * [https://github.com/hyperledger/indy-anoncreds/pull/96]

How to test:
 * checked that all mentioned files are presented in indy-anoncreds repo
 * check configuration of anoncreds'  CI and CD pipelines:
 ** [https://ci.evernym.com/job/Indy-Anoncreds|https://ci.evernym.com/job/Indy-Anoncreds/]
 ** PRs are built in CI pipeline
 ** master/stable are held by CD pipeline

Note. Currently CD pipeline uses legacy Jenkinsfile. We can't switch it to Jenkinsfile.cd until changes are merged into stable branch. Will do that after new release happens.;;;","25/Sep/17 7:16 PM;ozheregelya;Version Info:
indy-anoncreds 1.0.34

Following things were verified:
 * Jenkinsfile.ci and Jenkinsfile.cd files present in indy-anoncreds repository
 * There are two pipelines for indy-anoncreds in jenkins: Core: Indy-Anoncreds CD and Core: Indy-Anoncreds CI
 * PRs are built in CI pipeline
 * master/stable are held by CD pipeline;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to create fake build with higher than current RC version,INDY-857,20851,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,anikitinDSR,VladimirWork,VladimirWork,15/Sep/17 10:41 PM,11/Oct/19 6:51 PM,28/Oct/23 2:47 AM,11/Oct/19 6:51 PM,,,,,0,,,,,,"We need to create fake build with higher than current RC version for upgrade testing during acceptance testing.
Migration script should also be supported for this build.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1bb:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/17 11:16 PM;mzk-vct;[~krw910] Do you have something to add? Suggestions, thoughts?;;;","16/Sep/17 6:54 AM;krw910;[~mzk-vct] I like the idea of having a fake build to test. What we are trying to avoid is what we just had happen. A break in the upgrade process was introduced in a new build. The upgrade to that build was successful and there was no way to know the next upgrade would not work until it was tried. So that is the scenario we are trying to avoid by using this fake upgrade. We may need a different repo to hold this fake package and we can just change the sources.list file to point to this other location and I think that is fine. We want to keep it simple and not create a large amount of extra work. I would like to see a proposal on how we can accomplish this task.
Let also make sure we name the package to indicate what it is for so it does not accidentally get used. Something like ""SovrinUpgradeTestPackage"". Also have it provide the appropriate packages/files.;;;","11/Oct/19 6:51 PM;ashcherbakov;We don't have a need for this now;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Trustee, I need to be able to config Multisig parameters via config ledger",INDY-858,20872,,Story,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,ashcherbakov,ashcherbakov,ashcherbakov,18/Sep/17 8:15 PM,11/Oct/19 8:46 PM,28/Oct/23 2:47 AM,,,,,,0,should,,,,,"- Support MULTI_SIG_PARAMS txn in config ledger
-- Elliptic curve to use
-- generators
-- What groups (G1, G2, GT) should we use by default?
-- What functions should we choose as H and F?",,,,,,,,,,,,,,,,,,,,,,,INDY-670,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0q7:",,,,,,13,14,INDY 17.21,,,,,,5.0,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support historical BLS multi signatures,INDY-859,20873,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,ashcherbakov,ashcherbakov,ashcherbakov,18/Sep/17 8:26 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"As of now, we use and support only the multi-sig for the latest state. 
We need to support multi-sig for historical states to be able to query historical data.

The multi-sig storage (key-value db) uses state root as a key, so it's pretty trivial to store sigs for all required old states. 
We need to support some sort of catch-up for multi-sig storage.
We need to send multi-sigs  for previous batches on timeout if we didn't send new batches.",,,,,,,,,,,,,,,,,,,,,,,INDY-670,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-45,,,,,,,,,,"1|hzygmn:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
node control tool should be able to get updated and run migrations with the updated code,INDY-860,20874,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Deferred,andrey.goncharov,andrey.goncharov,andrey.goncharov,18/Sep/17 11:20 PM,11/Oct/19 6:38 PM,28/Oct/23 2:47 AM,11/Oct/19 6:38 PM,,,,,0,,,,,,"This ticket can go two ways:
 * an explicit explanation on how to upgrade a node control tool first and do an upgrade which requires the new tool can be created (an approach with intermittent releases) 
 * a specific mechanism can be developed and injected in the tool's code which allows code refresh before running the migrations",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzygmv:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/17 6:32 AM;krw910;[~andrey.goncharov] if this needs to occur lets do more than one release and not write a special tool. We need to know in advance that we will be running an upgrade to upgrade the tool and then another release to upgrade the product.;;;","11/Oct/19 6:38 PM;esplinr;This would still be a good feature to have, but we haven't needed it in the last two years. So we will defer doing it until it appears necessary.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Review existing scripts and cover necessary with tests,INDY-861,20875,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,andrey.goncharov,andrey.goncharov,andrey.goncharov,18/Sep/17 11:22 PM,11/Oct/19 6:44 PM,28/Oct/23 2:47 AM,11/Oct/19 6:44 PM,,,,,0,,,,,,Currently indy-node and indy-plenum contain a variety of scripts in scripts folder. All of them should be reviewed and deleted or covered with tests.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx1e7:",,,,,,,,,,,,,,,,,,,,,,,,,,andrey.goncharov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Sep/17 5:49 AM;krw910;[~andrey.goncharov] Please go through and log tickets just on the scripts that should be covered.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explore: What is the max transactions per second?,INDY-862,20878,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,19/Sep/17 1:12 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"What is the maximum number of transactions per second that can be written to the ledger? 
The ledger is design to queue requests. The question is how many requests can be sent at once before transactions are dropped and not everything was written to the ledger that was sent.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0g7:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Sep/17 6:46 PM;VladimirWork;The peak working throughput (before txns are dropped or pool is breaked) for 1 client sending requests (with --at-once option) is about 6..10 txns per second (varies strongly, additional investigation is needed).
The peak working throughput (before txns are dropped or pool is breaked) for many clients sending requests (via overmind.sh script, so not at once, but at the same time) is about 5..5.5 txns per second.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explore: Catch up time for large ledgers,INDY-863,20879,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,19/Sep/17 1:14 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"Some time ago a test was done where a new node was added to a pool that had 400,000 transactions. It took 2-3 days for that new node to catch up with the pool.

We need to retest this scenario by have a pool ledger of 400,000 transactions or more, then add a new node and see how long it takes for that node to catch up.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzwyo7:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Dec/17 7:47 PM;ozheregelya;Blocked by  problems with catch up: INDY-1018, INDY-1029.;;;","06/Apr/18 10:07 PM;ozheregelya;[~krw910], As intermediate result, we have 16min for catch-up of 100,000 transactions. Do we have any requirements for catch up time?;;;","18/Apr/18 12:42 AM;ozheregelya;Following results were gained:
 - 100,000 - 16 min
 - 200,000 - 27 min
 - 300,000 - 30 min

These results were discussed with Alex and he said that this is expected due to current design of catch-up procedure.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explore: Adding a new node and copying the existing ledger for manual catch up,INDY-864,20880,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,19/Sep/17 1:18 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,explore,,,,,"What is the process to manually catch up a node? If we have a ledger of 1 million transactions or more it could take days for it to catch up. If new transactions are continuing to be written to the ledger the new node may never catch up. 
We need a process in which a new node can be added and manually caught up. The process would allow the ledger to be copied to the new node and when it starts the first time it will be caught up to the pool or close enough it won't take long to get in sync.

The process will also allow for a disaster scenario so a single good ledger could be use to rebuild a pool.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1118,,,,,,,,,,"1|hzwyof:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Sep/17 6:17 AM;krw910;This goes with INDY-187. If we do not have steps then add comments to INDY-187.;;;","22/Sep/17 9:27 PM;VladimirWork;Intermediate results:
New added node with ledger copy catches up successfuly (checked with low amount of txns written after the ledger was copied).;;;","26/Dec/17 7:47 PM;ozheregelya;Blocked by  problems with catch up: INDY-1018, INDY-1029.;;;","07/Apr/18 10:30 PM;ozheregelya;*Environment:*
indy-node 1.3.362
AWS 25-nodes pool

*Things being tried:*
1.1. Adding node with only part of ledger (35,000 transactions on added node, 100,000 on the rest nodes).
1.2. Make sure that added node works fine by running load test. 
2.1. Adding node wit full copy of active node ledger (100,000 transactions).
2.2. Make sure that added node works fine by running load test. 

*Findings:*
""Manual catch-up"" works fine, all nodes were successfully added. There were only one issue - one node which was added with part of ledger, had some problems after adding. After load test it was not able to write about 10 transactions. Example: 100,000 transactions on all nodes after adding => writing 1000 transactions with load test => 101,000 txns on all nodes, 100,990 on added node => 1000 transactions more => 102,000 transactions on all nodes, 101,990 on the added node. Totally 5 nodes were added, but this behavior was noticed only on one of them. So, most probably this behavior resulted by current stability issues, not by ""manual catch-up"".

*General notes:*
""Manual catch-up"" for 100,000 txns ledger happens instantly, when usual catch-up takes about 16 minutes for this size.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explore: Adding new nodes with changed genesis files from original pool setup,INDY-865,20881,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,19/Sep/17 1:20 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,explore,,,,,"Consider this somewhat likely scenario:

There is an initial pool of 10 (called 1-10) validators.  Over time, an additional 5 (11-15) are added. Now say that #9 is deleted, and #7 is updated, so a new genesis file is created to reflect this.  Now add an additional validator.  On the first 15, which used the original genesis file, the ledger will be:

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
9 deletion
7 update
16

On the new node, assuming that the genesis file has the #9 deletion and the #7 update and none of the new nodes are added, what will it be?  This might be be the new genesis file:

1
2
3
4
5
6
8
10
7 update

Will the catchup be smart enough to recognize the different ordering?  The missing entry for #9?  That it already has the update for #7?  Are we at all concerned that even if the catchup works properly, the ledger for this node will not match the others entry-by-entry?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0fz:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Sep/17 1:58 AM;ozheregelya;No, catch up will fail because of different root hashes. 
 The main assumption of catch up logic is that roots are the same. It means that any node can miss some transactions, but it will not write anything before actualization its ledger. 

Steward initializes node based on this genesis file. After that, he is opens CLI and adds his node to the pool. The message ""<client_id> connected to NodeX"" will be shown, and it is true because specifier ports on specified IP are opened. But actually NodeX does not take part in consensus and does not work with the pool. Steward will see that node does not work with the pool only when he will look into validator info, or node ledger.

The next interesting thing in this case is CLI.
 - If steward will use the same incorrect genesis file for connection to pool, the CLI will not start because pool ledgers have different sizes and catch up of client ledger will fail. (This is correct and expected behavior.)
 - If steward will use genesis file with invalid content (invalid txnId or identifier fields) but the same size as pool ledger, catch up of client pool ledger will not happen because root hashes are not compared if pool ledgers sizes are the same and CLI will work and reconnect until any changes in pool ledger. This behavior is not quite correct, ticket for this: INDY-802. This case was additionally verified for node and node work correctly in this case: catch up will fail.
 - If steward will use valid genesis file for client, CLI will work without any problems.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explore: Can doing a ping in the Getting Started Tutorial delete the active wallet,INDY-866,20882,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,HeenaLulla,krw910,krw910,19/Sep/17 1:24 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,explore,,,,,"Our document writer found an issue that needs to be verified. While running through the Getting Started Tutorial she noticed we use the command ping to verify connection to the agents. The instructions do not have you ping 'Acme Corp', but she tried it.

When she ran 'ping Acme Corp' her active wallet was deleted. We need to verify this issue and log a bug if one is found.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzypv3:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
How does a client handle nodes' keys rotation?,INDY-867,20893,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,VladimirWork,VladimirWork,19/Sep/17 6:48 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,explore,,,,,"Overview:
We need to check how does a client handle nodes' keys rotation (and maybe add this check as new acceptance test scenario).

Steps to Validate:
1. Install pool of 4 nodes.
2. Connect to the pool with 2 clients.
3. Rotate nodes' keys from 1st client.
4. Check the 2nd client state.

Actual Results:
To be clarified.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0ef:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Dec/17 3:46 AM;ozheregelya;indy-node 1.2.251
indy-cli 1.1.1~297

Bls keys rotation was verified and it works correctly for both of old and new cli.

During connection to the pool client doing catch up with the ledger and it syncs pool transactions, so, it have latest data about node keys.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explore: How long will a transaction be held waiting for consensus?,INDY-868,20905,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,19/Sep/17 11:50 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,explore,,,,,"If the pool is unable to reach consensus for a transaction how long will it be held in the queue?

Have a pool fall below consensus and send a transaction to the pool. 
Bring the pool to the point it can reach consensus.

Does the transaction get written to the ledger? 
If so how long will it stay in the queue before it is dropped?

Track the time between sending the transaction and when the pool is able to reach consensus and writes the transaction to the ledger.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzy0gv:",,,,,,Exploratory Tests,,,,,,,,,,,,,,,,,,,,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Sep/17 8:10 PM;VladimirWork;There are 3 things found:
- if pool has lost consensus for 5 minutes or less: queued txn get written to the ledger by itself
- if pool has lost consensus for ~6..7 minutes: queued txn get not written to the ledger by itself, but next txn sent to ledger forces queued txn to get written too (so both txns are written, but is this behaviour good enough for us?)
- if pool has lost consensus for more than 8 minutes it doesn't return back to it by reaching n-f, so queued txn and all other txns sent later are not written to ledger (will be fixed in scope of INDY-849).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nodes are reverting to 1.1.33 when doing manual upgrade to 1.1.37,INDY-869,20942,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,mgbailey,mgbailey,21/Sep/17 8:03 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"Two weeks ago we upgraded the ESN to 1.1.33 using a ledger transaction.  The upgrade was successful, although no entries were seen on the config ledger to reflect this.  Today, I have been upgrading the nodes of the ESN manually (as required) to 1.1.37, one at a time.  I have seen that after doing ""sudo apt update"", ""sudo apt upgrade"", and ""sudo apt install indy-plenum indy-node"", that the correct packages are installed on the node.  

However, a few minutes after executing ""sudo systemctl start sovrin-node"", I notice that the packages have auto-reverted back to 1.1.33 and 1.1.24.  Looking in the logs (attached) I see at 17:17:14, that upgrader.py is running, and I see that there are now transactions in the config ledger (with today's timestamp) indicating that a successful upgrade to 1.1.33 was performed.

My theory is: when we upgraded to 1.1.33 two weeks ago, we had to use the --force flag, and we had the upgrade happen on all nodes at the same time.  This made it so that during the upgrade there was no consensus, and transactions could not be written to the config ledger.  Now, when we restarted the process today after upgrading to 1.1.37, it discovered an ""upgrade"" transaction pending in the config ledger, and actually downgraded it to 1.1.33.","ESN, running 1.1.33",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Sep/17 12:30 AM;mgbailey;journalctl.tgz;https://jira.hyperledger.org/secure/attachment/12142/journalctl.tgz","21/Sep/17 8:03 AM;mgbailey;majiyan_config_ledger.txt;https://jira.hyperledger.org/secure/attachment/12131/majiyan_config_ledger.txt","21/Sep/17 8:03 AM;mgbailey;majiyan_log.tgz;https://jira.hyperledger.org/secure/attachment/12130/majiyan_log.tgz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyl47:",,,,,,13,14,INDY 17.21,,,,,,,,,,,,,,,,,,andrey.goncharov,krw910,mgbailey,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Sep/17 3:42 AM;krw910;[~ashcherbakov] I would like someone to investigate this to make sure we don't have an upgrade issue that could affect us on the next upgrade.;;;","25/Sep/17 7:27 PM;andrey.goncharov;[~mgbailey] the logs are not completely informative. Could you provide journalctl logs and upgrade_log in .sovrin?;;;","26/Sep/17 12:22 AM;mgbailey;[~andrey.goncharov], I don't see journalctl logs:
{code:java}
sovrin@majiyan:~/.sovrin/data/nodes/majiyan$ locate journalctl
/bin/journalctl
/usr/share/bash-completion/completions/journalctl
/usr/share/man/man1/journalctl.1.gz
/usr/share/zsh/vendor-completions/_journalctl
{code}
Here is what is in the upgrade_log:
{code:java}
sovrin@majiyan:~/.sovrin/data/nodes/majiyan$ cat upgrade_log
2017-09-05 20:04:33.575341	scheduled	2017-09-05 15:05:33.555000-06:00	1.1.33
2017-09-05 21:05:32.577123	scheduled	2017-09-05 15:05:33.555000-06:00	1.1.33
2017-09-20 17:17:14.348492	scheduled	2017-09-05 15:05:33.555000-06:00	1.1.33	1504641873449143
2017-09-20 17:17:14.356783	started	2017-09-05 15:05:33.555000-06:00	1.1.33	1504641873449143
2017-09-20 17:17:37.979255	succeeded	2017-09-05 15:05:33.555000-06:00	1.1.33	1504641873449143
{code}
 

 ;;;","26/Sep/17 12:25 AM;andrey.goncharov;[~mgbailey] try running ""journalctl"" command on your machine;;;","26/Sep/17 12:25 AM;mgbailey;Additional note: I upgraded each of the nodes in the pool to 1.1.37 twice.  After the first upgrade, each node auto-downgraded back to 1.1.33.  After the second upgrade, each node remained at 1.1.37.;;;","26/Sep/17 12:31 AM;mgbailey;[^journalctl.tgz] output attached;;;","12/Oct/17 2:14 AM;krw910;I was easily able to reproduce this issue. Basically its the following:
 # upgrade pool using a transaction (in this case it also used force=True
 # next manually upgrade to the next version
 # on one node stop the services (sovrin-node, sovrin-node-control) and delete the config_transactions directory 
 # when you start the services the config ledger has to sync and when it does it runs the last transaction
 # in this case the last version is not the version on the system so it downgrades

I reproduced this because we have a version greater in the RC repo than in the Stable repo. So I installed 1.0.28 from stable, upgraded to 1.1.37 (the lastest) and then edit /etc/apt/sources.list to point to the RC repo instead of Stable. Now you can manually upgrade from that repo to 1.1.40. This puts you in a position to downgrade because the last transaction is for 1.1.37 and the current installed version is 1.1.40;;;","18/Oct/17 8:25 PM;spivachuk;*Problem reason:*
- When a node got new transactions to config ledger on catch-up, it processed the last {{POOL_UPGRADE}} {{start}} transaction from the ledger (if later there was no {{cancel}} transaction for this upgrade). Generally this logic was right. But in case a manual upgrade to a higher version had been made previously on a node, this logic resulted in that after catch-up the node upgraded to a lower version.

*Changes:*
- Added a constraint on a version that is lower than the current one to validation of {{POOL_UPGRADE}} transaction.
- Added prevention of upgrade to a lower version to {{Upgrader}}.
- Fixed a bug in {{Upgrader}} in search for a {{cancel}} transaction for the last upgrade {{start}} transaction.
- Added a test verifying prevention of upgrade to a lower version.
- Corrected existing tests according to introduced prevention of upgrade to a lower version.
- Made minor corrections in existing tests.

*Committed into:*
- https://github.com/hyperledger/indy-node/pull/402
- indy-node 1.1.42 rc

*Risk factors:*
- Validation and processing of {{POOL_UPGRADE}} transaction.

*Risk:*
- Low

*Covered with tests:*
- {{testPoolUpgradeFailsIfVersionIsLowerThanCurrent}}
- {{test_versions}};;;","20/Oct/17 12:07 AM;VladimirWork;Build Info:
1.1.42

Steps to Validate:
1. Upgrade pool using a transaction (in this case it also used force=True).
2. Next manually upgrade to the next version.
3. On one node stop the services (sovrin-node, sovrin-node-control) and delete the config_transactions directory.
4. When you start the services the config ledger has to sync and when it does it runs the last transaction.

Actual Results:
Downgrade is not performed. Pool works normally.

Additional Info:
- Added a constraint on a version that is lower than the current one to validation of POOL_UPGRADE transaction in the CLI.
- Fixed a bug in Upgrader in search for a cancel transaction for the last upgrade start transaction.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Anoncreds] Roots of an equation may be calculated incorrecttly when preparing primary proof,INDY-870,20966,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,ashcherbakov,ashcherbakov,ashcherbakov,23/Sep/17 1:17 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"For proof generation under Section 6 for the Validity Proof:

Part 2b says Let ∆←_mj_− _zj_ and find (possibly by exhaustive search) u1,u2,u3,u4 such that
∆ = (u1)^2+ (u2)^2+ (u3)^2+ (u4)^2;

The code doesn't compute properly for some cases and it should always sum to ∆

Example of ∆ which fails: 107, 112, 115, 119, 253, 1000, 3000",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Sep/17 1:16 AM;ashcherbakov;find_roots.py;https://jira.hyperledger.org/secure/attachment/12141/find_roots.py",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-44,,,,,,,,,,"1|hzx1br:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 6:51 AM;ashcherbakov;indy-anoncreds is deprecated and indy-crypto is used instead now;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLI attempts to connect to disabled validator node,INDY-871,20968,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,mgbailey,mgbailey,23/Sep/17 3:02 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"On the STN, the ""icenode"" validator was added to the network, and later removed.  A new record was written to the ledger for it, with no services: 
{code:java}
[9,{""data"":{""alias"":""icenode"",""services"":[]},""dest"":""BMFVNmQZPcbn4FhZmmsTHo76nwTQUC8QZJ1FSkXnn63u"",""identifier"":""6feBTywcmJUriqqnGc1zSJ"",""reqId"":1505757733062623,""signature"":""5emLWNwizobnoLPd1gTs2JR2QE14Y2SQb3TR4KUfenmwWJwKfCeFTcpnCvjRvaHxrdx6oULJTgSDQZj59J84jX2y"",""txnTime"":1505757733,""type"":""0""}]
{code}
The CLI client still attempts to connect to this disabled validator:
{code:java}
sovrin> connect test

Saved wallet ""Default"" restored (/home/vagrant/.sovrin/wallets/test/default.wallet)
Active wallet set to ""Default""
Client sovrin263c59 initialized with the following node registry:
australiaC listens at 52.64.96.160 on port 9702
brazilC listens at 54.233.203.241 on port 9702
canadaC listens at 52.60.207.225 on port 9702
englandC listens at 52.56.191.9 on port 9702
koreaC listens at 52.79.115.223 on port 9702
singaporeC listens at 13.228.62.7 on port 9702
virginiaC listens at 34.225.215.131 on port 9702
Active client set to sovrin263c59
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f listening for other nodes at 0.0.0.0:6005
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f looking for australiaC at 52.64.96.160:9702
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f looking for brazilC at 54.233.203.241:9702
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f looking for virginiaC at 34.225.215.131:9702
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f looking for englandC at 52.56.191.9:9702
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f looking for singaporeC at 13.228.62.7:9702
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f looking for canadaC at 52.60.207.225:9702
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f looking for koreaC at 52.79.115.223:9702
Connecting to test...
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f now connected to virginiaC
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f now connected to canadaC
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f now connected to koreaC
Connected to test.
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f now connected to englandC
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f looking for icenodeC at 185.102.43.35:9792
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f now connected to australiaC
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f now connected to singaporeC
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f now connected to brazilC
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f looking for thothC at 37.97.232.101:9701
CATCH-UP: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f completed catching up ledger 0, caught up 3 in total
CONNECTION: DpvptvkgWp3eR6CgNiH8VimNi4MZbbP9WZm7YteYYe9f now connected to thothC
{code}","CLI running 1.1.37, STN running 1.1.37",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1bj:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,mgbailey,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/18 3:53 AM;ozheregelya;Impossible to retest this issue in indy-cli because of IS-502.;;;","06/Sep/18 5:13 AM;esplinr;This issue is against the deprecated CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLI gives incorrect error message,INDY-872,20970,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,mgbailey,mgbailey,23/Sep/17 4:05 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"A steward entered an incorrect validator name onto the ledger.  When he attempted to correct it using another ""send NODE"" command, he got this error from the CLI:

 
{code:java}
""data"" must be in proper format
{code}
This is very misleading, since the CLI is pretty picky about formats, and this usually means a problem with a curly quote or a misplaced space or similar.

In the validator log, the correct error statement read:
{code:java}
2017-09-22 17:21:57,352 | WARNING | replica.py ( 657) | processReqDuringBatch | korea:0 encountered exception UnauthorizedClientRequest(""existing data has conflicts with request data {'services': ['VALIDATOR'], 'node_port': 9701, 'node_ip': '13.74.182.179', 'client_port': 9702, 'alias': 'ricFlair', 'client_ip': '13.74.182.179'}"",) while processing Request: {'operation': {'dest': '3DYWm1EcJHqPyUWKGKMYVB5vRwejverrb6Srmj2eKZP7', 'type': '0', 'data': {'services': ['VALIDATOR'], 'node_port': 9701, 'node_ip': '13.74.182.179', 'client_port': 9702, 'alias': 'ricFlair', 'client_ip': '13.74.182.179'}}, 'identifier': 'Q5vDQB3PZPvtLi5LZZj4xo', 'reqId': 1506100917098899, 'signature': '5LjrLjFBYgqXAwGxfJUVve3vrvie3cJrW7n143j1ZrJgUVeyLYjzgmecUC8pjf1HfR3Pm3BdUkWG8TZgZxYhDRd7'}, will reject
{code}
The error from the CLI should reflect the actual error, perhaps also stating
{code:java}
existing data has conflicts with request data{code}",CLI and STN validator pool are both at 1.1.37,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1fj:",,,,,,,,,,,,,,,,,,,,,,,,,,mgbailey,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 8:43 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI. Ticket with problems in indy-cli messages is https://jira.hyperledger.org/browse/IS-478.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Generalize config usage in code,INDY-873,20993,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,dsurnin,dsurnin,dsurnin,26/Sep/17 6:08 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,quality,,,,,"* For now config parameters such as base dir, data dir, log dir, etc. are defined differently in different classes: some of them are passed via constructor parameters, some are taken directly from config, some are calculated. As a result it is hard to reconfigure such parameters.

We need to remove direct config usage from the code. All the needed parameters should be read once from config and passed via constructors.

 

* Tests do not use config. Testing environment is configured via temporary directories which are passed as a parameters. As a result it is hard to add additional configuration parameter and modify existing ones.

We need to create special test config for the test environment.",,,,,,,,,,,,,,,,,,,,,,INDY-878,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0un:",,,,,,,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/17 6:20 AM;krw910;[~dsurnin] Please provide a design proposal and get it reviewed by a couple of the maintainers like Jason.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migration script needs to be run from sovrin (indy) user if it uses config,INDY-874,21012,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,ashcherbakov,ashcherbakov,27/Sep/17 5:15 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"Make sure that all existing migration scripts are run from sovrin (indy) if they use getConfig() since a correct config file (with overridden values) must be taken.
Have a look at 1_0_28_to_1_0_29.py as an example.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/17 10:30 PM;VladimirWork;874_journalctl_errors.PNG;https://jira.hyperledger.org/secure/attachment/12509/874_journalctl_errors.PNG","16/Oct/17 10:30 PM;VladimirWork;874_pool_upgrade_loop.PNG;https://jira.hyperledger.org/secure/attachment/12510/874_pool_upgrade_loop.PNG","12/Oct/17 9:33 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/12420/Screenshot.PNG","16/Oct/17 10:29 PM;VladimirWork;journalctl.txt;https://jira.hyperledger.org/secure/attachment/12508/journalctl.txt","12/Oct/17 11:35 PM;VladimirWork;node1_journal.PNG;https://jira.hyperledger.org/secure/attachment/12421/node1_journal.PNG","12/Oct/17 11:35 PM;VladimirWork;node4_journal.PNG;https://jira.hyperledger.org/secure/attachment/12422/node4_journal.PNG","12/Oct/17 11:36 PM;VladimirWork;node4_journalctl.txt;https://jira.hyperledger.org/secure/attachment/12423/node4_journalctl.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk6f:",,,,,,13,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,ashcherbakov,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/17 3:04 AM;spivachuk;Changed the user performing the migration that uses {{getConfig()}} (from {{root}} to {{sovrin}}).

The changes ate contained in the following pull request:
https://github.com/hyperledger/indy-node/pull/378;;;","07/Oct/17 1:00 AM;spivachuk;To verify this fix:
# Deploy a pool of the version 1.0.96 master in Docker.
# Log in to any node machine.
# Stop the node service.
# Remove {{pool_transactions_sandbox_genesis}} file.
# Override {{poolTransactionsFile}} configuration parameter in {{sovrin_config.py}} and rename the directory with the pool ledger correspondingly.
# Start the node service and make sure that the node connects to other nodes in the pool and participates in consensus, i.e. the overridden parameter takes effect.
# From CLI on the client machine send POOL_UPGRADE transaction to the version 1.1.156 and wait for all the nodes to be upgraded.
# Verify that the node with the overridden parameter is connected to other nodes and participates in consensus. This will indicate that on this node the migration script has updated the format of the pool ledger to {{msgpack}} being used in the new version, hence the script found {{sovrin_config.py}} with the overridden parameter, hence the script searched for {{sovrin_config.py}} in the home directory of the user {{sovrin}}, not of the user {{root}}.;;;","12/Oct/17 9:33 PM;VladimirWork;We have an issue with step 7:

Oct 12 12:10:14 d3d2f4c4907d env[2437]: The following packages have unmet dependencies:
Oct 12 12:10:14 d3d2f4c4907d env[2437]:  indy-plenum : Depends: python3-msgpack-python (= 0.4.6-1build1) but it is not installable
Oct 12 12:10:14 d3d2f4c4907d env[2437]: E: Unable to correct problems, you have held broken packages.

So it's unable to perform upgrade to versions with msgpack. !Screenshot.PNG|thumbnail! ;;;","12/Oct/17 11:36 PM;VladimirWork;Steps to Reproduce:
1. Deploy a pool of the version 1.0.96 master in Docker.
2. Log in to *node 4* machine.
3. Stop the node service.
4. Remove pool_transactions_sandbox_genesis file.
5. Override poolTransactionsFile configuration parameter in sovrin_config.py and rename the directory with the pool ledger correspondingly.
6. Start the node service and make sure that the node connects to other nodes in the pool and participates in consensus, i.e. the overridden parameter takes effect.
7. From CLI on the client machine send POOL_UPGRADE transaction to the version 1.1.156 and wait for all the nodes to be upgraded.

Actual Results:
Upgrade to 1.1.156 is failed at all nodes. See screenshots and logs for additional info. !node1_journal.PNG|thumbnail!  !node4_journal.PNG|thumbnail!  [^node4_journalctl.txt] 

Expected Results:
Upgrade should perform normally. ;;;","12/Oct/17 11:42 PM;ashcherbakov;[~spivachuk] [~VladimirWork]
I think 1.0.96 is incorrect version for migration from. Although migration is written for version 96 -> 97, there were some fixes in further versions.
Please try the version corresponding to MGL;;;","16/Oct/17 10:30 PM;VladimirWork;Steps to Reproduce:

1. Deploy a pool of the version 1.0.67 master in Docker.
2. Log in to node 4 machine.
3. Stop the node service.
4. Remove pool_transactions_sandbox_genesis file.
5. Override poolTransactionsFile configuration parameter in sovrin_config.py and rename the directory with the pool ledger correspondingly.
6. Start the node service and make sure that the node connects to other nodes in the pool and participates in consensus, i.e. the overridden parameter takes effect.
7. From CLI on the client machine send POOL_UPGRADE transaction to the version 1.1.156 and wait for all the nodes to be upgraded.

Actual Results:
Pool upgrade is failed due to migration script applying errors and falls into upgrade loop. See attachments for more info. [^journalctl.txt]  !874_journalctl_errors.PNG|thumbnail!  !874_pool_upgrade_loop.PNG|thumbnail! ;;;","19/Oct/17 3:02 AM;spivachuk;The issue described in the previous comment from [~VladimirWork] is also reproduced without overriding {{poolTransactionsFile}} config parameter and renaming the corresponding directory. So the upgrade from 1.0.67 to 1.1.156 on master fails in any case with the symptoms described in the previous comment. However, the fix made in scope of this ticket is just a copy of the hotfix made in stable branch (https://github.com/hyperledger/indy-node/pull/361). The hotfix in stable was verified and works correctly.

The issue with upgrade from 1.0.67 to 1.1.156 on master seems to be caused by a wide version jump. It includes 3 migrations at once. From the logs it is seen that the variable {{pool_transactions_file_base}} cannot be imported from the module {{plenum.config}} when the migration {{1_0_96_to_1_0_97.py}} is executed. This variable exists in indy-plenum version which indy-node 1.1.156 master depends on but does not exist in indy-plenum version which indy-node 1.0.67 master depends on. However, the migration {{1_0_96_to_1_0_97.py}} is executed when the new deb packages have already been installed and {{plenum.config}} loading seems to be triggered by {{helper_1_0_96_to_1_0_97.py}} which is run in a new process created by {{1_0_96_to_1_0_97.py}}. For the current moment we don't see why {{plenum.config}} from indy-plenum version which indy-node 1.0.67 master depends on is actually loaded.

The live pool was already upgraded using the same migration from stable - {{1_0_28_to_1_0_29.py}}. So on the live pool an upgrade with such version jump as from 1.0.67 to 1.1.156 on master will not take place. Taking this into account, the issue with upgrade from 1.0.67 to 1.1.156 on master seems not to be critical while further investigation of the issue may be time-consuming. [~nage], [~krw910], can we close this bug as ""Won't Fix""?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy-sdk integration,INDY-875,21018,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ashcherbakov,ashcherbakov,27/Sep/17 7:46 PM,09/Oct/19 6:18 PM,28/Oct/23 2:47 AM,09/Oct/19 6:18 PM,,,,,0,,,,,,"- As of now, we have to support two versions of 'client' code: python (indy-client) and indy-sdk
- We need to use indy-sdk only (possibly integrate it into current CLI)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Indy-sdk integration,Done,,,,,,,,"1|hzyg7b:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support a new version of indy-crypto,INDY-876,21019,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,ashcherbakov,ashcherbakov,27/Sep/17 7:57 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"- There are changes in indy-crypto build that need to be supported
- Also there is a new version of indy-crypto that uses another curve",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzwzav:",,,,,,13,14,,,,,,,1.0,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/17 5:17 PM;ashcherbakov;The new build is 1.1.149;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Backward compatibility for clients with state proof support ,INDY-877,21037,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ashcherbakov,ashcherbakov,28/Sep/17 7:11 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"We may have old client (python indy-clients) be not 100% backward compatible with pool having state proofs support.
This is because old clients will check for f+1 equal replies from the nodes. Noes with state proof support will include proof into replies. As the proof's state root multi-sig may be different for the latest txn (this is because it becomes equal only with the next batch when Primary propagates )

So, we have the following Options:

Option1:
- do nothing, and require update of the client (we will deprecate the python CLI in any case soon, so probably it isn't worth efforts here?)

Option 2:
- make sure that we always have equal replies. 
- It can be done by not calculating multi-sigs be individual nodes for the latest batch, and always use the multi-sig from the Primary only.
We need to send multi-sig for timeout in this case
- It will have a problem that we will not have a multi-sig for the ;ast batch immediately (only after some timeout)
- Also we will still have a problem if some nodes in the pool have state proofs support (that is they return proofs in replies), but some nodes don't have it (that is they don't return it). It means that we may not have equal f+1 replies.

Option3:
- A new client must specify its version with each of the requests.
- If there is no version, then we assume that the client doesn't support state proofs, and we don't return it with replies.
- This is a long-term solution for other possible backward-compatibilities problems.

I prefer either Option1 or Option3",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzyk9j:",,,,,,14,INDY 17.21,INDY 17.22,,,,,,5.0,,,,,,,,,,,,ashcherbakov,danielhardman,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/17 7:12 PM;ashcherbakov;[~nage] [~danielhardman] [~krw910] [~gudkov]
We need to choose the option to implement;;;","29/Sep/17 11:03 PM;danielhardman;I prefer option 3. However, I don't feel that our thinking is mature enough about versioning to do it. (For example, I think a client version number is not granular enough, because there could be many clients besides our CLI, and some of them may be more advanced in one type of ledger interaction than they are in another. What we probably need, instead, is a version for each transaction type. That way transaction types can each evolve, and a client only needs to be as up-to-date as the txn types it uses.)

If we are prepared to design Option 3 fully, then let's go down that road. It would require a doc that gets reviewed and blessed in a meeting of key architectural stakeholders.

Otherwise, I think Option 1 is the only alternative.;;;","30/Sep/17 12:13 AM;ashcherbakov;I agree that having a version for each individual transaction is better.
But in my opinion the Client version can be considered as not version of a Client, but rather a version of a Node's state (taking into account all transactions and features) that the client supports. Probably due to limited time we may consider this approach too 
;;;","03/Oct/17 5:07 PM;ashcherbakov;[~danielhardman] [~mzk-vct] [~gudkov]
After internal discussion with the team, we realized that we need both versions of individual transaction and a version of the protocol.
I captured that briefly in https://docs.google.com/document/d/1Y2e_J2sWii2f6V6aS4g8Z6bq0g9Tqr-VMKbJWx86mRI/edit#
For the current task just a Short-term solution (version of the protocol) is enough.
;;;","06/Oct/17 8:09 PM;ashcherbakov;- Added 'protocolVersion' field to each Request
- if there is no protocolVersion specified, then the pool should still work, and return results without state proofs.
- as of now there is only one version supported: 1 (state proof support)
- this version needs to supported in indy-sdk

PRs:
- https://github.com/hyperledger/indy-plenum/pull/407
- https://github.com/hyperledger/indy-node/pull/379

Build (master):
- 1.1.159

Recommendation for QA:
- check that old clients (version <1.1.153) still work with latest nodes
- check that old clients still work even without state proofs support (version <= 1.1.143)
- check that latest client works with latest node;;;","25/Oct/17 11:07 PM;ozheregelya;Following versions compatibility was verified:
||Node version||CLI version||
|1.1.143 (master)|1.1.37 (stable)|
|1.1.160 (master)|1.1.37 (stable)|
|1.2.182 (master)|1.2.182 (master)|;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Refactor] We need to re-factor config.py to reflect file folder re-factoring for Incubation,INDY-878,21038,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,ashcherbakov,ashcherbakov,28/Sep/17 7:24 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"There is file folder paths re-factoring in the scope of INDY-833. It makes valid folder layout for output deb packages and provides required migration. 
But it doesn't assume any deep re-factoring of the code base.

We need to perform the following re-factoring on the code level:
1) Separate a number of paths in the config responsible for outputs
2) These paths must be absolute
3) These paths must be configurable for different installations (default, CLI, tests, deb, rpm, Windows, etc.)
4) We need to re-factor the code to not use paths from config only during initialization
5) We need to re-factor the code to use proper paths
6) We need to get rid of BASEDIR (there is no BASEDIR anymore, all paths are absolute).
7) We need to make tests use special config and be consistent.
8) DEB packages should use proper system-dependent configs
9) Required migration must be provided

",,,,,,,,,,,,,,,,,,,,,INDY-873,,,,,,INDY-879,,,,,,,,"08/Dec/17 1:57 AM;ozheregelya;journalctl.log;https://jira.hyperledger.org/secure/attachment/13446/journalctl.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzypx3:",,,,,,14,INDY 17.21,INDY 17.22,INDY 17.23,INDY 17.24: Node Perf,INDY 17.25,,,13.0,,,,,,,,,,,,ashcherbakov,ozheregelya,sergey-shilov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/17 3:19 AM;ashcherbakov;[~nage] [~danielhardman] [~sergey-shilov]
A design doc: https://docs.google.com/document/d/1-TV3BxeAznpXKg8wFTmF4DxUHpdnqRjX_KQVUFWhSFY/edit#heading=h.27zfbdnncpnx;;;","06/Dec/17 7:01 PM;sergey-shilov;The main changes done in scope of this ticket are related to config usage. The main ideas were:
 - to minimise getConfig() calls;
 - to minimise the count of code places where full paths are built;
 - to introduce some config structure to reflect file/folder re-factoring.

The main point of changes is the introducing of ConfigHelper classes hierarchy. These classes implement building of full paths for node placement in the file system. All paths for node placement should be retrieved using instances of ConfigHelper classes.

As file/folder placement is systems-dependent we decided to figure out paths config as a separate file. This file is merged with general config, which now contains only network name and will contain other user-editable parameter of node. This merge is done during build procedure, so that all build procedure and thus installation procedure for Ubuntu OS should be tested. Such separation of system-dependent things will help us in multi-platform support in the future.

Introducing of ConfigHelper and separation of configs led to huge re-factoring of test fixtures and tests themselves of Indy-Node and Indy-Plenum, Now the placement of nodes and clients in the file system during tests is the same as it is done on real system. The only difference is changed root. Such approach allows to control and debug the nodes/clients placement in the file system on the tests stage.

Also many scripts are changed according to ConfigHelper usage.

So the most careful attention during testing should be paid to:
 - build and installation procedures;
 - all scripts that are used by system administrators to control/modify/support Indy node.
;;;","07/Dec/17 8:22 PM;VladimirWork;There is an issue with node initialization, waitng for new sovrin build.;;;","07/Dec/17 11:17 PM;ozheregelya;Things to be tested:

Node:
 {color:#14892c}– manual installation  !https://jira.hyperledger.org/images/icons/emoticons/check.png|width=16,height=16!{color}
 {color:#14892c}– docker installation{color} (/)
 – vagrant installation
 {color:#14892c}– manual upgrade -  !https://jira.hyperledger.org/images/icons/emoticons/check.png|width=16,height=16! - case 1 fixed{color}
{color:#14892c} – POOL_UPGRADE {color}
{color:#14892c} – – force=True -  !https://jira.hyperledger.org/images/icons/emoticons/check.png|width=16,height=16!  - case 1 fixed{color}
{color:#14892c} – – force=False -  !https://jira.hyperledger.org/images/icons/emoticons/check.png|width=16,height=16!  - case 1 fixed{color}

Node initialization (+adding node to the pool) 
 – init_indy_node
 – init_bls_keys
 – generate_indy_pool_transactions
 Network setup
 – create network
 – change network

Indy scripts
 – pool_start.sh
 – pool_stop.sh
 – read_ledger
 – generate_indy_pool_transactions
 – init_bls_keys
 – init_indy_keys
 – init_indy_node
 – clear_node.py
 – reset_client
 -- validator-info
 – performance scripts

{color:#14892c}Client:{color}
 {color:#14892c} Clear installation {color}
 {color:#14892c} – manual installation (/){color}
 {color:#14892c} – docker installation (client_for_pool_start.sh) (/){color}
 {color:#14892c} Upgrade {color}
 {color:#14892c} – upgrade using apt-get install (/){color}

Configs:
 – overlapping of parameters
 The main config is /etc/indy/indy_config.py
 Values from /etc/indy/indy_config.py may be overrided in /etc/indy/network_name/indy_config.py
 Values from both of previous configs may be overrided in /home/indy/.indy/network_name/indy_config.py;;;","08/Dec/17 1:59 AM;ozheregelya;*Case 1:*
Pool upgrade and manual upgrade don't work.
*Steps to Reproduce:*
1. Set up the pool with following versions:
{noformat}
root@05b9cd614d2d:/home/indy# dpkg -l | grep indy
ii indy-anoncreds 1.0.32 amd64 Anonymous credentials
ii indy-node 1.2.223 amd64 Indy node
ii indy-plenum 1.2.180 amd64 Plenum Byzantine Fault Tolerant Protocol
ii libindy-crypto 0.1.6-10 amd64 This is the shared crypto libirary for Hyperledger Indy components.
ii python3-indy-crypto 0.1.6 amd64 This is the official wrapper for Hyperledger Indy Crypto library (https://www.hyperledger.org/projects).
root@05b9cd614d2d:/home/indy# dpkg -l | grep sovrin
ii sovrin 1.1.39 amd64 Sovrin node{noformat}
2. Open CLI and connect to the pool.
3. Send POOL_UPGRADE command:
{noformat}
send POOL_UPGRADE name=upgrade12227 version=1.2.227 sha256=f6f2ea8f45d8a057c9566a33f99474da2e5c6a6604d736121650e2730c6fb0a3 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-12-03T11:45:00.000000+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-12-03T11:45:00.000000+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-12-03T11:45:00.000000+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-12-03T11:45:00.000000+00:00'} timeout=20 force=True{noformat}

*Actual Results:*
Nodes are upgraded, but nodes can't start. See details in [^journalctl.log]

*Expected Results:*
Pool should work after upgrade.

*Additional Information:*
The same behavior reproduces during manual upgrade: https://docs.google.com/document/d/1vUvbioL5OsmZMSkwRcu0p0jdttJO5VS8K3GhDLdNaoI/edit;;;","08/Dec/17 10:31 PM;VladimirWork;*Case 2:*

There are empty node folders in /var/lib/indy/sandbox/data. Each node has folders with all other nodes' names and it causes read_ledger.py script to read data from wrong folder.;;;","09/Dec/17 12:27 AM;VladimirWork;*Case 3:*

validator-info tool doesn't work due to ""There are no info files in /var/lib/indy/sandbox"" error.;;;","15/Dec/17 9:23 PM;VladimirWork;All test plan cases are passed, except vagrant installation. Vagrant manual document will be reviewed and checked in scope of INDY-1009.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[REFACTORING] Config must contain only parameters that can be configured by the user,INDY-879,21039,,Story,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,ashcherbakov,ashcherbakov,28/Sep/17 7:29 PM,09/Oct/19 6:54 PM,28/Oct/23 2:47 AM,,,,,,0,REFACTORING,,,,,"- Re-factor config.py to have only parameters that can be configured by the user
- All other parameters can be just constants (in the code)
- Each configurable parameter must have tests to make sure that it's really configurable and it doesn't break the system
- All parameters that can be configured must be available and known for the end user. Default or disabled values must be present in user's config (/etc/indy/conf for deb)",,,,,,,,,,,,,,,,,,,,,,,INDY-878,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0qv:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/17 5:55 AM;krw910;[~ashcherbakov] 
# The parameters for the user should be configured in this file. 
# Parameter for the network should be in a ledger so they can be changed using consensus.
# Other settings can be in code, but we should organize them so the changes are easy to audit.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Incubation] Support indy branding in sovrin,INDY-880,21040,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,,ashcherbakov,ashcherbakov,28/Sep/17 7:32 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"https://github.com/sovrin-foundation/sovrin/blob/master/build-scripts/ubuntu-1604/postinst contains code which relies on /home/sovrin/.sovrin.
It must be changed since we use indy user now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzyl3z:",,,,,,14,INDY 17.21,,,,,,,1.0,,,,,,,,,,,,ashcherbakov,ozheregelya,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/17 1:08 AM;spivachuk;Supported the platform rebranding from Sovrin to Indy in {{sovrin}} package built on top of {{indy-node}}.

The changes are contained in the following pull request:
https://github.com/sovrin-foundation/sovrin/pull/25;;;","05/Oct/17 4:17 AM;ozheregelya;Build Info:
 indy-node 1.1.150 -> 1.1.152
 indy-anoncreds 1.0.25 -> 1.0.37
 indy-plenum 1.1.137 -> 1.1.138
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 4 nodes, 1 client

Regression testing of installation and upgrade was performed for following cases:
 1. Clear installation and generation of genesis files.
 2. Automatic upgrade (using node control tool and POOL_UPGRADE command).
 3. Manual upgrade (using apt and manual running of migration scripts).

Listed cases work correctly. Regression testing of basic functionality will be performed later for incubation tickets and for state profs tickets together. Problems which will be found during regression testing will be described in separated tickets, so this one will be moved to customer validation.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
POOL_UPGRADE parameter for sha256 is required but does not appear to be validated,INDY-881,21068,,Bug,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,krw910,krw910,29/Sep/17 3:58 AM,27/Nov/20 12:34 AM,28/Oct/23 2:47 AM,,,,,,0,,,,,,"The POOL_UPGRADE transaction has a required parameter for a sha256 hash. However the hash is not being used to validate the build being installed. Any hash will apparently fulfill the parameter.

 Please propose a change to either allow this hash to work across platforms. If not cross platform please propose another method to validate the upgrade is installing the correct version (we expect to support multiple platforms in the future)(far future we may have different instances of the code that implement the same version of the protocol).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0tr:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,krw910,ozkul,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/18 4:57 PM;spivachuk;{{sha256}} parameter of {{POOL_UPGRADE}} request is still not used.;;;","11/Oct/19 7:13 PM;esplinr;We should either fix this or remove it so that it isn't confusing. Because we use Debian packaging signing, we don't need this hash for security reasons.;;;","27/Nov/20 12:34 AM;ozkul;Can we run the upgrade command without sha256? Like this ;

ledger pool-upgrade name=upgrade1121 version=1.12.1 action=start  timeout=15 force=true;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CI] Support new repo for indy-crypto in our CI/CD,INDY-882,21079,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,ashcherbakov,ashcherbakov,29/Sep/17 6:45 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"A separate repo will be used for libindy-crypto and python3-indy-crypto (see IS-360).

We need to support it in indy-node and indy-plenum:
- use correct repo when running tests (ci's Dockerfile)
- copy libindy-crypto and python3-indy-crypto debs of the required version from repo X (created in IS-360) to master/stable when creating master/stable releases of indy-node (similar to how we copy plenum for latest to master)
- update Docs to point to a new repo for libindy-crypto",,,,,,,,,,,,,,,,,,,,,,,IS-360,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk5b:",,,,,,14,INDY 17.21,INDY 17.22,,,,,,8.0,,,,,,,,,,,,andkononykhin,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/17 9:56 PM;andkononykhin;PRs:
https://github.com/evernym/sovrin-packaging/pull/20
https://github.com/evernym/jenkins-shared/pull/23
https://github.com/hyperledger/indy-node/pull/387
https://github.com/sovrin-foundation/sovrin/pull/29;;;","27/Oct/17 10:52 PM;andkononykhin;Problem reason:
 - indy sdk team has its own workflow non synced with indy core's one and it make possible (and it's already happened once) to break indy core logic of releasing indy-node packages with necessary dependencies to master/stable apt repo component because currently indy core packages depend on indy sdk ones (in particular python3-indy-crypto and libindy-crypto). It was decided to move all indy-sdk packages to a separate repo.

Changes:
 - re-organized file structure on repo.sovrin.org to support multiple apt repos on that single host (backward compatible)
 - evernym/sovrin-packaging repo:
 ** re-implemented logic of publishing deb packages into apt repo and releasing packages by copying from one apt repo component to another one
 ** created API to simplify apt repo management
 ** support of multiple repos
 ** option to the release deb package with all its dependencies collected by parsing deb packages metadata
 - adjusted other repos (see PRs list)

Committed into:
 - [https://github.com/evernym/sovrin-packaging/pull/20]
 - [https://github.com/evernym/jenkins-shared/pull/23]
 - [https://github.com/hyperledger/indy-node/pull/387]
 - [https://github.com/sovrin-foundation/sovrin/pull/29]

Risk factors:
 - Broken logic of CD pipelines for indy core projects

Risk:
 - Low

Covered with tests:
 - tested manually

Recommendations for QA:
 # check that CD pipelines for masters (currently the changes are there only) work without any errors
 ** [https://ci.evernym.com/view/cd|https://ci.evernym.com/view/cd/]
 ** [https://ci.evernym.com/job/Sovrin|https://ci.evernym.com/job/Sovrin/]
 # install indy-node >= 1.2.185 from master and check that apt doesn't raise any unmet dependencies errors
 # install sovrin>= 1.1.32 from master and check the same things
 # check [https://repo.sovrin.org/sdk/] it is expected as a new separate repo for sdk packages. Currently it consists only of a pair of packages just for testing because sdk team haven't finished support of new publishing logic
 ** replace [https://repo.sovrin.org/deb] line with  *https://repo.sovrin.org/sdk/deb xenial master* and check that
 *** packages from there (https://repo.sovrin.org/sdk/lib/apt/xenial/master/) are available to install (e.g. apt-cache search crypto)
 *** try to install them;;;","30/Oct/17 7:26 PM;VladimirWork;Build Info:
indy-node 1.2.188
sovrin 1.1.33

Steps to Validate:
1. Check that CD pipelines for masters (currently the changes are there only) work without any errors:
   https://ci.evernym.com/view/cd
   https://ci.evernym.com/job/Sovrin
2. Install indy-node >= 1.2.185 from master and check that apt doesn't raise any unmet dependencies errors.
3. Install sovrin>= 1.1.32 from master and check the same things.
4. Check https://repo.sovrin.org/sdk/ it is expected as a new separate repo for sdk packages.
5. Replace https://repo.sovrin.org/deb line with  https://repo.sovrin.org/sdk/deb xenial master and check that
packages from there (https://repo.sovrin.org/sdk/lib/apt/xenial/master/) are available to install (e.g. apt-cache search crypto).
6. Try to install them.

Actual Results:
CD pipelines/installation of indy and sdk packages works without errors. There is a separate repo for sdk packages.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide smooth possibility to enable BLS for live pool,INDY-883,21091,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,ashcherbakov,ashcherbakov,30/Sep/17 2:36 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"In order to use BLS multi-sigs and state proofs, a node needs to generate BLS keys and send NODE txn with BLS key specified.

We have the following options on how live pool can have BLS signatures supported.
1. Manual
- each Steward runs 'init_bls_keys' script
- each Steward send NODE txn with BLS key specified there

2. Semi-automated 1
- each Steward runs 'init_bls_keys' script
- we gather public BLS keys from each Steward, and edit genesis txn file and current ledgers in migration script.

3. Semi-automated 2
- we provide a script for each Steward (which needs to be executed manually) which does the following:
-- runs 'init_bls_keys'
-- send NODE txn with BLS keys
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzyk67:",,,,,,14,INDY 17.21,INDY 17.22,,,,,,2.0,,,,,,,,,,,,ashcherbakov,danielhardman,mgbailey,nage,ozheregelya,tharmon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Oct/17 10:29 PM;ashcherbakov;[~nage] [~danielhardman] [~tharmon] [~krw910] 
I think we need to have a decision here when we get the next RC with state proofs;;;","05/Oct/17 11:41 PM;tharmon;Is there a way whereby we can add the functionality, but not enforce it in the next release?;;;","05/Oct/17 11:43 PM;ashcherbakov;[~tharmon] Yes. BLS will just not be applied if we have no keys.;;;","11/Oct/17 6:01 AM;nage;We want something that looks like Option 2.  We would like a script that generates the right BLS key from the same seed used to generate the ed25519 key they are using and then submits the correct transaction.  The ""onboarding a node"" code/script (if there is one) should generate the BLS key for a new node that will follow this same pattern so that old and new nodes have keys that can be recreated from the seed in the same way (no differences between existing stewards and ones that will be onboarded after state proofs).;;;","16/Oct/17 7:13 PM;ashcherbakov;We already support using the same seed as for ed25519 for generation of BLS keys.
So, nothing new is expected for new Nodes (they will use `init_indy_keys` as usual which will generate BLS keys automatically, and then send NODE txn as usual, but with BLS field specified).
Existing Stewards need to run existing `init_bls_keys` script to generate just BLS keys for the same seed.

The only thing which needs to be done in this ticket is to extend `init_bls_keys` script (or add another script) for sending NODE txn with a newly generated BLS key (to update NODE txn in the Ledger);;;","19/Oct/17 4:48 PM;ashcherbakov;Created a script `enable_bls`
# The script generates a new BLS key from a seed (either node seed used for ed25519 keys, or a separate seed) like `ini_bls_keys` script.
# The script also sends NODE txn with `blskey` specified.
# So, the only thing a Steward needs to do to enable BLS for this Node, is to run this script as shown below
# The script needs to be run from `indy` user
# The script is delivered with deb package (as other scripts like read_ledger)
# How to use a script:
If BLS key needs to be created from the same seed as used for init node keys (I think it will be the default use case:
{code}enable_bls --name=<node-name> --node_seed=<seed-used-for-init-node-keys> --steward_seed=<seed-used-to-create-steward-did>{code}
If BLS key needs to be created using a separate seed
{code}enable_bls --name=<node-name> --node_seed=<seed-used-for-init-node-keys> --steward_seed=<seed-used-to-create-steward-did> --bls_seed=<seed-for-bls-key>{code}
Example for Docker pool:
{code}
enable_bls --name=Node1 --node_seed=000000000000000000000000000Node1 --steward_seed=000000000000000000000000Steward1 --bls_seed=rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
{code}

PR: https://github.com/hyperledger/indy-node/pull/405
Build: 1.1.168

;;;","23/Oct/17 4:48 PM;ashcherbakov;^ [~tharmon] [~krw910] [~mgbailey]
There were some discussions that Stewards may not know their seeds, or rotate the keys. In this case the only Option to enable BLS is Option1 (run `init_bls_keys` manually and send NODE txn manually).
if a Steward knows a seed and didn't rotate a key, then it can use `enable_bls`.;;;","24/Oct/17 12:11 AM;mgbailey;[~ashcherbakov]
All stewards should know their steward seeds.  We emphasized to them that these should be saved during the setup.  What some may not know is their node seeds, which were randomly generated by init_sovrin_node, and which they were not told to save.  What is a work around if their node seed was not saved?;;;","24/Oct/17 12:24 AM;ashcherbakov;[~mgbailey] [~ozheregelya] [~krw910] [~tharmon] 
Ok, then I will update the script to use `node_nym` instead of `node_seed`, it should be enough. `bls_seed` parameter will be required then (a Steward may use `node_seed` value here if it's known, or provide any new seed which will be used for BLS).;;;","24/Oct/17 1:47 AM;ashcherbakov;PR: https://github.com/hyperledger/indy-node/pull/414
Build: 1.1.176

New command syntax will be (*must be run from indy user*!):
{code}
enable_bls --name=<node-name> --node_dest=<node-dest-as-in-node-txn> --steward_seed=<seed-used-to-create-steward-did> --bls_seed=<seed-for-bls-key>{code}
Example for Docker pool (for Node2):
{code}
enable_bls --name=Node2 --node_dest=8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb --steward_seed=000000000000000000000000Steward2 --bls_seed=rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr{code};;;","24/Oct/17 3:16 AM;mgbailey;[~ashcherbakov], Looks good, thanks.;;;","24/Oct/17 5:27 AM;danielhardman;[~ashcherbakov] I saw that you urgently wanted feedback, but I'm not sure what the question is. Your PR looked fine, and Mike's suggestions seem good to me.;;;","25/Oct/17 10:59 PM;ozheregelya;Build Info: indy-node 1.1.178
enable_bls script was verified and it works fine.

See following document for details of state proofs testing: https://docs.google.com/spreadsheets/d/1XzJ6yK1z4em_N-ZY6IMeGxs54x-ar4uYKOYR_x5_CCo/edit#gid=0;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to create a ledger from genesis files if using configuration override settings to point to the live genesis files,INDY-884,21098,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Invalid,krw910,krw910,krw910,30/Sep/17 7:19 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"*Build*
indy-plenum= 1.1.27
indy-anoncreds= 1.0.10
indy-node= 1.1.37
sovrin= 1.1.6

1. Bring up a pool, but don't start the services yet.
2. From the sovrin user go into the .sovrin directory
3. Copy the sandbox files as live files
{code}
cp pool_transactions_sandbox_genesis pool_transactions_live_genesis
cp domain_transactions_sandbox_genesis domain_transactions_live_genesis
{code}

4. Edit the sovrin_config.py file and add the following two lines. These lines override the default and use the live transactions files to create the ledger under directories using 'live' in the naming
{code}
poolTransactionsFile = 'pool_transactions_live'
domainTransactionsFile = 'transactions_live'
{code}

5. Start the sovrin node service 
{code}
systemctl start sovrin-node
{code}

*The ledgers should be created under the sovrin user in*
{code}
.sovrin/data/nodes/<node name>/pool_transactions_live_genesis
.sovrin/data/nodes/<node name>/transactions_live_genesis
{code}

*To view the ledgers run the tool read_ledger as the sovrin user with the following command*
{code}
read_ledger --type domain
{code}
*or*
{code}
read_ledger --type pool
{code}

{color:#d04437}*Issue*{color}
In either case nothing is returned. If I try a transaction using the default users from the domain_transactions_live_genesis file I get a message that the verkey of the DID cannot be found.

This happens using an install of the latest stable build (1.1.37).
If you have upgraded from 1.0.28 to 1.1.37 you do not run into this issue due to a fix that occurred with the migration script for the upgrade process.





",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyih3:",,,,,,14,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Sep/17 7:24 AM;krw910;This may cause an issue with adding new nodes to the existing live pool. We are going to test the scenario by upgrading a pool from 1.0.28 to 1.1.37 then adding a new node that was not upgraded, but has a fresh install of 1.1.37.

We believe that even if the ledger does not get populated when the node starts that it will do a catch-up with the pool and sync its ledgers. If this is not the case this becomes the highest priority ticket.;;;","06/Oct/17 5:43 AM;krw910;Retest this with the settings from below to see if a fresh pool works. Then try again with the upgrade scenario from 1.1.28 to 1.1.37 adding a new node.

This may not be an issue with a fresh new pool. You just change the override setting from 
domainTransactionsFile = 'transactions_live'
to 
domainTransactionsFile = 'domain_transactions_live';;;","11/Oct/17 10:34 PM;krw910;It works when pointing to the correct file name.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incubation: Remove all non-Indy branding from documentation beyond GitHub repositories,INDY-885,21215,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,danielhardman,spivachuk,spivachuk,02/Oct/17 7:43 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Documentation,,,,,"Non-Indy branding and names was removed from documentation in {{indy-plenum}}, {{indy-anoncreds}} and {{indy-node}} repositories in scope of INDY-829, INDY-855 and INDY-830. However there are other resources with Indy documentation (e.g. Google Drive). In scope of this ticket remove non-Indy branding and names from documentation in such repositories.

For the purposes of this ticket, the scope is all Google Doc references that are made in {{hyperledger/indy*}} repositories. It also includes links found in the Indy wiki. Any additional documents that need changes should be submitted as separate tickets.",,,,,,,,,,,,,,,,,,,,,,,INDY-830,,,,INDY-829,INDY-855,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzyk7r:",,,,,,14,INDY 17.21,INDY 17.22,,,,,,2.0,,,,,,,,,,,,danielhardman,spivachuk,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/17 2:11 AM;TechWritingWhiz;Reached out to Nate for further specific instructions. I'm not sure at this point what is considered ""Indy"" documentation and what is not, where it is all located, etc...;;;","07/Oct/17 4:54 AM;TechWritingWhiz;Received further clarification on this. Will continue to proceed...;;;","11/Oct/17 7:50 AM;TechWritingWhiz;This work has been completed. The following applicable PR's are here and have been noted in Rocket.Chat. In no particular order: 

[https://github.com/hyperledger/indy-node/pull/393]

[https://github.com/hyperledger-archives/indy-client/pull/265]

[https://github.com/hyperledger-archives/indy-common/pull/125]

All places where the Getting Started Guide has been referenced from any of the current hyperledger/indy-* repos has been updated directly (if it was a Google Doc) or via pull requests for markdown. Some items in the hyperledger/indy-* still point to hypeledger-archives/indy-* for up to date instructions outside of the Getting Started Guide. These have been updated as well and have been included in the above pull requests. 

All documentation from the Hypledger Indy Wiki page has been scanned for references to the Getting Started Guide and have been updated where applicable.;;;","24/Oct/17 5:41 AM;danielhardman;[~TechWritingWhiz] Two of your PRs were against old archive projects instead of current ones. Is there work in current projects that's equivalent, that should be done?;;;","24/Oct/17 6:34 AM;TechWritingWhiz;[~danielhardman] I only updated those old archived products because in the current project/repo, in the Indy-node/setup.md located here: [https://github.com/hyperledger/indy-node/blob/master/setup.md] says to follow the instructions at ""Common Setup Instructions"".

The link to ""Common Setup Instructions"" is [https://github.com/hyperledger-archives/indy-common/blob/master/setup.md.] 

Originally, part of this request came about because someone visited the old Getting Started Guide. This was in part because some of the links still pointed towards the old project. To avoid any further possible misunderstandings, I updated the old Getting Started Guide, among other things, with messages advising that ""such and such"" has been deprecated with links towards the correct ones. 

It is up to whoever is in charge of those decisions to leave those two pull requests closed (they have been closed) or to merge them. I would recommend merging them because those updates do offer clarification. I also recommend them to be merged because in more than one place in the current project/repo – we have instructions telling the user to follow instructions blatantly located in the old archive. 

Outside of this, and one I found randomly earlier this morning in the current project, I do not know of anything else that needs to be done in the old archive. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[REFACTOR] Design refactoring of Request-Reply and tranasactions structure,INDY-886,21247,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,gudkov,ashcherbakov,ashcherbakov,03/Oct/17 5:13 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"As of now, Request-Reply jsons in client-to-node communication doesn't separate properly transaction data (body) and metadata.
We need to re-factor it (see details in https://docs.google.com/document/d/1Y2e_J2sWii2f6V6aS4g8Z6bq0g9Tqr-VMKbJWx86mRI/edit#)",,,,,,,,,,,,,,,,,,,,,,,INDY-1065,INDY-1066,INDY-1067,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1374,,,,,,,,,,"1|hzyvrr:",,,,,,Sprint 18.02 Stability,"Sprint 18.03 Stability, DKMS",,,,,,,8.0,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jan/18 7:46 PM;ashcherbakov;PoA:
 * Write a Design with proposed changes (we can just send a PR with existing doc update: [https://github.com/hyperledger/indy-node/blob/master/docs/transactions.md] and [https://github.com/hyperledger/indy-node/blob/master/docs/requests.md).]
Separate data and metadata; remove duplicates.
 * Support the changes in code (non-backward-compatible). Have just one place where transactions and requests are created (metadata is added).
 * Support a new client's protocol version. Reject all client requests with protocol version less that a new one and a message that client should be updated.;;;","26/Jan/18 2:56 AM;ashcherbakov;PR with proposed changes: https://github.com/hyperledger/indy-node/pull/536;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Each transaction in the Ledger can evolve ,INDY-887,21248,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,ashcherbakov,ashcherbakov,03/Oct/17 5:19 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"We need to support evolving of transaction in the Ledger (adding new fields, changing data types, etc.)
https://docs.google.com/document/d/1Y2e_J2sWii2f6V6aS4g8Z6bq0g9Tqr-VMKbJWx86mRI/edit#
We can do this by having a VERSION field in each of the transactions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-64,,,,,,,,,,"1|hzyi5j:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/18 11:29 PM;ashcherbakov;Done in the scope of INDY-1123;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make state proof processing logic independent of txn type,INDY-888,21249,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,ashcherbakov,ashcherbakov,ashcherbakov,03/Oct/17 5:24 PM,11/Oct/19 8:47 PM,28/Oct/23 2:47 AM,11/Oct/19 8:47 PM,,,,,0,Could,,,,,"As of now, a client needs to create key and value (how they are stored in State Trie) from a Replies DATA depending on the transaction type.
It makes the client code (indy-sdk in particular) dependent on the current structure of the State Trie.
One of the options on how we can get rid of it is sending KEY together with the DATA in each Reply. But we must be sure that malicious Node didn't replaced the KEY with something wrong. So, the KEY should be a part of VALUE in State Trie, that is signed by multi-sig.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0qf:",,,,,,14,INDY 17.21,,,,,,,3.0,,,,,,,,,,,,ashcherbakov,danielhardman,lovesh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/17 10:24 PM;ashcherbakov;[~krw910] [~nage] It doesn't block state proofs release, this is just a possible enhancement to have a better code in indy-sdk.
So, everything will work even without this ticket.
Moreover, I would like to discuss the change proposed in the ticket with [~jlaw 1] [~lovesh] [~danielhardman] [~nage] before doing it.;;;","24/Oct/17 5:23 AM;danielhardman;This feels to me like a desirable enhancement. I'd like to fit it in quickly.;;;","25/Oct/17 12:38 AM;lovesh;So the problem that you are trying to solve is making the client library agnostic to how relevant key(s) of a transaction are encoded to be stored in the state trie. I don't consider this as a problem until we decide to change in future how we encode keys from a transaction.;;;","25/Oct/17 1:26 AM;ashcherbakov;Yes. I agree that it's not a critical problem, but this is a nice enhancement that can allow us to have cleaner code and better maintainability (less dependency between libindy and indy-node implementation details).;;;","11/Oct/19 8:47 PM;ashcherbakov;I believe we will not do this in a near future;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Monitoring - Need a external signal or alarm that the pool is not functioning ,INDY-889,21267,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,krw910,krw910,04/Oct/17 12:47 AM,10/Oct/19 1:24 AM,28/Oct/23 2:47 AM,10/Oct/19 1:24 AM,,,,,0,,,,,,"We need a signal or alarm (external measure) when a pool stops functioning. If the pool is no longer accepting new transactions or unable to perform a read action.

*Basic Requirements *
Pick a timeframe, 60/90 mins, then an alarm goes off. 
Introduce a simulation for this. 
Keep rotating a key on a test account. 
When a transaction cannot be written, have an email sent. Need to define who should be in the email list and how it is controlled.
Need a system that shows the exact way it works externally.  
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-56,,,,,,,,,,"1|hzwyyn:",,,,,,,,,,,,,,,,,,,,,,,,,,esplinr,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/19 1:24 AM;esplinr;Automated monitoring now exists for the Sovrin Networks using the information provided by validator-info.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
There should be a way to record on a special ledger-like log without consensus,INDY-890,21268,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,ashcherbakov,ashcherbakov,04/Oct/17 1:01 AM,11/Oct/19 6:44 PM,28/Oct/23 2:47 AM,11/Oct/19 6:44 PM,,,,,0,,,,,,"* We need a way to record on the ledger-like log without consensus
* Significant events should be logged there.
* Define if it is public.
* Think about security vulnerability. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx1g7:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 6:44 PM;esplinr;This would be a useful feature in theory, but over the past two years it hasn't proved to be necessary. So we don't plan on implementing it.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support Indy branding in sovrin-environments,INDY-891,21269,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,krw910,spivachuk,spivachuk,04/Oct/17 1:48 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,The changes made in scope of the platform rebranding from Sovrin to Indy must be supported in the environments being deployed from {{sovrin-environments}}.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzx0nj:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,ozheregelya,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/17 7:29 PM;spivachuk;The following changes have been made for Docker environment:
- Supported rebranding in Docker environment.
- Fixed support for ""--help"" argument in client_start.sh, pool_build.sh, pool_stop.sh scripts for Docker environment.
- Added execution permission to client_stop.sh script for Docker environment.

The changes are contained in the following pull request:
https://github.com/evernym/sovrin-environments/pull/28;;;","05/Oct/17 1:21 AM;spivachuk;The following changes have been made for Vagrant environment:
- Supported rebranding in Vagrant environment.
- Replaced sovrin-node and sovrin-client packages with sovrin package in ""apt-get install"" commands where outdated sovrin-node and sovrin-client packages had still been used.

The changes are contained in the following pull request:
https://github.com/evernym/sovrin-environments/pull/29;;;","06/Oct/17 6:07 PM;spivachuk;Faced a problem with deploying OpenShift environment using the instructions at https://github.com/evernym/sovrin-environments/tree/master/openshift

Created an issue on GitHub about this:
https://github.com/evernym/sovrin-environments/issues/30;;;","09/Oct/17 9:53 PM;spivachuk;Wade Barnes has commented on https://github.com/evernym/sovrin-environments/issues/30;;;","09/Oct/17 10:04 PM;spivachuk;Extracted support for Indy branding in OpenShift environment to a separate task - INDY-898.;;;","09/Oct/17 10:06 PM;spivachuk;Extracted support for Indy branding in CloudFormation environment to a separate task - INDY-899.;;;","11/Oct/17 12:52 AM;ozheregelya;Building the pool on docker containers was verified on following version:
 indy-node 1.1.159
 indy-anoncreds 1.0.32
 indy-plenum 1.1.143
OS/Platform: Ubuntu 16.04.2 LTS
Building the pool using vagrant can be tested only after release, and it will be test after acceptance testing of RC.;;;","12/Jan/18 2:29 AM;ashcherbakov;Done in the scope of https://jira.hyperledger.org/browse/INDY-1055;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node monitoring manual for stewards,INDY-892,21276,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,andrey.goncharov,andrey.goncharov,04/Oct/17 5:16 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"Get all stewards running a plug in that can notify themselves of upgrades, etc. Sample SNS plug in. PART A - Need to craft information on how to monitor your node. Communicate the raw content regarding plug ins to Misty, Do this in Jira, and assign to Misty.",,,,,,,,,,,INDY-995,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/17 6:46 AM;TechWritingWhiz;Node Monitoring Tools for Stewards- PDF.pdf;https://jira.hyperledger.org/secure/attachment/12419/Node+Monitoring+Tools+for+Stewards-+PDF.pdf",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-792,,,,,,,,,,"1|hzytxb:",,,,,,INDY 17.21,INDY 17.22,INDY 17.23,Sprint 18.02 Stability,,,,,1.0,,,,,,,,,,,,andrey.goncharov,ashcherbakov,krw910,SusanBradford,TechWritingWhiz,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/17 5:17 AM;andrey.goncharov;I composed a short doc with available information and necessary links [https://docs.google.com/document/d/1Ev3YQ1mPUd71QTj1YzTyjyl4S2hBzlfjbpV1hLWKbzI]

[~TechWritingWhiz] could you take it from here?;;;","04/Oct/17 11:53 PM;TechWritingWhiz;Yes I can. [~andrey.goncharov] is there a due date for this and what formats does it need to be in? HTML? PDF? Markdown? ;;;","05/Oct/17 4:11 AM;SusanBradford;We would like to present this to the TGB at the next meeting Oct 26. It will need to go through [~krw910] prior to that. ;;;","12/Oct/17 6:47 AM;TechWritingWhiz;""The Node Monitoring Tool for Stewards"" document is complete. Attached is the PDF. Please review it for accuracy and let me know what changes need to be made. [^Node Monitoring Tools for Stewards- PDF.pdf];;;","25/Oct/17 1:43 AM;krw910;[~mgbailey] Can you take a look at the documentation Misty has provided? The link is in her comments above.
;;;","18/Nov/17 6:36 AM;krw910;The documentation looks good. I am checking to see if the steps have been tested before moving to done.;;;","21/Nov/17 6:45 AM;krw910;This functionality needs to be tested.;;;","02/Dec/17 2:15 AM;VladimirWork;Email plugin configured according to this manual doesn't work so INDY-995 is reported. This ticket is about documentation so it will be closed (I'll make changes in this manual if it will be needed after INDY-995 fix).;;;","05/Dec/17 8:00 AM;TechWritingWhiz;[~VladimirWork] Actually, any changes needed to the manual needs to go through me so that I can update our official documentation and then distribute it back out to proper channels. Please let me know via this ticket or a new ticket, what changes need to be made. The document attached to this ticket is a PDF and is NOT meant to be changed/updated. Those changes need to go through me first. This avoids having multiple drafts of multiple documents in multiple places. Let me know if  you have any questions.;;;","05/Dec/17 5:19 PM;VladimirWork;[~TechWritingWhiz]
bq. Please let me know via this ticket or a new ticket, what changes need to be made.
Ok.;;;","17/Jan/18 6:38 PM;ashcherbakov;[~TechWritingWhiz] is the manual published somewhere? I believe it should be either uploaded or referenced in [https://github.com/hyperledger/indy-node/tree/master/docs].;;;","17/Jan/18 6:40 PM;ashcherbakov;This ticket is blocked by INDY-995. We need to make sure the following:
1) The manual is uploaded and available from within indy-node repo (either the manual itself or a reference).

2) Required changes (if any) are added after INDY-995 is fixed.;;;","18/Jan/18 12:25 AM;TechWritingWhiz;[~ashcherbakov] The PDF that was attached to this ticket was meant to be reviewed for accuracy. According to the comments it was accurate. However, after that no request has been made until your recent comments for publishing it in an alternative location. I also would like to make any necessary changes to it prior to official publication. I will touch bases with [~krw910] to see what needs to be done to make this as smooth as possible.;;;","18/Jan/18 3:25 AM;TechWritingWhiz;[~ashcherbakov] It is agreed it should be in the indy-node/docs section as you mentioned. I will create a markdown of this and check it in. Any changes that need to be made to it can then be done by the community.;;;","18/Jan/18 5:10 AM;TechWritingWhiz;[~ashcherbakov] I have created a .md document for this item and placed in the docs folder of indy-node per the request. The pull request is here: [https://github.com/hyperledger/indy-node/pull/526|https://github.com/hyperledger/indy-node/pull/526.];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node fails to sync following upgrade,INDY-893,21334,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,ashcherbakov,mgbailey,mgbailey,06/Oct/17 2:05 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,should,,,,,"Metis, a node on the ESN, will not sync with the other nodes on the network following a manual upgrade from 1.1.33 to 1.1.37.  In the logs, a hash mismatch error on the config ledger is being reported:
{code:java}
2017-09-29 11:49:17,887 | INFO     | ledger_manager.py    ( 601) | hasValidCatchupReplies | metis could not verify catchup reply CATCHUP_REP{'consProof': ['3SicutRJhiGma6ZGV7x1U8Dgd3ysSyRrrxdNVTtTpgQ1', 'BVa43Pg8SLAXi7NMvTfXDNXECA1SVSoihsfSDPkc4BNG', 'EJ7McLjzmQFxuvHm8d65zoQDREZJfvN3XHZ7Q5BzjSyi', '8HhxoviUnWyJ1RCEqCGJ19QPtmonuPKDfrH6GVxYnM9x', 'FLuA9mEmudY1tTBvhk18uapfF8cmRf6Cs8AAsx7NC49S', '4dicxCBSiGvjhppLZLGqLAdn7dpLKyr63oZgTNcsJ3E5'], 'ledgerId': 2, 'txns': {'3': {'reqId': 1505926023556578, 'identifier': '7VNYvJaxDraquhMC9YneziwmM9SZzR5KM24xWtm1jVh', 'txnTime': 1505926023, 'signature': '3Vr9bnzoxnSSUM3UZPMD2uXVmfdGDA5nVCrPSiawNPymE4pJentkGYkAAp2hbzTozuUMUuSunZVD8emCwf7F4ogh', 'data': {'version': '1.1.33', 'action': 'complete'}, 'type': '110'}}} since Inconsistency: first root hash does not match. Expected hash: b'99bbdf156bbfb1578944d380bd5f33996400330256f3b9a1398802c937e59ce1', computed hash: b'6ce3b31822cb39fbee6601df74abd6d1f5f6710d1cb1915f7da3f986cb834172'
{code}
When inspecting the config ledger, a mismatch is indeed found on the second transaction, which had been posted to the ledger a month ago, when an upgrade transaction with the --force flag was used to upgrade from 1.0.28 to 1.1.33.  The node has been operational and processing domain transactions normally over the past month, while running 1.1.33. With this failure to sync, the node is no longer able to accept transactions.

Theory:

A non-consensus transaction (or a *duplicate transaction*) was posted only to the metis config ledger a month ago during the 1.1.33 upgrade with the --force flag, but for some reason the problem was not detected then, perhaps because nothing was written to the config ledger after that.  The problem sat dormant until the node service was stopped and started during the 1.1.37 upgrade, triggering the resync event on all the ledgers, and the config ledger resync failed due to the mismatch.  Node functionality was then halted.

 

Attached are the log, domain (partial) and config ledgers for metis, and the config ledger for one of the other, presumed good, nodes on the ESN.  The domain ledger of metis matches the domain ledger of the other nodes.","ESN, running 1.1.37",,,,,,,,,,INDY-911,,,,,,,,,,,,INDY-960,,,,INDY-1213,,,,,,,,"06/Oct/17 1:58 AM;mgbailey;jouer_config_ledger.txt;https://jira.hyperledger.org/secure/attachment/12207/jouer_config_ledger.txt","10/Oct/17 5:51 AM;mgbailey;journalctl-10-09-17.txt;https://jira.hyperledger.org/secure/attachment/12403/journalctl-10-09-17.txt","10/Oct/17 5:51 AM;mgbailey;metis-10-09-17.txt;https://jira.hyperledger.org/secure/attachment/12402/metis-10-09-17.txt","06/Oct/17 2:03 AM;mgbailey;metis_config_ledger-10-04-17.txt;https://jira.hyperledger.org/secure/attachment/12206/metis_config_ledger-10-04-17.txt","06/Oct/17 1:50 AM;mgbailey;metis_ledger_trans-10-04-17.txt;https://jira.hyperledger.org/secure/attachment/12209/metis_ledger_trans-10-04-17.txt","06/Oct/17 1:51 AM;mgbailey;metis_log_2017-09-29.txt;https://jira.hyperledger.org/secure/attachment/12208/metis_log_2017-09-29.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx0vb:",,,,,,INDY 17.21,INDY 17.22,INDY 17.23,INDY 17.24: Node Perf,,,,,,,,,,,,,,,,,ashcherbakov,dsurnin,krw910,mgbailey,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/17 6:31 AM;krw910;It looks like the issue is the node wrote the entry to its own ledger twice. What could cause that to happen? We believe it was due to using the ""force=True"" parameter on the upgrade transaction.;;;","10/Oct/17 5:54 AM;mgbailey;I got with the steward and tried these steps:
 # stop the sovrin-node and sovrin-node-control services
 # delete the config_transactions directory
 # start the sovrin-node service

The theory was that this would rebuild the config ledger, and it would match the ledgers in the pool.  It didn't work.  It rebuilt the ledger exactly as it appears above, which does not match the config ledger of any other node in the pool.

Digging deeper, I see in journalctl that the node ""upgraded"" to 1.1.33 from 1.1.37.  So now I have a new theory.

When the node is coming up with an empty config ledger, it gets a transaction from somewhere (either something in sovrin-node-control or via catchup from another node) to upgrade to 1.1.33. This was an old transaction that was supposed to execute back in early September. The node is already at 1.1.37, so this is actually a downgrade at this point.

The node then does the downgrade, and reverts back to 1.1.37, and somewhere along the way a second copy of the 1.1.33 upgrade transaction is written to the config ledger, causing the mismatch and the lack of ability to catch up on all ledgers.

I am attaching the journalctl and logs from today.  The downgrade is at 12:10.

Here is another note.  The downgrade only happened once.  The duplicate ledger entries happened on other restarts as well, so this does not explain everything.  The difference when the downgrade occurred was that the sovrin-node-control service was restarted as well.;;;","26/Oct/17 7:21 PM;dsurnin;[~mgbailey]

The issue with downgrade to 1.1.33 was fixed in [INDY-869|https://jira.hyperledger.org/browse/INDY-869]. 

However the main issue of the Bug still requires research.

 

[~krw910] [~mgbailey]

It requires a lot time to research. Is it still a high priority bug?

Also we did several important fixes to forced upgrade recently and probably it should be retested with the new version before continue.

Could you please prioritize it against the rest tasks?;;;","28/Oct/17 12:45 AM;mgbailey;This issue happened in the config ledger, so it was not part of an upgrade script. Since we are continuing to use force=True for upgrades, this continues to be a concern.  ;;;","17/Nov/17 12:37 AM;ashcherbakov;[~mgbailey]
Are you sure that config_ledger of Metis node was deleted in trying to catch it up?
I can see from the log that Metis always has 2 txns in its Config ledger, so it looks like this is the two duplicated txns that were there from the very beginning.
I think deleting the config ledger should help.;;;","17/Nov/17 12:53 AM;ashcherbakov;[~mgbailey]
I can see some strange difference between txns on Metis and other Nodes:

Both duplicated txns on Metis have the following schedule for Metis ('7Mxn7MzXTGRbUBWwaGzpU2j7d58kSpjpfQnjoMdLV3xZ' id)
# ""7Mxn7MzXTGRbUBWwaGzpU2j7d58kSpjpfQnjoMdLV3xZ"":""*2017-09-06T18:55:33*.555000-06:00"",

while in the one and only POOL_UPGRADE txn on other Nodes we have the following for Metis:
# 
""7Mxn7MzXTGRbUBWwaGzpU2j7d58kSpjpfQnjoMdLV3xZ"":""*2017-09-05T15:05:33*.555000-06:00""


;;;","17/Nov/17 12:55 AM;ashcherbakov;Can it be that there were more than one POOL_UPGRADE txn? ;;;","17/Nov/17 1:32 AM;mgbailey;[~ashcherbakov], I am sure that we deleted the config ledger.  That was one of the mysteries of this thing: where were these 2 transactions coming from?  I don't recall: do we see a catchup of ledger 2 happening in the logs?  If so, why do the transactions not match exactly, as you noted above?

Another odd thing: only the transaction time for metis is different, not for the other nodes. and that is for an entirely different hour, on another day.  We certainly did not post a transaction like this!;;;","17/Nov/17 10:23 PM;ashcherbakov;Still have no idea why a wrong POOL_UPGRADE txn (with incorrect time) appeared in Metis's config ledger twice.

But found the reason why Metis wasn't able to catch-up after Config ledger was removed (it was really removed):
1) Metis started catch-up of removed config ledger (from size 0 to size 29)
2) It caught up just fine
3) Once config ledger is caught up, but before domain ledger catch up starts, Node checks config ledger to see whether a Node needs to perform scheduled Upgrade.
4) Metis sees POOL_UPGRADE txn to version 1.1.33. Because of the problem which was fixed in INDY-869, metis schedules downgrade to 1.1.33 (it should not happen anymore because of the fix in INDY-869)
5) Metis sends NODE_UPGRADE txn for his upcoming Upgrade
6) Before Upgrade (downgrade to 1.1.33) is started for Metis, Metis starts domain ledger catch-up (from size 40801 to 43800)
7) It gets the first batch of missing domain transactions (1500).
8) Metis started applying these txns, and *downgrade to 1.1.33 happens in between this applying. Moreover, it happened in between writing a txn to ledger transaction log and the tree. It's possible since this operation is not atomic. As a result, Metis's domain ledger transaction log has 41076 txns, and Metis's domain ledger hash tree has 41075 txns*.
9) Metis re-started, and tries to restore the ledger tree from the hash store. The hash store size differs from transaction log size (41075 != 41076), so it fails.
10) Then Metis falls back to restoration of the ledger tree from transaction log. *It tries to reset the tree, but looks like doesn't do it correctly. So, the tree is restored with 41075 (from hash store) + 41076 (from txn log) = 82151 txns*.
11) When Metis starts to catch-up domain ledger, it fails, since *it assumes it has 82151, but really has only 41075*
;;;","17/Nov/17 10:24 PM;ashcherbakov;Further steps:
1) Fix the problem with recovering of the ledger tree 
2) Create a ticket for trying to make ledger add operation atomic
3) Analysing possibility of having POOL_UPGRADE txn with incorrect  time further.;;;","21/Nov/17 1:33 AM;ashcherbakov;Created https://jira.hyperledger.org/browse/INDY-955;;;","21/Nov/17 10:09 PM;ashcherbakov;1) The problem with downgrade is already fixed in INDY-869
2) Fixed the problem with ledger recovery: 
- PR: https://github.com/hyperledger/indy-plenum/pull/451
3) Created a ticket in backlog for atomic operations in ledger: INDY-955
4) I still have no idea how incorrect txns (with incorrect time) appeared on Metis.

I think 1) and 2) should be enough to declare the problem fixed.
Let's monitor if we face Issue 4 (incorrect POOL_UPGRADE txn times) again.

Build:
- master 1.2.216;;;","05/Dec/17 12:37 AM;ashcherbakov;[~mgbailey] will you be able to validate this one?;;;","05/Dec/17 3:12 AM;mgbailey;[~ashcherbakov] I am unable to validate this.  Metis has been removed from the ledger and destroyed.;;;","05/Dec/17 4:30 AM;ozheregelya;[~ashcherbakov], [~mgbailey], today I tried to verify this issue on test pool, but I have some problems with catch up after sending lots of transactions. It probably may relate to INDY-911. I'll discuss this problem with team tomorrow.;;;","06/Dec/17 4:52 PM;ashcherbakov;[~ozheregelya] ok, then I think you can close the ticket once you test it.;;;","08/Dec/17 5:52 PM;ashcherbakov;As INDY-911 and INDY-960 cover the fixed issue in some sense, I suggest that we close this ticket and continue validation in the scope of INDY-911;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Getting Started Guide: Some verbiage is incorrect with new verbiage changes,INDY-894,21336,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,TechWritingWhiz,TechWritingWhiz,06/Oct/17 7:01 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Documentation,,,,,"Update the Getting Started Guide with correct verbiage changes. With the branding changes that have taken place, it appears that everywhere ""Sovrin"" once appeared ""Indy"" has now been replaced. This has caused contextual problems.

Example: Title page states ""A Developer Guide from the Indy Foundation"" 

There is no ""Indy Foundation"". There is a Sovrin Foundation and a Linux Foundation. Indy is a project of Hyperledger. 

Review the contents of the Getting Started Guide for necessary changes such as these. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk7z:",,,,,,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Oct/17 4:48 AM;TechWritingWhiz;The pull request for this item: 
[https://github.com/hyperledger/indy-node/pull/386]

 ;;;","10/Oct/17 11:25 PM;TechWritingWhiz;This was resubmitted as pull request #391 and was approved and merged. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New nodes added to existing pool are unable to sync ledgers with the pool.,INDY-895,21337,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,Artemkaaas,krw910,krw910,06/Oct/17 8:00 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"When adding a new validator node to an existing pool the ledgers are unable to sync. Due to this issue the new node cannot participate in consensus and counts as a failed node.

The issue may be due to the use of the 'force=True' parameter in the POOL_UPGRADE transaction.

*Short version*
Setup pool with indy-node 1.0.28 using live pool configuration settings
Upgrade to 1.1.37
Add a new node to the pool from a fresh install of 1.1.37

Steps
1. Setup a pool using the provisional live build
{code}
indy-plenum=1.0.21
indy-anoncreds=1.0.8
indy-node=1.0.28
sovrin=1.0.3
{code}

2. Before starting the pool change the configuration to use the live transaction files. As the sovrin user edit "".sovrin/sovrin_config.py""
Add the following lines
{code}
poolTransactionsFile = 'pool_transactions_live'
domainTransactionsFile = 'transactions_live'
{code}

3. Start the sovrin-node service. The ledgers for pool and domain will be created in the following directories
{code}
.sovrin/data/nodes/<node name>/pool_transactions_live
.sovrin/data/nodes/<node name>/transactions_live
{code}

4. Send a few transactions from the CLI to make sure the pool is working correctly.

*{color:#205081}Upgrade {color}*to indy-node 1.1.37
*Note*- The upgrade to 1.1.37 introduced serialized ledgers. Due to this significant change it was necessary that all validator nodes in the pool upgraded simultaneously. The instructions to those upgrading the pool included the use of the upgrade parameter ""force=True"".

5. Send the an upgrade transaction with the parameter ""force=True"" like in the example below.
{code}
send POOL_UPGRADE name=upgradestable37 version=1.1.37 sha256=e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv':'2017-10-04T17:30:00.258870-06:00','8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-10-04T17:30:00.258870-06:00','DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya':'2017-10-04T17:30:00.258870-06:00','4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA':'2017-10-04T17:30:00.258870-06:00','4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe':'2017-10-04T17:30:00.258870-06:00','Cv1Ehj43DDM5ttNBmC6VPpEfwXWwfGktHwjDJsTV5Fz8':'2017-10-04T17:30:00.258870-06:00','BM8dTooz5uykCbYSAAFwKNkYfT4koomBHsSWHTDtkjhW':'2017-10-04T17:30:00.258870-06:00','98VysG35LxrutKTNXvhaztPFHnx5u9kHtT7PnUGqDa8x':'2017-10-04T17:30:00.258870-06:00','6pfbFuX5tx7u3XKz8MNK4BJiHxvEcnGRBs1AQyNaiEQL':'2017-10-04T17:30:00.258870-06:00','HaNW78ayPK4b8vTggD4smURBZw7icxJpjZvCMLdUueiN':'2017-10-04T17:30:00.258870-06:00'} timeout=10 force=True
{code}

6. After upgrading successfully the pool version on each node showed
{code}
indy-plenum=1.1.27
indy-anoncreds=1.0.10
indy-node=1.1.37
sovrin=1.1.6
{code}

7. Send some transactions to make sure the pool is functioning. I sent 15 transactions.
*Note* - At this point the pool was functioning and all nodes are in sync

*{color:#205081}Add Node{color}* - Now install a new node to add to the pool
8. Install the latest stable (indy-node 1.1.37) to a new machine.
9. Initialize the node, but do not start the services
10. From one of the nodes in the pool copy the following files to the .sovrin directory of the new node
{code}
pool_transactions_live_genesis
domain_transactions_live_genesis
{code}

11. Before starting the node change the configuration file to use the live transaction files. As the sovrin user edit "".sovrin/sovrin_config.py""
Add the following lines
{code}
poolTransactionsFile = 'pool_transactions_live'
domainTransactionsFile = 'domain_transactions_live'
{code}
*Note the difference here. After the upgrade the transactions_live file was renamed to ""domain_transactions_live"" and the format change to be in a json format*

12. Now start the sovrin-node service
13. You can verify the ledger has data using the read_ledger tool as the sovrin user.
{code}
read_ledger --type domain
{code}

14. From the CLI add a new steward for this node
15. Using the CLI as the new Steward add the node with the send node transaction like below
{code}
send NODE dest=<base 58 Key> data={'client_port': 9702, 'client_ip': '<IP Address>', 'alias': 'ohioLiveQA11', 'node_ip': '<IP Address>', 'node_port': 9701, 'services': ['VALIDATOR']}
{code}

16. You should see the node show up in the CLI as connected.

ISSUE
The domain ledger will not sync.
The other nodes show they are connected to the new node.
The logs in on the new node show the following error
{code}
2017-10-05 22:36:31,736 | INFO     | ledger_manager.py    ( 601) | hasValidCatchupReplies | Node11 could not verify catchup reply CATCHUP_REP{'txns': {'16': {'txnTime': 1507156101, 'data': None, 'verkey': None, 'ref': None, 'type': '1', 'alias': None, 'enc': None, 'signature_type': None, 'role': None, 'dest': 'CA6NHp54iKYu4zTEobYKy7', 'reqId': 1507156101755400, 'identifier': 'V4SGRU86Z58d6TV7PBUe6f', 'hash': None, 'signature': '2tN1sHvPmc8bcd3YT2fpW8tHibqAr8JbovmKCmompzfbDjU45mPr6Q5D6ZXkKqfDJg6uA6zXUbSRMESxy2LVTEAz', 'raw': None}}, 'consProof': ['7MMFgPR4syqDpTjnpXe5guGLWuVSTeNUUG25nnG5M1Ho', 'GBS6VPdF21Rz13AbiAjStwLULmthUJPV4eKeLgC7Pa99'], 'ledgerId': 1} since Bad Merkle proof: second root hash does not match. Expected hash: b'5da495937529bcb7a9cff1135316250839296bc7e655fe32555e1c4444411b72' , computed hash: b'338aa575f9f71708bc45f9ece724c09886648b5cd19bf2de79a2bf6d6d2db73b'
{code} [^Node11.log] ",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-909,INDY-908,,,,,,,"06/Oct/17 9:56 AM;krw910;Node11.log;https://jira.hyperledger.org/secure/attachment/12211/Node11.log","12/Oct/17 3:05 AM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/12413/_node1.txt","12/Oct/17 3:05 AM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/12414/_node2.txt","12/Oct/17 3:05 AM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/12415/_node3.txt","12/Oct/17 3:05 AM;VladimirWork;_node4.txt;https://jira.hyperledger.org/secure/attachment/12416/_node4.txt","12/Oct/17 3:05 AM;VladimirWork;_node5.txt;https://jira.hyperledger.org/secure/attachment/12417/_node5.txt","12/Oct/17 3:05 AM;VladimirWork;_node6.txt;https://jira.hyperledger.org/secure/attachment/12418/_node6.txt","06/Oct/17 12:58 PM;mgbailey;icenode 3_log.txt;https://jira.hyperledger.org/secure/attachment/12213/icenode+3_log.txt","13/Oct/17 1:58 AM;VladimirWork;journal.txt;https://jira.hyperledger.org/secure/attachment/12425/journal.txt","16/Oct/17 5:48 PM;VladimirWork;journalctl_1.1.41_migration;https://jira.hyperledger.org/secure/attachment/12500/journalctl_1.1.41_migration","13/Oct/17 1:59 AM;VladimirWork;migration_failure.PNG;https://jira.hyperledger.org/secure/attachment/12426/migration_failure.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk7j:",,,,,,14,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,,ashcherbakov,danielhardman,krw910,mgbailey,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/17 1:01 PM;mgbailey;[^icenode 3_log.txt] contains the logs from the steward that we attempted to onboard onto the live network.  It shows a similar problem when attempting to sync the domain ledger.  The logs say it is attempting to sync beginning at entry #17.  Entries 1-16 are contained in the genesis file, which were verified to be correct.;;;","06/Oct/17 6:06 PM;ashcherbakov;I think I got the issue:
- old domain genesis txns contained NULLS (which were saved in domain ledger for first 10 nodes)
- new domain genesis txns contain only non-Null values, and the Node11 has different ledger because of this.

We will think how to fix this better and provide a fix.;;;","06/Oct/17 6:30 PM;ashcherbakov;We're going to provide a migration for this (to get rid of NULL values in existing ledgers).
The question is how to deliver it the best way:
* Option1:
create a new RC with just a hot fix for this migration
* Option2:
include this migration into the next RC 

If this is a critical issue, then probably Option1 is better (we may have a delay with Option 2 since we have lots of quite risky features in the next RC). 
regardless of Option, it needs to be tested properly.;;;","10/Oct/17 4:28 PM;ashcherbakov;New RC: 1.1.40
Migration script: https://github.com/hyperledger/indy-node/blob/stable/data/migrations/deb/helper_1_1_37_to_1_1_38.py;;;","11/Oct/17 12:59 AM;ashcherbakov;Changes after migration is applied:
1) All domain ledgers will be the same (no null values there)
2) If user's config (/home/sovrin/.sovrin/sovrin_config.py) contains {code}domainTransactionsFile = 'transactions_live'{code} (this is the case for live pool), then this line will be renamed to {code}domainTransactionsFile = 'domain_transactions_live'{code} It's needed because domain_ prefix was added to domain ledger files, so it's better to have all names equal on all Nodes.
We're planning to deprecate modification of domainTransactionsFile in config (there will be network_name parameter instead to define a network (live, test., etc.)).
3) New Nodes should also have `domainTransactionsFile = 'domain_transactions_live'` in their config (otherwise they will not be able to see genesis file).;;;","12/Oct/17 3:07 AM;VladimirWork;Steps to Reproduce:

1. Install 1.0.28 pool of 4 nodes and send some NYMs.
2. Upgrade it to 1.1.37 with force=True (and the whole pool at the same time) and send some NYMs.
3. Upgrade it to 1.1.40 with force=False and send some NYMs.
4. Add 5th (1.1.40) node and send some NYMs.
5. Add 6th (1.1.40) node and send some NYMs.

Actual results:
When we add 5th node (1.1.40) to 1.1.40 pool (4 nodes) the 5th node catches up successfully, but doesn't participate in consensus (so other NYMs write in initial 4 nodes only)
When we add 6th node (1.1.40) to that pool (5 nodes) the 6th node catches up succesfully, but pool falls in broken state (other NYMs don't write in any of 6 nodes).
See debug logs for additional info. [^_node1.txt]  [^_node2.txt]  [^_node3.txt]  [^_node4.txt]  [^_node5.txt]  [^_node6.txt] 

Expected Results:
Pool should work normally after both nodes adding.

*Workaround:
Restart all 6 nodes in the pool.*;;;","13/Oct/17 1:59 AM;VladimirWork;Steps to Reproduce - Case 2:

1. Install 1.0.28 pool of 4 nodes and send some NYMs.
2. Upgrade it to 1.1.37 with force=True (and the whole pool at the same time) and send some NYMs.
3. Add 5th (1.1.37, node-control-tool wasn't stopped before upgrade) node and send some NYMs.
4. Upgrade the whole pool (5 nodes) to 1.1.40 with force=True and send some NYMs.

Actual Results:
Upgrade of 5th node is failed. 5th node is rolled back to 1.0.28 due to migration script's applying failure. See attachments for more info. [^journal.txt]  !migration_failure.PNG|thumbnail! ;;;","13/Oct/17 11:01 PM;VladimirWork;There are results of pool upgrade scenarios (1.1.40 version):

Scenario 1.1: install 1.0.28 pool of 4 nodes -> upgrade the pool with force=True to 1.1.37 -> add 1.1.37 5th node with genesis ledger -> upgrade the pool with force=False to 1.1.40 -> add 1.1.40 6th node [FAILED: 5th node is not upgraded and not catched up, 6th node's adding breaks the pool]

Scenario 1.2: install 1.0.28 pool of 4 nodes -> upgrade the pool with force=True to 1.1.37 -> add 1.1.37 5th node with genesis ledger -> upgrade the pool with force=True to 1.1.40 -> add 1.1.40 6th node [PASSED: 5th node is upgraded and catched up, 6th node is catched up, pool works]

Scenario 2: install 1.0.28 pool of 4 nodes -> upgrade the pool with force=True to 1.1.37 -> add 1.1.37 5th node with genesis ledger -> -> upgrade the pool with force=True to 1.1.40 and with 5th node turned off after the upgrade txn is scheduled -> add 1.1.40 6th node [UNCLEAR: 5th node is not upgraded but catched up, 6th node is catched up, pool works]

Scenario 3: install 1.0.28 pool of 4 nodes -> upgrade the pool with force=True to 1.1.37 -> add 1.1.37 5th node with genesis ledger -> shut down the pool and manually upgrade each node to 1.1.41 -> add 1.1.41 6th node [UNCLEAR: 5th node is catched up after the manual upgrade, 6th node is catched up, pool works, but initial 4 nodes downgrade back to 1.1.37 (INDY-869)]

Scenario 4: install 1.0.28 pool of 4 nodes -> upgrade the pool with force=True to 1.1.37 -> add 1.1.37 5th node with copied ledger -> upgrade the pool with force=False to 1.1.40 -> add 1.1.40 6th node [FAILED: 5th node is upgraded and catched up, there are duplicated entries in ledger after the 1.1.40 pool upgrade, 6th node is catched up after adding but is not in consensus with other 5 nodes];;;","13/Oct/17 11:29 PM;ashcherbakov;The problem mentioned in https://jira.hyperledger.org/browse/INDY-895?focusedCommentId=32050&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-32050 is fixed in RC 1.1.41;;;","16/Oct/17 6:43 PM;VladimirWork;New found issue is reported as INDY-908.;;;","17/Oct/17 9:36 PM;VladimirWork;Build Info:
indy-node 1.1.41

Steps to Validate:
1. Install 1.0.28 pool of 4 nodes.
2. Upgrade the pool with force=True to 1.1.37.
3. Add 1.1.37 5th node with genesis ledger.
4. Upgrade the pool with force=True to 1.1.40.
5. Add 1.1.40 6th node.

Actual Results:
5th node is upgraded and catched up, 6th node is catched up and reached consensus, pool works normally.

Addititonal Info:
More info about all tests run is in https://jira.hyperledger.org/browse/INDY-895?focusedCommentId=32104&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-32104. All related issues found during this ticket confirmation testing are reported in INDY-869, INDY-908, INDY-909.;;;","19/Oct/17 11:36 PM;VladimirWork;Build Info:
indy-node 1.1.43

Steps to Validate - Case 2:
1. Install 1.1.37 pool of 4 nodes.
2. Add schema to ledger.
3. Add claim definition using schema from Step 2.
4. Upgrade the pool (with force=True or force=False) to 1.1.43.

Actual Results:
Migration script 1.1.37->1.1.38 is applied succesfully. All ledger entries are converted normally during the upgrade.

Additional Info:
There was an issue with the migration of schema and claim def ledger's entries in 1.1.42:

{quote}
Oct 19 09:21:01 005c42ac09ef env[68]: Traceback (most recent call last):
Oct 19 09:21:01 005c42ac09ef env[68]:   File ""/usr/local/lib/python3.5/dist-packages/data/migrations/deb/helper_1_1_37_to_1_1_38.py"", line 202, in <module>
Oct 19 09:21:01 005c42ac09ef env[68]:     migrate_all()
Oct 19 09:21:01 005c42ac09ef env[68]:   File ""/usr/local/lib/python3.5/dist-packages/data/migrations/deb/helper_1_1_37_to_1_1_38.py"", line 195, in migrate_all
Oct 19 09:21:01 005c42ac09ef env[68]:     migrate_domain_ledger_for_node(node_data_dir)
Oct 19 09:21:01 005c42ac09ef env[68]:   File ""/usr/local/lib/python3.5/dist-packages/data/migrations/deb/helper_1_1_37_to_1_1_38.py"", line 137, in migrate_domain_ledger_for_node
Oct 19 09:21:01 005c42ac09ef env[68]:     new_name)
Oct 19 09:21:01 005c42ac09ef env[68]:   File ""/usr/local/lib/python3.5/dist-packages/data/migrations/deb/helper_1_1_37_to_1_1_38.py"", line 49, in __migrate_ledger
Oct 19 09:21:01 005c42ac09ef env[68]:     txn[DATA] = json.loads(txn[DATA])
Oct 19 09:21:01 005c42ac09ef env[68]:   File ""/usr/lib/python3.5/json/__init__.py"", line 312, in loads
Oct 19 09:21:01 005c42ac09ef env[68]:     s.__class__.__name__))
Oct 19 09:21:01 005c42ac09ef env[68]: TypeError: the JSON object must be str, not 'OrderedDict'
Oct 19 09:21:01 005c42ac09ef su[1183]: pam_unix(su:session): session closed for user sovrin
Oct 19 09:21:01 005c42ac09ef env[68]: 2017-10-19 09:21:01,675 | ERROR    | 1_1_37_to_1_1_38.py  (28) | <module> | Migration failed: script returned 1
Oct 19 09:21:01 005c42ac09ef env[68]: Traceback (most recent call last):
Oct 19 09:21:01 005c42ac09ef env[68]:   File ""/usr/local/lib/python3.5/dist-packages/data/migrations/deb/1_1_37_to_1_1_38.py"", line 29, in <module>
Oct 19 09:21:01 005c42ac09ef env[68]:     raise Exception(msg)
Oct 19 09:21:01 005c42ac09ef env[68]: Exception: Migration failed: script returned 1
{quote};;;","24/Oct/17 5:30 AM;danielhardman;So if we had an issue with 1.1.42, what should be done about it? Are we ignoring it because nobody will have 1.1.42 deployed? Or does it need some attention before we close the ticket?;;;","24/Oct/17 4:15 PM;VladimirWork;This issue with 1.1.42 doesn't need any additional attention because our release candidate to stable is 1.1.43. This information was added just for explanation why the additional test case was used.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ATTR cannot be added without dest,INDY-896,21371,,Bug,To Develop,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,mzk-vct,mzk-vct,07/Oct/17 2:48 AM,08/Nov/18 4:47 PM,28/Oct/23 2:47 AM,,,,,,0,,,,,,"According to [Sovrin (Indy) Transaction Types|https://docs.google.com/spreadsheets/d/1ELPxVjYwmjTc4BGb9VzabguZtocfsR74cLlSdTlO6-I/edit#gid=657206024] document if no 'dest' specified origin should be used instead (adding attribute for own did).

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx14f:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,Derashe,mzk-vct,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/18 3:34 AM;ozheregelya;Dest (did) is also mandatory parameter in ledger attrib command of indy-cli. [~ashcherbakov], [~gudkov], is this requirement still actual? Should I create similar ticket for indy-cli in IS project?;;;","09/Jan/18 5:38 PM;ashcherbakov;This ticket is not about old CLI, but rather about implementation and validation of this on Ledger side.
Let's decide whether this is a critical requirement (I think it's desirable, but not critical). 
Once it's done on Ledger side (in the scope of current ticket), we can create a ticket for libindy CLI.;;;","08/Nov/18 4:46 PM;Derashe;I think the most easy way to do that is to implement logic on sdk side: if sender did not set dest, than set dest to his identifier.

Why is it harder to implement on node side:
 * We could add dest field to txn right after checking signature (because adding new filed will breake signature), but in this case we will need to check signature again when pre-prepare propagated, and that will break the trick
 * We could add just some dynamic validation logic, but in this case txn will be written as is (without dest) anyway

If this must be done on node side, than we need to implement logic of applying right state (i.e. checking if dest present) and this need really deep analyse to be sure that we would not get problems with inequal hash state roots. For now i think we can postpone such a minor problem (and do not do such a serious changes).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to send an upgrade transaction without including demoted nodes,INDY-897,21705,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,krw910,krw910,09/Oct/17 1:37 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"We are unable to send a pool upgrade transaction if you do not include all nodes that have ever been a part of the pool. If you have a node that has been demoted from the pool you cannot send an upgrade transaction without including it in the transaction.

# Create a pool with 4 nodes. 
# Add a 5th node to the pool.
# Remove the 5th node from the pool by demoting it.
# Now try to send a pool upgrade transaction to just the 4 nodes in the pool.

*{color:#d04437}Error{color}*
You will get an error message telling you that all the nodes must be in the transaction. The issue is the 5th node is no longer a part of the pool.

We have a ""force=True"" parameter that would allowed the transaction to be sent, but that option has issues and cannot be used.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jan/18 11:38 PM;VladimirWork;INDY-897.PNG;https://jira.hyperledger.org/secure/attachment/14396/INDY-897.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzytyf:",,,,,,Sprint 18.02 Stability,,,,,,,,,,,,,,,,,,,,dsurnin,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jan/18 9:37 PM;dsurnin;Problem reason:
service status was not checked

Changes:
check service status

Versions:
master plenum 226
master node 280

Risk factors:
upgrade

Risk:
low

Covered with tests:
indy_node/test/upgrade/test_upgrade_pool_with_demoted_nodes.py;;;","24/Jan/18 11:37 PM;VladimirWork;Build Info:
indy-node 1.2.281

Steps to Validate:
1. Create a pool with 4 nodes.
2. Add a 5th node to the pool.
3. Remove the 5th node from the pool by demoting it.
4. Try to send a pool upgrade transaction to just the 4 nodes in the pool.
5. Demote any node of initial 4.
6. Try to send a pool upgrade transaction to just the 3 nodes in the pool.

Actual Results:
Both commands schedule successfully. !INDY-897.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support Indy branding in OpenShift environment from sovrin-environments,INDY-898,21711,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,krw910,spivachuk,spivachuk,09/Oct/17 10:01 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"The changes made in scope of the platform rebranding from Sovrin to Indy must be supported in OpenShift environment from {{sovrin-environments}}.

Also in scope of this ticket, ensure that OpenShift environment defaults to using deb packages from {{stable}} repository.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzx0nr:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jan/18 2:28 AM;ashcherbakov;Done in the scope of https://jira.hyperledger.org/browse/INDY-1064;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support Indy branding in CloudFormation environment from sovrin-environments,INDY-899,21712,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,krw910,spivachuk,spivachuk,09/Oct/17 10:01 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"The changes made in scope of the platform rebranding from Sovrin to Indy must be supported in CloudFormation environment from {{sovrin-environments}}.

Also in scope of this ticket, ensure that CloudFormation environment defaults to using deb packages from {{stable}} repository.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzx0nz:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jan/18 2:29 AM;ashcherbakov;Done in the scope of https://jira.hyperledger.org/browse/INDY-1064;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add indy-sdk test dependency to plenum,INDY-900,21748,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ashcherbakov,ashcherbakov,10/Oct/17 5:35 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,should,,,,,"We need to be able to use indy-sdk for tests.
We should take a version of indy-sdk and add it as a *test* dependency. ",,,,,,,,,,,,,,INDY-903,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-875,,,,,,,,,,"1|hzx0xz:",,,,,,INDY 17.23,INDY 17.24: Node Perf,,,,,,,3.0,,,,,,,,,,,,andkononykhin,ashcherbakov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Nov/17 11:46 PM;andkononykhin;*PoA*
 # add steps to dockerfiles:
 ** add sdk apt repo to docker files
 ** install libindy deb from there
 ** install python3-indy from pypi
 ** configure apt pinning to prefer other indy sdk packages form core apt repo
 # configure apt repos labels to make apt pinning possible;;;","23/Nov/17 10:03 PM;andkononykhin;PRs to indy core repos:

https://github.com/hyperledger/indy-node/pull/464
https://github.com/hyperledger/indy-anoncreds/pull/113
https://github.com/hyperledger/indy-plenum/pull/460;;;","24/Nov/17 6:34 PM;andkononykhin;Problem reason:
 - indy-sdk is not in current dev environment but it needs to be for coming integration tests

Changes:
 - updated dockerfiles to install libindy deb package form sdk apt repo
 - added python3-indy (python wrapper) into tests dependencies for plenum's and node's setup.py

Committed into:
 - [https://github.com/hyperledger/indy-node/pull/464]
 - [https://github.com/hyperledger/indy-anoncreds/pull/113]
 - [https://github.com/hyperledger/indy-plenum/pull/460]

Risk factors:
 - Nothing is expected.

Risk:
 - Low

Covered with tests:
 - tested manually

Recommendations for QA: do the following sequence of steps
 * install charm-crypto as described https://github.com/hyperledger/indy-anoncreds#prerequisites-for-debian-based-systems
 * check that python wrapper is installed for tests
 ** clone indy-plenum / indy-node
 ** create and activate virtual environment:
 *** *virtualenv -p python3 venv && source venv/bin/activate*
 ** run *pip install .[tests]*
 ** check that python3-indy is installed: *pip list | grep python3-indy*
 * check that libindy is instaled in ci environment (ci docker image)
 ** clone  indy-node
 ** create base images *make -C docker-files/baseimage*
 ** create ci image for indy-node *docker build -t indy-node-test -f ci/ubuntu.dockerfile ci*
 ** check that libindy is presented in that image *docker run -it --rm indy-node-test bash -c ""dpkg -l | grep libindy""*
 ** clone indy-plenum, create ci image (base images are ready after previous steps)  *docker build -t indy-plenum-test -f ci/ubuntu.dockerfile ci*
 ** check that libindy is presented in that image *docker run -it --rm indy-plenum-test bash -c ""dpkg -l | grep libindy""*;;;","28/Nov/17 12:45 AM;ozheregelya;Build Info:
indy-node 1.2.221

Steps to Validate:
1. Perform necessary steps to check that python wrapper is installed for tests.
=> 
{code:java}
(venv) me@me-VM:~/git/indy-node$ pip list | grep python3-indy
python3-indy (1.1.0){code}
2. Perform necessary steps to check that libindy is instaled in ci environment (ci docker image)
=>
{code:java}
me@me-VM:~/git/indy-plenum$ docker run -it --rm indy-node-test bash -c ""dpkg -l | grep libindy""
ii libindy 1.1.0~270 amd64 This is the official SDK for Hyperledger Indy, which provides a
ii libindy-crypto 0.1.6 amd64 This is the shared crypto libirary for Hyperledger Indy components.
me@me-VM:~/git/indy-plenum$ docker run -it --rm indy-plenum-test bash -c ""dpkg -l | grep libindy""
ii libindy 1.1.0~270 amd64 This is the official SDK for Hyperledger Indy, which provides a
ii libindy-crypto 0.1.6 amd64 This is the shared crypto libirary for Hyperledger Indy components.{code}

Actual Results:
All dependencies present.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use indy-sdk for integration tests in plenum,INDY-901,21749,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,ashcherbakov,ashcherbakov,10/Oct/17 5:43 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"Use indy-sdk to send requests to the pool (instead if current python client) in plenum tests.
Do it for as much tests as possible. If there are some tests where we can not do it because of, for example, a missing feature/specific in libindy, then please create separate tickets for this.",,,,,,,,,,,,,,INDY-903,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-875,,,,,,,,,,"1|hzx0v3:",,,,,,INDY 17.23,INDY 17.24: Node Perf,,,,,,,13.0,,,,,,,,,,,,ashcherbakov,dsurnin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Nov/17 7:54 PM;dsurnin;Indy-SDK integration into indy-node tests

Indy-SDK tests in node tests
 * Create tests to check sdk is able to connect to test pool
 * Create tests to check sdk is able to send requests to test pool
 * Create tests to check sdk is able to receive responses from test pool

Node tests based on Indy-SDK

We should start from the simplest tests: node functionality of the plenum repo.
 * Create fixtures to connect to pool
 * Create fixtures to create wallet with default keys filled
 * Create fixtures to submit and send requests
 * Modify tests that uses sendRandomRequests to use new sdk based fixtures;;;","07/Dec/17 8:56 PM;VladimirWork;There is an issue with test_logging_txn_state.py:

{quote}ImportError while importing test module '/home/alexander/indy-plenum/plenum/test/logging/test_logging_txn_state.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
plenum/test/logging/test_logging_txn_state.py:13: in <module>
    from plenum.test.sdk.helper import send_random_and_check
E   ImportError: No module named 'plenum.test.sdk.helper'{quote};;;","08/Dec/17 6:12 PM;VladimirWork;Build Info:
indy-plenum (master)

Steps to Validate:
1. Run ~/indy-plenum/plenum/test/.. tests (master) via pytest.

Actual Results:
All tests run normally (without environment or import errors).

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use indy-sdk for integration tests in indy-node,INDY-902,21750,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,Derashe,Derashe,ashcherbakov,10/Oct/17 5:44 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,Use indy-sdk for sending requests to the pool in indy-node,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-875,,,,,,,,,,"1|hzwx87:",,,,,,Ev 18.23,,,,,,,,5.0,,,,,,,,,,,,ashcherbakov,Derashe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Nov/18 12:04 AM;Derashe;*PoA:*

We've integrated almost all tests from indy-node folder in previous tasks. Cli tests mainly have been left in indy-client folder. Some of them (cli specific) we need to mark as deprecated, cause we will delete them in future tickets. Some of them (with common for cli and sdk logic) must be integrated with sdk and transferred to indy-node folder.

To deprecate:

indy-client/test/training/*

indy-client/test/agent/*

indy-client/test/client/*

indy-client/test/cli/ (part of it)

To integrate:

indy-client/test_nym_attrib

indy-client/test/anoncreds/*

indy-client/test/state_proof/*

indy-node/indy_node/test/did/*

indy-client/test/cli/ (part of it);;;","13/Nov/18 12:22 AM;Derashe;Integration progress: 

[https://docs.google.com/spreadsheets/d/1Pu8OOURWoeazt9Dv11AHNnURn1DWzLuqQbcIX9urdlU/edit?usp=sharing];;;","22/Nov/18 12:15 AM;Derashe;Problem reason:
 * We are using old cli for our tests

Changes:
 * All tests are integrated, cli code removed from tests

Committed into:
 * https://github.com/hyperledger/indy-node/pull/1049
 * [https://github.com/hyperledger/indy-node/pull/1045]
 * [https://github.com/hyperledger/indy-node/pull/1036]
 * [https://github.com/hyperledger/indy-node/pull/1034]
 * [https://github.com/hyperledger/indy-node/pull/1033]
 * [https://github.com/hyperledger/indy-node/pull/1032]
 * https://github.com/hyperledger/indy-plenum/pull/983

Risk:
 * Low

Recommendations for QA: 
 * Nothing to validate;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove python CLI and client code,INDY-903,21751,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ozheregelya,ashcherbakov,ashcherbakov,10/Oct/17 5:45 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,1.6.79,,,0,,,,,,"Once indy-sdk is used for tests, and we have a CLI in indy-sdk, remove all client and CLI code from plenum and indy-node.",,,,,,,,,,,INDY-900,INDY-901,IS-274,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-875,,,,,,,,,,"1|hzwx07:",,,,,,EV 18.24,,,,,,,,3.0,,,,,,,,,,,,ashcherbakov,Derashe,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Nov/18 5:54 PM;Derashe;PRs:
 * [https://github.com/hyperledger/indy-node/pull/1051]
 * https://github.com/hyperledger/indy-plenum/pull/986;;;","23/Nov/18 10:39 PM;ozheregelya;Upgrade should be tested because of removing indy-anoncreds form dependencies.;;;","24/Nov/18 1:20 AM;ozheregelya;Verified in scope of INDY-1850.

*Environment:*
 indy-node 1.6.634 -> 1.6.688 -> 1.6.699
 sovrin 1.1.62 -> 1.1.91 -> 1.1.93

*Steps to Validate:*
 1. Check upgrade to new version.
 2. Check upgrade from new version.
3. Check rollback after failed upgrade and manual upgrade.
 (see [https://docs.google.com/spreadsheets/d/1ZeeTy0iwP2UhU-y2nJF3HNGlx0NZoLTgIEe9EwxQVQ8/edit#gid=1122130859] for details about upgrade cases)

*Actual Results:*
 Upgrade works.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failure to sync with domain ledger,INDY-904,21827,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,nage,mgbailey,mgbailey,13/Oct/17 6:53 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Metis, a node on the ESN, has been experiencing difficulties since the network upgraded to 1.1.37.  As a ""last resort"" we removed the .sovrin/data directory to get the node to a reset state.  The node matches the version information of the other nodes on the network, and the services were down when we removed the directory.  The expectation was that the ledgers would sync when the sovrin-node service was brought back up.

The config ledger had been deleted on all nodes, so no sync was needed on that ledger.  The pool ledger synced normally.  But the domain ledger never synced, although it is evident in the logs that there was an attempt.  The domain genesis file contains 15 entries, and only these 15 entries ever appear on the ledger.  The other network validators have 43800 transactions on each.

This customer node has been down for 2 weeks now, and patience is gone.","ESN, Indy node version 1.1.37",,,,,,,,,,,,,,,,,,,,,,,,,,INDY-907,,,,,,,,"13/Oct/17 6:53 AM;mgbailey;metis-10-12-17.txt;https://jira.hyperledger.org/secure/attachment/12427/metis-10-12-17.txt","17/Oct/17 1:01 AM;mgbailey;play_log.tgz;https://jira.hyperledger.org/secure/attachment/12511/play_log.tgz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk8f:",,,,,,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,mgbailey,mzk-vct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Oct/17 7:42 AM;krw910;[~ashcherbakov] This is a high priority issue and is being escalated to the current sprint.;;;","13/Oct/17 9:32 PM;mzk-vct;Looks like the ledger is too large to be fully synced using catchup.
I tried to reproduced it on a local pool and found that it is time consuming even to start node with such a huge ledger. It takes ~4 minutes.
Catchup failed too.

Quick workaround for this problem is just to copy domain ledger from other node.
It is the most simple and quick way to solve it as of now.

Here is the new ticket https://jira.hyperledger.org/browse/INDY-907
;;;","17/Oct/17 12:14 AM;ashcherbakov;The immediate issue is solved by copying the domain ledger.
The rest of the problem will be addressed in INDY-907.;;;","17/Oct/17 1:02 AM;mgbailey;[^play_log.tgz] is the corresponding logs on the 'play' node, which is the primary on the network, and which has logging set to trace.  Play is the the GMT timezone, and metis is in the CDT timezone, so there is a 5 hour offset in the logs.;;;","19/Oct/17 4:18 AM;krw910;We will track the rest of the issue in the new ticket that was logged and close this one.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Steward can't change blskey.,INDY-905,22000,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,ozheregelya,ozheregelya,13/Oct/17 9:11 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"Steps to Reproduce:

1. Set up the pool.
2. Open the CLI.
3. Set yourself as existing node Steward.
4. Send NODE transaction with other blskey.
{code:java}
sovrin@test> send NODE dest=4SWokCJWJc69Tn74VvLS6t2G2ucvXqM9FDMsWJjmsUxe data={'client_port': 9710, 'client_ip': '10.0.0.6', 'alias': 'Node5', 'node_ip': '10.0.0.6', '
node_port': 9709, 'blskey':'4YUUShLgQLdqmMZWfoWxZJpwtQu4CA8YHMszoXVUmiq7pEjQj8vHWWG4Ea77TVuAZQWgubFgqFZwr2agTFm1p6bgiUz6eEecY27EwJVtdvzHa2FYtGhDvNA1JP5557xDgj57LK15etrx9TRwKDmrfAJdDkQrJQ6h7PrLM6MfVsQqHnd'}{code}


Actual Results:
{code:java}
Node request failed with error: client request invalid: UnauthorizedClientRequest(""key '0_blskey_2JSLkTGhnG3ZzGoeuZufc7V1kF5wxHqTuSUbaudhwRJzsGZupNHs5igohLnsdcYG7kFj1JGC5aV2JuiJtDtHPKBeGw24ZmBJ44YYaqfCMi5ywNyP42aSjMkvjtHrGS7oVoFbP4aG4aRaKZL3UZbbGcnGTK5kfacmBNKdPSQDyXGCoxB_4YUUShLgQLdqmMZWfoWxZJpwtQu4CA8YHMszoXVUmiq7pEjQj8vHWWG4Ea77TVuAZQWgubFgqFZwr2agTFm1p6bgiUz6eEecY27EwJVtdvzHa2FYtGhDvNA1JP5557xDgj57LK15etrx9TRwKDmrfAJdDkQrJQ6h7PrLM6MfVsQqHnd' not found in authorized map"",){code}


Expected Results:
Transaction should be successfully send.","Build Info:
 indy-node 1.1.161
 indy-anoncreds 1.0.32
 indy-plenum 1.1.143
OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/17 10:29 PM;VladimirWork;905.PNG;https://jira.hyperledger.org/secure/attachment/12719/905.PNG","18/Oct/17 8:58 PM;VladimirWork;trustee_changes_bls.PNG;https://jira.hyperledger.org/secure/attachment/12512/trustee_changes_bls.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk8n:",,,,,,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,,,ashcherbakov,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Oct/17 6:59 PM;ashcherbakov;Fixed.
There was a missing rule in Authorizer for changing of bls-key.
Also added unit tests for Authorizer (we didn't have any) and integration test to change BLS keys from CLI.

PR: https://github.com/hyperledger/indy-node/pull/400

Fixed in 1.1.165;;;","18/Oct/17 8:58 PM;VladimirWork;Build Info:
indy-node 1.1.167

Preconditions:
Install pool of 4 nodes.

Steps to Reproduce:
1. Generate new blskey for Node1.
2. Send node txn with new blskey as Steward1.
3. Send NYM to check that pool is working.
4. Send node txn from Step 2 as Trustee1.

Actual Results:
Step 4 txn performs successfully. !trustee_changes_bls.PNG|thumbnail! 

Expected Results:
Node's blskey should be changed by its node Steward only.;;;","23/Oct/17 5:51 PM;ashcherbakov;Can not reproduce the issue (both in the pool and in integration tests).
Added tests that prove that everything works as expected.

PR: https://github.com/hyperledger/indy-node/pull/410

Build: 1.1.173;;;","23/Oct/17 10:29 PM;VladimirWork;Build Info:
indy-node 1.1.173

Steps To Validate:
1. Generate new blskey for Node1.
2. Send node txn with new blskey as Trustee1 (or other role that is not a Steward of Node1).

Actual Results:
""%ROLENAME% not in allowed roles ['STEWARD']"" error message.

Additional Info:
If we send node txn as Steward of node and send it again (without changes) as any other role - permissions don't check (because node info is not updated) so txn looks successful in the CLI. It will be fixed in scope of separate ticket. !905.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
There is no init_bls_keys script in /usr/local/bin,INDY-906,22001,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,ozheregelya,ozheregelya,13/Oct/17 9:15 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"Steps to Reproduce:
1. Connect to the node.
2. cd /usr/local/bin
3. Look at scripts.

Actual Result:
There is no init_bls_keys script.

Expected Results:
init_bls_keys script should present after installation of indy-node package.","Build Info:
 indy-node 1.1.161
 indy-anoncreds 1.0.32
 indy-plenum 1.1.143
OS/Platform: Ubuntu 16.04.2 LTS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk8v:",,,,,,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,,,ashcherbakov,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Oct/17 2:02 AM;ashcherbakov;Fixed in 1.1.164;;;","19/Oct/17 8:24 PM;VladimirWork;Build Info:
indy-node 1.1.167

Steps to Validate:
1. Connect to the node.
2. cd /usr/local/bin
3. Look at scripts.

Actual Results:
init_bls_keys script is present after installation of indy-node package. BLS keys are generated successfully.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance catch up mechanism to let it work with large ledgers,INDY-907,22002,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,mzk-vct,mzk-vct,13/Oct/17 9:31 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"If there is a large domain ledger and you add one new node to the pool you risk to fail because catch-up cannot complete. New node sends catchup requests, but gets no replies from the pool.

Such a situation is described in https://jira.hyperledger.org/browse/INDY-904 

Furthermore it would probably be good to think out another mechanism for such cases. 
Like usage of torrent protocol or something similar.",,,,,,,,,,,,,,,,,,,,,,,INDY-904,,,,,,,,,,,,"23/Oct/17 6:37 PM;VladimirWork;Node4.log.tar.gz;https://jira.hyperledger.org/secure/attachment/12718/Node4.log.tar.gz","23/Oct/17 6:37 PM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/12715/_node1.txt","23/Oct/17 6:37 PM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/12716/_node2.txt","23/Oct/17 6:37 PM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/12717/_node3.txt","23/Oct/17 6:36 PM;VladimirWork;duplicate_NYM.PNG;https://jira.hyperledger.org/secure/attachment/12714/duplicate_NYM.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk4v:",,,,,,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,,,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Oct/17 12:56 AM;mzk-vct;Also check message size limitation ;;;","19/Oct/17 10:11 PM;mzk-vct;Problem is caused by message size limitation - catchup response can be too large.
Following pull request introduces mechanism for splitting messages on smaller parts have been introduced:
https://github.com/hyperledger/indy-plenum/pull/423/files;;;","20/Oct/17 1:41 AM;mzk-vct;Node version: 1.1.170;;;","23/Oct/17 6:37 PM;VladimirWork;Build Info:
indy-node 1.1.171

Steps to Reproduce:
1. Install a pool of 4 nodes.
2. Write 100k NYMs via load_test.py script.
3. Stop the 4th node and delete .sovrin/data/ folder.
4. Start the 4th node.

Actual Results:
The 4th node catched up 536 entries out of 100k. There is an info in log about discarding CATCHUP_REP message because it contains duplicates or gaps. [^_node1.txt]  [^_node2.txt]  [^_node3.txt]  [^Node4.log.tar.gz] 

Expexted Results:
The 4th node should catch up successfully.

Additional Info:
There is at least one duplicated NYM entry in the ledger that was added manually (but there should be no issues with catch up of duplicate entries because this is a normal case). !duplicate_NYM.PNG|thumbnail! 
Although small ledger (18 txns) with 3 duplicated entries catches up successfully in this case.
Also the 4th node doesn't catch up after restart.;;;","26/Oct/17 12:16 AM;mzk-vct;The problem is caused by 'dict' which is used for transactions in CatchupRep message. 
Following pr replaces it by SortedDict
https://github.com/hyperledger/indy-plenum/pull/430;;;","26/Oct/17 11:59 PM;mzk-vct;Node version: 1.2.187;;;","31/Oct/17 12:21 AM;VladimirWork;Build Info:
indy-node 1.2.188

Steps to Validate:
1. Install a pool of 4 nodes.
2. Write 10..100k NYMs via load_test.py script.
3. Stop the 4th node and delete .indy/data/ folder.
4. Start the 4th node.

Actual Results:
Nodes with large ledgers catch up successfully.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Added node loses ledger after the pool upgrade,INDY-908,22401,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,VladimirWork,VladimirWork,16/Oct/17 6:39 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Build Info:
See Steps to Reproduce.

Overview:
Added node loses ledger after the pool upgrade.

Steps to Reproduce:
1. Install 1.0.28 pool of 4 nodes and send some NYMs.
2. Upgrade it to 1.1.37 with force=True (and the whole pool at the same time) and send some NYMs.
3. Install the 5th node with 1.0.28 version.
4. Reset the 5th node with clear_node.py -- full.
5. Upgrade the 5th node manually to 1.1.37 without applying migration script and without stopping node-control-service (so during upgrade to 1.1.41 there will be not 1 but 2 migration script applyings).
6. Fill the 5th node's ledger with genesis txn (by starting it with 1.1.37 genesis files).
6. Add the 5th node and send some NYMs (5th node shouldn't catch up at this step).
7. Upgrade the whole pool (5 nodes) to 1.1.41 with force=True and send some NYMs.

Actual Results:
After the Step 7 pool upgrade the 5th node loses its ledger (but at installation this node has it with genesis txns).

Expected Results:
Step 7 migration scripts should be applied without errors and the 5th node should keep its ledger after the pool upgrade to catch up with other nodes after it.

Additional Info:
This steps consist special case of single node upgrading and there is a small chance of reproducing it at the live pool.",,,,,,,,,,,,,,,,,,,,,,,INDY-895,,,,,,,,,,,,"16/Oct/17 6:30 PM;VladimirWork;Pasted image at 2017_10_16 12_06 PM.png;https://jira.hyperledger.org/secure/attachment/12501/Pasted+image+at+2017_10_16+12_06+PM.png","16/Oct/17 6:29 PM;VladimirWork;journalctl_1.1.41_migration;https://jira.hyperledger.org/secure/attachment/12502/journalctl_1.1.41_migration",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzx0pr:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 8:10 PM;Derashe;Outdated;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New nodes added to existing pool are unable to participate in consensus after the upgrade,INDY-909,22405,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,VladimirWork,VladimirWork,VladimirWork,16/Oct/17 10:15 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,should,,,,,"Build Info:
indy-node 1.1.41
live pool configuration

Overview:
New nodes added to existing pool are unable to participate in consensus.

Preconditions:
The 1.1.40 pool of 4 nodes installed. The single 1.1.41 node installed.

Steps to Reproduce:
1. Upgrade the pool to 1.1.41 version with force=False.
2. Add the single node to the pool as 5th node.
3. Check that the 5th node catches up and reaches consensus.

Actual Results:
The 5th node cathces up successfully but doesn't reach the consensus.

Expected Results:
The 5th node should catch up and reach consensus successfully.",,,,,,,,,,,,,,,,,,,,,,,INDY-895,,,,INDY-948,,,,,,,,"16/Oct/17 10:15 PM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/12507/_node1.txt","16/Oct/17 10:15 PM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/12506/_node2.txt","16/Oct/17 10:15 PM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/12505/_node3.txt","16/Oct/17 10:15 PM;VladimirWork;_node4.txt;https://jira.hyperledger.org/secure/attachment/12504/_node4.txt","16/Oct/17 10:15 PM;VladimirWork;_node5.txt;https://jira.hyperledger.org/secure/attachment/12503/_node5.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzympz:",,,,,,INDY 17.22,INDY 17.23,,,,,,,,,,,,,,,,,,,andkononykhin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/17 7:37 PM;andkononykhin;PoA:
 # implement test: 5th node added to pool of 4 nodes, 4 view changes already happened, expect node5 will accept current primaries
 # implement logic of collecting pool information using optional argument of ledger size
 # add conditional logic during primary selection routine to use only ledger info which was actual for the moment when view change happened  (possible for nodes that are connected to a running pool);;;","09/Nov/17 10:36 PM;andkononykhin;Problem reason:
 - when node is joined after several view changes happened it will likely choose different primary than other nodes because it operates with different node registry than other nodes
 - as far as I explored the logs there it's not an issue of upgrade

Changes:
 - added logic for newly joined node to accept current primary without sending any view change done messages to other nodes
 - besides that such a node during primary selection chooses pool ledger of the state actual for the moment when view change happened (according to information from CURRENT_STATE messages)
 - did some refactoring
 - fixed some low level util api
 - added api to cancel scheduled events
 - added tests

Committed into:
 - https://github.com/hyperledger/indy-plenum/pull/443

Risk factors:
 - Nothing is expected.

Risk:
 - Low

Covered with tests:
 - https://github.com/hyperledger/indy-plenum/blob/master/plenum/test/primary_selection/test_new_node_accepts_chosen_primary.py

Recommendations for QA: do the following sequence of steps
 * start pool of 4 nodes
 * force 4 view changes
 * add new node
 * ensure that pool works properly and all 5 nodes chose Alpha:0 as a master primary and Beta:1 as a primary for backup instance;;;","13/Nov/17 6:50 PM;VladimirWork;Build Info:
indy-node 1.2.208

Steps to Validate:
1. Start pool of 4 nodes.
2. Force 4 view changes.
3. Add new node.

Actual Results:
Pool works properly and all 5 nodes chose Node1:0 as a master primary and Node2:1 as a primary for backup instance.
Normal cases with nodes adding (without view changes) also works.

Additional info:
Special case with two nodes adding and more view changes reported as INDY-948.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
----------MARKER NEW TICKETS BELOW--------------------------------------------------------------------------------------------------------,INDY-910,22489,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,krw910,krw910,19/Oct/17 4:20 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzygnb:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Pool stopped taking transactions after sending 1,000 simultaneous transactions",INDY-911,22490,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,,krw910,krw910,19/Oct/17 5:04 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Must,performance,,,,"I have a 7 node pool.
I have an additional 5 machines setup running libindy with some performance generating scripts.

On each of the 5 machines the script runs 200 threads sending 30 transactions each one at a time. So across the 5 machines I am sending 1,000 transactions at a time.

The pool received and processed about 8 transactions and then stopped taking any new transactions. I stopped the scripts and tried from the CLI which also failed to add a new transaction.

The pool functioned properly after restarting the nodes.

Each node in the pool shows the same error in its log at about the same time.
*{color:#d04437}commit failed for batch request, error IndexError('list index out of range'{color}*

I have seen this error before under a load less than 1,000 at a time. 

I am including only a portion of one of the logs since their size is too big to attach. I have all 7 logs (223 MB) if anyone needs me to send them.",,,,,,,,,,,,,,INDY-893,,,,,,,,,INDY-960,,,,,,,,,,,,"19/Oct/17 4:55 AM;krw910;Node1 - Copy.log;https://jira.hyperledger.org/secure/attachment/12517/Node1+-+Copy.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzypxj:",,,,,,INDY 17.24: Node Perf,INDY 17.25,,,,,,,,,,,,,,,,,,,krw910,ozheregelya,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/17 1:47 PM;krw910;I have now seen this with just 200 simultaneous transactions.;;;","09/Dec/17 1:10 AM;spivachuk;Problem reason:
- The issue with warnings about that a node is trying to commit a batch with a particular state root but no uncommitted found was caused by a missed call of {{Node.onBatchCreated}} method on re-applying a batch prior to ordering before ledgers synchronization in case the batch was rejected previously due to catch-up start. This resulted in absence of the batch in {{IdrCache.uncommitted}} list when the batch was being ordered by the node.
- The issue with warnings about {{IndexError}} was revealed by the previous one and caused by a missed {{return}} statement in {{IdrCache.onBatchCommitted}} method.

Problem state:
- Both the issues were fixed in scope of INDY-960.;;;","15/Dec/17 12:03 AM;ozheregelya;Version Info:
indy-node 1.2.236

Case 1:
Steps to Validate:
1. Setup the pool of 7 nodes.
2. Run load_test with different parameters.

Actual Results:
Pool works correctly.

There are some problems with node demotion under load. They are described in INDY-1033.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix documentation: init_indy_node now must be called several time for each desired network,INDY-912,22498,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,dsurnin,dsurnin,19/Oct/17 9:13 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"For the moment init_indy_node script should be called only once, right after node installed.

After new file structure will be implemented the init_indy_node script must be called once for each network. So every document that mentions init_indy_node script run, should now be changed to something like this
 * open /etc/indy/indy_config.py
 * change NETWORK_NAME parameter to desired network
 * run init_indy_node as before

NOTE: now these steps must be done for each network

 ",,,,,,,,,,,INDY-831,INDY-832,INDY-833,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0m7:",,,,,,INDY 17.22,INDY 17.23,,,,,,,1.0,,,,,,,,,,,,ashcherbakov,dsurnin,krw910,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Oct/17 11:19 PM;TechWritingWhiz;""every document"".....


Every document --where? Which repositories are we talking about? Is there an initial known list of documents you know of? What is the due date for this ticket?;;;","20/Oct/17 2:35 PM;dsurnin;The changes I'm talking about will be done in indy-plenum, indy-node and sovrin repositories. For the moment I'm preparing build to test these changes and after testing the changes will be included into RC. So probably the user documentation for that RC should contain proper description of indy-node starting procedure.

I have not checked all the user documentation we have and for now I can think of documents like this

[https://docs.google.com/document/d/1fUrvt8rEekZmpfHjoeod7ZmWh3ISvSf-18vK5yTH6RY/edit#|https://docs.google.com/document/d/1fUrvt8rEekZmpfHjoeod7ZmWh3ISvSf-18vK5yTH6RY/edit]

 

Probably we should ask QA team to help;;;","20/Oct/17 2:40 PM;dsurnin;[~ozheregelya] [~VladimirWork]

Have you checked the user documentation?

Could you please think of which one contains description of indy-node starting process, initial configuration of the services, key management and generation?;;;","21/Oct/17 12:52 AM;TechWritingWhiz;[~dsurnin] Ok, so all of the How-To guides should be reviewed. If there is documentation in Github itself, that is what I was looking for, if there are any docs in the Github repo itself (.md) that have these instructions to be changed, those documents should be placed in the list as well. I'll wait until you finish up with the results of your testing. This is the list so far:
 * How-to Guides
 * Release Notes;;;","31/Oct/17 7:33 AM;TechWritingWhiz;[~dsurnin] I'm just following up on this ticket. Has your team contributed any other items to be reviewed other than just what I have listed above for where these changes might be? Also, is your testing complete? If not, that is fine. I'm just following up since this is on my radar. When you complete that, will you update this ticket and provide further instructions? ;;;","01/Nov/17 9:36 PM;ashcherbakov;https://github.com/hyperledger/indy-node/pull/427
Fixed this in https://github.com/hyperledger/indy-node/blob/improve-doc/docs/setup-dev.md

I'm not sure what other public documentation we have. ;;;","18/Nov/17 6:39 AM;krw910;The documentation looks good. I will be adding it to the changes needed in the how to documentation.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] GET_SCHEMA must return Schema's seqNo,INDY-913,22500,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,ashcherbakov,ashcherbakov,19/Oct/17 10:24 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Could,,,,,"Schema's seqNo is required for CLAIM_DEF txn, but currently CLI doesn't return it with GET_SCHEMA command.",,,,,,,,,,,,,,,,,INDY-916,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx0rz:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/18 3:22 AM;ozheregelya;In indy-cli (version 1.1.1~306) ledger get-schema command returns schema's Sequence Number:
{code:java}
ledger get-schema did=V4SGRU86Z58d6TV7PBUe6f name=gvt version=1.0
Following Schema has been received.
Metadata:
+------------------------+-----------------+---------------------+---------------------+
| Identifier | Sequence Number | Request ID | Transaction time |
+------------------------+-----------------+---------------------+---------------------+
| V4SGRU86Z58d6TV7PBUe6f | 19 | 1515003574564849875 | 2018-01-03 18:14:41 |
+------------------------+-----------------+---------------------+---------------------+
Data:ledger get-schema did=V4SGRU86Z58d6TV7PBUe6f name=gvt version=1.0
Following Schema has been received.
Metadata:
+------------------------+-----------------+---------------------+---------------------+
| Identifier | Sequence Number | Request ID | Transaction time |
+------------------------+-----------------+---------------------+---------------------+
| V4SGRU86Z58d6TV7PBUe6f | 19 | 1515003574564849875 | 2018-01-03 18:14:41 |
+------------------------+-----------------+---------------------+---------------------+
Data:
+------+---------+--------------+
| Name | Version | Attributes |
+------+---------+--------------+
| gvt | 1.0 | ""name"",""age"" |
+------+---------+--------------+
_
+------+---------+--------------+
| Name | Version | Attributes |
+------+---------+--------------+
| gvt | 1.0 | ""name"",""age"" |
+------+---------+--------------+{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] It should be possible to get CLAIM_DEF for other Issuers ,INDY-914,22504,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,ashcherbakov,ashcherbakov,19/Oct/17 10:57 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Could,,,,,"As of now, GET_CLAIM_DEF command can return CLAIM_DEF issued by the sender (current DID in the CLI) only. 
There is ORIGIN field in GET_CLAIM_DEF request, and CLI always uses current sender's DID for it. In fact, ORIGIN must be provided explicitly. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx0s7:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/18 3:05 AM;ozheregelya;Origin field was added to get-claim-def command in indy-cli (version 1.1.1~306).

 
{code:java}
pool(p1):wallet(wall):did(3a6...bWd):indy> ledger get-claim-def help 
Command:
 ledger get-claim-def - Get Claim Definition from Ledger.
Usage:
 ledger get-claim-def schema_no=<schema_no-value> signature_type=<signature_type-value> origin=<origin-value>
Parameters are:
 schema_no - Sequence number of schema
 signature_type - Signature type (only CL supported now)
 origin - Claim definition owner DID
Examples:
 ledger get-claim-def schema_no=1 signature_type=CL origin=VsKV7grR1BUE29mG2Fm2kX
{code}
{code:java}
pool(p1):wallet(wall):did(3a6...bWd):indy> ledger get-claim-def schema_no=1 signature_type=CL origin=V4SGRU86Z58d6TV7PBUe6f
Following Claim Definition has been received.
Metadata:
+------------------------+-----------------+---------------------+---------------------+
| Identifier | Sequence Number | Request ID | Transaction time |
+------------------------+-----------------+---------------------+---------------------+
| 3a6hBrK2nBLxH5L34HcbWd | 18 | 1515002536360728654 | 2018-01-03 18:00:07 |
+------------------------+-----------------+---------------------+---------------------+
Data:
+----------------------------------------------------------------+----------------+
| Primary Key | Revocation Key |
+----------------------------------------------------------------+----------------+
| {n:""1"",r:{""age"":""4"",""name"":""5""},rctxt:""6"",rms:""3"",s:""2"",z:""7""} | {} |
+----------------------------------------------------------------+----------------+
{code}
 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unclear errors appear in CLI on GET_NYM after upgrade pool from 1.0.28 version.,INDY-915,22505,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,nage,ozheregelya,ozheregelya,19/Oct/17 11:16 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"*Steps to Reproduce:*
 1. Setup the pool with version 1.0.28 (stable).
 2. Send NYM.
 3. Upgrade pool to the 1.1.37 version (stable).
 4. Send NYM.
 5. Upgrade pool to the 1.1.41 version (RC).
 6. Send NYM.
 7. Upgrade pool to the 1.1.165 (master) version.
 8. Send NYM.
 9. Setup bls keys on nodes (init_bls_keys --name nodeN) and send NODE transactions with created bls keys.
 10. Try to GET_NYM for one of created NYMs.

*Actual Results:*
{code:java}
indy@test> send GET_NYM dest=V4SGRU86Z58d6TV7PB7777
Getting nym V4SGRU86Z58d6TV7PB7777
There is a state proof, but no multi signature
6DKmmq7CLbE2vZDZmhFYHZencyyUQz9N1RtNZbvB48wH got reply for (V4SGRU86Z58d6TV7PBUe6f:1508407453717608) with bad multi signature from Node4C
There is a state proof, but no multi signature
6DKmmq7CLbE2vZDZmhFYHZencyyUQz9N1RtNZbvB48wH got reply for (V4SGRU86Z58d6TV7PBUe6f:1508407453717608) with bad multi signature from Node6C
There is a state proof, but no multi signature
6DKmmq7CLbE2vZDZmhFYHZencyyUQz9N1RtNZbvB48wH got reply for (V4SGRU86Z58d6TV7PBUe6f:1508407453717608) with bad multi signature from Node3C
There is a state proof, but no multi signature
6DKmmq7CLbE2vZDZmhFYHZencyyUQz9N1RtNZbvB48wH got reply for (V4SGRU86Z58d6TV7PBUe6f:1508407453717608) with bad multi signature from Node2C
There is a state proof, but no multi signature
6DKmmq7CLbE2vZDZmhFYHZencyyUQz9N1RtNZbvB48wH got reply for (V4SGRU86Z58d6TV7PBUe6f:1508407453717608) with bad multi signature from Node5C
There is a state proof, but no multi signature
6DKmmq7CLbE2vZDZmhFYHZencyyUQz9N1RtNZbvB48wH got reply for (V4SGRU86Z58d6TV7PBUe6f:1508407453717608) with bad multi signature from Node1C
Current verkey for NYM V4SGRU86Z58d6TV7PB7777 is ~V4SGRU86Z58d6TV7PB7777 with role TRUST_ANCHOR{code}
*Expected Results:*
 Errors ""There is a state proof, but no multi signature
 6DKmmq7CLbE2vZDZmhFYHZencyyUQz9N1RtNZbvB48wH got reply for (V4SGRU86Z58d6TV7PBUe6f:1508407453717608) with bad multi signature from Node1C"" should not appear neither for NYMs added before update to version with state proofs, nor for newly created NYMs.

*Additional Information:*
 Restart of the pool and restart of CLI didn't help.

*Case 2:*

0. After Case 1 do following:
 1. Demote 4 of 6 nodes.
 2. send GET_NYM for NYM created after configuring blskeys.
 => GET_NYM worked successfully.
 3. Demote 1 more node.
 4. send GET_NYM for NYM created after configuring blskeys.

*Actual Results:*
 Messages are repeatedly shown until stopping the CLI:
{code:java}
indy@test> send GET_NYM dest=V4SGRU86Z58d6TV7PB6666
Getting nym V4SGRU86Z58d6TV7PB6666
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424114096257) with bad multi signature from Node2C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424114096257) with bad multi signature from Node1C
Current verkey for NYM V4SGRU86Z58d6TV7PB6666 is ~V4SGRU86Z58d6TV7PB6666
CONNECTION: 4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 disconnected from Node2C
indy@test> send GET_NYM dest=V4SGRU86Z58d6TV7PB6666
Getting nym V4SGRU86Z58d6TV7PB6666
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
There is a state proof, but no multi signature
4YYedN1pErWMeMdWdLW5Pa3EVddkfr8s8g5FAXN6B2o8 got reply for (V4SGRU86Z58d6TV7PBUe6f:1508424126544585) with bad multi signature from Node1C
....
etc. {code}
 

*Expected Results:*
 Errors should not appear.

 

*Case 2.1 (the same behavior, but other steps):*

Steps to Reproduce:
1. Set up the pool of 4 nodes with 1.1.170 version (with initialized blskeys, like in docker pool).
2. Set up the client.
3. Change the blskey fields for each node in pool_transaction_sandbox_genesis file on client.
4. Open the CLI, send GET_NYM.
=> Message appears for each node.
5. Demote 3 nodes.
6. Send GET_NYM.

*Actual Results:*
Message repeatedly appears for the last not demoted node.

*Expected Results:*
Message should appear only once.","Build Info:
 indy-node 1.0.28 (stable) -> 1.1.37 (stable) -> 1.1.41 (RC) -> 1.1.165 (master)
 OS/Platform: Ubuntu 16.04.2 LTS
 Setup: 6 nodes (docker pool), 1 client",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzyk73:",,,,,,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,,,ashcherbakov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Oct/17 1:36 AM;ashcherbakov;PR: https://github.com/hyperledger/indy-node/pull/412;;;","24/Oct/17 6:20 PM;ashcherbakov;Case1: the reason is an error in init_bls_keys script (wrong config was used). It's fixed in the PR above.

Case2, Case 2.1: the reason is that
1) We have warning level of logs in client, which is shown in CLI
2) There is no timeout in CLI when receiving a reply, so in cases 2 we are waiting for the correct reply forever (logging to stdout the reason of the issue: incorrect BLS sigs).;;;","24/Oct/17 11:46 PM;ashcherbakov;PRs: 
- https://github.com/hyperledger/indy-plenum/pull/427
- https://github.com/hyperledger/indy-node/pull/417

Build: 1.2.180

The fix just reduces log level, so that we don't have these message shown in the logs.
In case of incorrect signatures, CLI will just don't return anything (like currently we don't return anything if don't have a quorum). We can create a ticket for better error processing (I think with low priority since we're going to get rid of this CLI).;;;","26/Oct/17 1:50 AM;ozheregelya;Build Info: indy-node 1.2.182
Messages are not shown for all cases:
- Keys are not configured, signature is absent
- Keys are configured, signature is invalid
- Keys are configured, signature is valid.

Additionally, following case was verified (test that signature validation works on client side):
1. Setup the pool with vonfigured BLS keys. 
2. Change blskeys in CLI genesis file. 
3. Run the CLI. 4. Try to GET NYM. 
=> GET_NYM worked correctly because of quorum. 
5. Turn off services on n-1 nodes. 6. Try to GET_NYM. 
=> GET_NYM didn't return result because of difference between keys in CLI genesis file and in pool ledger.

See more details about state proofs testing here: https://docs.google.com/spreadsheets/d/1XzJ6yK1z4em_N-ZY6IMeGxs54x-ar4uYKOYR_x5_CCo/edit#gid=0;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[CLI] show connection must return Schema's version of available claim(s),INDY-916,22601,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,ashcherbakov,bdonneaux,bdonneaux,20/Oct/17 12:30 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Schema's version is required for GET_SCHEMA txn, but currently CLI doesn't return it with show connection command.",,,,,,,,,,,,,,,,,,,,INDY-913,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx1pr:",,,,,,,,,,,,,,,,,,,,,,,,,,bdonneaux,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Oct/17 12:38 AM;bdonneaux;I guess it is about adding version around this [line|https://github.com/hyperledger/indy-node/blob/f16beadc9e5477718334cfbc5033ece0a0dd9c87/indy_client/client/wallet/connection.py#L176].;;;","09/Oct/18 5:52 PM;sergey-shilov;CLI is deprecated and is going to be removed, this ticket is not relevant any more and may be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node gets wrong upgrade_log entries after restart and runs the wrong upgrade,INDY-917,22717,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,VladimirWork,VladimirWork,20/Oct/17 9:07 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"Overwiew:
Node gets wrong upgrade_log entries after restart and run the wrong upgrade.

Build Info:
indy-node 1.1.171

Steps to Reproduce:
1. Install a pool.
2. Schedule an upgrade txn.
3. Cancel the txn from Step 2.
4. Shut down the primary and start it after some time (~1 minute).

Actual Results:
The primary has 3 entries in upgrade_log: scheduled, cancelled, scheduled. All other nodes have 2 entries.

Expected Results:
All nodes should have 2 entries in upgrade_log in this case.",,,,,,,,,,,,,,,,,,,,,,,INDY-157,,,,,,,,,,,,"20/Oct/17 9:06 PM;VladimirWork;primary_after_restart.PNG;https://jira.hyperledger.org/secure/attachment/12709/primary_after_restart.PNG","20/Oct/17 9:06 PM;VladimirWork;primary_upgrade.PNG;https://jira.hyperledger.org/secure/attachment/12708/primary_upgrade.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-738,,,,,,,,,,"1|hzyk7b:",,,,,,INDY 17.21,INDY 17.22,,,,,,,,,,,,,,,,,,,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Oct/17 6:30 PM;spivachuk;*Problem reason:*
- There was a bug with wrong boundaries of search for a transaction in Upgrader.get_upgrade_txn method. In particular this bug resulted in the behavior described in this ticket.

*Changes:*
- Fixed the bug with wrong search boundaries in Upgrader.get_upgrade_txn method.
- Added a test verifying that a canceled upgrade is not rescheduled after the node has been restarted.

*Committed into:*
- https://github.com/hyperledger/indy-node/pull/416
- https://github.com/hyperledger/indy-node/pull/418
- indy-node 1.2.181 master

*Risk factors:*
- Nothing is expected.

*Risk:*
- Low

*Covered with tests:*
- {{test_node_does_not_reschedule_cancelled_upgrade_after_restart}};;;","26/Oct/17 12:54 AM;VladimirWork;Build Info:
indy-node 1.2.181

Steps to Reproduce:
1. Install a pool.
2. Schedule an upgrade txn.
3. Cancel the txn from Step 2.
4. Shut down the primary and start it after some time (~1 minute).

Actual Results:
All nodes have 2 entries in upgrade_log in this case.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node should consider itself as a new primary as well,INDY-918,22720,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,dsurnin,andkononykhin,andkononykhin,20/Oct/17 11:26 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,should,ViewChange,,,,"[plenum/server/node.py:primary_selected()|https://github.com/hyperledger/indy-plenum/blob/3c51daa4d800f1089a50bda5dbe576c2684c3c0e/plenum/server/node.py#L2088]  checks if connection to primary has been restored but doesn't check if it is actually a new primary (e.g. after view change)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzx0zr:",,,,,,INDY 18.01: Stability+,Sprint 18.02 Stability,,,,,,,,,,,,,,,,,,,andkononykhin,ashcherbakov,dsurnin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jan/18 5:23 PM;dsurnin;The function plenum/server/node.py:primary_selected() is called in the end of primary selection only and does not called during connection monitoring.
Connection to primary is already monitored in a separate events.
We need additional discussion about this issue to narrow the problem.;;;","31/Jan/18 10:36 PM;ashcherbakov;Fixed in https://github.com/hyperledger/indy-plenum/pull/504;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hot fix 1.1.43 Release Notes,INDY-919,22721,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,krw910,krw910,20/Oct/17 11:34 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Documentation,,,,,"{color:#205081}*Hot Fix*{color}

*Version Information*
indy-plenum=1.1.27 
indy-anoncreds=1.0.10
indy-node=1.1.43
sovrin=1.1.6

*Bug Fixes  *

The following changes have been made in scope of the hotfix for INDY-895/INDY-869:
- Added a migration script which eliminates redundant fields with `null` values from legacy transactions in the domain ledger.
- Added a constraint on `version` field of `POOL_UPGRADE` transaction that denies values lower than the current installed version.
- Added prevention of upgrade to a lower version to `Upgrader` class.
- Fixed a bug in `Upgrader` class in search for a `POOL_UPGRADE cancel` transaction for the last `POOL_UPGRADE start` transaction.
- Added a test verifying prevention of upgrade to a lower version.
- Corrected existing tests according to introduced prevention of upgrade to a lower version.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-792,,,,,,,,,,"1|hzyk93:",,,,,,INDY 17.21,INDY 17.22,,,,,,,1.0,,,,,,,,,,,,krw910,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Oct/17 8:25 AM;TechWritingWhiz;This information has been added to the release notes both in our online version, made PDF available and in markdown within the GitHub repo. The pull request for this item is: [https://github.com/sovrin-foundation/sovrin/pull/31]

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
analyze work required to do multifaceted state machine refactors,INDY-920,22756,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,danielhardman,danielhardman,24/Oct/17 6:02 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,should,,,,,"State machine thinking (not necessarily a formal state machine pattern) could probably help us implement with greater confidence in various contexts. We don't have the freedom to do a comprehensive overhaul as one big effort, but if we could identify granular subtasks and incremental improvements, we could begin them quickly.

This task is to analyze how state machine thinking could help us in at least the following 3 areas: consensus, view change, and catchup. Each of those could be different state machines.

What we'd like to do in this task is study/think about the state machines that would be appropriate to these problems, and draw a picture (UML state machine) or create some other sort of diagram that describes how we want them to work. We can then generate new tickets/subtasks to implement some or all of the work implied by those artifacts.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0w7:",,,,,,INDY 17.23,INDY 17.24: Node Perf,,,,,,,5.0,,,,,,,,,,,,ashcherbakov,danielhardman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Nov/17 12:50 AM;ashcherbakov;The document:
https://docs.google.com/document/d/1qDfyb6ALqvf7Cwrnmk0RUmyVbM2Znd7urey-8B21j6o/edit#;;;","06/Dec/17 4:51 PM;ashcherbakov;Discussed with Nathan, proposed to Architects. Created corresponding tickets.
I'm going to close the ticket technically, expecting more discussion in Architects channel;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool is unable to perform view change during blskeys rotation,INDY-921,22812,,Bug,To Develop,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,ashcherbakov,VladimirWork,VladimirWork,24/Oct/17 9:57 PM,28/Sep/18 7:18 AM,28/Oct/23 2:47 AM,,,,,,0,should,,,,,"Build Info:
indy-node 1.1.176

Overview:
Pool is unable to perform view change during blskeys rotation.

Preconditions:
Pool of 3 nodes is installed.

Steps to Reproduce:
1. Start CLI and send NYM to check that pool works.
2. Change blskey for Node1 -> Restart CLI -> Send NYM txn.
3. Change blskey for Node2 -> Restart CLI -> Send NYM txn.
4. Change blskey for Node3 -> Restart CLI -> Send NYM txn.

Actual Results:
Step 4 NYM is not added due to the pool is broken. Node1 and Node2 cannot perform view change after Node3 blskey changing. See logs for additional info.

Expected Results:
Pool should work normally.

Additional Info:
The similar case with pool of 4 nodes works but the 3th node was restarted twice spontaneously due to send NODE command (see screenshot).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Oct/17 9:53 PM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/12804/_node1.txt","24/Oct/17 9:53 PM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/12803/_node2.txt","24/Oct/17 9:53 PM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/12802/_node3.txt","24/Oct/17 9:56 PM;VladimirWork;node3_bls_change.PNG;https://jira.hyperledger.org/secure/attachment/12801/node3_bls_change.PNG","01/Nov/17 9:54 PM;VladimirWork;node7_bls_change.PNG;https://jira.hyperledger.org/secure/attachment/13000/node7_bls_change.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzx0rj:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/17 5:25 AM;krw910;[~VladimirWork] Can we try this with a larger pool? You said it works with a pool of 4. Can you try a pool of 7 to see if we get the same issue with a staggered roll out of the BLS keys.;;;","01/Nov/17 9:54 PM;VladimirWork;[~krw910] Case with pool of 7 nodes has exactly the same result as with pool of 4 nodes: it works and one of nodes (7th) was restarted twice spontaneously due to send NODE command. !node7_bls_change.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incorrect CLI messages due to blskeys rotation,INDY-922,22813,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,ashcherbakov,VladimirWork,VladimirWork,24/Oct/17 10:29 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
indy-node 1.1.177

Overview:
Incorrect CLI messages due to blskeys rotation.

Steps to Reproduce:
1. Update blskeys on nodes of pool one by one.
2. Restart the CLI after each update.
3. Send some NYM txns.

Actual Results:
CLI shows messages about connecting/disconnecting of nodes that have updated blskeys (actually, this nodes are not restarted). There are some pauses during NYM adding after CLI restart (~1 minute). See CLI/nodes' logs and screenshot for more info.

Expected Results:
CLI should work normally.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Oct/17 10:25 PM;VladimirWork;CLI_all_bls_changed.PNG;https://jira.hyperledger.org/secure/attachment/12810/CLI_all_bls_changed.PNG","24/Oct/17 10:28 PM;VladimirWork;_cli.txt;https://jira.hyperledger.org/secure/attachment/12809/_cli.txt","24/Oct/17 10:28 PM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/12808/_node1.txt","24/Oct/17 10:28 PM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/12807/_node2.txt","24/Oct/17 10:28 PM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/12806/_node3.txt","24/Oct/17 10:28 PM;VladimirWork;_node4.txt;https://jira.hyperledger.org/secure/attachment/12805/_node4.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx0ov:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 7:17 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LibIndy should support client app data version changes,INDY-923,22818,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,tylerq,tylerq,25/Oct/17 12:13 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Blocks [https://evernym.atlassian.net/browse/CO-355]

and [https://evernym.atlassian.net/browse/CO-675]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-64,,,,,,,,,,"1|hzykof:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/17 5:30 AM;krw910;We don't know of anything that can cause an issue around versioning. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LibIndy should support connect.me app upgrading the OS of the phone,INDY-924,22819,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,tylerq,tylerq,25/Oct/17 12:13 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,blocks https://evernym.atlassian.net/browse/CO-675,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-64,,,,,,,,,,"1|hzyi5r:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,tylerq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/17 5:30 AM;krw910;We don't know of anything that can cause an issue around versioning. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement client migration for rebranding and multiple pool networks support upgrade,INDY-925,22822,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,spivachuk,spivachuk,25/Oct/17 1:49 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"When CLI is being started for the first time (per user) after the rebranding upgrade the migration mechanism must check whether the current user's home directory contains {{.sovrin}} subdirectory. If the user's home directory contain {{.sovrin}} subdirectory, then the migration mechanism must offer the user to migrate this data. If the user agrees then the application data must be migrated from {{.sovrin}} subdirectory to {{.indy}} subdirectory and the former must be kept as a backup.

See comments to INDY-830 for details on migration for client.

*UPD:*
In scope of this task a client migration for the indy-node version that supports multiple pool networks (see INDY-832, INDY-833 for details) must also be implemented. This client migration may be combined with the client migration for the rebranded indy-node version (because both rebranding and multiple pool networks support will be introduced simultaneously in the upcoming stable indy-node version).",,,,,,,,,,,,,,,,,,,,,,,INDY-830,,,,INDY-832,INDY-833,,,,,,,"08/Nov/17 9:15 PM;VladimirWork;CLI_after_wallet_migration.PNG;https://jira.hyperledger.org/secure/attachment/13304/CLI_after_wallet_migration.PNG","08/Nov/17 1:55 AM;VladimirWork;client_migration_error.PNG;https://jira.hyperledger.org/secure/attachment/13302/client_migration_error.PNG","08/Nov/17 1:55 AM;VladimirWork;home_.tar.gz;https://jira.hyperledger.org/secure/attachment/13301/home_.tar.gz","09/Nov/17 8:03 PM;VladimirWork;wallet_migrated_request_claims_before_and_after_old_agents_wallets_using.PNG;https://jira.hyperledger.org/secure/attachment/13316/wallet_migrated_request_claims_before_and_after_old_agents_wallets_using.PNG","09/Nov/17 8:03 PM;VladimirWork;wallet_migrated_use_DID.PNG;https://jira.hyperledger.org/secure/attachment/13317/wallet_migrated_use_DID.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzymqv:",,,,,,INDY 17.21,INDY 17.22,INDY 17.23,,,,,,2.0,,,,,,,,,,,,ashcherbakov,krw910,mgbailey,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/17 12:48 AM;spivachuk;[~danielhardman], [~nage], [~tharmon], [~krw910], we have a question on upgrade of agents.
Agents may be run in CLI mode as well as in non-CLI mode. If an agent is run in non-CLI mode, it should not ask the user about anything interactively.

So to keep it simple we propose the following two options for the rebranding upgrade of agents:
* provide unconditional app data migration for agents (i.e. don't ask the user for confirmation in case {{.indy}} is untouched and {{.sovrin}} has been found);
* don't provide app data migration for agents.

Which option should we choose? Or should we use some other workflow for agents?;;;","31/Oct/17 7:10 AM;krw910;[~spivachuk]
# If its interactive then prompt.
# If it is not interactive and there is no .indy folder error out and tell them how to give the command line option to trigger the migration.
# If there is already a .indy folder just use it.;;;","01/Nov/17 12:21 AM;spivachuk;[~krw910], do we understand right that non-libindy-based agents (which we are talking about here) are used for Getting Started Tutorial demo agents only?

If this is the case then non-libindy-based agents don't store any worth data in their wallets and so after rebranding upgrade they can be just restarted with a clean {{.indy}} directories and re-create wallets there from scratch without any negative effect for users.;;;","02/Nov/17 12:40 AM;spivachuk;[~tharmon], [~mgbailey], could you please help us with clarifying the question from the previous comment?;;;","02/Nov/17 6:33 AM;mgbailey;[~spivachuk], we do have customers that are using python-based agents, however, not many.  Since there are few, I think that detailed instructions for migration will be sufficient.  With this, here are my votes:
 # If interactive (i.e. CLI) prompt and upgrade if response is yes
 # If not interactive (i.e. agents), no automated upgrade.  Just provide instructions;;;","07/Nov/17 10:33 PM;ashcherbakov;Changes:
- fixed migration of wallets after re-branding;
- added migration of data from one dir to another after rebranding and file folder re-factoring (CLI asks if the user wants to apply the migration)

PR:
- https://github.com/hyperledger/indy-plenum/pull/437
- https://github.com/hyperledger/indy-node/pull/429

Build:
- 1.2.201

For QA:
- Check that migration works from the latest stable version (on the pool)
- Check that wallets from Getting Started can be migrated successfully
- Check that Agents can be migrated successfully (see instructions below)
;;;","08/Nov/17 1:55 AM;VladimirWork;Build Info:
indy-node 1.2.201

Steps to Reproduce:
1. Place old wallet (1.1.43) in /home/indy/.sovrin directory (e.g. /home/indy/.sovrin/wallets/test/default.wallet).
2. Run CLI as indy user.
3. Type Y to migrate client data.

Actual Results:
{quote}Application data from previous Indy version has been found
Do you want to migrate it? [Y/n] Y
Error occurred when trying to migrate application data: [Errno 18] Invalid cross-device link: '/home/indy/.indy-cli' -> '/home/indy/.indy-cli.backup'
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/indy_client/cli/cli.py"", line 136, in _migrate_legacy_app_data_if_just_upgraded_and_user_agrees
    combined_migration.migrate()
  File ""/usr/local/lib/python3.5/dist-packages/indy_client/utils/migration/combined_migration.py"", line 68, in migrate
    raise e
  File ""/usr/local/lib/python3.5/dist-packages/indy_client/utils/migration/combined_migration.py"", line 53, in migrate
    os.rename(_CLI_BASE_DIR, _CLI_BASE_BACKUP_DIR)
OSError: [Errno 18] Invalid cross-device link: '/home/indy/.indy-cli' -> '/home/indy/.indy-cli.backup'
Application data has not been migrated

Indy-CLI (c) 2017 Evernym, Inc.
Type 'help' for more information.
Running Indy 1.2.201{quote}

Expected Results:
Client data should migrate normally.

Additional Info:
Test /home/ directory for indy user with needed folder structure and old wallet is in attachment. [^home_.tar.gz] 

*Not reproducing on 1.2.202.*;;;","08/Nov/17 9:15 PM;VladimirWork;Build Info:
indy-node 1.2.202

Steps to Reproduce:
1. Place .sovrin directory (1.1.43) to /home/indy/.
2. Run CLI as indy user.
3. Type Y to migrate client data.
4. Try to connect sandbox network. !CLI_after_wallet_migration.PNG|thumbnail! 

Actual Results:
Exception in callback PosixAsyncioEventLoop.run_as_coroutine.<locals>.stdin_ready() at /usr/lib/python3/dist-packages/prompt_toolkit/eventloop/asyncio_posix.py:65
handle: <Handle PosixAsyncioEventLoop.run_as_coroutine.<locals>.stdin_ready() at /usr/lib/python3/dist-packages/prompt_toolkit/eventloop/asyncio_posix.py:65>

Expected Results:
CLI should work normally.

Additional Info:
*Issue reproduces in docker only.*;;;","09/Nov/17 12:49 AM;ashcherbakov;In order to migrate agent's wallets, once can manually copy
`/home/user/.sovrin/wallets/agnets/<agent_name>` to `home/user/.indy-cli/wallets/agnets/<agent_name>`.

But actually as for faber, acme and thrift (and probably for other wallets as well), it just doesn't make sense, because the only private information they can have is Issuer secret keys, and they are re-created (with the same values) on each startup of the Agent.;;;","09/Nov/17 8:04 PM;VladimirWork;Build Info:
indy-node 1.2.203

Steps to Validate:
1. Install 1.1.43 (stable) pool.
2. Make some NYMs and run through Getting Started Tutorial.
3. Upgrade client to 1.2.203 manually.
4. Move /home/sovrin/.sovrin folder to /home/indy folder.
4. Upgrade the pool to 1.2.203 (master) version (or connect client to another 1.2.203 pool and copy old agents' wallets to it).
5. Start CLI and perform client migration.
6. Use DIDs that were made in initial pool.
7. Request claims (that were accepted on 1.1.43) from agents (that were connected on 1.1.43) (in other words, run the *last 3 steps* of GST with migrated wallet).

Actual Results:
Migrated wallet connects to network, can use DIDs and requests all claims successfully. !wallet_migrated_request_claims_before_and_after_old_agents_wallets_using.PNG|thumbnail!  !wallet_migrated_use_DID.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Common Setup Instructions"" document needs to be moved from Archive to Current",INDY-926,22845,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,TechWritingWhiz,TechWritingWhiz,TechWritingWhiz,26/Oct/17 6:13 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,documentation,,,,,"The document: ""Common Setup Instructions"" located here: [https://github.com/hyperledger-archives/indy-common/blob/master/setup.md] needs to be moved to: [hyperledger/indy-node|https://github.com/hyperledger/indy-node]. 

Currently, this document is referenced off the setup.md document located in: [hyperledger/indy-node|https://github.com/hyperledger/indy-node]. It should not be located in the ""hyperledger-archives"" repo. 

The link to the new location also needs to be updated in setup.md. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-792,,,,,,,,,,"1|hzyt6n:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,SeanBohan_Sovrin,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jan/18 7:22 AM;SeanBohan_Sovrin;Nathan agrees!;;;","16/Jan/18 5:06 PM;ashcherbakov;The setup instructions have been already updated.
[~TechWritingWhiz] can you please check https://github.com/hyperledger/indy-node/blob/master/docs/setup-dev.md and make sure that everything is fine here?;;;","17/Jan/18 5:45 AM;TechWritingWhiz;[~ashcherbakov]  Unfortunately, I don't know how to answer this question. I do not see a document called ""Common Setup Instructions"" within indy-node. I also no longer see  the ""setup.md"" document in indy-node. Because this is what the ticket is referencing, this is exactly what I'm looking for. 

Now, if this was done, but one document stripped or combined with the other or even if the document changed titles? That I do not know. I also do not know if ""everything is fine here"" because I have no way of knowing what is correct or not. If the document changed title and was moved, added, is the content correct? Only a subject matter expert would know that.

I have to assume ""yes"" BUT I cannot definitively say that because I'm not finding the documents referenced in the ticket by their names as referenced in the ticket. [~SeanBohan_Sovrin] ?;;;","17/Jan/18 5:10 PM;ashcherbakov;[~TechWritingWhiz] There are no more setup.md or ""Common Setup Instructions"" docs. There is just one doc now: [https://github.com/hyperledger/indy-node/blob/master/docs/setup-dev.md,] and it contains all required information.

So, I believe we can close this ticket as Invalid.;;;","18/Jan/18 12:16 AM;TechWritingWhiz;Updated this ticket to ""Done"" to close it out per the comments above.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client needs to be able to send read requests to one Node only,INDY-927,22851,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,ashcherbakov,ashcherbakov,26/Oct/17 5:37 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"With State proofs implemented, we can reduce load on live pool dramatically, since we can send read request to one Node only.
We need to make it possible for existing client/CLI.

Think about how to do it best. Possible options: send reqs to Nodes in round robin or randomly (if there is state proof returned).",,,,,,,,,,,,,,,,,,,,,,,INDY-670,INDY-790,,,INDY-949,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzymof:",,,,,,INDY 17.21,INDY 17.22,INDY 17.23,,,,,,5.0,,,,,,,,,,,,ashcherbakov,mzk-vct,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Oct/17 8:21 PM;mzk-vct;Implemented sending of read only requests to one node even if there are more connections:
https://github.com/hyperledger/indy-plenum/pull/431;;;","01/Nov/17 1:10 AM;mzk-vct;Done in node 1.2.192;;;","13/Nov/17 10:08 AM;ozheregelya;*Version Info:*
indy-node=1.2.208

*Reason for Rejection:*
 Unclear messages appear during reading transactions.

*Steps to Reproduce:*

1. Set up the docker pool of 4 nodes with 1.2.208 version of indy-node.
 2. Install client with the same version (using other machine, not docker container created by client_for_pool_start.sh).
 3. Copy content of /var/lib/indy/sandbox/pool_transactions_genesis and /var/lib/indy/sandbox/domain_transactions_genesis files from node machine to ~/.indy-cli/networks/sandbox/pool_transactions_genesis and~ /.indy-cli/networks/sandbox/domain_transactions_genesis on client machine.
 4. Run the client. Verify that all works correctly by rending write and read transactions.
 => transactions are successfully written and read.
 5. Stop services on n-1 nodes one-by-one and send read transaction after each node stopping.
  
 *Actual Results:*
 Here is output of CLI for described steps.
{code:java}
indy@sandbox> send NYM dest=V4SGRU86Z58d6TV7PBUe61 role=TRUST_ANCHOR verkey=~V4SGRU86Z58d6TV7PBUe61
Adding nym V4SGRU86Z58d6TV7PBUe61
Nym V4SGRU86Z58d6TV7PBUe61 added
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe61
Getting nym V4SGRU86Z58d6TV7PBUe61
Current verkey for NYM V4SGRU86Z58d6TV7PBUe61 is ~V4SGRU86Z58d6TV7PBUe61 with role TRUST_ANCHOR
CONNECTION: HoN6XaczjWJpnyZUB1LvtpKpVLmzjJv78rCY3scKGt99 disconnected from Node5C
indy@sandbox> send NYM dest=V4SGRU86Z58d6TV7PBUe62 role=TRUST_ANCHOR verkey=~V4SGRU86Z58d6TV7PBUe62
Adding nym V4SGRU86Z58d6TV7PBUe62
Nym V4SGRU86Z58d6TV7PBUe62 added
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe62
Getting nym V4SGRU86Z58d6TV7PBUe62
Current verkey for NYM V4SGRU86Z58d6TV7PBUe62 is ~V4SGRU86Z58d6TV7PBUe62 with role TRUST_ANCHOR
CONNECTION: HoN6XaczjWJpnyZUB1LvtpKpVLmzjJv78rCY3scKGt99 disconnected from Node4C
indy@sandbox> send NYM dest=V4SGRU86Z58d6TV7PBUe63 role=TRUST_ANCHOR verkey=~V4SGRU86Z58d6TV7PBUe62
Adding nym V4SGRU86Z58d6TV7PBUe63
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe62
Getting nym V4SGRU86Z58d6TV7PBUe62
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
Current verkey for NYM V4SGRU86Z58d6TV7PBUe62 is ~V4SGRU86Z58d6TV7PBUe62 with role TRUST_ANCHOR
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
CONNECTION: HoN6XaczjWJpnyZUB1LvtpKpVLmzjJv78rCY3scKGt99 disconnected from Node3C
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe61
Getting nym V4SGRU86Z58d6TV7PBUe61
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
Current verkey for NYM V4SGRU86Z58d6TV7PBUe61 is ~V4SGRU86Z58d6TV7PBUe61 with role TRUST_ANCHOR
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe62
Getting nym V4SGRU86Z58d6TV7PBUe62
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
Current verkey for NYM V4SGRU86Z58d6TV7PBUe62 is ~V4SGRU86Z58d6TV7PBUe62 with role TRUST_ANCHOR
CONNECTION: HoN6XaczjWJpnyZUB1LvtpKpVLmzjJv78rCY3scKGt99 disconnected from Node2C
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe62
Getting nym V4SGRU86Z58d6TV7PBUe62
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""{code}
*Expected Results:*
 Obvious problem is that messages are strange and useless. Messages should not be shown or they should be informative for user.

*Question:*
 Is that correct that pool_transactions_genesis and domain_transactions_genesis are not enough for correct validation of blskeys on CLI side?

*Additional Information:*
 If you will use docker client (created by client_for_pool_start.sh), client will work correctly, error messages will not be shown.
 Genesis files of docker client and client on separated machine were double-checked and they are the same.;;;","14/Nov/17 11:41 PM;ashcherbakov;I can not reproduce it neither in docker nor local client.
Let's try to re-test it, and, if the issue reproduces, create a separate ticket (since it looks quite minor).;;;","15/Nov/17 7:23 PM;VladimirWork;Issue with unclear messages reproduces on 1.2.210 and is reported as INDY-949.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client needs to be able to make sure that we have the latest State Proof ,INDY-928,22881,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,ashcherbakov,ashcherbakov,27/Oct/17 8:31 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,Must,,,,,"As of now, Results with state proofs contain the time when transaction was written to the Ledger.
It may be enough for some of the cases, but in general we also need to make sure that a Node returned a State Proof for the latest state. It's especially critical if we get reply from one node only, and this node can be malicious.

*Example:*
- There is a NYM with seqNo 10 and time X. Then the key was rotated in a NYM with seqNo 20 and time Y.
- We send GET_NYM to a node willing to get the latest key. 
- But the Node is malicious, and returns result as it was at the time X and seqNo 10. A client doesn't know if this is the latest state or not.

*Possible solution:*
- we need to sign not only domain and pool state roots as of now, but also the timestamp of this state (and possibly seqNo as well).
- so, we create multi-signature over `state_root_hash+txn_root_hash+pool_state_root_hash+state_ts+ledger_id`
- include domain_state_ts and domain_state_last_seqNo into State Proof with each Reply
- With this approach, once client receives a Reply, he validates the multi-signature (against returned  `state_root_hash+txn_root_hash+pool_state_root_hash+state_ts+ledger_id`). So, a client can be sure that the result is not older than specified timestamp.
The client can later decide if the transaction is fresh enough for him. If not, he can ask another Node (another Observer for example), or fall back to f+1 replies.

The proposed solution can not guarantee that the result is really the latest one (but actually we can not guarantee it in general in BFT system, especially once we introduce Observer Nodes). But the provided information should be enough for the client to decide of the returned result is fresh enough for him.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzymq7:",,,,,,INDY 17.22,INDY 17.23,,,,,,,3.0,,,,,,,,,,,,ashcherbakov,gudkov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Oct/17 9:42 PM;gudkov;> that we have the latest State Proof

The proposed solution doesn't solve the problem of getting ""latest"" state. It only allows making sure that it is state proof for the concrete date. It causes the obvious problem for rarely updated pools. All received proofs will be too old to trust.;;;","27/Oct/17 9:49 PM;ashcherbakov;The issue with rarely updated pool can be solved by https://jira.hyperledger.org/browse/INDY-933 (so we update multi-signature every N seconds);;;","28/Oct/17 1:08 AM;ashcherbakov;Ok, it looks like initial PoAs already contained the same approach (https://docs.google.com/document/d/1WRkqNqXXi1LoVxZu0C353uR0KRatoQuvrV_UZNDuNcc/edit#heading=h.rte6ku9uqfb2), so it was just missed in the current implementation.;;;","30/Oct/17 7:23 PM;ashcherbakov;Changes:
# BLS multi-signature is now calculated over the following array:
{code}[ledger_id, state_root_hash, pool_state_root_hash, txn_root_hash, timestamp]{code}
where
ledger_id: id of the ledger multisig is created over
state_root_hash: root hash (base58) of the state associated with ledger_id and multisig is created over
pool_state_root_hash: root hash (base58) of pool state needed to anchor the state of Nodes participated in multisig
txn_root_hash: root hash (base58) of the ledger associated with ledger_id and multisig is created over
timestamp: timestamp of the state the multisig is created over

The value for multi-signature is calculated as msgpack serialized dict of fields above sorted in alphabetical order by keys

The Result sent to client with Replies is changed a bit to support this multi-component value:
{code}
{<txn-sepcific fields>
 'txnTime': 1509351179,
 'seqNo': 9,
 'reqId': 1509351179375352, 
 'identifier': '4AdS22kC7xzb4bcqg9JATuCfAMNcQYcZa1u5eWzs6cSJ',
 'state_proof': {
	'multi_signature': {
		'participants': ['Gamma', 'Alpha', 'Delta'],
		'signature': 'RZir972nhZqPNR2mrJRyQ8tUtQSEC13eFsAFfUAMdVsVm8gwSj7chkCVW7crZ8gzcTZKnmCsLzcY1BAyptVH3axYmtk1FrouSC9PfXmdv9bAfPogNDc99TPBMxUmH5BdiWtBqBhcdgDscw5XTpwXMh5kjHGVhZ8jtnoBRUnYXfY9Ry',
		'value': {
			'timestamp': 1509351179,
			'pool_state_root_hash': '7zzGLtFhgYU68z4qwbTr1edweRN1naz6u71tvUDC9UGt',
			'txn_root_hash': '8tXbYmhYrvA6x2y8murmpw5pe7h5tR2hkb1fCQ4bFLmi',
			'state_root_hash': 'DR95nhGqT7GbxPi7fwRGs63XnpAimQN7tJNu4724kCCr', 
			'ledger_id': 1
		}
	},
	'proof_nodes': '+QFn8qA8iiEKWlZYbpsQpBw7gY6e19O5Yu1n69WuD6iOGMdJU5DPjnsidHlwZSI6ImJ1eSJ9+QExgICg/z7X4Kbks98q5LZoyWKyB16vNhQmO8B36Onbz9aUaziAoOkwBIZQU6meTGpVGn8gnArmK4/3EBcfRUrcaECp7AjkoH+mTD6m9guPfJi1NRS/ycWzW7AjPZLjZ1LQLCKNVhrMoAlqV6pkrGYm21AhuCJuyfJq/HQP1kXXokX5iyh5mdzvgKApciTKL+FVdP39bxBwVFjVNGyKRwh1aiZWrJaQoMwTbKAQXABUnMiqhgZ4m6Gv+dlSexO95N2s5b+vXFL/ke8GoYCgcme6jpzxwHVqClrAwpHJY/tW+/TKU/NVtjhpUDaLYp2gCM3C41C+braaKFifLMlxc77kPNEax1pNXMj6HBeu+9aAoLahkK/Vnn+9MS9XBBoCnNJ9RrKGCllWQxYSIA3qAJgWgIA=', 
	'root_hash': 'DR95nhGqT7GbxPi7fwRGs63XnpAimQN7tJNu4724kCCr'
  },
 }
{code}
# Made a hotfix to not crash when incorrect value is passed to indy-crypto

PRs:
- https://github.com/hyperledger/indy-plenum/pull/433
- https://github.com/hyperledger/indy-node/pull/425
- https://github.com/hyperledger/indy-plenum/pull/434

Build:
- indy-node 1.2.192

New tickets:
- Created IS-402 to support the changes in libindy
- Created IS-403 to fix the problems with indy-crypto

Recommendations to QA:
- Check that BLS feature still works as expected.;;;","13/Nov/17 10:30 AM;ozheregelya;[~ashcherbakov], [~VladimirWork]

Regression testing of state proofs was performed on indy-node=1.2.208. Following cases were verified:
* Reading and writing without configured bls keys (reading is possible when at least 2 of 5 nodes are active);
* Reading and writing with configured bls keys (reading with only 1 client in the pool works without any errors);
* Reading and writing with invalid bls keys (reading is possible when at least 2 of 5 nodes are active, but unclear messages appear if some nodes are stopped);
* Backward compatibility with the latest stable client (indy-node on client machine is 1.1.43-stable, indy-node on the pool is 1.2.208-master).

If it is enough for verification of this ticket, please move it to Done.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validator Info Tool: Ledger count lags behind read_ledger tool by 1 minute or more,INDY-929,22882,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,krw910,krw910,27/Oct/17 10:29 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,validator-info,,0,,,,,,"When running the validator_info tool to check ledger count it can be 1,000 or more off trailing behind what the read_ledger tool by 1 minute or more.

*Setup*
You should be able to use the load_test.py script to generate a load. 
If you need the libindy version reply to Kelly Wilson on this ticket for setup information.
I had two putty sessions open for the same node.

*Steps*
# Run a load against a pool sending a few thousand transactions. 
# In one putty session for a node run ""validator_info -v""
# In the other putty session for the same node run ""read_ledger --type domain --count""

*{color:#d04437}Issue{color}*
You will notice there is a large difference between the two tools.
Keep refreshing the validator_info report and you should notice it takes 1 minute or longer for it to catch up to what the read_ledger tool was showing.



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzx1sv:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/18 6:51 PM;ashcherbakov;This is expected behaviour, since the data for validator_info is dumped every 60 seconds.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validator Info Tool: Writes per second is so far off it is not useful,INDY-930,22883,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,sergey.khoroshavin,krw910,krw910,27/Oct/17 10:48 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,validator-info,,0,,,,,,"In the validator_info tool the metric showing writes per second is so far off it is not useful.

*Setup*
You should be able to use the load_test.py script to generate a load. 
If you need the libindy version reply to Kelly Wilson on this ticket for setup information.
On a node in the pool run the following to get the current ledger count
{code}
read_ledger --type domain --count
{code}

*Steps*
# I had 5 client machines each sending 400 transactions
# In a putty session I ran ""validator_info -v"" to get the metrics. 
# I continued to refresh the tool and record the highest displayed writes per second.
# After the load finished sending I went to a node and ran the command below. Where xxx is one number higher than the ledger count before we started. So if it was 1,000 before running the load I put in ""--to 1,001"".
{code}
read_ledger --type domain --to xxx
{code}

# Record the epoch time stamp from that transaction.
# Now get the full ledger count with running the command below and then go to the last transaction and get its epoch time stamp.
{code}
read_ledger --type domain --count
{code}
# Get the difference between the two and that will be your seconds.
# Now you can get the transactions per second based off what was written to the ledger.

*{color:#d04437}Issue{color}*
The validator_info tool showed the highest writes per second being 0.74
The ledger difference between the start and end epoch time shows 24 writes per second",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1749,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzx1t3:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,sergey.khoroshavin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 8:19 PM;sergey.khoroshavin;*Triage*
Currently validator_info shows average throughput from node start time, so this behaviour is expected. If throughput measurement with smaller time window is needed then there should be a separate task describing requirements. Also we already have windowed throughput measurements in monitor for write requests, so if requirements match this implementation fix will be relatively easy.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
We need a tool to create custom genesis transaction files,INDY-931,22884,,Story,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,nage,krw910,krw910,27/Oct/17 10:56 PM,21/May/19 12:05 AM,28/Oct/23 2:47 AM,,,,,,0,,,,,,"We had created a script that was able to create custom genesis transaction files that used custom alias names and node ports. The default "" generate_sovrin_pool_transactions "" script is hard coded to use NodeX and Port XXXX where they just increment the number.

 

With all the changes we have made with serialized ledgers and BLS keys we need a new tool that can create the genesis files that are not using the default test settings.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzwyxo:",,,,,,,,,,,,,,,,,,,,,,,,,,krw910,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validator runs instance change continually,INDY-932,22885,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,mgbailey,mgbailey,27/Oct/17 11:02 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"On the provisional network one of the validator nodes, ev1, is running instance change continually.  This is not preventing it from reaching consensus, but this is a high priority to debug anyway since it is one of the live nodes.  It got into this state immediately following the force=True upgrade to 1.1.43.  A service restart did not fix the issue.  Logs are attached.","Provisional network, running indy-node 1.1.43",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Oct/17 11:02 PM;mgbailey;ev1_log_20171026.tgz;https://jira.hyperledger.org/secure/attachment/12823/ev1_log_20171026.tgz","28/Oct/17 1:11 AM;mgbailey;royal_sovrin.log;https://jira.hyperledger.org/secure/attachment/12824/royal_sovrin.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzymqn:",,,,,,INDY 17.22,INDY 17.23,,,,,,,,,,,,,,,,,,,ashcherbakov,mgbailey,mzk-vct,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Oct/17 1:12 AM;mgbailey;I just got a log from another steward that also shows the instance changes in its logs.  This node was unable to be in sync while the instance changes were occurring.  Then at 17:26 the problem abruptly cleared up and the node caught up and synced.  The log is [^royal_sovrin.log].  The issue is still occurring on ev1.;;;","30/Oct/17 11:57 PM;ashcherbakov;May be related to INDY-34;;;","02/Nov/17 7:57 PM;mzk-vct;Partial fix which disables performance checks if there were no new requests received.
https://github.com/hyperledger/indy-plenum/pull/435;;;","02/Nov/17 8:05 PM;mzk-vct;Problem is caused by the bug in catchup mechanism. 

When node does catch-up it receives missing transactions from other nodes and applies them to ledger.
Node also tells master instance replica latest preprepare sequence number. 
But it does not do same thing for backups and also does not tell Monitor about it. 

So if then node receives commit for transaction which it caught up - master replica discards it, but backup replicas execute.
That's why maser and backups  are actually at the same state, but since Monitor was not notified it says that backups ordered more requests than master.
;;;","03/Nov/17 5:19 PM;mzk-vct;Update: I found that actually monitor is reset, so it is not a part of problem. 

Fix that notifies backup replicas about catchup:
https://github.com/hyperledger/indy-plenum/pull/438

;;;","03/Nov/17 6:51 PM;mzk-vct;Node version: 1.2.194;;;","03/Nov/17 11:05 PM;mgbailey;Update:

Early this morning, as a test, the steward of the node that was the primary turned off the service on his node temporarily, forcing a view change.  A new primary was selected, and the problem stopped appearing in the ev1 logs.  

^^ [~mzk-vct];;;","09/Nov/17 10:04 PM;VladimirWork;Fix works after upgrade form master to master. Upgrade from stable to master is blocked by INDY-833 case 12.;;;","13/Nov/17 11:35 PM;VladimirWork;Build Info:
indy-node 1.2.208

Steps to Validate:
1. Set up pool (master or stable).
2. Perform upgrade to 1.2.208.
3. Check logs for view changes.

Actual Results:
Pool makes view changes with normal rate (due to starting and stopping nodes or due to degraded node performance).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
There should always be fresh enough signature of a state,INDY-933,22886,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,ashcherbakov,ashcherbakov,27/Oct/17 11:26 PM,13/Jul/19 6:53 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,1.6.83,,,0,GA-0,,,,,"As of now, multi-sigs are created on every Request. But if there are no Requests in a pool, then the state and multi-signatures may become outdated. 
 So, a Primary needs to initiate re-signing of the same state periodically to have up-to-date state (for the latest pool ledger).
 It will help to solve two problems:
 - Have up-to-date multi-signature (with the latest timestamp)
 - Have multi-signature for the latest pool ledger (the client can use the latest pool ledger in most of the cases)

All states (for all ledgers) need to be re-signed periodically.

 

*Acceptance criteria*
 * Implement periodic BLS re-signing of all states (for all ledgers). It can be done via existing PrePrepare msg, or via a new message (decide when creating a PoA).
 * Re-sign period needs to be configurable (config file for now). Default is 1 min.
 * It should be possible to disable/enable the feature in config.
* An INFO level log message is issued which states ""Freshness was updated through consensus.""",,,,,,,,,,,,,,INDY-614,INDY-1911,INDY-1928,,,,,,,INDY-1281,,,,INDY-968,INDY-1137,INDY-1954,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzwvif:0002c",,,,,,Ev 19.1,,,,,,,,5.0,,,,,,,,,,,,ashcherbakov,lovesh,Toktar,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Sep/18 4:35 PM;lovesh;{quote}Primary needs to initiate re-signing of the same state periodically
{quote}
Why periodically? Shouldn't it be just once. If the primry sees no new txns for say 5 secs, it can send (the protocol can enforce by other nodes demanding it) the aggregate signature on empty state with timestamp. As far as freshness of replies by clients on a low traffic network (1 txn every minute or below) is concerned:

The client can have a config variable like _staleness_tolerance_ which determines how much staleness it is willing to accept. eg. it _staleness_tolerance_ is set to 30 mins and client asks 1 node for reply, it gets a reply with state proof but that is 35 minutes old, the client then asks another node, it still gets a response that is 33 minutes old, the client then asks another node, it keeps on asking nodes till it gets a reply that is <= 30 minutes old or has talked to >f nodes. Clients asking multiple nodes should not be a problem for nodes since we are imagining this condition in a network with low traffic anyway.

Also client should track how fresh and timely responses then get from different nodes and keep a sorted list of nodes in that order. The client should ask the topmost node in the list whenever a read is needed.;;;","05/Sep/18 8:00 PM;ashcherbakov;[~lovesh]
As I understand, you propose that if there is no load for 5 sec, then Primary sends aggregated signature of the previous PrePrepare, so that all Nodes have the same BLS multi-sig for the latest state and can generate correctly signed state proofs.
However, in the current implementation this is not needed, since each Node individually calculates multi-signature based on the verified quorum of COMMITs, so that a Node can provide correctly signed state proof even without next PrePrepare received from the Primary. That means that nodes may have different (though correct) multi-sig values for the latest state, but this doesn't matter (until we have catch-up of BLS store), and the the multi-sig value for the state will be updated by the one calculated by the Primary with the next PrePrepare, so eventually it becomes equal on all nodes.;;;","05/Sep/18 9:13 PM;lovesh;Your're right, i mentioned that its optional in doc but forgot to mention here;;;","25/Dec/18 12:17 AM;ashcherbakov;*PoA:*
 # Enable BLS multi-sig for all ledgers
 # Send PrePrepare with no requests just to update the BLS multi-sig regularily
 ** Track the time of last sent PrePrepare for each ledger by master Primary
 ** Add two new vales to config:
 *** UPDATE_STATE_FRESHNESS = True/False
 *** STATE_FRESHNESS_WINDOW = 60 (sec) <--- need to decide exact value
 ** Check if state needs to be updated for a ledger before sending the next 3PC batch
 *** check if feature is enabled in config
 *** check for every ledger sequentially
 *** get the latest timstamp for the ledger's state (from `bls_store`), that is get the latest key (`get_last_key`).
 *** do it as the first action in `send3PCBatch`
 ** If the state needs to be updated, send a common PrePrepare, but with empty requests
 ** Do a common 3PC. Make sure that everything works if requests are empty.
 ** Do not send `Order` msg to the Node if there are no requests.

Integration Tests:
 # Check that the state gets updated for every ledger according to the STATE_FRESHNESS_WINDOW and no requests at all
 # Check that the state gets updated for every ledger according to the STATE_FRESHNESS_WINDOW if there are requests sent for 1 of the ledgers only;;;","30/Dec/18 12:53 AM;ashcherbakov;PR: https://github.com/hyperledger/indy-plenum/pull/1047;;;","10/Jan/19 8:31 PM;ashcherbakov;Changes:
 - Periodically (5 min) update BLS state for every ledger
 - Support BLS multi-sigs for Pool ledger
 - Fix the problem with ordering on backup instances after view change

PR:
 - [https://github.com/hyperledger/indy-plenum/pull/1047]

Version:
 - TBD

Risk factors:
 - Consensus
 - Ordering
 - View change triggerring

Risk:
 - Med

Covered with tests:
 - tests in plenum/test/freshness

Recommendations for QA
 # Run acceptance load test
 # Run some acceptance for POOL ledge txns (NODE txn)
 # Check that we have fresh enough time (not more than 5 mins outdated) for every ledger in replies:
 ** Send requests (for every ledger)
 ** Wait for more than 5 mins
 ** Send read requests for every ledger
 ** Check that the time in the Reply is not older than 5 mins from the current one
 *** Check  {{state_proof}}/ {{multi_signature}}/ {{value/}} {{timestamp}}{{}}
 # Check the item 3 for Tokens Ledgers (so that freshness is updated for payments);;;","16/Jan/19 6:24 PM;Toktar;Version:
 * indy-node 1.6.758 -master
 * indy-plenum 1.6.653 -master;;;","17/Jan/19 10:53 PM;VladimirWork;GET_TXN doesn't support state proofs so we can't check freshness for pool and config ledger.;;;","18/Jan/19 12:29 AM;VladimirWork;Build Info:
indy-node 1.6.760
libindy 1.7.0~924 (libindy 1.6.8 + libsovtoken 0.9.6 for token case since it is the last libsovtoken for now)

Actual Results:
Pool ledger freshness (x) INDY-1954
Config ledger freshness (x) INDY-1954
Domain ledger freshness (/)
Sovtoken ledger freshness (!) INDY-1954 (verify_payment also based on GET_TXN)
Production load for pool with freshness (/)

So freshness works for all domain txns and for part of token txns, all other ledgers will be supported after INDY-1954 fix and in scope of INDY-1928.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sovrin CLI stacktraces when command list passed on STDIN includes 'exit',INDY-934,22890,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,krw910,ckochenower,ckochenower,28/Oct/17 2:48 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,quality,,,,,"Steps to reproduce:
 # Install the sovrin CLI
 # Run the following command: 'sovrin ""new key"" ""exit""'

Produces:
{code:java}
$ sovrin ""new key"" ""exit""
Loading module /usr/lib/python3.5/site-packages/config/config-crypto-example1.py
Module loaded.

Sovrin-CLI (c) 2017 Evernym, Inc.
Type 'help' for more information.
Running Sovrin 1.1.43


Saved wallet ""Default"" restored (/home/ec2-user/.sovrin/wallets/no-env/default.wallet)
Active wallet set to ""Default""

Running command: 'new key'...

Key created in wallet Default
DID for key is E73ZJ3zdpFJWQ3PuzoTHmq
Verification key is ~GdcsMH6uNUUzBdQdTaRgAJ
Current DID set to E73ZJ3zdpFJWQ3PuzoTHmq

Running command: 'exit'...

Active wallet ""Default"" saved (/home/ec2-user/.sovrin/wallets/no-env/default.wallet)
Error while running coroutine shell: Exit()
Traceback (most recent call last):
  File ""/usr/bin/sovrin"", line 78, in <module>
    run_cli()
  File ""/usr/bin/sovrin"", line 56, in run_cli
    looper.run(cli.shell(*commands))
  File ""/usr/lib/python3.5/site-packages/stp_core/loop/looper.py"", line 259, in run
    return self.loop.run_until_complete(what)
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 467, in run_until_complete
    return future.result()
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 294, in result
    raise self._exception
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 240, in _step
    result = coro.send(None)
  File ""/usr/lib/python3.5/site-packages/stp_core/loop/looper.py"", line 250, in wrapper
    raise ex
  File ""/usr/lib/python3.5/site-packages/stp_core/loop/looper.py"", line 237, in wrapper
    results.append(await coro)
  File ""/usr/lib/python3.5/site-packages/plenum/cli/cli.py"", line 1151, in shell
    self.parse(command)
  File ""/usr/lib/python3.5/site-packages/plenum/cli/cli.py"", line 1976, in parse
    r = action(matchedVars)
  File ""/usr/lib/python3.5/site-packages/plenum/cli/cli.py"", line 1178, in _simpleAction
    raise Exit
plenum.cli.cli.Exit{code}",Amazon Linux AMI,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzygnr:",,,,,,,,,,,,,,,,,,,,,,,,,,ckochenower,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Nov/17 7:11 AM;krw910;When we change over to the SDK Cli retest this issue.;;;","04/Jan/18 2:46 AM;ozheregelya;indy-cli (version 1.1.1~306) works correctly with the same steps in batch mode:

{code:java}
me@me-VB:~$ cat batch.txt 
- wallet create wallet1 pool_name=p1
wallet open wallet1
did new
exit
me@me-VB:~$ indy-cli batch.txt 
- wallet create wallet1 pool_name=p1
Wallet ""wallet1"" has been created

wallet open wallet1
Wallet ""wallet1"" has been opened

did new
Did ""VUgmJcEHzodww5Cxh3xcAN"" has been created with ""GXE3ArThro1RdstaqCQPLdq7donEQCK8CrpK353ffAMj"" verkey

exit

Wallet ""wallet1"" has been closed
Goodbye...
{code}
;;;","04/Jan/18 2:53 AM;ckochenower;[~ozheregelya] or [~krw910] - It is great that ""batch mode"" works as it should. Is the following not a valid use of sovrin CLI? If not, shouldn't the CLI prevent anyone from using it this way?
{code:java}
sovrin ""new key"" ""exit""{code};;;","04/Jan/18 5:15 AM;ozheregelya;[~ckochenower], I never tried to use sovrin-cli that way, but I think this is valid use.
The point is that new indy-cli will replace sovrin-cli soon, so this fix in sovrin-cli will not make sense.;;;","04/Jan/18 5:41 AM;ckochenower;[~ozheregelya] - I see. If indy-cli is not derived from sovrin-cli and does not have this same flaw, then I say close the issue. The ""invalid"" designation was confusing. Thank you for looking into this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
It should be possible to add new fields to Node-to-Node messages,INDY-935,22932,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,ashcherbakov,ashcherbakov,30/Oct/17 9:39 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"As if now, Input Validation will not allow to have unknown (extra) fields in Node-to-Node messages (see node_messages.py).
But sometimes we have to extend communication with new fields.
The problem is that there can be Nodes in the pool which are still on old version, so they wil not understand this new messages.

As an option, we can just support having unknown extra fields at the end of a message, so the Nodes at least won't fail. 

Also as of now all Node-to-Node messages are just lists, not dicts. So, it's hard to map new values to fields.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-936,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-64,,,,,,,,,,"1|hzylmv:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 7:06 AM;ashcherbakov;This is already done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
We need to be able to support changes in Node-to-Node communication,INDY-936,22933,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,nage,ashcherbakov,ashcherbakov,30/Oct/17 10:08 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"It's perfectly possible that we may need to change Node-to-Node communication (add new messages, change protocol, ass/remove fields from messages, edit messages, etc.).

Option1:
Always require UPDATE on the same time, so we can assume that our pool is always at the same version.
- It may mean that our pool is unavailable for a couple of minutes, but probably it's fine for now, since we don't have big load, and we can always announce a maintenance time

Option2:
Define a 'pool protocol version' as a minimal version of nodes in the pool. We can get this version from config ledger (NODE_UPGRADE txn).
Have protocol-version-dependent code, so that we don't send new messages until all Nodes in the pool understand the new type of messages.
- it may slow down providing hotfixes, so probably should be combined with Option1.

Option3:
Each Node-to-Node message has a version, and we should send all versions of a message, so that both old and new Nodes can understand it.
- it doesn't help when we change the whole protocol, so we need Option2 there.",,,,,,,,,,,,,,,,,,,,,,,INDY-935,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-64,,,,,,,,,,"1|hzyln3:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 7:07 AM;ashcherbakov;Option2 is already implemented;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Inconsistent ledger entries count during the large ledger catch up,INDY-937,22938,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,anikitinDSR,VladimirWork,VladimirWork,31/Oct/17 12:11 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"Build Info:
indy-node 1.2.188

Overview:
Inconsistent ledger entries count during the large ledger catch up

Steps to Reproduce:
1. Install a pool of 4 nodes.
2. Write more than 50k NYMs via load_test.py script.
3. Stop the 1th node and delete .indy/data/ folder.
4. Start the 1th node.
5. Perform _read_ledger --type=domain --count_ at the 1th node several times during catch up.

Actual Results:
There are inconsistent sequence of entries (later requests can return lesser values or even bigger than the ledger pool count) and read_ledger tool freezes due to some requests:

root@28c8b0341b77:/home/indy# read_ledger --type=domain --count
773
root@28c8b0341b77:/home/indy# read_ledger --type=domain --count
28345
root@28c8b0341b77:/home/indy# read_ledger --type=domain --count
19871
root@28c8b0341b77:/home/indy# read_ledger --type=domain --count
^CTraceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 73, in recoverTree
    self.recoverTreeFromHashStore()
  File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 101, in recoverTreeFromHashStore
    self.tree.verify_consistency(self._transactionLog.size)
  File ""/usr/local/lib/python3.5/dist-packages/ledger/compact_merkle_tree.py"", line 287, in verify_consistency
    raise ConsistencyVerificationFailed()
ledger.util.ConsistencyVerificationFailed

Expected Results:
read_ledger tool should return actual values and shouldn't freeze.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/17 12:08 AM;VladimirWork;catch_up_40k.PNG;https://jira.hyperledger.org/secure/attachment/12827/catch_up_40k.PNG","31/Oct/17 10:24 PM;VladimirWork;logs.tar.gz;https://jira.hyperledger.org/secure/attachment/12900/logs.tar.gz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzx0mf:",,,,,,,,,,,,,,,,,,,,,,,,,,anikitinDSR,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/18 6:56 PM;anikitinDSR;This issue looks similar with INDY-1117. I think it's not actual for now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Resolve licensing issues discovered by Fossology scan,INDY-938,22949,,Bug,To Develop,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,tkuhrt,tkuhrt,31/Oct/17 4:31 AM,09/Oct/19 6:16 PM,28/Oct/23 2:47 AM,,,,,,0,,,,,,"Hyperledger Indy source from October 12, 2017 was scanned using Fossology to determine license for files contained in the following repositories
 * [https://github.com/hyperledger/indy-plenum.git]

 * [https://github.com/hyperledger/indy-node.git]

 * [https://github.com/hyperledger/indy-sdk.git]

 * [https://github.com/hyperledger/indy-anoncreds.git]

 * [https://github.com/hyperledger/indy-crypto.git]

From the Hyperledger Charter ([https://www.hyperledger.org/about/charter)] Section 13, all files that are included in Hyperledger projects should either be licensed with the Apache License, Version 2.0 for source code or Creative Commons Attribution 4.0 International License for documentation.  There are a few files in the Indy source base that do not meet these requirements.  See the attached file for results. 

The files listed under Attribution and No License Found need to be resolved. For the Attribution tab, these files should be replaced with code meeting the Apache 2.0 license.

For the files listed as No License Found, we should first check with the original contributors to make sure that they can contain an Apache 2.0 license (for source code) or a Creative Commons with Attribution 4.0 license (for documentation). Once this has been verified, the editable files must be annotated with the correct license text and/or the SPDX short identifiers (see  [https://spdx.org/sites/cpstandard/files/pages/files/using_spdx_license_list_short_identifiers.pdf]). For binary files, a license.txt file should be included in the directory calling out the file types and the associated license.

In addition, there are 5 files that say ""MIT/Apache-2.0"" as the license. It would be great if we can get confirmation from the contributor that this is a dual-license choice (e.g. we can choose one OR the other), and not a requirement that both licenses be followed.

Any files that are not covered by Apache 2.0 or CC by 4.0 that need to remain with the project will need to go through an exception process with the governing board.",,,,,,,,,,,,,,,,,,,,,,,IS-649,,,,,,,,,,,,"31/Oct/17 4:28 AM;tkuhrt;indy-2017-10.xlsx;https://jira.hyperledger.org/secure/attachment/12835/indy-2017-10.xlsx","06/Apr/18 1:38 AM;tkuhrt;indy-2018-04.xlsx;https://jira.hyperledger.org/secure/attachment/14857/indy-2018-04.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzwxqn:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,bdonneaux,esplinr,tkuhrt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Nov/17 6:40 PM;ashcherbakov;We have LGPL dependency because indy-anoncreds depends on charm-crypto. 
Our next plans are to create a new CLI based on libindy, so that indy-anoncreds will be fully deprecated, and we can remove indy-anoncreds (and hence LGPL dependency).

So, in the scope of this task, we need to fix No license found and other issues.;;;","17/Nov/17 5:08 PM;ashcherbakov;Moving the ticket to the next Sprint since we are waiting to some decisions related to Copyrights;;;","19/Dec/17 1:06 AM;bdonneaux;Happy I've found this opened issue, as I've got an additional remark for [/indy-plenum/LICENSE|https://github.com/hyperledger/indy-plenum/blob/master/LICENSE] : it contains the ""how to use"" APPENDIX and the template boilerplate with bracket-fields.

Created PR #[485|https://github.com/hyperledger/indy-plenum/pull/485] with a proposed update...

Apart from this, I'm not sure why indy-node is the only repo for which Github does not display the Apache-2.0 license badge and banner!?

See difference between those pages for instance:

[https://github.com/hyperledger/indy-node/blob/master/LICENSE]

[https://github.com/hyperledger/indy-plenum/blob/master/LICENSE]

[https://github.com/hyperledger/indy-sdk/blob/master/LICENSE]

Even weirder: our forks are showing the license badge/banner:

[https://github.com/digital-me/indy-node/blob/master/LICENSE]

Does anyone have the same issue or any idea?

 

REM: The md5sum is equivalent for all of them, and I've tried adding the LICENSE file in some other repo and it always ""fix"" the badge/banner.;;;","06/Apr/18 1:39 AM;tkuhrt;Added the latest results from the April 4, 2018 source code. The biggest call out here in addition to what is above is : 
 * There are some LGPL / LGPL-3.0 files in Indy, which should be reviewed and removed if possible.;;;","25/Apr/18 1:00 AM;esplinr;In IS-649, we added LICENSE files to most repos.

Remaining work:
* Deciding on a policy for file headers
* Migrating everything to be in compliance with that policy
* Remove LGPL components, probably by deprecating the old CLI with the legacy anoncred implementation and old getting started guide
* Double check everything

Prerequisites:
* What is the Hyperledger about copyright/license headers in source files?;;;","25/Apr/18 6:34 AM;tkuhrt;First, we do not have a mandated header but let projects decide what and how they want to establish a practice for this. 

We generally find copyright notices in headers fall out of date quickly. The contributor data is stored in git and determining ""copyright"" requires an analysis that becomes quite complex after the initial commit. 

We DO NOT remove copyright notices that are already in a file unless they're removed by the copyright owner. 

Most of our projects say something like, ""Copyright Hyperledger and its contributors."" and then include an SPDX short identifier for the license. For Apache 2, it would be a simple comment at the top of the file:  

{{SPDX-License-Identifier: Apache-2.0}}

See [https://spdx.org/using-spdx] for more information on using SPDX short identifiers.

 ;;;","25/Apr/18 6:49 AM;esplinr;[~tkuhrt]: Thank you for the guidance. We will follow that minimalist format.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLI can't be run by different users.,INDY-939,23215,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,dsurnin,ozheregelya,ozheregelya,01/Nov/17 12:49 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Steps to Reproduce:

1. Run CLI as one user (e.g. _me_)
2. Connect to test.
3. Exit the CLI.
4. Set yourself as another user (e.g. _indy_).
5. Run CLI.
6. Connect to test environment.

Actual Results:
Stacktrace and following error appear: PermissionError: [Errno 13] Permission denied: '/tmp/stp-portmutex.127.0.0.1.txt'

Expected Results:
CLI should work correctly with different users.

Additional Information:
Permissions for this file are:
{code:java}
19602 -rw-rw-r-- 1 me me 4 Out 31 15:13 /tmp/stp-portmutex.127.0.0.1.txt{code}","indy-anoncreds 1.0.32
indy-node 1.2.191
indy-plenum 1.2.158
libindy-crypto 0.1.6-10
python3-indy-crypto 0.1.6
sovrin 1.1.36",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzx0r3:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/17 9:27 PM;ashcherbakov;[~krw910] [~ozheregelya] [~VladimirWork]
I think we always had a problem that a CLI can be run only from the user it's installed from, hadn't we?;;;","01/Nov/17 10:42 PM;krw910;[~ashcherbakov] Yes that is correct. I have been having that issue and my understanding from [~ozheregelya] is that [~dsurnin] is aware of this issue and was working on it. At least I think it was Dmitry.;;;","05/Dec/17 7:19 PM;ozheregelya;Probably ticket will not be actual after changing current python CLI to indy-sdk based CLI. Need to retest it after implementation of new CLI.;;;","04/Jan/18 2:33 AM;ozheregelya;Ticket is not actual for indy-cli (version 1.1.1~306). New cli works correctly for several users on one machine.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testNodeControlRemovesBackups fails intermittently,INDY-940,23216,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,ashcherbakov,ashcherbakov,01/Nov/17 1:16 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Example log:
https://ci.evernym.com/job/indy-node-verify-x86_64/47/artifact/test-result-node.ubuntu-11.txt

{code}
        nct = NCT(backup_dir=tdir, backup_target=tdir, transform=transform)
        try:
>           assert len(nct.tool._get_backups()) == 0
E           AssertionError: assert 1 == 0
E            +  where 1 = len(['/tmp/pytest-of-indy/pytest-6/2/_backup_1.2.zip'])
E            +    where ['/tmp/pytest-of-indy/pytest-6/2/_backup_1.2.zip'] = <bound method NodeControlTool._get_backups of <indy_node.utils.node_control_tool.NodeControlTool object at 0x7f7a21ceafd0>>()
E            +      where <bound method NodeControlTool._get_backups of <indy_node.utils.node_control_tool.NodeControlTool object at 0x7f7a21ceafd0>> = <indy_node.utils.node_control_tool.NodeControlTool object at 0x7f7a21ceafd0>._get_backups
E            +        where <indy_node.utils.node_control_tool.NodeControlTool object at 0x7f7a21ceafd0> = <indy_node.test.upgrade.helper.NodeControlToolExecutor object at 0x7f7a21ceaf98>.tool

indy_node/test/upgrade/test_node_control_tool.py:143: AssertionError
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzx0lb:",,,,,,INDY 17.23,,,,,,,,,,,,,,,,,,,,anikitinDSR,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Nov/17 12:04 AM;anikitinDSR;Problem reason: 
 * the problem was in testNodeControlRemovesBackups. When test checks that backups were removed from directory, they still not removed (check without waiting for remove).

Changes: 
 * added waiting while process with NodeControlTool was really stopped
 * added async wait for ""backups exists check""

Committed into:
 * https://github.com/hyperledger/indy-node/pull/455

Risk factors:
 * Nothing is expected.

Risk:
 * Low;;;","22/Nov/17 11:27 PM;ashcherbakov;The test started to pass. Done.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to catch up agent if a validator is down,INDY-941,23234,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,VladimirWork,mgbailey,mgbailey,01/Nov/17 7:00 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,Must,,,,,"The catch up logic divides the transactions that need to be be caught up by the number of nodes that are in the genesis file, parceling the upgrade transactions out some to each node.  If one of the nodes is down or even slow in responding, we do not catch up and the system goes into a failed state.  This is true for agents that are attempting to catchup the pool ledger while connecting, and possibly for validators as well.  On the other hand, the CLI client appears to retry and get the update from another node.

*Failure or slow response from any node must not result in a failure to catchup, whether the catchup request is from another validator, an agent, or a client CLI.*

The network that was being used when this issue appeared is the STN.  This network has 7 transactions in the pool genesis file, and 18 transactions on the pool ledger, meaning that 11 transactions need to be caught up.  The agent code requests 2 transactions from each of the first 5 nodes listed in the genesis file, and 1 transaction from the 6th (singapore). From some agent VMs, singapore was slow to respond, triggering the issue when the agent did not catch up that last transaction.  From other agent VMs it is able to respond to the request in time and the catchup is successful.  To confirm the issue, we shut down singapore entirely.  In this case, catchup was unsuccessful on all nodes.

Attached are the following logs:
 # intrepid_working.txt - an agent log with the singapore validator node running, from a vm that connects to it relatively quickly.  Update succeeds.
 # intrepid_broken.txt - an agent log with the singapore validator node down. Update fails.
 # cli.log - a log from a node running the cli with the singapore validator node down.  After a delay, update succeeds when a different validator is used to fetch the transaction.

 ","STN, running 1.1.43.  All agents and clients used were 1.1.43 as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Nov/17 7:30 PM;VladimirWork;Screenshot.PNG;https://jira.hyperledger.org/secure/attachment/13324/Screenshot.PNG","01/Nov/17 6:59 AM;mgbailey;cli.log;https://jira.hyperledger.org/secure/attachment/12904/cli.log","14/Nov/17 8:42 PM;VladimirWork;faber@live.PNG;https://jira.hyperledger.org/secure/attachment/13334/faber%40live.PNG","01/Nov/17 7:17 AM;mgbailey;intrepid.py;https://jira.hyperledger.org/secure/attachment/12905/intrepid.py","01/Nov/17 7:00 AM;mgbailey;intrepid_broken.txt;https://jira.hyperledger.org/secure/attachment/12903/intrepid_broken.txt","01/Nov/17 7:00 AM;mgbailey;intrepid_working.txt;https://jira.hyperledger.org/secure/attachment/12902/intrepid_working.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzymqf:",,,,,,INDY 17.22,INDY 17.23,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,mgbailey,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/17 7:06 AM;krw910;[~ashcherbakov] We need someone on this issue right away.;;;","01/Nov/17 7:17 AM;mgbailey;This is the agent code used: [^intrepid.py].  ;;;","01/Nov/17 9:29 AM;mgbailey;I was able to reproduce this issue with an out-of-the-box faber agent;;;","02/Nov/17 1:13 AM;ashcherbakov;[~mgbailey] [~krw910]
I think the problem is the following:
- Once started, Agent performs some bootstrapping scripts including sending of SCHEMA txns. 
- There is a timeout for this sending (30 seconds)
- Sending of a txn can not be done until catch-up is finished 
- It turned out in this particular case that it takes more than 30 seconds to catch-up (there is a timeout in catch-up logic as well which checks whether we got sufficient number of CatchupReplies from Nodes, and, if not, ask for missing; this timeout may be close to 30 seconds as well, so we may strat a second round of catch-up in 30 seconds only, when timeout for sending of SCHEMA is reached).
- Although we will probably need to have a look at catch-up logic and see whether it's possible to reduce this timeout and speed up catch-up, I propose the following hotfix you can apply for Agents:

*Hotfix*
Wait until client is connected to Nodes and catch-up is finished before sending initial SCHEMA txns.
Find out `run_agent.py` script (in `indy_client/agent/run_agent.py`), and modify `def runAgent(agent, looper=None, bootstrap=None):` as follows:
{code}
def runAgent(agent, looper=None, bootstrap=None):
    assert agent

    def is_connected(agent):
        client = agent.client
        from plenum.common.startable import Mode
        if client.mode != Mode.discovered:
            raise Exception(""Client hasn't finished catch-up with Pool Ledger yet"")
        if not client.hasSufficientConnections:
            raise Exception(""Client doesn't have sufficient number of connections to send write requests"")

    async def wait_until_connected(agent):
        from stp_core.loop.eventually import eventually
        await eventually(is_connected, agent,
                         timeout=120, retryWait=2)

    def do_run(looper):
        agent.loop = looper.loop
        looper.add(agent)
        logger.info(""Running {} now (port: {})"".format(agent.name, agent.port))
        if bootstrap:
            looper.run(wait_until_connected(agent))
            looper.run(runBootstrap(bootstrap))

    if looper:
        do_run(looper)
    else:
        with Looper(debug=getConfig().LOOPER_DEBUG, loop=agent.loop) as looper:
            do_run(looper)
            looper.run()
{code}
;;;","02/Nov/17 3:02 AM;mgbailey;[~ashcherbakov], thanks for this hotfix, it works.  I tested it by leaving the singapore node down.  After starting the agent, it gets transaction updates from all nodes except for singapore.  It then waits for quite a while, and then it looks like it gets the update that was assigned to singapore from a different node instead. Then the agent is able to come up. It is good that I will be able to move forward with the client now.

Will it ever time out, or is it in an infinite loop now?  [~krw910], we will want to make sure that this, or something like it, is merged into the codebase.;;;","02/Nov/17 5:19 PM;ashcherbakov;[~krw910] [~mgbailey]
I will merge the hotfix I provided into the codebase.
As I know, there is no timeout for catch-up, so it will try forever.;;;","07/Nov/17 10:24 PM;ashcherbakov;Changes:
- applied the hotfix above to the code;
- fixed client's class to have proper can_send methods (which wait for pool ledger catch-up finishing), and added tests for this

PR:
- https://github.com/hyperledger/indy-plenum/pull/440
- https://github.com/hyperledger/indy-node/pull/435

Build:
- 1.2.204;;;","10/Nov/17 7:29 PM;VladimirWork;Build Info:
indy-node 1.2.205

Steps to Reproduce:
1. Install pool of 7 nodes.
2. Shut down the 7th node.
3. Send role and verkey to Faber's DID.
4. Start the Faber agent on the 2nd node.
5. Wait 2+ minutes.

Actual Results:
{quote}
2017-11-10 09:55:02,302 | INFO     | run_agent.py         (79) | do_run | Running Faber College now (port: 5555)
2017-11-10 09:57:02,398 | ERROR    | eventually.py        (182) | eventually | is_connected failed; not trying any more because 120 seconds have passed; args were (<indy_client.agent.walleted_agent.WalletedAgent object at 0x7f717354a7b8>,)
2017-11-10 09:57:02,398 | ERROR    | looper.py            (249) | wrapper | Error while running coroutine wait_until_connected: NotConnectedToNetwork(""Client hasn't finished catch-up with Pool Ledger yet or doesn't have sufficient number of connections"",)
2017-11-10 09:57:02,399 | INFO     | looper.py            (272) | shutdown | Looper shutting down now...
2017-11-10 09:57:02,405 | INFO     | walleted_agent.py    (129) | _saveWallet | Active wallet ""Faber College"" saved (/home/indy/.indy-cli/wallets/agents/faber-college/faber college.wallet)
2017-11-10 09:57:02,407 | INFO     | walleted_agent.py    (129) | _saveWallet | Active wallet ""issuer"" saved (/home/indy/.indy-cli/wallets/agents/faber-college/issuer/issuer.wallet)
2017-11-10 09:57:02,408 | INFO     | zstack.py            (327) | stop | stack HVVEPZzbaHdLK6RRxgJLcLR6mh6Zvn1ePTUD1AZxdEG9 closing its listener
2017-11-10 09:57:02,408 | DEBUG    | authenticator.py     (37) | stop | Stopping ZAP at b'inproc://zeromq.zap.1'
2017-11-10 09:57:02,408 | INFO     | zstack.py            (331) | stop | stack HVVEPZzbaHdLK6RRxgJLcLR6mh6Zvn1ePTUD1AZxdEG9 stopped
2017-11-10 09:57:02,408 | INFO     | zstack.py            (327) | stop | stack FaberCollege closing its listener
2017-11-10 09:57:02,409 | DEBUG    | authenticator.py     (37) | stop | Stopping ZAP at b'inproc://zeromq.zap.2'
2017-11-10 09:57:02,409 | INFO     | zstack.py            (331) | stop | stack FaberCollege stopped
2017-11-10 09:57:02,409 | INFO     | looper.py            (279) | shutdown | Looper shut down in 0.010 seconds.
2017-11-10 09:57:02,409 | ERROR    | runnable_agent.py    (50) | run_agent | 

------------------------------------------------------------------ERROR------------------------------------------------------------------
  Agent startup failed: [cause : Client hasn't finished catch-up with Pool Ledger yet or doesn't have sufficient number of connections]
------------------------------------------------------------------ERROR------------------------------------------------------------------

sys:1: RuntimeWarning: coroutine 'bootstrap_faber' was never awaited
{quote}

Expected Results:
Agent should catch up normally.;;;","11/Nov/17 12:16 AM;ashcherbakov;The cause of the problem is file-folder refactoring issues.
Fixed in https://github.com/hyperledger/indy-node/pull/444

Now faber, acme and thrift are run against a correct folder (taking into account Networks). Agents are connected to sandbox by default.
--network parameter is also added which can help in connecting to another network.;;;","14/Nov/17 8:42 PM;VladimirWork;Build Info:
indy-node 1.2.209

Steps to Validate:
1. Set up pool and shut down some of the nodes.
2. Run agent.

Actual Results:
Agent catches up and works successfully. Parameter --network works correctly. !faber@live.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Doc] Community needs to be able to follow guidelines we propose,INDY-942,23833,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,ashcherbakov,ashcherbakov,08/Nov/17 12:31 AM,09/Oct/19 5:51 PM,28/Oct/23 2:47 AM,09/Oct/19 5:51 PM,,,,,0,Documentation,,,,,"- Need to analyse recent stories and add required guidelines 
- Make the guidelines public to share with the Community

Examples of guidelines:
- file folder guideline;
- keys guideline",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-792,,,,,,,,,,"1|hzwyyv:",,,,,,,,,,,,,,3.0,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 5:51 PM;ashcherbakov;We have guidelines in https://github.com/hyperledger/indy-node/tree/master/docs/source;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Doc] Analyze what design docs we can make public for community,INDY-943,23834,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ashcherbakov,ashcherbakov,ashcherbakov,08/Nov/17 12:32 AM,09/Oct/19 5:50 PM,28/Oct/23 2:47 AM,09/Oct/19 5:50 PM,,,,,0,Documentation,,,,,"We improved our docs in the scope of INDY-754.
We need also to have a closer look at what else can be made public to help Community to understand Architecture and code.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-792,,,,,,,,,,"1|hzx0pj:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 5:50 PM;ashcherbakov;We've already made public as much as possible;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Problems with dependencies during manual upgrading of indy-node package,INDY-944,23860,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ozheregelya,ozheregelya,09/Nov/17 4:23 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Steps to Reproduce:

1. Set up the docker pool with indy-node 1.2.180 version.
 2. Connect to all nodes and start manual upgrade as described in [https://docs.google.com/document/d/1vUvbioL5OsmZMSkwRcu0p0jdttJO5VS8K3GhDLdNaoI/edit]

Actual Results: 
 On part of nodes sudo apt-get install indy-node command failed with following error:

 
{code:java}
root@449bf745d0b8:/home/indy# sudo apt-get install indy-node
Reading package lists... Done
Building dependency tree 
Reading state information... Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:
The following packages have unmet dependencies:
 indy-node : Depends: indy-plenum (= 1.2.169) but 1.2.151 is to be installed
E: Unable to correct problems, you have held broken packages.
{code}
Expected Results:
 Dependencies should be upgraded without errors.

Additional Information:
 Packages were upgraded without errors on the first node:
!Screenshot_2017-11-08_16-18-33.png|thumbnail!
Packages have the same versions on all nodes:
!Screenshot_2017-11-08_16-21-29.png|thumbnail!",indy-node 1.2.203,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Nov/17 4:22 AM;ozheregelya;Screenshot_2017-11-08_16-18-33.png;https://jira.hyperledger.org/secure/attachment/13310/Screenshot_2017-11-08_16-18-33.png","09/Nov/17 4:20 AM;ozheregelya;Screenshot_2017-11-08_16-21-29.png;https://jira.hyperledger.org/secure/attachment/13311/Screenshot_2017-11-08_16-21-29.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzympr:",,,,,,INDY 17.23,,,,,,,,,,,,,,,,,,,,andkononykhin,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Nov/17 10:35 PM;andkononykhin;Problem reason:
 - indy-node package upgrade using *apt-get install indy-node* failed because indy-plenum package (as well as other indy packages) had been marked held. Thus, it couldn't be updated implicitly ([automatically|http://manpages.ubuntu.com/manpages/zesty/man8/apt-mark.8.html]) by mentioned apt-get command.
 - options how to fix:
 ** use *apt-get install indy-node indy-plenum indy-anoncreds*  instead. this explicitly marks indy-plenum (and indy-anoncreds) for update so hold limitation is passed. Node control service itself uses that way.
 ** unhold indy-plenum (indy-anoncreds) and do indy-node installation:
 *** apt-mark unfold indy-node indy-anoncreds
 *** apt-get install indy-node
 *** apt-mark fold indy-node indy-anoncreds

Changes:
 - no

Recommendations for QA:
 * check suggested fixes
 * updated QA docs;;;","13/Nov/17 10:44 AM;ozheregelya;*How to upgrade a node manually* document  ([https://docs.google.com/document/d/1vUvbioL5OsmZMSkwRcu0p0jdttJO5VS8K3GhDLdNaoI/edit|https://docs.google.com/document/d/1vUvbioL5OsmZMSkwRcu0p0jdttJO5VS8K3GhDLdNaoI/edit)] ) was updated.
*Scenario 00 - Upgrade* doesn't need to be changed because of problem with holding packages does not affects client installation. But comment for using client on node machine was added.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[devops] We need to be able to work with docker images for running tests in Hyperledger infrustructure,INDY-945,23872,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ashcherbakov,ashcherbakov,09/Nov/17 6:12 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"- Our tests are run in Docker.
- Our current Jenkins uses persistent Agents, so there is no need to re-create Docker images
- Hyperledger Jenkins uses Agents on demand, so re-creating images may slow down tests a lot.

We need to find a solution for this (upload docker images to Dockerhub for example?)",,,,,,,,,,,,,,,,,,,,,,,INDY-837,,,,INDY-963,INDY-964,INDY-965,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0xr:",,,,,,INDY 17.23,INDY 17.24: Node Perf,,,,,,,5.0,,,,,,,,,,,,andkononykhin,ashcherbakov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Nov/17 10:32 PM;andkononykhin;Hyperledger Jenkins uses minions from OpenStack - on demand created agents with a set of software pre-installed including pulled docker images.
h2. PoA

*option 1*
 * use base image for fabric projects based on ubuntu 16.04
 * configure our dockerfiles to base on it

*option 2* 
 * creat base docker image for indy projects and inject to one of the OpecnStack images
 * configure dockerfiles to base on it

Option 2 seems quite better because:
 * cleaner environment
 * more configuration common for all indy projects will be pre-installed

 ;;;","23/Nov/17 10:04 PM;andkononykhin;PRs to indy core repos:

https://github.com/hyperledger/indy-node/pull/464
https://github.com/hyperledger/indy-anoncreds/pull/113
https://github.com/hyperledger/indy-plenum/pull/460;;;","24/Nov/17 6:54 PM;andkononykhin;Problem reason:
 - no docker images hierarchy for ci testing and copy-paste like (similar but not the same) dockerfiles in indy core repos lead to non optimal docker images build routine

Changes:
 - moved common parts of dockerfiles to baseimages (3 levels of them) and automated baseimages build routine. For now that code [is placed|https://github.com/hyperledger/indy-node/tree/master/docker-files/baseimage] in indy-node repo and used by all three repos.
 - updated in dockerfiles  in repos
 - updated jenkinsfiles

Committed into:
 - [https://github.com/hyperledger/indy-node/pull/464]
 - [https://github.com/hyperledger/indy-anoncreds/pull/113]
 - [https://github.com/hyperledger/indy-plenum/pull/460]

Risk factors:
 - broken CI testing

Risk:
 - Low

Covered with tests:
 - tested manually

Recommendations for QA: do the following sequence of steps
 * check that base images are built by the make routine without any issues
 ** clone  indy-node
 ** create base images *make -C docker-files/baseimage*
 ** check images *docker images hyperledger/indy**
 * check that ci images are built as well
 ** for any core indy repo: *docker build -t indy-test -f ci/ubuntu.dockerfile ci*
 *  check that tests are run as usual on jenkins pipelines
 ** [https://ci.evernym.com/view/ci/job/Indy-Anoncreds/job/indy-anoncreds-verify-x86_64/]
 ** [https://ci.evernym.com/view/ci/job/Indy-Node/job/indy-node-verify-x86_64/]
 ** [https://ci.evernym.com/view/ci/job/Indy-Plenum/job/indy-plenum-verify-x86_64/];;;","29/Nov/17 1:39 AM;ozheregelya;Version Info:
indy-node 1.2.222

Steps to Validate:
 * check that base images are built by the make routine without any issues
 ** clone  indy-node
 ** create base images *make -C docker-files/baseimage*
 ** check images *docker images hyperledger/indy**
 * check that ci images are built as well
 ** for any core indy repo: *docker build -t indy-test -f ci/ubuntu.dockerfile ci*
 *  check that tests are run as usual on jenkins pipelines
 ** [https://ci.evernym.com/view/ci/job/Indy-Anoncreds/job/indy-anoncreds-verify-x86_64/]
 ** [https://ci.evernym.com/view/ci/job/Indy-Node/job/indy-node-verify-x86_64/]
 ** [https://ci.evernym.com/view/ci/job/Indy-Plenum/job/indy-plenum-verify-x86_64/]

Actual Results:
Following images were build after performed steps:
{code:java}
indy-test
hyperledger/indy-core-baseci
hyperledger/indy-baseci
hyperledger/indy-baseimage{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testNodeCatchupFPlusOne fails intermittenty,INDY-946,23879,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ashcherbakov,ashcherbakov,09/Nov/17 11:46 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,See attached,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Nov/17 11:46 PM;ashcherbakov;testNodeCatchupFPlusOne;https://jira.hyperledger.org/secure/attachment/13318/testNodeCatchupFPlusOne",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzwzbz:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,sergey.khoroshavin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/18 7:49 PM;sergey.khoroshavin;*Triage*
This test didn't fail for quite a long time, also there were lots of fixes in catchup since then, so I'm marking this as done.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"As a Node, I need to be able to present Signed State Proof for write requests",INDY-947,23883,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,ashcherbakov,ashcherbakov,ashcherbakov,10/Nov/17 12:34 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"As of now, we return State Proof for read requests only.
We need to extend it to present state proof for write requests as well, so that a client would be able to connect to one node only for both write and read requests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-61,,,,,,,,,,"1|hzx0pz:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Mar/18 10:35 PM;ashcherbakov;We are going to use audit proof (based on ledger state) for write requests.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node is broken after adding it to pool,INDY-948,23911,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,11/Nov/17 12:20 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
indy-node 1.2.206

Steps to Reproduce:
1. Start pool of 4 nodes.
2. Force 4 view changes (so new primary is the 1st node again).
3. Add the 5th node.
4. Send some NYMs.
5. Force 4 view changes (so new primary is the 5st node).
6. Add the 6th node.
7. Check ledger and log on the 6th node.

Actual Results:
The 6th node isn't catched up with other 5 nodes.
There is a trace log in `systemctl status indy-node` and in journalctl.

Expected Result:
The 6th node should work the same as the 5th node after adding.",,,,,,,,,,,,,,,,,,,,,,,INDY-909,,,,,,,,,,,,"11/Nov/17 12:20 AM;VladimirWork;6th_node_adding.PNG;https://jira.hyperledger.org/secure/attachment/13327/6th_node_adding.PNG","20/Dec/17 12:33 AM;VladimirWork;INDY-948.PNG;https://jira.hyperledger.org/secure/attachment/13924/INDY-948.PNG","11/Nov/17 12:20 AM;VladimirWork;Node1.log;https://jira.hyperledger.org/secure/attachment/13326/Node1.log","11/Nov/17 12:20 AM;VladimirWork;Node6.log;https://jira.hyperledger.org/secure/attachment/13325/Node6.log","30/Nov/17 6:35 PM;VladimirWork;_node6_new.txt;https://jira.hyperledger.org/secure/attachment/13431/_node6_new.txt","30/Nov/17 6:35 PM;VladimirWork;domain_count.PNG;https://jira.hyperledger.org/secure/attachment/13432/domain_count.PNG","14/Nov/17 10:22 PM;VladimirWork;journalctl.txt;https://jira.hyperledger.org/secure/attachment/13335/journalctl.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzypvz:",,,,,,INDY 17.23,INDY 17.25,,,,,,,,,,,,,,,,,,,anikitinDSR,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Nov/17 6:31 PM;VladimirWork;Additional Info:
Case without view changes (simply adding 5th and 6th nodes to the pool) works normally.;;;","30/Nov/17 6:35 PM;VladimirWork;Build Info:
indy-node 1.2.224

Steps to Reproduce:
1. Start pool of 4 nodes.
2. Force 4 view changes (so new primary is the 1st node again).
3. Add the 5th node.
4. Send some NYMs.
5. Force 4 view changes (so new primary is the 5st node).
6. Add the 6th node.
7. Check ledger and log on the 6th node.

Actual Results:
There is no errors in status or journalctl, but there are errors in Node6 log and it still isn't catched up with other 5 nodes. [^_node6_new.txt]  !domain_count.PNG|thumbnail! 
;;;","19/Dec/17 7:43 PM;anikitinDSR;Problem reason:
 - The problem is in adding 6th node after forcing 4 view change view. 

Changes:

 - Remove adding line separator in binary files before init domainLedger if file is not empty

 -  Tests added:
     - plenum/test/node_catchup/test_node_catchup_when_3_not_primary_node_restarted.py
     - plenum/test/view_change/test_new_node_joins_after_view_change.py
    - plenum/test/view_change/test_that_domain_ledger_the_same_after_restart_for_all_nodes.py

PR:
 - [https://github.com/hyperledger/indy-plenum/pull/486/]

Version:
 - master

Risk:
 - Low

Covered with tests:

    - plenum/test/node_catchup/test_node_catchup_when_3_not_primary_node_restarted.py
     - plenum/test/view_change/test_new_node_joins_after_view_change.py
    - plenum/test/view_change/test_that_domain_ledger_the_same_after_restart_for_all_nodes.py

Recommendations for QA
 1. Start pool of 4 nodes.
 2. Force 4 view changes (so new primary is the 1st node again).
 3. Add the 5th node.
 4. Send some NYMs.
 5. Force 4 view changes (so new primary is the 5st node).
 6. Add the 6th node.
 7. Check ledger and log on the 6th node.;;;","20/Dec/17 12:33 AM;VladimirWork;Build Info:
indy-node 1.2.244

Steps to Validate:
1. Start pool of 4 nodes.
2. Force 4 view changes (so new primary is the 1st node again).
3. Add the 5th node.
4. Send some NYMs.
5. Force 4 view changes (so new primary is the 5st node).
6. Add the 6th node.
7. Check ledger and log on the 6th node.
8. Restart 5th node to select 6th node as primary.
9. Send some NYMs and check ledgers of all nodes.

Actual Results:
Both nodes are added, catched up and reached consensus normally. Pool of 6 nodes works well. !INDY-948.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unclear messages appear during reading transactions,INDY-949,23945,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,15/Nov/17 7:07 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Version Info:
indy-node=1.2.209

Steps to Reproduce:
1. Set up the docker pool of 4 nodes with 1.2.209 version of indy-node.
2. Install client with the same version (using other machine, not docker container created by client_for_pool_start.sh).
3. Copy content of /var/lib/indy/sandbox/pool_transactions_genesis and /var/lib/indy/sandbox/domain_transactions_genesis files from node machine to /.indy-cli/networks/sandbox/pool_transactions_genesis and /.indy-cli/networks/sandbox/domain_transactions_genesis on client machine.
4. Run the client. Verify that all works correctly by rending write and read transactions.
=> transactions are successfully written and read.
5. Stop services on n-1 nodes one-by-one and send read transaction after each node stopping.
 
Actual Results:
Here is output of CLI for described steps:
{quote}indy@sandbox> send NYM dest=V4SGRU86Z58d6TV7PBUe61 role=TRUST_ANCHOR verkey=~V4SGRU86Z58d6TV7PBUe61
Adding nym V4SGRU86Z58d6TV7PBUe61
Nym V4SGRU86Z58d6TV7PBUe61 added
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe61
Getting nym V4SGRU86Z58d6TV7PBUe61
Current verkey for NYM V4SGRU86Z58d6TV7PBUe61 is ~V4SGRU86Z58d6TV7PBUe61 with role TRUST_ANCHOR
CONNECTION: HoN6XaczjWJpnyZUB1LvtpKpVLmzjJv78rCY3scKGt99 disconnected from Node5C
indy@sandbox> send NYM dest=V4SGRU86Z58d6TV7PBUe62 role=TRUST_ANCHOR verkey=~V4SGRU86Z58d6TV7PBUe62
Adding nym V4SGRU86Z58d6TV7PBUe62
Nym V4SGRU86Z58d6TV7PBUe62 added
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe62
Getting nym V4SGRU86Z58d6TV7PBUe62
Current verkey for NYM V4SGRU86Z58d6TV7PBUe62 is ~V4SGRU86Z58d6TV7PBUe62 with role TRUST_ANCHOR
CONNECTION: HoN6XaczjWJpnyZUB1LvtpKpVLmzjJv78rCY3scKGt99 disconnected from Node4C
indy@sandbox> send NYM dest=V4SGRU86Z58d6TV7PBUe63 role=TRUST_ANCHOR verkey=~V4SGRU86Z58d6TV7PBUe62
Adding nym V4SGRU86Z58d6TV7PBUe63
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe62
Getting nym V4SGRU86Z58d6TV7PBUe62
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
Current verkey for NYM V4SGRU86Z58d6TV7PBUe62 is ~V4SGRU86Z58d6TV7PBUe62 with role TRUST_ANCHOR
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
CONNECTION: HoN6XaczjWJpnyZUB1LvtpKpVLmzjJv78rCY3scKGt99 disconnected from Node3C
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe61
Getting nym V4SGRU86Z58d6TV7PBUe61
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
Current verkey for NYM V4SGRU86Z58d6TV7PBUe61 is ~V4SGRU86Z58d6TV7PBUe61 with role TRUST_ANCHOR
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe62
Getting nym V4SGRU86Z58d6TV7PBUe62
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
Current verkey for NYM V4SGRU86Z58d6TV7PBUe62 is ~V4SGRU86Z58d6TV7PBUe62 with role TRUST_ANCHOR
CONNECTION: HoN6XaczjWJpnyZUB1LvtpKpVLmzjJv78rCY3scKGt99 disconnected from Node2C
indy@sandbox> send GET_NYM dest=V4SGRU86Z58d6TV7PBUe62
Getting nym V4SGRU86Z58d6TV7PBUe62
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""
b""\x86\xbb\xfa\xafdun\x90\xe3k\xd7T&@'\x11)\x9c\x9bt\xe3\xceh\x90\x95\x97\xaeB\x04\xf9I\x93""{quote}

Expected Results:
Obvious problem is that messages are strange and useless. Messages should not be shown or they should be informative for user.

Question:
Is that correct that pool_transactions_genesis and domain_transactions_genesis are not enough for correct validation of blskeys on CLI side?

Additional Information:
If you will use docker client (created by client_for_pool_start.sh), client will work correctly, error messages will not be shown.
Genesis files of docker client and client on separated machine were double-checked and they are the same.",,,,,,,,,,,,,,,,,,,,,,,INDY-927,,,,,,,,,,,,"15/Nov/17 7:07 PM;VladimirWork;CLI_messages.PNG;https://jira.hyperledger.org/secure/attachment/13337/CLI_messages.PNG","17/Nov/17 5:59 PM;VladimirWork;INDY-949.PNG;https://jira.hyperledger.org/secure/attachment/13349/INDY-949.PNG","15/Nov/17 7:41 PM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/13338/_node1.txt","15/Nov/17 7:41 PM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/13339/_node2.txt","15/Nov/17 7:41 PM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/13340/_node3.txt","15/Nov/17 7:41 PM;VladimirWork;_node4.txt;https://jira.hyperledger.org/secure/attachment/13341/_node4.txt","15/Nov/17 7:41 PM;VladimirWork;cli.log.tar.gz;https://jira.hyperledger.org/secure/attachment/13342/cli.log.tar.gz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzymo7:",,,,,,INDY 17.23,,,,,,,,,,,,,,,,,,,,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Nov/17 10:02 PM;ashcherbakov;Problem: 
- there was a bug in create state proof code. It created the proof for the latest state, not the committed one.
- so, in the situation above, when we send NYM txn to a pool of 2 nodes, it's applied to the state trie, but not committed (since we don't have consensus). If later on we send GET_NYM, it returns state proof for the uncommitted state trie root, so state proof validation fails, and we see the problem above.

PR:
- https://github.com/hyperledger/indy-plenum/pull/449
- https://github.com/hyperledger/indy-node/pull/451

Build:
0.2.211;;;","17/Nov/17 5:59 PM;VladimirWork;Build Info:
indy-node 1.2.211

Steps to Validate:
1. Set up the docker pool of 4 nodes with 1.2.211 version of indy-node.
2. Install client with the same version (using other machine, not docker container created by client_for_pool_start.sh).
3. Copy content of /var/lib/indy/sandbox/pool_transactions_genesis and /var/lib/indy/sandbox/domain_transactions_genesis files from node machine to /.indy-cli/networks/sandbox/pool_transactions_genesis and /.indy-cli/networks/sandbox/domain_transactions_genesis on client machine.
4. Run the client. Verify that all works correctly by rending write and read transactions.
=> transactions are successfully written and read.
5. Stop services on n-1 nodes one-by-one and send read transaction after each node stopping.

Actual Results:
There are no incorrect CLI messages. GET_NYM works normally with n-1 nodes stopped (returns the last commited NYM). !INDY-949.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RC 1.2.44 fails to install due to package error,INDY-950,23995,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,VladimirWork,mgbailey,mgbailey,17/Nov/17 8:21 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"While attempting to install the RC using
{code:java}
apt-get install -y debsigs debsig-verify apt-transport-https dialog figlet python-pip python3-pip python3.5-dev libsodium18 python3-indy-crypto=0.1.6 sovrin
{code}
we fail with the error ""sovrin : Depends: indy-node but it is not going to be installed""

Tracing the error back to its source, I see that there is a dependency on python3-indy-crypto  version 0.1.6 that is not being met.  This version is in the rc repo, but it is not the most recent version.  There are also versions 0.1.6-6 and 1.1.6-7, which seem to be interfering with the ability of apt to find the correct package.  These versions only exist in the rc branch.  We do not have this same problem in the master branch.  If the above line is modified to include the package information for python3-indy-crypto, then the package installation succeeds:
{code:java}
apt-get install -y debsigs debsig-verify apt-transport-https dialog figlet python-pip python3-pip python3.5-dev libsodium18 python3-indy-crypto=0.1.6 python3-indy-crypto=0.1.6 sovrin
{code}
It should not be necessary to include package version information on dependencies during installation.",,,,,,,,,,,,,,,,,,,,,,,IS-360,,,,,,,,,,,,"17/Nov/17 9:00 PM;VladimirWork;pool_setup.PNG;https://jira.hyperledger.org/secure/attachment/13350/pool_setup.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzymnz:",,,,,,INDY 17.23,,,,,,,,,,,,,,,,,,,,andkononykhin,mgbailey,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Nov/17 5:28 PM;andkononykhin;[~mgbailey] actually you don't need to specify python3-indy-crypto during sovrin/node/plenumr installation explicitly. If it doesn't work without that - it's a bug.;;;","17/Nov/17 5:28 PM;andkononykhin;Problem reason:
 - rc component of sovrin apt repo includes temporary artifacts (v.0.1.6-6 and v.0.1.6-7) generated by sdk team during releasing 1.0.6 version of indy-crypto. It breaks sovrin (indy-node) normal package installation

Changes:
 - removed v.0.1.6-6 and v.0.1.6-7 of pyhon3-indy-crypto from rc component, chekcked stable as well - no issue there. IS-360 should fix that case completely.

Committed into:
 - nothing

Risk factors:
 - Nothing is expected.

Risk:
 - Low

Covered with tests:
 - tested manually:
{code:java}
$ tail -n5 /etc/apt/sources.list
# deb-src http://security.ubuntu.com/ubuntu xenial-security multiverse
deb https://apt.dockerproject.org/repo/ ubuntu-xenial main
# deb-src https://apt.dockerproject.org/repo/ ubuntu-xenial main
deb http://us.archive.ubuntu.com/ubuntu xenial main universe
deb https://repo.sovrin.org/deb xenial rc

$ sudo apt-get install sovrin
Reading package lists... Done
Building dependency tree 
Reading state information... Done
The following additional packages will be installed:
at indy-anoncreds indy-node indy-plenum libleveldb1v5 libsnappy1v5 python3-base58 python3-dateutil
python3-indy-crypto python3-intervaltree python3-ioflo python3-jsonpickle python3-lazy-object-proxy python3-leveldb
python3-libnacl python3-msgpack python3-orderedset python3-portalocker python3-prompt-toolkit python3-psutil
python3-pygments python3-pyzmq python3-raet python3-rlp python3-semver python3-sha3 python3-sortedcontainers
python3-timeout-decorator python3-ujson python3-wcwidth
Suggested packages:
default-mta | mail-transport-agent python3-simplejson python3-numpy python-psutil-doc ttf-bitstream-vera
The following NEW packages will be installed:
at indy-anoncreds indy-node indy-plenum libleveldb1v5 libsnappy1v5 python3-base58 python3-dateutil
python3-indy-crypto python3-intervaltree python3-ioflo python3-jsonpickle python3-lazy-object-proxy python3-leveldb
python3-libnacl python3-msgpack python3-orderedset python3-portalocker python3-prompt-toolkit python3-psutil
python3-pygments python3-pyzmq python3-raet python3-rlp python3-semver python3-sha3 python3-sortedcontainers
python3-timeout-decorator python3-ujson python3-wcwidth sovrin
0 upgraded, 31 newly installed, 0 to remove and 227 not upgraded.
Need to get 6 079 kB of archives.
After this operation, 23,4 MB of additional disk space will be used.
Do you want to continue? [Y/n]

$ apt-cache show python3-indy-crypto | grep ""^Version""
Version: 0.1.6
Version: 0.1.5-5
Version: 0.1.4-4
Version: 0.1.4-3
Version: 0.1.4-2{code}

Recommendations for QA: do the following sequence of steps
 * set rc component for sovrin repo in apt sources.list
 * check available versions of python3-indy-crypto (apt-cache show python3-indy-crypto)
 * (try to) install sovrin: apt-get install sovrin

 ;;;","17/Nov/17 9:00 PM;VladimirWork;Build Info:
indy-node 1.2.44

Steps to Validate:
1. Install 1.2.44 (rc) pool.

Actual Results:
Pool is installed normally. !pool_setup.PNG|thumbnail! ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incorrect CLI validation error,INDY-951,23998,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,nage,VladimirWork,VladimirWork,17/Nov/17 9:59 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
indy-node 1.2.45

Steps to Reproduce:
1. On the client machine, make a copy of the pool_transactions_sandbox file:
cd .indy-cli/networks/sandbox
cp pool_transactions_genesis original_pool_trasnsactions_genesis
2. Delete contents of the pool_transactions_sandbox file:
cd .indy-cli/networks/sandbox
sudo vim pool_transactions_genesis
Select all and delete in vim gg then d <shift>G, then type :wq and press enter
3. Run CLI:
indy
connect sandbox

Actual Results:
{quote}Connecting to sandbox...

The information required to connect this client to the nodes cannot be found.
This is an error. To correct the error, get the file containing genesis transactions
(the file name is `pool_transactions_genesis`) from the github repository and place
it in directory `/home/agent/.indy-cli/networks`.

The github url is https://github.com/hyperledger/indy-node.

Invalid command: 'connect sandbox'

Indy-CLI, a simple command-line interface for a Indy Identity platform.
   Commands:
       help - Shows this or specific help message for given command
         Usage:
            help [<command name>]
       connect - Lets you connect to the respective environment
         Usage:
            connect sandbox|live{quote}

Expected Results:
There should be no 'invalid command' error, because the command is valid. There should be this message only:
{quote}Connecting to sandbox...

The information required to connect this client to the nodes cannot be found.
This is an error. To correct the error, get the file containing genesis transactions
(the file name is `pool_transactions_genesis`) from the github repository and place
it in directory `/home/agent/.indy-cli/networks`.

The github url is https://github.com/hyperledger/indy-node.{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzynen:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/17 9:26 PM;ozheregelya;Ticket is not actual anymore because of changing current python CLI to indy-sdk based CLI.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A client needs to be able to recieve a bunch for Replies for a batch of Requests,INDY-952,23999,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Won't Do,,ashcherbakov,ashcherbakov,17/Nov/17 10:19 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"If client sends a batch of Requests, it would be nice to receive a a batch of Replies for it.",,,,,,,,,,,,,,,,,,,,,,,IS-432,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzwzbj:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/18 7:21 AM;esplinr;We'll reopen this story if we get more requests.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The last pool node is failed to upgrade during pool upgrade,INDY-953,24001,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,VladimirWork,VladimirWork,17/Nov/17 11:24 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
indy-node 1.2.45

Steps to Reproduce:
1. Install 1.1.43 pool.
2. Schedule upgrade:
bq. send POOL_UPGRADE name=upgrade_to_the_latest_full version=1.2.45 sha256=ed0a366b4ef36d40c055672a8b83679e99246fec71a706b4ae4cb7958feace3f action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-11-17T13:47:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-11-17T13:52:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-11-17T13:57:00.258870+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-11-17T14:02:00.258870+00:00'} timeout=10 force=False reinstall=False
3. Check the 4th node after its upgrade time.

Actual Results:
The 4th node upgrade doesn't start. Upgrade_log has wrong ""cancelled"" and ""scheduled"" entries (they are written with each node upgrade).

Expected Results:
The whole pool should upgrade normally.

Workaround:
Restart the 4th node manually to trigger scheduled upgrade.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Nov/17 11:22 PM;VladimirWork;_1.PNG;https://jira.hyperledger.org/secure/attachment/13357/_1.PNG","17/Nov/17 11:38 PM;VladimirWork;_1st_node_config_ledger.txt;https://jira.hyperledger.org/secure/attachment/13358/_1st_node_config_ledger.txt","17/Nov/17 11:23 PM;VladimirWork;_2.PNG;https://jira.hyperledger.org/secure/attachment/13356/_2.PNG","17/Nov/17 11:38 PM;VladimirWork;_2nd_node_config_ledger.txt;https://jira.hyperledger.org/secure/attachment/13359/_2nd_node_config_ledger.txt","17/Nov/17 11:38 PM;VladimirWork;_3rd_node_config_ledger.txt;https://jira.hyperledger.org/secure/attachment/13360/_3rd_node_config_ledger.txt","17/Nov/17 11:23 PM;VladimirWork;_4th_node_config_ledger.txt;https://jira.hyperledger.org/secure/attachment/13351/_4th_node_config_ledger.txt","17/Nov/17 11:23 PM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/13355/_node1.txt","17/Nov/17 11:23 PM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/13354/_node2.txt","17/Nov/17 11:23 PM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/13353/_node3.txt","17/Nov/17 11:23 PM;VladimirWork;_node4.txt;https://jira.hyperledger.org/secure/attachment/13352/_node4.txt","17/Nov/17 11:38 PM;VladimirWork;all_upgrade_logs.PNG;https://jira.hyperledger.org/secure/attachment/13361/all_upgrade_logs.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0lz:",,,,,,INDY 17.23,,,,,,,,,,,,,,,,,,,,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Nov/17 5:10 PM;ashcherbakov;*Problems*
There were multiple issues related to Upgrade:
1) Upgrade on Node4 didn't happen because the Node crashed once it gets NODE_UPGRADE request from other Nodes that already upgraded.
Once Upgraded, other Nodes start using protocol version with all requests. Node 4 doesn't understand it before Upgrade and crashes.
2) There is a number of view changes during Upgrade (because Primary gets upgraded). 
This caused cancel-schedule entry in Upgrade log for each Upgrade.
3) View changes also caused multiple SUCCESS NODE_UPGRADE txns.

*Changes*
1) Fixed by not sending protocol version for NODE_UPGRADE txns
2) Fixed by checking if we've already scheduled the same Upgrade (no need to cancel-reschedule it)
3) Fixed by changing the logic of how we decide that NODE_UPGRADE txn needs to be sent (have a flag based on Started Upgrade log event; see INDY-799)

*PR*:
- to stable: https://github.com/hyperledger/indy-node/pull/460 (as a hotfix)

*New tests*:
- test_node_upgrade_unsuccessful.py
- test_node_upgrade_rescheduled_view_change.py
- test_node_upgrade_no_protocol_version.py
- test_node_upgrade_in_progress_no_protocol_version.py
- test_node_upgrade_in_progress.py
- test_node_upgrade.py

*Builds*:
- rc: 1.2.46
- master: 1.2.214;;;","21/Nov/17 2:01 AM;VladimirWork;Build Info:
indy-node 1.2.46

Steps to Reproduce:
1. Install 1.2.46 pool.
2. Schedule upgrade:
send POOL_UPGRADE name=upgrade_to_the_latest_full version=1.2.46 sha256=ed0a366b4ef36d40c055672a8b83679e99246fec71a706b4ae4cb7958feace3f action=start schedule={'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv': '2017-11-17T13:47:00.258870+00:00', '8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb': '2017-11-17T13:52:00.258870+00:00', 'DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya': '2017-11-17T13:57:00.258870+00:00', '4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA': '2017-11-17T14:02:00.258870+00:00'} timeout=10 force=False reinstall=False
3. Check the 4th node after its upgrade time.

Actual Results:
Pool is upgraded normally.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unclear messages in CLI during GST run,INDY-954,24028,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,20/Nov/17 9:10 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Build Info:
indy-node 1.2.45

Steps to Validate:
1. Install pool of 4 nodes and 4 clients for this pool.
2. Run agents on 2-4 clients.
3. Run through GST (steps with wallet moving can be skipped) https://docs.google.com/document/d/1j9R0J6sur9CKO4O6MYD0tY6Ui8uORHE0mIrbzyqDras/edit#

Actual Results:
There are unclear messages in CLI during the next commands execution:
show claim Transcript
request claim Transcript
show claim Job-Certificate
request claim Job-Certificate

{quote}b'\xc9\x92\x16\xdb\xb4\xe8\xb0\x98\xa2\xc8\x1f\xe8\xcd~\x9f\x1e\x1e\x1d\xfd|\x92\xe3\x16\xdf@\xdcSq\xa08a`'
b'\xc9\x92\x16\xdb\xb4\xe8\xb0\x98\xa2\xc8\x1f\xe8\xcd~\x9f\x1e\x1e\x1d\xfd|\x92\xe3\x16\xdf@\xdcSq\xa08a`'
b'\xc9\x92\x16\xdb\xb4\xe8\xb0\x98\xa2\xc8\x1f\xe8\xcd~\x9f\x1e\x1e\x1d\xfd|\x92\xe3\x16\xdf@\xdcSq\xa08a`'
b'\xc9\x92\x16\xdb\xb4\xe8\xb0\x98\xa2\xc8\x1f\xe8\xcd~\x9f\x1e\x1e\x1d\xfd|\x92\xe3\x16\xdf@\xdcSq\xa08a`'
b'\xc9\x92\x16\xdb\xb4\xe8\xb0\x98\xa2\xc8\x1f\xe8\xcd~\x9f\x1e\x1e\x1d\xfd|\x92\xe3\x16\xdf@\xdcSq\xa08a`' {quote}

Expected Results:
There should be no unclear messages.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Nov/17 9:10 PM;VladimirWork;acme_claim_messages.PNG;https://jira.hyperledger.org/secure/attachment/13366/acme_claim_messages.PNG","20/Nov/17 9:10 PM;VladimirWork;faber_claim_messages.PNG;https://jira.hyperledger.org/secure/attachment/13367/faber_claim_messages.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0lj:",,,,,,INDY 17.23,,,,,,,,,,,,,,,,,,,,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Nov/17 11:10 PM;ashcherbakov;*Problem reason*
Wrongs IDs were used for GET_SCHEMA and GET_CLAIM_DEF requests when verifying the state proof on the client side. So, when submitter (who sent SCHEMA) and reader (who sent GET_SCHEMA) differ, state proof was wrong.
Everything worked since we fall back to f+1 consensus.

*Fix*
Use correct IDs of submitter (""origin"" for CLAIM_DEF and ""dest"" for SCHEMA)

*PR*:
- to master: https://github.com/hyperledger/indy-node/pull/463
- to stable: https://github.com/hyperledger/indy-node/pull/462

*Tests*:
- test_state_proof_for_get_requests.py

*Build*:
- rc: 1.2.47
- master: 1.2.215
;;;","21/Nov/17 2:02 AM;VladimirWork;Build Info:
indy-node 1.2.47

Steps to Validate:
1. Install pool of 4 nodes and 4 clients for this pool.
2. Run agents on 2-4 clients.
3. Run through GST (steps with wallet moving can be skipped) https://docs.google.com/document/d/1j9R0J6sur9CKO4O6MYD0tY6Ui8uORHE0mIrbzyqDras/edit#

Actual Results:
There are no unclear or unexpected messages during the GST run.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Adding transaction to the ledger must be an atomic operation,INDY-955,24038,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Deferred,,ashcherbakov,ashcherbakov,21/Nov/17 1:33 AM,29/Oct/19 11:28 PM,28/Oct/23 2:47 AM,29/Oct/19 11:28 PM,,,,,0,,,,,,"Currently adding of a txn to the ledger consists of two steps:
- add txn to transaction log
- add txn to the tree (hash store).

It's possible (see, for example, INDY-893), that Node may stop/crash in between. So, we may have a bit inconsistent data. 

We will be able to recover the ledger (merkle tree) from txn log in any case, so this is not so critical from recover point of view.
It may be more critical if something wrong happens in between without crashing, so that will continue working with inconsistency between txn log and the tree.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-785,,,,,,,,,,"1|hzwyn3:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,esplinr,sergey.khoroshavin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Apr/19 12:15 AM;sergey.khoroshavin;It might have sense to do the following:
* commit audit ledger the last
* after starting up check ledgers and states and rollback them to match last audit transaction

That way atomicity between ledgers can be achieved even in case of hard crashes.

;;;","29/Oct/19 11:28 PM;esplinr;This would be a great feature to have, but we don't see it as a priority because our consensus protects us from incomplete ledger writes. We will close this as deferred, but if someone were to submit a pull request along the lines of Sergey's suggestion, we would be glad to accept it.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Redundant CLI messages,INDY-956,24400,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Invalid,nage,VladimirWork,VladimirWork,21/Nov/17 11:19 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
indy-node 1.2.47

Steps to Reproduce:
1. Install pool of 4 nodes.
2. Add two nodes to this pool.
3. Run CLI for this pool.

Actual Results:
There are a bunch of redundant diagnostic messages during waiting for all nodes connecting.

Expected Results:
There should be less messages (initial one and one or two more as 5th and 6th nodes are connecting).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Nov/17 11:18 PM;VladimirWork;redundant_CLI_messages.PNG;https://jira.hyperledger.org/secure/attachment/13400/redundant_CLI_messages.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-985,,,,,,,,,,"1|hzwyqn:",,,,,,,,,,,,,,,,,,,,,,,,,,ozheregelya,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/18 2:30 AM;ozheregelya;This ticket is not actual for indy-cli because indy-cli doesn't show messages about nodes connections.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Script add_keys.py doesn't work,INDY-957,24403,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,VladimirWork,VladimirWork,21/Nov/17 11:52 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"Build Info:
indy-node 1.2.47

Steps to Reproduce:
0. Install pool.
1. Put the next files to /home/indy/.indy-cli:
bq. load_test_clients.list
bq. add_keys.py
bq. load_test.py
2. Run `python3 add_keys.py Steward1 000000000000000000000000Steward1` as indy user.

Actual Results:
{quote}Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 801, in loadPubKeyFromDisk
    public, _ = zmq.auth.load_certificate(filePath)
  File ""/usr/local/lib/python3.5/dist-packages/zmq/auth/certs.py"", line 91, in load_certificate
    raise IOError(""Invalid certificate file: {0}"".format(filename))
OSError: Invalid certificate file: keys/DQqKjyWe4nrVFiovaYTfqxJDAUUuUXv8fhLXoB6PRKAu/public_keys/Node4C.key

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 830, in getPublicKey
    return self.loadPubKeyFromDisk(self.publicKeysDir, name)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 804, in loadPubKeyFromDisk
    raise KeyError from ex
KeyError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""add_keys.py"", line 149, in <module>
    addNyms()
  File ""add_keys.py"", line 112, in addNyms
    looper.add(client)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 164, in add
    prodable.start(self.loop)
  File ""/usr/local/lib/python3.5/dist-packages/indy_client/client/client.py"", line 194, in start
    super().start(loop)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 259, in start
    self.nodestack.maintainConnections(force=True)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/kit_zstack.py"", line 47, in maintainConnections
    missing = self.connectToMissing()
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/kit_zstack.py"", line 101, in connectToMissing
    self.connect(name, ha=self.registry[name])
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 570, in connect
    publicKeyRaw) if publicKeyRaw else self.getPublicKey(name)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 832, in getPublicKey
    raise PublicKeyNotFoundOnDisk(self.name, name)
stp_core.network.exceptions.PublicKeyNotFoundOnDisk: DQqKjyWe4nrVFiovaYTfqxJDAUUuUXv8fhLXoB6PRKAu could not get Node4C's public key from disk. Make sure the keys are initialized for this remote or provided explicitly.
{quote}

Expected Results:
Scripts add_keys.py and load_test.py should work normally.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0lr:",,,,,,INDY 17.23,,,,,,,,,,,,,,,,,,,,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Nov/17 8:28 PM;VladimirWork;Build Info:
indy-node 1.2.49

Steps to Validate:
1. Install pool.
2. Place load test files anywhere.
3. Run `python3 add_keys.py Steward1 000000000000000000000000Steward1` as indy user.
4. Run `python3 load_test.py -c 10 -r 1000` as indy user.

Actual Results:
Keys are added and load test runs normally.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pool is unable to write NYMs after BLS keys enabling,INDY-958,24413,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,VladimirWork,VladimirWork,22/Nov/17 12:42 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
indy-node 1.2.47

Steps to Reproduce:
1. Install 1.1.43 version pool.
2. Perform upgrade with force=False to 1.2.47 version.
3. Run enable_bls script as indy user from all nodes, e.g.:
bq. enable_bls --name=Node1 --node_dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv --steward_seed=000000000000000000000000Steward1 --bls_seed=000000000000000000000000Steward1
bq. enable_bls --name=Node2 --node_dest=8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb --steward_seed=000000000000000000000000Steward2 --bls_seed=000000000000000000000000Steward2
bq. enable_bls --name=Node3 --node_dest=DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya --steward_seed=000000000000000000000000Steward3 --bls_seed=000000000000000000000000Steward3
bq. enable_bls --name=Node4 --node_dest=4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA --steward_seed=000000000000000000000000Steward4 --bls_seed=000000000000000000000000Steward4
4. Check /var/lib/indy/sandbox/keys/NodeX/bls_keys.
5. Check logs for ""bls"" entries.
6. Send and get some NYMs (it works).
7. Restart all nodes.
8. Check logs for ""bls"" entries.
9. Send and get some NYMs (NYMs adding doesn't work).

Actual Results:
There is an error in Step 3:
{quote}Traceback (most recent call last):
  File ""/usr/local/bin/enable_bls"", line 115, in <module>
    send_node_txn(node_name, bls_key, steward_seed, node_dest)
  File ""/usr/local/bin/enable_bls"", line 54, in send_node_txn
    client = Client(name, ha=ha)
  File ""/usr/local/lib/python3.5/dist-packages/indy_client/client/client.py"", line 51, in __init__
    sighex)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/client/client.py"", line 151, in __init__
    sighex)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/common/stacks.py"", line 73, in __init__
    seed=seed, sighex=sighex, config=config)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/kit_zstack.py"", line 29, in __init__
    msgRejectHandler=msgRejectHandler)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/simple_zstack.py"", line 39, in __init__
    msgRejectHandler=msgRejectHandler)
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 81, in __init__
    self.setupDirs()
  File ""/usr/local/lib/python3.5/dist-packages/stp_zmq/zstack.py"", line 263, in setupDirs
    os.makedirs(d, exist_ok=True)
  File ""/usr/lib/python3.5/os.py"", line 231, in makedirs
    makedirs(head, mode, exist_ok)
  File ""/usr/lib/python3.5/os.py"", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: 'keys'{quote}

BLS keys looks like added (Step 4) but not enabled (Step 5). Nodes restarting activates BLS on nodes (Step 8) but pool can read NYMs only after that (Step 9).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Nov/17 12:42 AM;VladimirWork;Step_3.PNG;https://jira.hyperledger.org/secure/attachment/13402/Step_3.PNG","22/Nov/17 12:42 AM;VladimirWork;Step_9.PNG;https://jira.hyperledger.org/secure/attachment/13401/Step_9.PNG","22/Nov/17 12:46 AM;VladimirWork;_node1.txt;https://jira.hyperledger.org/secure/attachment/13403/_node1.txt","22/Nov/17 12:46 AM;VladimirWork;_node2.txt;https://jira.hyperledger.org/secure/attachment/13404/_node2.txt","22/Nov/17 12:47 AM;VladimirWork;_node3.txt;https://jira.hyperledger.org/secure/attachment/13405/_node3.txt","22/Nov/17 12:47 AM;VladimirWork;_node4.txt;https://jira.hyperledger.org/secure/attachment/13406/_node4.txt","23/Nov/17 1:00 AM;VladimirWork;state_proof_from 1_node_of_4.PNG;https://jira.hyperledger.org/secure/attachment/13411/state_proof_from+1_node_of_4.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0l3:",,,,,,INDY 17.23,,,,,,,,,,,,,,,,,,,,ashcherbakov,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Nov/17 1:28 AM;ashcherbakov;A fix from INDY-957 should fix this issue as well;;;","22/Nov/17 4:45 PM;VladimirWork;Build Info:
indy-node 1.2.48

Actual Results:
{quote}indy@ea4f68f1bc2b:/usr/local/bin$ enable_bls --name=Node1 --node_dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv --steward_seed=000000000000000000000000Steward1 --bls_seed=000000000000000000000000Steward1
Loading module /usr/local/lib/python3.5/dist-packages/config/config-crypto-example1.py
Module loaded.
BLS Public key is 3474sSZkgn6rjCdEwSB6BFBLT2HPNxgL8kqrPJ8xD73T3Z5Grc3uxMmjhwDhmszH89cGzGEc6depRWjQUdMnBGC7Qfza1aiygdACR27KKk3BB2oco7wV8dziBYLS4fnU61ncPisop9BGGzN4SEWpQbDZSkSasKFDuFvMLmg9MosVi8f
2017-11-22 07:34:11,574 | INFO     | client.py            (240) | setPoolParams | steward_wallet updated its pool parameters: f 0, totalNodes 0,minNodesToConnect 1, quorums {'propagate_primary': Quorum(1), 'consistency_proof': Quorum(1), 'checkpoint': Quorum(0), 'reply': Quorum(1), 'f': 0, 'commit': Quorum(0), 'election': Quorum(0), 'same_consistency_proof': Quorum(1), 'ledger_status': Quorum(-1), 'bls_signatures': Quorum(0), 'propagate': Quorum(1), 'view_change': Quorum(0), 'prepare': Quorum(-1), 'timestamp': Quorum(1), 'view_change_done': Quorum(0)}
2017-11-22 07:34:11,575 | INFO     | zstack.py            (274) | setupOwnKeysIfNeeded | Signing and Encryption keys were not found for Huk6bywPBKdCKe4fgVGTDdkbbEWC39Dz4eAKxw5jRRd1. Creating them now
2017-11-22 07:34:11,577 | INFO     | client.py            (167) | __init__ | Client steward_wallet found an empty node registry:
2017-11-22 07:34:11,579 | INFO     | stacks.py            (84) | start | CONNECTION: Huk6bywPBKdCKe4fgVGTDdkbbEWC39Dz4eAKxw5jRRd1 listening for other nodes at 0.0.0.0:6001
>>>>>>>>>>> Updating NYM with BLS keys...
>>>>>>>>>>>> Sent Request: {'protocolVersion': 1, 'signature': 'rWgeikuDqoHf9YEqwTFTBnpiJ6LFqwzvkhzSGLYjVFrvEsmYHDurEXo8725SeVUrZqjiy7XPyCQFeqcRxgUi6hL', 'reqId': 1511336051580498, 'operation': {'type': '0', 'dest': 'Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv', 'data': {'blskey': '3474sSZkgn6rjCdEwSB6BFBLT2HPNxgL8kqrPJ8xD73T3Z5Grc3uxMmjhwDhmszH89cGzGEc6depRWjQUdMnBGC7Qfza1aiygdACR27KKk3BB2oco7wV8dziBYLS4fnU61ncPisop9BGGzN4SEWpQbDZSkSasKFDuFvMLmg9MosVi8f', 'alias': 'Node1'}}, 'identifier': 'Th7MpTaRZVRYnPiabds81Y'}
2017-11-22 07:34:31,603 | ERROR    | eventually.py        (182) | eventually | _ensureReqCompleted failed; not trying any more because 20 seconds have passed; args were (('Th7MpTaRZVRYnPiabds81Y', 1511336051580498), Huk6bywPBKdCKe4fgVGTDdkbbEWC39Dz4eAKxw5jRRd1)
2017-11-22 07:34:31,603 | ERROR    | looper.py            (249) | wrapper | Error while running coroutine eventually: NoConsensusYet('not completed',)
2017-11-22 07:34:31,603 | INFO     | looper.py            (272) | shutdown | Looper shutting down now...
2017-11-22 07:34:31,612 | INFO     | zstack.py            (327) | stop | stack Huk6bywPBKdCKe4fgVGTDdkbbEWC39Dz4eAKxw5jRRd1 closing its listener
2017-11-22 07:34:31,613 | INFO     | zstack.py            (331) | stop | stack Huk6bywPBKdCKe4fgVGTDdkbbEWC39Dz4eAKxw5jRRd1 stopped
2017-11-22 07:34:31,613 | INFO     | looper.py            (279) | shutdown | Looper shut down in 0.010 seconds.
Traceback (most recent call last):
  File ""/usr/local/bin/enable_bls"", line 72, in send_node_txn
    timeout=20, retryWait=2))
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 259, in run
    return self.loop.run_until_complete(what)
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
    return future.result()
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
    raise self._exception
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
    result = coro.send(None)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 250, in wrapper
    raise ex
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 237, in wrapper
    results.append(await coro)
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/eventually.py"", line 183, in eventually
    raise ex
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/eventually.py"", line 156, in eventually
    res = coroFunc(*args)
  File ""/usr/local/bin/enable_bls"", line 106, in _ensureReqCompleted
    raise NoConsensusYet('not completed')
plenum.common.exceptions.NoConsensusYet: not completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/bin/enable_bls"", line 115, in <module>
    send_node_txn(node_name, bls_key, steward_seed, node_dest)
  File ""/usr/local/bin/enable_bls"", line 75, in send_node_txn
    raise TimeoutError('Request timed out')
TimeoutError: Request timed out{quote};;;","22/Nov/17 10:01 PM;ashcherbakov;Fixed in RC 1.2.49;;;","23/Nov/17 1:00 AM;VladimirWork;Build Info:
indy-node 1.2.49

Steps to Validate:
1. Install 1.1.43 version pool.
2. Perform upgrade with force=False to 1.2.49 version.
3. Run enable_bls script as indy user from all nodes, e.g.:
bq. enable_bls --name=Node1 --node_dest=Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv --steward_seed=000000000000000000000000Steward1 --bls_seed=000000000000000000000000Steward1
bq. enable_bls --name=Node2 --node_dest=8ECVSk179mjsjKRLWiQtssMLgp6EPhWXtaYyStWPSGAb --steward_seed=000000000000000000000000Steward2 --bls_seed=000000000000000000000000Steward2
bq. enable_bls --name=Node3 --node_dest=DKVxG2fXXTU8yT5N7hGEbXB3dfdAnYv1JczDUHpmDxya --steward_seed=000000000000000000000000Steward3 --bls_seed=000000000000000000000000Steward3
bq. enable_bls --name=Node4 --node_dest=4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA --steward_seed=000000000000000000000000Steward4 --bls_seed=000000000000000000000000Steward4
4. Check /var/lib/indy/sandbox/keys/NodeX/bls_keys.
5. Check logs for ""BLS"" entries.
6. Send and get some NYMs.

Actual Results:
BLS keys are activated normally and works. !state_proof_from 1_node_of_4.PNG|thumbnail!  NYMs are sent and got.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validator node is re-promoted during view change,INDY-959,24429,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,mgbailey,mgbailey,22/Nov/17 6:56 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"On the STN network, a trustee demoted a validator node in the ledger in preparation of moving the validator from the STN onto the live network.  A few hours later it was noticed that the validator was once again connecting to the STN.  A new, apparently un-initiated transaction is now on the ledger, which appeared on the ledger during a view change.

Here is the timeline:

17:07 Trustee posts a transaction to ledger demoting 'esatus'

19:23 View change occurs, seemingly re-writing the 'esatus' node data to the ledger

19:23 'esatus' reconnects

One node has low-level logs available, which are attached. Logs on all other nodes look similar, so a representative is attached.  Logs from the esatus validator will also be attached, when we get them.

The pool ledger is attached.","STN network, running 1.1.43.",,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1061,INDY-1045,INDY-1121,,,,,,"23/Nov/17 1:02 AM;mgbailey;esatus_log.tgz;https://jira.hyperledger.org/secure/attachment/13415/esatus_log.tgz","23/Nov/17 1:02 AM;mgbailey;esatus_log_new.tgz;https://jira.hyperledger.org/secure/attachment/13414/esatus_log_new.tgz","22/Nov/17 6:24 AM;mgbailey;ledger_autopromote_STN.txt;https://jira.hyperledger.org/secure/attachment/13408/ledger_autopromote_STN.txt","22/Nov/17 6:13 AM;mgbailey;logs_autopromote_STN.tgz;https://jira.hyperledger.org/secure/attachment/13409/logs_autopromote_STN.tgz","22/Nov/17 6:55 AM;mgbailey;low_level_logs.tgz;https://jira.hyperledger.org/secure/attachment/13407/low_level_logs.tgz",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzypun:",,,,,,INDY 17.25,INDY 18.01: Stability+,,,,,,,,,,,,,,,,,,,mgbailey,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Nov/17 7:33 AM;mgbailey;The reqId of the transaction that was posted during the view change is identical to the one that was posted when the validator was originally added to the ledger weeks ago.;;;","23/Nov/17 1:02 AM;mgbailey;adding logs from the esatus node;;;","22/Dec/17 12:54 AM;spivachuk;[~mgbailey], could you please provide the logs from the nodes ""canada"" and ""england"" for 11/20/2017 if they are available?;;;","22/Dec/17 1:35 AM;mgbailey;[~spivachuk] The logs of these nodes go back only 2 days because they are quickly filling with repeated messages and are rolling.  The messages are: 
{code:java}
2017-12-21 15:01:05,485 | WARNING | replica.py ( 983) | __is_next_pre_prepare | england:0 missing PRE-PREPAREs between 4 and 0
2017-12-21 15:01:05,511 | WARNING | replica.py ( 983) | __is_next_pre_prepare | england:0 missing PRE-PREPAREs between 4 and 0
2017-12-21 15:01:05,523 | WARNING | replica.py ( 983) | __is_next_pre_prepare | england:0 missing PRE-PREPAREs between 4 and 0
2017-12-21 15:01:05,536 | WARNING | replica.py ( 983) | __is_next_pre_prepare | england:0 missing PRE-PREPAREs between 4 and 0
...{code};;;","22/Dec/17 3:04 AM;spivachuk;Thank you, [~mgbailey]. Could you please check also if ""singapore"" log for 11/20/2017 is available and attach it if so?;;;","22/Dec/17 3:59 AM;mgbailey;[~spivachuk], although we have about 12 days of logs on Singapore, it also is rolling logs more quickly than might be expected due to repeated log messages.  I am concerned about the health of this network, which is our most active long-lived network.  Here are the log messages I am seeing repeated:
{code:java}
2017-12-21 10:45:08,833 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'0@75wWXu$y-:}@dG*&HtG!H4kuYXW/&MPgUBV8%7' has been removed
2017-12-21 10:45:16,110 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'BEhc!q7/{^9)vgy&p$f!kx.sTfa9gxeT9(BqKVil' has been removed
2017-12-21 10:45:23,544 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'0@75wWXu$y-:}@dG*&HtG!H4kuYXW/&MPgUBV8%7' has been removed
2017-12-21 10:45:30,841 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'BEhc!q7/{^9)vgy&p$f!kx.sTfa9gxeT9(BqKVil' has been removed
2017-12-21 10:45:38,861 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'0@75wWXu$y-:}@dG*&HtG!H4kuYXW/&MPgUBV8%7' has been removed
2017-12-21 10:45:46,139 | WARNING | batched.py ( 123) | flushOutBoxes | CONNECTION: singapore rid b'BEhc!q7/{^9)vgy&p$f!kx.sTfa9gxeT9(BqKVil' has been removed
...{code};;;","27/Dec/17 3:04 AM;spivachuk;*Problem reason:*
 As we can see in the attached logs, the scenario was as follows:
 # In the backup instance 3 its primary replica {{singapore:3}} sent PREPREPARE with one client request that was already ordered earlier to all the other replicas in the instance _(this request was {{send NODE services=[VALIDATOR]}} for {{esatus}})_.
 # The nodes containing these other replicas sent MESSAGE_REQUEST for PROPAGATE of this client request to all the others.
 # {{singapore}} responded to each received MESSAGE_REQUEST by MESSAGE_RESPONSE with the requested PROPAGATE.
 # Having seen the client request as if for the first time, the rest of the nodes sent the PROPAGATE to all the others (but actually the nodes just didn't detect that this old already processed request was received earlier).
 # All the nodes reached quorum for PROPAGATE. 3PC-process for the request proceeded in the instance 3 and also started in in all the other instances (0, 1, 2).
 # Eventually the client request was ordered for the second time.

We were not able to detect the initial cause of why {{singapore:3}} initiated 3PC-process for the old already processed request because logs were available for some nodes only (for {{singapore}} - not available) and a DEBUG/TRACE log was available for one node only ({{korea}}). Most likely, the node {{singapore}} took the request from some queue of postponed messages where it was stashed previously and was not removed later after the request had been ordered in scope of some 3PC-batch. Possibly the issue was fixed in master branch in scope of one of recently resolved bug tickets.

However, another issue was also revealed - the nodes didn't detect that the received PROPAGATE contained a request received earlier. This issue was caused by a lack in {{Node.processPropagate}} method of a check of the request presence in {{seqNoDB}}. This resulted in the following behavior: if some repeated or belated request or PROPAGATE was received when the request had already been processed and later removed from {{Propagator.requests}} dictionary (for example, on a view change) then the request was processed again. In our case this issue made it possible for the nodes in the pool to order once again the already ordered request {{send NODE services=[VALIDATOR]}} for {{esatus}}. So the node {{esatus}} was promoted.

*Changes:*
 - Fixed a bug with a lack of a check of the request presence in {{seqNoDB}} on processing of the belated PROPAGATE message.
 - Added tests for processing of repeated requests, belated requests and belated PROPAGATE messages received at different moments (during 3PC-process, after the request has been ordered, after the request has been ordered and a view change has occurred).
 - Corrected {{sdk_send_and_check}} and {{sdk_send_random_and_check}} functions. Now they ensure that each passed request gets a confirmed reply.

*PRs:*
 - [https://github.com/hyperledger/indy-plenum/pull/492]
 - [https://github.com/hyperledger/indy-plenum/pull/493]
 - [https://github.com/hyperledger/indy-node/pull/507]

*Version:*
 - indy-node 1.2.252 master
 - indy-plenum 1.2.212 master

*Risk factors:*
 - Nothing is expected.

*Risk:*
 - Low

*Covered with tests:*
 - {{test_belated_propagate_not_processed_after_view_change}};;;","29/Dec/17 12:47 AM;VladimirWork;Build Info:
indy-node 1.2.253

Steps to Validate:
1. Demote new added to the pool nodes.
2. Force view changes by primary nodes restarting.
3. Demote nodes that were demoted and promoted back earlier.
4. Force view changes by primary nodes restarting.
5. Check logs of all nodes for `propagate` messages.

Actual Results:
Issue with spontaneously promoted back node is not reproducing.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node is broken after load_test.py run,INDY-960,24436,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,VladimirWork,VladimirWork,23/Nov/17 2:01 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,Must,,,,,"Build Info:
indy-node 1.2.49

Steps to Reproduce:
1. Install pool of 4 nodes.
2. Place load test files to /home/indy at any node (e.g. Node 1).
3. Run `python3 add_keys.py Steward1 000000000000000000000000Steward1`.
4. Run `python3 load_test.py -c 10 -r 1000` as indy user (works).
5. Run `python3 load_test.py -c 20 -r 2000` as indy user (doesn't work).

Actual Results:
It's unable to run Step 4 because script can't connect to node where we run load scripts (raise Exception(""Not connected fully""). Restarting of this node doesn't help. There is a message in node log about ""found node state empty .. try to recreate ledger"".

`read_ledger --type=domain --count` returns the next:
{quote}ERROR:stp_core.common.log:/var/lib/indy/sandbox/data/nodes/Node1-read-copy/domain_merkleNodes does not have position 9842
Traceback (most recent call last):
  File ""/usr/local/bin/read_ledger"", line 164, in <module>
    ledger = get_ledger(args.type, read_copy_ledger_data_dir)
  File ""/usr/local/bin/read_ledger"", line 98, in get_ledger
    return Ledger(CompactMerkleTree(hashStore=hash_store), dataDir=ledger_data_dir, fileName=ledger_name)
  File ""/usr/local/lib/python3.5/dist-packages/plenum/common/ledger.py"", line 14, in __init__
    super().__init__(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 55, in __init__
    self.recoverTree()
  File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 73, in recoverTree
    self.recoverTreeFromHashStore()
  File ""/usr/local/lib/python3.5/dist-packages/ledger/ledger.py"", line 99, in recoverTreeFromHashStore
    treeSize + 1)))
  File ""/usr/local/lib/python3.5/dist-packages/ledger/compact_merkle_tree.py"", line 220, in inclusion_proof
    for a, b in self._path(start, 0, end)]
  File ""/usr/local/lib/python3.5/dist-packages/ledger/compact_merkle_tree.py"", line 220, in <listcomp>
    for a, b in self._path(start, 0, end)]
  File ""/usr/local/lib/python3.5/dist-packages/ledger/compact_merkle_tree.py"", line 211, in merkle_tree_hash
    foldedHash = self.__hasher._hash_fold(hashes[::-1])
  File ""/usr/local/lib/python3.5/dist-packages/ledger/tree_hasher.py"", line 77, in _hash_fold
    accum = self.hash_children(cur, accum)
  File ""/usr/local/lib/python3.5/dist-packages/ledger/tree_hasher.py"", line 29, in hash_children
    hasher.update(b""\x01"" + left + right)
TypeError: can't concat bytes to NoneType{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-911,INDY-893,,,,,,,"23/Nov/17 2:01 AM;VladimirWork;Node1.log;https://jira.hyperledger.org/secure/attachment/13418/Node1.log","23/Nov/17 2:01 AM;VladimirWork;Node1_journalctl.txt;https://jira.hyperledger.org/secure/attachment/13416/Node1_journalctl.txt","23/Nov/17 2:01 AM;VladimirWork;Node2.log;https://jira.hyperledger.org/secure/attachment/13417/Node2.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzypy7:",,,,,,INDY 17.24: Node Perf,INDY 17.25,,,,,,,,,,,,,,,,,,,spivachuk,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Dec/17 1:04 AM;spivachuk;Problem state / reason:
- The issue with recovering Merkle tree was fixed in scope of INDY-893.
- The issue with warnings about that a node is trying to commit a batch with a particular state root but no uncommitted found was caused by a missed call of {{Node.onBatchCreated}} method on re-applying a batch prior to ordering before ledgers synchronization in case the batch was rejected previously due to catch-up start. This resulted in absence of the batch in {{IdrCache.uncommitted}} list when the batch was being ordered by the node.
- The issue with warnings about {{IndexError}} was revealed by the previous one and caused by a missed {{return}} statement in {{IdrCache.onBatchCommitted}} method.

Changes:
- Fixed a bug with a missed {{return}} statement in {{IdrCache.onBatchCommitted}} method.
- Fixed a bug with a missed call of {{Node.onBatchCreated}} method on re-applying a batch prior to ordering before ledgers synchronization in case the batch was rejected previously due to catch-up start.
- Wrote a test verifying that a batch rejected due to catch-up start can be successfully re-applied and ordered later before ledgers synchronization without any warnings.

Committed into:
- https://github.com/hyperledger/indy-plenum/pull/474
- https://github.com/hyperledger/indy-node/pull/474
- https://github.com/hyperledger/indy-node/pull/481
- indy-plenum 1.2.193 master
- indy-node 1.2.229 master

Risk factors:
- Nothing is expected.

Risk:
- Low

Covered with tests:
- {{test_batch_rejected_on_catchup_start_can_be_ordered_before_ledgers_sync}};;;","12/Dec/17 11:00 PM;VladimirWork;Build Info:
indy-node 1.2.234

Steps to Validate:
1. Install pool of 4 nodes.
2. Place load test files to /home/indy at any node (e.g. Node 1).
3. Run `python3 add_keys.py Steward1 000000000000000000000000Steward1`.
4. Run `python3 load_test.py -c 10 -r 1000` as indy user (works).
5. Run `python3 load_test.py -c 20 -r 2000` as indy user (works).

Actual Results:
Pool works normally. Both scripts run successfully. All nodes have the same domain ledger txn count after scripts' running.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Complete RoleField validator,INDY-961,24438,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,spivachuk,spivachuk,23/Nov/17 3:19 AM,30/Nov/17 7:22 AM,28/Oct/23 2:47 AM,,,,,,0,,,,,,Currently the validator {{plenum.common.messages.fields.RoleField}} only checks the value type. In scope of this task a check must be added that the role field value is from the list of the valid role values.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-54,,,,,,,,,,"1|hzwyzb:",,,,,,,,,,,,,,,,,,,,,,,,,,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Debug logs from indy-crypto are shown in indy-node logs,INDY-962,24445,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ashcherbakov,ashcherbakov,23/Nov/17 4:34 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0xj:",,,,,,INDY 17.24: Node Perf,,,,,,,,,,,,,,,,,,,,ashcherbakov,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/17 4:35 PM;ashcherbakov;Made a fix so that only WARNING/ERROR logs from indy-crypto will be shown in indy-node logs.

PR: https://github.com/hyperledger/indy-plenum/pull/456

Build: 1.2.217;;;","29/Nov/17 1:53 AM;ozheregelya;Version Info:
indy-node 1.2.222

Steps to Validate:
1. Setup the pool of nodes or start client.
2. Look at node logs or at client output before CLI start.

Actual Results:
INFO logs from bls.py are not appear.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Publish docker images to dockerhub,INDY-963,24459,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,andkononykhin,andkononykhin,24/Nov/17 4:36 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"Need:
 * create an automated process of pushing indy's docker images to Hyperledger's dockerhub account
 * push [baseimages|https://github.com/hyperledger/indy-node/tree/master/docker-files/baseimage] to optimize docker build routine for the ones that base on them (e.g. images for ci testing)",,,,,,,,,,,,,,INDY-965,,,,,,,,,INDY-837,INDY-945,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzx0wn:",,,,,,INDY 17.24: Node Perf,,,,,,,,3.0,,,,,,,,,,,,andkononykhin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Dec/17 12:09 AM;andkononykhin;Problem reason:
 - we don't have automated logic of pushing images to dockerhub
 - we don't have docker hub repo in Hyeprledger's account that could be used to optimize our docker routine (in particular, now we need that for CI dockers)

Changes:
 - added versioning for of base docker images
 - implemented automation for pushing into docker hub
 - with the help of Hyperledger's admins created and populated with images [docker repo|https://hub.docker.com/r/hyperledger/indy-core-baseci]  in Hyperledger for indy core ci testing
 - updated indy core repos to make ci docker working with our image from the docker hub
 - wrote a [readme|https://github.com/hyperledger/indy-node/blob/master/docker-files/baseimage/README.md]

Committed into:
 - [https://github.com/hyperledger/indy-node/pull/479]
 - [https://github.com/hyperledger/indy-node/pull/478|https://github.com/hyperledger/indy-node/pull/479]
 - [https://github.com/hyperledger/indy-plenum/pull/465]
 - [https://github.com/hyperledger/indy-anoncreds/pull/115]

Risk factors:
 - Nothing is expected.

Risk:
 - Low

Covered with tests:
 - tested manually
 - also there is a [Makefile|https://github.com/hyperledger/indy-node/blob/master/ci/Makefile] to check that indy-node image (based on indy-core-baseci) is built and have enough configuration to process testing

Recommendations for QA: do the following sequence of steps
 * do *docker pull hyperledger/indy-core-baseci:0.0.1* to ensure that the base image could be pulled from docker hub
 * do *git clone [https://github.com/hyperledger/indy-node.git] && cd indy-node && make -C ci* to ensure that tests are run without any env issues
 * change version in one of *docker-files/baseimage/*.version* files and do *make -C docker-files/baseimage publish* to ensure that images are built and pushed to docker hub (actually you will stop at the docker login step and will need credentials for further routine, as an option for complete testing you can create an account in the docker hub and try publish there like that: *DOCKER_NS=<docker-username>* *make -C docker-files/baseimage* *publish*)
 * check [readme|https://github.com/hyperledger/indy-node/blob/master/docker-files/baseimage/README.md] (spell or other erros, content etc.);;;","01/Dec/17 9:48 PM;VladimirWork;Steps to Validate:
1. docker pull hyperledger/indy-core-baseci:0.0.1
2. git clone https://github.com/hyperledger/indy-node.git
3. cd indy-node
4. make -C ci
5. Check results.
6. Change version in some of docker-files/baseimage/.version* files.
7. DOCKER_NS=<docker-username> make -C docker-files/baseimage publish

Actual Results:
Environment setup, pytest run and dockerhub publsih works without errors. Readme file looks good.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[devops] Refactor debian packages build routine,INDY-964,24460,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,andkononykhin,andkononykhin,24/Nov/17 4:49 PM,09/Oct/19 6:50 PM,28/Oct/23 2:47 AM,,,,,,0,devops,,,,,"Currently all three indy core repos include very similar set of files for deb packages build. It is hard to maintain as it needs a lot of copy-paste operations. Also it is better to have a kind of base image for dockerfiles used by the process.

We need:
 * move common logic (scripts) into one place (it could be indy-node repo)
 * create base image for dockerfiles and publish it to docker hub
 * update debs build routine for all repos leaving only specific things
 * update groovy scripts used by jenkins CD jobs",,,,,,,,,,,,,,,,,,,,,,,INDY-945,INDY-580,INDY-997,,INDY-965,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzyo3j:",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make code validation dockerfiles based on indy baseimages,INDY-965,24461,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,andkononykhin,andkononykhin,24/Nov/17 5:00 PM,09/Oct/19 6:50 PM,28/Oct/23 2:47 AM,,,,,,0,devops,,,,,"Currently in indy core we have dockerfiles for code validation routine. They are exactly the same and mostly repeat the steps defined in [baseimages|https://github.com/hyperledger/indy-node/tree/master/docker-files/baseimage]

Thus it's reasonable to change the base for the them from ubuntu to our base image once we start pushing the latter to dockerhub",,,,,,,,,,,INDY-963,,,,,,,,,,,,INDY-945,INDY-964,INDY-997,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-766,,,,,,,,,,"1|hzyo3r:",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DOC: Request for release notes on Indy-node 1.2.50,INDY-966,24462,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,VladimirWork,VladimirWork,24/Nov/17 7:02 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,15/Dec/17 12:00 AM,0,Documentation,,,,,"*Version Information*
indy-node 1.2.49
indy-anoncreds 1.0.11
indy-plenum 1.2.29
sovrin 1.1.7

*Major Fixes*
INDY-759 - validator maintains pace with network, exactly 12 transactions behind
INDY-895 - Wrote a migration that eliminates the rudimentary difference between ledgers
INDY-231 - Fixed a bug with a wrong upgrade time
INDY-157 - Fixed a bug with failed node restart after canceled pool upgrade
INDY-801 - Sovrin logs are insufficient for failed upgrade
INDY-917 - Node gets wrong upgrade_log entries after restart and runs the wrong upgrade
INDY-231 - Upgrade scheduled to future date happened in current date on part of nodes 
INDY-701 - More earlier pool_upgrade was not happened when there were scheduled upgrade to future date.
INDY-932 - Validator runs instance change continually (issue found on live pool)
INDY-909 - New nodes added to existing pool are unable to participate in consensus after the upgrade
INDY-541 - Node logs repeat message ""NodeRequestSuspiciousSpike suspicious spike has been noticed""
INDY-941 - Unable to catch up agent if a validator is down
INDY-907 - Enhance catch up mechanism to let it work with large ledgers
INDY-849 - Pool can't be restored after losing consensus if at least one view change was happened
INDY-941 - Unable to catch up agent if a validator is down
INDY-958 - Pool is unable to write NYMs after BLS keys enabling
INDY-953 - The last pool node is failed to upgrade during pool upgrade
INDY-954 - State Proof creating is fixed
INDY-949 - State Proof verifying is fixed

*Changes and Additions*
INDY-670 - Signed State implementation
INDY-790 - State Proofs implementation
INDY-829 - Remove all non-Indy branding from indy-plenum repo
INDY-855 - Remove all non-Indy branding from indy-anoncreds repo
INDY-830 - Remove all non-Indy branding from indy-node repo
INDY-877 - Backward compatibility of nodes with state proofs support with old clients
INDY-880 - Supported rebranding in sovrin package
INDY-891 - Supported rebranding in Docker and Vagrant environments of sovrin-environments
INDY-831 - Support of multiple pool networks by Indy Node
INDY-832 - Support of multiple pool networks by Indy Client (CLI)
INDY-833 - Proper file folder paths for system service
INDY-927 - Client needs to be able to send read requests to one Node only
INDY-928 - Client needs to be able to make sure that we have the latest State Proof 

*Known Issues*
INDY-960 - Node is broken after load_test.py run

*Additional Info*
Mapping of all file/folder changes is here: https://docs.google.com/spreadsheets/d/1A84H8knCtn8rrTirzxta8XC1jpHBjvQiqrxquTv6bpc/edit#gid=0",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/17 4:04 PM;krw910;bls upgrade steps.odt;https://jira.hyperledger.org/secure/attachment/13704/bls+upgrade+steps.odt",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzypwn:",,,,,,INDY 17.24: Node Perf,INDY 17.25,,,,,,,1.0,,,,,,,,,,,,krw910,TechWritingWhiz,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Nov/17 8:14 AM;krw910;*Additional Notes*

*Upgrade Steps*

# Send Pool Upgrade command so all nodes upgrade

Sometime later each Steward will need to run the following command line to add their BLS Keys
# Steward should run from ""indy"" user script ""enable_bls"" (placed in /usr/local/bin):
# enable_bls --name=<node-name> --node_dest=<node-dest-as-in-node-txn> --steward_seed=<seed-used-to-create-steward-did> --bls_seed=<32 character seed-for-bls-key>


*Questions and Answers*

*+BLS Keys for State Proofs+*

*What does BLS stand for?*
Boneh-Lynn-Shacham - The BLS signature scheme is used to verify that a signer is authentic.

*How does the CLI use State Proof for confirmation?*
When the CLI requests information about a transaction is checks the BLS signatures to verify the transaction was written by nodes that are part of the validator pool. The CLI sends a request to one Node (arbitrary one). If the Reply doesn't have a State Proof, or the reply is incorrect/invalid, then CLI falls back to sending reqeusts to all Nodes and waiting for f+1 equal Replies.

*What  if not all nodes in the pool have BLS signing keys for a transaction? *
Transactions only get signed if all nodes reaching consensus can sign it (>= n-f Nodes with correct BLS signatures).

*Can the bls_seed be any 32 character seed like the Steward seed?*
Yes.

*When adding a new node to an existing pool where do I find my BLS key?*
When initializing your node using init_indy_node the output will display the keys for the node including the BLS key. It can be found in /var/lib/indy/<network_name>/keys/<node_name>/bls_keys/bls_pk file (e.g.: /var/lib/indy/sandbox/keys/Node1/bls_keys/bls_pk)

When you send the transaction to add the new node to the pool it will also contain the BLS key in the transaction shown in this example.
+Example of send node command with BLS for 5th AWS node:+
send NODE dest=4Tn3wZMNCvhSTXPcLinQDnHyj56DTLQtL61ki4jo2Loc data={'client_port': 9702, 'client_ip': '10.0.0.105', 'alias': 'Node5', 'node_ip': '10.0.0.105', 'node_port': 9701, 'services': ['VALIDATOR'], 'blskey':'2RdajPq6rCidK5gQbMzSJo1NfBMYiS3e44GxjTqZUk3RhBdtF28qEABHRo4MgHS2hwekoLWRTza9XiGEMRCompeujWpX85MPt87WdbTMysXZfb7J1ZXUEMrtE5aZahfx6p2YdhZdrArFvTmFWdojaD2V5SuvuaQL4G92anZ1yteay3R'}

*Can I use a seed when generating my BLS keys?*
For a new node when using init_indy_node if you specify a seed for this script that same seed is used to generate your BLS keys.
For existing nodes being upgraded to the new version using state proofs you would use the script enable_bls where you can specify a seed on the command line.

enable_bls --name=<node-name> --node_dest=<node-dest-as-in-node-txn> --steward_seed=<seed-used-to-create-steward-did> --bls_seed=<32 character seed-for-bls-key>


*+Multi-network and indy_config.py+*

*Where do I find the configuration file settings?*
With file and folder changes the new location for indy_config.py is in the directory location /etc/indy/. The configuration file has a new setting called ""NETWORK_NAME"" which is used to identify which network and associated genesis transaction files to use like 'sandbox' or 'live'. If adding a new node to a live pool change this setting before initializing the node.

The genesis files are now located in their own directory based off the network name ""/var/lib/indy/NETWORK_NAME"". The defaults are live, local, and sandbox. Setting the ""NETWORK_NAME"" in the indy_config.py file will determine which network is used. The default setting in the indy_config.py file is """"NETWORK_NAME=sandbox"".
;;;","29/Nov/17 7:00 AM;TechWritingWhiz;The pull request for this item is here: [https://github.com/sovrin-foundation/sovrin/pull/40]

The HTML and PDF version of this are complete as well.;;;","06/Dec/17 6:49 AM;krw910;This is done, but in the Master branch only. We need to get it into the Stable branch.;;;","12/Dec/17 12:28 AM;krw910;We are going to make a change to the steps the Stewards will have to do after upgrade. Until a decision is made this is blocked.;;;","14/Dec/17 4:04 PM;krw910;[~TechWritingWhiz] We need to change the upgrade steps in the release notes to the information in the attachment ""bls upgrade steps.odt"". We have been debating some of the steps which took a lot longer than expected. ;;;","15/Dec/17 7:21 AM;TechWritingWhiz;This has been updated within the release notes. The pull request is here: 
https://github.com/sovrin-foundation/sovrin/pull/43;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhancements to validator-info,INDY-967,24483,,Story,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,ozheregelya,mgbailey,mgbailey,28/Nov/17 6:36 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,1.6.79,validator-info,,0,help-wanted,,,,,"The validator-info diagnostic script is an excellent addition to the Indy suite.  Here are a few additional features that will enhance its usefulness:
 # In the verbose human-readable output, indicate the time (which must include the timezone) in ISO 8601 format.  For example: ""Current time:    2017-12-15T15:53:00+05:00""
# In addition to the DID and verkey, report the BLS public key
 # Indicate the nodes that are the current primaries.  In the verbose human-readable output, this can be indicated by the primary number in parenthesis after the name of the nodes that are primaries, in this fashion:

 
{code:java}
Reachable Hosts: 10/10
RFCU
australia   (1)
brazil      (0)
canada
england     (2)
korea       (3)
mapleleaf
ricFlair
singapore
virginia
{code}
For the json output, this could be done using a hash instead of a list for the nodes as shown, or by another means:
{code:java}
{
""RFCU"": null,
""australia"": 1,
""brazil"": 0,
""canada"": null,
""england"": 2,
""korea"": 3,
""mapleleaf"": null,
""ricFlair"": null,
""singapore"": null,
""virginia"": null
}
{code}",,,,,,,,,,,,,,,,,,,,,,,INDY-1174,,,,INDY-1814,INDY-1841,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzwxa6:",,,,,,EV 18.24,,,,,,,,2.0,,,,,,,,,,,,dsurnin,mgbailey,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Mar/18 1:18 AM;mgbailey;validator-info files should be owned by the indy user, not root (as it currently is);;;","30/Nov/18 2:51 AM;ozheregelya;*Environment:*
 indy-node 1.6.709
 docker pool of 4 nodes

*Reason for Reopen:*
 Primary indicator disappears after node disconnection.

*Steps to Reproduce:*
 1. Setup the pool. 
 => Node1 indicated with 0, Node2 indicated with 2.
 2. Stop services on Node2.
 => Node2 displayed as unreachable, but still indicated with 2.
 3. Wait few minutes.
 => Primary indicator disappeared from Node2.

*Actual Results:*
{code:java}
""Reachable_nodes"": 
 ['Node1', 0]
 ['Node3', None]
 ['Node4', None]
 ""Reachable_nodes_count"": 3 
 ""Read_only"": False 
 ""Suspicious_nodes"": 
 ""Total_nodes_count"": 4 
 ""Unreachable_nodes"": 
 ['Node2', None]
 ""Unreachable_nodes_count"": 1 
 ""f_value"": 1 {code}
*Expected Results:*
 Indicator should not disappear.

Additional Information:
The issue is actual for all modes of validator-info.;;;","30/Nov/18 6:13 PM;dsurnin;if node is primary for instance and it is disconnected for more than 2-3 min then whole instance is removed. if we do not have instance we cannot have primary for it, so it is expected that unreachable node is not a primary.
also it is possible that some instance has no primary during view change ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The pool state should be updated after any node BLS key changing,INDY-968,24498,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,anikitinDSR,VladimirWork,VladimirWork,28/Nov/17 6:42 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"The pool state is updated after new txn writing now (it was identified after the discussion about node BLS keys rotation) so there are some cases when we are unable to get NYM using BLS signatures:

- we change node BLS and no txns were written to ledger after that - pool state is not updated - we can verify txns signed with old keys by reaching consensus f+1 (old way) *but not using BLS*
- we change node BLS, no txns were written to ledger after that and we have *only one node online (with just rotated BLS)* - pool state is not updated - we cannot verify txns signed with old keys because the single node has new BLS and we cannot reach f+1

So we need to update the pool's signature of state straight after any node BLS key changing.",,,,,,,,,,,,,,,,,,,,,,,INDY-933,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzwyz3:",,,,,,,,,,,,,,,,,,,,,,,,,,anikitinDSR,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/18 6:53 PM;anikitinDSR;This issue need to recheck for current indy-node version;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test_large_catchup fails intermittently,INDY-969,24500,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,ashcherbakov,ashcherbakov,28/Nov/17 8:44 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,`test_large_catchup` fails intermittently on Jenkins,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Nov/17 8:44 PM;ashcherbakov;log.txt.zip;https://jira.hyperledger.org/secure/attachment/13426/log.txt.zip",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-781,,,,,,,,,,"1|hzypxr:",,,,,,INDY 17.25,,,,,,,,,,,,,,,,,,,,ashcherbakov,lovesh,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/17 8:24 PM;lovesh;This has been fixed and merged in https://github.com/hyperledger/indy-plenum/pull/467.;;;","13/Dec/17 7:48 PM;VladimirWork;Build Info:
indy-plenum 1.2.198

Steps to Validate:
1. Run test_large_catchup.py several times via pytest.
2. Run all plenum tests several times via runner.py.

Actual Results:
test_large_catchup.py runs without fails.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Refactor] Apply state machine to View Change code,INDY-970,24507,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,,ashcherbakov,ashcherbakov,29/Nov/17 12:48 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,GA-0,,,,,See https://docs.google.com/document/d/1qDfyb6ALqvf7Cwrnmk0RUmyVbM2Znd7urey-8B21j6o/edit#heading=h.myn1swcdi79r,,,,,,,,,,,INDY-1080,,,,,,,,,,,INDY-1290,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-784,,,,,,,,,,"1|hzwwgn:",,,,,,,,,,,,,,8.0,,,,,,,,,,,,ashcherbakov,esplinr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Apr/18 1:06 AM;esplinr;We decided that INDY-1290 represents a better way to meet the same goal.

If more refactoring is needed, we will create a separate issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Refactor] [Design] Apply state machine to Catchup code,INDY-971,24508,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,spivachuk,ashcherbakov,ashcherbakov,29/Nov/17 12:49 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,GA-0,,,,,"See https://docs.google.com/document/d/1qDfyb6ALqvf7Cwrnmk0RUmyVbM2Znd7urey-8B21j6o/edit#

Design State Machine refactoring for Catch-up.
Analyse existing issues with catch-up and whether refactoring can fix them.",,,,,,,,,,,,,,INDY-1301,INDY-1299,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1377,,,,,,,,,,"1|hzz613:",,,,,,Sprint 18.05,18.06,18.07 Stability & Monitoring,18.08 Stability-Monitoring,,,,,8.0,,,,,,,,,,,,ashcherbakov,spivachuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Mar/18 12:39 AM;spivachuk;In addition to introduction of a state machine to the catch-up logic, the whole node catch-up procedure must be divided into separate procedures for each of the replicas. Please see the comments to INDY-1153 for details.;;;","20/Apr/18 5:06 PM;spivachuk;During analysis of the current logic of catch-up the following issues have been found in it:
* Possible start of catch-up from an arbitrary ledger on reception of a newer {{LedgerStatus}}.
* If catch-up was triggered by reception of a newer {{LedgerStatus}} then {{Node.allLedgersCaughtUp}} is called each time when any ledger catch-up is completed, not only once when all the ledgers have been caught up.
* {{LedgerManager.mark_ledger_synced}} is called periodically on reception of each {{n-f-1}}'th not newer {{LedgerStatus}} that is not an indication of catch-up necessity while this method calls {{LedgerInfo.postCatchupCompleteClbk}} and {{Node.allLedgersCaughtUp}}.
* Execution of 3PC-batch after catch-up in case it was applied before catch-up and then reverted at catch-up start.
* Absence of removal of {{PrePrepares}} from {{Replica.stashingWhileCatchingUp}}.
* Absence of asking other nodes for {{LedgerStatuses}} on reception of a newer {{LedgerStatus}} from one node (when catch-up is not in progress).
* If catch-up is not in progress then the node ignores incoming {{ConsistencyProof}} (which may be sent in reply to {{LedgerStatus}} that was sent to a reconnected node).
* If catch-up is in progress and some ledger catch-up has not been started yet then the node does not respond older {{LedgerStatuses}} for this ledger with {{ConsistencyProofs}} until it starts catch-up of this ledger.
* Different quorums for not newer {{LedgerStatuses}} and none-proofs which actually mean the same.
* Mode.syncing is used instead of Mode.discovering.
* Wrong log message on reaching the quorum of none-proofs in {{LedgerManager.canProcessConsistencyProof}}.;;;","26/Apr/18 1:11 AM;spivachuk;The statuses of the issues found in the current logic of catch-up are as follows:
 * Possible start of catch-up from an arbitrary ledger on reception of a newer {{LedgerStatus}}. _[This catch-up trigger together with the wrong catch-up workflow can be removed from the current logic due to we have another catch-up trigger - the checkpoint-based one - for the case if a ledger lags behind from the ledgers on other nodes.]_
 * If catch-up was triggered by reception of a newer {{LedgerStatus}} then {{Node.allLedgersCaughtUp}} is called each time when any ledger catch-up is completed, not only once when all the ledgers have caught up. _[Will be eliminated if the ledger status based catch-up trigger is removed.]_
 * {{LedgerManager.mark_ledger_synced}} is called periodically on reception of each {{n-f-1}}'th not newer {{LedgerStatus}} that is not an indication of catch-up necessity while this method calls {{LedgerInfo.postCatchupCompleteClbk}} and {{Node.allLedgersCaughtUp}}. _[Will be eliminated if the ledger status based catch-up trigger is removed.]_
 * Execution of 3PC-batch after catch-up in case it was applied before catch-up and then reverted at catch-up start. _[Can be fixed in the current logic.]_
 * Absence of removal of {{PrePrepares}} from {{Replica.stashingWhileCatchingUp}}. _[Can be fixed in the current logic.]_
 * Absence of asking other nodes for {{LedgerStatuses}} on reception of a newer {{LedgerStatus}} from one node (when catch-up is not in progress). _[Will be eliminated if the ledger status based catch-up trigger is removed.]_
 * If catch-up is not in progress then the node ignores incoming {{ConsistencyProof}} (which may be sent in reply to {{LedgerStatus}} that was sent to a reconnected node). _[Will be eliminated if the ledger status based catch-up trigger is removed.]_
 * If catch-up is in progress and some ledger catch-up has not been started yet then the node does not respond older {{LedgerStatuses}} for this ledger with {{ConsistencyProofs}} until it starts catch-up of this ledger. _[Can be fixed in the current logic.]_
 * Different quorums for not newer {{LedgerStatuses}} and none-proofs which actually mean the same. _[Can be fixed in the current logic.]_
 * Mode.syncing is used instead of Mode.discovering. _[Can be fixed in the current logic.]_
 * Wrong log message on reaching the quorum of none-proofs in {{LedgerManager.canProcessConsistencyProof}}. _[Can be fixed in the current logic.]_

Created the task INDY-1297 for removing ledger status based catch-up trigger together with wrong catch-up workflow and the bug INDY-1298 for fixing the rest found issues in the current logic of catch-up.;;;","26/Apr/18 1:34 AM;spivachuk;PR with state diagrams for catch-up actors (the new catch-up design):
https://github.com/hyperledger/indy-plenum/pull/630

Interaction between catch-up actors and 3PC actor must be designed in scope of INDY-1299.;;;","26/Apr/18 6:09 PM;spivachuk;Created the separate task INDY-1301 for a design of the division of the whole node catch-up procedure into separate procedures for each of the replicas.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Documentation changes to How To documents due to rebrand and file / folder changes,INDY-972,24518,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,krw910,krw910,krw910,29/Nov/17 1:46 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,01/Dec/17 12:00 AM,0,,,,,,"We need to update many of the ""How To"" documents with the new release. We have rebranded sovrin to indy and changed several of the files and folder names or locations.

A google document in the ""How To"" directory contains a list of the documents and the changes necessary.

.Doc Changes for Indy Rebrand and Folder Migration
https://docs.google.com/document/d/1NCBC7o3a-G902gv7ltpQBs9ywzvC3HF58379m7TRiFM/edit#",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0vj:",,,,,,INDY 17.24: Node Perf,,,,,,,,3.0,,,,,,,,,,,,krw910,TechWritingWhiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Dec/17 7:07 AM;TechWritingWhiz;The items in this ticket are now complete. New PDF's with these changes were uploaded to the Development/Testing/How To folder in Google Drive. All other drafts were renamed as ""Deprecated"" within the file name. I then removed the deprecated copies from my shared folder in Google Drive. ;;;","02/Dec/17 1:26 AM;krw910;[~TechWritingWhiz] Looks like I made a few mistakes. Here are a few changes we need and then it all looks good.

*Rotating Keys*
 (/home/ubuntu/.sovrin/wallets/test/mywallet.wallet)
 to 
 (/home/indy/.indy-cli/wallets/sandbox/default.wallet)

*Working with Nodes and Clients-PDFv2.2.pdf*
 {color:#205081}Everywhere{color}
 The command connect should be lowercase in these instances.
 indy> {color:#d04437}Connect {color}sandbox to indy> {color:#14892c}connect {color}sandbox

To get the most stable code(recommended when adding a node to the {color:#d04437}Indy {color}sandbox)
 to
 To get the most stable code(recommended when adding a node to the {color:#14892c}Sovrin {color}sandbox)

*Everywhere*
 $ sudo apt-get install {color:#d04437}indy {color}-y
 to
 $ sudo apt-get install {color:#14892c}sovrin {color}-y

*Everywhere*
 When starting the indy cli it is all lowercase.
 $ {color:#d04437}Indy{color}
 to
 $ {color:#14892c}indy{color}

$ sudo apt-get upgrade -y {color:#d04437}indy-client{color}
 to 
 $ sudo apt-get upgrade -y {color:#14892c}indy-node{color};;;","02/Dec/17 5:45 AM;TechWritingWhiz;These items have been corrected. Updated PDF's have been uploaded to the same folder, with the older ones being renamed to contain the word ""deprecated"" in it and then 'removed'.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Searching the ledger with read_ledger,INDY-973,24536,,Story,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,mgbailey,mgbailey,29/Nov/17 5:33 AM,18/Jan/18 7:04 AM,28/Oct/23 2:47 AM,,,,,,0,help-wanted,,,,,"It is very useful to be able to search for something, such as a particular DID or verkey, in a ledger.  For a small ledger (100 or less transactions) this can easily be done by piping the output of read_ledger to grep:
{code:java}
read_ledger --type domain | grep MEPecrczs4Wh6FA12u519D{code}
For a larger ledger, the admin would first need to use --count to determine the size of the ledger, and then do a second call using the result to retrieve the entire range using --frm and --to before piping to grep.  Please provide the ability to search for something on the whole ledger.  This may be as easy as a --all flag to retrieve the entire contents of the ledger that can be used with a pipe to grep.  It is possible that --all may be inefficient with very large ledgers, so an alternative method may be to provide a --find flag with a parameter of the value sought, which would search the entire ledger. Properly written, this latter may be more efficient.  The proposed --find should return all entries that contain the value.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzwynb:",,,,,,,,,,,,,,,,,,,,,,,,,,mgbailey,SeanBohan_Sovrin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jan/18 7:04 AM;SeanBohan_Sovrin;Find expression that takes a regular expression;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The larger the pool size the slower the transactions per second,INDY-974,24537,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,sergey-shilov,krw910,krw910,29/Nov/17 6:06 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"The larger the size of a pool the slower the writes per second become. 

*Testing Setup*
Global pool setup through AWS across as many as 13 regions.
5 Globally dispersed client machines each running Libindy and load testing scripts.

Each client machine using Libindy ran 40 threads each thread sending 10 transactions. So with 5 Libindy machines it was simulating 200 clients each sending 10 transactions for a total of 2,000 transactions.

I would run this test 4 times and take the average transaction per second.

The measurement of transactions per second is done be getting the epoch time stamp from the first transaction that was sent and subtracting it from the epoch time stamp of the last transaction that was sent. The difference in the time stamps gives you the total number of seconds. 
Dividing the total transactions by the total seconds of what was committed to the ledger gives the number of transactions per second.

I started with a 7 node pool. After 4 successful runs I would wipe out the ledger and add 3 more nodes. So each run using a different pool size started with basically the same fresh ledger with the exception of the few node transactions to add the new ones to the pool.

*Results of Test*
|| Ledger Size || Pool Size || Avg Txns / Sec ||
| 8012 | 7 | 41 |
| 8023 | 10 | 35 |
| 8021 | 13 | 27 |
| 8024 | 16 | 23 |
| 6357 | 19 | 21 |
| 6705 | 22 | 18 |
| 6836 | 25 | 16 |  ",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1051,INDY-1049,INDY-1050,INDY-1052,INDY-1053,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzypw7:",,,,,,INDY 17.25,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Dec/17 12:39 AM;sergey-shilov;[~krw910] [~danielhardman] [~ashcherbakov]

Hello all,
firstly let me please introduce my vision of performance testing as I have some experience with it.

============================================================================
ABSTRACT
As a PhD I can say that one of the most important (and difficult) things in measurements is to get ""true results"", i.e. results that really correspond to things that are in scope of the investigation. For example, we want to investigate the optimality of implementation of some algorithm by measuring the time of its execution. Also current implementation of algorithm does some I/O operations with hard disk. So in this case in fact we test disk performance instead of optimality of algorithm implementation as time of disk I/O wait may be several (x10, x100, x1000) times greater than time spent on execution of algorithm instructions itself. The same situation occurs for distributed systems that use network for communication as network I/O wait may take a long time. So that each measurement should be done taking into account all causes that affect performance. If some cause may unexpectedly influence gathered results then this cause should be excluded from the experiment, especially if this cause is not under control (hard disk read/write speed, global network routing etc.).


POOL MEASUREMENTS
Our pool setup is a globally dispersed system. The main causes affecting pool performance are:
    - network I/O wait
    - hard disk I/O wait
    - nodes consensus algorithm
    - implementation of algorithms that work with tree structure and levelDB settings
Measurements using global pool setup can just show the fact that there are performance problems, but they can not determine the root causes of performance degradation. I propose to divide performance testing into several stages with different isolation level. Each stage should exclude causes of the performance degradation one by one. In this step by step performance testing the measurements using global pool setup should be the last stage. The first stages should exclude at least global network and global routing.

I propose the following test plan:
    1. Some static code analysis.
    2. Single-node read/write ledger operations without hard disk (in-memory).
    3. Single-node read/write ledger operations with hard disk (including levelDB).
    4. Multi-node read/write ledger operations using isolated local network.
    5. Multi-node read/write ledger operations using global network.

Some details for each stage:
1. Short stage to figure out obvious implementation inaccuracy like unnecessary iteration over all records and so on.
2. At this stage we can determine problems in implementation of tree algorithms by analysis of decreasing of number of read/write operations per second caused by growing number of written records.
3. Analysis of levelDB settings and hard disk usage, try to find the ways to minimise disk I/O operations (use caches, I/O batching etc.).
4. Investigation of functionality of isolated pool with different number of nodes without influence of global routing, here we can check implementation of requests processing and RBFT influence.
5. Investigation of influence of global routing and AWS infrastructure, comparing throughput degradation with isolated pool.


DISCUSSION: THRESHOLDS
The main question related to gathered results is a question of thresholds: which throughput is acceptable and which is not? I think that it is a topic of a separate discussion.
Another question is a consequence or RBFT design. It is obvious that increasing of number of pool nodes leads to the performance degradation due to the consensus algorithm: more nodes => more requests. So that the questions is: which performance degradation is acceptable and Which is not? I think that we can determine theoretical dependence graph of throughput and number of nodes as we know the number of requests to get the consensus for N nodes. So we can compare experimental results with these theoretical results to determine how far/close we are from/to acceptable results. Of course this is another topic for discussion.
============================================================================;;;","15/Dec/17 9:44 PM;ashcherbakov;Let's create separate tasks for each of the proposed steps;;;","18/Dec/17 11:01 PM;ashcherbakov;Created INDY-1049, INDY-1050, INDY-1051, INDY-1052, INDY-1053.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validator-info tool is not working with build 1.2.49,INDY-975,24538,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Highest,Done,,krw910,krw910,29/Nov/17 6:09 AM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,validator-info,,0,,,,,,"After installation of validator node try running ""validator-info -v"" or just ""validator-info"" as the indy user.

*{color:#d04437}Error{color}*
""There are no info files in /var/lib/indy""

The validator-info.log file is present, but is empty.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzx0xb:",,,,,,INDY 17.24: Node Perf,,,,,,,,,,,,,,,,,,,,ashcherbakov,dsurnin,krw910,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Nov/17 9:12 PM;dsurnin;it is still possible to use the script but with the full directory specification like this

validator-info --basedir /var/lib/indy/\{CURRENT_NETWORK_NAME} -v

 

however the fix was done;;;","29/Nov/17 10:03 PM;ashcherbakov;Fixed in RC 1.2.50 (there is a fix in Validator script only, not in the main code);;;","30/Nov/17 12:35 AM;ozheregelya;Version Info:
indy-node 1.2.50 (RC)

Steps to Validate:
1. Set up the AWS pool.
2. Run the validator-info, check data.
3. Send several tnx, run the validator-info, check changed data.
4. Stop any node, run the validator-info, check changed data.
5. Check all parameters of validator-info.
6. Check logs of validator-info.

Actual Results:
Validator-info works.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validator pools over 19 nodes lose consensus,INDY-976,24539,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Won't Do,krw910,krw910,krw910,29/Nov/17 6:20 AM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,blocked,,,,,"Once I had validator pools over 19 nodes I would start to lose consensus after 6,000 transactions. The pool would stop working and the fix is to restart all nodes in the pool. Restarting 19 nodes in a global pool by having to contact all the stewards is not acceptable.

*Testing Setup*
Global pool setup through AWS across as many as 13 regions.
5 Globally dispersed client machines each running Libindy and load testing scripts.

Each client machine using Libindy ran 40 threads each thread sending 10 transactions. So with 5 Libindy machines it was simulating 200 clients each sending 10 transactions for a total of 2,000 transactions.

I would run this test 4 times and take the average transaction per second.

The measurement of transactions per second is done be getting the epoch time stamp from the first transaction that was sent and subtracting it from the epoch time stamp of the last transaction that was sent. The difference in the time stamps gives you the total number of seconds. 
Dividing the total transactions by the total seconds of what was committed to the ledger gives the number of transactions per second.

I started with a 7 node pool. After 4 successful runs I would wipe out the ledger and add 3 more nodes. So each run using a different pool size started with basically the same fresh ledger with the exception of the few node transactions to add the new ones to the pool.

*Results of Test*
Each test run should produce a little over 8.000 transactions. As you can see below once I got over 6,000 transactions I started losing consensus.


|| Ledger Size || Pool Size || Avg Txns / Sec ||
| 8012 | 7 | 41 |
| 8023 | 10 | 35 |
| 8021 | 13 | 27 |
| 8024 | 16 | 23 |
| 6357 | 19 | 21 |
| 6705 | 22 | 18 |
| 6836 | 25 | 16 |  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzx0z3:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,dsurnin,krw910,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Dec/17 5:43 PM;dsurnin;Kelly is going to attach some logs soon;;;","13/Dec/17 4:13 PM;dsurnin;from dialog with Kelly

kelly.wilson [1:20 AM] 
I have not been able to reproduce the issue. I had one node fall out of sync with the pool during the testing. When I logged the issue the pool had the same ledger count of 6357 txns, but would not accept any new ones. I guess assign the ticket back to me in the backlog and I will have to keep an eye on it to see if it happens again.
While trying to reproduce the issue I ran into another one that I am looking into. I sent 25,000 txns and the ledger wrote 25,082 txns. So it appears I ended up with 82 duplicates. I am working through that information now before I log anything.;;;","13/Dec/17 5:06 PM;ashcherbakov;[~krw910] [~dsurnin]
I think the issue may be already fixed in the scope of INDY-911 and INDY-960.;;;","15/Dec/17 12:41 AM;sergey-shilov;[~krw910] [~danielhardman] [~ashcherbakov]

Hello all,
firstly let me please introduce my vision of performance testing as I have some experience with it.

============================================================================
ABSTRACT
As a PhD I can say that one of the most important (and difficult) things in measurements is to get ""true results"", i.e. results that really correspond to things that are in scope of the investigation. For example, we want to investigate the optimality of implementation of some algorithm by measuring the time of its execution. Also current implementation of algorithm does some I/O operations with hard disk. So in this case in fact we test disk performance instead of optimality of algorithm implementation as time of disk I/O wait may be several (x10, x100, x1000) times greater than time spent on execution of algorithm instructions itself. The same situation occurs for distributed systems that use network for communication as network I/O wait may take a long time. So that each measurement should be done taking into account all causes that affect performance. If some cause may unexpectedly influence gathered results then this cause should be excluded from the experiment, especially if this cause is not under control (hard disk read/write speed, global network routing etc.).


POOL MEASUREMENTS
Our pool setup is a globally dispersed system. The main causes affecting pool performance are:
    - network I/O wait
    - hard disk I/O wait
    - nodes consensus algorithm
    - implementation of algorithms that work with tree structure and levelDB settings
Measurements using global pool setup can just show the fact that there are performance problems, but they can not determine the root causes of performance degradation. I propose to divide performance testing into several stages with different isolation level. Each stage should exclude causes of the performance degradation one by one. In this step by step performance testing the measurements using global pool setup should be the last stage. The first stages should exclude at least global network and global routing.

I propose the following test plan:
    1. Some static code analysis.
    2. Single-node read/write ledger operations without hard disk (in-memory).
    3. Single-node read/write ledger operations with hard disk (including levelDB).
    4. Multi-node read/write ledger operations using isolated local network.
    5. Multi-node read/write ledger operations using global network.

Some details for each stage:
1. Short stage to figure out obvious implementation inaccuracy like unnecessary iteration over all records and so on.
2. At this stage we can determine problems in implementation of tree algorithms by analysis of decreasing of number of read/write operations per second caused by growing number of written records.
3. Analysis of levelDB settings and hard disk usage, try to find the ways to minimise disk I/O operations (use caches, I/O batching etc.).
4. Investigation of functionality of isolated pool with different number of nodes without influence of global routing, here we can check implementation of requests processing and RBFT influence.
5. Investigation of influence of global routing and AWS infrastructure, comparing throughput degradation with isolated pool.


DISCUSSION: THRESHOLDS
The main question related to gathered results is a question of thresholds: which throughput is acceptable and which is not? I think that it is a topic of a separate discussion.
Another question is a consequence or RBFT design. It is obvious that increasing of number of pool nodes leads to the performance degradation due to the consensus algorithm: more nodes => more requests. So that the questions is: which performance degradation is acceptable and Which is not? I think that we can determine theoretical dependence graph of throughput and number of nodes as we know the number of requests to get the consensus for N nodes. So we can compare experimental results with these theoretical results to determine how far/close we are from/to acceptable results. Of course this is another topic for discussion.
============================================================================;;;","19/Dec/17 5:43 AM;krw910;I am closing this bug and opening a new one. I was not able to reproduce this ticket as it was written, but did find the issue another way. This looks like a view change issue and I will be logging a new ticket with logs around that issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The larger the ledger size the slower the transactions per second ,INDY-977,24541,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,sergey-shilov,krw910,krw910,29/Nov/17 6:30 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"The larger the size of a ledger the slower the writes per second become.

*Testing Setup*
 Global pool setup through AWS across as many as 13 regions.
 5 Globally dispersed client machines each running Libindy and load testing scripts.

Each client machine using Libindy ran 40 threads each thread sending 10 transactions. So with 5 Libindy machines it was simulating 200 clients each sending 10 transactions for a total of 2,000 transactions.

After each run of 2,000 transactions I would check the transactions per second.

The measurement of transactions per second is done be getting the epoch time stamp from the first transaction that was sent and subtracting it from the epoch time stamp of the last transaction that was sent. The difference in the time stamps gives you the total number of seconds. 
 Dividing the total transactions by the total seconds of what was committed to the ledger gives the number of transactions per second.

I ran only with a 7 node pool. The results are in increments of 2,000 transactions on the ledger.

*Results of Test*
 I will only show every 10,000 in this chart, but it steadily declines.
||Ledger Size||TXNs per Second||
|2,000|53|
|10,000|36|
|20,000|21|
|40,000|10|
|60,000|9|",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1051,INDY-1049,INDY-1050,INDY-1052,INDY-1053,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzypwv:",,,,,,INDY 17.25,,,,,,,,,,,,,,,,,,,,ashcherbakov,krw910,lovesh,ozheregelya,sergey-shilov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Nov/17 5:40 PM;lovesh;[~krw910] Were the nodes restarted during the experiment? I am trying to determine if it is the large ledger or the fact that the pool had processed lot of txns? If we restarted the pool after every 10K txns, would the results vary?;;;","09/Dec/17 3:08 AM;krw910;[~lovesh] I restarted the pool at 48k and saw a slight bump. By the time it was at 46k the txns/sec was down to 9. After restarting the pool at 48k the txns/sec went up to 13, but by the time I hit 58k they dropped again to 10 txns/sec and falling. The time between 48k and 58k was a pool up time of only 43 minutes.

 ;;;","12/Dec/17 6:34 AM;ozheregelya;The same behavior was occurred on local setup. Performance decreases during increasing ledger size. In case of restarting pool each 10000 tnx performance getting better, but it is still less than initial value and decreases to the next 10000 tnx.;;;","15/Dec/17 6:06 PM;sergey-shilov;[~krw910] [~danielhardman] [~ashcherbakov]

Hello all,
firstly let me please introduce my vision of performance testing as I have some experience with it.

============================================================================
ABSTRACT
As a PhD I can say that one of the most important (and difficult) things in measurements is to get ""true results"", i.e. results that really correspond to things that are in scope of the investigation. For example, we want to investigate the optimality of implementation of some algorithm by measuring the time of its execution. Also current implementation of algorithm does some I/O operations with hard disk. So in this case in fact we test disk performance instead of optimality of algorithm implementation as time of disk I/O wait may be several (x10, x100, x1000) times greater than time spent on execution of algorithm instructions itself. The same situation occurs for distributed systems that use network for communication as network I/O wait may take a long time. So that each measurement should be done taking into account all causes that affect performance. If some cause may unexpectedly influence gathered results then this cause should be excluded from the experiment, especially if this cause is not under control (hard disk read/write speed, global network routing etc.).


POOL MEASUREMENTS
Our pool setup is a globally dispersed system. The main causes affecting pool performance are:
    - network I/O wait
    - hard disk I/O wait
    - nodes consensus algorithm
    - implementation of algorithms that work with tree structure and levelDB settings
Measurements using global pool setup can just show the fact that there are performance problems, but they can not determine the root causes of performance degradation. I propose to divide performance testing into several stages with different isolation level. Each stage should exclude causes of the performance degradation one by one. In this step by step performance testing the measurements using global pool setup should be the last stage. The first stages should exclude at least global network and global routing.

I propose the following test plan:
    1. Some static code analysis.
    2. Single-node read/write ledger operations without hard disk (in-memory).
    3. Single-node read/write ledger operations with hard disk (including levelDB).
    4. Multi-node read/write ledger operations using isolated local network.
    5. Multi-node read/write ledger operations using global network.

Some details for each stage:
1. Short stage to figure out obvious implementation inaccuracy like unnecessary iteration over all records and so on.
2. At this stage we can determine problems in implementation of tree algorithms by analysis of decreasing of number of read/write operations per second caused by growing number of written records.
3. Analysis of levelDB settings and hard disk usage, try to find the ways to minimise disk I/O operations (use caches, I/O batching etc.).
4. Investigation of functionality of isolated pool with different number of nodes without influence of global routing, here we can check implementation of requests processing and RBFT influence.
5. Investigation of influence of global routing and AWS infrastructure, comparing throughput degradation with isolated pool.


DISCUSSION: THRESHOLDS
The main question related to gathered results is a question of thresholds: which throughput is acceptable and which is not? I think that it is a topic of a separate discussion.
Another question is a consequence or RBFT design. It is obvious that increasing of number of pool nodes leads to the performance degradation due to the consensus algorithm: more nodes => more requests. So that the questions is: which performance degradation is acceptable and Which is not? I think that we can determine theoretical dependence graph of throughput and number of nodes as we know the number of requests to get the consensus for N nodes. So we can compare experimental results with these theoretical results to determine how far/close we are from/to acceptable results. Of course this is another topic for discussion.
============================================================================;;;","15/Dec/17 9:44 PM;ashcherbakov;Let's create separate tasks for each of the proposed steps;;;","18/Dec/17 11:01 PM;ashcherbakov;Created INDY-1049, INDY-1050, INDY-1051, INDY-1052, INDY-1053.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Refactor] Apply state machine to Requests,INDY-978,24594,,Task,To Develop,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,ashcherbakov,ashcherbakov,29/Nov/17 10:04 PM,25/Oct/19 9:17 PM,28/Oct/23 2:47 AM,,,,,,0,GA-0,,,,,"replica.py contains lots of different logic for processing of all 3PC messages, Checkpoints, parts of view change, etc.
 Break the monolith.

In particular, apply state machine to Requests
 See [https://docs.google.com/document/d/1qDfyb6ALqvf7Cwrnmk0RUmyVbM2Znd7urey-8B21j6o/edit#heading=h.myn1swcdi79r]

The code may live separately. Full integration and replacement of Replica can be done in another task.",,,,,,,,,,,,,,,,,,,,,,,INDY-1121,,,,INDY-981,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-2251,,,,,,,,,,"1|i0125u:w",,,,,,Sprint 18.05,18.06,18.07 Stability & Monitoring,,,,,,8.0,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Refactor] Apply state machine to 3PC Actor,INDY-979,24595,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,andkononykhin,ashcherbakov,ashcherbakov,29/Nov/17 10:04 PM,10/Oct/19 11:58 PM,28/Oct/23 2:47 AM,10/Oct/19 11:58 PM,,,,,0,GA-0,,,,,"replica.py contains lots of different logic for processing of all 3PC messages, Checkpoints, parts of view change, etc.
Break the monolith.

In particular, create 3PC Actor and apply state machine to it
See https://docs.google.com/document/d/1qDfyb6ALqvf7Cwrnmk0RUmyVbM2Znd7urey-8B21j6o/edit#heading=h.myn1swcdi79r

The code may live separately. Full integration and replacement of Replica can be done in another task.",,,,,,,,,,,,,,INDY-1299,,,,,,,,,,,,,INDY-981,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzwydb:",,,,,,,,,,,,,,8.0,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/19 11:58 PM;ashcherbakov;We've done a lot of refactorings and improvements in the scope of PBFT View Chnage protocol.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Refactor] Create Checkpoint Actor,INDY-980,24596,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ashcherbakov,ashcherbakov,29/Nov/17 10:06 PM,11/Oct/19 12:00 AM,28/Oct/23 2:47 AM,11/Oct/19 12:00 AM,,,,,0,,,,,,"replica.py contains lots of different logic for processing of all 3PC messages, Checkpoints, parts of view change, etc.
Break the monolith.

In particular, create Checkpoint Actor and apply state machine to it
See https://docs.google.com/document/d/1qDfyb6ALqvf7Cwrnmk0RUmyVbM2Znd7urey-8B21j6o/edit#heading=h.myn1swcdi79r

The code may live separately. Full integration and replacement of Replica can be done in another task.",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-981,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzyorz:",,,,,,,,,,,,,,5.0,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 12:00 AM;ashcherbakov;We've done a lot of refactorings and improvements in the scope of PBFT View Change protocol.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Refactor] Replace replica.py with new Actors,INDY-981,24597,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,ashcherbakov,ashcherbakov,29/Nov/17 10:08 PM,11/Oct/19 12:00 AM,28/Oct/23 2:47 AM,11/Oct/19 12:00 AM,,,,,0,,,,,,"replica.py contains lots of different logic for processing of all 3PC messages, Checkpoints, parts of view change, etc.
Break the monolith.

Integrate all Request related actors together and remove replica.py (INDY-495, INDY-978, INDY-979, INDY-980)

See https://docs.google.com/document/d/1qDfyb6ALqvf7Cwrnmk0RUmyVbM2Znd7urey-8B21j6o/edit#heading=h.myn1swcdi79r

",,,,,,,,,,,,,,,,,,,,,,,INDY-978,INDY-979,INDY-980,INDY-495,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1382,,,,,,,,,,"1|hzyos7:",,,,,,,,,,,,,,8.0,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/19 12:00 AM;ashcherbakov;We've done a lot of refactorings and improvements in the scope of PBFT View Change protocol.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validator-info shows outdated information on stopped node,INDY-982,24611,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,ozheregelya,ozheregelya,30/Nov/17 12:57 AM,08/Oct/19 8:42 PM,28/Oct/23 2:47 AM,08/Oct/19 8:42 PM,,,validator-info,,0,,,,,,"*Steps to Reproduce:*
1. Set up the pool.
2. Stop any node.
3. Run validator-info on stopped node.

*Actual Results:*
Following data are shown:
{code:java}
Validator Node4 is stopped
Current time: Wednesday, November 29, 2017 2:08:48 PM
Validator DID: 4PS3EDQ3dW1tci1Bp6543CfuuebjFrg36kLAUcskGfaA
Verification Key: 68yVKe5AeXynD5A8K91aTZFjCQEoKV4hKPtauqjHa9phgitWEGkS5TR
Node Port:
Client Port:
Metrics:
Uptime: 15 minutes, 0 seconds
Total Config Transactions: 0
Total Ledger Transactions: 14
Total Pool Transactions: 4
Read Transactions/Seconds: 0.00
Write Transactions/Seconds: 0.00
Reachable Hosts: 4/4
Node1
Node2
Node3
Node4
Unreachable Hosts: 0/4
Software Versions:
indy-node: 1.2.50
sovrin: 1.1.7{code}
""Reachable Hosts: 4/4"" may confuse steward.

*Expected Results:*
Need to discuss. As an option - do not show outdated information at all, or write that information is actual at the time of last activity of node.

 ",indy-node 1.2.50 (RC),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-775,,,,,,,,,,"1|hzx1tj:",,,,,,,,,,,,,,,,,,,,,,,,,,ckochenower,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jul/18 7:22 AM;ckochenower;[~ozheregelya] - I also noticed that if you stop indy-node on a validator node and then run `validator-info -v | grep Mode` it says 'participating' or whatever Mode said before shutting down indy-node. I appears that the persistence layer (file, etc.) being read by the validator-info executable is not being updated on service shutdown.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Read_ledger can't exit correctly on one node,INDY-983,24615,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,ozheregelya,ozheregelya,30/Nov/17 2:56 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Steps to Reproduce:
1. Set up the aws pool.
2. ???
3. Run read_ledger (e.g. read_ledger --type domain --count).
=> Correct result is shown, but read_ledger didn't exit. So user have to terminate it using Ctrl+C.
4. Run read_ledger which will return nothing (e.g. read_ledger --network notexistingnetwork --type domain --count)
=> No result shown, read_ledger sucessfully exited.

Actual Results:
Read_ledger sometimes doesn't exit.

Expected Results:
Read_ledger should always exit after returning the result.

Additional Information:
The issue reproduces not stable, it was appear only on one node in the pool. Here is node IP: 35.157.4.96 (AWS pool for RC testing)",indy-node 1.2.50 (RC),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzx1tb:",,,,,,,,,,,,,,,,,,,,,,,,,,Derashe,ozheregelya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 8:14 PM;Derashe;In actual code read_ledger exits properly.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Handy tools to have,INDY-984,24621,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,stevetolman,stevetolman,30/Nov/17 7:12 AM,19/Dec/18 4:52 PM,28/Oct/23 2:47 AM,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-3,,Tools,To Do,,,,,,,,"1|hzyvj3:",,,,,,,,,,,,,,,,,,,,,,,,,,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLI,INDY-985,24622,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,stevetolman,stevetolman,30/Nov/17 7:23 AM,09/Oct/19 5:33 PM,28/Oct/23 2:47 AM,09/Oct/19 5:33 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-5,,CLI,Done,,,,,,,,"1|hzxwzj:",,,,,,,,,,,,,,,,,,,,,,,,,,stevetolman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Pool stops working: Node services stop with 1,000 simultaneous clients doing GET_NYM reads",INDY-986,24624,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,High,Done,VladimirWork,krw910,krw910,30/Nov/17 8:43 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build: 1.1.43 of indy node

*Testing Setup*
Global pool setup through AWS across 7 regions.
5 Globally dispersed client machines each running Libindy and load testing scripts.

Each client machine using Libindy ran 200 threads each thread sending 2,000 GET_NYM transactions each one at a time. So with 5 Libindy machines it was simulating 1,000 clients each sending 2,000 GET_NYM transactions for a total of 2,000,000 read transactions.

I successfully ran this with each machine simulating 150 threads per libindy machine for a total of 750 clients across 5 machines doing 1,500,000 GET_NYM transactions.

After a little over 30,000 reads from the pool the pool stopped working. I started the CLI and tried to connect, but none of the nodes would connect. The logs showed no errors so I checked the status of the node service.

Here is the error:
{code}
Traceback (most recent call last):
  File ""/usr/local/bin/start_sovrin_node"", line 19, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/utils/node_runner.py"", line 29, in run_node
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 289, in __exit__
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 285, in shutdownSync
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 275, in shutdown
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 363, in __iter__
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/utils/node_runner.py"", line 29, in run_node
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 259, in run
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 222, in runForever
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 205, in runOnceNicely
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 150, in prodAllOnce
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 361, in prod
  File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 742, in prod
  File ""/usr/local/lib/python3.5/dist-packages/plenum/server/has_action_queue.py"", line 67, in _serviceActions
  File ""/usr/local/lib/python3.5/dist-packages/plenum/server/has_action_queue.py"", line 74, in wrapper
  File ""/usr/local/lib/python3.5/dist-packages/plenum/server/validator_info_tool.py"", line 171, in dump_json_file
OSError: [Errno 24] Too many open files: '/home/sovrin/.sovrin/node1_info.json'
Error in sys.excepthook:
Traceback (most recent call last):
  File ""/usr/lib/python3/dist-packages/apport_python_hook.py"", line 63, in apport_excepthook
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 661, in exec_module
  File ""<frozen importlib._bootstrap_external>"", line 766, in get_code
  File ""<frozen importlib._bootstrap_external>"", line 818, in get_data
OSError: [Errno 24] Too many open files: '/usr/lib/python3/dist-packages/apport/__init__.py'
Original exception was:
Traceback (most recent call last):
  File ""/usr/local/bin/start_sovrin_node"", line 19, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/utils/node_runner.py"", line 29, in run_node
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 289, in __exit__
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 285, in shutdownSync
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 275, in shutdown
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 363, in __iter__
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/utils/node_runner.py"", line 29, in run_node
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 259, in run
  File ""/usr/lib/python3.5/asyncio/base_events.py"", line 387, in run_until_complete
  File ""/usr/lib/python3.5/asyncio/futures.py"", line 274, in result
  File ""/usr/lib/python3.5/asyncio/tasks.py"", line 239, in _step
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 222, in runForever
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 205, in runOnceNicely
  File ""/usr/local/lib/python3.5/dist-packages/stp_core/loop/looper.py"", line 150, in prodAllOnce
  File ""/usr/local/lib/python3.5/dist-packages/sovrin_node/server/node.py"", line 361, in prod
  File ""/usr/local/lib/python3.5/dist-packages/plenum/server/node.py"", line 742, in prod
  File ""/usr/local/lib/python3.5/dist-packages/plenum/server/has_action_queue.py"", line 67, in _serviceActions
  File ""/usr/local/lib/python3.5/dist-packages/plenum/server/has_action_queue.py"", line 74, in wrapper
  File ""/usr/local/lib/python3.5/dist-packages/plenum/server/validator_info_tool.py"", line 171, in dump_json_file
OSError: [Errno 24] Too many open files: '/home/sovrin/.sovrin/node1_info.json'
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1037,INDY-570,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-1032,,,,,,,,,,"1|hzypvj:",,,,,,INDY 17.25,,,,,,,,,,,,,,,,,,,,andkononykhin,ashcherbakov,krw910,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Dec/17 12:09 AM;andkononykhin;I was able to reproduce the case. The reason:
 * node's process reached the limit for number of open files because it held so many (about 1000) simultaneous tcp connections.
 * Soft limit for number of opened files was 1024. Each new more tcp connection was silently dropped. (I believe it is somewhere inside zmq library).
 * But node crashed during the file opening (from the level of our plenum code) because of 'Too many open files' exception

It was reproduced inside docker with nofile limit set to 100 and using simple ""telnet"" to emulate tcp connections.
 
Seems it's a quite serious issue and needs some discussion which was initiated vie email.

As a fast fix I'm going to increase soft/hard limits from default 1024/4096 to 16K/64 for node service: it will allow to perform load testing with higher number of clients and seems it is more appropriate values for node's needs (I failed to find any requirements for that).

Also new task INDY-1037 was created to review our usage of zmq because I failed to quickly find a zmq's configuration parameter to limit number of peers connections: there is a [ZMQ_MAX_SOCKETS|http://api.zeromq.org/3-2:zmq-ctx-set#toc4] parameter that we already use but it's not what we need here.

 ;;;","15/Dec/17 5:30 PM;ashcherbakov;There is also INDY-570 about limiting number of client connections.
;;;","16/Dec/17 12:26 AM;andkononykhin;Problem reason:
 - tcp connections are not limited by the app but there is an OS limit for open files that lead to exception when node exhausts the limit because of too many clients are connected
 - mentioned OS limit (nofile) by default is 1024/4096 (soft/hard) which seems too small in any case

Changes:
 - increased OS limit for node service to 16K/64K
 - further improvements are expected in scope of INDY-570 / INDY-1037 tasks

Committed into:
 - [https://github.com/hyperledger/indy-node/pull/492]
 - [https://github.com/hyperledger/indy-node/pull/494]

Risk factors:
 - Nothing is expected.

Risk:
 - Low

Covered with tests:
 - no

Recommendations for QA: version - indy-node 1.2.242 (master)
 * the issue is easily reproduced by opening 1000 connections to some node (either by using load test as in description or any kind of tool that can create tcp connection, e.g. telnet)
 * I think it should be checked for two cases:
 ## check upgrade
 ### install sovrin with indy-node <= 1.2.242 and ensure that service is running
 ### set *DUMP_VALIDATOR_INFO_PERIOD_SEC* to *10* in */usr/local/lib/python3.5/dist-packages/plenum/server/validator_info_tool.py* so the node will dump validator info more frequently (info each 10secs) and will fail faster
 ### restart indy-node service
 ### initiate 1000 connection as mentioned upper. You can check how mane connections using *lsof -p <PID> | grep TCP* under indy user (*apt-get install* *lsof* if needed)
 ### in node's logs (and journalctl) you should see exception the same as in the task description (wait for 10 secs)on clean machine
 ### do *apt-get install indy-node indy-plenum* and ensure that indy-node is >= 1.2.242
 ### do node restart.
 ### you should see warning like: *Warning: indy-node.service changed on disk. Run 'systemctl daemon-reload' to reload units.* so do the reload
 ### run restart node command again
 ### create 1000 connections again - node should work for that time without any errors or crash
 ### check more connections number: node should work up to 16K (16536) connections
 ## on clean machine
 ### install sovrin with indy-node
 ### do steps 10-11 from previous check: the same results are expected;;;","21/Dec/17 12:58 AM;VladimirWork;Build Info:
indy-node 1.2.243

Steps to Validate:
1. Run performance tests with GET_NYM txns on upgraded to 1.2.242+ version (250 threads x 4..6 clients).
2. Run performance tests with GET_NYM txns on installed 1.2.242+ version (250 threads x 4..6 clients).

Actual Results:
Pool works normally with at least 1500 simultaneous clients doing GET_NYM reads. Results with more simultaneous clients are unclear because of spontaneous threads' denials on AWS clients and issues with libindy that throws errors due to big number of requests run but there is no `OSError: [Errno 24] Too many open files` error found in nodes' logs or journalctl on any node. Test case with 16k simultaneous connections can be checked on larger AWS pool if needed in scope of new ticket.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Tickets related to code that improves the ""clean install to doing stuff"" situation with Indy",INDY-987,24625,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,SeanBohan_Sovrin,SeanBohan_Sovrin,30/Nov/17 12:22 PM,09/Oct/19 6:40 PM,28/Oct/23 2:47 AM,09/Oct/19 6:39 PM,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-7,,Onboarding,Done,,,,,,,,"1|hzyvfb:",,,,,,,,,,,,,,,,,,,,,,,,,,SeanBohan_Sovrin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change testRequestDynamicValidation test to using indy-sdk,INDY-988,24627,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,anikitinDSR,anikitinDSR,30/Nov/17 6:50 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Need to change test testRequestDynamicValidation to using indy-sdk.
For now, indy-sdk raises only general IndyError exception while getting REJECTED message.
Therefore, when corresponded functionality would be added to indy-sdk, this test should be changed.

Test location:
indy-plenum/plenum/test/batching_3pc/test_basic_batching.py",,,,,,,,,,,IS-427,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-875,,,,,,,,,,"1|hzz10n:",,,,,,Sprint 18.05,,,,,,,,1.0,,,,,,,,,,,,anikitinDSR,Derashe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Mar/18 10:38 PM;Derashe;Problem reason:
 - We need to integrate basic batching tests with sdk

Changes:
 - Requests in tests changed from python client to sdk

PR:
- [https://github.com/hyperledger/indy-plenum/pull/558|https://github.com/hyperledger/indy-plenum/pull/557]

Version:
 - master, 620

Risk factors:
 - No

Risk:
 - Low

Covered with tests:
 - No

Recommendations for QA
- ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Resolve obsolete code under example in indy-plenum and indy-node repos,INDY-989,24628,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,,lovesh,lovesh,30/Nov/17 6:54 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"The code under https://github.com/hyperledger/indy-node/tree/master/examples and https://github.com/hyperledger/indy-plenum/tree/master/examples is obsolete, we need to either discard or fix these.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-828,,,,,,,,,,"1|hzwynj:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,lovesh,SeanBohan_Sovrin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jan/18 7:02 AM;SeanBohan_Sovrin;Fix - Nathan;;;","24/May/18 6:57 PM;ashcherbakov;The code is already removed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indy-sdk tests migration,INDY-990,24629,,Epic,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Invalid,,ashcherbakov,ashcherbakov,30/Nov/17 6:55 PM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,We need to deprecate and remove all client code in indy-node and use indy-sdk in all integration tests.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-1,,Indy-sdk tests migration,Done,,,,,,,,"1|hzyox3:",,,,,,,,,,,,,,,,,,,,,,,,,,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Files in /var/lib/indy/<network_name> are marked as executable,INDY-991,24634,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Low,Done,VladimirWork,VladimirWork,VladimirWork,01/Dec/17 12:04 AM,30/Mar/19 5:33 AM,28/Oct/23 2:47 AM,30/Mar/19 5:33 AM,,,,,0,,,,,,"Build Info:
indy-node 1.2.50 (rc)

Steps to Reproduce:
1. Install pool.
2. cd /var/lib/indy/sandbox on any node.

Actual Results:
All files in /var/lib/indy/<network_name> are marked as executable.

Expected Results:
This files should not be marked as executables.

Additional Info:
The issue reproduces after installation only (but not after upgrade).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Dec/17 12:04 AM;VladimirWork;Pasted image at 2017_11_30 04_50 PM.png;https://jira.hyperledger.org/secure/attachment/13435/Pasted+image+at+2017_11_30+04_50+PM.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|hzytxj:",,,,,,Sprint 18.02 Stability,,,,,,,,,,,,,,,,,,,,anikitinDSR,mgbailey,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jan/18 11:31 PM;anikitinDSR;Not reproduced on current master;;;","27/Jan/18 12:02 AM;VladimirWork;Build Info:
indy-node 1.2.282

Steps to Validate:
1. Install pool (AWS/docker).
2. Check /var/lib/indy/<network_name>.

Actual Results:
Files in this folder are not marked as executables.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cannot move bls tests to sdk,INDY-992,24655,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,dsurnin,dsurnin,01/Dec/17 6:32 PM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,connect  to pool with invalid bls key in one node does not work,,,,,,,,,,,IS-444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-875,,,,,,,,,,"1|hzz0xj:",,,,,,18.06,,,,,,,,2.0,,,,,,,,,,,,Derashe,dsurnin,SeanBohan_Sovrin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/18 10:33 PM;dsurnin;To generate wrong bls ley tests use code like this
{code:java}
''.join(random_from_alphabet(32, base58.alphabet))
{code}

there are two issues
1 - random string from base58 decoded to key different length
2 - static validation of node does not check that the key is base 58 of valid length;;;","18/Jan/18 7:01 AM;SeanBohan_Sovrin;[~dsurnin]

Is this still an issue - please advise;;;","18/Jan/18 1:29 PM;dsurnin;[~SeanBohan_Sovrin]
Not an issue anymore, sdk is ready so we can continue to move tests to sdk;;;","20/Mar/18 12:19 AM;Derashe;Problem reason:
 - We need to integrate all tests in bls folder with sdk

Changes:
 - Tests integrated, created additional fixtures and functions

PR:
- https://github.com/hyperledger/indy-plenum/pull/564

Version:
 - master, 278

Risk factors:
 - No

Risk:
 - Low

Covered with tests:
 - No

Recommendations for QA

Check that script generate_txns.py working correctly;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Changing  test_batch_rejection to use sdk,INDY-993,24658,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,anikitinDSR,anikitinDSR,01/Dec/17 10:40 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"Need to change tests:
testViewChangeAfterBatchRejected
testMoreBatchesWillBeSentAfterViewChange.

Test location:
indy-plenum/plenum/test/batching_3pc/test_batch_rejection.py",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-875,,,,,,,,,,"1|hzz10v:",,,,,,Sprint 18.05,,,,,,,,1.0,,,,,,,,,,,,anikitinDSR,Derashe,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Mar/18 6:57 PM;Derashe;Problem reason:
 - We need to integrate betch rejection tests with sdk

Changes:
 - Requests in tests changed from python client to sdk

PR:
 - [https://github.com/hyperledger/indy-plenum/pull/558]

Version:
 - master, 602

Risk factors:
 - No

Risk:
 - Low

Covered with tests:
 - No

Recommendations for QA
 - ;;;","06/Mar/18 9:40 PM;VladimirWork;Build Info:
indy-plenum master

Steps to Validate:
1. Run `plenum/test/batching_3pc/test_batch_rejection.py` locally via pytest.
2. Run `plenum/test/batching_3pc/` tests locally via runner.py.

Actual Results:
Test is switched to sdk and passes.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change logging tests,INDY-994,24660,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,,anikitinDSR,anikitinDSR,01/Dec/17 11:06 PM,30/Mar/19 5:32 AM,28/Oct/23 2:47 AM,30/Mar/19 5:32 AM,,,,,0,,,,,,"Need to change tests for logging rejected requests.
testLoggingTxnStateForInvalidRequest
testLoggingTxnStateWhenCommitFails

Test location:

indy-plenum/plenum/test/logging/test_logging_txn_state.py",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-875,,,,,,,,,,"1|hzz113:",,,,,,Sprint 18.05,,,,,,,,2.0,,,,,,,,,,,,anikitinDSR,Derashe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Mar/18 11:14 PM;Derashe;Problem reason:
 - We need to integrate logging tests with sdk

Changes:
 - Requests in tests changed from python client to sdk

PR:
- https://github.com/hyperledger/indy-plenum/pull/559

Version:
 - master, 266

Risk factors:
 - No

Risk:
 - Low

Covered with tests:
 - No

Recommendations for QA;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node monitoring tool (email plugin) doesn't work,INDY-995,24669,,Bug,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,VladimirWork,VladimirWork,VladimirWork,02/Dec/17 2:12 AM,30/Mar/19 5:34 AM,28/Oct/23 2:47 AM,30/Mar/19 5:34 AM,,,,,0,,,,,,"Build Info:
indy-node 1.2.50 (rc)

Steps to Reproduce:
0. Install pool and make the following steps on any node.
1. apt-get install sendmail
2. Check that it works: `echo ""Subject: sendmail test"" | sendmail -v youremail@
example.com -f alert@noreply.com`
3. pip3 install sovrinnotifieremail
4. Add `SOVRIN_NOTIFIER_EMAIL_RECIPIENTS=
youremail@example.com` to your /etc/environment
5. Check messages about events emitted by pool (node).

Actual Results:
There are no messages about pool (node) activity.

Expected Results:
The tool should work as it described in manual (in attachment).",,,,,,,,,,,,,,INDY-892,,,,,,,,,,,,,,,,,,,,,"16/Jan/18 6:48 PM;VladimirWork;INDY-995.PNG;https://jira.hyperledger.org/secure/attachment/14202/INDY-995.PNG","07/Feb/18 7:26 PM;VladimirWork;INDY-995_PASS.PNG;https://jira.hyperledger.org/secure/attachment/14552/INDY-995_PASS.PNG","02/Dec/17 2:12 AM;VladimirWork;Node Monitoring Tools for Stewards- PDF.pdf;https://jira.hyperledger.org/secure/attachment/13440/Node+Monitoring+Tools+for+Stewards-+PDF.pdf","02/Feb/18 12:08 AM;VladimirWork;Node4.log;https://jira.hyperledger.org/secure/attachment/14525/Node4.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-984,,,,,,,,,,"1|hzysxr:",,,,,,Sprint 18.02 Stability,"Sprint 18.03 Stability, DKMS",,,,,,,,,,,,,,,,,,,anikitinDSR,SeanBohan_Sovrin,VladimirWork,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jan/18 7:20 AM;SeanBohan_Sovrin;can you demonstrate sendmail is configured properly by sending an email from the command line or another utility;;;","16/Jan/18 6:48 PM;VladimirWork;[~SeanBohan_Sovrin] 
bq. can you demonstrate sendmail is configured properly by sending an email from the command line or another utility
Yes, it was checked in Step 2 (I used my mail in this step): `echo ""Subject: sendmail test"" | sendmail -v youremail@example.com -f alert@noreply.com` !INDY-995.PNG|thumbnail! ;;;","30/Jan/18 12:28 AM;anikitinDSR;Problem reason: 
- list of reasons

Changes: 
- Delete sovrin from pakage and rename it to indynotifieremail

PR:
- https://github.com/evernym/sovrin-notifier-email/pull/5


Version:
- master


Risk:
- Low

Recommendations for QA
- Package name was changed. Therefore, use 'pip3 install indynotifieremail' for install;;;","02/Feb/18 12:08 AM;VladimirWork;Build Info:
indy-node 1.2.291

Steps to Reproduce:
0. Install pool and make the following steps on any node.
1. 
{noformat}
apt-get install sendmail
{noformat}

2. Check that it works: 
{noformat}
echo ""Subject: sendmail test"" | sendmail -v youremail@example.com -f alert@noreply.com
{noformat}

3. 
{noformat}
pip3 install indynotifieremail
{noformat}

4. Add `INDY_NOTIFIER_EMAIL_RECIPIENTS=
youremail@example.com` to your /etc/environment.
5. Restart indy-node.
5. Schedule and then cancel some time later the POOL_UPGRADE command.

Actual results:
There are no notifications about POOL_UPGRADE (but test messages are sent and delivered successfully). [^Node4.log] ;;;","06/Feb/18 6:57 PM;anikitinDSR;Adding INDY_NOTIFIER_EMAIL_RECIPIENTS parameter into /etc/environment will be ignore by systemd.
Possible ways are:
 # Add 'Environment' var into /etc/systemd/system/indy-node.service in 'Service' section manually and restart indy-node service.
 # Run 'systemctl import-environment INDY_NOTIFIER_EMAIL_RECIPIENTS=<some email addres>' and then restart indy-node service. This command will add environment var for all services, but not for already run. Therefore need to restart indy-node service for approve new environment var.;;;","07/Feb/18 7:26 PM;VladimirWork;Build Info:
indy-node 1.2.297

Steps to Validate:

{noformat}
1. sudo apt-get install sendmail
2. echo ""Subject: sendmail test001"" | sendmail -v vladimir.shishkin@dsr-corporation.com -f alert@noreply.com
3. pip3 install indynotifieremail
4. sudo systemctl set-environment 'INDY_NOTIFIER_EMAIL_RECIPIENTS=vladimir.shishkin@dsr-corporation.com'
5. sudo systemctl restart indy-node
{noformat}

Actua Results:
Notifications are sent successfully. !INDY-995_PASS.PNG|thumbnail! 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Security tickets and bugs,INDY-996,24692,,Epic,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,SeanBohan_Sovrin,SeanBohan_Sovrin,02/Dec/17 7:15 AM,08/Feb/18 5:41 AM,28/Oct/23 2:47 AM,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ghx-label-3,,Security,To Do,,,,,,,,"1|hzyvhb:",,,,,,,,,,,,,,,,,,,,,,,,,,SeanBohan_Sovrin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Split private Jenkins shared repos into public and private,INDY-997,24700,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Done,andrey.goncharov,andkononykhin,andkononykhin,04/Dec/17 4:39 PM,30/Mar/19 5:35 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,REFACTORING,,,,,"Currently CD routine for both building and publishing is placed in private [jenkins-shared|https://github.com/evernym/jenkins-shared] and [sovrin-packaging|https://github.com/evernym/sovrin-packaging] repos. And it makes really hard to contribute for developers from outside the Evernym organization.

The solution could be to split mentioned private repos to private and public parts:
 * Public part will get the code for building. It also could define common CD pipeline steps sequence, implement them as a templates and provide an API to pass things specific for different environment (like credentials references, callback functions for delivering logic etc.). Also someday we can move there CI logic to resolve copy-paste madness between Jenkinsfile.ci in Indy core github repos.
 * private will keep all things specific for Evernym company (like credentials references, publishing: packaging repos endpoints, specific logic of debian/centos... management). It will configure the public part

Also once we make public repo we should be able to verify PRs for it. Thus, we need testing pipeline on Jenkins as well.",,,,,,,,,,,,,,INDY-580,,,,,,,,,,,,,INDY-998,INDY-999,INDY-964,INDY-965,INDY-1194,INDY-1195,INDY-1196,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-47,,,,,,,,,,"1|hzyrav:",,,,,,INDY 17.25,INDY 18.01: Stability+,Sprint 18.02 Stability,"Sprint 18.03 Stability, DKMS",Sprint 18.04,,,,5.0,,,,,,,,,,,,andkononykhin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Dec/17 2:39 AM;andkononykhin;PoA:
 # create private github repo *indy-jenkins-pipeline-lib* in evernym org account
 # split `evernym/jenkins-shared` into public and private parts:
    - public: 
        - common groovy helpers 
        - testing 
        - packaging (debs building)
    - private: 
        - publishing logic which includes usage of credentials references and api endpoints
 # move public part into 'indy-jenkins-lib' and leave the rest in jcurrent location
 # ask [~danielhardman] and/or [~tharmon] to review and make the repo public by moving it to Hypereldger org
 # update Jenkinsfile.cd in indy github repos to use public shared lib with optional linking to other (private) lib for some stages (publishing first of all);;;","31/Jan/18 9:18 PM;andkononykhin;[https://github.com/evernym/jenkins-shared/pull/27]
 [https://github.com/evernym/jenkins-shared/pull/26]

Summary about changes:
 # all CI related things are grouped in public part, CD logics - in private part
 ** prefixes for global variables/functions:_indy_ - for public, _evernym_ - for private
 ** steps:
 *** public part expose a set of steps with ability to extend/replace them using [indyStagesInit|https://github.com/evernym/jenkins-shared/tree/feature/INDY-997_public-lib#indystagesinit] function which is virtual. First of all It was designed so to extend _indyPublish_ step.
 *** private implements head-publish step [evernymPublish|https://github.com/evernym/jenkins-shared/blob/feature/INDY-997_private-lib/vars/evernymPublish.groovy]
 # Configuration:
 ** All configuration related things localized inside configuration steps:
 *** [indyConfig|https://github.com/evernym/jenkins-shared/blob/feature/INDY-997_public-lib/vars/indyConfig.groovy]
 *** [evernymConfig|https://github.com/evernym/jenkins-shared/blob/feature/INDY-997_private-lib/vars/evernymConfig.groovy].
 ** config parameters could be adjusted either via job's env or parameters
 ** default values including privacy sensitive things for private library located in [evernymDefaults|https://github.com/evernym/jenkins-shared/blob/feature/INDY-997_private-lib/vars/evernymDefaults.groovy]
 # more accurate folder hierarchy:
 ** _vars_ - for global steps
 ** _src_ - for class based APIs
 ** _resources_ - for necessary non-groovy resources
 ** _src_ and _resources_ have got deeper hierarchy to match for java classpaths standard (e.g. `_src/org/hyperledger/pipeline/indy_`, `_resources/com/evernym/pipeline_`)
 # use of closure-based steps configuration pattern (""builder pattern"")  described [here|https://jenkins.io/blog/2016/04/21/dsl-plugins/]. Also see [Readme|https://github.com/evernym/jenkins-shared/blob/feature/INDY-997_public-lib/README.md] for public part.
 # examples of the pipelines: [ci|https://github.com/hyperledger/indy-node/blob/feature/indy-997_new_jenkins_api/Jenkinsfile.ci], [cd|https://github.com/hyperledger/indy-node/blob/feature/indy-997_new_jenkins_api/Jenkinsfile.cd]

Waiting technical review by [~andrey.goncharov];;;","27/Feb/18 5:08 PM;andkononykhin;PRs were aproved by [~andrey.goncharov].

[https://github.com/evernym/jenkins-shared/pull/27]
 [https://github.com/evernym/jenkins-shared/pull/26]

And were merged:
public https://github.com/evernym/jenkins-shared/tree/indy-public
private https://github.com/evernym/jenkins-shared/tree/indy-private

Currently we are waiting approvals from Evernym repo's owners to move public part code to public repository.

Also I've created new tasks to update pipelines for indy repos to use the new approach: INDY-1194, INDY-1195, INDY-1196.;;;","01/Mar/18 7:19 PM;andkononykhin;Public part code was landed here:

https://github.com/hyperledger/indy-jenkins-pipeline-lib;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test pipelines for CD logic,INDY-998,24701,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,andkononykhin,andkononykhin,04/Dec/17 4:50 PM,21/Sep/18 4:52 PM,28/Oct/23 2:47 AM,,,,,,0,devops,,,,,Our CD logic currently not covered by any Jenkins testing. As long as our CD logic is private is not critical. But once we make it public (partly at least) we should have a way to test and verify proposed changes.,,,,,,,,,,,,,,,,,,,,,,,INDY-997,,,,INDY-999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-47,,,,,,,,,,"1|hzwynr:",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Parameterize CD pipeline to be able to skip some steps,INDY-999,24702,,Task,New,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,,,andkononykhin,andkononykhin,04/Dec/17 4:54 PM,21/Sep/18 4:51 PM,28/Oct/23 2:47 AM,,,,,,0,devops,,,,,Need some kine of dry-run option for CD pipelines to have an ability to skip publishing and tests some other steps.,,,,,,,,,,,,,,,,,,,,,,,INDY-997,INDY-998,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-47,,,,,,,,,,"1|hzwynz:",,,,,,,,,,,,,,,,,,,,,,,,,,andkononykhin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Yum repository to serve CentOS packages,INDY-1000,24703,,Task,Complete,INDY,Indy Node,software,nage,The server portion of an Indy identity network.,https://github.com/hyperledger/indy-node,Medium,Won't Do,andkononykhin,andkononykhin,andkononykhin,04/Dec/17 5:29 PM,18/Jul/19 1:01 AM,28/Oct/23 2:47 AM,30/Mar/19 5:35 AM,,,,,0,,,,,,"Once CentOS CI testing and packaging is done we need to publish the packages to somewhere. Seems, it's not a problem to set up it on ubuntu machine as long as [creatrepo|http://manpages.ubuntu.com/manpages/xenial/man8/createrepo.8.html] is available. Thus, we can create yum repository on the same machine as apt one (repo.sovrin.org)",,,,,,,,,,,,,,,,,,,,,,,,,,,IS-1318,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INDY-47,,,,,,,,,,"1|hzypyn:",,,,,,INDY 17.25,,,,,,,,3.0,,,,,,,,,,,,andkononykhin,ashcherbakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Dec/17 2:43 AM;andkononykhin;PoA:
 # create and configure yum repo locally on ubuntu machine (virtual, docker) and populate it with some rpms
 # verify that it works for centos client machine
 # create yum repo on Sovrin production server repo.sovrin.org
 # test that it works as well;;;","20/Dec/17 9:40 PM;ashcherbakov;[~tharmon]'s team has been already working on it, and created a base.
We will close this ticket as Won't Fix, and create another one to integrate indy with the Trev's team solution.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
